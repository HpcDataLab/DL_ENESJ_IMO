{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "import os\n",
    "import cv2\n",
    "import pickle\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataPath = \"../../data/OCT/OCT2017/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of Classes Detected : 4\n"
     ]
    }
   ],
   "source": [
    "labels_available = os.listdir(os.path.join(dataPath, \"train\"))\n",
    "print(\"Total Number of Classes Detected :\",len(labels_available))\n",
    "\n",
    "labels_list = ['NORMAL',\"CNV\",\"DME\",\"DRUSEN\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NORMAL CNV DME DRUSEN "
     ]
    }
   ],
   "source": [
    "images=[]\n",
    "y_trn=[]\n",
    "for x in labels_list:\n",
    "    xPath = os.path.join(dataPath, \"train\", x)\n",
    "    myPicList = os.listdir(xPath)\n",
    "    for y in myPicList:\n",
    "        images.append(cv2.imread(os.path.join(xPath, y)))\n",
    "        y_trn.append(labels_list.index(x))\n",
    "    print(x ,end=\" \")\n",
    "\n",
    "y_train = to_categorical(y_trn,len(labels_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NORMAL CNV DME DRUSEN "
     ]
    }
   ],
   "source": [
    "x_val=[]\n",
    "y_val=[]\n",
    "for x in labels_list:\n",
    "    xPath = os.path.join(dataPath, \"val\", x)\n",
    "    myPicList = os.listdir(xPath)\n",
    "    for y in myPicList:\n",
    "        x_val.append(cv2.imread(os.path.join(xPath, y)))\n",
    "        y_val.append(labels_list.index(x))\n",
    "    print(x ,end=\" \")\n",
    "\n",
    "y_validation = to_categorical(y_val,len(labels_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NORMAL CNV DME DRUSEN "
     ]
    }
   ],
   "source": [
    "x_tst=[]\n",
    "y_tst=[]\n",
    "for x in labels_list:\n",
    "    xPath = os.path.join(dataPath, \"test\", x)\n",
    "    myPicList = os.listdir(xPath)\n",
    "    for y in myPicList:\n",
    "        x_tst.append(cv2.imread(os.path.join(xPath, y)))\n",
    "        y_tst.append(labels_list.index(x))\n",
    "    print(x ,end=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resizeIm(im, size):\n",
    "    if im.shape[2] == 1:\n",
    "        im = cv2.cvtColor(im,cv2.COLOR_GRAY2RGB)\n",
    "    return cv2.resize(im, size)\n",
    "\n",
    "def resizeIms(x, size):\n",
    "    return np.array(list(map(lambda im: resizeIm(im, size), x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self,fraction, model):\n",
    "        super(CustomCallback,self).__init__()\n",
    "        self.fraction = fraction\n",
    "        self.train_a = [];\n",
    "        self.val_a =[];\n",
    "        self.logPath = os.path.join(model, \"log.txt\")\n",
    "\n",
    "        if not os.path.isdir(model):\n",
    "            os.mkdir(model)\n",
    "\n",
    "        with open(self.logPath,'w') as f:\n",
    "            f.write('Starting of logging..\\n')\n",
    "\n",
    "        self.fig = plt.figure(figsize=(4,3))\n",
    "        self.ax = plt.subplot(1,1,1)\n",
    "        plt.ion()\n",
    "\n",
    "    def on_train_begin(self,logs=None):\n",
    "        self.fig.show()\n",
    "        self.fig.canvas.draw()\n",
    "\n",
    "    def on_train_end(self,logs=None):\n",
    "        with open(self.logPath,'a') as f:\n",
    "              f.write('End of logging..\\n')\n",
    "    \n",
    "    def on_epoch_begin(self,epoch,logs=None):\n",
    "        lr= tf.keras.backend.get_value(self.model.optimizer.lr)\n",
    "        lr *= self.fraction\n",
    "        tf.keras.backend.set_value(self.model.optimizer.lr,lr)\n",
    "        with open(self.logPath,'a') as f:\n",
    "            f.write('At epoch {:02d}, learning rate changed to {:.4f}\\n'.format(epoch,lr))\n",
    "    \n",
    "    def on_epoch_end(self,epoch,logs=None):\n",
    "        val_acc = logs.get('val_accuracy')\n",
    "        train_acc = logs.get('accuracy')\n",
    "        self.train_a.append(train_acc)\n",
    "        self.val_a.append(val_acc)\n",
    "        with open(self.logPath,'a') as f:\n",
    "            f.write('At epoch {:02d}, training accuracy: {:.3f}, validation accuracy: {:.3f}\\n'.format(epoch,train_acc,val_acc))\n",
    "        self.ax.clear()\n",
    "        self.ax.plot(range(1+epoch),self.train_a,label=\"Training\")\n",
    "        self.ax.plot(range(1+epoch),self.val_a,label=\"Validation\")\n",
    "        self.ax.set_xlabel('Epochs')\n",
    "        self.ax.set_ylabel('Accuracy')\n",
    "        self.ax.legend()\n",
    "        self.fig.canvas.draw()\n",
    "        self.fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xception base model\n",
    "from tensorflow.keras.applications.xception import Xception\n",
    "from tensorflow.keras.applications.xception import preprocess_input, decode_predictions\n",
    "xceptionNetModel = Xception(weights='imagenet')\n",
    "\n",
    "# opticnet base model\n",
    "opticNetModel = tf.keras.models.load_model('../Optic_net-4_classes-Kermany2018.hdf5')\n",
    "\n",
    "# resnet base model\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "\n",
    "resNetModel = ResNet50(weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emptyModelGenerator(model, newWeights=False):\n",
    "    model = model.lower()\n",
    "    if model == \"resnet\":\n",
    "        x = resNetModel.output\n",
    "        predictions = Dense(len(labels_list), activation='softmax')(x)\n",
    "        newModel = Model(inputs=resNetModel.input, outputs=predictions)\n",
    "        size = (224, 224)\n",
    "    elif model == \"xception\":\n",
    "        x = xceptionNetModel.output\n",
    "        predictions = Dense(len(labels_list), activation='softmax')(x)\n",
    "        newModel = Model(inputs=xceptionNetModel.input, outputs=predictions)\n",
    "        size = (299, 299)\n",
    "    elif model == \"opticnet\":\n",
    "        newModel = tf.keras.models.load_model('../Optic_net-4_classes-Kermany2018.hdf5')\n",
    "        size = (224, 224)\n",
    "    if newWeights:\n",
    "        newModel = tf.keras.models.clone_model(newModel)\n",
    "    return newModel, size\n",
    "\n",
    "\n",
    "def testPredict(model, size, name=None):\n",
    "    X_test = resizeIms(x_tst, size)\n",
    "    X_test = np.array(X_test)\n",
    "    Y_test = np.array(y_tst)\n",
    "    \n",
    "    prediction = model.predict(X_test)\n",
    "    preds = np.argmax(prediction, axis=1)\n",
    "    acc = sum(preds == Y_test) / len(Y_test)\n",
    "    print(f'Test acc for {name if name else \"model\"}: {acc:.6f}')\n",
    "    \n",
    "\n",
    "def computeConfussionMatrix(predictions, labels):\n",
    "    num_labels = len(labels_list)\n",
    "    cMatrix = np.zeros(shape=(num_labels, num_labels))\n",
    "    for i in len(predictions):\n",
    "        p = int(predictions[i])\n",
    "        t = int(predictions[i])\n",
    "        cMatrix[t, p] += 1\n",
    "    print(cMatrix)\n",
    "    ax = sns.heatmap(cMatrix, cmap=\"Blues\", annot=True, fmt=\"d\", xticklabels=labels_list, yticklabels=labels_list)\n",
    "    plt.xlabel(\"Predicted label\")\n",
    "    plt.ylabel(\"True label\")\n",
    "    plt.title(\"Confusion matrix\")\n",
    "    plt.show();\n",
    "    return cMatrix\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = Adam(learning_rate=0.001)\n",
    "epochs = 30\n",
    "batch_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels fraction: [1. 1. 1. 1.]\n",
      "Training xception for 1.0% of train size (aka 83484 images)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "   6/1670 [..............................] - ETA: 27:38 - loss: 1.3790 - accuracy: 0.3903WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1562s vs `on_train_batch_begin` time: 0.1563s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1562s vs `on_train_batch_end` time: 0.5441s). Check your callbacks.\n",
      "1670/1670 [==============================] - 1307s 772ms/step - loss: 0.9535 - accuracy: 0.8207 - val_loss: 0.4980 - val_accuracy: 0.9062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "1670/1670 [==============================] - 1289s 772ms/step - loss: 0.3525 - accuracy: 0.9311 - val_loss: 0.1433 - val_accuracy: 1.0000\n",
      "Epoch 3/30\n",
      "1670/1670 [==============================] - 1295s 775ms/step - loss: 0.2152 - accuracy: 0.9512 - val_loss: 0.0696 - val_accuracy: 1.0000\n",
      "Epoch 4/30\n",
      "1670/1670 [==============================] - 1289s 772ms/step - loss: 0.1476 - accuracy: 0.9633 - val_loss: 0.0558 - val_accuracy: 1.0000\n",
      "Epoch 5/30\n",
      "1670/1670 [==============================] - 1290s 772ms/step - loss: 0.1145 - accuracy: 0.9705 - val_loss: 0.0510 - val_accuracy: 1.0000\n",
      "Epoch 6/30\n",
      "1670/1670 [==============================] - 1295s 775ms/step - loss: 0.0849 - accuracy: 0.9777 - val_loss: 0.0270 - val_accuracy: 1.0000\n",
      "Epoch 7/30\n",
      "1670/1670 [==============================] - 1301s 779ms/step - loss: 0.0680 - accuracy: 0.9823 - val_loss: 0.0321 - val_accuracy: 1.0000\n",
      "Epoch 8/30\n",
      "1670/1670 [==============================] - 1301s 779ms/step - loss: 0.0511 - accuracy: 0.9874 - val_loss: 0.0134 - val_accuracy: 1.0000\n",
      "Epoch 9/30\n",
      "1670/1670 [==============================] - 1292s 773ms/step - loss: 0.0431 - accuracy: 0.9897 - val_loss: 0.0323 - val_accuracy: 1.0000\n",
      "Epoch 10/30\n",
      "1670/1670 [==============================] - 1292s 774ms/step - loss: 0.0367 - accuracy: 0.9916 - val_loss: 0.0295 - val_accuracy: 1.0000\n",
      "Epoch 11/30\n",
      "1670/1670 [==============================] - 1295s 775ms/step - loss: 0.0305 - accuracy: 0.9925 - val_loss: 0.0245 - val_accuracy: 1.0000\n",
      "Epoch 12/30\n",
      "1670/1670 [==============================] - 1298s 777ms/step - loss: 0.0290 - accuracy: 0.9931 - val_loss: 0.0338 - val_accuracy: 0.9688\n",
      "Epoch 13/30\n",
      "1670/1670 [==============================] - 1296s 776ms/step - loss: 0.0257 - accuracy: 0.9940 - val_loss: 0.0207 - val_accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "1670/1670 [==============================] - 1296s 776ms/step - loss: 0.0217 - accuracy: 0.9943 - val_loss: 0.0229 - val_accuracy: 1.0000\n",
      "Epoch 15/30\n",
      "1670/1670 [==============================] - 1296s 776ms/step - loss: 0.0195 - accuracy: 0.9948 - val_loss: 0.0276 - val_accuracy: 0.9688\n",
      "Epoch 16/30\n",
      "1670/1670 [==============================] - 1299s 778ms/step - loss: 0.0172 - accuracy: 0.9953 - val_loss: 0.0294 - val_accuracy: 0.9688\n",
      "Epoch 17/30\n",
      "1670/1670 [==============================] - 1301s 779ms/step - loss: 0.0150 - accuracy: 0.9957 - val_loss: 0.0261 - val_accuracy: 0.9688\n",
      "Epoch 18/30\n",
      "1670/1670 [==============================] - 1301s 779ms/step - loss: 0.0151 - accuracy: 0.9953 - val_loss: 0.0271 - val_accuracy: 0.9688\n",
      "Epoch 19/30\n",
      "1670/1670 [==============================] - 1295s 776ms/step - loss: 0.0139 - accuracy: 0.9957 - val_loss: 0.0255 - val_accuracy: 0.9688\n",
      "Epoch 20/30\n",
      "1670/1670 [==============================] - 1296s 776ms/step - loss: 0.0134 - accuracy: 0.9962 - val_loss: 0.0293 - val_accuracy: 0.9688\n",
      "Epoch 21/30\n",
      "1670/1670 [==============================] - 1295s 775ms/step - loss: 0.0127 - accuracy: 0.9962 - val_loss: 0.0247 - val_accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "1670/1670 [==============================] - 1295s 775ms/step - loss: 0.0111 - accuracy: 0.9963 - val_loss: 0.0248 - val_accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "1670/1670 [==============================] - 1293s 774ms/step - loss: 0.0119 - accuracy: 0.9963 - val_loss: 0.0224 - val_accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "1670/1670 [==============================] - 1293s 774ms/step - loss: 0.0108 - accuracy: 0.9964 - val_loss: 0.0256 - val_accuracy: 0.9688\n",
      "Epoch 25/30\n",
      "1670/1670 [==============================] - 1288s 771ms/step - loss: 0.0111 - accuracy: 0.9962 - val_loss: 0.0267 - val_accuracy: 0.9688\n",
      "Epoch 26/30\n",
      "1670/1670 [==============================] - 1291s 773ms/step - loss: 0.0115 - accuracy: 0.9964 - val_loss: 0.0262 - val_accuracy: 0.9688\n",
      "Epoch 27/30\n",
      "1670/1670 [==============================] - 1290s 772ms/step - loss: 0.0098 - accuracy: 0.9964 - val_loss: 0.0223 - val_accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "1670/1670 [==============================] - 1292s 774ms/step - loss: 0.0107 - accuracy: 0.9961 - val_loss: 0.0244 - val_accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "1670/1670 [==============================] - 1289s 772ms/step - loss: 0.0109 - accuracy: 0.9961 - val_loss: 0.0248 - val_accuracy: 0.9688\n",
      "Epoch 30/30\n",
      "1670/1670 [==============================] - 1291s 773ms/step - loss: 0.0107 - accuracy: 0.9965 - val_loss: 0.0225 - val_accuracy: 1.0000\n",
      "INFO:tensorflow:Assets written to: ../xception/xception_30epochs_83484.0 images/assets\n",
      "Test acc for xception: 0.998967\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training resnet for 1.0% of train size (aka 83484 images)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "   6/1670 [..............................] - ETA: 19:39 - loss: 1.3733 - accuracy: 0.5187WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0993s vs `on_train_batch_begin` time: 0.1996s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0993s vs `on_train_batch_end` time: 0.3085s). Check your callbacks.\n",
      "1670/1670 [==============================] - 342s 201ms/step - loss: 1.0367 - accuracy: 0.7468 - val_loss: 0.7267 - val_accuracy: 0.5938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "1670/1670 [==============================] - 331s 198ms/step - loss: 0.4630 - accuracy: 0.8872 - val_loss: 0.1919 - val_accuracy: 1.0000\n",
      "Epoch 3/30\n",
      "1670/1670 [==============================] - 331s 198ms/step - loss: 0.2853 - accuracy: 0.9269 - val_loss: 0.1587 - val_accuracy: 0.9688\n",
      "Epoch 4/30\n",
      "1670/1670 [==============================] - 331s 198ms/step - loss: 0.2005 - accuracy: 0.9468 - val_loss: 0.1087 - val_accuracy: 0.9375\n",
      "Epoch 5/30\n",
      "1670/1670 [==============================] - 331s 198ms/step - loss: 0.1572 - accuracy: 0.9561 - val_loss: 0.0819 - val_accuracy: 0.9688\n",
      "Epoch 6/30\n",
      "1670/1670 [==============================] - 331s 198ms/step - loss: 0.1344 - accuracy: 0.9623 - val_loss: 0.0300 - val_accuracy: 1.0000\n",
      "Epoch 7/30\n",
      "1670/1670 [==============================] - 331s 198ms/step - loss: 0.1127 - accuracy: 0.9674 - val_loss: 0.0565 - val_accuracy: 0.9688\n",
      "Epoch 8/30\n",
      "1670/1670 [==============================] - 332s 199ms/step - loss: 0.0946 - accuracy: 0.9719 - val_loss: 0.0421 - val_accuracy: 1.0000\n",
      "Epoch 9/30\n",
      "1670/1670 [==============================] - 331s 198ms/step - loss: 0.0804 - accuracy: 0.9765 - val_loss: 0.0391 - val_accuracy: 1.0000\n",
      "Epoch 10/30\n",
      "1670/1670 [==============================] - 331s 198ms/step - loss: 0.0676 - accuracy: 0.9810 - val_loss: 0.0132 - val_accuracy: 1.0000\n",
      "Epoch 11/30\n",
      "1670/1670 [==============================] - 331s 198ms/step - loss: 0.0584 - accuracy: 0.9841 - val_loss: 0.2215 - val_accuracy: 0.9062\n",
      "Epoch 12/30\n",
      "1670/1670 [==============================] - 331s 198ms/step - loss: 0.0469 - accuracy: 0.9878 - val_loss: 0.0612 - val_accuracy: 0.9688\n",
      "Epoch 13/30\n",
      "1670/1670 [==============================] - 332s 199ms/step - loss: 0.0430 - accuracy: 0.9888 - val_loss: 0.0276 - val_accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "1670/1670 [==============================] - 333s 199ms/step - loss: 0.0367 - accuracy: 0.9910 - val_loss: 0.0230 - val_accuracy: 1.0000\n",
      "Epoch 15/30\n",
      "1670/1670 [==============================] - 332s 199ms/step - loss: 0.0331 - accuracy: 0.9920 - val_loss: 0.0190 - val_accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "1670/1670 [==============================] - 332s 199ms/step - loss: 0.0298 - accuracy: 0.9928 - val_loss: 0.0182 - val_accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "1670/1670 [==============================] - 332s 199ms/step - loss: 0.0291 - accuracy: 0.9928 - val_loss: 0.0172 - val_accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "1670/1670 [==============================] - 332s 199ms/step - loss: 0.0258 - accuracy: 0.9935 - val_loss: 0.0124 - val_accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "1670/1670 [==============================] - 332s 199ms/step - loss: 0.0226 - accuracy: 0.9944 - val_loss: 0.0163 - val_accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "1670/1670 [==============================] - 332s 199ms/step - loss: 0.0226 - accuracy: 0.9942 - val_loss: 0.0308 - val_accuracy: 0.9688\n",
      "Epoch 21/30\n",
      "1670/1670 [==============================] - 332s 199ms/step - loss: 0.0205 - accuracy: 0.9946 - val_loss: 0.0220 - val_accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "1670/1670 [==============================] - 333s 199ms/step - loss: 0.0193 - accuracy: 0.9947 - val_loss: 0.0232 - val_accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "1670/1670 [==============================] - 332s 199ms/step - loss: 0.0167 - accuracy: 0.9956 - val_loss: 0.0229 - val_accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "1670/1670 [==============================] - 332s 199ms/step - loss: 0.0156 - accuracy: 0.9957 - val_loss: 0.0209 - val_accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "1670/1670 [==============================] - 333s 199ms/step - loss: 0.0147 - accuracy: 0.9956 - val_loss: 0.0115 - val_accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "1670/1670 [==============================] - 332s 199ms/step - loss: 0.0159 - accuracy: 0.9952 - val_loss: 0.0187 - val_accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "1670/1670 [==============================] - 332s 199ms/step - loss: 0.0154 - accuracy: 0.9954 - val_loss: 0.0212 - val_accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "1670/1670 [==============================] - 332s 199ms/step - loss: 0.0153 - accuracy: 0.9957 - val_loss: 0.0142 - val_accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "1670/1670 [==============================] - 332s 199ms/step - loss: 0.0141 - accuracy: 0.9961 - val_loss: 0.0166 - val_accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "1670/1670 [==============================] - 333s 199ms/step - loss: 0.0126 - accuracy: 0.9962 - val_loss: 0.0191 - val_accuracy: 1.0000\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_83484.0 images/assets\n",
      "Test acc for resnet: 0.996901\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training opticnet for 1.0% of train size (aka 83484 images)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "   6/1670 [..............................] - ETA: 50:18 - loss: 5.2586 - accuracy: 0.1687 WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.4647s vs `on_train_batch_end` time: 0.9613s). Check your callbacks.\n",
      "1670/1670 [==============================] - 2003s 1s/step - loss: 0.2919 - accuracy: 0.9144 - val_loss: 0.0393 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "1670/1670 [==============================] - 1977s 1s/step - loss: 0.1196 - accuracy: 0.9601 - val_loss: 0.0157 - val_accuracy: 1.0000\n",
      "Epoch 3/30\n",
      "1670/1670 [==============================] - 1976s 1s/step - loss: 0.1042 - accuracy: 0.9647 - val_loss: 0.0042 - val_accuracy: 1.0000\n",
      "Epoch 4/30\n",
      "1670/1670 [==============================] - 1976s 1s/step - loss: 0.0864 - accuracy: 0.9707 - val_loss: 0.0268 - val_accuracy: 1.0000\n",
      "Epoch 5/30\n",
      "1670/1670 [==============================] - 1976s 1s/step - loss: 0.0667 - accuracy: 0.9766 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
      "Epoch 6/30\n",
      "1670/1670 [==============================] - 1976s 1s/step - loss: 0.0573 - accuracy: 0.9802 - val_loss: 0.1028 - val_accuracy: 0.9688\n",
      "Epoch 7/30\n",
      "1670/1670 [==============================] - 1975s 1s/step - loss: 0.0452 - accuracy: 0.9841 - val_loss: 0.0344 - val_accuracy: 0.9688\n",
      "Epoch 8/30\n",
      "1670/1670 [==============================] - 1976s 1s/step - loss: 0.0358 - accuracy: 0.9877 - val_loss: 0.0241 - val_accuracy: 1.0000\n",
      "Epoch 9/30\n",
      "1670/1670 [==============================] - 1976s 1s/step - loss: 0.0270 - accuracy: 0.9910 - val_loss: 0.0147 - val_accuracy: 1.0000\n",
      "Epoch 10/30\n",
      "1670/1670 [==============================] - 1975s 1s/step - loss: 0.0254 - accuracy: 0.9910 - val_loss: 0.0068 - val_accuracy: 1.0000\n",
      "Epoch 11/30\n",
      "1670/1670 [==============================] - 1975s 1s/step - loss: 0.0197 - accuracy: 0.9932 - val_loss: 0.0063 - val_accuracy: 1.0000\n",
      "Epoch 12/30\n",
      "1670/1670 [==============================] - 1976s 1s/step - loss: 0.0165 - accuracy: 0.9944 - val_loss: 0.0356 - val_accuracy: 0.9688\n",
      "Epoch 13/30\n",
      "1670/1670 [==============================] - 1976s 1s/step - loss: 0.0150 - accuracy: 0.9944 - val_loss: 0.0408 - val_accuracy: 0.9688\n",
      "Epoch 14/30\n",
      "1670/1670 [==============================] - 1975s 1s/step - loss: 0.0134 - accuracy: 0.9952 - val_loss: 0.0691 - val_accuracy: 0.9688\n",
      "Epoch 15/30\n",
      "1670/1670 [==============================] - 1975s 1s/step - loss: 0.0125 - accuracy: 0.9954 - val_loss: 0.0049 - val_accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "1670/1670 [==============================] - 1975s 1s/step - loss: 0.0117 - accuracy: 0.9951 - val_loss: 0.0347 - val_accuracy: 0.9688\n",
      "Epoch 17/30\n",
      "1670/1670 [==============================] - 1975s 1s/step - loss: 0.0090 - accuracy: 0.9961 - val_loss: 0.0116 - val_accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "1670/1670 [==============================] - 1976s 1s/step - loss: 0.0095 - accuracy: 0.9961 - val_loss: 0.0202 - val_accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "1670/1670 [==============================] - 1976s 1s/step - loss: 0.0075 - accuracy: 0.9966 - val_loss: 0.0146 - val_accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "1670/1670 [==============================] - 1975s 1s/step - loss: 0.0077 - accuracy: 0.9963 - val_loss: 0.0193 - val_accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "1670/1670 [==============================] - 1975s 1s/step - loss: 0.0074 - accuracy: 0.9960 - val_loss: 0.0177 - val_accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "1670/1670 [==============================] - 1974s 1s/step - loss: 0.0073 - accuracy: 0.9960 - val_loss: 0.0115 - val_accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "1670/1670 [==============================] - 1975s 1s/step - loss: 0.0063 - accuracy: 0.9965 - val_loss: 0.0136 - val_accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "1670/1670 [==============================] - 1975s 1s/step - loss: 0.0055 - accuracy: 0.9965 - val_loss: 0.0208 - val_accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "1670/1670 [==============================] - 1976s 1s/step - loss: 0.0059 - accuracy: 0.9963 - val_loss: 0.0252 - val_accuracy: 0.9688\n",
      "Epoch 26/30\n",
      "1670/1670 [==============================] - 1976s 1s/step - loss: 0.0057 - accuracy: 0.9965 - val_loss: 0.0162 - val_accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "1670/1670 [==============================] - 1975s 1s/step - loss: 0.0055 - accuracy: 0.9963 - val_loss: 0.0200 - val_accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "1670/1670 [==============================] - 1977s 1s/step - loss: 0.0051 - accuracy: 0.9968 - val_loss: 0.0362 - val_accuracy: 0.9688\n",
      "Epoch 29/30\n",
      "1670/1670 [==============================] - 1977s 1s/step - loss: 0.0051 - accuracy: 0.9967 - val_loss: 0.0251 - val_accuracy: 0.9688\n",
      "Epoch 30/30\n",
      "1670/1670 [==============================] - 1978s 1s/step - loss: 0.0043 - accuracy: 0.9971 - val_loss: 0.0170 - val_accuracy: 1.0000\n",
      "INFO:tensorflow:Assets written to: ../opticnet/opticnet_30epochs_83484.0 images/assets\n",
      "Test acc for opticnet: 0.998967\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import datetime\n",
    "\n",
    "maxTrain = len(y_train)\n",
    "#for p in [0.01, 0.025, 0.05, 0.075, 0.09]:\n",
    "#for p in [0.1, 0.25, 0.4, 0.5, 0.6, 0.75, 0.9]:\n",
    "for p in [1.0]:\n",
    "    #X_trn, X_tst, y_trn, y_tst\n",
    "    if p < 1:\n",
    "        X_t, _, y_t, _ = train_test_split(images, y_train, test_size=1-p, random_state=123)\n",
    "    else:\n",
    "        X_t = images; y_t = y_train;\n",
    "    print(f\"Labels fraction: {sum(y_t == 1) / sum(y_train == 1)}\")\n",
    "    for net in [\"xception\", \"resnet\", \"opticnet\"]:\n",
    "        print(f\"Training {net} for {p}% of train size (aka {len(X_t)} images)...\")\n",
    "        model, size = emptyModelGenerator(net, False)\n",
    "        X_trn = resizeIms(X_t, size)\n",
    "        X_val = resizeIms(x_val, size)\n",
    "        log_dir = f\"logs/{net}/fit/{p}trainSet_\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "        tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "        optim = Adam(learning_rate=0.001)\n",
    "        model.compile(optimizer=optim, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "        hist = model.fit(X_trn, y_t, epochs=epochs, validation_data = (X_val, y_validation), batch_size=batch_size,\n",
    "                    shuffle=True, max_queue_size=20,\n",
    "                    use_multiprocessing=True, workers=5, \n",
    "                    callbacks=[CustomCallback(fraction=0.9, model=net), tensorboard_callback])\n",
    "        model.save(f\"../{net}/{net}_{epochs}epochs_{p*maxTrain} images\")\n",
    "        testPredict(model, size, name=net)\n",
    "        del model\n",
    "        del X_trn\n",
    "        del X_val\n",
    "        print(\"Done!\\n\" + '-'*50, end='\\n\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
