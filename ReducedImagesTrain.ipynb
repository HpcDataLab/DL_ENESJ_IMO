{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "import os\n",
    "import cv2\n",
    "import pickle\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataPath = \"../../data/OCT/OCT2017/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of Classes Detected : 4\n"
     ]
    }
   ],
   "source": [
    "labels_available = os.listdir(os.path.join(dataPath, \"train\"))\n",
    "print(\"Total Number of Classes Detected :\",len(labels_available))\n",
    "\n",
    "labels_list = ['NORMAL',\"CNV\",\"DME\",\"DRUSEN\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NORMAL CNV DME DRUSEN "
     ]
    }
   ],
   "source": [
    "images=[]\n",
    "y_trn=[]\n",
    "for x in labels_list:\n",
    "    xPath = os.path.join(dataPath, \"train\", x)\n",
    "    myPicList = os.listdir(xPath)\n",
    "    for y in myPicList:\n",
    "        images.append(cv2.imread(os.path.join(xPath, y)))\n",
    "        y_trn.append(labels_list.index(x))\n",
    "    print(x ,end=\" \")\n",
    "\n",
    "y_train = to_categorical(y_trn,len(labels_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NORMAL CNV DME DRUSEN "
     ]
    }
   ],
   "source": [
    "x_val=[]\n",
    "y_val=[]\n",
    "for x in labels_list:\n",
    "    xPath = os.path.join(dataPath, \"val\", x)\n",
    "    myPicList = os.listdir(xPath)\n",
    "    for y in myPicList:\n",
    "        x_val.append(cv2.imread(os.path.join(xPath, y)))\n",
    "        y_val.append(labels_list.index(x))\n",
    "    print(x ,end=\" \")\n",
    "\n",
    "y_validation = to_categorical(y_val,len(labels_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NORMAL CNV DME DRUSEN "
     ]
    }
   ],
   "source": [
    "x_tst=[]\n",
    "y_tst=[]\n",
    "for x in labels_list:\n",
    "    xPath = os.path.join(dataPath, \"test\", x)\n",
    "    myPicList = os.listdir(xPath)\n",
    "    for y in myPicList:\n",
    "        x_tst.append(cv2.imread(os.path.join(xPath, y)))\n",
    "        y_tst.append(labels_list.index(x))\n",
    "    print(x ,end=\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of images per category and set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label\t\tTrain\t\tValidation\t\tTest\n",
      "NORMAL\t\t26315\t\t8\t\t\t242\n",
      "CNV\t\t37205\t\t8\t\t\t242\n",
      "DME\t\t11348\t\t8\t\t\t242\n",
      "DRUSEN\t\t8616\t\t8\t\t\t242\n"
     ]
    }
   ],
   "source": [
    "def getNumberOfItems(labels, itemLabel):\n",
    "    return sum(list(map(lambda x: x == itemLabel, labels))) \n",
    "\n",
    "\n",
    "print(\"Label\\t\\tTrain\\t\\tValidation\\t\\tTest\")\n",
    "for i, label in enumerate(labels_list):\n",
    "    print(f\"{label}\\t\\t{getNumberOfItems(y_trn, i)}\\t\\t{getNumberOfItems(y_val, i)}\\t\\t\\t{getNumberOfItems(y_tst, i)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resizeIm(im, size):\n",
    "    if im.shape[2] == 1:\n",
    "        im = cv2.cvtColor(im,cv2.COLOR_GRAY2RGB)\n",
    "    return cv2.resize(im, size)\n",
    "\n",
    "def resizeIms(x, size):\n",
    "    return np.array(list(map(lambda im: resizeIm(im, size), x)))\n",
    "\n",
    "# Substract the mean specified by Mean (https://www.mathworks.com/help/deeplearning/ref/nnet.cnn.layer.imageinputlayer.html)\n",
    "# Substract mean by channel\n",
    "def zerocenter(x):\n",
    "    return (x - np.mean(x, axis=(0, 1))) / (2*np.std(x, axis=(0, 1)))\n",
    "\n",
    "# Rescale the input to be in the range [-1, 1] using the minimum and maximum values specified by Min and Max, respectively. (https://www.mathworks.com/help/deeplearning/ref/nnet.cnn.layer.imageinputlayer.html)\n",
    "# Compute using the formula: $x\\prime = 2 * \\frac{x - \\min{x}}{\\max{x} - \\min{x}} - 1$ taken from: https://stats.stackexchange.com/a/178629\n",
    "def rescaleSymmetric(x):\n",
    "    x = zerocenter(x)\n",
    "    return 2 * (x - np.min(x, axis=(0, 1)))/np.ptp(x, axis=(0, 1)) - 1\n",
    "\n",
    "def normalizeIms(x, normalization):\n",
    "    if normalization == \"zerocenter\":\n",
    "        func = zerocenter\n",
    "    elif normalization == \"rescale-symmetric\":\n",
    "        func = rescaleSymmetric\n",
    "    else:\n",
    "        return x\n",
    "    return np.array(list(map(lambda im: func(im), x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self,fraction, model):\n",
    "        super(CustomCallback,self).__init__()\n",
    "        self.fraction = fraction\n",
    "        self.train_a = [];\n",
    "        self.val_a =[];\n",
    "        self.logPath = os.path.join(model, \"log.txt\")\n",
    "\n",
    "        if not os.path.isdir(model):\n",
    "            os.mkdir(model)\n",
    "\n",
    "        with open(self.logPath,'w') as f:\n",
    "            f.write('Starting of logging..\\n')\n",
    "\n",
    "        self.fig = plt.figure(figsize=(4,3))\n",
    "        self.ax = plt.subplot(1,1,1)\n",
    "        plt.ion()\n",
    "\n",
    "    def on_train_begin(self,logs=None):\n",
    "        self.fig.show()\n",
    "        self.fig.canvas.draw()\n",
    "\n",
    "    def on_train_end(self,logs=None):\n",
    "        with open(self.logPath,'a') as f:\n",
    "              f.write('End of logging..\\n')\n",
    "    \n",
    "    def on_epoch_begin(self,epoch,logs=None):\n",
    "        lr= tf.keras.backend.get_value(self.model.optimizer.lr)\n",
    "        lr *= self.fraction\n",
    "        tf.keras.backend.set_value(self.model.optimizer.lr,lr)\n",
    "        with open(self.logPath,'a') as f:\n",
    "            f.write('At epoch {:02d}, learning rate changed to {:.4f}\\n'.format(epoch,lr))\n",
    "    \n",
    "    def on_epoch_end(self,epoch,logs=None):\n",
    "        val_acc = logs.get('val_accuracy')\n",
    "        train_acc = logs.get('accuracy')\n",
    "        self.train_a.append(train_acc)\n",
    "        self.val_a.append(val_acc)\n",
    "        with open(self.logPath,'a') as f:\n",
    "            f.write('At epoch {:02d}, training accuracy: {:.3f}, validation accuracy: {:.3f}\\n'.format(epoch,train_acc,val_acc))\n",
    "        self.ax.clear()\n",
    "        self.ax.plot(range(1+epoch),self.train_a,label=\"Training\")\n",
    "        self.ax.plot(range(1+epoch),self.val_a,label=\"Validation\")\n",
    "        self.ax.set_xlabel('Epochs')\n",
    "        self.ax.set_ylabel('Accuracy')\n",
    "        self.ax.legend()\n",
    "        self.fig.canvas.draw()\n",
    "        self.fig.show()\n",
    "        \n",
    "class TimeHistory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.times = []\n",
    "\n",
    "    def on_epoch_begin(self, batch, logs={}):\n",
    "        self.epoch_time_start = time.time()\n",
    "\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.times.append(time.time() - self.epoch_time_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "# xception base model\n",
    "#from tensorflow.keras.applications.xception import Xception\n",
    "#from tensorflow.keras.applications.xception import preprocess_input, decode_predictions\n",
    "#xceptionNetModel = Xception(weights='imagenet')\n",
    "#xceptionNetModel.save(\"../Xception.hdf5\")\n",
    "\n",
    "xceptionNetModel = tf.keras.models.load_model('../Xception.hdf5')\n",
    "\n",
    "# opticnet base model\n",
    "opticNetModel = tf.keras.models.load_model('../Optic_net-4_classes-Kermany2018.hdf5')\n",
    "\n",
    "# resnet base model\n",
    "#from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "#from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "#resNetModel = ResNet50(weights='imagenet')\n",
    "#resNetModel.save(\"../Resnet50.hdf5\")\n",
    "\n",
    "resNetModel = tf.keras.models.load_model('../Resnet50.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_10 (Conv2D)           (None, 221, 221, 32)      4736      \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 221, 221, 32)      128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 110, 110, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 104, 104, 32)      50208     \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 104, 104, 32)      128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 52, 52, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 48, 48, 64)        51264     \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 48, 48, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 24, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 20, 20, 128)       204928    \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 20, 20, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 10, 10, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 8, 8, 256)         295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_2 (Average (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 128)               131200    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 4)                 132       \n",
      "_________________________________________________________________\n",
      "softmax_2 (Softmax)          (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 743,812\n",
      "Trainable params: 742,788\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "conv_init = tf.keras.initializers.RandomNormal(mean=0., stddev=1.) # convolutional layer with zero mean and 1 sd\n",
    "#batch_init = tf.keras.initializers.RandomNormal(mean=1., stddev=0.02) # non-sense here\n",
    "\n",
    "octnet = keras.models.Sequential() # empty model\n",
    "\n",
    "octnet.add(keras.layers.Conv2D(32, (7, 7), activation=\"relu\", use_bias=True, input_shape=(227, 227, 3), kernel_initializer=conv_init))\n",
    "octnet.add(keras.layers.BatchNormalization())\n",
    "octnet.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "octnet.add(keras.layers.Conv2D(32, (7, 7), activation=\"relu\", use_bias=True, kernel_initializer=conv_init))\n",
    "octnet.add(keras.layers.BatchNormalization())\n",
    "octnet.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "octnet.add(keras.layers.Conv2D(64, (5, 5), activation=\"relu\", use_bias=True, kernel_initializer=conv_init))\n",
    "octnet.add(keras.layers.BatchNormalization())\n",
    "octnet.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "octnet.add(keras.layers.Conv2D(128, (5, 5), activation=\"relu\", use_bias=True, kernel_initializer=conv_init))\n",
    "octnet.add(keras.layers.BatchNormalization())\n",
    "octnet.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "octnet.add(keras.layers.Conv2D(256, (3, 3), activation=\"relu\", use_bias=True, kernel_initializer=conv_init))\n",
    "octnet.add(keras.layers.BatchNormalization())\n",
    "octnet.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "#octnet.add(keras.layers.Conv2D(512, (3, 3), activation=\"relu\", use_bias=True))\n",
    "#octnet.add(keras.layers.BatchNormalization())\n",
    "#octnet.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "octnet.add(keras.layers.AveragePooling2D())\n",
    "octnet.add(keras.layers.Flatten())\n",
    "octnet.add(keras.layers.Dense(128))\n",
    "octnet.add(keras.layers.Dropout(0.5))\n",
    "octnet.add(keras.layers.Dense(32))\n",
    "octnet.add(keras.layers.Dropout(0.5))\n",
    "octnet.add(keras.layers.Dense(4))\n",
    "octnet.add(keras.layers.Softmax())\n",
    "\n",
    "octnet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emptyModelGenerator(model, newWeights=False, lastOnly=False):\n",
    "    model = model.lower() # lower case model name\n",
    "    if model == \"resnet\":\n",
    "        x = resNetModel.output\n",
    "        predictions = Dense(len(labels_list), activation='softmax')(x)\n",
    "        newModel = Model(inputs=resNetModel.input, outputs=predictions)\n",
    "        size = (224, 224)\n",
    "        normalization = \"zerocenter\"\n",
    "    elif model == \"xception\":\n",
    "        x = xceptionNetModel.output\n",
    "        predictions = Dense(len(labels_list), activation='softmax')(x)\n",
    "        newModel = Model(inputs=xceptionNetModel.input, outputs=predictions)\n",
    "        size = (299, 299)\n",
    "        normalization = \"rescale-symmetric\"\n",
    "    elif model == \"opticnet\":\n",
    "        newModel = tf.keras.models.load_model('../Optic_net-4_classes-Kermany2018.hdf5')\n",
    "        size = (224, 224)\n",
    "        normalization = \"rescale-symmetric\"\n",
    "    elif model == \"octnet\":\n",
    "        newModel = tf.keras.models.clone_model(octnet)\n",
    "        size = (227, 227)\n",
    "        normalization = \"zerocenter\"\n",
    "    if newWeights:\n",
    "        newModel = tf.keras.models.clone_model(newModel)\n",
    "    if lastOnly:\n",
    "        newModel = lastDenseTrainable(newModel) # block all layer except the last dense ones\n",
    "    else:\n",
    "        newModel.trainable = True\n",
    "    return newModel, size, normalization\n",
    "\n",
    "\n",
    "def lastDenseTrainable(model):\n",
    "    model.trainable = False\n",
    "    for i in range(1, len(model.layers)):\n",
    "        if model.layers[-i].__class__.__name__ == \"Dense\":\n",
    "            model.layers[-i].trainable= True\n",
    "        elif model.layers[-i].__class__.__name__ == \"Activation\":\n",
    "            continue\n",
    "        else:\n",
    "            break\n",
    "    return model\n",
    "    \n",
    "\n",
    "def testPredict(model, size, name=None, normalization=None):\n",
    "    X_test = resizeIms(x_tst, size)\n",
    "    if normalization:\n",
    "        X_test = normalizeIms(X_test, normalization)\n",
    "    X_test = np.array(X_test)\n",
    "    Y_test = np.array(y_tst)\n",
    "    \n",
    "    prediction = model.predict(X_test)\n",
    "    preds = np.argmax(prediction, axis=1)\n",
    "    acc = sum(preds == Y_test) / len(Y_test)\n",
    "    print(f'Test acc for {name if name else \"model\"}: {acc:.6f}')\n",
    "    return acc\n",
    "    \n",
    "\n",
    "def computeConfussionMatrix(predictions, labels):\n",
    "    num_labels = len(labels_list)\n",
    "    cMatrix = np.zeros(shape=(num_labels, num_labels))\n",
    "    for i in len(predictions):\n",
    "        p = int(predictions[i])\n",
    "        t = int(predictions[i])\n",
    "        cMatrix[t, p] += 1\n",
    "    print(cMatrix)\n",
    "    ax = sns.heatmap(cMatrix, cmap=\"Blues\", annot=True, fmt=\"d\", xticklabels=labels_list, yticklabels=labels_list)\n",
    "    plt.xlabel(\"Predicted label\")\n",
    "    plt.ylabel(\"True label\")\n",
    "    plt.title(\"Confusion matrix\")\n",
    "    plt.show();\n",
    "    return cMatrix\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "**************************************************\n",
      "Model: xception\n",
      "**************************************************\n",
      "\n",
      "Total: 135 trainable: 2\n",
      "\n",
      "\n",
      "**************************************************\n",
      "Model: resnet\n",
      "**************************************************\n",
      "\n",
      "Total: 178 trainable: 2\n",
      "\n",
      "\n",
      "**************************************************\n",
      "Model: opticnet\n",
      "**************************************************\n",
      "\n",
      "Total: 276 trainable: 2\n",
      "\n",
      "\n",
      "**************************************************\n",
      "Model: octnet\n",
      "**************************************************\n",
      "\n",
      "Total: 23 trainable: 0\n"
     ]
    }
   ],
   "source": [
    "models = [\"xception\", \"resnet\", \"opticnet\", \"octnet\"]\n",
    "\n",
    "def printTrainableLayers(m):\n",
    "    a = 0\n",
    "    for l in m.layers:\n",
    "        #l.trainable = True\n",
    "        if l.trainable:\n",
    "            #print(l.name, l.trainable)\n",
    "            a += 1\n",
    "    print(f\"\\nTotal: {len(m.layers)} trainable: {a}\")\n",
    "\n",
    "for mod in models:\n",
    "    print(\"\\n\\n\" + (\"*\"*50) + \"\\nModel: \" + mod + '\\n' + (\"*\"*50))\n",
    "    m = emptyModelGenerator(mod, newWeights=False, lastOnly=True)[0]\n",
    "    printTrainableLayers(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "momentum = 0.5\n",
    "optim = lambda lr: Adam(learning_rate=lr)\n",
    "#optim = SGD(learning_rate=lr, momentum=momentum)\n",
    "epochs = 30\n",
    "batch_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "results = pd.read_csv(\"Results.csv\")\n",
    "results[\"normalization\"] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pandas as pd\n",
    "#res = pd.read_csv(\"Results_temp.csv\")\n",
    "#res.to_csv(\"Results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels fraction: [0.0100703  0.01042871 0.00845964 0.00986537]\n",
      "Training octnet for 0.01% of train size (aka 834 images) with pretrained: False and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 23 trainable: 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      " 6/17 [=========>....................] - ETA: 4s - loss: 4.1766 - accuracy: 0.4038WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0376s vs `on_train_batch_begin` time: 0.1659s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0376s vs `on_train_batch_end` time: 0.1561s). Check your callbacks.\n",
      "17/17 [==============================] - 6s 237ms/step - loss: 4.3913 - accuracy: 0.4032 - val_loss: 438.6927 - val_accuracy: 0.3750\n",
      "Epoch 2/30\n",
      " 1/17 [>.............................] - ETA: 0s - loss: 3.4621 - accuracy: 0.5000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 1s 55ms/step - loss: 2.8405 - accuracy: 0.4850 - val_loss: 72.9719 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "17/17 [==============================] - 1s 55ms/step - loss: 2.5662 - accuracy: 0.5105 - val_loss: 45.0310 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "17/17 [==============================] - 1s 55ms/step - loss: 2.0232 - accuracy: 0.5486 - val_loss: 15.4109 - val_accuracy: 0.5000\n",
      "Epoch 5/30\n",
      "17/17 [==============================] - 1s 56ms/step - loss: 1.6725 - accuracy: 0.6290 - val_loss: 8.2076 - val_accuracy: 0.5000\n",
      "Epoch 6/30\n",
      "17/17 [==============================] - 1s 73ms/step - loss: 1.4150 - accuracy: 0.6398 - val_loss: 5.1861 - val_accuracy: 0.5000\n",
      "Epoch 7/30\n",
      "17/17 [==============================] - 1s 53ms/step - loss: 1.1439 - accuracy: 0.6820 - val_loss: 4.9488 - val_accuracy: 0.5000\n",
      "Epoch 8/30\n",
      "17/17 [==============================] - 1s 56ms/step - loss: 1.3368 - accuracy: 0.6484 - val_loss: 3.9944 - val_accuracy: 0.5000\n",
      "Epoch 9/30\n",
      "17/17 [==============================] - 1s 49ms/step - loss: 1.1366 - accuracy: 0.6482 - val_loss: 2.1654 - val_accuracy: 0.5000\n",
      "Epoch 10/30\n",
      "17/17 [==============================] - 1s 51ms/step - loss: 1.0297 - accuracy: 0.6838 - val_loss: 2.1759 - val_accuracy: 0.5312\n",
      "Epoch 11/30\n",
      "17/17 [==============================] - 1s 63ms/step - loss: 0.8631 - accuracy: 0.7017 - val_loss: 1.9615 - val_accuracy: 0.5312\n",
      "Epoch 12/30\n",
      "17/17 [==============================] - 1s 54ms/step - loss: 0.9365 - accuracy: 0.7164 - val_loss: 1.9035 - val_accuracy: 0.5312\n",
      "Epoch 13/30\n",
      "17/17 [==============================] - 1s 72ms/step - loss: 0.7765 - accuracy: 0.7436 - val_loss: 1.6549 - val_accuracy: 0.5625\n",
      "Epoch 14/30\n",
      "17/17 [==============================] - 1s 72ms/step - loss: 0.7976 - accuracy: 0.7503 - val_loss: 1.6729 - val_accuracy: 0.5625\n",
      "Epoch 15/30\n",
      "17/17 [==============================] - 1s 65ms/step - loss: 0.7887 - accuracy: 0.7459 - val_loss: 1.3487 - val_accuracy: 0.5625\n",
      "Epoch 16/30\n",
      "17/17 [==============================] - 1s 66ms/step - loss: 0.7713 - accuracy: 0.7695 - val_loss: 1.5642 - val_accuracy: 0.5625\n",
      "Epoch 17/30\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 0.7349 - accuracy: 0.7538 - val_loss: 1.2871 - val_accuracy: 0.5312\n",
      "Epoch 18/30\n",
      "17/17 [==============================] - 1s 56ms/step - loss: 0.6998 - accuracy: 0.7711 - val_loss: 1.3877 - val_accuracy: 0.5625\n",
      "Epoch 19/30\n",
      "17/17 [==============================] - 1s 57ms/step - loss: 0.7109 - accuracy: 0.7626 - val_loss: 1.4252 - val_accuracy: 0.5625\n",
      "Epoch 20/30\n",
      "17/17 [==============================] - 1s 67ms/step - loss: 0.6207 - accuracy: 0.7716 - val_loss: 1.3828 - val_accuracy: 0.5625\n",
      "Epoch 21/30\n",
      "17/17 [==============================] - 1s 72ms/step - loss: 0.5651 - accuracy: 0.7932 - val_loss: 1.4224 - val_accuracy: 0.5625\n",
      "Epoch 22/30\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 0.6799 - accuracy: 0.7594 - val_loss: 1.3622 - val_accuracy: 0.5625\n",
      "Epoch 23/30\n",
      "17/17 [==============================] - 1s 77ms/step - loss: 0.5713 - accuracy: 0.8092 - val_loss: 1.2525 - val_accuracy: 0.5625\n",
      "Epoch 24/30\n",
      "17/17 [==============================] - 1s 62ms/step - loss: 0.6265 - accuracy: 0.7841 - val_loss: 1.2072 - val_accuracy: 0.5625\n",
      "Epoch 25/30\n",
      "17/17 [==============================] - 1s 80ms/step - loss: 0.5586 - accuracy: 0.8018 - val_loss: 1.2131 - val_accuracy: 0.5625\n",
      "Epoch 26/30\n",
      "17/17 [==============================] - 1s 68ms/step - loss: 0.5587 - accuracy: 0.8001 - val_loss: 1.2523 - val_accuracy: 0.5625\n",
      "Epoch 27/30\n",
      "17/17 [==============================] - 1s 78ms/step - loss: 0.5131 - accuracy: 0.8018 - val_loss: 1.2945 - val_accuracy: 0.5625\n",
      "Epoch 28/30\n",
      "17/17 [==============================] - 1s 68ms/step - loss: 0.5903 - accuracy: 0.7962 - val_loss: 1.2717 - val_accuracy: 0.5625\n",
      "Epoch 29/30\n",
      "17/17 [==============================] - 1s 68ms/step - loss: 0.5383 - accuracy: 0.8254 - val_loss: 1.2400 - val_accuracy: 0.5625\n",
      "Epoch 30/30\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 0.4888 - accuracy: 0.8262 - val_loss: 1.1465 - val_accuracy: 0.5625\n",
      "INFO:tensorflow:Assets written to: ../octnet/octnet_30epochs_834.84_images_True_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for octnet: 0.595041\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training resnet for 0.01% of train size (aka 834 images) with pretrained: False and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 178 trainable: 178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      " 6/17 [=========>....................] - ETA: 7s - loss: 1.3810 - accuracy: 0.3117WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1112s vs `on_train_batch_begin` time: 0.1400s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1112s vs `on_train_batch_end` time: 0.3528s). Check your callbacks.\n",
      "17/17 [==============================] - 17s 479ms/step - loss: 1.3681 - accuracy: 0.3821 - val_loss: 1.3871 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "17/17 [==============================] - 4s 208ms/step - loss: 1.3316 - accuracy: 0.4706 - val_loss: 1.3895 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "17/17 [==============================] - 4s 213ms/step - loss: 1.3233 - accuracy: 0.4557 - val_loss: 1.3963 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "17/17 [==============================] - 4s 221ms/step - loss: 1.3142 - accuracy: 0.4519 - val_loss: 1.3988 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "17/17 [==============================] - 3s 204ms/step - loss: 1.3046 - accuracy: 0.4499 - val_loss: 1.4018 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "17/17 [==============================] - 4s 205ms/step - loss: 1.2913 - accuracy: 0.4912 - val_loss: 1.4046 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "17/17 [==============================] - 4s 207ms/step - loss: 1.2926 - accuracy: 0.4568 - val_loss: 1.4071 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "17/17 [==============================] - 3s 204ms/step - loss: 1.2856 - accuracy: 0.4673 - val_loss: 1.4094 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "17/17 [==============================] - 4s 210ms/step - loss: 1.2847 - accuracy: 0.4710 - val_loss: 1.4115 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "17/17 [==============================] - 4s 207ms/step - loss: 1.2705 - accuracy: 0.4911 - val_loss: 1.4135 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "17/17 [==============================] - 3s 205ms/step - loss: 1.2743 - accuracy: 0.4708 - val_loss: 1.4153 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "17/17 [==============================] - 4s 210ms/step - loss: 1.2674 - accuracy: 0.4662 - val_loss: 1.4170 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "17/17 [==============================] - 4s 207ms/step - loss: 1.2740 - accuracy: 0.4447 - val_loss: 1.4185 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "17/17 [==============================] - 3s 204ms/step - loss: 1.2673 - accuracy: 0.4856 - val_loss: 1.4199 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "17/17 [==============================] - 3s 204ms/step - loss: 1.2685 - accuracy: 0.4743 - val_loss: 1.4211 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "17/17 [==============================] - 4s 210ms/step - loss: 1.2695 - accuracy: 0.4670 - val_loss: 1.4222 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "17/17 [==============================] - 4s 206ms/step - loss: 1.2650 - accuracy: 0.4831 - val_loss: 1.4233 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "17/17 [==============================] - 4s 206ms/step - loss: 1.2518 - accuracy: 0.4772 - val_loss: 1.4243 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "17/17 [==============================] - 4s 207ms/step - loss: 1.2575 - accuracy: 0.4855 - val_loss: 1.4251 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "17/17 [==============================] - 4s 206ms/step - loss: 1.2691 - accuracy: 0.4498 - val_loss: 1.4258 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "17/17 [==============================] - 4s 207ms/step - loss: 1.2601 - accuracy: 0.4683 - val_loss: 1.4266 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "17/17 [==============================] - 4s 208ms/step - loss: 1.2554 - accuracy: 0.4816 - val_loss: 1.4272 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "17/17 [==============================] - 4s 206ms/step - loss: 1.2571 - accuracy: 0.4696 - val_loss: 1.4278 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "17/17 [==============================] - 4s 206ms/step - loss: 1.2544 - accuracy: 0.4821 - val_loss: 1.4283 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "17/17 [==============================] - 4s 205ms/step - loss: 1.2509 - accuracy: 0.4726 - val_loss: 1.4288 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "17/17 [==============================] - 4s 206ms/step - loss: 1.2600 - accuracy: 0.4532 - val_loss: 1.4292 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "17/17 [==============================] - 3s 204ms/step - loss: 1.2614 - accuracy: 0.4561 - val_loss: 1.4296 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "17/17 [==============================] - 4s 206ms/step - loss: 1.2581 - accuracy: 0.4623 - val_loss: 1.4299 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "17/17 [==============================] - 3s 205ms/step - loss: 1.2688 - accuracy: 0.4500 - val_loss: 1.4302 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "17/17 [==============================] - 4s 208ms/step - loss: 1.2498 - accuracy: 0.4682 - val_loss: 1.4305 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_834.84_images_True_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.02496675 0.02607176 0.02264716 0.02356082]\n",
      "Training octnet for 0.025% of train size (aka 2087 images) with pretrained: False and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 23 trainable: 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      " 6/42 [===>..........................] - ETA: 16s - loss: 5.2506 - accuracy: 0.3559WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0243s vs `on_train_batch_begin` time: 0.2034s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0243s vs `on_train_batch_end` time: 0.1612s). Check your callbacks.\n",
      "42/42 [==============================] - 6s 119ms/step - loss: 4.3767 - accuracy: 0.3999 - val_loss: 41.7145 - val_accuracy: 0.2500\n",
      "Epoch 2/30\n",
      " 1/42 [..............................] - ETA: 1s - loss: 2.7947 - accuracy: 0.5000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 2s 50ms/step - loss: 2.3794 - accuracy: 0.5276 - val_loss: 5.6495 - val_accuracy: 0.5625\n",
      "Epoch 3/30\n",
      "42/42 [==============================] - 2s 48ms/step - loss: 1.6813 - accuracy: 0.5730 - val_loss: 3.2032 - val_accuracy: 0.5625\n",
      "Epoch 4/30\n",
      "42/42 [==============================] - 2s 47ms/step - loss: 1.4966 - accuracy: 0.6229 - val_loss: 2.2743 - val_accuracy: 0.5312\n",
      "Epoch 5/30\n",
      "42/42 [==============================] - 2s 48ms/step - loss: 1.2184 - accuracy: 0.6606 - val_loss: 1.4304 - val_accuracy: 0.5625\n",
      "Epoch 6/30\n",
      "42/42 [==============================] - 2s 46ms/step - loss: 1.0724 - accuracy: 0.6937 - val_loss: 1.3037 - val_accuracy: 0.5938\n",
      "Epoch 7/30\n",
      "42/42 [==============================] - 2s 47ms/step - loss: 1.0287 - accuracy: 0.6916 - val_loss: 0.7872 - val_accuracy: 0.7188\n",
      "Epoch 8/30\n",
      "42/42 [==============================] - 2s 49ms/step - loss: 0.9638 - accuracy: 0.6843 - val_loss: 0.8793 - val_accuracy: 0.6875\n",
      "Epoch 9/30\n",
      "42/42 [==============================] - 2s 50ms/step - loss: 0.8091 - accuracy: 0.7155 - val_loss: 1.1945 - val_accuracy: 0.6250\n",
      "Epoch 10/30\n",
      "42/42 [==============================] - 2s 50ms/step - loss: 0.7732 - accuracy: 0.7449 - val_loss: 0.8362 - val_accuracy: 0.6250\n",
      "Epoch 11/30\n",
      "42/42 [==============================] - 2s 48ms/step - loss: 0.7022 - accuracy: 0.7670 - val_loss: 0.8019 - val_accuracy: 0.7188\n",
      "Epoch 12/30\n",
      "42/42 [==============================] - 2s 50ms/step - loss: 0.6894 - accuracy: 0.7708 - val_loss: 1.0324 - val_accuracy: 0.5312\n",
      "Epoch 13/30\n",
      "42/42 [==============================] - 2s 46ms/step - loss: 0.7110 - accuracy: 0.7396 - val_loss: 0.8965 - val_accuracy: 0.5938\n",
      "Epoch 14/30\n",
      "42/42 [==============================] - 2s 53ms/step - loss: 0.6074 - accuracy: 0.7989 - val_loss: 0.9486 - val_accuracy: 0.6250\n",
      "Epoch 15/30\n",
      "42/42 [==============================] - 2s 47ms/step - loss: 0.6155 - accuracy: 0.7885 - val_loss: 0.8273 - val_accuracy: 0.6250\n",
      "Epoch 16/30\n",
      "42/42 [==============================] - 2s 46ms/step - loss: 0.5829 - accuracy: 0.8004 - val_loss: 0.8153 - val_accuracy: 0.7188\n",
      "Epoch 17/30\n",
      "42/42 [==============================] - 2s 50ms/step - loss: 0.5870 - accuracy: 0.7832 - val_loss: 0.8470 - val_accuracy: 0.5938\n",
      "Epoch 18/30\n",
      "42/42 [==============================] - 2s 53ms/step - loss: 0.5446 - accuracy: 0.8014 - val_loss: 0.8331 - val_accuracy: 0.6875\n",
      "Epoch 19/30\n",
      "42/42 [==============================] - 2s 46ms/step - loss: 0.5309 - accuracy: 0.8061 - val_loss: 0.8479 - val_accuracy: 0.6875\n",
      "Epoch 20/30\n",
      "42/42 [==============================] - 2s 48ms/step - loss: 0.4793 - accuracy: 0.8191 - val_loss: 0.8336 - val_accuracy: 0.7812\n",
      "Epoch 21/30\n",
      "42/42 [==============================] - 2s 53ms/step - loss: 0.4573 - accuracy: 0.8302 - val_loss: 0.8727 - val_accuracy: 0.7188\n",
      "Epoch 22/30\n",
      "42/42 [==============================] - 2s 48ms/step - loss: 0.4458 - accuracy: 0.8253 - val_loss: 0.7904 - val_accuracy: 0.7188\n",
      "Epoch 23/30\n",
      "42/42 [==============================] - 2s 48ms/step - loss: 0.4317 - accuracy: 0.8464 - val_loss: 0.8627 - val_accuracy: 0.6875\n",
      "Epoch 24/30\n",
      "42/42 [==============================] - 2s 54ms/step - loss: 0.4895 - accuracy: 0.8108 - val_loss: 0.8740 - val_accuracy: 0.6562\n",
      "Epoch 25/30\n",
      "42/42 [==============================] - 2s 52ms/step - loss: 0.4763 - accuracy: 0.8175 - val_loss: 0.8144 - val_accuracy: 0.7500\n",
      "Epoch 26/30\n",
      "42/42 [==============================] - 2s 45ms/step - loss: 0.4360 - accuracy: 0.8335 - val_loss: 0.8117 - val_accuracy: 0.7188\n",
      "Epoch 27/30\n",
      "42/42 [==============================] - 2s 51ms/step - loss: 0.4209 - accuracy: 0.8334 - val_loss: 0.8220 - val_accuracy: 0.7188\n",
      "Epoch 28/30\n",
      "42/42 [==============================] - 2s 49ms/step - loss: 0.4413 - accuracy: 0.8303 - val_loss: 0.8274 - val_accuracy: 0.7188\n",
      "Epoch 29/30\n",
      "42/42 [==============================] - 2s 52ms/step - loss: 0.3893 - accuracy: 0.8515 - val_loss: 0.8251 - val_accuracy: 0.7500\n",
      "Epoch 30/30\n",
      "42/42 [==============================] - 2s 48ms/step - loss: 0.3982 - accuracy: 0.8609 - val_loss: 0.7976 - val_accuracy: 0.7188\n",
      "INFO:tensorflow:Assets written to: ../octnet/octnet_30epochs_2087.1_images_True_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for octnet: 0.674587\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training resnet for 0.025% of train size (aka 2087 images) with pretrained: False and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 178 trainable: 178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      " 6/42 [===>..........................] - ETA: 43s - loss: 1.3786 - accuracy: 0.3032WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1266s vs `on_train_batch_begin` time: 0.3064s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1266s vs `on_train_batch_end` time: 0.6059s). Check your callbacks.\n",
      "42/42 [==============================] - 24s 395ms/step - loss: 1.3575 - accuracy: 0.4139 - val_loss: 1.3923 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "42/42 [==============================] - 9s 203ms/step - loss: 1.3005 - accuracy: 0.5810 - val_loss: 1.3962 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "42/42 [==============================] - 9s 202ms/step - loss: 1.2752 - accuracy: 0.6038 - val_loss: 1.4027 - val_accuracy: 0.2812\n",
      "Epoch 4/30\n",
      "42/42 [==============================] - 9s 202ms/step - loss: 1.2292 - accuracy: 0.6808 - val_loss: 1.3755 - val_accuracy: 0.4062\n",
      "Epoch 5/30\n",
      "42/42 [==============================] - 9s 204ms/step - loss: 1.1956 - accuracy: 0.7115 - val_loss: 1.4269 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "42/42 [==============================] - 9s 206ms/step - loss: 1.1914 - accuracy: 0.6551 - val_loss: 1.3535 - val_accuracy: 0.4688\n",
      "Epoch 7/30\n",
      "42/42 [==============================] - 9s 203ms/step - loss: 1.1699 - accuracy: 0.6850 - val_loss: 1.4525 - val_accuracy: 0.2188\n",
      "Epoch 8/30\n",
      "42/42 [==============================] - 9s 203ms/step - loss: 1.1499 - accuracy: 0.6999 - val_loss: 1.4635 - val_accuracy: 0.2188\n",
      "Epoch 9/30\n",
      "42/42 [==============================] - 9s 204ms/step - loss: 1.1152 - accuracy: 0.7222 - val_loss: 1.4614 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "42/42 [==============================] - 9s 204ms/step - loss: 1.1170 - accuracy: 0.7029 - val_loss: 1.4940 - val_accuracy: 0.1875\n",
      "Epoch 11/30\n",
      "42/42 [==============================] - 9s 207ms/step - loss: 1.1049 - accuracy: 0.7163 - val_loss: 1.4557 - val_accuracy: 0.2812\n",
      "Epoch 12/30\n",
      "42/42 [==============================] - 9s 204ms/step - loss: 1.0919 - accuracy: 0.7304 - val_loss: 1.4277 - val_accuracy: 0.3438\n",
      "Epoch 13/30\n",
      "42/42 [==============================] - 9s 204ms/step - loss: 1.0649 - accuracy: 0.7546 - val_loss: 1.3333 - val_accuracy: 0.5000\n",
      "Epoch 14/30\n",
      "42/42 [==============================] - 9s 203ms/step - loss: 1.0702 - accuracy: 0.7340 - val_loss: 1.3306 - val_accuracy: 0.5000\n",
      "Epoch 15/30\n",
      "42/42 [==============================] - 9s 204ms/step - loss: 1.0579 - accuracy: 0.7441 - val_loss: 1.3577 - val_accuracy: 0.4688\n",
      "Epoch 16/30\n",
      "42/42 [==============================] - 9s 205ms/step - loss: 1.0457 - accuracy: 0.7475 - val_loss: 1.3315 - val_accuracy: 0.5000\n",
      "Epoch 17/30\n",
      "42/42 [==============================] - 9s 203ms/step - loss: 1.0524 - accuracy: 0.7392 - val_loss: 1.3300 - val_accuracy: 0.5000\n",
      "Epoch 18/30\n",
      "42/42 [==============================] - 9s 203ms/step - loss: 1.0510 - accuracy: 0.7367 - val_loss: 1.3233 - val_accuracy: 0.5000\n",
      "Epoch 19/30\n",
      "42/42 [==============================] - 9s 203ms/step - loss: 1.0323 - accuracy: 0.7489 - val_loss: 1.3285 - val_accuracy: 0.5000\n",
      "Epoch 20/30\n",
      "42/42 [==============================] - 9s 205ms/step - loss: 1.0081 - accuracy: 0.7722 - val_loss: 1.3204 - val_accuracy: 0.5000\n",
      "Epoch 21/30\n",
      "42/42 [==============================] - 9s 208ms/step - loss: 1.0221 - accuracy: 0.7621 - val_loss: 1.3193 - val_accuracy: 0.5000\n",
      "Epoch 22/30\n",
      "42/42 [==============================] - 9s 205ms/step - loss: 1.0185 - accuracy: 0.7618 - val_loss: 1.3250 - val_accuracy: 0.5000\n",
      "Epoch 23/30\n",
      "42/42 [==============================] - 9s 207ms/step - loss: 1.0258 - accuracy: 0.7501 - val_loss: 1.3108 - val_accuracy: 0.5000\n",
      "Epoch 24/30\n",
      "42/42 [==============================] - 9s 203ms/step - loss: 1.0112 - accuracy: 0.7620 - val_loss: 1.3086 - val_accuracy: 0.5000\n",
      "Epoch 25/30\n",
      "42/42 [==============================] - 9s 205ms/step - loss: 1.0036 - accuracy: 0.7691 - val_loss: 1.3136 - val_accuracy: 0.5000\n",
      "Epoch 26/30\n",
      "42/42 [==============================] - 9s 205ms/step - loss: 1.0119 - accuracy: 0.7597 - val_loss: 1.3147 - val_accuracy: 0.5000\n",
      "Epoch 27/30\n",
      "42/42 [==============================] - 9s 206ms/step - loss: 0.9897 - accuracy: 0.7705 - val_loss: 1.3128 - val_accuracy: 0.5000\n",
      "Epoch 28/30\n",
      "42/42 [==============================] - 9s 207ms/step - loss: 0.9950 - accuracy: 0.7670 - val_loss: 1.3145 - val_accuracy: 0.5000\n",
      "Epoch 29/30\n",
      "42/42 [==============================] - 9s 204ms/step - loss: 0.9886 - accuracy: 0.7728 - val_loss: 1.3200 - val_accuracy: 0.5000\n",
      "Epoch 30/30\n",
      "42/42 [==============================] - 9s 205ms/step - loss: 0.9861 - accuracy: 0.7786 - val_loss: 1.3174 - val_accuracy: 0.5000\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_2087.1_images_True_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.497934\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.05050352 0.04929445 0.05137469 0.04967502]\n",
      "Training octnet for 0.05% of train size (aka 4174 images) with pretrained: False and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 23 trainable: 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      " 6/84 [=>............................] - ETA: 35s - loss: 5.0911 - accuracy: 0.3209WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0230s vs `on_train_batch_begin` time: 0.2078s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0230s vs `on_train_batch_end` time: 0.1538s). Check your callbacks.\n",
      "84/84 [==============================] - 8s 84ms/step - loss: 3.9617 - accuracy: 0.3925 - val_loss: 6.9693 - val_accuracy: 0.4688\n",
      "Epoch 2/30\n",
      " 1/84 [..............................] - ETA: 3s - loss: 1.9459 - accuracy: 0.5600"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84/84 [==============================] - 4s 44ms/step - loss: 1.9453 - accuracy: 0.5449 - val_loss: 2.4693 - val_accuracy: 0.4688\n",
      "Epoch 3/30\n",
      "84/84 [==============================] - 4s 47ms/step - loss: 1.5547 - accuracy: 0.5886 - val_loss: 1.4960 - val_accuracy: 0.5312\n",
      "Epoch 4/30\n",
      "84/84 [==============================] - 4s 46ms/step - loss: 1.3351 - accuracy: 0.6186 - val_loss: 1.1734 - val_accuracy: 0.5312\n",
      "Epoch 5/30\n",
      "84/84 [==============================] - 4s 47ms/step - loss: 1.0393 - accuracy: 0.6608 - val_loss: 1.3612 - val_accuracy: 0.5312\n",
      "Epoch 6/30\n",
      "84/84 [==============================] - 4s 50ms/step - loss: 1.0042 - accuracy: 0.6852 - val_loss: 0.8721 - val_accuracy: 0.5312\n",
      "Epoch 7/30\n",
      "84/84 [==============================] - 4s 52ms/step - loss: 0.8706 - accuracy: 0.7103 - val_loss: 0.9941 - val_accuracy: 0.5625\n",
      "Epoch 8/30\n",
      "84/84 [==============================] - 4s 45ms/step - loss: 0.7768 - accuracy: 0.7265 - val_loss: 0.8824 - val_accuracy: 0.6250\n",
      "Epoch 9/30\n",
      "84/84 [==============================] - 4s 45ms/step - loss: 0.7216 - accuracy: 0.7432 - val_loss: 0.7803 - val_accuracy: 0.6250\n",
      "Epoch 10/30\n",
      "84/84 [==============================] - 4s 46ms/step - loss: 0.6684 - accuracy: 0.7707 - val_loss: 0.8607 - val_accuracy: 0.5625\n",
      "Epoch 11/30\n",
      "84/84 [==============================] - 4s 50ms/step - loss: 0.6558 - accuracy: 0.7553 - val_loss: 0.8672 - val_accuracy: 0.6250\n",
      "Epoch 12/30\n",
      "84/84 [==============================] - 4s 49ms/step - loss: 0.6145 - accuracy: 0.7816 - val_loss: 0.9739 - val_accuracy: 0.5938\n",
      "Epoch 13/30\n",
      "84/84 [==============================] - 4s 47ms/step - loss: 0.5932 - accuracy: 0.7868 - val_loss: 0.7908 - val_accuracy: 0.6250\n",
      "Epoch 14/30\n",
      "84/84 [==============================] - 4s 48ms/step - loss: 0.5914 - accuracy: 0.7890 - val_loss: 0.9007 - val_accuracy: 0.6250\n",
      "Epoch 15/30\n",
      "84/84 [==============================] - 4s 48ms/step - loss: 0.5749 - accuracy: 0.7843 - val_loss: 0.8578 - val_accuracy: 0.6250\n",
      "Epoch 16/30\n",
      "84/84 [==============================] - 4s 47ms/step - loss: 0.5251 - accuracy: 0.8053 - val_loss: 0.8246 - val_accuracy: 0.5938\n",
      "Epoch 17/30\n",
      "84/84 [==============================] - 4s 48ms/step - loss: 0.4887 - accuracy: 0.8191 - val_loss: 0.8769 - val_accuracy: 0.5938\n",
      "Epoch 18/30\n",
      "84/84 [==============================] - 4s 45ms/step - loss: 0.4633 - accuracy: 0.8361 - val_loss: 1.0133 - val_accuracy: 0.6562\n",
      "Epoch 19/30\n",
      "84/84 [==============================] - 4s 44ms/step - loss: 0.5067 - accuracy: 0.8134 - val_loss: 0.8095 - val_accuracy: 0.6250\n",
      "Epoch 20/30\n",
      "84/84 [==============================] - 4s 48ms/step - loss: 0.4488 - accuracy: 0.8314 - val_loss: 0.8134 - val_accuracy: 0.6562\n",
      "Epoch 21/30\n",
      "84/84 [==============================] - 4s 49ms/step - loss: 0.4379 - accuracy: 0.8441 - val_loss: 0.8539 - val_accuracy: 0.6562\n",
      "Epoch 22/30\n",
      "84/84 [==============================] - 4s 46ms/step - loss: 0.4242 - accuracy: 0.8456 - val_loss: 0.9776 - val_accuracy: 0.6562\n",
      "Epoch 23/30\n",
      "84/84 [==============================] - 4s 50ms/step - loss: 0.4181 - accuracy: 0.8587 - val_loss: 0.8647 - val_accuracy: 0.6250\n",
      "Epoch 24/30\n",
      "84/84 [==============================] - 4s 47ms/step - loss: 0.4399 - accuracy: 0.8406 - val_loss: 0.8654 - val_accuracy: 0.6562\n",
      "Epoch 25/30\n",
      "84/84 [==============================] - 4s 48ms/step - loss: 0.3917 - accuracy: 0.8517 - val_loss: 0.8975 - val_accuracy: 0.6250\n",
      "Epoch 26/30\n",
      "84/84 [==============================] - 4s 51ms/step - loss: 0.4076 - accuracy: 0.8547 - val_loss: 0.8295 - val_accuracy: 0.6250\n",
      "Epoch 27/30\n",
      "84/84 [==============================] - 4s 50ms/step - loss: 0.3938 - accuracy: 0.8597 - val_loss: 0.8724 - val_accuracy: 0.6250\n",
      "Epoch 28/30\n",
      "84/84 [==============================] - 4s 50ms/step - loss: 0.4053 - accuracy: 0.8506 - val_loss: 0.8713 - val_accuracy: 0.6250\n",
      "Epoch 29/30\n",
      "84/84 [==============================] - 4s 53ms/step - loss: 0.3870 - accuracy: 0.8538 - val_loss: 0.9093 - val_accuracy: 0.6562\n",
      "Epoch 30/30\n",
      "84/84 [==============================] - 4s 49ms/step - loss: 0.3786 - accuracy: 0.8698 - val_loss: 0.8392 - val_accuracy: 0.6562\n",
      "INFO:tensorflow:Assets written to: ../octnet/octnet_30epochs_4174.2_images_True_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for octnet: 0.744835\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training resnet for 0.05% of train size (aka 4174 images) with pretrained: False and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 178 trainable: 178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      " 6/84 [=>............................] - ETA: 56s - loss: 1.3794 - accuracy: 0.2529 WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1078s vs `on_train_batch_begin` time: 0.2121s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1078s vs `on_train_batch_end` time: 0.3124s). Check your callbacks.\n",
      "84/84 [==============================] - 32s 266ms/step - loss: 1.3508 - accuracy: 0.4087 - val_loss: 1.4016 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "84/84 [==============================] - 17s 202ms/step - loss: 1.3031 - accuracy: 0.4274 - val_loss: 1.4232 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "84/84 [==============================] - 17s 205ms/step - loss: 1.2693 - accuracy: 0.4448 - val_loss: 1.4440 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "84/84 [==============================] - 17s 204ms/step - loss: 1.2542 - accuracy: 0.4337 - val_loss: 1.4625 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "84/84 [==============================] - 17s 204ms/step - loss: 1.2452 - accuracy: 0.4380 - val_loss: 1.4777 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "84/84 [==============================] - 17s 205ms/step - loss: 1.2439 - accuracy: 0.4374 - val_loss: 1.4894 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "84/84 [==============================] - 17s 204ms/step - loss: 1.2408 - accuracy: 0.4378 - val_loss: 1.4993 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "84/84 [==============================] - 17s 205ms/step - loss: 1.2509 - accuracy: 0.4235 - val_loss: 1.5074 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "84/84 [==============================] - 17s 205ms/step - loss: 1.2381 - accuracy: 0.4397 - val_loss: 1.5146 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "84/84 [==============================] - 17s 204ms/step - loss: 1.2495 - accuracy: 0.4287 - val_loss: 1.5193 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "84/84 [==============================] - 17s 205ms/step - loss: 1.2202 - accuracy: 0.4590 - val_loss: 1.5235 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "84/84 [==============================] - 17s 205ms/step - loss: 1.2363 - accuracy: 0.4294 - val_loss: 1.5266 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "84/84 [==============================] - 17s 205ms/step - loss: 1.2294 - accuracy: 0.4423 - val_loss: 1.5287 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "84/84 [==============================] - 17s 205ms/step - loss: 1.2346 - accuracy: 0.4400 - val_loss: 1.5312 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "84/84 [==============================] - 17s 206ms/step - loss: 1.2298 - accuracy: 0.4460 - val_loss: 1.5331 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "84/84 [==============================] - 17s 206ms/step - loss: 1.2315 - accuracy: 0.4381 - val_loss: 1.5346 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "84/84 [==============================] - 17s 204ms/step - loss: 1.2146 - accuracy: 0.4553 - val_loss: 1.5359 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "84/84 [==============================] - 17s 205ms/step - loss: 1.2168 - accuracy: 0.4506 - val_loss: 1.5373 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "84/84 [==============================] - 17s 206ms/step - loss: 1.2192 - accuracy: 0.4438 - val_loss: 1.5380 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "84/84 [==============================] - 17s 204ms/step - loss: 1.2289 - accuracy: 0.4414 - val_loss: 1.5390 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "84/84 [==============================] - 17s 205ms/step - loss: 1.2238 - accuracy: 0.4484 - val_loss: 1.5396 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "84/84 [==============================] - 17s 204ms/step - loss: 1.2446 - accuracy: 0.4359 - val_loss: 1.5400 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "84/84 [==============================] - 17s 205ms/step - loss: 1.2299 - accuracy: 0.4459 - val_loss: 1.5405 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "84/84 [==============================] - 17s 204ms/step - loss: 1.2323 - accuracy: 0.4383 - val_loss: 1.5411 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "84/84 [==============================] - 17s 203ms/step - loss: 1.2481 - accuracy: 0.4318 - val_loss: 1.5415 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "84/84 [==============================] - 17s 204ms/step - loss: 1.2269 - accuracy: 0.4444 - val_loss: 1.5419 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "84/84 [==============================] - 17s 205ms/step - loss: 1.2291 - accuracy: 0.4451 - val_loss: 1.5422 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "84/84 [==============================] - 17s 203ms/step - loss: 1.2220 - accuracy: 0.4488 - val_loss: 1.5425 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "84/84 [==============================] - 17s 204ms/step - loss: 1.2261 - accuracy: 0.4419 - val_loss: 1.5427 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "84/84 [==============================] - 17s 206ms/step - loss: 1.2358 - accuracy: 0.4416 - val_loss: 1.5429 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_4174.2_images_True_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.07573627 0.07464051 0.07543179 0.07370009]\n",
      "Training octnet for 0.075% of train size (aka 6261 images) with pretrained: False and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 23 trainable: 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/126 [>.............................] - ETA: 57s - loss: 6.1620 - accuracy: 0.2742 WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0340s vs `on_train_batch_begin` time: 0.2069s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0340s vs `on_train_batch_end` time: 0.1650s). Check your callbacks.\n",
      "126/126 [==============================] - 11s 71ms/step - loss: 3.8039 - accuracy: 0.4036 - val_loss: 4.3085 - val_accuracy: 0.5312\n",
      "Epoch 2/30\n",
      "  1/126 [..............................] - ETA: 5s - loss: 1.9739 - accuracy: 0.5200"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126/126 [==============================] - 6s 47ms/step - loss: 1.6793 - accuracy: 0.5785 - val_loss: 1.3021 - val_accuracy: 0.5625\n",
      "Epoch 3/30\n",
      "126/126 [==============================] - 6s 47ms/step - loss: 1.2837 - accuracy: 0.6389 - val_loss: 0.9953 - val_accuracy: 0.5938\n",
      "Epoch 4/30\n",
      "126/126 [==============================] - 6s 52ms/step - loss: 1.0490 - accuracy: 0.6697 - val_loss: 0.7070 - val_accuracy: 0.6875\n",
      "Epoch 5/30\n",
      "126/126 [==============================] - 6s 49ms/step - loss: 0.9179 - accuracy: 0.7102 - val_loss: 0.9348 - val_accuracy: 0.6250\n",
      "Epoch 6/30\n",
      "126/126 [==============================] - 6s 48ms/step - loss: 0.7924 - accuracy: 0.7354 - val_loss: 0.7535 - val_accuracy: 0.6875\n",
      "Epoch 7/30\n",
      "126/126 [==============================] - 6s 50ms/step - loss: 0.7152 - accuracy: 0.7523 - val_loss: 0.7365 - val_accuracy: 0.6875\n",
      "Epoch 8/30\n",
      "126/126 [==============================] - 7s 59ms/step - loss: 0.6548 - accuracy: 0.7672 - val_loss: 0.7262 - val_accuracy: 0.6875\n",
      "Epoch 9/30\n",
      "126/126 [==============================] - 6s 51ms/step - loss: 0.6123 - accuracy: 0.7898 - val_loss: 0.8988 - val_accuracy: 0.6250\n",
      "Epoch 10/30\n",
      "126/126 [==============================] - 7s 54ms/step - loss: 0.5751 - accuracy: 0.7951 - val_loss: 0.7054 - val_accuracy: 0.7500\n",
      "Epoch 11/30\n",
      "126/126 [==============================] - 7s 53ms/step - loss: 0.5701 - accuracy: 0.7998 - val_loss: 0.7025 - val_accuracy: 0.7188\n",
      "Epoch 12/30\n",
      "126/126 [==============================] - 6s 49ms/step - loss: 0.5150 - accuracy: 0.8151 - val_loss: 0.7572 - val_accuracy: 0.7188\n",
      "Epoch 13/30\n",
      "126/126 [==============================] - 6s 52ms/step - loss: 0.5061 - accuracy: 0.8175 - val_loss: 0.7071 - val_accuracy: 0.7500\n",
      "Epoch 14/30\n",
      "126/126 [==============================] - 6s 50ms/step - loss: 0.5014 - accuracy: 0.8221 - val_loss: 0.6778 - val_accuracy: 0.7188\n",
      "Epoch 15/30\n",
      "126/126 [==============================] - 6s 48ms/step - loss: 0.4524 - accuracy: 0.8402 - val_loss: 0.6348 - val_accuracy: 0.7812\n",
      "Epoch 16/30\n",
      "126/126 [==============================] - 6s 50ms/step - loss: 0.4487 - accuracy: 0.8384 - val_loss: 0.6223 - val_accuracy: 0.7500\n",
      "Epoch 17/30\n",
      "126/126 [==============================] - 6s 49ms/step - loss: 0.4158 - accuracy: 0.8482 - val_loss: 0.6563 - val_accuracy: 0.7188\n",
      "Epoch 18/30\n",
      "126/126 [==============================] - 6s 51ms/step - loss: 0.4157 - accuracy: 0.8450 - val_loss: 0.6459 - val_accuracy: 0.7500\n",
      "Epoch 19/30\n",
      "126/126 [==============================] - 6s 50ms/step - loss: 0.3857 - accuracy: 0.8586 - val_loss: 0.7167 - val_accuracy: 0.7500\n",
      "Epoch 20/30\n",
      "126/126 [==============================] - 7s 52ms/step - loss: 0.3765 - accuracy: 0.8529 - val_loss: 0.6322 - val_accuracy: 0.7812\n",
      "Epoch 21/30\n",
      "126/126 [==============================] - 7s 52ms/step - loss: 0.3701 - accuracy: 0.8676 - val_loss: 0.6432 - val_accuracy: 0.7812\n",
      "Epoch 22/30\n",
      "126/126 [==============================] - 6s 51ms/step - loss: 0.3517 - accuracy: 0.8759 - val_loss: 0.7231 - val_accuracy: 0.7188\n",
      "Epoch 23/30\n",
      "126/126 [==============================] - 7s 53ms/step - loss: 0.3344 - accuracy: 0.8827 - val_loss: 0.6597 - val_accuracy: 0.7812\n",
      "Epoch 24/30\n",
      "126/126 [==============================] - 6s 51ms/step - loss: 0.3474 - accuracy: 0.8733 - val_loss: 0.7042 - val_accuracy: 0.7188\n",
      "Epoch 25/30\n",
      "126/126 [==============================] - 6s 51ms/step - loss: 0.3501 - accuracy: 0.8719 - val_loss: 0.7224 - val_accuracy: 0.7188\n",
      "Epoch 26/30\n",
      "126/126 [==============================] - 6s 50ms/step - loss: 0.3265 - accuracy: 0.8730 - val_loss: 0.6401 - val_accuracy: 0.7812\n",
      "Epoch 27/30\n",
      "126/126 [==============================] - 6s 48ms/step - loss: 0.3263 - accuracy: 0.8806 - val_loss: 0.6973 - val_accuracy: 0.7500\n",
      "Epoch 28/30\n",
      "126/126 [==============================] - 6s 48ms/step - loss: 0.3278 - accuracy: 0.8867 - val_loss: 0.7149 - val_accuracy: 0.7188\n",
      "Epoch 29/30\n",
      "126/126 [==============================] - 7s 53ms/step - loss: 0.3213 - accuracy: 0.8823 - val_loss: 0.6693 - val_accuracy: 0.7500\n",
      "Epoch 30/30\n",
      "126/126 [==============================] - 7s 52ms/step - loss: 0.3110 - accuracy: 0.8962 - val_loss: 0.6876 - val_accuracy: 0.7188\n",
      "INFO:tensorflow:Assets written to: ../octnet/octnet_30epochs_6261.3_images_True_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for octnet: 0.790289\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training resnet for 0.075% of train size (aka 6261 images) with pretrained: False and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 178 trainable: 178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/126 [>.............................] - ETA: 1:29 - loss: 1.3785 - accuracy: 0.3407WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1088s vs `on_train_batch_begin` time: 0.2069s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1088s vs `on_train_batch_end` time: 0.3288s). Check your callbacks.\n",
      "126/126 [==============================] - 40s 243ms/step - loss: 1.3371 - accuracy: 0.4327 - val_loss: 1.4157 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "126/126 [==============================] - 26s 203ms/step - loss: 1.2729 - accuracy: 0.4538 - val_loss: 1.4499 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "126/126 [==============================] - 26s 204ms/step - loss: 1.2489 - accuracy: 0.4449 - val_loss: 1.4792 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "126/126 [==============================] - 26s 208ms/step - loss: 1.2401 - accuracy: 0.4425 - val_loss: 1.5005 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "126/126 [==============================] - 26s 204ms/step - loss: 1.2318 - accuracy: 0.4483 - val_loss: 1.5164 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "126/126 [==============================] - 26s 205ms/step - loss: 1.2323 - accuracy: 0.4359 - val_loss: 1.5272 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "126/126 [==============================] - 26s 205ms/step - loss: 1.2324 - accuracy: 0.4452 - val_loss: 1.5361 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "126/126 [==============================] - 26s 204ms/step - loss: 1.2386 - accuracy: 0.4356 - val_loss: 1.5418 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "126/126 [==============================] - 26s 205ms/step - loss: 1.2272 - accuracy: 0.4466 - val_loss: 1.5454 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "126/126 [==============================] - 26s 205ms/step - loss: 1.2279 - accuracy: 0.4453 - val_loss: 1.5477 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "126/126 [==============================] - 26s 204ms/step - loss: 1.2238 - accuracy: 0.4535 - val_loss: 1.5498 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "126/126 [==============================] - 26s 203ms/step - loss: 1.2274 - accuracy: 0.4433 - val_loss: 1.5514 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "126/126 [==============================] - 26s 206ms/step - loss: 1.2251 - accuracy: 0.4494 - val_loss: 1.5528 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "126/126 [==============================] - 26s 204ms/step - loss: 1.2297 - accuracy: 0.4360 - val_loss: 1.5538 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "126/126 [==============================] - 26s 204ms/step - loss: 1.2325 - accuracy: 0.4333 - val_loss: 1.5545 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "126/126 [==============================] - 26s 204ms/step - loss: 1.2248 - accuracy: 0.4470 - val_loss: 1.5549 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "126/126 [==============================] - 26s 203ms/step - loss: 1.2210 - accuracy: 0.4448 - val_loss: 1.5557 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "126/126 [==============================] - 26s 203ms/step - loss: 1.2372 - accuracy: 0.4430 - val_loss: 1.5558 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "126/126 [==============================] - 26s 203ms/step - loss: 1.2455 - accuracy: 0.4337 - val_loss: 1.5561 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "126/126 [==============================] - 26s 204ms/step - loss: 1.2323 - accuracy: 0.4405 - val_loss: 1.5566 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "126/126 [==============================] - 26s 204ms/step - loss: 1.2234 - accuracy: 0.4483 - val_loss: 1.5566 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "126/126 [==============================] - 26s 205ms/step - loss: 1.2380 - accuracy: 0.4331 - val_loss: 1.5570 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "126/126 [==============================] - 26s 205ms/step - loss: 1.2313 - accuracy: 0.4552 - val_loss: 1.5570 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "126/126 [==============================] - 26s 203ms/step - loss: 1.2245 - accuracy: 0.4584 - val_loss: 1.5572 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "126/126 [==============================] - 26s 204ms/step - loss: 1.2342 - accuracy: 0.4415 - val_loss: 1.5574 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "126/126 [==============================] - 26s 204ms/step - loss: 1.2259 - accuracy: 0.4431 - val_loss: 1.5575 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "126/126 [==============================] - 26s 204ms/step - loss: 1.2309 - accuracy: 0.4391 - val_loss: 1.5575 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "126/126 [==============================] - 26s 204ms/step - loss: 1.2283 - accuracy: 0.4468 - val_loss: 1.5575 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "126/126 [==============================] - 26s 203ms/step - loss: 1.2344 - accuracy: 0.4418 - val_loss: 1.5576 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "126/126 [==============================] - 26s 203ms/step - loss: 1.2280 - accuracy: 0.4462 - val_loss: 1.5574 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_6261.3_images_True_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.09158275 0.08899341 0.08970744 0.08983287]\n",
      "Training octnet for 0.09% of train size (aka 7513 images) with pretrained: False and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 23 trainable: 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/151 [>.............................] - ETA: 1:01 - loss: 4.2016 - accuracy: 0.2948WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0299s vs `on_train_batch_begin` time: 0.1889s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0299s vs `on_train_batch_end` time: 0.1452s). Check your callbacks.\n",
      "151/151 [==============================] - 11s 63ms/step - loss: 3.0610 - accuracy: 0.4303 - val_loss: 2.1515 - val_accuracy: 0.5000\n",
      "Epoch 2/30\n",
      "  1/151 [..............................] - ETA: 6s - loss: 1.8126 - accuracy: 0.5400"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151/151 [==============================] - 7s 47ms/step - loss: 1.4990 - accuracy: 0.5949 - val_loss: 1.2268 - val_accuracy: 0.5625\n",
      "Epoch 3/30\n",
      "151/151 [==============================] - 7s 50ms/step - loss: 1.0970 - accuracy: 0.6531 - val_loss: 0.8733 - val_accuracy: 0.6250\n",
      "Epoch 4/30\n",
      "151/151 [==============================] - 7s 46ms/step - loss: 0.8902 - accuracy: 0.6860 - val_loss: 0.9059 - val_accuracy: 0.6250\n",
      "Epoch 5/30\n",
      "151/151 [==============================] - 7s 48ms/step - loss: 0.8065 - accuracy: 0.7217 - val_loss: 0.7086 - val_accuracy: 0.7500\n",
      "Epoch 6/30\n",
      "151/151 [==============================] - 7s 46ms/step - loss: 0.6797 - accuracy: 0.7503 - val_loss: 0.6736 - val_accuracy: 0.7500\n",
      "Epoch 7/30\n",
      "151/151 [==============================] - 7s 49ms/step - loss: 0.6385 - accuracy: 0.7679 - val_loss: 0.5954 - val_accuracy: 0.7812\n",
      "Epoch 8/30\n",
      "151/151 [==============================] - 7s 48ms/step - loss: 0.5637 - accuracy: 0.7944 - val_loss: 0.7424 - val_accuracy: 0.7500\n",
      "Epoch 9/30\n",
      "151/151 [==============================] - 7s 48ms/step - loss: 0.5332 - accuracy: 0.8097 - val_loss: 0.6784 - val_accuracy: 0.7812\n",
      "Epoch 10/30\n",
      "151/151 [==============================] - 8s 50ms/step - loss: 0.5084 - accuracy: 0.8179 - val_loss: 0.6084 - val_accuracy: 0.7812\n",
      "Epoch 11/30\n",
      "151/151 [==============================] - 7s 48ms/step - loss: 0.4706 - accuracy: 0.8354 - val_loss: 0.7358 - val_accuracy: 0.7188\n",
      "Epoch 12/30\n",
      "151/151 [==============================] - 7s 49ms/step - loss: 0.4387 - accuracy: 0.8402 - val_loss: 0.6233 - val_accuracy: 0.8125\n",
      "Epoch 13/30\n",
      "151/151 [==============================] - 7s 45ms/step - loss: 0.4112 - accuracy: 0.8540 - val_loss: 0.5475 - val_accuracy: 0.7812\n",
      "Epoch 14/30\n",
      "151/151 [==============================] - 7s 46ms/step - loss: 0.3927 - accuracy: 0.8540 - val_loss: 0.5602 - val_accuracy: 0.8125\n",
      "Epoch 15/30\n",
      "151/151 [==============================] - 7s 45ms/step - loss: 0.3701 - accuracy: 0.8666 - val_loss: 0.5413 - val_accuracy: 0.8125\n",
      "Epoch 16/30\n",
      "151/151 [==============================] - 7s 47ms/step - loss: 0.3728 - accuracy: 0.8648 - val_loss: 0.5106 - val_accuracy: 0.8125\n",
      "Epoch 17/30\n",
      "151/151 [==============================] - 7s 48ms/step - loss: 0.3371 - accuracy: 0.8781 - val_loss: 0.5175 - val_accuracy: 0.8438\n",
      "Epoch 18/30\n",
      "151/151 [==============================] - 7s 49ms/step - loss: 0.3294 - accuracy: 0.8850 - val_loss: 0.4457 - val_accuracy: 0.8438\n",
      "Epoch 19/30\n",
      "151/151 [==============================] - 7s 47ms/step - loss: 0.3087 - accuracy: 0.8875 - val_loss: 0.5483 - val_accuracy: 0.8438\n",
      "Epoch 20/30\n",
      "151/151 [==============================] - 7s 47ms/step - loss: 0.3066 - accuracy: 0.8916 - val_loss: 0.5055 - val_accuracy: 0.8125\n",
      "Epoch 21/30\n",
      "151/151 [==============================] - 7s 46ms/step - loss: 0.2779 - accuracy: 0.9010 - val_loss: 0.4997 - val_accuracy: 0.8438\n",
      "Epoch 22/30\n",
      "151/151 [==============================] - 7s 46ms/step - loss: 0.2726 - accuracy: 0.9040 - val_loss: 0.5062 - val_accuracy: 0.8438\n",
      "Epoch 23/30\n",
      "151/151 [==============================] - 7s 49ms/step - loss: 0.2810 - accuracy: 0.9030 - val_loss: 0.5816 - val_accuracy: 0.8125\n",
      "Epoch 24/30\n",
      "151/151 [==============================] - 7s 47ms/step - loss: 0.2638 - accuracy: 0.9058 - val_loss: 0.4951 - val_accuracy: 0.8438\n",
      "Epoch 25/30\n",
      "151/151 [==============================] - 7s 46ms/step - loss: 0.2442 - accuracy: 0.9156 - val_loss: 0.5524 - val_accuracy: 0.8125\n",
      "Epoch 26/30\n",
      "151/151 [==============================] - 7s 47ms/step - loss: 0.2285 - accuracy: 0.9229 - val_loss: 0.6046 - val_accuracy: 0.7812\n",
      "Epoch 27/30\n",
      "151/151 [==============================] - 7s 45ms/step - loss: 0.2380 - accuracy: 0.9102 - val_loss: 0.4833 - val_accuracy: 0.8438\n",
      "Epoch 28/30\n",
      "151/151 [==============================] - 7s 46ms/step - loss: 0.2245 - accuracy: 0.9207 - val_loss: 0.5268 - val_accuracy: 0.8438\n",
      "Epoch 29/30\n",
      "151/151 [==============================] - 7s 47ms/step - loss: 0.2269 - accuracy: 0.9182 - val_loss: 0.5261 - val_accuracy: 0.8438\n",
      "Epoch 30/30\n",
      "151/151 [==============================] - 7s 48ms/step - loss: 0.2143 - accuracy: 0.9214 - val_loss: 0.5024 - val_accuracy: 0.8438\n",
      "INFO:tensorflow:Assets written to: ../octnet/octnet_30epochs_7513.5599999999995_images_True_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for octnet: 0.861570\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training resnet for 0.09% of train size (aka 7513 images) with pretrained: False and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 178 trainable: 178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/151 [>.............................] - ETA: 1:43 - loss: 1.3753 - accuracy: 0.3324WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1099s vs `on_train_batch_begin` time: 0.2062s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1099s vs `on_train_batch_end` time: 0.3060s). Check your callbacks.\n",
      "151/151 [==============================] - 44s 234ms/step - loss: 1.3309 - accuracy: 0.4505 - val_loss: 1.4183 - val_accuracy: 0.1875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "151/151 [==============================] - 30s 202ms/step - loss: 1.2119 - accuracy: 0.6441 - val_loss: 1.4686 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "151/151 [==============================] - 31s 204ms/step - loss: 1.1212 - accuracy: 0.6820 - val_loss: 1.5251 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "151/151 [==============================] - 31s 203ms/step - loss: 1.1672 - accuracy: 0.5616 - val_loss: 1.5341 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "151/151 [==============================] - 31s 203ms/step - loss: 1.2505 - accuracy: 0.4393 - val_loss: 1.5316 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "151/151 [==============================] - 31s 204ms/step - loss: 1.2416 - accuracy: 0.4333 - val_loss: 1.5350 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "151/151 [==============================] - 31s 204ms/step - loss: 1.2352 - accuracy: 0.4389 - val_loss: 1.5398 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "151/151 [==============================] - 31s 203ms/step - loss: 1.2319 - accuracy: 0.4448 - val_loss: 1.5440 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "151/151 [==============================] - 31s 204ms/step - loss: 1.2329 - accuracy: 0.4425 - val_loss: 1.5467 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "151/151 [==============================] - 31s 203ms/step - loss: 1.2303 - accuracy: 0.4391 - val_loss: 1.5486 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "151/151 [==============================] - 31s 204ms/step - loss: 1.2412 - accuracy: 0.4343 - val_loss: 1.5504 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "151/151 [==============================] - 31s 204ms/step - loss: 1.2310 - accuracy: 0.4409 - val_loss: 1.5518 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "151/151 [==============================] - 31s 205ms/step - loss: 1.2355 - accuracy: 0.4367 - val_loss: 1.5526 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "151/151 [==============================] - 31s 203ms/step - loss: 1.2301 - accuracy: 0.4407 - val_loss: 1.5534 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "151/151 [==============================] - 31s 205ms/step - loss: 1.2295 - accuracy: 0.4405 - val_loss: 1.5539 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "151/151 [==============================] - 31s 203ms/step - loss: 1.2335 - accuracy: 0.4335 - val_loss: 1.5544 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "151/151 [==============================] - 31s 204ms/step - loss: 1.2275 - accuracy: 0.4440 - val_loss: 1.5548 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "151/151 [==============================] - 31s 203ms/step - loss: 1.2351 - accuracy: 0.4376 - val_loss: 1.5548 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "151/151 [==============================] - 31s 203ms/step - loss: 1.2311 - accuracy: 0.4469 - val_loss: 1.5552 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "151/151 [==============================] - 31s 203ms/step - loss: 1.2301 - accuracy: 0.4387 - val_loss: 1.5553 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "151/151 [==============================] - 31s 204ms/step - loss: 1.2414 - accuracy: 0.4381 - val_loss: 1.5553 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "151/151 [==============================] - 31s 205ms/step - loss: 1.2215 - accuracy: 0.4450 - val_loss: 1.5555 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "151/151 [==============================] - 31s 204ms/step - loss: 1.2340 - accuracy: 0.4382 - val_loss: 1.5554 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "151/151 [==============================] - 31s 203ms/step - loss: 1.2340 - accuracy: 0.4376 - val_loss: 1.5556 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "151/151 [==============================] - 31s 203ms/step - loss: 1.2248 - accuracy: 0.4401 - val_loss: 1.5558 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "151/151 [==============================] - 31s 205ms/step - loss: 1.2196 - accuracy: 0.4521 - val_loss: 1.5559 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "151/151 [==============================] - 31s 204ms/step - loss: 1.2311 - accuracy: 0.4418 - val_loss: 1.5558 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "151/151 [==============================] - 31s 203ms/step - loss: 1.2360 - accuracy: 0.4409 - val_loss: 1.5559 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "151/151 [==============================] - 31s 204ms/step - loss: 1.2245 - accuracy: 0.4482 - val_loss: 1.5559 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "151/151 [==============================] - 31s 207ms/step - loss: 1.2375 - accuracy: 0.4363 - val_loss: 1.5559 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_7513.5599999999995_images_True_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.10089303 0.09931461 0.10028199 0.0998143 ]\n",
      "Training octnet for 0.1% of train size (aka 8348 images) with pretrained: False and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 23 trainable: 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  5/167 [..............................] - ETA: 1:28 - loss: 5.5017 - accuracy: 0.3119WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0260s vs `on_train_batch_begin` time: 0.2077s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0260s vs `on_train_batch_end` time: 0.1454s). Check your callbacks.\n",
      "167/167 [==============================] - 12s 65ms/step - loss: 3.4345 - accuracy: 0.4513 - val_loss: 1.6939 - val_accuracy: 0.5000\n",
      "Epoch 2/30\n",
      "  1/167 [..............................] - ETA: 8s - loss: 1.3304 - accuracy: 0.5800"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "167/167 [==============================] - 8s 48ms/step - loss: 1.4471 - accuracy: 0.5919 - val_loss: 1.0373 - val_accuracy: 0.4688\n",
      "Epoch 3/30\n",
      "167/167 [==============================] - 8s 48ms/step - loss: 1.0488 - accuracy: 0.6443 - val_loss: 0.9558 - val_accuracy: 0.5625\n",
      "Epoch 4/30\n",
      "167/167 [==============================] - 8s 46ms/step - loss: 0.8649 - accuracy: 0.7016 - val_loss: 0.7841 - val_accuracy: 0.7188\n",
      "Epoch 5/30\n",
      "167/167 [==============================] - 8s 46ms/step - loss: 0.7837 - accuracy: 0.7259 - val_loss: 0.9079 - val_accuracy: 0.5625\n",
      "Epoch 6/30\n",
      "167/167 [==============================] - 8s 45ms/step - loss: 0.6659 - accuracy: 0.7693 - val_loss: 0.7318 - val_accuracy: 0.7500\n",
      "Epoch 7/30\n",
      "167/167 [==============================] - 8s 45ms/step - loss: 0.6007 - accuracy: 0.7878 - val_loss: 0.7299 - val_accuracy: 0.7188\n",
      "Epoch 8/30\n",
      "167/167 [==============================] - 8s 46ms/step - loss: 0.5703 - accuracy: 0.7977 - val_loss: 0.7324 - val_accuracy: 0.7812\n",
      "Epoch 9/30\n",
      "167/167 [==============================] - 8s 45ms/step - loss: 0.5256 - accuracy: 0.8063 - val_loss: 0.7442 - val_accuracy: 0.7188\n",
      "Epoch 10/30\n",
      "167/167 [==============================] - 8s 47ms/step - loss: 0.5350 - accuracy: 0.8137 - val_loss: 0.6864 - val_accuracy: 0.7812\n",
      "Epoch 11/30\n",
      "167/167 [==============================] - 8s 50ms/step - loss: 0.4677 - accuracy: 0.8336 - val_loss: 0.9337 - val_accuracy: 0.7500\n",
      "Epoch 12/30\n",
      "167/167 [==============================] - 8s 46ms/step - loss: 0.4552 - accuracy: 0.8376 - val_loss: 0.7263 - val_accuracy: 0.7500\n",
      "Epoch 13/30\n",
      "167/167 [==============================] - 8s 48ms/step - loss: 0.4096 - accuracy: 0.8582 - val_loss: 0.7141 - val_accuracy: 0.7188\n",
      "Epoch 14/30\n",
      "167/167 [==============================] - 8s 46ms/step - loss: 0.4013 - accuracy: 0.8630 - val_loss: 0.7157 - val_accuracy: 0.7500\n",
      "Epoch 15/30\n",
      "167/167 [==============================] - 8s 49ms/step - loss: 0.3819 - accuracy: 0.8568 - val_loss: 0.8781 - val_accuracy: 0.7500\n",
      "Epoch 16/30\n",
      "167/167 [==============================] - 8s 48ms/step - loss: 0.3746 - accuracy: 0.8749 - val_loss: 0.8528 - val_accuracy: 0.7500\n",
      "Epoch 17/30\n",
      "167/167 [==============================] - 8s 47ms/step - loss: 0.3407 - accuracy: 0.8790 - val_loss: 0.7627 - val_accuracy: 0.7812\n",
      "Epoch 18/30\n",
      "167/167 [==============================] - 8s 47ms/step - loss: 0.3204 - accuracy: 0.8850 - val_loss: 0.8727 - val_accuracy: 0.7500\n",
      "Epoch 19/30\n",
      "167/167 [==============================] - 8s 48ms/step - loss: 0.3136 - accuracy: 0.8883 - val_loss: 0.7146 - val_accuracy: 0.7812\n",
      "Epoch 20/30\n",
      "167/167 [==============================] - 8s 47ms/step - loss: 0.3029 - accuracy: 0.8929 - val_loss: 0.8869 - val_accuracy: 0.7500\n",
      "Epoch 21/30\n",
      "167/167 [==============================] - 8s 47ms/step - loss: 0.2937 - accuracy: 0.8941 - val_loss: 0.8186 - val_accuracy: 0.7500\n",
      "Epoch 22/30\n",
      "167/167 [==============================] - 8s 49ms/step - loss: 0.2863 - accuracy: 0.8964 - val_loss: 1.0282 - val_accuracy: 0.7500\n",
      "Epoch 23/30\n",
      "167/167 [==============================] - 8s 47ms/step - loss: 0.2786 - accuracy: 0.9019 - val_loss: 0.8014 - val_accuracy: 0.6875\n",
      "Epoch 24/30\n",
      "167/167 [==============================] - 8s 45ms/step - loss: 0.2722 - accuracy: 0.9027 - val_loss: 0.7913 - val_accuracy: 0.7500\n",
      "Epoch 25/30\n",
      "167/167 [==============================] - 8s 47ms/step - loss: 0.2479 - accuracy: 0.9112 - val_loss: 0.9239 - val_accuracy: 0.7500\n",
      "Epoch 26/30\n",
      "167/167 [==============================] - 8s 47ms/step - loss: 0.2435 - accuracy: 0.9132 - val_loss: 0.8820 - val_accuracy: 0.7500\n",
      "Epoch 27/30\n",
      "167/167 [==============================] - 8s 45ms/step - loss: 0.2501 - accuracy: 0.9114 - val_loss: 0.9064 - val_accuracy: 0.7500\n",
      "Epoch 28/30\n",
      "167/167 [==============================] - 8s 50ms/step - loss: 0.2436 - accuracy: 0.9173 - val_loss: 0.9244 - val_accuracy: 0.7500\n",
      "Epoch 29/30\n",
      "167/167 [==============================] - 8s 49ms/step - loss: 0.2454 - accuracy: 0.9132 - val_loss: 0.9745 - val_accuracy: 0.7500\n",
      "Epoch 30/30\n",
      "167/167 [==============================] - 9s 52ms/step - loss: 0.2270 - accuracy: 0.9213 - val_loss: 0.8627 - val_accuracy: 0.7500\n",
      "INFO:tensorflow:Assets written to: ../octnet/octnet_30epochs_8348.4_images_True_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for octnet: 0.845041\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training resnet for 0.1% of train size (aka 8348 images) with pretrained: False and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 178 trainable: 178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/167 [>.............................] - ETA: 1:55 - loss: 1.3781 - accuracy: 0.3823WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1093s vs `on_train_batch_begin` time: 0.2019s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1093s vs `on_train_batch_end` time: 0.3132s). Check your callbacks.\n",
      "167/167 [==============================] - 49s 236ms/step - loss: 1.3212 - accuracy: 0.5475 - val_loss: 1.4228 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "167/167 [==============================] - 34s 202ms/step - loss: 1.2089 - accuracy: 0.6185 - val_loss: 1.4695 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "167/167 [==============================] - 34s 204ms/step - loss: 1.2434 - accuracy: 0.4474 - val_loss: 1.5007 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "167/167 [==============================] - 34s 204ms/step - loss: 1.2351 - accuracy: 0.4462 - val_loss: 1.5209 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "167/167 [==============================] - 34s 205ms/step - loss: 1.2332 - accuracy: 0.4411 - val_loss: 1.5331 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "167/167 [==============================] - 34s 205ms/step - loss: 1.2278 - accuracy: 0.4498 - val_loss: 1.5411 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "167/167 [==============================] - 34s 205ms/step - loss: 1.2320 - accuracy: 0.4444 - val_loss: 1.5463 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "167/167 [==============================] - 34s 205ms/step - loss: 1.2310 - accuracy: 0.4417 - val_loss: 1.5493 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "167/167 [==============================] - 34s 204ms/step - loss: 1.2385 - accuracy: 0.4367 - val_loss: 1.5519 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "167/167 [==============================] - 34s 204ms/step - loss: 1.2316 - accuracy: 0.4341 - val_loss: 1.5537 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "167/167 [==============================] - 34s 204ms/step - loss: 1.2228 - accuracy: 0.4466 - val_loss: 1.5543 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "167/167 [==============================] - 34s 204ms/step - loss: 1.2337 - accuracy: 0.4423 - val_loss: 1.5547 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "167/167 [==============================] - 34s 204ms/step - loss: 1.2353 - accuracy: 0.4358 - val_loss: 1.5545 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "167/167 [==============================] - 34s 206ms/step - loss: 1.2317 - accuracy: 0.4420 - val_loss: 1.5551 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "167/167 [==============================] - 34s 204ms/step - loss: 1.2285 - accuracy: 0.4379 - val_loss: 1.5554 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "167/167 [==============================] - 34s 204ms/step - loss: 1.2312 - accuracy: 0.4456 - val_loss: 1.5560 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "167/167 [==============================] - 34s 203ms/step - loss: 1.2333 - accuracy: 0.4354 - val_loss: 1.5560 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "167/167 [==============================] - 34s 205ms/step - loss: 1.2232 - accuracy: 0.4461 - val_loss: 1.5562 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "167/167 [==============================] - 34s 205ms/step - loss: 1.2383 - accuracy: 0.4368 - val_loss: 1.5561 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "167/167 [==============================] - 34s 204ms/step - loss: 1.2306 - accuracy: 0.4468 - val_loss: 1.5560 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "167/167 [==============================] - 34s 204ms/step - loss: 1.2295 - accuracy: 0.4413 - val_loss: 1.5562 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "167/167 [==============================] - 34s 205ms/step - loss: 1.2350 - accuracy: 0.4472 - val_loss: 1.5562 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "167/167 [==============================] - 34s 206ms/step - loss: 1.2162 - accuracy: 0.4521 - val_loss: 1.5563 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "167/167 [==============================] - 34s 204ms/step - loss: 1.2286 - accuracy: 0.4461 - val_loss: 1.5561 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "167/167 [==============================] - 34s 205ms/step - loss: 1.2289 - accuracy: 0.4458 - val_loss: 1.5561 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "167/167 [==============================] - 34s 205ms/step - loss: 1.2261 - accuracy: 0.4466 - val_loss: 1.5562 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "167/167 [==============================] - 35s 207ms/step - loss: 1.2262 - accuracy: 0.4434 - val_loss: 1.5562 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "167/167 [==============================] - 34s 206ms/step - loss: 1.2329 - accuracy: 0.4421 - val_loss: 1.5563 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "167/167 [==============================] - 35s 212ms/step - loss: 1.2345 - accuracy: 0.4366 - val_loss: 1.5563 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "167/167 [==============================] - 35s 209ms/step - loss: 1.2423 - accuracy: 0.4308 - val_loss: 1.5563 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_8348.4_images_True_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.25251758 0.24784303 0.25484667 0.24524141]\n",
      "Training octnet for 0.25% of train size (aka 20871 images) with pretrained: False and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 23 trainable: 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/418 [..............................] - ETA: 3:09 - loss: 4.8107 - accuracy: 0.2649WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0374s vs `on_train_batch_begin` time: 0.2107s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0374s vs `on_train_batch_end` time: 0.1450s). Check your callbacks.\n",
      "418/418 [==============================] - 24s 55ms/step - loss: 2.4497 - accuracy: 0.5225 - val_loss: 0.8616 - val_accuracy: 0.6562\n",
      "Epoch 2/30\n",
      "  1/418 [..............................] - ETA: 17s - loss: 0.7611 - accuracy: 0.7000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "418/418 [==============================] - 19s 47ms/step - loss: 0.8552 - accuracy: 0.7134 - val_loss: 0.5896 - val_accuracy: 0.6875\n",
      "Epoch 3/30\n",
      "418/418 [==============================] - 22s 52ms/step - loss: 0.6489 - accuracy: 0.7699 - val_loss: 0.5292 - val_accuracy: 0.7500\n",
      "Epoch 4/30\n",
      "418/418 [==============================] - 21s 50ms/step - loss: 0.5398 - accuracy: 0.8065 - val_loss: 0.4444 - val_accuracy: 0.7812\n",
      "Epoch 5/30\n",
      "418/418 [==============================] - 22s 52ms/step - loss: 0.4794 - accuracy: 0.8354 - val_loss: 0.3126 - val_accuracy: 0.8438\n",
      "Epoch 6/30\n",
      "418/418 [==============================] - 21s 50ms/step - loss: 0.4347 - accuracy: 0.8492 - val_loss: 0.3164 - val_accuracy: 0.9062\n",
      "Epoch 7/30\n",
      "418/418 [==============================] - 21s 50ms/step - loss: 0.3996 - accuracy: 0.8610 - val_loss: 0.2351 - val_accuracy: 0.9062\n",
      "Epoch 8/30\n",
      "418/418 [==============================] - 20s 48ms/step - loss: 0.3647 - accuracy: 0.8748 - val_loss: 0.1559 - val_accuracy: 0.9375\n",
      "Epoch 9/30\n",
      "418/418 [==============================] - 21s 51ms/step - loss: 0.3293 - accuracy: 0.8870 - val_loss: 0.2579 - val_accuracy: 0.9062\n",
      "Epoch 10/30\n",
      "418/418 [==============================] - 21s 49ms/step - loss: 0.3010 - accuracy: 0.8957 - val_loss: 0.1829 - val_accuracy: 0.9688\n",
      "Epoch 11/30\n",
      "418/418 [==============================] - 21s 51ms/step - loss: 0.2764 - accuracy: 0.9042 - val_loss: 0.0893 - val_accuracy: 0.9688\n",
      "Epoch 12/30\n",
      "418/418 [==============================] - 21s 50ms/step - loss: 0.2511 - accuracy: 0.9162 - val_loss: 0.1230 - val_accuracy: 0.9688\n",
      "Epoch 13/30\n",
      "418/418 [==============================] - 21s 50ms/step - loss: 0.2361 - accuracy: 0.9171 - val_loss: 0.2317 - val_accuracy: 0.9375\n",
      "Epoch 14/30\n",
      "418/418 [==============================] - 23s 54ms/step - loss: 0.2149 - accuracy: 0.9286 - val_loss: 0.1908 - val_accuracy: 0.9688\n",
      "Epoch 15/30\n",
      "418/418 [==============================] - 21s 51ms/step - loss: 0.2055 - accuracy: 0.9291 - val_loss: 0.1488 - val_accuracy: 0.9688\n",
      "Epoch 16/30\n",
      "418/418 [==============================] - 21s 50ms/step - loss: 0.1883 - accuracy: 0.9357 - val_loss: 0.1728 - val_accuracy: 0.9375\n",
      "Epoch 17/30\n",
      "418/418 [==============================] - 21s 50ms/step - loss: 0.1759 - accuracy: 0.9400 - val_loss: 0.2014 - val_accuracy: 0.9688\n",
      "Epoch 18/30\n",
      "418/418 [==============================] - 21s 50ms/step - loss: 0.1623 - accuracy: 0.9457 - val_loss: 0.1079 - val_accuracy: 0.9688\n",
      "Epoch 19/30\n",
      "418/418 [==============================] - 23s 56ms/step - loss: 0.1480 - accuracy: 0.9478 - val_loss: 0.1338 - val_accuracy: 0.9688\n",
      "Epoch 20/30\n",
      "418/418 [==============================] - 22s 53ms/step - loss: 0.1472 - accuracy: 0.9483 - val_loss: 0.1469 - val_accuracy: 0.9688\n",
      "Epoch 21/30\n",
      "418/418 [==============================] - 21s 51ms/step - loss: 0.1435 - accuracy: 0.9513 - val_loss: 0.1125 - val_accuracy: 0.9688\n",
      "Epoch 22/30\n",
      "418/418 [==============================] - 21s 50ms/step - loss: 0.1200 - accuracy: 0.9582 - val_loss: 0.1795 - val_accuracy: 0.9688\n",
      "Epoch 23/30\n",
      "418/418 [==============================] - 23s 54ms/step - loss: 0.1149 - accuracy: 0.9589 - val_loss: 0.1556 - val_accuracy: 0.9688\n",
      "Epoch 24/30\n",
      "418/418 [==============================] - 22s 53ms/step - loss: 0.1115 - accuracy: 0.9590 - val_loss: 0.1716 - val_accuracy: 0.9688\n",
      "Epoch 25/30\n",
      "418/418 [==============================] - 21s 50ms/step - loss: 0.1084 - accuracy: 0.9661 - val_loss: 0.1733 - val_accuracy: 0.9688\n",
      "Epoch 26/30\n",
      "418/418 [==============================] - 21s 50ms/step - loss: 0.1063 - accuracy: 0.9643 - val_loss: 0.2387 - val_accuracy: 0.9688\n",
      "Epoch 27/30\n",
      "418/418 [==============================] - 21s 49ms/step - loss: 0.0947 - accuracy: 0.9676 - val_loss: 0.1572 - val_accuracy: 0.9688\n",
      "Epoch 28/30\n",
      "418/418 [==============================] - 20s 49ms/step - loss: 0.0984 - accuracy: 0.9668 - val_loss: 0.1421 - val_accuracy: 0.9688\n",
      "Epoch 29/30\n",
      "418/418 [==============================] - 21s 51ms/step - loss: 0.0900 - accuracy: 0.9704 - val_loss: 0.2020 - val_accuracy: 0.9688\n",
      "Epoch 30/30\n",
      "418/418 [==============================] - 21s 49ms/step - loss: 0.0877 - accuracy: 0.9694 - val_loss: 0.1826 - val_accuracy: 0.9688\n",
      "INFO:tensorflow:Assets written to: ../octnet/octnet_30epochs_20871.0_images_True_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for octnet: 0.946281\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training resnet for 0.25% of train size (aka 20871 images) with pretrained: False and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 178 trainable: 178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/418 [..............................] - ETA: 5:01 - loss: 1.3786 - accuracy: 0.2774WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1200s vs `on_train_batch_begin` time: 0.2063s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1200s vs `on_train_batch_end` time: 0.3082s). Check your callbacks.\n",
      "418/418 [==============================] - 103s 224ms/step - loss: 1.3078 - accuracy: 0.4288 - val_loss: 1.5044 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "418/418 [==============================] - 88s 211ms/step - loss: 1.2414 - accuracy: 0.4341 - val_loss: 1.5498 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "418/418 [==============================] - 88s 211ms/step - loss: 1.2326 - accuracy: 0.4413 - val_loss: 1.5545 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "418/418 [==============================] - 93s 221ms/step - loss: 1.2242 - accuracy: 0.4504 - val_loss: 1.5542 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "418/418 [==============================] - 88s 210ms/step - loss: 1.2262 - accuracy: 0.4439 - val_loss: 1.5556 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "418/418 [==============================] - 88s 211ms/step - loss: 1.2361 - accuracy: 0.4393 - val_loss: 1.5582 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "418/418 [==============================] - 88s 210ms/step - loss: 1.2280 - accuracy: 0.4493 - val_loss: 1.5559 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "418/418 [==============================] - 88s 210ms/step - loss: 1.2253 - accuracy: 0.4468 - val_loss: 1.5557 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "418/418 [==============================] - 88s 210ms/step - loss: 1.2319 - accuracy: 0.4435 - val_loss: 1.5565 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "418/418 [==============================] - 88s 211ms/step - loss: 1.2341 - accuracy: 0.4381 - val_loss: 1.5581 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "418/418 [==============================] - 88s 211ms/step - loss: 1.2289 - accuracy: 0.4436 - val_loss: 1.5571 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "418/418 [==============================] - 87s 209ms/step - loss: 1.2294 - accuracy: 0.4476 - val_loss: 1.5562 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "418/418 [==============================] - 88s 211ms/step - loss: 1.2324 - accuracy: 0.4391 - val_loss: 1.5566 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "418/418 [==============================] - 135s 323ms/step - loss: 1.2275 - accuracy: 0.4465 - val_loss: 1.5568 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "418/418 [==============================] - 135s 323ms/step - loss: 1.2336 - accuracy: 0.4400 - val_loss: 1.5571 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "418/418 [==============================] - 88s 209ms/step - loss: 1.2278 - accuracy: 0.4419 - val_loss: 1.5574 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "418/418 [==============================] - 87s 209ms/step - loss: 1.2301 - accuracy: 0.4426 - val_loss: 1.5570 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "418/418 [==============================] - 87s 208ms/step - loss: 1.2345 - accuracy: 0.4407 - val_loss: 1.5570 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "418/418 [==============================] - 86s 206ms/step - loss: 1.2325 - accuracy: 0.4414 - val_loss: 1.5572 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "418/418 [==============================] - 87s 208ms/step - loss: 1.2323 - accuracy: 0.4440 - val_loss: 1.5570 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "418/418 [==============================] - 86s 205ms/step - loss: 1.2345 - accuracy: 0.4405 - val_loss: 1.5571 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "418/418 [==============================] - 88s 211ms/step - loss: 1.2286 - accuracy: 0.4429 - val_loss: 1.5573 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "418/418 [==============================] - 93s 222ms/step - loss: 1.2234 - accuracy: 0.4512 - val_loss: 1.5570 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "418/418 [==============================] - 91s 217ms/step - loss: 1.2347 - accuracy: 0.4354 - val_loss: 1.5570 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "418/418 [==============================] - 87s 209ms/step - loss: 1.2330 - accuracy: 0.4429 - val_loss: 1.5571 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "418/418 [==============================] - 87s 209ms/step - loss: 1.2337 - accuracy: 0.4374 - val_loss: 1.5570 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "418/418 [==============================] - 88s 211ms/step - loss: 1.2290 - accuracy: 0.4437 - val_loss: 1.5571 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "418/418 [==============================] - 89s 212ms/step - loss: 1.2334 - accuracy: 0.4396 - val_loss: 1.5571 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "418/418 [==============================] - 87s 207ms/step - loss: 1.2293 - accuracy: 0.4429 - val_loss: 1.5572 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "418/418 [==============================] - 88s 210ms/step - loss: 1.2283 - accuracy: 0.4453 - val_loss: 1.5571 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_20871.0_images_True_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.40547216 0.3980379  0.40183292 0.38927577]\n",
      "Training octnet for 0.4% of train size (aka 33393 images) with pretrained: False and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 23 trainable: 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  5/668 [..............................] - ETA: 7:36 - loss: 4.3486 - accuracy: 0.3304WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0370s vs `on_train_batch_begin` time: 0.2151s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0370s vs `on_train_batch_end` time: 0.2283s). Check your callbacks.\n",
      "668/668 [==============================] - 40s 58ms/step - loss: 1.9717 - accuracy: 0.5517 - val_loss: 0.7071 - val_accuracy: 0.5938\n",
      "Epoch 2/30\n",
      "  1/668 [..............................] - ETA: 28s - loss: 0.7166 - accuracy: 0.7400"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "668/668 [==============================] - 36s 54ms/step - loss: 0.6777 - accuracy: 0.7648 - val_loss: 0.5404 - val_accuracy: 0.7500\n",
      "Epoch 3/30\n",
      "668/668 [==============================] - 35s 53ms/step - loss: 0.5286 - accuracy: 0.8119 - val_loss: 0.3876 - val_accuracy: 0.8750\n",
      "Epoch 4/30\n",
      "668/668 [==============================] - 63s 95ms/step - loss: 0.4393 - accuracy: 0.8484 - val_loss: 0.2719 - val_accuracy: 0.8750\n",
      "Epoch 5/30\n",
      "668/668 [==============================] - 62s 93ms/step - loss: 0.3902 - accuracy: 0.8653 - val_loss: 0.2748 - val_accuracy: 0.9375\n",
      "Epoch 6/30\n",
      "668/668 [==============================] - 41s 61ms/step - loss: 0.3469 - accuracy: 0.8812 - val_loss: 0.1234 - val_accuracy: 0.9375\n",
      "Epoch 7/30\n",
      "668/668 [==============================] - 34s 51ms/step - loss: 0.3222 - accuracy: 0.8904 - val_loss: 0.2426 - val_accuracy: 0.9062\n",
      "Epoch 8/30\n",
      "668/668 [==============================] - 35s 52ms/step - loss: 0.2827 - accuracy: 0.9046 - val_loss: 0.1358 - val_accuracy: 0.9375\n",
      "Epoch 9/30\n",
      "668/668 [==============================] - 33s 49ms/step - loss: 0.2554 - accuracy: 0.9139 - val_loss: 0.1575 - val_accuracy: 0.9688\n",
      "Epoch 10/30\n",
      "668/668 [==============================] - 32s 48ms/step - loss: 0.2255 - accuracy: 0.9227 - val_loss: 0.1136 - val_accuracy: 0.9375\n",
      "Epoch 11/30\n",
      "668/668 [==============================] - 32s 48ms/step - loss: 0.2086 - accuracy: 0.9295 - val_loss: 0.1055 - val_accuracy: 0.9688\n",
      "Epoch 12/30\n",
      "668/668 [==============================] - 32s 48ms/step - loss: 0.1864 - accuracy: 0.9373 - val_loss: 0.0659 - val_accuracy: 0.9688\n",
      "Epoch 13/30\n",
      "668/668 [==============================] - 31s 47ms/step - loss: 0.1744 - accuracy: 0.9407 - val_loss: 0.0445 - val_accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "668/668 [==============================] - 34s 51ms/step - loss: 0.1445 - accuracy: 0.9507 - val_loss: 0.0215 - val_accuracy: 1.0000\n",
      "Epoch 15/30\n",
      "668/668 [==============================] - 34s 51ms/step - loss: 0.1394 - accuracy: 0.9528 - val_loss: 0.1159 - val_accuracy: 0.9375\n",
      "Epoch 16/30\n",
      "668/668 [==============================] - 34s 50ms/step - loss: 0.1259 - accuracy: 0.9587 - val_loss: 0.1277 - val_accuracy: 0.9375\n",
      "Epoch 17/30\n",
      "668/668 [==============================] - 35s 52ms/step - loss: 0.1147 - accuracy: 0.9622 - val_loss: 0.0275 - val_accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "668/668 [==============================] - 34s 50ms/step - loss: 0.1013 - accuracy: 0.9662 - val_loss: 0.0256 - val_accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "668/668 [==============================] - 33s 49ms/step - loss: 0.0922 - accuracy: 0.9686 - val_loss: 0.0226 - val_accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "668/668 [==============================] - 35s 53ms/step - loss: 0.0934 - accuracy: 0.9682 - val_loss: 0.0283 - val_accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "668/668 [==============================] - 34s 51ms/step - loss: 0.0909 - accuracy: 0.9691 - val_loss: 0.0244 - val_accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "668/668 [==============================] - 35s 53ms/step - loss: 0.0772 - accuracy: 0.9742 - val_loss: 0.0458 - val_accuracy: 0.9688\n",
      "Epoch 23/30\n",
      "668/668 [==============================] - 35s 52ms/step - loss: 0.0702 - accuracy: 0.9767 - val_loss: 0.0180 - val_accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "668/668 [==============================] - 34s 51ms/step - loss: 0.0649 - accuracy: 0.9783 - val_loss: 0.0193 - val_accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "668/668 [==============================] - 33s 50ms/step - loss: 0.0655 - accuracy: 0.9791 - val_loss: 0.0119 - val_accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "668/668 [==============================] - 36s 53ms/step - loss: 0.0629 - accuracy: 0.9793 - val_loss: 0.0256 - val_accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "668/668 [==============================] - 34s 51ms/step - loss: 0.0572 - accuracy: 0.9807 - val_loss: 0.0308 - val_accuracy: 0.9688\n",
      "Epoch 28/30\n",
      "668/668 [==============================] - 32s 48ms/step - loss: 0.0539 - accuracy: 0.9823 - val_loss: 0.0174 - val_accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "668/668 [==============================] - 36s 54ms/step - loss: 0.0595 - accuracy: 0.9805 - val_loss: 0.0269 - val_accuracy: 0.9688\n",
      "Epoch 30/30\n",
      "668/668 [==============================] - 32s 47ms/step - loss: 0.0515 - accuracy: 0.9825 - val_loss: 0.0226 - val_accuracy: 1.0000\n",
      "INFO:tensorflow:Assets written to: ../octnet/octnet_30epochs_33393.6_images_True_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for octnet: 0.959711\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training resnet for 0.4% of train size (aka 33393 images) with pretrained: False and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 178 trainable: 178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/668 [..............................] - ETA: 7:52 - loss: 1.3778 - accuracy: 0.3341WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1109s vs `on_train_batch_begin` time: 0.2081s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1109s vs `on_train_batch_end` time: 0.3026s). Check your callbacks.\n",
      "668/668 [==============================] - 151s 215ms/step - loss: 1.2936 - accuracy: 0.4375 - val_loss: 1.5487 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "668/668 [==============================] - 138s 207ms/step - loss: 1.2290 - accuracy: 0.4438 - val_loss: 1.5584 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "668/668 [==============================] - 137s 206ms/step - loss: 1.2319 - accuracy: 0.4464 - val_loss: 1.5674 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "668/668 [==============================] - 137s 206ms/step - loss: 1.2248 - accuracy: 0.4450 - val_loss: 1.5569 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "668/668 [==============================] - 138s 206ms/step - loss: 1.2303 - accuracy: 0.4411 - val_loss: 1.5616 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "668/668 [==============================] - 137s 206ms/step - loss: 1.2248 - accuracy: 0.4496 - val_loss: 1.5620 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "668/668 [==============================] - 137s 205ms/step - loss: 1.2278 - accuracy: 0.4396 - val_loss: 1.5601 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "668/668 [==============================] - 137s 205ms/step - loss: 1.2270 - accuracy: 0.4418 - val_loss: 1.5618 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "668/668 [==============================] - 137s 205ms/step - loss: 1.2258 - accuracy: 0.4444 - val_loss: 1.5602 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "668/668 [==============================] - 137s 205ms/step - loss: 1.2291 - accuracy: 0.4419 - val_loss: 1.5612 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "668/668 [==============================] - 137s 205ms/step - loss: 1.2250 - accuracy: 0.4430 - val_loss: 1.5607 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "668/668 [==============================] - 137s 206ms/step - loss: 1.2289 - accuracy: 0.4414 - val_loss: 1.5605 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "668/668 [==============================] - 137s 205ms/step - loss: 1.2259 - accuracy: 0.4462 - val_loss: 1.5602 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "668/668 [==============================] - 137s 205ms/step - loss: 1.2276 - accuracy: 0.4454 - val_loss: 1.5612 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "668/668 [==============================] - 137s 205ms/step - loss: 1.2326 - accuracy: 0.4416 - val_loss: 1.5619 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "668/668 [==============================] - 137s 205ms/step - loss: 1.2282 - accuracy: 0.4450 - val_loss: 1.5610 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "668/668 [==============================] - 137s 205ms/step - loss: 1.2233 - accuracy: 0.4478 - val_loss: 1.5604 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "668/668 [==============================] - 136s 204ms/step - loss: 1.2275 - accuracy: 0.4413 - val_loss: 1.5603 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "668/668 [==============================] - 137s 205ms/step - loss: 1.2278 - accuracy: 0.4423 - val_loss: 1.5608 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "668/668 [==============================] - 137s 205ms/step - loss: 1.2286 - accuracy: 0.4435 - val_loss: 1.5609 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "668/668 [==============================] - 136s 204ms/step - loss: 1.2310 - accuracy: 0.4426 - val_loss: 1.5610 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "668/668 [==============================] - 136s 204ms/step - loss: 1.2274 - accuracy: 0.4407 - val_loss: 1.5610 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "668/668 [==============================] - 136s 204ms/step - loss: 1.2210 - accuracy: 0.4485 - val_loss: 1.5607 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "668/668 [==============================] - 136s 204ms/step - loss: 1.2259 - accuracy: 0.4439 - val_loss: 1.5605 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "668/668 [==============================] - 136s 204ms/step - loss: 1.2254 - accuracy: 0.4427 - val_loss: 1.5606 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "668/668 [==============================] - 136s 204ms/step - loss: 1.2265 - accuracy: 0.4438 - val_loss: 1.5605 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "668/668 [==============================] - 136s 204ms/step - loss: 1.2299 - accuracy: 0.4412 - val_loss: 1.5606 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "668/668 [==============================] - 136s 204ms/step - loss: 1.2288 - accuracy: 0.4433 - val_loss: 1.5608 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "668/668 [==============================] - 136s 204ms/step - loss: 1.2258 - accuracy: 0.4420 - val_loss: 1.5608 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "668/668 [==============================] - 137s 206ms/step - loss: 1.2258 - accuracy: 0.4485 - val_loss: 1.5607 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_33393.6_images_True_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.5065552  0.49565919 0.50361297 0.49396472]\n",
      "Training octnet for 0.5% of train size (aka 41742 images) with pretrained: False and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 23 trainable: 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  5/835 [..............................] - ETA: 7:31 - loss: 3.5795 - accuracy: 0.3556 WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0289s vs `on_train_batch_begin` time: 0.2018s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0289s vs `on_train_batch_end` time: 0.1467s). Check your callbacks.\n",
      "835/835 [==============================] - 41s 48ms/step - loss: 1.8177 - accuracy: 0.5700 - val_loss: 1.1253 - val_accuracy: 0.6250\n",
      "Epoch 2/30\n",
      "  1/835 [..............................] - ETA: 34s - loss: 0.5107 - accuracy: 0.8600"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "835/835 [==============================] - 37s 44ms/step - loss: 0.6144 - accuracy: 0.7867 - val_loss: 0.4740 - val_accuracy: 0.7812\n",
      "Epoch 3/30\n",
      "835/835 [==============================] - 37s 45ms/step - loss: 0.4686 - accuracy: 0.8381 - val_loss: 0.3769 - val_accuracy: 0.8125\n",
      "Epoch 4/30\n",
      "835/835 [==============================] - 38s 46ms/step - loss: 0.3978 - accuracy: 0.8601 - val_loss: 0.3140 - val_accuracy: 0.8750\n",
      "Epoch 5/30\n",
      "835/835 [==============================] - 37s 45ms/step - loss: 0.3376 - accuracy: 0.8850 - val_loss: 0.1986 - val_accuracy: 0.9062\n",
      "Epoch 6/30\n",
      "835/835 [==============================] - 37s 45ms/step - loss: 0.3043 - accuracy: 0.8955 - val_loss: 0.1199 - val_accuracy: 0.9688\n",
      "Epoch 7/30\n",
      "835/835 [==============================] - 38s 45ms/step - loss: 0.2703 - accuracy: 0.9087 - val_loss: 0.2461 - val_accuracy: 0.9375\n",
      "Epoch 8/30\n",
      "835/835 [==============================] - 37s 45ms/step - loss: 0.2404 - accuracy: 0.9186 - val_loss: 0.3807 - val_accuracy: 0.8438\n",
      "Epoch 9/30\n",
      "835/835 [==============================] - 37s 45ms/step - loss: 0.2169 - accuracy: 0.9246 - val_loss: 0.0823 - val_accuracy: 0.9688\n",
      "Epoch 10/30\n",
      "835/835 [==============================] - 37s 45ms/step - loss: 0.1907 - accuracy: 0.9339 - val_loss: 0.1469 - val_accuracy: 0.9688\n",
      "Epoch 11/30\n",
      "835/835 [==============================] - 37s 45ms/step - loss: 0.1687 - accuracy: 0.9425 - val_loss: 0.1507 - val_accuracy: 0.9062\n",
      "Epoch 12/30\n",
      "835/835 [==============================] - 38s 45ms/step - loss: 0.1519 - accuracy: 0.9491 - val_loss: 0.0992 - val_accuracy: 0.9688\n",
      "Epoch 13/30\n",
      "835/835 [==============================] - 37s 45ms/step - loss: 0.1336 - accuracy: 0.9539 - val_loss: 0.0677 - val_accuracy: 0.9688\n",
      "Epoch 14/30\n",
      "835/835 [==============================] - 38s 45ms/step - loss: 0.1208 - accuracy: 0.9588 - val_loss: 0.0690 - val_accuracy: 0.9688\n",
      "Epoch 15/30\n",
      "835/835 [==============================] - 37s 45ms/step - loss: 0.1106 - accuracy: 0.9628 - val_loss: 0.1636 - val_accuracy: 0.9062\n",
      "Epoch 16/30\n",
      "835/835 [==============================] - 37s 45ms/step - loss: 0.0986 - accuracy: 0.9677 - val_loss: 0.0367 - val_accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "835/835 [==============================] - 38s 45ms/step - loss: 0.0885 - accuracy: 0.9702 - val_loss: 0.0954 - val_accuracy: 0.9688\n",
      "Epoch 18/30\n",
      "835/835 [==============================] - 37s 45ms/step - loss: 0.0776 - accuracy: 0.9742 - val_loss: 0.0800 - val_accuracy: 0.9688\n",
      "Epoch 19/30\n",
      "835/835 [==============================] - 38s 45ms/step - loss: 0.0683 - accuracy: 0.9776 - val_loss: 0.0810 - val_accuracy: 0.9688\n",
      "Epoch 20/30\n",
      "835/835 [==============================] - 38s 45ms/step - loss: 0.0662 - accuracy: 0.9776 - val_loss: 0.0624 - val_accuracy: 0.9688\n",
      "Epoch 21/30\n",
      "835/835 [==============================] - 38s 45ms/step - loss: 0.0602 - accuracy: 0.9793 - val_loss: 0.0546 - val_accuracy: 0.9688\n",
      "Epoch 22/30\n",
      "835/835 [==============================] - 37s 45ms/step - loss: 0.0586 - accuracy: 0.9799 - val_loss: 0.0356 - val_accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "835/835 [==============================] - 37s 45ms/step - loss: 0.0562 - accuracy: 0.9824 - val_loss: 0.0447 - val_accuracy: 0.9688\n",
      "Epoch 24/30\n",
      "835/835 [==============================] - 38s 45ms/step - loss: 0.0500 - accuracy: 0.9832 - val_loss: 0.0758 - val_accuracy: 0.9688\n",
      "Epoch 25/30\n",
      "835/835 [==============================] - 37s 45ms/step - loss: 0.0499 - accuracy: 0.9835 - val_loss: 0.0716 - val_accuracy: 0.9688\n",
      "Epoch 26/30\n",
      "835/835 [==============================] - 37s 45ms/step - loss: 0.0442 - accuracy: 0.9848 - val_loss: 0.0805 - val_accuracy: 0.9688\n",
      "Epoch 27/30\n",
      "835/835 [==============================] - 37s 45ms/step - loss: 0.0458 - accuracy: 0.9847 - val_loss: 0.0665 - val_accuracy: 0.9688\n",
      "Epoch 28/30\n",
      "835/835 [==============================] - 38s 45ms/step - loss: 0.0385 - accuracy: 0.9877 - val_loss: 0.0487 - val_accuracy: 0.9688\n",
      "Epoch 29/30\n",
      "835/835 [==============================] - 38s 46ms/step - loss: 0.0385 - accuracy: 0.9857 - val_loss: 0.0370 - val_accuracy: 0.9688\n",
      "Epoch 30/30\n",
      "835/835 [==============================] - 38s 45ms/step - loss: 0.0387 - accuracy: 0.9872 - val_loss: 0.0163 - val_accuracy: 1.0000\n",
      "INFO:tensorflow:Assets written to: ../octnet/octnet_30epochs_41742.0_images_True_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for octnet: 0.958678\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training resnet for 0.5% of train size (aka 41742 images) with pretrained: False and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 178 trainable: 178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/835 [..............................] - ETA: 9:31 - loss: 1.3765 - accuracy: 0.3485 WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1063s vs `on_train_batch_begin` time: 0.2032s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1063s vs `on_train_batch_end` time: 0.2905s). Check your callbacks.\n",
      "835/835 [==============================] - 186s 213ms/step - loss: 1.2755 - accuracy: 0.5105 - val_loss: 1.5465 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "835/835 [==============================] - 172s 206ms/step - loss: 1.2330 - accuracy: 0.4386 - val_loss: 1.5587 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "835/835 [==============================] - 171s 205ms/step - loss: 1.2332 - accuracy: 0.4419 - val_loss: 1.5587 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "835/835 [==============================] - 172s 206ms/step - loss: 1.2351 - accuracy: 0.4402 - val_loss: 1.5581 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "835/835 [==============================] - 172s 205ms/step - loss: 1.2273 - accuracy: 0.4438 - val_loss: 1.5579 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "835/835 [==============================] - 172s 206ms/step - loss: 1.2307 - accuracy: 0.4432 - val_loss: 1.5569 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "835/835 [==============================] - 171s 205ms/step - loss: 1.2316 - accuracy: 0.4430 - val_loss: 1.5578 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "835/835 [==============================] - 171s 205ms/step - loss: 1.2324 - accuracy: 0.4402 - val_loss: 1.5571 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "835/835 [==============================] - 171s 205ms/step - loss: 1.2350 - accuracy: 0.4408 - val_loss: 1.5589 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "835/835 [==============================] - 172s 205ms/step - loss: 1.2302 - accuracy: 0.4401 - val_loss: 1.5579 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "835/835 [==============================] - 171s 205ms/step - loss: 1.2282 - accuracy: 0.4419 - val_loss: 1.5558 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "835/835 [==============================] - 171s 205ms/step - loss: 1.2261 - accuracy: 0.4448 - val_loss: 1.5559 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "835/835 [==============================] - 173s 207ms/step - loss: 1.2290 - accuracy: 0.4418 - val_loss: 1.5562 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "835/835 [==============================] - 171s 205ms/step - loss: 1.2314 - accuracy: 0.4411 - val_loss: 1.5582 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "835/835 [==============================] - 172s 206ms/step - loss: 1.2310 - accuracy: 0.4424 - val_loss: 1.5581 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "835/835 [==============================] - 171s 205ms/step - loss: 1.2325 - accuracy: 0.4390 - val_loss: 1.5587 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "835/835 [==============================] - 171s 205ms/step - loss: 1.2343 - accuracy: 0.4399 - val_loss: 1.5585 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "835/835 [==============================] - 171s 205ms/step - loss: 1.2338 - accuracy: 0.4403 - val_loss: 1.5582 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "835/835 [==============================] - 171s 205ms/step - loss: 1.2302 - accuracy: 0.4428 - val_loss: 1.5574 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "835/835 [==============================] - 172s 205ms/step - loss: 1.2352 - accuracy: 0.4360 - val_loss: 1.5581 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "835/835 [==============================] - 171s 205ms/step - loss: 1.2354 - accuracy: 0.4419 - val_loss: 1.5580 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "835/835 [==============================] - 171s 205ms/step - loss: 1.2329 - accuracy: 0.4423 - val_loss: 1.5579 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "835/835 [==============================] - 171s 205ms/step - loss: 1.2343 - accuracy: 0.4384 - val_loss: 1.5581 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "835/835 [==============================] - 171s 205ms/step - loss: 1.2305 - accuracy: 0.4410 - val_loss: 1.5579 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "835/835 [==============================] - 172s 206ms/step - loss: 1.2308 - accuracy: 0.4427 - val_loss: 1.5578 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "835/835 [==============================] - 172s 206ms/step - loss: 1.2297 - accuracy: 0.4413 - val_loss: 1.5579 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "835/835 [==============================] - 171s 205ms/step - loss: 1.2287 - accuracy: 0.4450 - val_loss: 1.5577 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "835/835 [==============================] - 172s 205ms/step - loss: 1.2289 - accuracy: 0.4427 - val_loss: 1.5577 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "835/835 [==============================] - 171s 205ms/step - loss: 1.2287 - accuracy: 0.4455 - val_loss: 1.5575 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "835/835 [==============================] - 171s 205ms/step - loss: 1.2330 - accuracy: 0.4439 - val_loss: 1.5575 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_41742.0_images_True_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.60516816 0.59567262 0.60327811 0.5985376 ]\n",
      "Training octnet for 0.6% of train size (aka 50090 images) with pretrained: False and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 23 trainable: 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-a21c27d31b2a>:15: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  self.fig = plt.figure(figsize=(4,3))\n",
      "<ipython-input-10-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "   5/1002 [..............................] - ETA: 9:00 - loss: 5.7853 - accuracy: 0.2825 WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0209s vs `on_train_batch_begin` time: 0.2043s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0209s vs `on_train_batch_end` time: 0.1489s). Check your callbacks.\n",
      "1002/1002 [==============================] - 49s 48ms/step - loss: 1.9546 - accuracy: 0.5910 - val_loss: 0.7582 - val_accuracy: 0.6875\n",
      "Epoch 2/30\n",
      "   1/1002 [..............................] - ETA: 41s - loss: 0.6401 - accuracy: 0.7800"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1002/1002 [==============================] - 45s 45ms/step - loss: 0.5953 - accuracy: 0.7918 - val_loss: 0.5230 - val_accuracy: 0.7812\n",
      "Epoch 3/30\n",
      "1002/1002 [==============================] - 45s 45ms/step - loss: 0.4650 - accuracy: 0.8399 - val_loss: 0.6219 - val_accuracy: 0.7188\n",
      "Epoch 4/30\n",
      "1002/1002 [==============================] - 45s 45ms/step - loss: 0.3729 - accuracy: 0.8731 - val_loss: 0.3046 - val_accuracy: 0.8750\n",
      "Epoch 5/30\n",
      "1002/1002 [==============================] - 46s 46ms/step - loss: 0.3187 - accuracy: 0.8903 - val_loss: 0.1444 - val_accuracy: 0.9375\n",
      "Epoch 6/30\n",
      "1002/1002 [==============================] - 46s 46ms/step - loss: 0.2850 - accuracy: 0.9041 - val_loss: 0.1251 - val_accuracy: 0.9062\n",
      "Epoch 7/30\n",
      "1002/1002 [==============================] - 46s 46ms/step - loss: 0.2528 - accuracy: 0.9155 - val_loss: 0.1807 - val_accuracy: 0.9375\n",
      "Epoch 8/30\n",
      "1002/1002 [==============================] - 45s 45ms/step - loss: 0.2247 - accuracy: 0.9243 - val_loss: 0.1433 - val_accuracy: 0.9062\n",
      "Epoch 9/30\n",
      "1002/1002 [==============================] - 46s 46ms/step - loss: 0.2077 - accuracy: 0.9307 - val_loss: 0.0927 - val_accuracy: 0.9375\n",
      "Epoch 10/30\n",
      "1002/1002 [==============================] - 46s 46ms/step - loss: 0.1815 - accuracy: 0.9384 - val_loss: 0.0764 - val_accuracy: 0.9688\n",
      "Epoch 11/30\n",
      "1002/1002 [==============================] - 46s 46ms/step - loss: 0.1650 - accuracy: 0.9433 - val_loss: 0.0695 - val_accuracy: 0.9688\n",
      "Epoch 12/30\n",
      "1002/1002 [==============================] - 46s 46ms/step - loss: 0.1463 - accuracy: 0.9503 - val_loss: 0.1094 - val_accuracy: 0.9688\n",
      "Epoch 13/30\n",
      "1002/1002 [==============================] - 45s 45ms/step - loss: 0.1328 - accuracy: 0.9559 - val_loss: 0.1100 - val_accuracy: 0.9688\n",
      "Epoch 14/30\n",
      "1002/1002 [==============================] - 46s 46ms/step - loss: 0.1179 - accuracy: 0.9600 - val_loss: 0.0834 - val_accuracy: 0.9375\n",
      "Epoch 15/30\n",
      "1002/1002 [==============================] - 45s 45ms/step - loss: 0.1036 - accuracy: 0.9650 - val_loss: 0.0394 - val_accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "1002/1002 [==============================] - 45s 45ms/step - loss: 0.0978 - accuracy: 0.9671 - val_loss: 0.0565 - val_accuracy: 0.9688\n",
      "Epoch 17/30\n",
      "1002/1002 [==============================] - 45s 45ms/step - loss: 0.0904 - accuracy: 0.9694 - val_loss: 0.0407 - val_accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "1002/1002 [==============================] - 45s 45ms/step - loss: 0.0778 - accuracy: 0.9736 - val_loss: 0.0572 - val_accuracy: 0.9688\n",
      "Epoch 19/30\n",
      "1002/1002 [==============================] - 45s 45ms/step - loss: 0.0725 - accuracy: 0.9747 - val_loss: 0.0914 - val_accuracy: 0.9688\n",
      "Epoch 20/30\n",
      "1002/1002 [==============================] - 45s 45ms/step - loss: 0.0690 - accuracy: 0.9770 - val_loss: 0.0268 - val_accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "1002/1002 [==============================] - 46s 45ms/step - loss: 0.0653 - accuracy: 0.9770 - val_loss: 0.0620 - val_accuracy: 0.9688\n",
      "Epoch 22/30\n",
      "1002/1002 [==============================] - 46s 46ms/step - loss: 0.0597 - accuracy: 0.9803 - val_loss: 0.0423 - val_accuracy: 0.9688\n",
      "Epoch 23/30\n",
      "1002/1002 [==============================] - 46s 46ms/step - loss: 0.0570 - accuracy: 0.9798 - val_loss: 0.0270 - val_accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "1002/1002 [==============================] - 46s 46ms/step - loss: 0.0460 - accuracy: 0.9837 - val_loss: 0.0216 - val_accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "1002/1002 [==============================] - 45s 45ms/step - loss: 0.0489 - accuracy: 0.9829 - val_loss: 0.0166 - val_accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "1002/1002 [==============================] - 46s 46ms/step - loss: 0.0435 - accuracy: 0.9845 - val_loss: 0.0447 - val_accuracy: 0.9688\n",
      "Epoch 27/30\n",
      "1002/1002 [==============================] - 45s 45ms/step - loss: 0.0404 - accuracy: 0.9860 - val_loss: 0.0145 - val_accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "1002/1002 [==============================] - 45s 45ms/step - loss: 0.0404 - accuracy: 0.9863 - val_loss: 0.0829 - val_accuracy: 0.9688\n",
      "Epoch 29/30\n",
      "1002/1002 [==============================] - 46s 46ms/step - loss: 0.0394 - accuracy: 0.9867 - val_loss: 0.0248 - val_accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "1002/1002 [==============================] - 49s 48ms/step - loss: 0.0364 - accuracy: 0.9879 - val_loss: 0.0281 - val_accuracy: 1.0000\n",
      "INFO:tensorflow:Assets written to: ../octnet/octnet_30epochs_50090.4_images_True_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for octnet: 0.974174\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training resnet for 0.6% of train size (aka 50090 images) with pretrained: False and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 178 trainable: 178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "   6/1002 [..............................] - ETA: 11:34 - loss: 1.3761 - accuracy: 0.2977WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1096s vs `on_train_batch_begin` time: 0.2064s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1096s vs `on_train_batch_end` time: 0.2930s). Check your callbacks.\n",
      "1002/1002 [==============================] - 222s 215ms/step - loss: 1.2778 - accuracy: 0.4566 - val_loss: 1.5471 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "1002/1002 [==============================] - 205s 205ms/step - loss: 1.2282 - accuracy: 0.4431 - val_loss: 1.5495 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "1002/1002 [==============================] - 205s 205ms/step - loss: 1.2346 - accuracy: 0.4381 - val_loss: 1.5553 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "1002/1002 [==============================] - 206s 205ms/step - loss: 1.2284 - accuracy: 0.4445 - val_loss: 1.5570 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "1002/1002 [==============================] - 205s 205ms/step - loss: 1.2288 - accuracy: 0.4464 - val_loss: 1.5497 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "1002/1002 [==============================] - 205s 205ms/step - loss: 1.2296 - accuracy: 0.4433 - val_loss: 1.5559 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "1002/1002 [==============================] - 206s 206ms/step - loss: 1.2330 - accuracy: 0.4408 - val_loss: 1.5597 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "1002/1002 [==============================] - 206s 205ms/step - loss: 1.2308 - accuracy: 0.4404 - val_loss: 1.5533 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "1002/1002 [==============================] - 205s 205ms/step - loss: 1.2305 - accuracy: 0.4424 - val_loss: 1.5543 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "1002/1002 [==============================] - 206s 205ms/step - loss: 1.2316 - accuracy: 0.4370 - val_loss: 1.5574 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "1002/1002 [==============================] - 205s 205ms/step - loss: 1.2290 - accuracy: 0.4429 - val_loss: 1.5538 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "1002/1002 [==============================] - 205s 205ms/step - loss: 1.2291 - accuracy: 0.4429 - val_loss: 1.5553 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "1002/1002 [==============================] - 205s 205ms/step - loss: 1.2325 - accuracy: 0.4436 - val_loss: 1.5575 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "1002/1002 [==============================] - 206s 205ms/step - loss: 1.2325 - accuracy: 0.4419 - val_loss: 1.5565 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "1002/1002 [==============================] - 205s 204ms/step - loss: 1.2278 - accuracy: 0.4465 - val_loss: 1.5549 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "1002/1002 [==============================] - 205s 204ms/step - loss: 1.2339 - accuracy: 0.4414 - val_loss: 1.5572 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "1002/1002 [==============================] - 205s 204ms/step - loss: 1.2308 - accuracy: 0.4412 - val_loss: 1.5568 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "1002/1002 [==============================] - 205s 205ms/step - loss: 1.2304 - accuracy: 0.4430 - val_loss: 1.5566 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "1002/1002 [==============================] - 205s 205ms/step - loss: 1.2319 - accuracy: 0.4430 - val_loss: 1.5569 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "1002/1002 [==============================] - 206s 205ms/step - loss: 1.2248 - accuracy: 0.4460 - val_loss: 1.5558 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "1002/1002 [==============================] - 205s 205ms/step - loss: 1.2341 - accuracy: 0.4422 - val_loss: 1.5566 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "1002/1002 [==============================] - 205s 205ms/step - loss: 1.2260 - accuracy: 0.4471 - val_loss: 1.5560 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "1002/1002 [==============================] - 205s 204ms/step - loss: 1.2339 - accuracy: 0.4434 - val_loss: 1.5563 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "1002/1002 [==============================] - 205s 205ms/step - loss: 1.2295 - accuracy: 0.4439 - val_loss: 1.5562 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "1002/1002 [==============================] - 206s 206ms/step - loss: 1.2316 - accuracy: 0.4415 - val_loss: 1.5563 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "1002/1002 [==============================] - 205s 205ms/step - loss: 1.2332 - accuracy: 0.4425 - val_loss: 1.5564 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "1002/1002 [==============================] - 205s 204ms/step - loss: 1.2319 - accuracy: 0.4440 - val_loss: 1.5562 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "1002/1002 [==============================] - 205s 204ms/step - loss: 1.2321 - accuracy: 0.4429 - val_loss: 1.5562 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "1002/1002 [==============================] - 205s 205ms/step - loss: 1.2302 - accuracy: 0.4428 - val_loss: 1.5563 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "1002/1002 [==============================] - 205s 205ms/step - loss: 1.2290 - accuracy: 0.4425 - val_loss: 1.5561 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_50090.4_images_True_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.75500665 0.74748018 0.75255552 0.74222377]\n",
      "Training octnet for 0.75% of train size (aka 62613 images) with pretrained: False and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 23 trainable: 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "   5/1253 [..............................] - ETA: 11:22 - loss: 4.6624 - accuracy: 0.3135WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0227s vs `on_train_batch_begin` time: 0.2059s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0227s vs `on_train_batch_end` time: 0.1494s). Check your callbacks.\n",
      "1253/1253 [==============================] - 60s 47ms/step - loss: 1.7072 - accuracy: 0.6055 - val_loss: 0.8727 - val_accuracy: 0.6875\n",
      "Epoch 2/30\n",
      "   1/1253 [..............................] - ETA: 53s - loss: 0.4324 - accuracy: 0.9000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1253/1253 [==============================] - 57s 46ms/step - loss: 0.5367 - accuracy: 0.8126 - val_loss: 0.7405 - val_accuracy: 0.7500\n",
      "Epoch 3/30\n",
      "1253/1253 [==============================] - 57s 46ms/step - loss: 0.4146 - accuracy: 0.8558 - val_loss: 0.5462 - val_accuracy: 0.8125\n",
      "Epoch 4/30\n",
      "1253/1253 [==============================] - 58s 46ms/step - loss: 0.3436 - accuracy: 0.8827 - val_loss: 0.2674 - val_accuracy: 0.8750\n",
      "Epoch 5/30\n",
      "1253/1253 [==============================] - 58s 46ms/step - loss: 0.2901 - accuracy: 0.9019 - val_loss: 0.1173 - val_accuracy: 0.9688\n",
      "Epoch 6/30\n",
      "1253/1253 [==============================] - 57s 45ms/step - loss: 0.2485 - accuracy: 0.9175 - val_loss: 0.0990 - val_accuracy: 0.9375\n",
      "Epoch 7/30\n",
      "1253/1253 [==============================] - 58s 46ms/step - loss: 0.2213 - accuracy: 0.9274 - val_loss: 0.1895 - val_accuracy: 0.9688\n",
      "Epoch 8/30\n",
      "1253/1253 [==============================] - 57s 46ms/step - loss: 0.1912 - accuracy: 0.9355 - val_loss: 0.1529 - val_accuracy: 0.9688\n",
      "Epoch 9/30\n",
      "1253/1253 [==============================] - 57s 46ms/step - loss: 0.1697 - accuracy: 0.9425 - val_loss: 0.0708 - val_accuracy: 0.9688\n",
      "Epoch 10/30\n",
      "1253/1253 [==============================] - 58s 46ms/step - loss: 0.1565 - accuracy: 0.9483 - val_loss: 0.1040 - val_accuracy: 0.9688\n",
      "Epoch 11/30\n",
      "1253/1253 [==============================] - 57s 46ms/step - loss: 0.1426 - accuracy: 0.9521 - val_loss: 0.1341 - val_accuracy: 0.9688\n",
      "Epoch 12/30\n",
      "1253/1253 [==============================] - 57s 45ms/step - loss: 0.1216 - accuracy: 0.9589 - val_loss: 0.1182 - val_accuracy: 0.9375\n",
      "Epoch 13/30\n",
      "1253/1253 [==============================] - 57s 45ms/step - loss: 0.1091 - accuracy: 0.9648 - val_loss: 0.1878 - val_accuracy: 0.9688\n",
      "Epoch 14/30\n",
      "1253/1253 [==============================] - 57s 46ms/step - loss: 0.0971 - accuracy: 0.9664 - val_loss: 0.1378 - val_accuracy: 0.9688\n",
      "Epoch 15/30\n",
      "1253/1253 [==============================] - 57s 46ms/step - loss: 0.0870 - accuracy: 0.9703 - val_loss: 0.1998 - val_accuracy: 0.9688\n",
      "Epoch 16/30\n",
      "1253/1253 [==============================] - 57s 46ms/step - loss: 0.0791 - accuracy: 0.9733 - val_loss: 0.2587 - val_accuracy: 0.9688\n",
      "Epoch 17/30\n",
      "1253/1253 [==============================] - 58s 46ms/step - loss: 0.0679 - accuracy: 0.9777 - val_loss: 0.1934 - val_accuracy: 0.9688\n",
      "Epoch 18/30\n",
      "1253/1253 [==============================] - 58s 46ms/step - loss: 0.0664 - accuracy: 0.9773 - val_loss: 0.3184 - val_accuracy: 0.9688\n",
      "Epoch 19/30\n",
      "1253/1253 [==============================] - 59s 47ms/step - loss: 0.0534 - accuracy: 0.9817 - val_loss: 0.2562 - val_accuracy: 0.9688\n",
      "Epoch 20/30\n",
      "1253/1253 [==============================] - 58s 47ms/step - loss: 0.0530 - accuracy: 0.9824 - val_loss: 0.2835 - val_accuracy: 0.9688\n",
      "Epoch 21/30\n",
      "1253/1253 [==============================] - 56s 45ms/step - loss: 0.0483 - accuracy: 0.9838 - val_loss: 0.2668 - val_accuracy: 0.9688\n",
      "Epoch 22/30\n",
      "1253/1253 [==============================] - 58s 46ms/step - loss: 0.0462 - accuracy: 0.9840 - val_loss: 0.3075 - val_accuracy: 0.9688\n",
      "Epoch 23/30\n",
      "1253/1253 [==============================] - 57s 45ms/step - loss: 0.0399 - accuracy: 0.9864 - val_loss: 0.2962 - val_accuracy: 0.9688\n",
      "Epoch 24/30\n",
      "1253/1253 [==============================] - 57s 45ms/step - loss: 0.0397 - accuracy: 0.9870 - val_loss: 0.2971 - val_accuracy: 0.9688\n",
      "Epoch 25/30\n",
      "1253/1253 [==============================] - 58s 46ms/step - loss: 0.0399 - accuracy: 0.9870 - val_loss: 0.3239 - val_accuracy: 0.9688\n",
      "Epoch 26/30\n",
      "1253/1253 [==============================] - 58s 46ms/step - loss: 0.0356 - accuracy: 0.9880 - val_loss: 0.3251 - val_accuracy: 0.9688\n",
      "Epoch 27/30\n",
      "1253/1253 [==============================] - 58s 46ms/step - loss: 0.0359 - accuracy: 0.9876 - val_loss: 0.3708 - val_accuracy: 0.9688\n",
      "Epoch 28/30\n",
      "1253/1253 [==============================] - 55s 44ms/step - loss: 0.0309 - accuracy: 0.9899 - val_loss: 0.3411 - val_accuracy: 0.9688\n",
      "Epoch 29/30\n",
      "1253/1253 [==============================] - 58s 46ms/step - loss: 0.0307 - accuracy: 0.9888 - val_loss: 0.3703 - val_accuracy: 0.9688\n",
      "Epoch 30/30\n",
      "1253/1253 [==============================] - 57s 45ms/step - loss: 0.0307 - accuracy: 0.9900 - val_loss: 0.3343 - val_accuracy: 0.9688\n",
      "INFO:tensorflow:Assets written to: ../octnet/octnet_30epochs_62613.0_images_True_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for octnet: 0.984504\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training resnet for 0.75% of train size (aka 62613 images) with pretrained: False and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 178 trainable: 178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "   6/1253 [..............................] - ETA: 15:31 - loss: 1.3781 - accuracy: 0.2744WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1127s vs `on_train_batch_begin` time: 0.2342s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1127s vs `on_train_batch_end` time: 0.3036s). Check your callbacks.\n",
      "1253/1253 [==============================] - 270s 208ms/step - loss: 1.2389 - accuracy: 0.5578 - val_loss: 1.5625 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "1253/1253 [==============================] - 256s 204ms/step - loss: 1.2285 - accuracy: 0.4461 - val_loss: 1.5534 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "1253/1253 [==============================] - 257s 205ms/step - loss: 1.2320 - accuracy: 0.4437 - val_loss: 1.5645 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "1253/1253 [==============================] - 254s 202ms/step - loss: 1.2312 - accuracy: 0.4429 - val_loss: 1.5610 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "1253/1253 [==============================] - 252s 201ms/step - loss: 1.2264 - accuracy: 0.4462 - val_loss: 1.5593 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "1253/1253 [==============================] - 252s 201ms/step - loss: 1.2295 - accuracy: 0.4456 - val_loss: 1.5583 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "1253/1253 [==============================] - 252s 201ms/step - loss: 1.2298 - accuracy: 0.4459 - val_loss: 1.5581 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "1253/1253 [==============================] - 253s 202ms/step - loss: 1.2291 - accuracy: 0.4461 - val_loss: 1.5585 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "1253/1253 [==============================] - 253s 202ms/step - loss: 1.2312 - accuracy: 0.4437 - val_loss: 1.5585 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "1253/1253 [==============================] - 252s 201ms/step - loss: 1.2296 - accuracy: 0.4461 - val_loss: 1.5571 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "1253/1253 [==============================] - 252s 201ms/step - loss: 1.2314 - accuracy: 0.4427 - val_loss: 1.5606 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "1253/1253 [==============================] - 253s 202ms/step - loss: 1.2292 - accuracy: 0.4432 - val_loss: 1.5568 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "1253/1253 [==============================] - 253s 202ms/step - loss: 1.2307 - accuracy: 0.4450 - val_loss: 1.5575 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "1253/1253 [==============================] - 252s 201ms/step - loss: 1.2317 - accuracy: 0.4426 - val_loss: 1.5593 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "1253/1253 [==============================] - 252s 201ms/step - loss: 1.2298 - accuracy: 0.4448 - val_loss: 1.5579 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "1253/1253 [==============================] - 252s 201ms/step - loss: 1.2315 - accuracy: 0.4439 - val_loss: 1.5593 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "1253/1253 [==============================] - 253s 202ms/step - loss: 1.2365 - accuracy: 0.4393 - val_loss: 1.5608 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "1253/1253 [==============================] - 252s 201ms/step - loss: 1.2304 - accuracy: 0.4421 - val_loss: 1.5591 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "1253/1253 [==============================] - 253s 202ms/step - loss: 1.2245 - accuracy: 0.4471 - val_loss: 1.5573 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "1253/1253 [==============================] - 252s 201ms/step - loss: 1.2298 - accuracy: 0.4434 - val_loss: 1.5583 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "1253/1253 [==============================] - 252s 201ms/step - loss: 1.2310 - accuracy: 0.4425 - val_loss: 1.5582 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "1253/1253 [==============================] - 253s 202ms/step - loss: 1.2305 - accuracy: 0.4439 - val_loss: 1.5584 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "1253/1253 [==============================] - 252s 201ms/step - loss: 1.2273 - accuracy: 0.4426 - val_loss: 1.5579 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "1253/1253 [==============================] - 252s 201ms/step - loss: 1.2293 - accuracy: 0.4451 - val_loss: 1.5579 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "1253/1253 [==============================] - 252s 201ms/step - loss: 1.2345 - accuracy: 0.4408 - val_loss: 1.5587 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "1253/1253 [==============================] - 253s 202ms/step - loss: 1.2315 - accuracy: 0.4448 - val_loss: 1.5586 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "1253/1253 [==============================] - 252s 201ms/step - loss: 1.2274 - accuracy: 0.4433 - val_loss: 1.5584 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "1253/1253 [==============================] - 252s 201ms/step - loss: 1.2277 - accuracy: 0.4454 - val_loss: 1.5581 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "1253/1253 [==============================] - 252s 201ms/step - loss: 1.2275 - accuracy: 0.4461 - val_loss: 1.5581 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "1253/1253 [==============================] - 252s 201ms/step - loss: 1.2277 - accuracy: 0.4475 - val_loss: 1.5581 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_62613.0_images_True_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.90378111 0.89694933 0.90192104 0.89902507]\n",
      "Training octnet for 0.9% of train size (aka 75135 images) with pretrained: False and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 23 trainable: 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "   5/1503 [..............................] - ETA: 11:44 - loss: 3.5780 - accuracy: 0.3073WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0229s vs `on_train_batch_begin` time: 0.1533s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0229s vs `on_train_batch_end` time: 0.1507s). Check your callbacks.\n",
      "1503/1503 [==============================] - 67s 44ms/step - loss: 1.4003 - accuracy: 0.6318 - val_loss: 0.4762 - val_accuracy: 0.8125\n",
      "Epoch 2/30\n",
      "   1/1503 [..............................] - ETA: 1:02 - loss: 0.6018 - accuracy: 0.7600"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1503/1503 [==============================] - 63s 42ms/step - loss: 0.4663 - accuracy: 0.8369 - val_loss: 0.4388 - val_accuracy: 0.7812\n",
      "Epoch 3/30\n",
      "1503/1503 [==============================] - 63s 42ms/step - loss: 0.3431 - accuracy: 0.8839 - val_loss: 0.3335 - val_accuracy: 0.8750\n",
      "Epoch 4/30\n",
      "1503/1503 [==============================] - 65s 43ms/step - loss: 0.2897 - accuracy: 0.9038 - val_loss: 0.0843 - val_accuracy: 0.9688\n",
      "Epoch 5/30\n",
      "1503/1503 [==============================] - 64s 43ms/step - loss: 0.2498 - accuracy: 0.9186 - val_loss: 0.0444 - val_accuracy: 1.0000\n",
      "Epoch 6/30\n",
      "1503/1503 [==============================] - 64s 43ms/step - loss: 0.2281 - accuracy: 0.9271 - val_loss: 0.0988 - val_accuracy: 0.9688\n",
      "Epoch 7/30\n",
      "1503/1503 [==============================] - 64s 43ms/step - loss: 0.2035 - accuracy: 0.9331 - val_loss: 0.0493 - val_accuracy: 1.0000\n",
      "Epoch 8/30\n",
      "1503/1503 [==============================] - 64s 43ms/step - loss: 0.1762 - accuracy: 0.9426 - val_loss: 0.0253 - val_accuracy: 1.0000\n",
      "Epoch 9/30\n",
      "1503/1503 [==============================] - 63s 42ms/step - loss: 0.1618 - accuracy: 0.9470 - val_loss: 0.0299 - val_accuracy: 1.0000\n",
      "Epoch 10/30\n",
      "1503/1503 [==============================] - 63s 42ms/step - loss: 0.1463 - accuracy: 0.9517 - val_loss: 0.0083 - val_accuracy: 1.0000\n",
      "Epoch 11/30\n",
      "1503/1503 [==============================] - 63s 42ms/step - loss: 0.1284 - accuracy: 0.9579 - val_loss: 0.0418 - val_accuracy: 0.9688\n",
      "Epoch 12/30\n",
      "1503/1503 [==============================] - 63s 42ms/step - loss: 0.1162 - accuracy: 0.9612 - val_loss: 0.0080 - val_accuracy: 1.0000\n",
      "Epoch 13/30\n",
      "1503/1503 [==============================] - 63s 42ms/step - loss: 0.1015 - accuracy: 0.9669 - val_loss: 0.0126 - val_accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "1503/1503 [==============================] - 63s 42ms/step - loss: 0.0895 - accuracy: 0.9695 - val_loss: 0.0086 - val_accuracy: 1.0000\n",
      "Epoch 15/30\n",
      "1503/1503 [==============================] - 63s 42ms/step - loss: 0.0824 - accuracy: 0.9730 - val_loss: 0.0035 - val_accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "1503/1503 [==============================] - 63s 42ms/step - loss: 0.0747 - accuracy: 0.9743 - val_loss: 0.0889 - val_accuracy: 0.9688\n",
      "Epoch 17/30\n",
      "1503/1503 [==============================] - 63s 42ms/step - loss: 0.0652 - accuracy: 0.9780 - val_loss: 0.0272 - val_accuracy: 0.9688\n",
      "Epoch 18/30\n",
      "1503/1503 [==============================] - 63s 42ms/step - loss: 0.0573 - accuracy: 0.9805 - val_loss: 0.0328 - val_accuracy: 0.9688\n",
      "Epoch 19/30\n",
      "1503/1503 [==============================] - 63s 42ms/step - loss: 0.0540 - accuracy: 0.9820 - val_loss: 0.0316 - val_accuracy: 0.9688\n",
      "Epoch 20/30\n",
      "1503/1503 [==============================] - 63s 42ms/step - loss: 0.0526 - accuracy: 0.9828 - val_loss: 0.0691 - val_accuracy: 0.9688\n",
      "Epoch 21/30\n",
      "1503/1503 [==============================] - 63s 42ms/step - loss: 0.0454 - accuracy: 0.9847 - val_loss: 0.0369 - val_accuracy: 0.9688\n",
      "Epoch 22/30\n",
      "1503/1503 [==============================] - 64s 42ms/step - loss: 0.0442 - accuracy: 0.9847 - val_loss: 0.0078 - val_accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "1503/1503 [==============================] - 63s 42ms/step - loss: 0.0445 - accuracy: 0.9861 - val_loss: 0.0618 - val_accuracy: 0.9688\n",
      "Epoch 24/30\n",
      "1503/1503 [==============================] - 63s 42ms/step - loss: 0.0375 - accuracy: 0.9875 - val_loss: 0.0850 - val_accuracy: 0.9688\n",
      "Epoch 25/30\n",
      "1503/1503 [==============================] - 63s 42ms/step - loss: 0.0359 - accuracy: 0.9869 - val_loss: 0.0706 - val_accuracy: 0.9688\n",
      "Epoch 26/30\n",
      "1503/1503 [==============================] - 63s 42ms/step - loss: 0.0344 - accuracy: 0.9882 - val_loss: 0.0461 - val_accuracy: 0.9688\n",
      "Epoch 27/30\n",
      "1503/1503 [==============================] - 63s 42ms/step - loss: 0.0317 - accuracy: 0.9891 - val_loss: 0.0844 - val_accuracy: 0.9688\n",
      "Epoch 28/30\n",
      "1503/1503 [==============================] - 63s 42ms/step - loss: 0.0316 - accuracy: 0.9891 - val_loss: 0.1413 - val_accuracy: 0.9688\n",
      "Epoch 29/30\n",
      "1503/1503 [==============================] - 64s 42ms/step - loss: 0.0311 - accuracy: 0.9896 - val_loss: 0.0630 - val_accuracy: 0.9688\n",
      "Epoch 30/30\n",
      "1503/1503 [==============================] - 63s 42ms/step - loss: 0.0294 - accuracy: 0.9899 - val_loss: 0.0966 - val_accuracy: 0.9688\n",
      "INFO:tensorflow:Assets written to: ../octnet/octnet_30epochs_75135.6_images_True_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for octnet: 0.982438\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training resnet for 0.9% of train size (aka 75135 images) with pretrained: False and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 178 trainable: 178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "   6/1503 [..............................] - ETA: 17:52 - loss: 1.3784 - accuracy: 0.2972WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1051s vs `on_train_batch_begin` time: 0.2050s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1051s vs `on_train_batch_end` time: 0.3115s). Check your callbacks.\n",
      "1503/1503 [==============================] - 313s 203ms/step - loss: 1.2307 - accuracy: 0.5338 - val_loss: 1.4189 - val_accuracy: 0.4062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "1503/1503 [==============================] - 301s 200ms/step - loss: 0.8518 - accuracy: 0.7123 - val_loss: 1.3875 - val_accuracy: 0.5625\n",
      "Epoch 3/30\n",
      "1503/1503 [==============================] - 302s 201ms/step - loss: 0.7212 - accuracy: 0.7503 - val_loss: 0.8977 - val_accuracy: 0.6250\n",
      "Epoch 4/30\n",
      "1503/1503 [==============================] - 301s 200ms/step - loss: 0.6249 - accuracy: 0.7855 - val_loss: 0.9981 - val_accuracy: 0.5625\n",
      "Epoch 5/30\n",
      "1503/1503 [==============================] - 301s 201ms/step - loss: 0.5607 - accuracy: 0.8052 - val_loss: 0.7871 - val_accuracy: 0.6875\n",
      "Epoch 6/30\n",
      "1503/1503 [==============================] - 301s 200ms/step - loss: 0.4841 - accuracy: 0.8382 - val_loss: 0.6279 - val_accuracy: 0.7188\n",
      "Epoch 7/30\n",
      "1503/1503 [==============================] - 301s 200ms/step - loss: 0.3700 - accuracy: 0.8978 - val_loss: 0.1857 - val_accuracy: 0.9688\n",
      "Epoch 8/30\n",
      "1503/1503 [==============================] - 301s 200ms/step - loss: 0.3009 - accuracy: 0.9178 - val_loss: 0.8792 - val_accuracy: 0.7500\n",
      "Epoch 9/30\n",
      "1503/1503 [==============================] - 302s 201ms/step - loss: 0.2647 - accuracy: 0.9276 - val_loss: 0.1343 - val_accuracy: 0.9688\n",
      "Epoch 10/30\n",
      "1503/1503 [==============================] - 301s 200ms/step - loss: 0.2258 - accuracy: 0.9370 - val_loss: 0.2757 - val_accuracy: 0.9375\n",
      "Epoch 11/30\n",
      "1503/1503 [==============================] - 300s 200ms/step - loss: 0.1993 - accuracy: 0.9437 - val_loss: 0.0871 - val_accuracy: 0.9688\n",
      "Epoch 12/30\n",
      "1503/1503 [==============================] - 302s 201ms/step - loss: 0.1797 - accuracy: 0.9499 - val_loss: 0.0906 - val_accuracy: 0.9688\n",
      "Epoch 13/30\n",
      "1503/1503 [==============================] - 301s 200ms/step - loss: 0.1644 - accuracy: 0.9535 - val_loss: 0.0739 - val_accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "1503/1503 [==============================] - 301s 200ms/step - loss: 0.1583 - accuracy: 0.9545 - val_loss: 0.1283 - val_accuracy: 0.9688\n",
      "Epoch 15/30\n",
      "1503/1503 [==============================] - 301s 200ms/step - loss: 0.1463 - accuracy: 0.9583 - val_loss: 0.0524 - val_accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "1503/1503 [==============================] - 302s 201ms/step - loss: 0.1402 - accuracy: 0.9597 - val_loss: 0.0995 - val_accuracy: 0.9688\n",
      "Epoch 17/30\n",
      "1503/1503 [==============================] - 301s 200ms/step - loss: 0.1307 - accuracy: 0.9621 - val_loss: 0.0551 - val_accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "1503/1503 [==============================] - 301s 200ms/step - loss: 0.1233 - accuracy: 0.9640 - val_loss: 0.0541 - val_accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "1503/1503 [==============================] - 300s 200ms/step - loss: 0.1170 - accuracy: 0.9664 - val_loss: 0.0483 - val_accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "1503/1503 [==============================] - 301s 200ms/step - loss: 0.1080 - accuracy: 0.9694 - val_loss: 0.0404 - val_accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "1503/1503 [==============================] - 300s 200ms/step - loss: 0.1045 - accuracy: 0.9700 - val_loss: 0.0386 - val_accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "1503/1503 [==============================] - 301s 200ms/step - loss: 0.0989 - accuracy: 0.9724 - val_loss: 0.0497 - val_accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "1503/1503 [==============================] - 301s 200ms/step - loss: 0.0951 - accuracy: 0.9729 - val_loss: 0.0286 - val_accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "1503/1503 [==============================] - 301s 200ms/step - loss: 0.0904 - accuracy: 0.9741 - val_loss: 0.0310 - val_accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "1503/1503 [==============================] - 301s 200ms/step - loss: 0.0859 - accuracy: 0.9764 - val_loss: 0.0406 - val_accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "1503/1503 [==============================] - 301s 200ms/step - loss: 0.0818 - accuracy: 0.9776 - val_loss: 0.0258 - val_accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "1503/1503 [==============================] - 300s 200ms/step - loss: 0.0795 - accuracy: 0.9779 - val_loss: 0.0305 - val_accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "1503/1503 [==============================] - 301s 200ms/step - loss: 0.0773 - accuracy: 0.9786 - val_loss: 0.0275 - val_accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "1503/1503 [==============================] - 301s 200ms/step - loss: 0.0765 - accuracy: 0.9801 - val_loss: 0.0266 - val_accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "1503/1503 [==============================] - 300s 200ms/step - loss: 0.0721 - accuracy: 0.9810 - val_loss: 0.0314 - val_accuracy: 1.0000\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_75135.6_images_True_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.991736\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [1. 1. 1. 1.]\n",
      "Training octnet for 1.0% of train size (aka 83484 images) with pretrained: False and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 23 trainable: 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "   5/1670 [..............................] - ETA: 14:37 - loss: 5.6042 - accuracy: 0.2873WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0211s vs `on_train_batch_begin` time: 0.2001s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0211s vs `on_train_batch_end` time: 0.1439s). Check your callbacks.\n",
      "1670/1670 [==============================] - 72s 43ms/step - loss: 1.4159 - accuracy: 0.6450 - val_loss: 0.3636 - val_accuracy: 0.8750\n",
      "Epoch 2/30\n",
      "   1/1670 [..............................] - ETA: 1:08 - loss: 0.4747 - accuracy: 0.8000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1670/1670 [==============================] - 69s 41ms/step - loss: 0.4318 - accuracy: 0.8532 - val_loss: 0.2748 - val_accuracy: 0.9062\n",
      "Epoch 3/30\n",
      "1670/1670 [==============================] - 69s 42ms/step - loss: 0.3250 - accuracy: 0.8918 - val_loss: 0.1883 - val_accuracy: 0.9375\n",
      "Epoch 4/30\n",
      "1670/1670 [==============================] - 70s 42ms/step - loss: 0.2729 - accuracy: 0.9089 - val_loss: 0.0619 - val_accuracy: 0.9688\n",
      "Epoch 5/30\n",
      "1670/1670 [==============================] - 69s 41ms/step - loss: 0.2409 - accuracy: 0.9210 - val_loss: 0.0903 - val_accuracy: 0.9688\n",
      "Epoch 6/30\n",
      "1670/1670 [==============================] - 69s 41ms/step - loss: 0.2082 - accuracy: 0.9310 - val_loss: 0.0588 - val_accuracy: 0.9688\n",
      "Epoch 7/30\n",
      "1670/1670 [==============================] - 69s 41ms/step - loss: 0.1851 - accuracy: 0.9391 - val_loss: 0.0145 - val_accuracy: 1.0000\n",
      "Epoch 8/30\n",
      "1670/1670 [==============================] - 69s 42ms/step - loss: 0.1641 - accuracy: 0.9458 - val_loss: 0.0109 - val_accuracy: 1.0000\n",
      "Epoch 9/30\n",
      "1670/1670 [==============================] - 69s 41ms/step - loss: 0.1431 - accuracy: 0.9535 - val_loss: 0.0843 - val_accuracy: 0.9688\n",
      "Epoch 10/30\n",
      "1670/1670 [==============================] - 69s 41ms/step - loss: 0.1305 - accuracy: 0.9577 - val_loss: 0.0646 - val_accuracy: 0.9688\n",
      "Epoch 11/30\n",
      "1670/1670 [==============================] - 70s 42ms/step - loss: 0.1141 - accuracy: 0.9617 - val_loss: 0.1315 - val_accuracy: 0.9688\n",
      "Epoch 12/30\n",
      "1670/1670 [==============================] - 70s 42ms/step - loss: 0.0999 - accuracy: 0.9667 - val_loss: 0.0546 - val_accuracy: 0.9688\n",
      "Epoch 13/30\n",
      "1670/1670 [==============================] - 70s 42ms/step - loss: 0.0859 - accuracy: 0.9708 - val_loss: 0.0190 - val_accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "1670/1670 [==============================] - 69s 42ms/step - loss: 0.0768 - accuracy: 0.9744 - val_loss: 0.0253 - val_accuracy: 0.9688\n",
      "Epoch 15/30\n",
      "1670/1670 [==============================] - 69s 42ms/step - loss: 0.0724 - accuracy: 0.9754 - val_loss: 0.0834 - val_accuracy: 0.9688\n",
      "Epoch 16/30\n",
      "1670/1670 [==============================] - 69s 42ms/step - loss: 0.0662 - accuracy: 0.9778 - val_loss: 0.0321 - val_accuracy: 0.9688\n",
      "Epoch 17/30\n",
      "1670/1670 [==============================] - 69s 41ms/step - loss: 0.0602 - accuracy: 0.9790 - val_loss: 0.0396 - val_accuracy: 0.9688\n",
      "Epoch 18/30\n",
      "1670/1670 [==============================] - 69s 42ms/step - loss: 0.0523 - accuracy: 0.9826 - val_loss: 0.0534 - val_accuracy: 0.9688\n",
      "Epoch 19/30\n",
      "1670/1670 [==============================] - 69s 41ms/step - loss: 0.0493 - accuracy: 0.9833 - val_loss: 0.0278 - val_accuracy: 0.9688\n",
      "Epoch 20/30\n",
      "1670/1670 [==============================] - 69s 42ms/step - loss: 0.0459 - accuracy: 0.9847 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "1670/1670 [==============================] - 70s 42ms/step - loss: 0.0394 - accuracy: 0.9875 - val_loss: 0.1209 - val_accuracy: 0.9688\n",
      "Epoch 22/30\n",
      "1670/1670 [==============================] - 69s 42ms/step - loss: 0.0369 - accuracy: 0.9870 - val_loss: 0.0282 - val_accuracy: 0.9688\n",
      "Epoch 23/30\n",
      "1670/1670 [==============================] - 70s 42ms/step - loss: 0.0358 - accuracy: 0.9882 - val_loss: 9.5298e-04 - val_accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "1670/1670 [==============================] - 69s 42ms/step - loss: 0.0333 - accuracy: 0.9893 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "1670/1670 [==============================] - 69s 41ms/step - loss: 0.0321 - accuracy: 0.9890 - val_loss: 0.0259 - val_accuracy: 0.9688\n",
      "Epoch 26/30\n",
      "1670/1670 [==============================] - 69s 41ms/step - loss: 0.0301 - accuracy: 0.9898 - val_loss: 0.0098 - val_accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "1670/1670 [==============================] - 69s 42ms/step - loss: 0.0271 - accuracy: 0.9908 - val_loss: 0.0068 - val_accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "1670/1670 [==============================] - 69s 41ms/step - loss: 0.0264 - accuracy: 0.9912 - val_loss: 2.3529e-04 - val_accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "1670/1670 [==============================] - 69s 42ms/step - loss: 0.0262 - accuracy: 0.9911 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "1670/1670 [==============================] - 69s 41ms/step - loss: 0.0272 - accuracy: 0.9905 - val_loss: 0.0097 - val_accuracy: 1.0000\n",
      "INFO:tensorflow:Assets written to: ../octnet/octnet_30epochs_83484.0_images_True_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for octnet: 0.985537\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training resnet for 1.0% of train size (aka 83484 images) with pretrained: False and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 178 trainable: 178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "   6/1670 [..............................] - ETA: 18:55 - loss: 1.3757 - accuracy: 0.4387WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1077s vs `on_train_batch_begin` time: 0.1560s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1077s vs `on_train_batch_end` time: 0.3288s). Check your callbacks.\n",
      "1670/1670 [==============================] - 348s 202ms/step - loss: 1.1069 - accuracy: 0.6741 - val_loss: 1.6521 - val_accuracy: 0.4062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "1670/1670 [==============================] - 335s 201ms/step - loss: 0.7722 - accuracy: 0.7372 - val_loss: 0.9058 - val_accuracy: 0.6250\n",
      "Epoch 3/30\n",
      "1670/1670 [==============================] - 335s 200ms/step - loss: 0.6581 - accuracy: 0.7717 - val_loss: 1.0685 - val_accuracy: 0.6250\n",
      "Epoch 4/30\n",
      "1670/1670 [==============================] - 335s 201ms/step - loss: 0.5561 - accuracy: 0.8089 - val_loss: 1.2517 - val_accuracy: 0.5312\n",
      "Epoch 5/30\n",
      "1670/1670 [==============================] - 335s 200ms/step - loss: 0.3987 - accuracy: 0.8724 - val_loss: 0.6401 - val_accuracy: 0.7812\n",
      "Epoch 6/30\n",
      "1670/1670 [==============================] - 335s 200ms/step - loss: 0.3086 - accuracy: 0.9114 - val_loss: 0.4422 - val_accuracy: 0.8750\n",
      "Epoch 7/30\n",
      "1670/1670 [==============================] - 335s 200ms/step - loss: 0.2385 - accuracy: 0.9326 - val_loss: 1.0895 - val_accuracy: 0.6875\n",
      "Epoch 8/30\n",
      "1670/1670 [==============================] - 335s 201ms/step - loss: 0.2042 - accuracy: 0.9406 - val_loss: 0.4540 - val_accuracy: 0.7812\n",
      "Epoch 9/30\n",
      "1670/1670 [==============================] - 335s 200ms/step - loss: 0.1779 - accuracy: 0.9476 - val_loss: 0.9539 - val_accuracy: 0.6875\n",
      "Epoch 10/30\n",
      "1670/1670 [==============================] - 334s 200ms/step - loss: 0.1550 - accuracy: 0.9541 - val_loss: 0.1175 - val_accuracy: 0.9375\n",
      "Epoch 11/30\n",
      "1670/1670 [==============================] - 335s 201ms/step - loss: 0.1436 - accuracy: 0.9566 - val_loss: 0.0718 - val_accuracy: 0.9688\n",
      "Epoch 12/30\n",
      "1670/1670 [==============================] - 335s 200ms/step - loss: 0.1330 - accuracy: 0.9596 - val_loss: 0.0271 - val_accuracy: 1.0000\n",
      "Epoch 13/30\n",
      "1670/1670 [==============================] - 335s 200ms/step - loss: 0.1222 - accuracy: 0.9632 - val_loss: 0.0295 - val_accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "1670/1670 [==============================] - 335s 200ms/step - loss: 0.1136 - accuracy: 0.9658 - val_loss: 0.0274 - val_accuracy: 1.0000\n",
      "Epoch 15/30\n",
      "1670/1670 [==============================] - 335s 201ms/step - loss: 0.1043 - accuracy: 0.9690 - val_loss: 0.5741 - val_accuracy: 0.7812\n",
      "Epoch 16/30\n",
      "1670/1670 [==============================] - 334s 200ms/step - loss: 0.0987 - accuracy: 0.9709 - val_loss: 0.0258 - val_accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "1670/1670 [==============================] - 334s 200ms/step - loss: 0.0937 - accuracy: 0.9723 - val_loss: 0.0273 - val_accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "1670/1670 [==============================] - 334s 200ms/step - loss: 0.0835 - accuracy: 0.9756 - val_loss: 0.0245 - val_accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "1670/1670 [==============================] - 334s 200ms/step - loss: 0.0803 - accuracy: 0.9761 - val_loss: 0.0163 - val_accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "1670/1670 [==============================] - 334s 200ms/step - loss: 0.0749 - accuracy: 0.9784 - val_loss: 0.0256 - val_accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "1670/1670 [==============================] - 334s 200ms/step - loss: 0.0682 - accuracy: 0.9804 - val_loss: 0.0190 - val_accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "1670/1670 [==============================] - 334s 200ms/step - loss: 0.0619 - accuracy: 0.9827 - val_loss: 0.0137 - val_accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "1670/1670 [==============================] - 334s 200ms/step - loss: 0.0610 - accuracy: 0.9833 - val_loss: 0.0123 - val_accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "1670/1670 [==============================] - 334s 200ms/step - loss: 0.0575 - accuracy: 0.9844 - val_loss: 0.0170 - val_accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "1670/1670 [==============================] - 334s 200ms/step - loss: 0.0544 - accuracy: 0.9852 - val_loss: 0.0112 - val_accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "1670/1670 [==============================] - 334s 200ms/step - loss: 0.0511 - accuracy: 0.9859 - val_loss: 0.0110 - val_accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "1670/1670 [==============================] - 334s 200ms/step - loss: 0.0534 - accuracy: 0.9854 - val_loss: 0.0100 - val_accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "1670/1670 [==============================] - 334s 200ms/step - loss: 0.0475 - accuracy: 0.9880 - val_loss: 0.0099 - val_accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "1670/1670 [==============================] - 334s 200ms/step - loss: 0.0458 - accuracy: 0.9878 - val_loss: 0.0095 - val_accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "1670/1670 [==============================] - 333s 200ms/step - loss: 0.0402 - accuracy: 0.9898 - val_loss: 0.0092 - val_accuracy: 1.0000\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_83484.0_images_True_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.991736\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.0100703  0.01042871 0.00845964 0.00986537]\n",
      "Training octnet for 0.01% of train size (aka 834 images) with pretrained: True and onlyLastLayersTrained: True...\n",
      "\n",
      "Total: 23 trainable: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      " 3/17 [====>.........................] - ETA: 10s - loss: 2129477504.0000 - accuracy: 0.1622WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0134s vs `on_train_batch_begin` time: 0.1349s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0134s vs `on_train_batch_end` time: 0.1044s). Check your callbacks.\n",
      "17/17 [==============================] - 3s 129ms/step - loss: 2062998165.3333 - accuracy: 0.1642 - val_loss: 994279488.0000 - val_accuracy: 0.2500\n",
      "Epoch 2/30\n",
      " 5/17 [=======>......................] - ETA: 0s - loss: 1921956352.0000 - accuracy: 0.1832"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 16ms/step - loss: 1982422968.8889 - accuracy: 0.1726 - val_loss: 994279488.0000 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 1954989269.3333 - accuracy: 0.1860 - val_loss: 994279488.0000 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "17/17 [==============================] - 0s 15ms/step - loss: 1969465614.2222 - accuracy: 0.1872 - val_loss: 994279488.0000 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 1971984526.2222 - accuracy: 0.1828 - val_loss: 994279488.0000 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "17/17 [==============================] - 0s 15ms/step - loss: 1936414549.3333 - accuracy: 0.1601 - val_loss: 994279488.0000 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "17/17 [==============================] - 0s 15ms/step - loss: 2015847018.6667 - accuracy: 0.1668 - val_loss: 994279488.0000 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "17/17 [==============================] - 0s 15ms/step - loss: 1838373518.2222 - accuracy: 0.1928 - val_loss: 994279488.0000 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "17/17 [==============================] - 0s 14ms/step - loss: 1959299057.7778 - accuracy: 0.1700 - val_loss: 994279488.0000 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 2042953066.6667 - accuracy: 0.1668 - val_loss: 994279488.0000 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "17/17 [==============================] - 0s 15ms/step - loss: 1888741774.2222 - accuracy: 0.2128 - val_loss: 994279488.0000 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "17/17 [==============================] - 0s 15ms/step - loss: 2007537941.3333 - accuracy: 0.1697 - val_loss: 994279488.0000 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "17/17 [==============================] - 0s 15ms/step - loss: 1865363292.4444 - accuracy: 0.1840 - val_loss: 994279488.0000 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 1932892686.2222 - accuracy: 0.1747 - val_loss: 994279488.0000 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "17/17 [==============================] - 0s 15ms/step - loss: 2072568917.3333 - accuracy: 0.1662 - val_loss: 994279488.0000 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "17/17 [==============================] - 0s 15ms/step - loss: 1919804828.4444 - accuracy: 0.1778 - val_loss: 994279488.0000 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 2035921607.1111 - accuracy: 0.2047 - val_loss: 994279488.0000 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "17/17 [==============================] - 0s 15ms/step - loss: 1967673841.7778 - accuracy: 0.1824 - val_loss: 994279488.0000 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 1931671025.7778 - accuracy: 0.1802 - val_loss: 994279488.0000 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "17/17 [==============================] - 0s 15ms/step - loss: 1990091719.1111 - accuracy: 0.1703 - val_loss: 994279488.0000 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "17/17 [==============================] - 0s 15ms/step - loss: 2012375772.4444 - accuracy: 0.1901 - val_loss: 994279488.0000 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "17/17 [==============================] - 0s 15ms/step - loss: 1939039687.1111 - accuracy: 0.2176 - val_loss: 994279488.0000 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "17/17 [==============================] - 0s 15ms/step - loss: 1946510357.3333 - accuracy: 0.2144 - val_loss: 994279488.0000 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "17/17 [==============================] - 0s 15ms/step - loss: 2020367068.4444 - accuracy: 0.1787 - val_loss: 994279488.0000 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "17/17 [==============================] - 0s 15ms/step - loss: 1928477134.2222 - accuracy: 0.1666 - val_loss: 994279488.0000 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "17/17 [==============================] - 0s 15ms/step - loss: 2022167950.2222 - accuracy: 0.1942 - val_loss: 994279488.0000 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "17/17 [==============================] - 0s 15ms/step - loss: 1962573952.0000 - accuracy: 0.1671 - val_loss: 994279488.0000 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "17/17 [==============================] - 0s 15ms/step - loss: 1948325781.3333 - accuracy: 0.1805 - val_loss: 994279488.0000 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "17/17 [==============================] - 0s 15ms/step - loss: 1930849201.7778 - accuracy: 0.1970 - val_loss: 994279488.0000 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "17/17 [==============================] - 0s 15ms/step - loss: 1923785422.2222 - accuracy: 0.1851 - val_loss: 994279488.0000 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../octnet/octnet_30epochs_834.84_images_False_newWeights_True_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for octnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training resnet for 0.01% of train size (aka 834 images) with pretrained: True and onlyLastLayersTrained: True...\n",
      "\n",
      "Total: 178 trainable: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      " 6/17 [=========>....................] - ETA: 3s - loss: 1.3884 - accuracy: 0.1521WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0605s vs `on_train_batch_begin` time: 0.1350s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0605s vs `on_train_batch_end` time: 0.1104s). Check your callbacks.\n",
      "17/17 [==============================] - 8s 240ms/step - loss: 1.3881 - accuracy: 0.1633 - val_loss: 1.3796 - val_accuracy: 0.4688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.3892 - accuracy: 0.1696 - val_loss: 1.3796 - val_accuracy: 0.4688\n",
      "Epoch 3/30\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.3884 - accuracy: 0.1777 - val_loss: 1.3796 - val_accuracy: 0.4688\n",
      "Epoch 4/30\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.3887 - accuracy: 0.1766 - val_loss: 1.3796 - val_accuracy: 0.4688\n",
      "Epoch 5/30\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.3881 - accuracy: 0.1610 - val_loss: 1.3796 - val_accuracy: 0.4688\n",
      "Epoch 6/30\n",
      "17/17 [==============================] - 1s 59ms/step - loss: 1.3877 - accuracy: 0.1692 - val_loss: 1.3796 - val_accuracy: 0.4688\n",
      "Epoch 7/30\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.3892 - accuracy: 0.1723 - val_loss: 1.3796 - val_accuracy: 0.4688\n",
      "Epoch 8/30\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.3884 - accuracy: 0.1611 - val_loss: 1.3796 - val_accuracy: 0.4688\n",
      "Epoch 9/30\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.3879 - accuracy: 0.1883 - val_loss: 1.3796 - val_accuracy: 0.4688\n",
      "Epoch 10/30\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.3887 - accuracy: 0.1642 - val_loss: 1.3796 - val_accuracy: 0.4688\n",
      "Epoch 11/30\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.3882 - accuracy: 0.1673 - val_loss: 1.3796 - val_accuracy: 0.4688\n",
      "Epoch 12/30\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.3879 - accuracy: 0.1829 - val_loss: 1.3796 - val_accuracy: 0.4688\n",
      "Epoch 13/30\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.3887 - accuracy: 0.1729 - val_loss: 1.3796 - val_accuracy: 0.4688\n",
      "Epoch 14/30\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.3889 - accuracy: 0.1633 - val_loss: 1.3796 - val_accuracy: 0.4688\n",
      "Epoch 15/30\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.3877 - accuracy: 0.1832 - val_loss: 1.3796 - val_accuracy: 0.4688\n",
      "Epoch 16/30\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.3883 - accuracy: 0.1730 - val_loss: 1.3796 - val_accuracy: 0.4688\n",
      "Epoch 17/30\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.3888 - accuracy: 0.1672 - val_loss: 1.3796 - val_accuracy: 0.4688\n",
      "Epoch 18/30\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.3880 - accuracy: 0.1763 - val_loss: 1.3796 - val_accuracy: 0.4688\n",
      "Epoch 19/30\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.3883 - accuracy: 0.1567 - val_loss: 1.3796 - val_accuracy: 0.4688\n",
      "Epoch 20/30\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.3880 - accuracy: 0.1727 - val_loss: 1.3796 - val_accuracy: 0.4688\n",
      "Epoch 21/30\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.3877 - accuracy: 0.1896 - val_loss: 1.3796 - val_accuracy: 0.4688\n",
      "Epoch 22/30\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.3877 - accuracy: 0.1787 - val_loss: 1.3796 - val_accuracy: 0.4688\n",
      "Epoch 23/30\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.3888 - accuracy: 0.1575 - val_loss: 1.3796 - val_accuracy: 0.4688\n",
      "Epoch 24/30\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.3884 - accuracy: 0.1948 - val_loss: 1.3796 - val_accuracy: 0.4688\n",
      "Epoch 25/30\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.3881 - accuracy: 0.1791 - val_loss: 1.3796 - val_accuracy: 0.4688\n",
      "Epoch 26/30\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.3882 - accuracy: 0.1751 - val_loss: 1.3796 - val_accuracy: 0.4688\n",
      "Epoch 27/30\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.3889 - accuracy: 0.1548 - val_loss: 1.3796 - val_accuracy: 0.4688\n",
      "Epoch 28/30\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.3882 - accuracy: 0.1669 - val_loss: 1.3796 - val_accuracy: 0.4688\n",
      "Epoch 29/30\n",
      "17/17 [==============================] - 1s 59ms/step - loss: 1.3886 - accuracy: 0.1555 - val_loss: 1.3796 - val_accuracy: 0.4688\n",
      "Epoch 30/30\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.3887 - accuracy: 0.1628 - val_loss: 1.3796 - val_accuracy: 0.4688\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_834.84_images_False_newWeights_True_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.269628\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.02496675 0.02607176 0.02264716 0.02356082]\n",
      "Training octnet for 0.025% of train size (aka 2087 images) with pretrained: True and onlyLastLayersTrained: True...\n",
      "\n",
      "Total: 23 trainable: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      " 3/42 [=>............................] - ETA: 28s - loss: 1731979093.3333 - accuracy: 0.1978WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0135s vs `on_train_batch_begin` time: 0.1356s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0135s vs `on_train_batch_end` time: 0.1025s). Check your callbacks.\n",
      "42/42 [==============================] - 3s 57ms/step - loss: 1760005596.2791 - accuracy: 0.2263 - val_loss: 667604288.0000 - val_accuracy: 0.2500\n",
      "Epoch 2/30\n",
      " 6/42 [===>..........................] - ETA: 0s - loss: 1763497066.6667 - accuracy: 0.2002"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 1s 14ms/step - loss: 1794342724.4651 - accuracy: 0.2222 - val_loss: 667604288.0000 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 1785504226.2326 - accuracy: 0.2289 - val_loss: 667604288.0000 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 1803447147.1628 - accuracy: 0.2264 - val_loss: 667604288.0000 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 1716726328.5581 - accuracy: 0.2309 - val_loss: 667604288.0000 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 1726076055.8140 - accuracy: 0.2207 - val_loss: 667604288.0000 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 1712017574.6977 - accuracy: 0.2488 - val_loss: 667604288.0000 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 1748171659.9070 - accuracy: 0.2216 - val_loss: 667604288.0000 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 1776191008.7442 - accuracy: 0.2249 - val_loss: 667604288.0000 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 1836668847.6279 - accuracy: 0.2237 - val_loss: 667604288.0000 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 1771621843.3488 - accuracy: 0.2315 - val_loss: 667604288.0000 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 1786805405.7674 - accuracy: 0.2305 - val_loss: 667604288.0000 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 1799300676.4651 - accuracy: 0.2186 - val_loss: 667604288.0000 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 1722196658.6047 - accuracy: 0.2226 - val_loss: 667604288.0000 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 1718019750.6977 - accuracy: 0.2295 - val_loss: 667604288.0000 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 1832391135.2558 - accuracy: 0.2391 - val_loss: 667604288.0000 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 1745099219.3488 - accuracy: 0.2252 - val_loss: 667604288.0000 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 1777666360.5581 - accuracy: 0.2324 - val_loss: 667604288.0000 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 1714279858.6047 - accuracy: 0.2296 - val_loss: 667604288.0000 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 1704775165.0233 - accuracy: 0.2413 - val_loss: 667604288.0000 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 1783864483.7209 - accuracy: 0.2057 - val_loss: 667604288.0000 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 1720106457.3023 - accuracy: 0.2156 - val_loss: 667604288.0000 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 1797731289.3023 - accuracy: 0.2331 - val_loss: 667604288.0000 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 1758604975.6279 - accuracy: 0.2144 - val_loss: 667604288.0000 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 1812507570.6047 - accuracy: 0.2196 - val_loss: 667604288.0000 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 1787938530.2326 - accuracy: 0.2246 - val_loss: 667604288.0000 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 1750137531.5349 - accuracy: 0.2108 - val_loss: 667604288.0000 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 1695039874.9767 - accuracy: 0.2196 - val_loss: 667604288.0000 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 1760032345.3023 - accuracy: 0.2351 - val_loss: 667604288.0000 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 1775567261.7674 - accuracy: 0.2407 - val_loss: 667604288.0000 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../octnet/octnet_30epochs_2087.1_images_False_newWeights_True_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for octnet: 0.244835\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training resnet for 0.025% of train size (aka 2087 images) with pretrained: True and onlyLastLayersTrained: True...\n",
      "\n",
      "Total: 178 trainable: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      " 6/42 [===>..........................] - ETA: 13s - loss: 1.3875 - accuracy: 0.1909WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0588s vs `on_train_batch_begin` time: 0.1378s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0588s vs `on_train_batch_end` time: 0.1211s). Check your callbacks.\n",
      "42/42 [==============================] - 10s 136ms/step - loss: 1.3871 - accuracy: 0.2150 - val_loss: 1.3897 - val_accuracy: 0.0625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "42/42 [==============================] - 2s 58ms/step - loss: 1.3872 - accuracy: 0.2098 - val_loss: 1.3897 - val_accuracy: 0.0625\n",
      "Epoch 3/30\n",
      "42/42 [==============================] - 2s 58ms/step - loss: 1.3871 - accuracy: 0.2175 - val_loss: 1.3897 - val_accuracy: 0.0625\n",
      "Epoch 4/30\n",
      "42/42 [==============================] - 2s 58ms/step - loss: 1.3872 - accuracy: 0.2243 - val_loss: 1.3897 - val_accuracy: 0.0625\n",
      "Epoch 5/30\n",
      "42/42 [==============================] - 2s 58ms/step - loss: 1.3872 - accuracy: 0.2179 - val_loss: 1.3897 - val_accuracy: 0.0625\n",
      "Epoch 6/30\n",
      "42/42 [==============================] - 2s 58ms/step - loss: 1.3871 - accuracy: 0.2288 - val_loss: 1.3897 - val_accuracy: 0.0625\n",
      "Epoch 7/30\n",
      "42/42 [==============================] - 2s 58ms/step - loss: 1.3868 - accuracy: 0.2262 - val_loss: 1.3897 - val_accuracy: 0.0625\n",
      "Epoch 8/30\n",
      "42/42 [==============================] - 2s 58ms/step - loss: 1.3877 - accuracy: 0.2135 - val_loss: 1.3897 - val_accuracy: 0.0625\n",
      "Epoch 9/30\n",
      "42/42 [==============================] - 2s 58ms/step - loss: 1.3867 - accuracy: 0.2271 - val_loss: 1.3897 - val_accuracy: 0.0625\n",
      "Epoch 10/30\n",
      "42/42 [==============================] - 2s 59ms/step - loss: 1.3870 - accuracy: 0.2173 - val_loss: 1.3897 - val_accuracy: 0.0625\n",
      "Epoch 11/30\n",
      "42/42 [==============================] - 2s 59ms/step - loss: 1.3873 - accuracy: 0.2285 - val_loss: 1.3897 - val_accuracy: 0.0625\n",
      "Epoch 12/30\n",
      "42/42 [==============================] - 2s 59ms/step - loss: 1.3872 - accuracy: 0.2232 - val_loss: 1.3897 - val_accuracy: 0.0625\n",
      "Epoch 13/30\n",
      "42/42 [==============================] - 2s 58ms/step - loss: 1.3872 - accuracy: 0.2268 - val_loss: 1.3897 - val_accuracy: 0.0625\n",
      "Epoch 14/30\n",
      "42/42 [==============================] - 2s 58ms/step - loss: 1.3868 - accuracy: 0.2305 - val_loss: 1.3897 - val_accuracy: 0.0625\n",
      "Epoch 15/30\n",
      "42/42 [==============================] - 2s 58ms/step - loss: 1.3873 - accuracy: 0.2230 - val_loss: 1.3897 - val_accuracy: 0.0625\n",
      "Epoch 16/30\n",
      "42/42 [==============================] - 2s 58ms/step - loss: 1.3870 - accuracy: 0.2254 - val_loss: 1.3897 - val_accuracy: 0.0625\n",
      "Epoch 17/30\n",
      "42/42 [==============================] - 2s 58ms/step - loss: 1.3874 - accuracy: 0.2111 - val_loss: 1.3897 - val_accuracy: 0.0625\n",
      "Epoch 18/30\n",
      "42/42 [==============================] - 2s 58ms/step - loss: 1.3872 - accuracy: 0.2207 - val_loss: 1.3897 - val_accuracy: 0.0625\n",
      "Epoch 19/30\n",
      "42/42 [==============================] - 2s 58ms/step - loss: 1.3871 - accuracy: 0.2299 - val_loss: 1.3897 - val_accuracy: 0.0625\n",
      "Epoch 20/30\n",
      "42/42 [==============================] - 2s 58ms/step - loss: 1.3871 - accuracy: 0.2035 - val_loss: 1.3897 - val_accuracy: 0.0625\n",
      "Epoch 21/30\n",
      "42/42 [==============================] - 2s 58ms/step - loss: 1.3870 - accuracy: 0.2211 - val_loss: 1.3897 - val_accuracy: 0.0625\n",
      "Epoch 22/30\n",
      "42/42 [==============================] - 2s 58ms/step - loss: 1.3869 - accuracy: 0.2244 - val_loss: 1.3897 - val_accuracy: 0.0625\n",
      "Epoch 23/30\n",
      "42/42 [==============================] - 2s 58ms/step - loss: 1.3876 - accuracy: 0.2116 - val_loss: 1.3897 - val_accuracy: 0.0625\n",
      "Epoch 24/30\n",
      "42/42 [==============================] - 2s 58ms/step - loss: 1.3871 - accuracy: 0.2217 - val_loss: 1.3897 - val_accuracy: 0.0625\n",
      "Epoch 25/30\n",
      "42/42 [==============================] - 2s 58ms/step - loss: 1.3870 - accuracy: 0.2366 - val_loss: 1.3897 - val_accuracy: 0.0625\n",
      "Epoch 26/30\n",
      "42/42 [==============================] - 2s 58ms/step - loss: 1.3871 - accuracy: 0.2263 - val_loss: 1.3897 - val_accuracy: 0.0625\n",
      "Epoch 27/30\n",
      "42/42 [==============================] - 2s 59ms/step - loss: 1.3877 - accuracy: 0.2161 - val_loss: 1.3897 - val_accuracy: 0.0625\n",
      "Epoch 28/30\n",
      "42/42 [==============================] - 2s 58ms/step - loss: 1.3874 - accuracy: 0.2198 - val_loss: 1.3897 - val_accuracy: 0.0625\n",
      "Epoch 29/30\n",
      "42/42 [==============================] - 2s 58ms/step - loss: 1.3873 - accuracy: 0.2055 - val_loss: 1.3897 - val_accuracy: 0.0625\n",
      "Epoch 30/30\n",
      "42/42 [==============================] - 2s 58ms/step - loss: 1.3875 - accuracy: 0.2066 - val_loss: 1.3897 - val_accuracy: 0.0625\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_2087.1_images_False_newWeights_True_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.208678\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.05050352 0.04929445 0.05137469 0.04967502]\n",
      "Training octnet for 0.05% of train size (aka 4174 images) with pretrained: True and onlyLastLayersTrained: True...\n",
      "\n",
      "Total: 23 trainable: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      " 3/84 [>.............................] - ETA: 58s - loss: 1441626282.6667 - accuracy: 0.2467 WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0131s vs `on_train_batch_begin` time: 0.1348s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0131s vs `on_train_batch_end` time: 0.1013s). Check your callbacks.\n",
      "84/84 [==============================] - 4s 34ms/step - loss: 1336120188.9882 - accuracy: 0.2935 - val_loss: 640893760.0000 - val_accuracy: 0.2500\n",
      "Epoch 2/30\n",
      " 6/84 [=>............................] - ETA: 0s - loss: 1264613013.3333 - accuracy: 0.2867"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84/84 [==============================] - 1s 13ms/step - loss: 1289789105.6941 - accuracy: 0.3008 - val_loss: 640893760.0000 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 1345647634.0706 - accuracy: 0.2962 - val_loss: 640893760.0000 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 1324680166.4000 - accuracy: 0.2865 - val_loss: 640893760.0000 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "84/84 [==============================] - 1s 12ms/step - loss: 1335015061.0824 - accuracy: 0.2848 - val_loss: 640893760.0000 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 1305946467.3882 - accuracy: 0.2971 - val_loss: 640893760.0000 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 1266274859.6706 - accuracy: 0.3090 - val_loss: 640893760.0000 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 1337633755.8588 - accuracy: 0.3119 - val_loss: 640893760.0000 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "84/84 [==============================] - 1s 12ms/step - loss: 1297832130.2588 - accuracy: 0.2967 - val_loss: 640893760.0000 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "84/84 [==============================] - 1s 12ms/step - loss: 1311449356.0471 - accuracy: 0.3011 - val_loss: 640893760.0000 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "84/84 [==============================] - 5s 60ms/step - loss: 1324272088.8471 - accuracy: 0.2988 - val_loss: 640893760.0000 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "84/84 [==============================] - 5s 54ms/step - loss: 1354607759.0588 - accuracy: 0.2865 - val_loss: 640893760.0000 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "84/84 [==============================] - 4s 53ms/step - loss: 1300860334.6824 - accuracy: 0.3025 - val_loss: 640893760.0000 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "84/84 [==============================] - 4s 53ms/step - loss: 1306672443.4824 - accuracy: 0.2891 - val_loss: 640893760.0000 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "84/84 [==============================] - 4s 43ms/step - loss: 1353657575.9059 - accuracy: 0.2937 - val_loss: 640893760.0000 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "84/84 [==============================] - 5s 55ms/step - loss: 1379619504.1882 - accuracy: 0.2831 - val_loss: 640893760.0000 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "84/84 [==============================] - 4s 48ms/step - loss: 1368214562.6353 - accuracy: 0.2921 - val_loss: 640893760.0000 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "84/84 [==============================] - 4s 50ms/step - loss: 1361564786.4471 - accuracy: 0.2818 - val_loss: 640893760.0000 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "84/84 [==============================] - 4s 49ms/step - loss: 1305936772.5176 - accuracy: 0.2919 - val_loss: 640893760.0000 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "84/84 [==============================] - 4s 48ms/step - loss: 1354367391.6235 - accuracy: 0.2847 - val_loss: 640893760.0000 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "84/84 [==============================] - 5s 54ms/step - loss: 1301709913.6000 - accuracy: 0.2936 - val_loss: 640893760.0000 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "84/84 [==============================] - 4s 49ms/step - loss: 1313520683.6706 - accuracy: 0.2991 - val_loss: 640893760.0000 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "84/84 [==============================] - 4s 53ms/step - loss: 1320518412.0471 - accuracy: 0.2927 - val_loss: 640893760.0000 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "84/84 [==============================] - 4s 52ms/step - loss: 1342771763.2000 - accuracy: 0.2866 - val_loss: 640893760.0000 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "84/84 [==============================] - 4s 46ms/step - loss: 1343307974.7765 - accuracy: 0.2983 - val_loss: 640893760.0000 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "84/84 [==============================] - 4s 51ms/step - loss: 1327238597.2706 - accuracy: 0.2878 - val_loss: 640893760.0000 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "84/84 [==============================] - 5s 60ms/step - loss: 1342289423.0588 - accuracy: 0.2791 - val_loss: 640893760.0000 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "84/84 [==============================] - 5s 55ms/step - loss: 1317317290.1647 - accuracy: 0.3142 - val_loss: 640893760.0000 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "84/84 [==============================] - 4s 53ms/step - loss: 1330992640.0000 - accuracy: 0.2863 - val_loss: 640893760.0000 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "84/84 [==============================] - 4s 46ms/step - loss: 1313748972.4235 - accuracy: 0.2984 - val_loss: 640893760.0000 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../octnet/octnet_30epochs_4174.2_images_False_newWeights_True_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for octnet: 0.271694\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training resnet for 0.05% of train size (aka 4174 images) with pretrained: True and onlyLastLayersTrained: True...\n",
      "\n",
      "Total: 178 trainable: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      " 6/84 [=>............................] - ETA: 46s - loss: 1.3815 - accuracy: 0.3275WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0835s vs `on_train_batch_begin` time: 0.1882s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0835s vs `on_train_batch_end` time: 0.2453s). Check your callbacks.\n",
      "84/84 [==============================] - 19s 142ms/step - loss: 1.3832 - accuracy: 0.3083 - val_loss: 1.3844 - val_accuracy: 0.2812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "84/84 [==============================] - 7s 89ms/step - loss: 1.3831 - accuracy: 0.3054 - val_loss: 1.3844 - val_accuracy: 0.2812\n",
      "Epoch 3/30\n",
      "84/84 [==============================] - 7s 87ms/step - loss: 1.3833 - accuracy: 0.3006 - val_loss: 1.3844 - val_accuracy: 0.2812\n",
      "Epoch 4/30\n",
      "84/84 [==============================] - 8s 95ms/step - loss: 1.3830 - accuracy: 0.3009 - val_loss: 1.3844 - val_accuracy: 0.2812\n",
      "Epoch 5/30\n",
      "84/84 [==============================] - 7s 88ms/step - loss: 1.3829 - accuracy: 0.3090 - val_loss: 1.3844 - val_accuracy: 0.2812\n",
      "Epoch 6/30\n",
      "84/84 [==============================] - 7s 89ms/step - loss: 1.3827 - accuracy: 0.3102 - val_loss: 1.3844 - val_accuracy: 0.2812\n",
      "Epoch 7/30\n",
      "84/84 [==============================] - 8s 91ms/step - loss: 1.3828 - accuracy: 0.3161 - val_loss: 1.3844 - val_accuracy: 0.2812\n",
      "Epoch 8/30\n",
      "84/84 [==============================] - 8s 89ms/step - loss: 1.3832 - accuracy: 0.3077 - val_loss: 1.3844 - val_accuracy: 0.2812\n",
      "Epoch 9/30\n",
      "84/84 [==============================] - 8s 90ms/step - loss: 1.3836 - accuracy: 0.2952 - val_loss: 1.3844 - val_accuracy: 0.2812\n",
      "Epoch 10/30\n",
      "84/84 [==============================] - 7s 84ms/step - loss: 1.3835 - accuracy: 0.2982 - val_loss: 1.3844 - val_accuracy: 0.2812\n",
      "Epoch 11/30\n",
      "84/84 [==============================] - 7s 86ms/step - loss: 1.3833 - accuracy: 0.3097 - val_loss: 1.3844 - val_accuracy: 0.2812\n",
      "Epoch 12/30\n",
      "84/84 [==============================] - 8s 89ms/step - loss: 1.3832 - accuracy: 0.3003 - val_loss: 1.3844 - val_accuracy: 0.2812\n",
      "Epoch 13/30\n",
      "84/84 [==============================] - 7s 88ms/step - loss: 1.3831 - accuracy: 0.3001 - val_loss: 1.3844 - val_accuracy: 0.2812\n",
      "Epoch 14/30\n",
      "84/84 [==============================] - 7s 86ms/step - loss: 1.3828 - accuracy: 0.3072 - val_loss: 1.3844 - val_accuracy: 0.2812\n",
      "Epoch 15/30\n",
      "84/84 [==============================] - 7s 88ms/step - loss: 1.3833 - accuracy: 0.3095 - val_loss: 1.3844 - val_accuracy: 0.2812\n",
      "Epoch 16/30\n",
      "84/84 [==============================] - 7s 87ms/step - loss: 1.3835 - accuracy: 0.2961 - val_loss: 1.3844 - val_accuracy: 0.2812\n",
      "Epoch 17/30\n",
      "84/84 [==============================] - 8s 92ms/step - loss: 1.3829 - accuracy: 0.3119 - val_loss: 1.3844 - val_accuracy: 0.2812\n",
      "Epoch 18/30\n",
      "84/84 [==============================] - 7s 88ms/step - loss: 1.3833 - accuracy: 0.3092 - val_loss: 1.3844 - val_accuracy: 0.2812\n",
      "Epoch 19/30\n",
      "84/84 [==============================] - 7s 84ms/step - loss: 1.3828 - accuracy: 0.3147 - val_loss: 1.3844 - val_accuracy: 0.2812\n",
      "Epoch 20/30\n",
      "84/84 [==============================] - 7s 85ms/step - loss: 1.3834 - accuracy: 0.2962 - val_loss: 1.3844 - val_accuracy: 0.2812\n",
      "Epoch 21/30\n",
      "84/84 [==============================] - 7s 85ms/step - loss: 1.3826 - accuracy: 0.3184 - val_loss: 1.3844 - val_accuracy: 0.2812\n",
      "Epoch 22/30\n",
      "84/84 [==============================] - 7s 84ms/step - loss: 1.3832 - accuracy: 0.3031 - val_loss: 1.3844 - val_accuracy: 0.2812\n",
      "Epoch 23/30\n",
      "84/84 [==============================] - 7s 84ms/step - loss: 1.3828 - accuracy: 0.3122 - val_loss: 1.3844 - val_accuracy: 0.2812\n",
      "Epoch 24/30\n",
      "84/84 [==============================] - 7s 86ms/step - loss: 1.3829 - accuracy: 0.3008 - val_loss: 1.3844 - val_accuracy: 0.2812\n",
      "Epoch 25/30\n",
      "84/84 [==============================] - 7s 87ms/step - loss: 1.3830 - accuracy: 0.3136 - val_loss: 1.3844 - val_accuracy: 0.2812\n",
      "Epoch 26/30\n",
      "84/84 [==============================] - 7s 86ms/step - loss: 1.3826 - accuracy: 0.3112 - val_loss: 1.3844 - val_accuracy: 0.2812\n",
      "Epoch 27/30\n",
      "84/84 [==============================] - 8s 90ms/step - loss: 1.3836 - accuracy: 0.2936 - val_loss: 1.3844 - val_accuracy: 0.2812\n",
      "Epoch 28/30\n",
      "84/84 [==============================] - 8s 90ms/step - loss: 1.3836 - accuracy: 0.3049 - val_loss: 1.3844 - val_accuracy: 0.2812\n",
      "Epoch 29/30\n",
      "84/84 [==============================] - 8s 92ms/step - loss: 1.3832 - accuracy: 0.3068 - val_loss: 1.3844 - val_accuracy: 0.2812\n",
      "Epoch 30/30\n",
      "84/84 [==============================] - 7s 88ms/step - loss: 1.3831 - accuracy: 0.3061 - val_loss: 1.3844 - val_accuracy: 0.2812\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_4174.2_images_False_newWeights_True_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.211777\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.07573627 0.07464051 0.07543179 0.07370009]\n",
      "Training octnet for 0.075% of train size (aka 6261 images) with pretrained: True and onlyLastLayersTrained: True...\n",
      "\n",
      "Total: 23 trainable: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/126 [>.............................] - ETA: 49s - loss: 2384753749.3333 - accuracy: 0.2079 WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0388s vs `on_train_batch_begin` time: 0.1475s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0388s vs `on_train_batch_end` time: 0.1727s). Check your callbacks.\n",
      "126/126 [==============================] - 6s 39ms/step - loss: 2336127778.2677 - accuracy: 0.2276 - val_loss: 462396992.0000 - val_accuracy: 0.1562\n",
      "Epoch 2/30\n",
      "  2/126 [..............................] - ETA: 6s - loss: 2126797824.0000 - accuracy: 0.2700"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126/126 [==============================] - 5s 42ms/step - loss: 2307295213.8583 - accuracy: 0.2407 - val_loss: 462396992.0000 - val_accuracy: 0.1562\n",
      "Epoch 3/30\n",
      "126/126 [==============================] - 4s 29ms/step - loss: 2351883435.3386 - accuracy: 0.2224 - val_loss: 462396992.0000 - val_accuracy: 0.1562\n",
      "Epoch 4/30\n",
      "126/126 [==============================] - 5s 43ms/step - loss: 2298547534.6142 - accuracy: 0.2377 - val_loss: 462396992.0000 - val_accuracy: 0.1562\n",
      "Epoch 5/30\n",
      "126/126 [==============================] - 5s 43ms/step - loss: 2311935860.9134 - accuracy: 0.2295 - val_loss: 462396992.0000 - val_accuracy: 0.1562\n",
      "Epoch 6/30\n",
      "126/126 [==============================] - 4s 31ms/step - loss: 2327725626.4567 - accuracy: 0.2289 - val_loss: 462396992.0000 - val_accuracy: 0.1562\n",
      "Epoch 7/30\n",
      "126/126 [==============================] - 4s 34ms/step - loss: 2300525860.2835 - accuracy: 0.2302 - val_loss: 462396992.0000 - val_accuracy: 0.1562\n",
      "Epoch 8/30\n",
      "126/126 [==============================] - 3s 24ms/step - loss: 2402580038.5512 - accuracy: 0.2240 - val_loss: 462396992.0000 - val_accuracy: 0.1562\n",
      "Epoch 9/30\n",
      "126/126 [==============================] - 7s 56ms/step - loss: 2340726080.5039 - accuracy: 0.2423 - val_loss: 462396992.0000 - val_accuracy: 0.1562\n",
      "Epoch 10/30\n",
      "126/126 [==============================] - 6s 50ms/step - loss: 2280982088.5669 - accuracy: 0.2333 - val_loss: 462396992.0000 - val_accuracy: 0.1562\n",
      "Epoch 11/30\n",
      "126/126 [==============================] - 6s 47ms/step - loss: 2289609653.4173 - accuracy: 0.2253 - val_loss: 462396992.0000 - val_accuracy: 0.1562\n",
      "Epoch 12/30\n",
      "126/126 [==============================] - 7s 55ms/step - loss: 2345225369.1969 - accuracy: 0.2285 - val_loss: 462396992.0000 - val_accuracy: 0.1562\n",
      "Epoch 13/30\n",
      "126/126 [==============================] - 6s 51ms/step - loss: 2355350687.2441 - accuracy: 0.2193 - val_loss: 462396992.0000 - val_accuracy: 0.1562\n",
      "Epoch 14/30\n",
      "126/126 [==============================] - 6s 45ms/step - loss: 2305808736.7559 - accuracy: 0.2332 - val_loss: 462396992.0000 - val_accuracy: 0.1562\n",
      "Epoch 15/30\n",
      "126/126 [==============================] - 7s 52ms/step - loss: 2310729746.1417 - accuracy: 0.2279 - val_loss: 462396992.0000 - val_accuracy: 0.1562\n",
      "Epoch 16/30\n",
      "126/126 [==============================] - 7s 52ms/step - loss: 2306761133.3543 - accuracy: 0.2305 - val_loss: 462396992.0000 - val_accuracy: 0.1562\n",
      "Epoch 17/30\n",
      "126/126 [==============================] - 6s 47ms/step - loss: 2260997837.6063 - accuracy: 0.2410 - val_loss: 462396992.0000 - val_accuracy: 0.1562\n",
      "Epoch 18/30\n",
      "126/126 [==============================] - 7s 54ms/step - loss: 2288955574.4252 - accuracy: 0.2211 - val_loss: 462396992.0000 - val_accuracy: 0.1562\n",
      "Epoch 19/30\n",
      "126/126 [==============================] - 6s 49ms/step - loss: 2359324109.6063 - accuracy: 0.2241 - val_loss: 462396992.0000 - val_accuracy: 0.1562\n",
      "Epoch 20/30\n",
      "126/126 [==============================] - 5s 38ms/step - loss: 2414110435.7795 - accuracy: 0.2319 - val_loss: 462396992.0000 - val_accuracy: 0.1562\n",
      "Epoch 21/30\n",
      "126/126 [==============================] - 7s 52ms/step - loss: 2270812678.0472 - accuracy: 0.2417 - val_loss: 462396992.0000 - val_accuracy: 0.1562\n",
      "Epoch 22/30\n",
      "126/126 [==============================] - 8s 61ms/step - loss: 2368876257.7638 - accuracy: 0.2237 - val_loss: 462396992.0000 - val_accuracy: 0.1562\n",
      "Epoch 23/30\n",
      "126/126 [==============================] - 8s 60ms/step - loss: 2339378871.4331 - accuracy: 0.2296 - val_loss: 462396992.0000 - val_accuracy: 0.1562\n",
      "Epoch 24/30\n",
      "126/126 [==============================] - 7s 58ms/step - loss: 2354659049.8268 - accuracy: 0.2341 - val_loss: 462396992.0000 - val_accuracy: 0.1562\n",
      "Epoch 25/30\n",
      "126/126 [==============================] - 6s 48ms/step - loss: 2340028986.4567 - accuracy: 0.2234 - val_loss: 462396992.0000 - val_accuracy: 0.1562\n",
      "Epoch 26/30\n",
      "126/126 [==============================] - 6s 50ms/step - loss: 2385414668.0945 - accuracy: 0.2087 - val_loss: 462396992.0000 - val_accuracy: 0.1562\n",
      "Epoch 27/30\n",
      "126/126 [==============================] - 7s 54ms/step - loss: 2298126542.6142 - accuracy: 0.2240 - val_loss: 462396992.0000 - val_accuracy: 0.1562\n",
      "Epoch 28/30\n",
      "126/126 [==============================] - 6s 49ms/step - loss: 2341408376.9449 - accuracy: 0.2237 - val_loss: 462396992.0000 - val_accuracy: 0.1562\n",
      "Epoch 29/30\n",
      "126/126 [==============================] - 7s 56ms/step - loss: 2304786111.4961 - accuracy: 0.2339 - val_loss: 462396992.0000 - val_accuracy: 0.1562\n",
      "Epoch 30/30\n",
      "126/126 [==============================] - 7s 55ms/step - loss: 2349983804.4724 - accuracy: 0.2310 - val_loss: 462396992.0000 - val_accuracy: 0.1562\n",
      "INFO:tensorflow:Assets written to: ../octnet/octnet_30epochs_6261.3_images_False_newWeights_True_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for octnet: 0.216942\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training resnet for 0.075% of train size (aka 6261 images) with pretrained: True and onlyLastLayersTrained: True...\n",
      "\n",
      "Total: 178 trainable: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/126 [>.............................] - ETA: 1:07 - loss: 1.3894 - accuracy: 0.1473WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0745s vs `on_train_batch_begin` time: 0.2072s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0745s vs `on_train_batch_end` time: 0.2063s). Check your callbacks.\n",
      "126/126 [==============================] - 20s 119ms/step - loss: 1.3892 - accuracy: 0.1688 - val_loss: 1.3842 - val_accuracy: 0.2812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "126/126 [==============================] - 11s 84ms/step - loss: 1.3891 - accuracy: 0.1707 - val_loss: 1.3842 - val_accuracy: 0.2812\n",
      "Epoch 3/30\n",
      "126/126 [==============================] - 11s 85ms/step - loss: 1.3888 - accuracy: 0.1782 - val_loss: 1.3842 - val_accuracy: 0.2812\n",
      "Epoch 4/30\n",
      "126/126 [==============================] - 11s 83ms/step - loss: 1.3892 - accuracy: 0.1702 - val_loss: 1.3842 - val_accuracy: 0.2812\n",
      "Epoch 5/30\n",
      "126/126 [==============================] - 11s 85ms/step - loss: 1.3891 - accuracy: 0.1679 - val_loss: 1.3842 - val_accuracy: 0.2812\n",
      "Epoch 6/30\n",
      "126/126 [==============================] - 11s 85ms/step - loss: 1.3889 - accuracy: 0.1693 - val_loss: 1.3842 - val_accuracy: 0.2812\n",
      "Epoch 7/30\n",
      "126/126 [==============================] - 11s 85ms/step - loss: 1.3892 - accuracy: 0.1611 - val_loss: 1.3842 - val_accuracy: 0.2812\n",
      "Epoch 8/30\n",
      "126/126 [==============================] - 11s 88ms/step - loss: 1.3892 - accuracy: 0.1648 - val_loss: 1.3842 - val_accuracy: 0.2812\n",
      "Epoch 9/30\n",
      "126/126 [==============================] - 11s 83ms/step - loss: 1.3891 - accuracy: 0.1679 - val_loss: 1.3842 - val_accuracy: 0.2812\n",
      "Epoch 10/30\n",
      "126/126 [==============================] - 11s 87ms/step - loss: 1.3890 - accuracy: 0.1731 - val_loss: 1.3842 - val_accuracy: 0.2812\n",
      "Epoch 11/30\n",
      "126/126 [==============================] - 11s 88ms/step - loss: 1.3890 - accuracy: 0.1725 - val_loss: 1.3842 - val_accuracy: 0.2812\n",
      "Epoch 12/30\n",
      "126/126 [==============================] - 11s 86ms/step - loss: 1.3892 - accuracy: 0.1627 - val_loss: 1.3842 - val_accuracy: 0.2812\n",
      "Epoch 13/30\n",
      "126/126 [==============================] - 11s 84ms/step - loss: 1.3893 - accuracy: 0.1692 - val_loss: 1.3842 - val_accuracy: 0.2812\n",
      "Epoch 14/30\n",
      "126/126 [==============================] - 10s 83ms/step - loss: 1.3893 - accuracy: 0.1687 - val_loss: 1.3842 - val_accuracy: 0.2812\n",
      "Epoch 15/30\n",
      "126/126 [==============================] - 11s 89ms/step - loss: 1.3890 - accuracy: 0.1744 - val_loss: 1.3842 - val_accuracy: 0.2812\n",
      "Epoch 16/30\n",
      "126/126 [==============================] - 11s 84ms/step - loss: 1.3892 - accuracy: 0.1731 - val_loss: 1.3842 - val_accuracy: 0.2812\n",
      "Epoch 17/30\n",
      "126/126 [==============================] - 11s 88ms/step - loss: 1.3892 - accuracy: 0.1681 - val_loss: 1.3842 - val_accuracy: 0.2812\n",
      "Epoch 18/30\n",
      "126/126 [==============================] - 11s 86ms/step - loss: 1.3889 - accuracy: 0.1695 - val_loss: 1.3842 - val_accuracy: 0.2812\n",
      "Epoch 19/30\n",
      "126/126 [==============================] - 10s 80ms/step - loss: 1.3890 - accuracy: 0.1813 - val_loss: 1.3842 - val_accuracy: 0.2812\n",
      "Epoch 20/30\n",
      "126/126 [==============================] - 10s 80ms/step - loss: 1.3890 - accuracy: 0.1741 - val_loss: 1.3842 - val_accuracy: 0.2812\n",
      "Epoch 21/30\n",
      "126/126 [==============================] - 11s 86ms/step - loss: 1.3889 - accuracy: 0.1731 - val_loss: 1.3842 - val_accuracy: 0.2812\n",
      "Epoch 22/30\n",
      "126/126 [==============================] - 9s 72ms/step - loss: 1.3885 - accuracy: 0.1782 - val_loss: 1.3842 - val_accuracy: 0.2812\n",
      "Epoch 23/30\n",
      "126/126 [==============================] - 10s 76ms/step - loss: 1.3891 - accuracy: 0.1684 - val_loss: 1.3842 - val_accuracy: 0.2812\n",
      "Epoch 24/30\n",
      "126/126 [==============================] - 12s 92ms/step - loss: 1.3891 - accuracy: 0.1695 - val_loss: 1.3842 - val_accuracy: 0.2812\n",
      "Epoch 25/30\n",
      "126/126 [==============================] - 11s 89ms/step - loss: 1.3891 - accuracy: 0.1658 - val_loss: 1.3842 - val_accuracy: 0.2812\n",
      "Epoch 26/30\n",
      "126/126 [==============================] - 11s 89ms/step - loss: 1.3891 - accuracy: 0.1781 - val_loss: 1.3842 - val_accuracy: 0.2812\n",
      "Epoch 27/30\n",
      "126/126 [==============================] - 11s 90ms/step - loss: 1.3892 - accuracy: 0.1668 - val_loss: 1.3842 - val_accuracy: 0.2812\n",
      "Epoch 28/30\n",
      "126/126 [==============================] - 11s 86ms/step - loss: 1.3895 - accuracy: 0.1665 - val_loss: 1.3842 - val_accuracy: 0.2812\n",
      "Epoch 29/30\n",
      "126/126 [==============================] - 11s 87ms/step - loss: 1.3896 - accuracy: 0.1609 - val_loss: 1.3842 - val_accuracy: 0.2812\n",
      "Epoch 30/30\n",
      "126/126 [==============================] - 10s 80ms/step - loss: 1.3893 - accuracy: 0.1649 - val_loss: 1.3842 - val_accuracy: 0.2812\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_6261.3_images_False_newWeights_True_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.243802\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.09158275 0.08899341 0.08970744 0.08983287]\n",
      "Training octnet for 0.09% of train size (aka 7513 images) with pretrained: True and onlyLastLayersTrained: True...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total: 23 trainable: 0\n",
      "Epoch 1/30\n",
      "  6/151 [>.............................] - ETA: 57s - loss: 2208433877.3333 - accuracy: 0.2476 WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0367s vs `on_train_batch_begin` time: 0.1442s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0367s vs `on_train_batch_end` time: 0.1585s). Check your callbacks.\n",
      "151/151 [==============================] - 11s 68ms/step - loss: 2255549965.4737 - accuracy: 0.2641 - val_loss: 1044312832.0000 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "151/151 [==============================] - 5s 34ms/step - loss: 2292775594.1053 - accuracy: 0.2672 - val_loss: 1044312832.0000 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "151/151 [==============================] - 7s 44ms/step - loss: 2262287526.7368 - accuracy: 0.2594 - val_loss: 1044312832.0000 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "151/151 [==============================] - 3s 18ms/step - loss: 2291919914.1053 - accuracy: 0.2744 - val_loss: 1044312832.0000 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "151/151 [==============================] - 3s 19ms/step - loss: 2221794918.7368 - accuracy: 0.2751 - val_loss: 1044312832.0000 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "151/151 [==============================] - 7s 45ms/step - loss: 2311227055.1579 - accuracy: 0.2641 - val_loss: 1044312832.0000 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "151/151 [==============================] - 3s 19ms/step - loss: 2336864591.1579 - accuracy: 0.2658 - val_loss: 1044312832.0000 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "151/151 [==============================] - 7s 46ms/step - loss: 2317438443.7895 - accuracy: 0.2629 - val_loss: 1044312832.0000 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "151/151 [==============================] - 7s 45ms/step - loss: 2293992465.6842 - accuracy: 0.2610 - val_loss: 1044312832.0000 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "151/151 [==============================] - 8s 54ms/step - loss: 2244892037.0526 - accuracy: 0.2689 - val_loss: 1044312832.0000 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "151/151 [==============================] - 8s 56ms/step - loss: 2296619346.5263 - accuracy: 0.2609 - val_loss: 1044312832.0000 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "151/151 [==============================] - 8s 50ms/step - loss: 2288173717.8947 - accuracy: 0.2611 - val_loss: 1044312832.0000 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "151/151 [==============================] - 9s 56ms/step - loss: 2306915080.4211 - accuracy: 0.2642 - val_loss: 1044312832.0000 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "151/151 [==============================] - 8s 53ms/step - loss: 2283546176.0000 - accuracy: 0.2743 - val_loss: 1044312832.0000 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "151/151 [==============================] - 9s 57ms/step - loss: 2337805180.6316 - accuracy: 0.2662 - val_loss: 1044312832.0000 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "151/151 [==============================] - 9s 57ms/step - loss: 2235016896.0000 - accuracy: 0.2781 - val_loss: 1044312832.0000 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "151/151 [==============================] - 8s 52ms/step - loss: 2208485814.7368 - accuracy: 0.2812 - val_loss: 1044312832.0000 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "151/151 [==============================] - 8s 56ms/step - loss: 2228900874.1053 - accuracy: 0.2711 - val_loss: 1044312832.0000 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "151/151 [==============================] - 9s 63ms/step - loss: 2309668197.0526 - accuracy: 0.2546 - val_loss: 1044312832.0000 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "151/151 [==============================] - 4s 29ms/step - loss: 2273808286.3158 - accuracy: 0.2690 - val_loss: 1044312832.0000 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "151/151 [==============================] - 5s 31ms/step - loss: 2231548220.6316 - accuracy: 0.2722 - val_loss: 1044312832.0000 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "151/151 [==============================] - 7s 46ms/step - loss: 2270458725.8947 - accuracy: 0.2631 - val_loss: 1044312832.0000 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "151/151 [==============================] - 8s 54ms/step - loss: 2260547984.0000 - accuracy: 0.2707 - val_loss: 1044312832.0000 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "151/151 [==============================] - 9s 59ms/step - loss: 2282866447.1579 - accuracy: 0.2654 - val_loss: 1044312832.0000 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "151/151 [==============================] - 7s 50ms/step - loss: 2273955172.2105 - accuracy: 0.2570 - val_loss: 1044312832.0000 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "151/151 [==============================] - 8s 54ms/step - loss: 2276549379.3684 - accuracy: 0.2634 - val_loss: 1044312832.0000 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "151/151 [==============================] - 9s 58ms/step - loss: 2287863939.3684 - accuracy: 0.2677 - val_loss: 1044312832.0000 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "151/151 [==============================] - 9s 59ms/step - loss: 2274203363.3684 - accuracy: 0.2755 - val_loss: 1044312832.0000 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "151/151 [==============================] - 10s 64ms/step - loss: 2274778234.9474 - accuracy: 0.2592 - val_loss: 1044312832.0000 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "151/151 [==============================] - 9s 60ms/step - loss: 2262284867.3684 - accuracy: 0.2751 - val_loss: 1044312832.0000 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../octnet/octnet_30epochs_7513.5599999999995_images_False_newWeights_True_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for octnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training resnet for 0.09% of train size (aka 7513 images) with pretrained: True and onlyLastLayersTrained: True...\n",
      "\n",
      "Total: 178 trainable: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/151 [>.............................] - ETA: 1:17 - loss: 1.3898 - accuracy: 0.1813WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0730s vs `on_train_batch_begin` time: 0.1547s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0730s vs `on_train_batch_end` time: 0.2288s). Check your callbacks.\n",
      "151/151 [==============================] - 22s 116ms/step - loss: 1.3899 - accuracy: 0.2168 - val_loss: 1.3822 - val_accuracy: 0.3438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "151/151 [==============================] - 14s 92ms/step - loss: 1.3903 - accuracy: 0.2177 - val_loss: 1.3822 - val_accuracy: 0.3438\n",
      "Epoch 3/30\n",
      "151/151 [==============================] - 11s 76ms/step - loss: 1.3902 - accuracy: 0.2127 - val_loss: 1.3822 - val_accuracy: 0.3438\n",
      "Epoch 4/30\n",
      "151/151 [==============================] - 13s 85ms/step - loss: 1.3898 - accuracy: 0.2188 - val_loss: 1.3822 - val_accuracy: 0.3438\n",
      "Epoch 5/30\n",
      "151/151 [==============================] - 13s 86ms/step - loss: 1.3902 - accuracy: 0.2130 - val_loss: 1.3822 - val_accuracy: 0.3438\n",
      "Epoch 6/30\n",
      "151/151 [==============================] - 13s 86ms/step - loss: 1.3900 - accuracy: 0.2229 - val_loss: 1.3822 - val_accuracy: 0.3438\n",
      "Epoch 7/30\n",
      "151/151 [==============================] - 13s 85ms/step - loss: 1.3898 - accuracy: 0.2244 - val_loss: 1.3822 - val_accuracy: 0.3438\n",
      "Epoch 8/30\n",
      "151/151 [==============================] - 13s 87ms/step - loss: 1.3901 - accuracy: 0.2131 - val_loss: 1.3822 - val_accuracy: 0.3438\n",
      "Epoch 9/30\n",
      "151/151 [==============================] - 13s 87ms/step - loss: 1.3902 - accuracy: 0.2113 - val_loss: 1.3822 - val_accuracy: 0.3438\n",
      "Epoch 10/30\n",
      "151/151 [==============================] - 13s 84ms/step - loss: 1.3907 - accuracy: 0.2164 - val_loss: 1.3822 - val_accuracy: 0.3438\n",
      "Epoch 11/30\n",
      "151/151 [==============================] - 13s 88ms/step - loss: 1.3902 - accuracy: 0.2163 - val_loss: 1.3822 - val_accuracy: 0.3438\n",
      "Epoch 12/30\n",
      "151/151 [==============================] - 13s 87ms/step - loss: 1.3904 - accuracy: 0.2102 - val_loss: 1.3822 - val_accuracy: 0.3438\n",
      "Epoch 13/30\n",
      "151/151 [==============================] - 13s 87ms/step - loss: 1.3899 - accuracy: 0.2180 - val_loss: 1.3822 - val_accuracy: 0.3438\n",
      "Epoch 14/30\n",
      "151/151 [==============================] - 14s 89ms/step - loss: 1.3899 - accuracy: 0.2207 - val_loss: 1.3822 - val_accuracy: 0.3438\n",
      "Epoch 15/30\n",
      "151/151 [==============================] - 12s 81ms/step - loss: 1.3899 - accuracy: 0.2196 - val_loss: 1.3822 - val_accuracy: 0.3438\n",
      "Epoch 16/30\n",
      "151/151 [==============================] - 12s 81ms/step - loss: 1.3901 - accuracy: 0.2150 - val_loss: 1.3822 - val_accuracy: 0.3438\n",
      "Epoch 17/30\n",
      "151/151 [==============================] - 12s 80ms/step - loss: 1.3900 - accuracy: 0.2159 - val_loss: 1.3822 - val_accuracy: 0.3438\n",
      "Epoch 18/30\n",
      "151/151 [==============================] - 12s 79ms/step - loss: 1.3902 - accuracy: 0.2092 - val_loss: 1.3822 - val_accuracy: 0.3438\n",
      "Epoch 19/30\n",
      "151/151 [==============================] - 13s 83ms/step - loss: 1.3903 - accuracy: 0.2073 - val_loss: 1.3822 - val_accuracy: 0.3438\n",
      "Epoch 20/30\n",
      "151/151 [==============================] - 13s 83ms/step - loss: 1.3898 - accuracy: 0.2104 - val_loss: 1.3822 - val_accuracy: 0.3438\n",
      "Epoch 21/30\n",
      "151/151 [==============================] - 13s 87ms/step - loss: 1.3899 - accuracy: 0.2156 - val_loss: 1.3822 - val_accuracy: 0.3438\n",
      "Epoch 22/30\n",
      "151/151 [==============================] - 13s 89ms/step - loss: 1.3902 - accuracy: 0.2181 - val_loss: 1.3822 - val_accuracy: 0.3438\n",
      "Epoch 23/30\n",
      "151/151 [==============================] - 13s 86ms/step - loss: 1.3900 - accuracy: 0.2135 - val_loss: 1.3822 - val_accuracy: 0.3438\n",
      "Epoch 24/30\n",
      "151/151 [==============================] - 13s 86ms/step - loss: 1.3902 - accuracy: 0.2107 - val_loss: 1.3822 - val_accuracy: 0.3438\n",
      "Epoch 25/30\n",
      "151/151 [==============================] - 13s 85ms/step - loss: 1.3896 - accuracy: 0.2212 - val_loss: 1.3822 - val_accuracy: 0.3438\n",
      "Epoch 26/30\n",
      "151/151 [==============================] - 12s 79ms/step - loss: 1.3903 - accuracy: 0.2114 - val_loss: 1.3822 - val_accuracy: 0.3438\n",
      "Epoch 27/30\n",
      "151/151 [==============================] - 12s 78ms/step - loss: 1.3898 - accuracy: 0.2155 - val_loss: 1.3822 - val_accuracy: 0.3438\n",
      "Epoch 28/30\n",
      "151/151 [==============================] - 12s 76ms/step - loss: 1.3900 - accuracy: 0.2105 - val_loss: 1.3822 - val_accuracy: 0.3438\n",
      "Epoch 29/30\n",
      "151/151 [==============================] - 13s 86ms/step - loss: 1.3904 - accuracy: 0.2140 - val_loss: 1.3822 - val_accuracy: 0.3438\n",
      "Epoch 30/30\n",
      "151/151 [==============================] - 14s 91ms/step - loss: 1.3903 - accuracy: 0.2091 - val_loss: 1.3822 - val_accuracy: 0.3438\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_7513.5599999999995_images_False_newWeights_True_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.280992\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.10089303 0.09931461 0.10028199 0.0998143 ]\n",
      "Training octnet for 0.1% of train size (aka 8348 images) with pretrained: True and onlyLastLayersTrained: True...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total: 23 trainable: 0\n",
      "Epoch 1/30\n",
      "  6/167 [>.............................] - ETA: 1:02 - loss: 2199532714.6667 - accuracy: 0.3143WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0208s vs `on_train_batch_begin` time: 0.1875s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0208s vs `on_train_batch_end` time: 0.1182s). Check your callbacks.\n",
      "167/167 [==============================] - 9s 50ms/step - loss: 2420018598.0952 - accuracy: 0.2844 - val_loss: 2013933824.0000 - val_accuracy: 0.2500\n",
      "Epoch 2/30\n",
      "  3/167 [..............................] - ETA: 4s - loss: 2289213952.0000 - accuracy: 0.2944"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "167/167 [==============================] - 4s 25ms/step - loss: 2358958358.8571 - accuracy: 0.2909 - val_loss: 2013933824.0000 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "167/167 [==============================] - 7s 44ms/step - loss: 2362373376.0000 - accuracy: 0.2832 - val_loss: 2013933824.0000 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "167/167 [==============================] - 6s 38ms/step - loss: 2405312717.7143 - accuracy: 0.2768 - val_loss: 2013933824.0000 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "167/167 [==============================] - 8s 45ms/step - loss: 2423636880.0000 - accuracy: 0.2810 - val_loss: 2013933824.0000 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "167/167 [==============================] - 10s 61ms/step - loss: 2442642044.9524 - accuracy: 0.2847 - val_loss: 2013933824.0000 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "167/167 [==============================] - 10s 61ms/step - loss: 2390878006.8571 - accuracy: 0.2845 - val_loss: 2013933824.0000 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "167/167 [==============================] - 11s 64ms/step - loss: 2376794064.0000 - accuracy: 0.2847 - val_loss: 2013933824.0000 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "167/167 [==============================] - 9s 52ms/step - loss: 2384492537.9048 - accuracy: 0.2760 - val_loss: 2013933824.0000 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "167/167 [==============================] - 8s 49ms/step - loss: 2386376636.9524 - accuracy: 0.2956 - val_loss: 2013933824.0000 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "167/167 [==============================] - 4s 21ms/step - loss: 2346047524.5714 - accuracy: 0.2865 - val_loss: 2013933824.0000 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "167/167 [==============================] - 4s 27ms/step - loss: 2376362364.9524 - accuracy: 0.2791 - val_loss: 2013933824.0000 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "167/167 [==============================] - 3s 19ms/step - loss: 2399924673.5238 - accuracy: 0.2816 - val_loss: 2013933824.0000 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "167/167 [==============================] - 6s 36ms/step - loss: 2334079806.4762 - accuracy: 0.2957 - val_loss: 2013933824.0000 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "167/167 [==============================] - 6s 36ms/step - loss: 2390386267.4286 - accuracy: 0.2836 - val_loss: 2013933824.0000 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "167/167 [==============================] - 8s 50ms/step - loss: 2371831913.1429 - accuracy: 0.2888 - val_loss: 2013933824.0000 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "167/167 [==============================] - 9s 56ms/step - loss: 2468259401.1429 - accuracy: 0.2873 - val_loss: 2013933824.0000 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "167/167 [==============================] - 7s 42ms/step - loss: 2415925619.8095 - accuracy: 0.2830 - val_loss: 2013933824.0000 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "167/167 [==============================] - 7s 40ms/step - loss: 2400561557.3333 - accuracy: 0.2929 - val_loss: 2013933824.0000 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "167/167 [==============================] - 8s 49ms/step - loss: 2462332170.6667 - accuracy: 0.2703 - val_loss: 2013933824.0000 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "167/167 [==============================] - 6s 34ms/step - loss: 2442059800.3810 - accuracy: 0.2794 - val_loss: 2013933824.0000 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "167/167 [==============================] - 3s 17ms/step - loss: 2407693331.8095 - accuracy: 0.2766 - val_loss: 2013933824.0000 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "167/167 [==============================] - 7s 39ms/step - loss: 2375874256.7619 - accuracy: 0.2790 - val_loss: 2013933824.0000 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "167/167 [==============================] - 9s 54ms/step - loss: 2299136401.5238 - accuracy: 0.2992 - val_loss: 2013933824.0000 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "167/167 [==============================] - 10s 58ms/step - loss: 2398078696.3810 - accuracy: 0.2870 - val_loss: 2013933824.0000 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "167/167 [==============================] - 10s 59ms/step - loss: 2358700518.0952 - accuracy: 0.2760 - val_loss: 2013933824.0000 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "167/167 [==============================] - 10s 59ms/step - loss: 2347659376.7619 - accuracy: 0.2963 - val_loss: 2013933824.0000 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "167/167 [==============================] - 8s 48ms/step - loss: 2404342037.3333 - accuracy: 0.2742 - val_loss: 2013933824.0000 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "167/167 [==============================] - 3s 18ms/step - loss: 2416650771.8095 - accuracy: 0.2774 - val_loss: 2013933824.0000 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "167/167 [==============================] - 4s 24ms/step - loss: 2431345280.7619 - accuracy: 0.2752 - val_loss: 2013933824.0000 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../octnet/octnet_30epochs_8348.4_images_False_newWeights_True_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for octnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training resnet for 0.1% of train size (aka 8348 images) with pretrained: True and onlyLastLayersTrained: True...\n",
      "\n",
      "Total: 178 trainable: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/167 [>.............................] - ETA: 1:19 - loss: 1.3879 - accuracy: 0.2102WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0915s vs `on_train_batch_begin` time: 0.1654s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0915s vs `on_train_batch_end` time: 0.1714s). Check your callbacks.\n",
      "167/167 [==============================] - 23s 113ms/step - loss: 1.3894 - accuracy: 0.1988 - val_loss: 1.3885 - val_accuracy: 0.1562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "167/167 [==============================] - 15s 88ms/step - loss: 1.3891 - accuracy: 0.2059 - val_loss: 1.3885 - val_accuracy: 0.1562\n",
      "Epoch 3/30\n",
      "167/167 [==============================] - 14s 85ms/step - loss: 1.3891 - accuracy: 0.2122 - val_loss: 1.3885 - val_accuracy: 0.1562\n",
      "Epoch 4/30\n",
      "167/167 [==============================] - 15s 87ms/step - loss: 1.3892 - accuracy: 0.1995 - val_loss: 1.3885 - val_accuracy: 0.1562\n",
      "Epoch 5/30\n",
      "167/167 [==============================] - 15s 88ms/step - loss: 1.3888 - accuracy: 0.2142 - val_loss: 1.3885 - val_accuracy: 0.1562\n",
      "Epoch 6/30\n",
      "167/167 [==============================] - 15s 88ms/step - loss: 1.3890 - accuracy: 0.1997 - val_loss: 1.3885 - val_accuracy: 0.1562\n",
      "Epoch 7/30\n",
      "167/167 [==============================] - 14s 86ms/step - loss: 1.3891 - accuracy: 0.2052 - val_loss: 1.3885 - val_accuracy: 0.1562\n",
      "Epoch 8/30\n",
      "167/167 [==============================] - 15s 90ms/step - loss: 1.3893 - accuracy: 0.2001 - val_loss: 1.3885 - val_accuracy: 0.1562\n",
      "Epoch 9/30\n",
      "167/167 [==============================] - 14s 86ms/step - loss: 1.3896 - accuracy: 0.1978 - val_loss: 1.3885 - val_accuracy: 0.1562\n",
      "Epoch 10/30\n",
      "167/167 [==============================] - 15s 90ms/step - loss: 1.3891 - accuracy: 0.2081 - val_loss: 1.3885 - val_accuracy: 0.1562\n",
      "Epoch 11/30\n",
      "167/167 [==============================] - 14s 84ms/step - loss: 1.3891 - accuracy: 0.2050 - val_loss: 1.3885 - val_accuracy: 0.1562\n",
      "Epoch 12/30\n",
      "167/167 [==============================] - 14s 86ms/step - loss: 1.3889 - accuracy: 0.2051 - val_loss: 1.3885 - val_accuracy: 0.1562\n",
      "Epoch 13/30\n",
      "167/167 [==============================] - 14s 86ms/step - loss: 1.3892 - accuracy: 0.2034 - val_loss: 1.3885 - val_accuracy: 0.1562\n",
      "Epoch 14/30\n",
      "167/167 [==============================] - 14s 83ms/step - loss: 1.3894 - accuracy: 0.1981 - val_loss: 1.3885 - val_accuracy: 0.1562\n",
      "Epoch 15/30\n",
      "167/167 [==============================] - 14s 84ms/step - loss: 1.3892 - accuracy: 0.2020 - val_loss: 1.3885 - val_accuracy: 0.1562\n",
      "Epoch 16/30\n",
      "167/167 [==============================] - 14s 86ms/step - loss: 1.3892 - accuracy: 0.2001 - val_loss: 1.3885 - val_accuracy: 0.1562\n",
      "Epoch 17/30\n",
      "167/167 [==============================] - 14s 86ms/step - loss: 1.3894 - accuracy: 0.2039 - val_loss: 1.3885 - val_accuracy: 0.1562\n",
      "Epoch 18/30\n",
      "167/167 [==============================] - 14s 84ms/step - loss: 1.3895 - accuracy: 0.1977 - val_loss: 1.3885 - val_accuracy: 0.1562\n",
      "Epoch 19/30\n",
      "167/167 [==============================] - 14s 85ms/step - loss: 1.3891 - accuracy: 0.2025 - val_loss: 1.3885 - val_accuracy: 0.1562\n",
      "Epoch 20/30\n",
      "167/167 [==============================] - 14s 84ms/step - loss: 1.3893 - accuracy: 0.2060 - val_loss: 1.3885 - val_accuracy: 0.1562\n",
      "Epoch 21/30\n",
      "167/167 [==============================] - 15s 89ms/step - loss: 1.3889 - accuracy: 0.2071 - val_loss: 1.3885 - val_accuracy: 0.1562\n",
      "Epoch 22/30\n",
      "167/167 [==============================] - 14s 86ms/step - loss: 1.3892 - accuracy: 0.1991 - val_loss: 1.3885 - val_accuracy: 0.1562\n",
      "Epoch 23/30\n",
      "167/167 [==============================] - 15s 88ms/step - loss: 1.3890 - accuracy: 0.2050 - val_loss: 1.3885 - val_accuracy: 0.1562\n",
      "Epoch 24/30\n",
      "167/167 [==============================] - 15s 88ms/step - loss: 1.3893 - accuracy: 0.2027 - val_loss: 1.3885 - val_accuracy: 0.1562\n",
      "Epoch 25/30\n",
      "167/167 [==============================] - 14s 86ms/step - loss: 1.3892 - accuracy: 0.2015 - val_loss: 1.3885 - val_accuracy: 0.1562\n",
      "Epoch 26/30\n",
      "167/167 [==============================] - 15s 87ms/step - loss: 1.3895 - accuracy: 0.1941 - val_loss: 1.3885 - val_accuracy: 0.1562\n",
      "Epoch 27/30\n",
      "167/167 [==============================] - 14s 86ms/step - loss: 1.3891 - accuracy: 0.2000 - val_loss: 1.3885 - val_accuracy: 0.1562\n",
      "Epoch 28/30\n",
      "167/167 [==============================] - 15s 89ms/step - loss: 1.3893 - accuracy: 0.1978 - val_loss: 1.3885 - val_accuracy: 0.1562\n",
      "Epoch 29/30\n",
      "167/167 [==============================] - 15s 87ms/step - loss: 1.3893 - accuracy: 0.1994 - val_loss: 1.3885 - val_accuracy: 0.1562\n",
      "Epoch 30/30\n",
      "167/167 [==============================] - 15s 87ms/step - loss: 1.3890 - accuracy: 0.2050 - val_loss: 1.3885 - val_accuracy: 0.1562\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_8348.4_images_False_newWeights_True_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.216942\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.25251758 0.24784303 0.25484667 0.24524141]\n",
      "Training octnet for 0.25% of train size (aka 20871 images) with pretrained: True and onlyLastLayersTrained: True...\n",
      "\n",
      "Total: 23 trainable: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  4/418 [..............................] - ETA: 4:59 - loss: 2089836928.0000 - accuracy: 0.2596WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0269s vs `on_train_batch_begin` time: 0.1930s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0269s vs `on_train_batch_end` time: 0.1538s). Check your callbacks.\n",
      "418/418 [==============================] - 20s 44ms/step - loss: 1988608204.6778 - accuracy: 0.2783 - val_loss: 694277504.0000 - val_accuracy: 0.2500\n",
      "Epoch 2/30\n",
      "  3/418 [..............................] - ETA: 14s - loss: 2206442666.6667 - accuracy: 0.2500"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "418/418 [==============================] - 22s 53ms/step - loss: 1946657990.5680 - accuracy: 0.2796 - val_loss: 694277504.0000 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "418/418 [==============================] - 18s 44ms/step - loss: 1914662751.0072 - accuracy: 0.2907 - val_loss: 694277504.0000 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "418/418 [==============================] - 25s 59ms/step - loss: 1981026794.3103 - accuracy: 0.2705 - val_loss: 694277504.0000 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "418/418 [==============================] - 18s 43ms/step - loss: 1988071932.0286 - accuracy: 0.2805 - val_loss: 694277504.0000 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "418/418 [==============================] - 23s 54ms/step - loss: 1964028245.5370 - accuracy: 0.2825 - val_loss: 694277504.0000 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "418/418 [==============================] - 24s 57ms/step - loss: 1957094128.7255 - accuracy: 0.2851 - val_loss: 694277504.0000 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "418/418 [==============================] - 23s 54ms/step - loss: 1913359200.5346 - accuracy: 0.2879 - val_loss: 694277504.0000 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "418/418 [==============================] - 12s 29ms/step - loss: 1931774355.2458 - accuracy: 0.2848 - val_loss: 694277504.0000 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "418/418 [==============================] - 9s 23ms/step - loss: 1952009019.5704 - accuracy: 0.2912 - val_loss: 694277504.0000 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "418/418 [==============================] - 9s 22ms/step - loss: 1945299226.8831 - accuracy: 0.2825 - val_loss: 694277504.0000 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "418/418 [==============================] - 10s 23ms/step - loss: 1920742621.7852 - accuracy: 0.2882 - val_loss: 694277504.0000 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "418/418 [==============================] - 11s 27ms/step - loss: 1957368594.9403 - accuracy: 0.2815 - val_loss: 694277504.0000 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "418/418 [==============================] - 13s 32ms/step - loss: 1918662552.4391 - accuracy: 0.2907 - val_loss: 694277504.0000 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "418/418 [==============================] - 19s 45ms/step - loss: 1946663376.6492 - accuracy: 0.2900 - val_loss: 694277504.0000 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "418/418 [==============================] - 24s 59ms/step - loss: 2011244935.6372 - accuracy: 0.2672 - val_loss: 694277504.0000 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "418/418 [==============================] - 15s 36ms/step - loss: 1952548522.4630 - accuracy: 0.2829 - val_loss: 694277504.0000 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "418/418 [==============================] - 8s 20ms/step - loss: 1934229054.3198 - accuracy: 0.2871 - val_loss: 694277504.0000 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "418/418 [==============================] - 10s 24ms/step - loss: 1958177607.7900 - accuracy: 0.2820 - val_loss: 694277504.0000 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "418/418 [==============================] - 11s 27ms/step - loss: 1931539252.5442 - accuracy: 0.2849 - val_loss: 694277504.0000 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "418/418 [==============================] - 15s 37ms/step - loss: 1970900417.0692 - accuracy: 0.2824 - val_loss: 694277504.0000 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "418/418 [==============================] - 12s 30ms/step - loss: 1922299439.0453 - accuracy: 0.2911 - val_loss: 694277504.0000 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "418/418 [==============================] - 7s 17ms/step - loss: 1944358754.9785 - accuracy: 0.2859 - val_loss: 694277504.0000 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "418/418 [==============================] - 8s 20ms/step - loss: 1948851462.7208 - accuracy: 0.2883 - val_loss: 694277504.0000 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "418/418 [==============================] - 8s 19ms/step - loss: 1952032557.2124 - accuracy: 0.2818 - val_loss: 694277504.0000 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "418/418 [==============================] - 10s 24ms/step - loss: 1923538988.9069 - accuracy: 0.2954 - val_loss: 694277504.0000 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "418/418 [==============================] - 9s 22ms/step - loss: 1938981087.0072 - accuracy: 0.2890 - val_loss: 694277504.0000 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "418/418 [==============================] - 8s 18ms/step - loss: 1944824784.0382 - accuracy: 0.2868 - val_loss: 694277504.0000 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "418/418 [==============================] - 7s 17ms/step - loss: 1967042940.3341 - accuracy: 0.2795 - val_loss: 694277504.0000 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "418/418 [==============================] - 13s 31ms/step - loss: 1970230383.8091 - accuracy: 0.2816 - val_loss: 694277504.0000 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../octnet/octnet_30epochs_20871.0_images_False_newWeights_True_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for octnet: 0.254132\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training resnet for 0.25% of train size (aka 20871 images) with pretrained: True and onlyLastLayersTrained: True...\n",
      "\n",
      "Total: 178 trainable: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/418 [..............................] - ETA: 3:23 - loss: 1.3914 - accuracy: 0.1606WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0850s vs `on_train_batch_begin` time: 0.1496s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0850s vs `on_train_batch_end` time: 0.1945s). Check your callbacks.\n",
      "418/418 [==============================] - 47s 96ms/step - loss: 1.3921 - accuracy: 0.1553 - val_loss: 1.3860 - val_accuracy: 0.2812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "418/418 [==============================] - 36s 85ms/step - loss: 1.3922 - accuracy: 0.1596 - val_loss: 1.3860 - val_accuracy: 0.2812\n",
      "Epoch 3/30\n",
      "418/418 [==============================] - 35s 84ms/step - loss: 1.3923 - accuracy: 0.1552 - val_loss: 1.3860 - val_accuracy: 0.2812\n",
      "Epoch 4/30\n",
      "418/418 [==============================] - 33s 79ms/step - loss: 1.3922 - accuracy: 0.1584 - val_loss: 1.3860 - val_accuracy: 0.2812\n",
      "Epoch 5/30\n",
      "418/418 [==============================] - 36s 85ms/step - loss: 1.3921 - accuracy: 0.1558 - val_loss: 1.3860 - val_accuracy: 0.2812\n",
      "Epoch 6/30\n",
      "418/418 [==============================] - 35s 83ms/step - loss: 1.3922 - accuracy: 0.1552 - val_loss: 1.3860 - val_accuracy: 0.2812\n",
      "Epoch 7/30\n",
      "418/418 [==============================] - 36s 87ms/step - loss: 1.3920 - accuracy: 0.1557 - val_loss: 1.3860 - val_accuracy: 0.2812\n",
      "Epoch 8/30\n",
      "418/418 [==============================] - 34s 81ms/step - loss: 1.3920 - accuracy: 0.1545 - val_loss: 1.3860 - val_accuracy: 0.2812\n",
      "Epoch 9/30\n",
      "418/418 [==============================] - 36s 86ms/step - loss: 1.3920 - accuracy: 0.1573 - val_loss: 1.3860 - val_accuracy: 0.2812\n",
      "Epoch 10/30\n",
      "418/418 [==============================] - 35s 84ms/step - loss: 1.3920 - accuracy: 0.1558 - val_loss: 1.3860 - val_accuracy: 0.2812\n",
      "Epoch 11/30\n",
      "418/418 [==============================] - 36s 87ms/step - loss: 1.3922 - accuracy: 0.1538 - val_loss: 1.3860 - val_accuracy: 0.2812\n",
      "Epoch 12/30\n",
      "418/418 [==============================] - 37s 89ms/step - loss: 1.3923 - accuracy: 0.1512 - val_loss: 1.3860 - val_accuracy: 0.2812\n",
      "Epoch 13/30\n",
      "418/418 [==============================] - 36s 87ms/step - loss: 1.3921 - accuracy: 0.1561 - val_loss: 1.3860 - val_accuracy: 0.2812\n",
      "Epoch 14/30\n",
      "418/418 [==============================] - 36s 85ms/step - loss: 1.3922 - accuracy: 0.1515 - val_loss: 1.3860 - val_accuracy: 0.2812\n",
      "Epoch 15/30\n",
      "418/418 [==============================] - 36s 87ms/step - loss: 1.3922 - accuracy: 0.1542 - val_loss: 1.3860 - val_accuracy: 0.2812\n",
      "Epoch 16/30\n",
      "418/418 [==============================] - 37s 88ms/step - loss: 1.3921 - accuracy: 0.1538 - val_loss: 1.3860 - val_accuracy: 0.2812\n",
      "Epoch 17/30\n",
      "418/418 [==============================] - 36s 86ms/step - loss: 1.3922 - accuracy: 0.1527 - val_loss: 1.3860 - val_accuracy: 0.2812\n",
      "Epoch 18/30\n",
      "418/418 [==============================] - 36s 86ms/step - loss: 1.3921 - accuracy: 0.1562 - val_loss: 1.3860 - val_accuracy: 0.2812\n",
      "Epoch 19/30\n",
      "418/418 [==============================] - 36s 87ms/step - loss: 1.3922 - accuracy: 0.1549 - val_loss: 1.3860 - val_accuracy: 0.2812\n",
      "Epoch 20/30\n",
      "418/418 [==============================] - 31s 75ms/step - loss: 1.3920 - accuracy: 0.1543 - val_loss: 1.3860 - val_accuracy: 0.2812\n",
      "Epoch 21/30\n",
      "418/418 [==============================] - 32s 78ms/step - loss: 1.3920 - accuracy: 0.1576 - val_loss: 1.3860 - val_accuracy: 0.2812\n",
      "Epoch 22/30\n",
      "418/418 [==============================] - 33s 79ms/step - loss: 1.3922 - accuracy: 0.1534 - val_loss: 1.3860 - val_accuracy: 0.2812\n",
      "Epoch 23/30\n",
      "418/418 [==============================] - 32s 78ms/step - loss: 1.3924 - accuracy: 0.1514 - val_loss: 1.3860 - val_accuracy: 0.2812\n",
      "Epoch 24/30\n",
      "418/418 [==============================] - 34s 80ms/step - loss: 1.3920 - accuracy: 0.1573 - val_loss: 1.3860 - val_accuracy: 0.2812\n",
      "Epoch 25/30\n",
      "418/418 [==============================] - 35s 84ms/step - loss: 1.3920 - accuracy: 0.1539 - val_loss: 1.3860 - val_accuracy: 0.2812\n",
      "Epoch 26/30\n",
      "418/418 [==============================] - 35s 84ms/step - loss: 1.3920 - accuracy: 0.1550 - val_loss: 1.3860 - val_accuracy: 0.2812\n",
      "Epoch 27/30\n",
      "418/418 [==============================] - 35s 83ms/step - loss: 1.3921 - accuracy: 0.1566 - val_loss: 1.3860 - val_accuracy: 0.2812\n",
      "Epoch 28/30\n",
      "418/418 [==============================] - 37s 89ms/step - loss: 1.3921 - accuracy: 0.1505 - val_loss: 1.3860 - val_accuracy: 0.2812\n",
      "Epoch 29/30\n",
      "418/418 [==============================] - 36s 87ms/step - loss: 1.3920 - accuracy: 0.1556 - val_loss: 1.3860 - val_accuracy: 0.2812\n",
      "Epoch 30/30\n",
      "418/418 [==============================] - 36s 87ms/step - loss: 1.3920 - accuracy: 0.1575 - val_loss: 1.3860 - val_accuracy: 0.2812\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_20871.0_images_False_newWeights_True_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.242769\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.40547216 0.3980379  0.40183292 0.38927577]\n",
      "Training octnet for 0.4% of train size (aka 33393 images) with pretrained: True and onlyLastLayersTrained: True...\n",
      "\n",
      "Total: 23 trainable: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/668 [..............................] - ETA: 5:14 - loss: 2758113322.6667 - accuracy: 0.1778 WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0158s vs `on_train_batch_begin` time: 0.2300s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0158s vs `on_train_batch_end` time: 0.1535s). Check your callbacks.\n",
      "668/668 [==============================] - 19s 27ms/step - loss: 2663834177.4350 - accuracy: 0.2026 - val_loss: 1149749760.0000 - val_accuracy: 0.2500\n",
      "Epoch 2/30\n",
      "  5/668 [..............................] - ETA: 10s - loss: 2896166092.8000 - accuracy: 0.1360"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "668/668 [==============================] - 13s 20ms/step - loss: 2672256763.7907 - accuracy: 0.1985 - val_loss: 1149749760.0000 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "668/668 [==============================] - 13s 20ms/step - loss: 2649716612.7833 - accuracy: 0.2096 - val_loss: 1149749760.0000 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "668/668 [==============================] - 12s 18ms/step - loss: 2644685309.7040 - accuracy: 0.2057 - val_loss: 1149749760.0000 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "668/668 [==============================] - 13s 19ms/step - loss: 2658689096.3229 - accuracy: 0.2067 - val_loss: 1149749760.0000 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 2640283101.5605 - accuracy: 0.2039 - val_loss: 1149749760.0000 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "668/668 [==============================] - 19s 29ms/step - loss: 2653742580.1375 - accuracy: 0.2017 - val_loss: 1149749760.0000 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "668/668 [==============================] - 14s 21ms/step - loss: 2644299535.3064 - accuracy: 0.2041 - val_loss: 1149749760.0000 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "668/668 [==============================] - 13s 19ms/step - loss: 2621827335.6532 - accuracy: 0.2087 - val_loss: 1149749760.0000 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "668/668 [==============================] - 17s 25ms/step - loss: 2631011588.4006 - accuracy: 0.2062 - val_loss: 1149749760.0000 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "668/668 [==============================] - 20s 30ms/step - loss: 2671032471.5336 - accuracy: 0.1963 - val_loss: 1149749760.0000 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "668/668 [==============================] - 14s 20ms/step - loss: 2645003408.6457 - accuracy: 0.2023 - val_loss: 1149749760.0000 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "668/668 [==============================] - 16s 23ms/step - loss: 2618208936.7534 - accuracy: 0.2045 - val_loss: 1149749760.0000 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "668/668 [==============================] - 16s 24ms/step - loss: 2659171546.1166 - accuracy: 0.1984 - val_loss: 1149749760.0000 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "668/668 [==============================] - 12s 19ms/step - loss: 2652851787.7668 - accuracy: 0.2037 - val_loss: 1149749760.0000 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "668/668 [==============================] - 14s 21ms/step - loss: 2648114491.6951 - accuracy: 0.2026 - val_loss: 1149749760.0000 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 2658778167.4858 - accuracy: 0.2032 - val_loss: 1149749760.0000 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "668/668 [==============================] - 12s 18ms/step - loss: 2635067653.3572 - accuracy: 0.2072 - val_loss: 1149749760.0000 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "668/668 [==============================] - 14s 20ms/step - loss: 2640798421.1420 - accuracy: 0.2060 - val_loss: 1149749760.0000 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "668/668 [==============================] - 14s 21ms/step - loss: 2648485920.9088 - accuracy: 0.2059 - val_loss: 1149749760.0000 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "668/668 [==============================] - 13s 20ms/step - loss: 2623608982.7683 - accuracy: 0.2059 - val_loss: 1149749760.0000 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "668/668 [==============================] - 13s 19ms/step - loss: 2651793160.0359 - accuracy: 0.2044 - val_loss: 1149749760.0000 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "668/668 [==============================] - 14s 20ms/step - loss: 2634235979.3842 - accuracy: 0.2068 - val_loss: 1149749760.0000 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "668/668 [==============================] - 14s 21ms/step - loss: 2674318539.5755 - accuracy: 0.2038 - val_loss: 1149749760.0000 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "668/668 [==============================] - 18s 26ms/step - loss: 2627873800.8012 - accuracy: 0.2070 - val_loss: 1149749760.0000 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 2605200179.6592 - accuracy: 0.2093 - val_loss: 1149749760.0000 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "668/668 [==============================] - 12s 17ms/step - loss: 2638071036.9387 - accuracy: 0.2102 - val_loss: 1149749760.0000 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "668/668 [==============================] - 18s 27ms/step - loss: 2628005752.9208 - accuracy: 0.2038 - val_loss: 1149749760.0000 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "668/668 [==============================] - 19s 29ms/step - loss: 2650241659.2167 - accuracy: 0.2069 - val_loss: 1149749760.0000 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "668/668 [==============================] - 18s 28ms/step - loss: 2625703751.1749 - accuracy: 0.2064 - val_loss: 1149749760.0000 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../octnet/octnet_30epochs_33393.6_images_False_newWeights_True_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for octnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training resnet for 0.4% of train size (aka 33393 images) with pretrained: True and onlyLastLayersTrained: True...\n",
      "\n",
      "Total: 178 trainable: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/668 [..............................] - ETA: 6:22 - loss: 1.3823 - accuracy: 0.3454WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0875s vs `on_train_batch_begin` time: 0.2366s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0875s vs `on_train_batch_end` time: 0.1745s). Check your callbacks.\n",
      "668/668 [==============================] - 61s 85ms/step - loss: 1.3811 - accuracy: 0.3746 - val_loss: 1.3837 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "668/668 [==============================] - 56s 85ms/step - loss: 1.3811 - accuracy: 0.3752 - val_loss: 1.3837 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "668/668 [==============================] - 50s 75ms/step - loss: 1.3811 - accuracy: 0.3781 - val_loss: 1.3837 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "668/668 [==============================] - 51s 77ms/step - loss: 1.3812 - accuracy: 0.3711 - val_loss: 1.3837 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "668/668 [==============================] - 55s 83ms/step - loss: 1.3813 - accuracy: 0.3711 - val_loss: 1.3837 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "668/668 [==============================] - 53s 79ms/step - loss: 1.3810 - accuracy: 0.3784 - val_loss: 1.3837 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "668/668 [==============================] - 51s 76ms/step - loss: 1.3811 - accuracy: 0.3745 - val_loss: 1.3837 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "668/668 [==============================] - 54s 81ms/step - loss: 1.3810 - accuracy: 0.3754 - val_loss: 1.3837 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "668/668 [==============================] - 52s 77ms/step - loss: 1.3811 - accuracy: 0.3725 - val_loss: 1.3837 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "668/668 [==============================] - 49s 73ms/step - loss: 1.3813 - accuracy: 0.3713 - val_loss: 1.3837 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "668/668 [==============================] - 52s 78ms/step - loss: 1.3811 - accuracy: 0.3764 - val_loss: 1.3837 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "668/668 [==============================] - 57s 85ms/step - loss: 1.3812 - accuracy: 0.3764 - val_loss: 1.3837 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "668/668 [==============================] - 55s 82ms/step - loss: 1.3811 - accuracy: 0.3785 - val_loss: 1.3837 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "668/668 [==============================] - 56s 83ms/step - loss: 1.3811 - accuracy: 0.3782 - val_loss: 1.3837 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "668/668 [==============================] - 56s 84ms/step - loss: 1.3811 - accuracy: 0.3749 - val_loss: 1.3837 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "668/668 [==============================] - 55s 82ms/step - loss: 1.3811 - accuracy: 0.3744 - val_loss: 1.3837 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "668/668 [==============================] - 56s 83ms/step - loss: 1.3813 - accuracy: 0.3733 - val_loss: 1.3837 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "668/668 [==============================] - 53s 80ms/step - loss: 1.3812 - accuracy: 0.3741 - val_loss: 1.3837 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "668/668 [==============================] - 54s 81ms/step - loss: 1.3813 - accuracy: 0.3738 - val_loss: 1.3837 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "668/668 [==============================] - 53s 79ms/step - loss: 1.3810 - accuracy: 0.3753 - val_loss: 1.3837 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "668/668 [==============================] - 52s 78ms/step - loss: 1.3812 - accuracy: 0.3731 - val_loss: 1.3837 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "668/668 [==============================] - 56s 83ms/step - loss: 1.3810 - accuracy: 0.3764 - val_loss: 1.3837 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "668/668 [==============================] - 52s 79ms/step - loss: 1.3812 - accuracy: 0.3726 - val_loss: 1.3837 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "668/668 [==============================] - 55s 82ms/step - loss: 1.3811 - accuracy: 0.3739 - val_loss: 1.3837 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "668/668 [==============================] - 52s 78ms/step - loss: 1.3814 - accuracy: 0.3735 - val_loss: 1.3837 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "668/668 [==============================] - 57s 85ms/step - loss: 1.3811 - accuracy: 0.3762 - val_loss: 1.3837 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "668/668 [==============================] - 51s 76ms/step - loss: 1.3812 - accuracy: 0.3757 - val_loss: 1.3837 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "668/668 [==============================] - 54s 81ms/step - loss: 1.3811 - accuracy: 0.3768 - val_loss: 1.3837 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "668/668 [==============================] - 55s 82ms/step - loss: 1.3811 - accuracy: 0.3732 - val_loss: 1.3837 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "668/668 [==============================] - 54s 81ms/step - loss: 1.3810 - accuracy: 0.3737 - val_loss: 1.3837 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_33393.6_images_False_newWeights_True_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.298554\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.5065552  0.49565919 0.50361297 0.49396472]\n",
      "Training octnet for 0.5% of train size (aka 41742 images) with pretrained: True and onlyLastLayersTrained: True...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total: 23 trainable: 0\n",
      "Epoch 1/30\n",
      "  5/835 [..............................] - ETA: 6:55 - loss: 1516317158.4000 - accuracy: 0.2640 WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0203s vs `on_train_batch_begin` time: 0.2067s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0203s vs `on_train_batch_end` time: 0.1137s). Check your callbacks.\n",
      "835/835 [==============================] - 39s 46ms/step - loss: 1349005266.6794 - accuracy: 0.2598 - val_loss: 448909600.0000 - val_accuracy: 0.1875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "835/835 [==============================] - 24s 29ms/step - loss: 1342584293.2057 - accuracy: 0.2624 - val_loss: 448909600.0000 - val_accuracy: 0.1875\n",
      "Epoch 3/30\n",
      "835/835 [==============================] - 33s 40ms/step - loss: 1340779391.6938 - accuracy: 0.2626 - val_loss: 448909600.0000 - val_accuracy: 0.1875\n",
      "Epoch 4/30\n",
      "835/835 [==============================] - 25s 29ms/step - loss: 1352719564.0957 - accuracy: 0.2588 - val_loss: 448909600.0000 - val_accuracy: 0.1875\n",
      "Epoch 5/30\n",
      "835/835 [==============================] - 24s 29ms/step - loss: 1338526588.0191 - accuracy: 0.2562 - val_loss: 448909600.0000 - val_accuracy: 0.1875\n",
      "Epoch 6/30\n",
      "835/835 [==============================] - 16s 19ms/step - loss: 1349092511.6938 - accuracy: 0.2570 - val_loss: 448909600.0000 - val_accuracy: 0.1875\n",
      "Epoch 7/30\n",
      "835/835 [==============================] - 16s 20ms/step - loss: 1343613164.5550 - accuracy: 0.2620 - val_loss: 448909600.0000 - val_accuracy: 0.1875\n",
      "Epoch 8/30\n",
      "835/835 [==============================] - 17s 20ms/step - loss: 1336105468.7847 - accuracy: 0.2621 - val_loss: 448909600.0000 - val_accuracy: 0.1875\n",
      "Epoch 9/30\n",
      "835/835 [==============================] - 23s 27ms/step - loss: 1354448049.7608 - accuracy: 0.2577 - val_loss: 448909600.0000 - val_accuracy: 0.1875\n",
      "Epoch 10/30\n",
      "835/835 [==============================] - 23s 27ms/step - loss: 1345975116.7081 - accuracy: 0.2629 - val_loss: 448909600.0000 - val_accuracy: 0.1875\n",
      "Epoch 11/30\n",
      "835/835 [==============================] - 21s 26ms/step - loss: 1337124243.4450 - accuracy: 0.2644 - val_loss: 448909600.0000 - val_accuracy: 0.1875\n",
      "Epoch 12/30\n",
      "835/835 [==============================] - 21s 25ms/step - loss: 1352216252.7847 - accuracy: 0.2593 - val_loss: 448909600.0000 - val_accuracy: 0.1875\n",
      "Epoch 13/30\n",
      "835/835 [==============================] - 18s 21ms/step - loss: 1344014155.6364 - accuracy: 0.2603 - val_loss: 448909600.0000 - val_accuracy: 0.1875\n",
      "Epoch 14/30\n",
      "835/835 [==============================] - 19s 23ms/step - loss: 1348172263.0431 - accuracy: 0.2574 - val_loss: 448909600.0000 - val_accuracy: 0.1875\n",
      "Epoch 15/30\n",
      "835/835 [==============================] - 29s 34ms/step - loss: 1352205005.7799 - accuracy: 0.2599 - val_loss: 448909600.0000 - val_accuracy: 0.1875\n",
      "Epoch 16/30\n",
      "835/835 [==============================] - 22s 26ms/step - loss: 1349189850.0287 - accuracy: 0.2638 - val_loss: 448909600.0000 - val_accuracy: 0.1875\n",
      "Epoch 17/30\n",
      "835/835 [==============================] - 17s 21ms/step - loss: 1351874488.8038 - accuracy: 0.2546 - val_loss: 448909600.0000 - val_accuracy: 0.1875\n",
      "Epoch 18/30\n",
      "835/835 [==============================] - 24s 28ms/step - loss: 1330226354.0670 - accuracy: 0.2661 - val_loss: 448909600.0000 - val_accuracy: 0.1875\n",
      "Epoch 19/30\n",
      "835/835 [==============================] - 20s 24ms/step - loss: 1340682927.2344 - accuracy: 0.2643 - val_loss: 448909600.0000 - val_accuracy: 0.1875\n",
      "Epoch 20/30\n",
      "835/835 [==============================] - 16s 19ms/step - loss: 1349549429.7416 - accuracy: 0.2592 - val_loss: 448909600.0000 - val_accuracy: 0.1875\n",
      "Epoch 21/30\n",
      "835/835 [==============================] - 30s 35ms/step - loss: 1348335075.8278 - accuracy: 0.2607 - val_loss: 448909600.0000 - val_accuracy: 0.1875\n",
      "Epoch 22/30\n",
      "835/835 [==============================] - 22s 27ms/step - loss: 1347573827.6746 - accuracy: 0.2559 - val_loss: 448909600.0000 - val_accuracy: 0.1875\n",
      "Epoch 23/30\n",
      "835/835 [==============================] - 23s 28ms/step - loss: 1347158363.2536 - accuracy: 0.2549 - val_loss: 448909600.0000 - val_accuracy: 0.1875\n",
      "Epoch 24/30\n",
      "835/835 [==============================] - 20s 23ms/step - loss: 1335387380.5167 - accuracy: 0.2586 - val_loss: 448909600.0000 - val_accuracy: 0.1875\n",
      "Epoch 25/30\n",
      "835/835 [==============================] - 24s 29ms/step - loss: 1360255205.2057 - accuracy: 0.2589 - val_loss: 448909600.0000 - val_accuracy: 0.1875\n",
      "Epoch 26/30\n",
      "835/835 [==============================] - 33s 39ms/step - loss: 1349551831.8852 - accuracy: 0.2597 - val_loss: 448909600.0000 - val_accuracy: 0.1875\n",
      "Epoch 27/30\n",
      "835/835 [==============================] - 23s 28ms/step - loss: 1341413495.4258 - accuracy: 0.2626 - val_loss: 448909600.0000 - val_accuracy: 0.1875\n",
      "Epoch 28/30\n",
      "835/835 [==============================] - 34s 40ms/step - loss: 1342077457.6077 - accuracy: 0.2591 - val_loss: 448909600.0000 - val_accuracy: 0.1875\n",
      "Epoch 29/30\n",
      "835/835 [==============================] - 29s 35ms/step - loss: 1353764908.7081 - accuracy: 0.2578 - val_loss: 448909600.0000 - val_accuracy: 0.1875\n",
      "Epoch 30/30\n",
      "835/835 [==============================] - 23s 27ms/step - loss: 1347664564.9761 - accuracy: 0.2588 - val_loss: 448909600.0000 - val_accuracy: 0.1875\n",
      "INFO:tensorflow:Assets written to: ../octnet/octnet_30epochs_41742.0_images_False_newWeights_True_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for octnet: 0.262397\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training resnet for 0.5% of train size (aka 41742 images) with pretrained: True and onlyLastLayersTrained: True...\n",
      "\n",
      "Total: 178 trainable: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/835 [..............................] - ETA: 7:17 - loss: 1.3806 - accuracy: 0.3797WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0697s vs `on_train_batch_begin` time: 0.2444s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0697s vs `on_train_batch_end` time: 0.1414s). Check your callbacks.\n",
      "835/835 [==============================] - 74s 84ms/step - loss: 1.3833 - accuracy: 0.3478 - val_loss: 1.3890 - val_accuracy: 0.2188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "835/835 [==============================] - 68s 82ms/step - loss: 1.3833 - accuracy: 0.3450 - val_loss: 1.3890 - val_accuracy: 0.2188\n",
      "Epoch 3/30\n",
      "835/835 [==============================] - 69s 83ms/step - loss: 1.3834 - accuracy: 0.3452 - val_loss: 1.3890 - val_accuracy: 0.2188\n",
      "Epoch 4/30\n",
      "835/835 [==============================] - 64s 77ms/step - loss: 1.3835 - accuracy: 0.3459 - val_loss: 1.3890 - val_accuracy: 0.2188\n",
      "Epoch 5/30\n",
      "835/835 [==============================] - 63s 76ms/step - loss: 1.3835 - accuracy: 0.3448 - val_loss: 1.3890 - val_accuracy: 0.2188\n",
      "Epoch 6/30\n",
      "835/835 [==============================] - 67s 80ms/step - loss: 1.3834 - accuracy: 0.3467 - val_loss: 1.3890 - val_accuracy: 0.2188\n",
      "Epoch 7/30\n",
      "835/835 [==============================] - 65s 78ms/step - loss: 1.3836 - accuracy: 0.3428 - val_loss: 1.3890 - val_accuracy: 0.2188\n",
      "Epoch 8/30\n",
      "835/835 [==============================] - 66s 79ms/step - loss: 1.3834 - accuracy: 0.3463 - val_loss: 1.3890 - val_accuracy: 0.2188\n",
      "Epoch 9/30\n",
      "835/835 [==============================] - 64s 76ms/step - loss: 1.3834 - accuracy: 0.3478 - val_loss: 1.3890 - val_accuracy: 0.2188\n",
      "Epoch 10/30\n",
      "835/835 [==============================] - 66s 79ms/step - loss: 1.3834 - accuracy: 0.3485 - val_loss: 1.3890 - val_accuracy: 0.2188\n",
      "Epoch 11/30\n",
      "835/835 [==============================] - 69s 83ms/step - loss: 1.3833 - accuracy: 0.3488 - val_loss: 1.3890 - val_accuracy: 0.2188\n",
      "Epoch 12/30\n",
      "835/835 [==============================] - 68s 81ms/step - loss: 1.3835 - accuracy: 0.3442 - val_loss: 1.3890 - val_accuracy: 0.2188\n",
      "Epoch 13/30\n",
      "835/835 [==============================] - 69s 83ms/step - loss: 1.3834 - accuracy: 0.3459 - val_loss: 1.3890 - val_accuracy: 0.2188\n",
      "Epoch 14/30\n",
      "835/835 [==============================] - 69s 82ms/step - loss: 1.3834 - accuracy: 0.3466 - val_loss: 1.3890 - val_accuracy: 0.2188\n",
      "Epoch 15/30\n",
      "835/835 [==============================] - 65s 78ms/step - loss: 1.3834 - accuracy: 0.3464 - val_loss: 1.3890 - val_accuracy: 0.2188\n",
      "Epoch 16/30\n",
      "835/835 [==============================] - 67s 81ms/step - loss: 1.3834 - accuracy: 0.3467 - val_loss: 1.3890 - val_accuracy: 0.2188\n",
      "Epoch 17/30\n",
      "835/835 [==============================] - 66s 79ms/step - loss: 1.3834 - accuracy: 0.3489 - val_loss: 1.3890 - val_accuracy: 0.2188\n",
      "Epoch 18/30\n",
      "835/835 [==============================] - 63s 75ms/step - loss: 1.3833 - accuracy: 0.3493 - val_loss: 1.3890 - val_accuracy: 0.2188\n",
      "Epoch 19/30\n",
      "835/835 [==============================] - 68s 81ms/step - loss: 1.3833 - accuracy: 0.3464 - val_loss: 1.3890 - val_accuracy: 0.2188\n",
      "Epoch 20/30\n",
      "835/835 [==============================] - 70s 84ms/step - loss: 1.3835 - accuracy: 0.3441 - val_loss: 1.3890 - val_accuracy: 0.2188\n",
      "Epoch 21/30\n",
      "835/835 [==============================] - 65s 78ms/step - loss: 1.3835 - accuracy: 0.3437 - val_loss: 1.3890 - val_accuracy: 0.2188\n",
      "Epoch 22/30\n",
      "835/835 [==============================] - 70s 83ms/step - loss: 1.3834 - accuracy: 0.3482 - val_loss: 1.3890 - val_accuracy: 0.2188\n",
      "Epoch 23/30\n",
      "835/835 [==============================] - 67s 80ms/step - loss: 1.3834 - accuracy: 0.3482 - val_loss: 1.3890 - val_accuracy: 0.2188\n",
      "Epoch 24/30\n",
      "835/835 [==============================] - 71s 85ms/step - loss: 1.3835 - accuracy: 0.3460 - val_loss: 1.3890 - val_accuracy: 0.2188\n",
      "Epoch 25/30\n",
      "835/835 [==============================] - 61s 73ms/step - loss: 1.3834 - accuracy: 0.3456 - val_loss: 1.3890 - val_accuracy: 0.2188\n",
      "Epoch 26/30\n",
      "835/835 [==============================] - 73s 88ms/step - loss: 1.3835 - accuracy: 0.3410 - val_loss: 1.3890 - val_accuracy: 0.2188\n",
      "Epoch 27/30\n",
      "835/835 [==============================] - 64s 76ms/step - loss: 1.3835 - accuracy: 0.3447 - val_loss: 1.3890 - val_accuracy: 0.2188\n",
      "Epoch 28/30\n",
      "835/835 [==============================] - 64s 77ms/step - loss: 1.3834 - accuracy: 0.3468 - val_loss: 1.3890 - val_accuracy: 0.2188\n",
      "Epoch 29/30\n",
      "835/835 [==============================] - 68s 81ms/step - loss: 1.3834 - accuracy: 0.3471 - val_loss: 1.3890 - val_accuracy: 0.2188\n",
      "Epoch 30/30\n",
      "835/835 [==============================] - 65s 78ms/step - loss: 1.3832 - accuracy: 0.3488 - val_loss: 1.3890 - val_accuracy: 0.2188\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_41742.0_images_False_newWeights_True_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.334711\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.60516816 0.59567262 0.60327811 0.5985376 ]\n",
      "Training octnet for 0.6% of train size (aka 50090 images) with pretrained: True and onlyLastLayersTrained: True...\n",
      "\n",
      "Total: 23 trainable: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "   6/1002 [..............................] - ETA: 7:45 - loss: 2072703893.3333 - accuracy: 0.2706WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0250s vs `on_train_batch_begin` time: 0.2353s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0250s vs `on_train_batch_end` time: 0.1357s). Check your callbacks.\n",
      "1002/1002 [==============================] - 33s 32ms/step - loss: 2093389537.1167 - accuracy: 0.2585 - val_loss: 647740992.0000 - val_accuracy: 0.2500\n",
      "Epoch 2/30\n",
      "   4/1002 [..............................] - ETA: 23s - loss: 2085270400.0000 - accuracy: 0.2779"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1002/1002 [==============================] - 30s 30ms/step - loss: 2101852515.2861 - accuracy: 0.2586 - val_loss: 647740992.0000 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "1002/1002 [==============================] - 35s 35ms/step - loss: 2122432159.5214 - accuracy: 0.2468 - val_loss: 647740992.0000 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "1002/1002 [==============================] - 27s 27ms/step - loss: 2141206956.7936 - accuracy: 0.2542 - val_loss: 647740992.0000 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "1002/1002 [==============================] - 27s 27ms/step - loss: 2112966868.3549 - accuracy: 0.2564 - val_loss: 647740992.0000 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "1002/1002 [==============================] - 31s 31ms/step - loss: 2113859306.0499 - accuracy: 0.2540 - val_loss: 647740992.0000 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "1002/1002 [==============================] - 45s 45ms/step - loss: 2123071857.0688 - accuracy: 0.2586 - val_loss: 647740992.0000 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "1002/1002 [==============================] - 36s 36ms/step - loss: 2100716778.5603 - accuracy: 0.2584 - val_loss: 647740992.0000 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "1002/1002 [==============================] - 29s 29ms/step - loss: 2109019888.5583 - accuracy: 0.2557 - val_loss: 647740992.0000 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "1002/1002 [==============================] - 43s 43ms/step - loss: 2106358625.4995 - accuracy: 0.2568 - val_loss: 647740992.0000 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "1002/1002 [==============================] - 31s 31ms/step - loss: 2092947024.0160 - accuracy: 0.2597 - val_loss: 647740992.0000 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "1002/1002 [==============================] - 34s 34ms/step - loss: 2096900385.6909 - accuracy: 0.2539 - val_loss: 647740992.0000 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "1002/1002 [==============================] - 38s 38ms/step - loss: 2118936242.0259 - accuracy: 0.2574 - val_loss: 647740992.0000 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "1002/1002 [==============================] - 30s 30ms/step - loss: 2128928367.1545 - accuracy: 0.2539 - val_loss: 647740992.0000 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "1002/1002 [==============================] - 30s 30ms/step - loss: 2109495756.6979 - accuracy: 0.2537 - val_loss: 647740992.0000 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "1002/1002 [==============================] - 24s 24ms/step - loss: 2081620177.9302 - accuracy: 0.2609 - val_loss: 647740992.0000 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "1002/1002 [==============================] - 26s 26ms/step - loss: 2110393766.5404 - accuracy: 0.2574 - val_loss: 647740992.0000 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "1002/1002 [==============================] - 32s 32ms/step - loss: 2096244110.4207 - accuracy: 0.2590 - val_loss: 647740992.0000 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "1002/1002 [==============================] - 27s 27ms/step - loss: 2110962388.6102 - accuracy: 0.2552 - val_loss: 647740992.0000 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "1002/1002 [==============================] - 36s 35ms/step - loss: 2115963841.7228 - accuracy: 0.2534 - val_loss: 647740992.0000 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "1002/1002 [==============================] - 29s 29ms/step - loss: 2100707487.0110 - accuracy: 0.2605 - val_loss: 647740992.0000 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "1002/1002 [==============================] - 38s 38ms/step - loss: 2106316708.2433 - accuracy: 0.2556 - val_loss: 647740992.0000 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "1002/1002 [==============================] - 43s 43ms/step - loss: 2102954427.0867 - accuracy: 0.2557 - val_loss: 647740992.0000 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "1002/1002 [==============================] - 31s 31ms/step - loss: 2108159095.4497 - accuracy: 0.2571 - val_loss: 647740992.0000 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "1002/1002 [==============================] - 40s 40ms/step - loss: 2113530149.5194 - accuracy: 0.2579 - val_loss: 647740992.0000 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "1002/1002 [==============================] - 32s 32ms/step - loss: 2106323684.0518 - accuracy: 0.2572 - val_loss: 647740992.0000 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "1002/1002 [==============================] - 33s 33ms/step - loss: 2116751046.0618 - accuracy: 0.2535 - val_loss: 647740992.0000 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "1002/1002 [==============================] - 32s 32ms/step - loss: 2084505442.7757 - accuracy: 0.2591 - val_loss: 647740992.0000 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "1002/1002 [==============================] - 28s 28ms/step - loss: 2112598592.3190 - accuracy: 0.2580 - val_loss: 647740992.0000 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "1002/1002 [==============================] - 39s 39ms/step - loss: 2098727339.7727 - accuracy: 0.2599 - val_loss: 647740992.0000 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../octnet/octnet_30epochs_50090.4_images_False_newWeights_True_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for octnet: 0.243802\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training resnet for 0.6% of train size (aka 50090 images) with pretrained: True and onlyLastLayersTrained: True...\n",
      "\n",
      "Total: 178 trainable: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "   6/1002 [..............................] - ETA: 10:00 - loss: 1.3849 - accuracy: 0.2188WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0866s vs `on_train_batch_begin` time: 0.2664s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0866s vs `on_train_batch_end` time: 0.1659s). Check your callbacks.\n",
      "1002/1002 [==============================] - 86s 81ms/step - loss: 1.3855 - accuracy: 0.2198 - val_loss: 1.3830 - val_accuracy: 0.3438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "1002/1002 [==============================] - 77s 77ms/step - loss: 1.3854 - accuracy: 0.2181 - val_loss: 1.3830 - val_accuracy: 0.3438\n",
      "Epoch 3/30\n",
      "1002/1002 [==============================] - 76s 76ms/step - loss: 1.3854 - accuracy: 0.2208 - val_loss: 1.3830 - val_accuracy: 0.3438\n",
      "Epoch 4/30\n",
      "1002/1002 [==============================] - 81s 81ms/step - loss: 1.3856 - accuracy: 0.2148 - val_loss: 1.3830 - val_accuracy: 0.3438\n",
      "Epoch 5/30\n",
      "1002/1002 [==============================] - 80s 80ms/step - loss: 1.3855 - accuracy: 0.2182 - val_loss: 1.3830 - val_accuracy: 0.3438\n",
      "Epoch 6/30\n",
      "1002/1002 [==============================] - 78s 78ms/step - loss: 1.3854 - accuracy: 0.2189 - val_loss: 1.3830 - val_accuracy: 0.3438\n",
      "Epoch 7/30\n",
      "1002/1002 [==============================] - 81s 80ms/step - loss: 1.3854 - accuracy: 0.2199 - val_loss: 1.3830 - val_accuracy: 0.3438\n",
      "Epoch 8/30\n",
      "1002/1002 [==============================] - 81s 81ms/step - loss: 1.3855 - accuracy: 0.2177 - val_loss: 1.3830 - val_accuracy: 0.3438\n",
      "Epoch 9/30\n",
      "1002/1002 [==============================] - 80s 80ms/step - loss: 1.3855 - accuracy: 0.2186 - val_loss: 1.3830 - val_accuracy: 0.3438\n",
      "Epoch 10/30\n",
      "1002/1002 [==============================] - 81s 80ms/step - loss: 1.3854 - accuracy: 0.2180 - val_loss: 1.3830 - val_accuracy: 0.3438\n",
      "Epoch 11/30\n",
      "1002/1002 [==============================] - 80s 80ms/step - loss: 1.3856 - accuracy: 0.2138 - val_loss: 1.3830 - val_accuracy: 0.3438\n",
      "Epoch 12/30\n",
      "1002/1002 [==============================] - 82s 82ms/step - loss: 1.3855 - accuracy: 0.2183 - val_loss: 1.3830 - val_accuracy: 0.3438\n",
      "Epoch 13/30\n",
      "1002/1002 [==============================] - 73s 73ms/step - loss: 1.3855 - accuracy: 0.2174 - val_loss: 1.3830 - val_accuracy: 0.3438\n",
      "Epoch 14/30\n",
      "1002/1002 [==============================] - 80s 80ms/step - loss: 1.3855 - accuracy: 0.2190 - val_loss: 1.3830 - val_accuracy: 0.3438\n",
      "Epoch 15/30\n",
      "1002/1002 [==============================] - 79s 79ms/step - loss: 1.3854 - accuracy: 0.2201 - val_loss: 1.3830 - val_accuracy: 0.3438\n",
      "Epoch 16/30\n",
      "1002/1002 [==============================] - 81s 81ms/step - loss: 1.3855 - accuracy: 0.2188 - val_loss: 1.3830 - val_accuracy: 0.3438\n",
      "Epoch 17/30\n",
      "1002/1002 [==============================] - 78s 78ms/step - loss: 1.3855 - accuracy: 0.2180 - val_loss: 1.3830 - val_accuracy: 0.3438\n",
      "Epoch 18/30\n",
      "1002/1002 [==============================] - 76s 76ms/step - loss: 1.3855 - accuracy: 0.2171 - val_loss: 1.3830 - val_accuracy: 0.3438\n",
      "Epoch 19/30\n",
      "1002/1002 [==============================] - 80s 80ms/step - loss: 1.3855 - accuracy: 0.2161 - val_loss: 1.3830 - val_accuracy: 0.3438\n",
      "Epoch 20/30\n",
      "1002/1002 [==============================] - 80s 80ms/step - loss: 1.3855 - accuracy: 0.2201 - val_loss: 1.3830 - val_accuracy: 0.3438\n",
      "Epoch 21/30\n",
      "1002/1002 [==============================] - 84s 84ms/step - loss: 1.3854 - accuracy: 0.2194 - val_loss: 1.3830 - val_accuracy: 0.3438\n",
      "Epoch 22/30\n",
      "1002/1002 [==============================] - 81s 81ms/step - loss: 1.3855 - accuracy: 0.2168 - val_loss: 1.3830 - val_accuracy: 0.3438\n",
      "Epoch 23/30\n",
      "1002/1002 [==============================] - 80s 80ms/step - loss: 1.3854 - accuracy: 0.2179 - val_loss: 1.3830 - val_accuracy: 0.3438\n",
      "Epoch 24/30\n",
      "1002/1002 [==============================] - 79s 79ms/step - loss: 1.3854 - accuracy: 0.2200 - val_loss: 1.3830 - val_accuracy: 0.3438\n",
      "Epoch 25/30\n",
      "1002/1002 [==============================] - 83s 83ms/step - loss: 1.3855 - accuracy: 0.2186 - val_loss: 1.3830 - val_accuracy: 0.3438\n",
      "Epoch 26/30\n",
      "1002/1002 [==============================] - 82s 81ms/step - loss: 1.3855 - accuracy: 0.2163 - val_loss: 1.3830 - val_accuracy: 0.3438\n",
      "Epoch 27/30\n",
      "1002/1002 [==============================] - 83s 83ms/step - loss: 1.3855 - accuracy: 0.2181 - val_loss: 1.3830 - val_accuracy: 0.3438\n",
      "Epoch 28/30\n",
      "1002/1002 [==============================] - 84s 83ms/step - loss: 1.3854 - accuracy: 0.2194 - val_loss: 1.3830 - val_accuracy: 0.3438\n",
      "Epoch 29/30\n",
      "1002/1002 [==============================] - 85s 85ms/step - loss: 1.3854 - accuracy: 0.2189 - val_loss: 1.3830 - val_accuracy: 0.3438\n",
      "Epoch 30/30\n",
      "1002/1002 [==============================] - 81s 80ms/step - loss: 1.3856 - accuracy: 0.2175 - val_loss: 1.3830 - val_accuracy: 0.3438\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_50090.4_images_False_newWeights_True_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.267562\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.75500665 0.74748018 0.75255552 0.74222377]\n",
      "Training octnet for 0.75% of train size (aka 62613 images) with pretrained: True and onlyLastLayersTrained: True...\n",
      "\n",
      "Total: 23 trainable: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "   5/1253 [..............................] - ETA: 11:06 - loss: 1711465036.8000 - accuracy: 0.2359WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0167s vs `on_train_batch_begin` time: 0.2094s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0167s vs `on_train_batch_end` time: 0.1357s). Check your callbacks.\n",
      "1253/1253 [==============================] - 30s 23ms/step - loss: 1609052346.5901 - accuracy: 0.2365 - val_loss: 806858048.0000 - val_accuracy: 0.3125\n",
      "Epoch 2/30\n",
      "   2/1253 [..............................] - ETA: 1:13 - loss: 1697723776.0000 - accuracy: 0.2300"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1253/1253 [==============================] - 34s 27ms/step - loss: 1601241452.8102 - accuracy: 0.2360 - val_loss: 806858048.0000 - val_accuracy: 0.3125\n",
      "Epoch 3/30\n",
      "1253/1253 [==============================] - 27s 22ms/step - loss: 1615854955.4833 - accuracy: 0.2373 - val_loss: 806858048.0000 - val_accuracy: 0.3125\n",
      "Epoch 4/30\n",
      "1253/1253 [==============================] - 28s 22ms/step - loss: 1594933998.0351 - accuracy: 0.2390 - val_loss: 806858048.0000 - val_accuracy: 0.3125\n",
      "Epoch 5/30\n",
      "1253/1253 [==============================] - 32s 26ms/step - loss: 1627100548.2871 - accuracy: 0.2340 - val_loss: 806858048.0000 - val_accuracy: 0.3125\n",
      "Epoch 6/30\n",
      "1253/1253 [==============================] - 42s 34ms/step - loss: 1599299317.7927 - accuracy: 0.2353 - val_loss: 806858048.0000 - val_accuracy: 0.3125\n",
      "Epoch 7/30\n",
      "1253/1253 [==============================] - 42s 33ms/step - loss: 1604491383.7321 - accuracy: 0.2360 - val_loss: 806858048.0000 - val_accuracy: 0.3125\n",
      "Epoch 8/30\n",
      "1253/1253 [==============================] - 41s 33ms/step - loss: 1595702572.7081 - accuracy: 0.2428 - val_loss: 806858048.0000 - val_accuracy: 0.3125\n",
      "Epoch 9/30\n",
      "1253/1253 [==============================] - 44s 35ms/step - loss: 1602668807.3493 - accuracy: 0.2357 - val_loss: 806858048.0000 - val_accuracy: 0.3125\n",
      "Epoch 10/30\n",
      "1253/1253 [==============================] - 33s 26ms/step - loss: 1607581666.1946 - accuracy: 0.2341 - val_loss: 806858048.0000 - val_accuracy: 0.3125\n",
      "Epoch 11/30\n",
      "1253/1253 [==============================] - 35s 28ms/step - loss: 1606325459.8022 - accuracy: 0.2348 - val_loss: 806858048.0000 - val_accuracy: 0.3125\n",
      "Epoch 12/30\n",
      "1253/1253 [==============================] - 45s 36ms/step - loss: 1615852315.1515 - accuracy: 0.2358 - val_loss: 806858048.0000 - val_accuracy: 0.3125\n",
      "Epoch 13/30\n",
      "1253/1253 [==============================] - 50s 40ms/step - loss: 1595112854.6603 - accuracy: 0.2400 - val_loss: 806858048.0000 - val_accuracy: 0.3125\n",
      "Epoch 14/30\n",
      "1253/1253 [==============================] - 45s 36ms/step - loss: 1610876254.1116 - accuracy: 0.2370 - val_loss: 806858048.0000 - val_accuracy: 0.3125\n",
      "Epoch 15/30\n",
      "1253/1253 [==============================] - 32s 26ms/step - loss: 1605669311.5917 - accuracy: 0.2355 - val_loss: 806858048.0000 - val_accuracy: 0.3125\n",
      "Epoch 16/30\n",
      "1253/1253 [==============================] - 37s 30ms/step - loss: 1600947618.3987 - accuracy: 0.2368 - val_loss: 806858048.0000 - val_accuracy: 0.3125\n",
      "Epoch 17/30\n",
      "1253/1253 [==============================] - 28s 23ms/step - loss: 1610607209.4418 - accuracy: 0.2379 - val_loss: 806858048.0000 - val_accuracy: 0.3125\n",
      "Epoch 18/30\n",
      "1253/1253 [==============================] - 29s 23ms/step - loss: 1604277115.1005 - accuracy: 0.2399 - val_loss: 806858048.0000 - val_accuracy: 0.3125\n",
      "Epoch 19/30\n",
      "1253/1253 [==============================] - 30s 24ms/step - loss: 1609829599.8469 - accuracy: 0.2342 - val_loss: 806858048.0000 - val_accuracy: 0.3125\n",
      "Epoch 20/30\n",
      "1253/1253 [==============================] - 38s 30ms/step - loss: 1607338391.4769 - accuracy: 0.2336 - val_loss: 806858048.0000 - val_accuracy: 0.3125\n",
      "Epoch 21/30\n",
      "1253/1253 [==============================] - 38s 30ms/step - loss: 1613412936.0638 - accuracy: 0.2357 - val_loss: 806858048.0000 - val_accuracy: 0.3125\n",
      "Epoch 22/30\n",
      "1253/1253 [==============================] - 30s 24ms/step - loss: 1613587986.5774 - accuracy: 0.2357 - val_loss: 806858048.0000 - val_accuracy: 0.3125\n",
      "Epoch 23/30\n",
      "1253/1253 [==============================] - 48s 39ms/step - loss: 1621509399.4769 - accuracy: 0.2308 - val_loss: 806858048.0000 - val_accuracy: 0.3125\n",
      "Epoch 24/30\n",
      "1253/1253 [==============================] - 37s 29ms/step - loss: 1637708864.3062 - accuracy: 0.2329 - val_loss: 806858048.0000 - val_accuracy: 0.3125\n",
      "Epoch 25/30\n",
      "1253/1253 [==============================] - 37s 30ms/step - loss: 1616580678.7368 - accuracy: 0.2331 - val_loss: 806858048.0000 - val_accuracy: 0.3125\n",
      "Epoch 26/30\n",
      "1253/1253 [==============================] - 32s 25ms/step - loss: 1609819529.2887 - accuracy: 0.2373 - val_loss: 806858048.0000 - val_accuracy: 0.3125\n",
      "Epoch 27/30\n",
      "1253/1253 [==============================] - 44s 35ms/step - loss: 1607740062.3158 - accuracy: 0.2355 - val_loss: 806858048.0000 - val_accuracy: 0.3125\n",
      "Epoch 28/30\n",
      "1253/1253 [==============================] - 36s 29ms/step - loss: 1607430181.8692 - accuracy: 0.2385 - val_loss: 806858048.0000 - val_accuracy: 0.3125\n",
      "Epoch 29/30\n",
      "1253/1253 [==============================] - 29s 23ms/step - loss: 1614457259.5853 - accuracy: 0.2354 - val_loss: 806858048.0000 - val_accuracy: 0.3125\n",
      "Epoch 30/30\n",
      "1253/1253 [==============================] - 34s 27ms/step - loss: 1594574369.2759 - accuracy: 0.2396 - val_loss: 806858048.0000 - val_accuracy: 0.3125\n",
      "INFO:tensorflow:Assets written to: ../octnet/octnet_30epochs_62613.0_images_False_newWeights_True_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for octnet: 0.279959\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training resnet for 0.75% of train size (aka 62613 images) with pretrained: True and onlyLastLayersTrained: True...\n",
      "\n",
      "Total: 178 trainable: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "   6/1253 [..............................] - ETA: 11:18 - loss: 1.3818 - accuracy: 0.2072WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0823s vs `on_train_batch_begin` time: 0.2287s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0823s vs `on_train_batch_end` time: 0.1577s). Check your callbacks.\n",
      "1253/1253 [==============================] - 108s 82ms/step - loss: 1.3830 - accuracy: 0.2104 - val_loss: 1.3899 - val_accuracy: 0.1250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "1253/1253 [==============================] - 96s 76ms/step - loss: 1.3828 - accuracy: 0.2134 - val_loss: 1.3899 - val_accuracy: 0.1250\n",
      "Epoch 3/30\n",
      "1253/1253 [==============================] - 99s 79ms/step - loss: 1.3829 - accuracy: 0.2108 - val_loss: 1.3899 - val_accuracy: 0.1250\n",
      "Epoch 4/30\n",
      "1253/1253 [==============================] - 101s 80ms/step - loss: 1.3829 - accuracy: 0.2112 - val_loss: 1.3899 - val_accuracy: 0.1250\n",
      "Epoch 5/30\n",
      "1253/1253 [==============================] - 101s 80ms/step - loss: 1.3828 - accuracy: 0.2094 - val_loss: 1.3899 - val_accuracy: 0.1250\n",
      "Epoch 6/30\n",
      "1253/1253 [==============================] - 101s 81ms/step - loss: 1.3829 - accuracy: 0.2132 - val_loss: 1.3899 - val_accuracy: 0.1250\n",
      "Epoch 7/30\n",
      "1253/1253 [==============================] - 100s 79ms/step - loss: 1.3828 - accuracy: 0.2124 - val_loss: 1.3899 - val_accuracy: 0.1250\n",
      "Epoch 8/30\n",
      "1253/1253 [==============================] - 105s 83ms/step - loss: 1.3829 - accuracy: 0.2106 - val_loss: 1.3899 - val_accuracy: 0.1250\n",
      "Epoch 9/30\n",
      "1253/1253 [==============================] - 100s 80ms/step - loss: 1.3829 - accuracy: 0.2129 - val_loss: 1.3899 - val_accuracy: 0.1250\n",
      "Epoch 10/30\n",
      "1253/1253 [==============================] - 102s 81ms/step - loss: 1.3829 - accuracy: 0.2107 - val_loss: 1.3899 - val_accuracy: 0.1250\n",
      "Epoch 11/30\n",
      "1253/1253 [==============================] - 100s 80ms/step - loss: 1.3830 - accuracy: 0.2081 - val_loss: 1.3899 - val_accuracy: 0.1250\n",
      "Epoch 12/30\n",
      "1253/1253 [==============================] - 101s 81ms/step - loss: 1.3829 - accuracy: 0.2119 - val_loss: 1.3899 - val_accuracy: 0.1250\n",
      "Epoch 13/30\n",
      "1253/1253 [==============================] - 101s 81ms/step - loss: 1.3830 - accuracy: 0.2100 - val_loss: 1.3899 - val_accuracy: 0.1250\n",
      "Epoch 14/30\n",
      "1253/1253 [==============================] - 101s 81ms/step - loss: 1.3828 - accuracy: 0.2120 - val_loss: 1.3899 - val_accuracy: 0.1250\n",
      "Epoch 15/30\n",
      "1253/1253 [==============================] - 99s 79ms/step - loss: 1.3829 - accuracy: 0.2133 - val_loss: 1.3899 - val_accuracy: 0.1250\n",
      "Epoch 16/30\n",
      "1253/1253 [==============================] - 102s 82ms/step - loss: 1.3828 - accuracy: 0.2143 - val_loss: 1.3899 - val_accuracy: 0.1250\n",
      "Epoch 17/30\n",
      "1253/1253 [==============================] - 100s 80ms/step - loss: 1.3830 - accuracy: 0.2105 - val_loss: 1.3899 - val_accuracy: 0.1250\n",
      "Epoch 18/30\n",
      "1253/1253 [==============================] - 98s 79ms/step - loss: 1.3828 - accuracy: 0.2137 - val_loss: 1.3899 - val_accuracy: 0.1250\n",
      "Epoch 19/30\n",
      "1253/1253 [==============================] - 98s 78ms/step - loss: 1.3828 - accuracy: 0.2141 - val_loss: 1.3899 - val_accuracy: 0.1250\n",
      "Epoch 20/30\n",
      "1253/1253 [==============================] - 102s 81ms/step - loss: 1.3827 - accuracy: 0.2133 - val_loss: 1.3899 - val_accuracy: 0.1250\n",
      "Epoch 21/30\n",
      "1253/1253 [==============================] - 103s 82ms/step - loss: 1.3829 - accuracy: 0.2149 - val_loss: 1.3899 - val_accuracy: 0.1250\n",
      "Epoch 22/30\n",
      "1253/1253 [==============================] - 104s 83ms/step - loss: 1.3828 - accuracy: 0.2121 - val_loss: 1.3899 - val_accuracy: 0.1250\n",
      "Epoch 23/30\n",
      "1253/1253 [==============================] - 102s 82ms/step - loss: 1.3828 - accuracy: 0.2121 - val_loss: 1.3899 - val_accuracy: 0.1250\n",
      "Epoch 24/30\n",
      "1253/1253 [==============================] - 103s 82ms/step - loss: 1.3829 - accuracy: 0.2128 - val_loss: 1.3899 - val_accuracy: 0.1250\n",
      "Epoch 25/30\n",
      "1253/1253 [==============================] - 104s 83ms/step - loss: 1.3829 - accuracy: 0.2126 - val_loss: 1.3899 - val_accuracy: 0.1250\n",
      "Epoch 26/30\n",
      "1253/1253 [==============================] - 104s 83ms/step - loss: 1.3829 - accuracy: 0.2129 - val_loss: 1.3899 - val_accuracy: 0.1250\n",
      "Epoch 27/30\n",
      "1253/1253 [==============================] - 100s 80ms/step - loss: 1.3828 - accuracy: 0.2120 - val_loss: 1.3899 - val_accuracy: 0.1250\n",
      "Epoch 28/30\n",
      "1253/1253 [==============================] - 101s 81ms/step - loss: 1.3829 - accuracy: 0.2107 - val_loss: 1.3899 - val_accuracy: 0.1250\n",
      "Epoch 29/30\n",
      "1253/1253 [==============================] - 106s 85ms/step - loss: 1.3828 - accuracy: 0.2165 - val_loss: 1.3899 - val_accuracy: 0.1250\n",
      "Epoch 30/30\n",
      "1253/1253 [==============================] - 103s 82ms/step - loss: 1.3829 - accuracy: 0.2137 - val_loss: 1.3899 - val_accuracy: 0.1250\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_62613.0_images_False_newWeights_True_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.224174\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.90378111 0.89694933 0.90192104 0.89902507]\n",
      "Training octnet for 0.9% of train size (aka 75135 images) with pretrained: True and onlyLastLayersTrained: True...\n",
      "\n",
      "Total: 23 trainable: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "   5/1503 [..............................] - ETA: 13:19 - loss: 1886262681.6000 - accuracy: 0.2661WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0265s vs `on_train_batch_begin` time: 0.1828s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0265s vs `on_train_batch_end` time: 0.1570s). Check your callbacks.\n",
      "1503/1503 [==============================] - 70s 46ms/step - loss: 1967485014.1277 - accuracy: 0.2588 - val_loss: 1111194240.0000 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "1503/1503 [==============================] - 56s 37ms/step - loss: 1965941623.4043 - accuracy: 0.2581 - val_loss: 1111194240.0000 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "1503/1503 [==============================] - 60s 40ms/step - loss: 1952796825.0213 - accuracy: 0.2591 - val_loss: 1111194240.0000 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "1503/1503 [==============================] - 63s 42ms/step - loss: 1974532702.4681 - accuracy: 0.2572 - val_loss: 1111194240.0000 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "1503/1503 [==============================] - 53s 35ms/step - loss: 1974059266.2979 - accuracy: 0.2581 - val_loss: 1111194240.0000 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "1503/1503 [==============================] - 60s 40ms/step - loss: 1975530137.2766 - accuracy: 0.2558 - val_loss: 1111194240.0000 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "1503/1503 [==============================] - 53s 35ms/step - loss: 1972558716.6809 - accuracy: 0.2566 - val_loss: 1111194240.0000 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "1503/1503 [==============================] - 66s 44ms/step - loss: 1960848370.8936 - accuracy: 0.2605 - val_loss: 1111194240.0000 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "1503/1503 [==============================] - 49s 33ms/step - loss: 1968142385.1915 - accuracy: 0.2578 - val_loss: 1111194240.0000 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "1503/1503 [==============================] - 74s 49ms/step - loss: 1988265658.6383 - accuracy: 0.2539 - val_loss: 1111194240.0000 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "1503/1503 [==============================] - 72s 48ms/step - loss: 1970140619.8298 - accuracy: 0.2571 - val_loss: 1111194240.0000 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "1503/1503 [==============================] - 66s 44ms/step - loss: 1971798982.4681 - accuracy: 0.2600 - val_loss: 1111194240.0000 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "1503/1503 [==============================] - 76s 51ms/step - loss: 1975915718.4681 - accuracy: 0.2579 - val_loss: 1111194240.0000 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "1503/1503 [==============================] - 82s 55ms/step - loss: 1977191273.8723 - accuracy: 0.2571 - val_loss: 1111194240.0000 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "1503/1503 [==============================] - 67s 44ms/step - loss: 1970734419.1489 - accuracy: 0.2564 - val_loss: 1111194240.0000 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "1503/1503 [==============================] - 78s 52ms/step - loss: 1976354537.8723 - accuracy: 0.2578 - val_loss: 1111194240.0000 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "1503/1503 [==============================] - 73s 49ms/step - loss: 1971865478.0426 - accuracy: 0.2581 - val_loss: 1111194240.0000 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "1503/1503 [==============================] - 73s 49ms/step - loss: 1967968129.7872 - accuracy: 0.2600 - val_loss: 1111194240.0000 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "1503/1503 [==============================] - 63s 42ms/step - loss: 1976514512.4255 - accuracy: 0.2575 - val_loss: 1111194240.0000 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "1503/1503 [==============================] - 61s 40ms/step - loss: 1971949324.5957 - accuracy: 0.2552 - val_loss: 1111194240.0000 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "1503/1503 [==============================] - 62s 42ms/step - loss: 1972751131.4894 - accuracy: 0.2576 - val_loss: 1111194240.0000 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "1503/1503 [==============================] - 68s 46ms/step - loss: 1973842408.0000 - accuracy: 0.2557 - val_loss: 1111194240.0000 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "1503/1503 [==============================] - 51s 34ms/step - loss: 1961513589.8723 - accuracy: 0.2609 - val_loss: 1111194240.0000 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "1503/1503 [==============================] - 59s 39ms/step - loss: 1966152136.8511 - accuracy: 0.2600 - val_loss: 1111194240.0000 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "1503/1503 [==============================] - 59s 40ms/step - loss: 1966285125.7872 - accuracy: 0.2597 - val_loss: 1111194240.0000 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "1503/1503 [==============================] - 73s 48ms/step - loss: 1973399263.4894 - accuracy: 0.2596 - val_loss: 1111194240.0000 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "1503/1503 [==============================] - 76s 51ms/step - loss: 1960139030.1277 - accuracy: 0.2576 - val_loss: 1111194240.0000 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "1503/1503 [==============================] - 77s 51ms/step - loss: 1974681405.8723 - accuracy: 0.2555 - val_loss: 1111194240.0000 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "1503/1503 [==============================] - 82s 55ms/step - loss: 1975071041.9574 - accuracy: 0.2585 - val_loss: 1111194240.0000 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "1503/1503 [==============================] - 53s 35ms/step - loss: 1975390201.1915 - accuracy: 0.2584 - val_loss: 1111194240.0000 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../octnet/octnet_30epochs_75135.6_images_False_newWeights_True_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for octnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training resnet for 0.9% of train size (aka 75135 images) with pretrained: True and onlyLastLayersTrained: True...\n",
      "\n",
      "Total: 178 trainable: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "   6/1503 [..............................] - ETA: 11:59 - loss: 1.3862 - accuracy: 0.2366WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0659s vs `on_train_batch_begin` time: 0.2099s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0659s vs `on_train_batch_end` time: 0.1361s). Check your callbacks.\n",
      "1503/1503 [==============================] - 128s 82ms/step - loss: 1.3854 - accuracy: 0.2510 - val_loss: 1.3894 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "1503/1503 [==============================] - 121s 81ms/step - loss: 1.3853 - accuracy: 0.2515 - val_loss: 1.3894 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "1503/1503 [==============================] - 118s 78ms/step - loss: 1.3852 - accuracy: 0.2533 - val_loss: 1.3894 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "1503/1503 [==============================] - 121s 81ms/step - loss: 1.3853 - accuracy: 0.2530 - val_loss: 1.3894 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "1503/1503 [==============================] - 121s 80ms/step - loss: 1.3852 - accuracy: 0.2547 - val_loss: 1.3894 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "1503/1503 [==============================] - 112s 74ms/step - loss: 1.3852 - accuracy: 0.2537 - val_loss: 1.3894 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "1503/1503 [==============================] - 114s 76ms/step - loss: 1.3853 - accuracy: 0.2523 - val_loss: 1.3894 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "1503/1503 [==============================] - 119s 79ms/step - loss: 1.3852 - accuracy: 0.2532 - val_loss: 1.3894 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "1503/1503 [==============================] - 119s 79ms/step - loss: 1.3853 - accuracy: 0.2529 - val_loss: 1.3894 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "1503/1503 [==============================] - 128s 85ms/step - loss: 1.3854 - accuracy: 0.2537 - val_loss: 1.3894 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "1503/1503 [==============================] - 125s 83ms/step - loss: 1.3854 - accuracy: 0.2492 - val_loss: 1.3894 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "1503/1503 [==============================] - 128s 85ms/step - loss: 1.3852 - accuracy: 0.2530 - val_loss: 1.3894 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "1503/1503 [==============================] - 123s 82ms/step - loss: 1.3853 - accuracy: 0.2516 - val_loss: 1.3894 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "1503/1503 [==============================] - 123s 82ms/step - loss: 1.3853 - accuracy: 0.2514 - val_loss: 1.3894 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "1503/1503 [==============================] - 125s 83ms/step - loss: 1.3852 - accuracy: 0.2554 - val_loss: 1.3894 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "1503/1503 [==============================] - 126s 84ms/step - loss: 1.3854 - accuracy: 0.2518 - val_loss: 1.3894 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "1503/1503 [==============================] - 123s 82ms/step - loss: 1.3853 - accuracy: 0.2525 - val_loss: 1.3894 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "1503/1503 [==============================] - 125s 83ms/step - loss: 1.3854 - accuracy: 0.2526 - val_loss: 1.3894 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "1503/1503 [==============================] - 121s 80ms/step - loss: 1.3853 - accuracy: 0.2521 - val_loss: 1.3894 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "1503/1503 [==============================] - 125s 83ms/step - loss: 1.3854 - accuracy: 0.2510 - val_loss: 1.3894 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "1503/1503 [==============================] - 128s 85ms/step - loss: 1.3853 - accuracy: 0.2548 - val_loss: 1.3894 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "1503/1503 [==============================] - 132s 88ms/step - loss: 1.3854 - accuracy: 0.2526 - val_loss: 1.3894 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "1503/1503 [==============================] - 126s 84ms/step - loss: 1.3852 - accuracy: 0.2545 - val_loss: 1.3894 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "1503/1503 [==============================] - 125s 83ms/step - loss: 1.3853 - accuracy: 0.2533 - val_loss: 1.3894 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "1503/1503 [==============================] - 130s 87ms/step - loss: 1.3854 - accuracy: 0.2520 - val_loss: 1.3894 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "1503/1503 [==============================] - 128s 85ms/step - loss: 1.3854 - accuracy: 0.2501 - val_loss: 1.3894 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "1503/1503 [==============================] - 120s 80ms/step - loss: 1.3852 - accuracy: 0.2543 - val_loss: 1.3894 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "1503/1503 [==============================] - 125s 83ms/step - loss: 1.3852 - accuracy: 0.2509 - val_loss: 1.3894 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "1503/1503 [==============================] - 124s 83ms/step - loss: 1.3853 - accuracy: 0.2541 - val_loss: 1.3894 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "1503/1503 [==============================] - 127s 85ms/step - loss: 1.3853 - accuracy: 0.2539 - val_loss: 1.3894 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_75135.6_images_False_newWeights_True_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.302686\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [1. 1. 1. 1.]\n",
      "Training octnet for 1.0% of train size (aka 83484 images) with pretrained: True and onlyLastLayersTrained: True...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total: 23 trainable: 0\n",
      "Epoch 1/30\n",
      "   6/1670 [..............................] - ETA: 11:37 - loss: 2341261056.0000 - accuracy: 0.1186WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0275s vs `on_train_batch_begin` time: 0.1930s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0275s vs `on_train_batch_end` time: 0.1340s). Check your callbacks.\n",
      "1670/1670 [==============================] - 62s 36ms/step - loss: 2221998087.2005 - accuracy: 0.1649 - val_loss: 1105479424.0000 - val_accuracy: 0.2500\n",
      "Epoch 2/30\n",
      "   1/1670 [..............................] - ETA: 1:40 - loss: 1891763968.0000 - accuracy: 0.1200"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1670/1670 [==============================] - 74s 44ms/step - loss: 2210996030.5829 - accuracy: 0.1632 - val_loss: 1105479424.0000 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "1670/1670 [==============================] - 70s 42ms/step - loss: 2194654706.2885 - accuracy: 0.1669 - val_loss: 1105479424.0000 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "1670/1670 [==============================] - 72s 43ms/step - loss: 2216159577.6230 - accuracy: 0.1637 - val_loss: 1105479424.0000 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "1670/1670 [==============================] - 79s 48ms/step - loss: 2213997846.5206 - accuracy: 0.1626 - val_loss: 1105479424.0000 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "1670/1670 [==============================] - 74s 45ms/step - loss: 2210917981.7594 - accuracy: 0.1643 - val_loss: 1105479424.0000 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "1670/1670 [==============================] - 67s 40ms/step - loss: 2219867364.8833 - accuracy: 0.1621 - val_loss: 1105479424.0000 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "1670/1670 [==============================] - 74s 44ms/step - loss: 2232622414.4393 - accuracy: 0.1605 - val_loss: 1105479424.0000 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "1670/1670 [==============================] - 78s 47ms/step - loss: 2215169548.0263 - accuracy: 0.1647 - val_loss: 1105479424.0000 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "1670/1670 [==============================] - 45s 27ms/step - loss: 2222365392.9671 - accuracy: 0.1627 - val_loss: 1105479424.0000 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "1670/1670 [==============================] - 39s 24ms/step - loss: 2220566079.9617 - accuracy: 0.1620 - val_loss: 1105479424.0000 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "1670/1670 [==============================] - 40s 24ms/step - loss: 2215692054.5206 - accuracy: 0.1613 - val_loss: 1105479424.0000 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "1670/1670 [==============================] - 38s 23ms/step - loss: 2221577620.5290 - accuracy: 0.1603 - val_loss: 1105479424.0000 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "1670/1670 [==============================] - 32s 19ms/step - loss: 2223120753.3692 - accuracy: 0.1656 - val_loss: 1105479424.0000 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "1670/1670 [==============================] - 39s 23ms/step - loss: 2223210250.8773 - accuracy: 0.1636 - val_loss: 1105479424.0000 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "1670/1670 [==============================] - 35s 21ms/step - loss: 2221925593.2400 - accuracy: 0.1608 - val_loss: 1105479424.0000 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "1670/1670 [==============================] - 66s 40ms/step - loss: 2223172661.5440 - accuracy: 0.1630 - val_loss: 1105479424.0000 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "1670/1670 [==============================] - 58s 35ms/step - loss: 2218820031.9617 - accuracy: 0.1641 - val_loss: 1105479424.0000 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "1670/1670 [==============================] - 55s 33ms/step - loss: 2198271463.4877 - accuracy: 0.1647 - val_loss: 1105479424.0000 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "1670/1670 [==============================] - 37s 22ms/step - loss: 2217638701.1945 - accuracy: 0.1618 - val_loss: 1105479424.0000 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "1670/1670 [==============================] - 41s 24ms/step - loss: 2203995121.2160 - accuracy: 0.1637 - val_loss: 1105479424.0000 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "1670/1670 [==============================] - 46s 28ms/step - loss: 2207129309.0700 - accuracy: 0.1659 - val_loss: 1105479424.0000 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "1670/1670 [==============================] - 75s 45ms/step - loss: 2227305305.6230 - accuracy: 0.1634 - val_loss: 1105479424.0000 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "1670/1670 [==============================] - 84s 50ms/step - loss: 2218583996.2083 - accuracy: 0.1646 - val_loss: 1105479424.0000 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "1670/1670 [==============================] - 77s 46ms/step - loss: 2231326304.0575 - accuracy: 0.1623 - val_loss: 1105479424.0000 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "1670/1670 [==============================] - 67s 40ms/step - loss: 2220187221.2567 - accuracy: 0.1626 - val_loss: 1105479424.0000 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "1670/1670 [==============================] - 68s 41ms/step - loss: 2227875157.7929 - accuracy: 0.1618 - val_loss: 1105479424.0000 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "1670/1670 [==============================] - 73s 44ms/step - loss: 2208348266.9348 - accuracy: 0.1658 - val_loss: 1105479424.0000 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "1670/1670 [==============================] - 69s 41ms/step - loss: 2220006445.6541 - accuracy: 0.1621 - val_loss: 1105479424.0000 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "1670/1670 [==============================] - 52s 31ms/step - loss: 2218265780.4716 - accuracy: 0.1653 - val_loss: 1105479424.0000 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../octnet/octnet_30epochs_83484.0_images_False_newWeights_True_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for octnet: 0.248967\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training resnet for 1.0% of train size (aka 83484 images) with pretrained: True and onlyLastLayersTrained: True...\n",
      "\n",
      "Total: 178 trainable: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "   6/1670 [..............................] - ETA: 12:35 - loss: 1.3828 - accuracy: 0.3885WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0671s vs `on_train_batch_begin` time: 0.1712s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0671s vs `on_train_batch_end` time: 0.1553s). Check your callbacks.\n",
      "1670/1670 [==============================] - 146s 83ms/step - loss: 1.3842 - accuracy: 0.3249 - val_loss: 1.3769 - val_accuracy: 0.4688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "1670/1670 [==============================] - 146s 87ms/step - loss: 1.3842 - accuracy: 0.3219 - val_loss: 1.3769 - val_accuracy: 0.4688\n",
      "Epoch 3/30\n",
      "1670/1670 [==============================] - 141s 84ms/step - loss: 1.3842 - accuracy: 0.3250 - val_loss: 1.3769 - val_accuracy: 0.4688\n",
      "Epoch 4/30\n",
      "1670/1670 [==============================] - 134s 80ms/step - loss: 1.3841 - accuracy: 0.3271 - val_loss: 1.3769 - val_accuracy: 0.4688\n",
      "Epoch 5/30\n",
      "1670/1670 [==============================] - 126s 75ms/step - loss: 1.3842 - accuracy: 0.3222 - val_loss: 1.3769 - val_accuracy: 0.4688\n",
      "Epoch 6/30\n",
      "1670/1670 [==============================] - 132s 79ms/step - loss: 1.3841 - accuracy: 0.3277 - val_loss: 1.3769 - val_accuracy: 0.4688\n",
      "Epoch 7/30\n",
      "1670/1670 [==============================] - 119s 71ms/step - loss: 1.3842 - accuracy: 0.3222 - val_loss: 1.3769 - val_accuracy: 0.4688\n",
      "Epoch 8/30\n",
      "1670/1670 [==============================] - 133s 80ms/step - loss: 1.3843 - accuracy: 0.3214 - val_loss: 1.3769 - val_accuracy: 0.4688\n",
      "Epoch 9/30\n",
      "1670/1670 [==============================] - 120s 72ms/step - loss: 1.3842 - accuracy: 0.3218 - val_loss: 1.3769 - val_accuracy: 0.4688\n",
      "Epoch 10/30\n",
      "1670/1670 [==============================] - 126s 76ms/step - loss: 1.3842 - accuracy: 0.3236 - val_loss: 1.3769 - val_accuracy: 0.4688\n",
      "Epoch 11/30\n",
      "1670/1670 [==============================] - 131s 79ms/step - loss: 1.3841 - accuracy: 0.3230 - val_loss: 1.3769 - val_accuracy: 0.4688\n",
      "Epoch 12/30\n",
      "1670/1670 [==============================] - 129s 77ms/step - loss: 1.3843 - accuracy: 0.3225 - val_loss: 1.3769 - val_accuracy: 0.4688\n",
      "Epoch 13/30\n",
      "1670/1670 [==============================] - 132s 79ms/step - loss: 1.3841 - accuracy: 0.3235 - val_loss: 1.3769 - val_accuracy: 0.4688\n",
      "Epoch 14/30\n",
      "1670/1670 [==============================] - 124s 74ms/step - loss: 1.3842 - accuracy: 0.3206 - val_loss: 1.3769 - val_accuracy: 0.4688\n",
      "Epoch 15/30\n",
      "1670/1670 [==============================] - 126s 75ms/step - loss: 1.3842 - accuracy: 0.3234 - val_loss: 1.3769 - val_accuracy: 0.4688\n",
      "Epoch 16/30\n",
      "1670/1670 [==============================] - 121s 72ms/step - loss: 1.3843 - accuracy: 0.3214 - val_loss: 1.3769 - val_accuracy: 0.4688\n",
      "Epoch 17/30\n",
      "1670/1670 [==============================] - 115s 69ms/step - loss: 1.3841 - accuracy: 0.3265 - val_loss: 1.3769 - val_accuracy: 0.4688\n",
      "Epoch 18/30\n",
      "1670/1670 [==============================] - 117s 70ms/step - loss: 1.3841 - accuracy: 0.3241 - val_loss: 1.3769 - val_accuracy: 0.4688\n",
      "Epoch 19/30\n",
      "1670/1670 [==============================] - 118s 71ms/step - loss: 1.3842 - accuracy: 0.3239 - val_loss: 1.3769 - val_accuracy: 0.4688\n",
      "Epoch 20/30\n",
      "1670/1670 [==============================] - 115s 69ms/step - loss: 1.3842 - accuracy: 0.3238 - val_loss: 1.3769 - val_accuracy: 0.4688\n",
      "Epoch 21/30\n",
      "1670/1670 [==============================] - 122s 73ms/step - loss: 1.3844 - accuracy: 0.3183 - val_loss: 1.3769 - val_accuracy: 0.4688\n",
      "Epoch 22/30\n",
      "1670/1670 [==============================] - 128s 77ms/step - loss: 1.3842 - accuracy: 0.3234 - val_loss: 1.3769 - val_accuracy: 0.4688\n",
      "Epoch 23/30\n",
      "1670/1670 [==============================] - 122s 73ms/step - loss: 1.3842 - accuracy: 0.3200 - val_loss: 1.3769 - val_accuracy: 0.4688\n",
      "Epoch 24/30\n",
      "1670/1670 [==============================] - 135s 81ms/step - loss: 1.3842 - accuracy: 0.3219 - val_loss: 1.3769 - val_accuracy: 0.4688\n",
      "Epoch 25/30\n",
      "1670/1670 [==============================] - 126s 75ms/step - loss: 1.3843 - accuracy: 0.3236 - val_loss: 1.3769 - val_accuracy: 0.4688\n",
      "Epoch 26/30\n",
      "1670/1670 [==============================] - 129s 77ms/step - loss: 1.3842 - accuracy: 0.3232 - val_loss: 1.3769 - val_accuracy: 0.4688\n",
      "Epoch 27/30\n",
      "1670/1670 [==============================] - 131s 79ms/step - loss: 1.3842 - accuracy: 0.3226 - val_loss: 1.3769 - val_accuracy: 0.4688\n",
      "Epoch 28/30\n",
      "1670/1670 [==============================] - 138s 82ms/step - loss: 1.3842 - accuracy: 0.3225 - val_loss: 1.3769 - val_accuracy: 0.4688\n",
      "Epoch 29/30\n",
      "1670/1670 [==============================] - 123s 74ms/step - loss: 1.3842 - accuracy: 0.3227 - val_loss: 1.3769 - val_accuracy: 0.4688\n",
      "Epoch 30/30\n",
      "1670/1670 [==============================] - 132s 79ms/step - loss: 1.3842 - accuracy: 0.3210 - val_loss: 1.3769 - val_accuracy: 0.4688\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_83484.0_images_False_newWeights_True_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.292355\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.0100703  0.01042871 0.00845964 0.00986537]\n",
      "Training octnet for 0.01% of train size (aka 834 images) with pretrained: True and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 23 trainable: 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      " 5/17 [=======>......................] - ETA: 5s - loss: 5.2859 - accuracy: 0.3643WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0303s vs `on_train_batch_begin` time: 0.1504s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0303s vs `on_train_batch_end` time: 0.1558s). Check your callbacks.\n",
      "17/17 [==============================] - 5s 222ms/step - loss: 5.0206 - accuracy: 0.3959 - val_loss: 318.4433 - val_accuracy: 0.4375\n",
      "Epoch 2/30\n",
      " 1/17 [>.............................] - ETA: 0s - loss: 3.5229 - accuracy: 0.4200"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 1s 55ms/step - loss: 3.0557 - accuracy: 0.4760 - val_loss: 46.2738 - val_accuracy: 0.5000\n",
      "Epoch 3/30\n",
      "17/17 [==============================] - 1s 52ms/step - loss: 2.3023 - accuracy: 0.4932 - val_loss: 8.4291 - val_accuracy: 0.5625\n",
      "Epoch 4/30\n",
      "17/17 [==============================] - 2s 113ms/step - loss: 1.9427 - accuracy: 0.5307 - val_loss: 10.2791 - val_accuracy: 0.5000\n",
      "Epoch 5/30\n",
      "17/17 [==============================] - 2s 106ms/step - loss: 1.5005 - accuracy: 0.5772 - val_loss: 2.5704 - val_accuracy: 0.6562\n",
      "Epoch 6/30\n",
      "17/17 [==============================] - 2s 97ms/step - loss: 1.4162 - accuracy: 0.6345 - val_loss: 3.1853 - val_accuracy: 0.5625\n",
      "Epoch 7/30\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.2218 - accuracy: 0.6656 - val_loss: 2.4467 - val_accuracy: 0.6250\n",
      "Epoch 8/30\n",
      "17/17 [==============================] - 2s 92ms/step - loss: 1.0794 - accuracy: 0.7006 - val_loss: 2.7258 - val_accuracy: 0.5312\n",
      "Epoch 9/30\n",
      "17/17 [==============================] - 1s 50ms/step - loss: 0.9815 - accuracy: 0.7125 - val_loss: 1.7677 - val_accuracy: 0.5625\n",
      "Epoch 10/30\n",
      "17/17 [==============================] - 1s 48ms/step - loss: 0.9155 - accuracy: 0.7306 - val_loss: 1.9379 - val_accuracy: 0.6250\n",
      "Epoch 11/30\n",
      "17/17 [==============================] - 1s 54ms/step - loss: 0.9216 - accuracy: 0.7012 - val_loss: 1.9715 - val_accuracy: 0.5000\n",
      "Epoch 12/30\n",
      "17/17 [==============================] - 1s 52ms/step - loss: 0.8368 - accuracy: 0.7031 - val_loss: 1.6153 - val_accuracy: 0.5312\n",
      "Epoch 13/30\n",
      "17/17 [==============================] - 1s 53ms/step - loss: 0.7154 - accuracy: 0.7523 - val_loss: 1.4897 - val_accuracy: 0.5625\n",
      "Epoch 14/30\n",
      "17/17 [==============================] - 1s 52ms/step - loss: 0.6478 - accuracy: 0.8163 - val_loss: 1.8649 - val_accuracy: 0.5312\n",
      "Epoch 15/30\n",
      "17/17 [==============================] - 1s 53ms/step - loss: 0.7312 - accuracy: 0.7527 - val_loss: 1.2550 - val_accuracy: 0.5938\n",
      "Epoch 16/30\n",
      "17/17 [==============================] - 1s 54ms/step - loss: 0.6923 - accuracy: 0.7688 - val_loss: 1.2131 - val_accuracy: 0.5938\n",
      "Epoch 17/30\n",
      "17/17 [==============================] - 1s 54ms/step - loss: 0.6047 - accuracy: 0.7680 - val_loss: 1.1235 - val_accuracy: 0.6250\n",
      "Epoch 18/30\n",
      "17/17 [==============================] - 1s 50ms/step - loss: 0.6955 - accuracy: 0.7681 - val_loss: 1.2402 - val_accuracy: 0.5625\n",
      "Epoch 19/30\n",
      "17/17 [==============================] - 1s 49ms/step - loss: 0.5451 - accuracy: 0.8150 - val_loss: 1.0970 - val_accuracy: 0.6562\n",
      "Epoch 20/30\n",
      "17/17 [==============================] - 1s 56ms/step - loss: 0.5706 - accuracy: 0.7868 - val_loss: 1.2222 - val_accuracy: 0.5938\n",
      "Epoch 21/30\n",
      "17/17 [==============================] - 1s 58ms/step - loss: 0.5642 - accuracy: 0.7895 - val_loss: 1.0670 - val_accuracy: 0.6250\n",
      "Epoch 22/30\n",
      "17/17 [==============================] - 1s 66ms/step - loss: 0.6118 - accuracy: 0.7789 - val_loss: 1.0384 - val_accuracy: 0.6250\n",
      "Epoch 23/30\n",
      "17/17 [==============================] - 1s 51ms/step - loss: 0.5089 - accuracy: 0.8189 - val_loss: 1.1324 - val_accuracy: 0.6250\n",
      "Epoch 24/30\n",
      "17/17 [==============================] - 1s 65ms/step - loss: 0.5142 - accuracy: 0.8233 - val_loss: 1.1847 - val_accuracy: 0.6250\n",
      "Epoch 25/30\n",
      "17/17 [==============================] - 1s 49ms/step - loss: 0.5454 - accuracy: 0.7981 - val_loss: 1.2945 - val_accuracy: 0.5938\n",
      "Epoch 26/30\n",
      "17/17 [==============================] - 1s 55ms/step - loss: 0.5428 - accuracy: 0.8279 - val_loss: 1.1817 - val_accuracy: 0.6250\n",
      "Epoch 27/30\n",
      "17/17 [==============================] - 1s 56ms/step - loss: 0.5065 - accuracy: 0.8113 - val_loss: 1.0228 - val_accuracy: 0.6250\n",
      "Epoch 28/30\n",
      "17/17 [==============================] - 1s 50ms/step - loss: 0.5515 - accuracy: 0.8170 - val_loss: 1.1586 - val_accuracy: 0.6250\n",
      "Epoch 29/30\n",
      "17/17 [==============================] - 1s 48ms/step - loss: 0.4470 - accuracy: 0.8549 - val_loss: 1.2249 - val_accuracy: 0.6250\n",
      "Epoch 30/30\n",
      "17/17 [==============================] - 1s 51ms/step - loss: 0.4915 - accuracy: 0.8285 - val_loss: 1.1144 - val_accuracy: 0.6562\n",
      "INFO:tensorflow:Assets written to: ../octnet/octnet_30epochs_834.84_images_False_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for octnet: 0.620868\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training resnet for 0.01% of train size (aka 834 images) with pretrained: True and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 178 trainable: 178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      " 6/17 [=========>....................] - ETA: 8s - loss: 1.3739 - accuracy: 0.4416 WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1362s vs `on_train_batch_begin` time: 0.1694s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1362s vs `on_train_batch_end` time: 0.3396s). Check your callbacks.\n",
      "17/17 [==============================] - 18s 508ms/step - loss: 1.3582 - accuracy: 0.5368 - val_loss: 1.3857 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "17/17 [==============================] - 4s 222ms/step - loss: 1.3147 - accuracy: 0.6834 - val_loss: 1.3911 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "17/17 [==============================] - 4s 228ms/step - loss: 1.3003 - accuracy: 0.6906 - val_loss: 1.3944 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "17/17 [==============================] - 3s 203ms/step - loss: 1.2661 - accuracy: 0.7697 - val_loss: 1.3960 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "17/17 [==============================] - 4s 206ms/step - loss: 1.2555 - accuracy: 0.7458 - val_loss: 1.3562 - val_accuracy: 0.4375\n",
      "Epoch 6/30\n",
      "17/17 [==============================] - 4s 216ms/step - loss: 1.2425 - accuracy: 0.7473 - val_loss: 1.3424 - val_accuracy: 0.4375\n",
      "Epoch 7/30\n",
      "17/17 [==============================] - 4s 239ms/step - loss: 1.2255 - accuracy: 0.7663 - val_loss: 1.3225 - val_accuracy: 0.5000\n",
      "Epoch 8/30\n",
      "17/17 [==============================] - 4s 244ms/step - loss: 1.2145 - accuracy: 0.7639 - val_loss: 1.3500 - val_accuracy: 0.4062\n",
      "Epoch 9/30\n",
      "17/17 [==============================] - 4s 248ms/step - loss: 1.2004 - accuracy: 0.7775 - val_loss: 1.3161 - val_accuracy: 0.5000\n",
      "Epoch 10/30\n",
      "17/17 [==============================] - 4s 239ms/step - loss: 1.1784 - accuracy: 0.8086 - val_loss: 1.3196 - val_accuracy: 0.5000\n",
      "Epoch 11/30\n",
      "17/17 [==============================] - 4s 240ms/step - loss: 1.1831 - accuracy: 0.7747 - val_loss: 1.3180 - val_accuracy: 0.5000\n",
      "Epoch 12/30\n",
      "17/17 [==============================] - 4s 255ms/step - loss: 1.1690 - accuracy: 0.7879 - val_loss: 1.3248 - val_accuracy: 0.5000\n",
      "Epoch 13/30\n",
      "17/17 [==============================] - 4s 233ms/step - loss: 1.1633 - accuracy: 0.7829 - val_loss: 1.3158 - val_accuracy: 0.5000\n",
      "Epoch 14/30\n",
      "17/17 [==============================] - 4s 245ms/step - loss: 1.1591 - accuracy: 0.7860 - val_loss: 1.3062 - val_accuracy: 0.5000\n",
      "Epoch 15/30\n",
      "17/17 [==============================] - 3s 204ms/step - loss: 1.1769 - accuracy: 0.7400 - val_loss: 1.3135 - val_accuracy: 0.5000\n",
      "Epoch 16/30\n",
      "17/17 [==============================] - 4s 253ms/step - loss: 1.1510 - accuracy: 0.7767 - val_loss: 1.3077 - val_accuracy: 0.5000\n",
      "Epoch 17/30\n",
      "17/17 [==============================] - 4s 251ms/step - loss: 1.1443 - accuracy: 0.7836 - val_loss: 1.3076 - val_accuracy: 0.5000\n",
      "Epoch 18/30\n",
      "17/17 [==============================] - 4s 265ms/step - loss: 1.1496 - accuracy: 0.7616 - val_loss: 1.3037 - val_accuracy: 0.5000\n",
      "Epoch 19/30\n",
      "17/17 [==============================] - 4s 223ms/step - loss: 1.1369 - accuracy: 0.7821 - val_loss: 1.3088 - val_accuracy: 0.5000\n",
      "Epoch 20/30\n",
      "17/17 [==============================] - 4s 236ms/step - loss: 1.1302 - accuracy: 0.7896 - val_loss: 1.2981 - val_accuracy: 0.5000\n",
      "Epoch 21/30\n",
      "17/17 [==============================] - 4s 243ms/step - loss: 1.1402 - accuracy: 0.7629 - val_loss: 1.2998 - val_accuracy: 0.5000\n",
      "Epoch 22/30\n",
      "17/17 [==============================] - 4s 245ms/step - loss: 1.1305 - accuracy: 0.7827 - val_loss: 1.3216 - val_accuracy: 0.4688\n",
      "Epoch 23/30\n",
      "17/17 [==============================] - 4s 242ms/step - loss: 1.1244 - accuracy: 0.7824 - val_loss: 1.2915 - val_accuracy: 0.5000\n",
      "Epoch 24/30\n",
      "17/17 [==============================] - 4s 242ms/step - loss: 1.1270 - accuracy: 0.7831 - val_loss: 1.2910 - val_accuracy: 0.5000\n",
      "Epoch 25/30\n",
      "17/17 [==============================] - 4s 257ms/step - loss: 1.1154 - accuracy: 0.7915 - val_loss: 1.2826 - val_accuracy: 0.5000\n",
      "Epoch 26/30\n",
      "17/17 [==============================] - 4s 254ms/step - loss: 1.1222 - accuracy: 0.7846 - val_loss: 1.2821 - val_accuracy: 0.5000\n",
      "Epoch 27/30\n",
      "17/17 [==============================] - 4s 251ms/step - loss: 1.1279 - accuracy: 0.7639 - val_loss: 1.2813 - val_accuracy: 0.5000\n",
      "Epoch 28/30\n",
      "17/17 [==============================] - 4s 236ms/step - loss: 1.1126 - accuracy: 0.7902 - val_loss: 1.2808 - val_accuracy: 0.5000\n",
      "Epoch 29/30\n",
      "17/17 [==============================] - 5s 265ms/step - loss: 1.1192 - accuracy: 0.7787 - val_loss: 1.2804 - val_accuracy: 0.5000\n",
      "Epoch 30/30\n",
      "17/17 [==============================] - 3s 200ms/step - loss: 1.1187 - accuracy: 0.7797 - val_loss: 1.2800 - val_accuracy: 0.5000\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_834.84_images_False_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.500000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.02496675 0.02607176 0.02264716 0.02356082]\n",
      "Training octnet for 0.025% of train size (aka 2087 images) with pretrained: True and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 23 trainable: 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      " 6/42 [===>..........................] - ETA: 15s - loss: 4.3418 - accuracy: 0.3148WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0239s vs `on_train_batch_begin` time: 0.1686s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0239s vs `on_train_batch_end` time: 0.1808s). Check your callbacks.\n",
      "42/42 [==============================] - 6s 107ms/step - loss: 3.4638 - accuracy: 0.4013 - val_loss: 45.4772 - val_accuracy: 0.2500\n",
      "Epoch 2/30\n",
      " 1/42 [..............................] - ETA: 1s - loss: 2.8157 - accuracy: 0.4800"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 2s 50ms/step - loss: 2.1051 - accuracy: 0.5212 - val_loss: 3.3377 - val_accuracy: 0.5312\n",
      "Epoch 3/30\n",
      "42/42 [==============================] - 2s 53ms/step - loss: 1.6342 - accuracy: 0.5678 - val_loss: 3.8592 - val_accuracy: 0.5000\n",
      "Epoch 4/30\n",
      "42/42 [==============================] - 2s 47ms/step - loss: 1.2076 - accuracy: 0.6327 - val_loss: 1.2763 - val_accuracy: 0.6250\n",
      "Epoch 5/30\n",
      "42/42 [==============================] - 2s 46ms/step - loss: 1.0034 - accuracy: 0.6749 - val_loss: 1.5897 - val_accuracy: 0.5625\n",
      "Epoch 6/30\n",
      "42/42 [==============================] - 2s 47ms/step - loss: 0.9540 - accuracy: 0.7149 - val_loss: 1.0304 - val_accuracy: 0.6250\n",
      "Epoch 7/30\n",
      "42/42 [==============================] - 2s 52ms/step - loss: 0.9487 - accuracy: 0.7068 - val_loss: 1.0389 - val_accuracy: 0.5312\n",
      "Epoch 8/30\n",
      "42/42 [==============================] - 2s 47ms/step - loss: 0.8156 - accuracy: 0.7202 - val_loss: 1.2009 - val_accuracy: 0.5312\n",
      "Epoch 9/30\n",
      "42/42 [==============================] - 2s 46ms/step - loss: 0.7568 - accuracy: 0.7452 - val_loss: 0.8059 - val_accuracy: 0.7188\n",
      "Epoch 10/30\n",
      "42/42 [==============================] - 2s 55ms/step - loss: 0.7543 - accuracy: 0.7440 - val_loss: 0.9002 - val_accuracy: 0.5938\n",
      "Epoch 11/30\n",
      "42/42 [==============================] - 2s 55ms/step - loss: 0.7131 - accuracy: 0.7551 - val_loss: 1.0733 - val_accuracy: 0.5938\n",
      "Epoch 12/30\n",
      "42/42 [==============================] - 2s 51ms/step - loss: 0.6713 - accuracy: 0.7662 - val_loss: 0.8928 - val_accuracy: 0.5625\n",
      "Epoch 13/30\n",
      "42/42 [==============================] - 2s 48ms/step - loss: 0.5787 - accuracy: 0.7986 - val_loss: 0.9346 - val_accuracy: 0.5625\n",
      "Epoch 14/30\n",
      "42/42 [==============================] - 2s 49ms/step - loss: 0.5971 - accuracy: 0.7866 - val_loss: 0.8528 - val_accuracy: 0.5938\n",
      "Epoch 15/30\n",
      "42/42 [==============================] - 2s 46ms/step - loss: 0.5234 - accuracy: 0.8105 - val_loss: 0.8479 - val_accuracy: 0.6250\n",
      "Epoch 16/30\n",
      "42/42 [==============================] - 2s 47ms/step - loss: 0.5041 - accuracy: 0.8154 - val_loss: 0.9298 - val_accuracy: 0.5625\n",
      "Epoch 17/30\n",
      "42/42 [==============================] - 2s 60ms/step - loss: 0.5583 - accuracy: 0.7953 - val_loss: 0.8583 - val_accuracy: 0.6250\n",
      "Epoch 18/30\n",
      "42/42 [==============================] - 3s 74ms/step - loss: 0.4857 - accuracy: 0.8278 - val_loss: 0.8720 - val_accuracy: 0.6250\n",
      "Epoch 19/30\n",
      "42/42 [==============================] - 2s 49ms/step - loss: 0.5202 - accuracy: 0.8075 - val_loss: 0.8047 - val_accuracy: 0.6250\n",
      "Epoch 20/30\n",
      "42/42 [==============================] - 2s 49ms/step - loss: 0.4440 - accuracy: 0.8334 - val_loss: 0.6996 - val_accuracy: 0.6562\n",
      "Epoch 21/30\n",
      "42/42 [==============================] - 2s 47ms/step - loss: 0.4644 - accuracy: 0.8324 - val_loss: 0.8624 - val_accuracy: 0.6250\n",
      "Epoch 22/30\n",
      "42/42 [==============================] - 2s 47ms/step - loss: 0.4483 - accuracy: 0.8308 - val_loss: 0.7952 - val_accuracy: 0.6250\n",
      "Epoch 23/30\n",
      "42/42 [==============================] - 2s 51ms/step - loss: 0.4229 - accuracy: 0.8440 - val_loss: 0.7841 - val_accuracy: 0.6250\n",
      "Epoch 24/30\n",
      "42/42 [==============================] - 2s 54ms/step - loss: 0.4271 - accuracy: 0.8383 - val_loss: 0.7335 - val_accuracy: 0.6562\n",
      "Epoch 25/30\n",
      "42/42 [==============================] - 2s 57ms/step - loss: 0.4516 - accuracy: 0.8411 - val_loss: 0.7973 - val_accuracy: 0.6562\n",
      "Epoch 26/30\n",
      "42/42 [==============================] - 4s 107ms/step - loss: 0.3754 - accuracy: 0.8593 - val_loss: 0.7438 - val_accuracy: 0.6562\n",
      "Epoch 27/30\n",
      "42/42 [==============================] - 4s 95ms/step - loss: 0.4063 - accuracy: 0.8469 - val_loss: 0.7708 - val_accuracy: 0.6562\n",
      "Epoch 28/30\n",
      "42/42 [==============================] - 4s 100ms/step - loss: 0.3817 - accuracy: 0.8549 - val_loss: 0.7888 - val_accuracy: 0.6562\n",
      "Epoch 29/30\n",
      "42/42 [==============================] - 3s 82ms/step - loss: 0.4065 - accuracy: 0.8373 - val_loss: 0.8252 - val_accuracy: 0.6250\n",
      "Epoch 30/30\n",
      "42/42 [==============================] - 4s 98ms/step - loss: 0.3848 - accuracy: 0.8544 - val_loss: 0.7707 - val_accuracy: 0.6562\n",
      "INFO:tensorflow:Assets written to: ../octnet/octnet_30epochs_2087.1_images_False_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for octnet: 0.675620\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training resnet for 0.025% of train size (aka 2087 images) with pretrained: True and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 178 trainable: 178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      " 6/42 [===>..........................] - ETA: 30s - loss: 1.3873 - accuracy: 0.070 - ETA: 25s - loss: 1.3857 - accuracy: 0.0985WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1159s vs `on_train_batch_begin` time: 0.1556s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1159s vs `on_train_batch_end` time: 0.3364s). Check your callbacks.\n",
      "42/42 [==============================] - 22s 328ms/step - loss: 1.3601 - accuracy: 0.4384 - val_loss: 1.3901 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "42/42 [==============================] - 10s 238ms/step - loss: 1.2958 - accuracy: 0.7072 - val_loss: 1.3891 - val_accuracy: 0.3750\n",
      "Epoch 3/30\n",
      "42/42 [==============================] - 10s 234ms/step - loss: 1.2466 - accuracy: 0.7373 - val_loss: 1.3691 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "42/42 [==============================] - 9s 215ms/step - loss: 1.2077 - accuracy: 0.7511 - val_loss: 1.3127 - val_accuracy: 0.5000\n",
      "Epoch 5/30\n",
      "42/42 [==============================] - 9s 210ms/step - loss: 1.1752 - accuracy: 0.7537 - val_loss: 1.4103 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "42/42 [==============================] - 10s 243ms/step - loss: 1.1483 - accuracy: 0.7613 - val_loss: 1.3150 - val_accuracy: 0.5000\n",
      "Epoch 7/30\n",
      "42/42 [==============================] - 9s 209ms/step - loss: 1.1284 - accuracy: 0.7617 - val_loss: 1.3148 - val_accuracy: 0.5000\n",
      "Epoch 8/30\n",
      "42/42 [==============================] - 9s 215ms/step - loss: 1.1062 - accuracy: 0.7665 - val_loss: 1.3380 - val_accuracy: 0.4375\n",
      "Epoch 9/30\n",
      "42/42 [==============================] - 9s 209ms/step - loss: 1.0769 - accuracy: 0.7747 - val_loss: 1.2779 - val_accuracy: 0.5000\n",
      "Epoch 10/30\n",
      "42/42 [==============================] - 9s 208ms/step - loss: 1.0619 - accuracy: 0.7714 - val_loss: 1.2676 - val_accuracy: 0.5000\n",
      "Epoch 11/30\n",
      "42/42 [==============================] - 10s 227ms/step - loss: 1.0427 - accuracy: 0.7680 - val_loss: 1.2640 - val_accuracy: 0.5000\n",
      "Epoch 12/30\n",
      "42/42 [==============================] - 9s 219ms/step - loss: 1.0285 - accuracy: 0.7661 - val_loss: 1.2598 - val_accuracy: 0.5000\n",
      "Epoch 13/30\n",
      "42/42 [==============================] - 9s 203ms/step - loss: 1.0162 - accuracy: 0.7706 - val_loss: 1.2222 - val_accuracy: 0.5000\n",
      "Epoch 14/30\n",
      "42/42 [==============================] - 9s 203ms/step - loss: 0.9970 - accuracy: 0.7756 - val_loss: 1.1957 - val_accuracy: 0.5000\n",
      "Epoch 15/30\n",
      "42/42 [==============================] - 9s 205ms/step - loss: 0.9877 - accuracy: 0.7687 - val_loss: 1.2590 - val_accuracy: 0.5000\n",
      "Epoch 16/30\n",
      "42/42 [==============================] - 9s 206ms/step - loss: 0.9688 - accuracy: 0.7736 - val_loss: 1.2486 - val_accuracy: 0.5000\n",
      "Epoch 17/30\n",
      "42/42 [==============================] - 9s 206ms/step - loss: 0.9610 - accuracy: 0.7705 - val_loss: 1.2369 - val_accuracy: 0.5000\n",
      "Epoch 18/30\n",
      "42/42 [==============================] - 10s 238ms/step - loss: 0.9654 - accuracy: 0.7705 - val_loss: 1.1960 - val_accuracy: 0.5000\n",
      "Epoch 19/30\n",
      "42/42 [==============================] - 9s 204ms/step - loss: 0.9515 - accuracy: 0.7688 - val_loss: 1.1424 - val_accuracy: 0.5000\n",
      "Epoch 20/30\n",
      "42/42 [==============================] - 9s 204ms/step - loss: 0.9247 - accuracy: 0.7787 - val_loss: 1.1221 - val_accuracy: 0.5000\n",
      "Epoch 21/30\n",
      "42/42 [==============================] - 9s 205ms/step - loss: 0.9264 - accuracy: 0.7692 - val_loss: 1.1264 - val_accuracy: 0.5000\n",
      "Epoch 22/30\n",
      "42/42 [==============================] - 9s 211ms/step - loss: 0.9216 - accuracy: 0.7645 - val_loss: 1.0995 - val_accuracy: 0.5000\n",
      "Epoch 23/30\n",
      "42/42 [==============================] - 9s 212ms/step - loss: 0.9101 - accuracy: 0.7739 - val_loss: 1.0814 - val_accuracy: 0.5000\n",
      "Epoch 24/30\n",
      "42/42 [==============================] - 9s 217ms/step - loss: 0.8932 - accuracy: 0.7798 - val_loss: 1.0694 - val_accuracy: 0.5000\n",
      "Epoch 25/30\n",
      "42/42 [==============================] - 9s 218ms/step - loss: 0.8764 - accuracy: 0.7994 - val_loss: 1.0873 - val_accuracy: 0.5000\n",
      "Epoch 26/30\n",
      "42/42 [==============================] - 9s 211ms/step - loss: 0.8746 - accuracy: 0.7892 - val_loss: 1.0739 - val_accuracy: 0.5000\n",
      "Epoch 27/30\n",
      "42/42 [==============================] - 9s 226ms/step - loss: 0.8952 - accuracy: 0.7636 - val_loss: 1.1059 - val_accuracy: 0.5000\n",
      "Epoch 28/30\n",
      "42/42 [==============================] - 9s 206ms/step - loss: 0.8870 - accuracy: 0.7694 - val_loss: 1.0631 - val_accuracy: 0.5000\n",
      "Epoch 29/30\n",
      "42/42 [==============================] - 9s 207ms/step - loss: 0.8738 - accuracy: 0.7789 - val_loss: 1.0620 - val_accuracy: 0.5000\n",
      "Epoch 30/30\n",
      "42/42 [==============================] - 9s 204ms/step - loss: 0.8678 - accuracy: 0.7930 - val_loss: 1.0457 - val_accuracy: 0.5000\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_2087.1_images_False_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.497934\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.05050352 0.04929445 0.05137469 0.04967502]\n",
      "Training octnet for 0.05% of train size (aka 4174 images) with pretrained: True and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 23 trainable: 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      " 6/84 [=>............................] - ETA: 32s - loss: 5.0313 - accuracy: 0.3022WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0445s vs `on_train_batch_begin` time: 0.1493s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0445s vs `on_train_batch_end` time: 0.1628s). Check your callbacks.\n",
      "84/84 [==============================] - 11s 121ms/step - loss: 3.7618 - accuracy: 0.4074 - val_loss: 6.2877 - val_accuracy: 0.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "84/84 [==============================] - 7s 79ms/step - loss: 2.1358 - accuracy: 0.5359 - val_loss: 1.4827 - val_accuracy: 0.5312\n",
      "Epoch 3/30\n",
      "84/84 [==============================] - 6s 69ms/step - loss: 1.6199 - accuracy: 0.5980 - val_loss: 1.3654 - val_accuracy: 0.4688\n",
      "Epoch 4/30\n",
      "84/84 [==============================] - 7s 84ms/step - loss: 1.2633 - accuracy: 0.6415 - val_loss: 0.8872 - val_accuracy: 0.5938\n",
      "Epoch 5/30\n",
      "84/84 [==============================] - 4s 47ms/step - loss: 1.0619 - accuracy: 0.6754 - val_loss: 0.8995 - val_accuracy: 0.5938\n",
      "Epoch 6/30\n",
      "84/84 [==============================] - 5s 55ms/step - loss: 0.9540 - accuracy: 0.6976 - val_loss: 0.8923 - val_accuracy: 0.6250\n",
      "Epoch 7/30\n",
      "84/84 [==============================] - 4s 48ms/step - loss: 0.9036 - accuracy: 0.7228 - val_loss: 0.9268 - val_accuracy: 0.6562\n",
      "Epoch 8/30\n",
      "84/84 [==============================] - 4s 48ms/step - loss: 0.8432 - accuracy: 0.7238 - val_loss: 0.9088 - val_accuracy: 0.6562\n",
      "Epoch 9/30\n",
      "84/84 [==============================] - 4s 44ms/step - loss: 0.7627 - accuracy: 0.7476 - val_loss: 0.8518 - val_accuracy: 0.6562\n",
      "Epoch 10/30\n",
      "84/84 [==============================] - 4s 50ms/step - loss: 0.6738 - accuracy: 0.7717 - val_loss: 0.8925 - val_accuracy: 0.7188\n",
      "Epoch 11/30\n",
      "84/84 [==============================] - 7s 82ms/step - loss: 0.6692 - accuracy: 0.7788 - val_loss: 0.7532 - val_accuracy: 0.6562\n",
      "Epoch 12/30\n",
      "84/84 [==============================] - 5s 54ms/step - loss: 0.6132 - accuracy: 0.7880 - val_loss: 0.8922 - val_accuracy: 0.6875\n",
      "Epoch 13/30\n",
      "84/84 [==============================] - 7s 89ms/step - loss: 0.5996 - accuracy: 0.8012 - val_loss: 0.8354 - val_accuracy: 0.7188\n",
      "Epoch 14/30\n",
      "84/84 [==============================] - 7s 79ms/step - loss: 0.5245 - accuracy: 0.8140 - val_loss: 0.8191 - val_accuracy: 0.6875\n",
      "Epoch 15/30\n",
      "84/84 [==============================] - 6s 66ms/step - loss: 0.5356 - accuracy: 0.8070 - val_loss: 0.7752 - val_accuracy: 0.7500\n",
      "Epoch 16/30\n",
      "84/84 [==============================] - 4s 53ms/step - loss: 0.5375 - accuracy: 0.7965 - val_loss: 0.9179 - val_accuracy: 0.6875\n",
      "Epoch 17/30\n",
      "84/84 [==============================] - 5s 63ms/step - loss: 0.5071 - accuracy: 0.8185 - val_loss: 0.7598 - val_accuracy: 0.6875\n",
      "Epoch 18/30\n",
      "84/84 [==============================] - 4s 48ms/step - loss: 0.4829 - accuracy: 0.8276 - val_loss: 0.8131 - val_accuracy: 0.7188\n",
      "Epoch 19/30\n",
      "84/84 [==============================] - 4s 49ms/step - loss: 0.4822 - accuracy: 0.8276 - val_loss: 0.7875 - val_accuracy: 0.6875\n",
      "Epoch 20/30\n",
      "84/84 [==============================] - 4s 50ms/step - loss: 0.4396 - accuracy: 0.8415 - val_loss: 0.7479 - val_accuracy: 0.6875\n",
      "Epoch 21/30\n",
      "84/84 [==============================] - 4s 47ms/step - loss: 0.4361 - accuracy: 0.8368 - val_loss: 0.7795 - val_accuracy: 0.7188\n",
      "Epoch 22/30\n",
      "84/84 [==============================] - 6s 66ms/step - loss: 0.4368 - accuracy: 0.8391 - val_loss: 0.7735 - val_accuracy: 0.7500\n",
      "Epoch 23/30\n",
      "84/84 [==============================] - 4s 51ms/step - loss: 0.4397 - accuracy: 0.8470 - val_loss: 0.7611 - val_accuracy: 0.7188\n",
      "Epoch 24/30\n",
      "84/84 [==============================] - 4s 48ms/step - loss: 0.4176 - accuracy: 0.8526 - val_loss: 0.7624 - val_accuracy: 0.6875\n",
      "Epoch 25/30\n",
      "84/84 [==============================] - 4s 48ms/step - loss: 0.3945 - accuracy: 0.8557 - val_loss: 0.7716 - val_accuracy: 0.7188\n",
      "Epoch 26/30\n",
      "84/84 [==============================] - 4s 51ms/step - loss: 0.3826 - accuracy: 0.8631 - val_loss: 0.7621 - val_accuracy: 0.7500\n",
      "Epoch 27/30\n",
      "84/84 [==============================] - 6s 74ms/step - loss: 0.4033 - accuracy: 0.8508 - val_loss: 0.7719 - val_accuracy: 0.7188\n",
      "Epoch 28/30\n",
      "84/84 [==============================] - 4s 48ms/step - loss: 0.3581 - accuracy: 0.8706 - val_loss: 0.8050 - val_accuracy: 0.7188\n",
      "Epoch 29/30\n",
      "84/84 [==============================] - 4s 49ms/step - loss: 0.3715 - accuracy: 0.8681 - val_loss: 0.7605 - val_accuracy: 0.7500\n",
      "Epoch 30/30\n",
      "84/84 [==============================] - 4s 48ms/step - loss: 0.3868 - accuracy: 0.8626 - val_loss: 0.7827 - val_accuracy: 0.7188\n",
      "INFO:tensorflow:Assets written to: ../octnet/octnet_30epochs_4174.2_images_False_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for octnet: 0.743802\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training resnet for 0.05% of train size (aka 4174 images) with pretrained: True and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 178 trainable: 178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      " 6/84 [=>............................] - ETA: 56s - loss: 1.4054 - accuracy: 0.0452 WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1238s vs `on_train_batch_begin` time: 0.1575s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1238s vs `on_train_batch_end` time: 0.3456s). Check your callbacks.\n",
      "84/84 [==============================] - 34s 285ms/step - loss: 1.3781 - accuracy: 0.2847 - val_loss: 1.3923 - val_accuracy: 0.2812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "84/84 [==============================] - 18s 219ms/step - loss: 1.3010 - accuracy: 0.5460 - val_loss: 1.3468 - val_accuracy: 0.5000\n",
      "Epoch 3/30\n",
      "84/84 [==============================] - 18s 212ms/step - loss: 1.2172 - accuracy: 0.6897 - val_loss: 1.4292 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "84/84 [==============================] - 17s 203ms/step - loss: 1.1599 - accuracy: 0.7033 - val_loss: 1.4484 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "84/84 [==============================] - 18s 215ms/step - loss: 1.1000 - accuracy: 0.7359 - val_loss: 1.2564 - val_accuracy: 0.5000\n",
      "Epoch 6/30\n",
      "84/84 [==============================] - 20s 232ms/step - loss: 1.0542 - accuracy: 0.7455 - val_loss: 1.3036 - val_accuracy: 0.4688\n",
      "Epoch 7/30\n",
      "84/84 [==============================] - 18s 212ms/step - loss: 1.0274 - accuracy: 0.7412 - val_loss: 1.2587 - val_accuracy: 0.5000\n",
      "Epoch 8/30\n",
      "84/84 [==============================] - 18s 217ms/step - loss: 0.9933 - accuracy: 0.7463 - val_loss: 1.2478 - val_accuracy: 0.5000\n",
      "Epoch 9/30\n",
      "84/84 [==============================] - 19s 226ms/step - loss: 0.9479 - accuracy: 0.7452 - val_loss: 1.2558 - val_accuracy: 0.5000\n",
      "Epoch 10/30\n",
      "84/84 [==============================] - 17s 204ms/step - loss: 0.9226 - accuracy: 0.7463 - val_loss: 1.2085 - val_accuracy: 0.5000\n",
      "Epoch 11/30\n",
      "84/84 [==============================] - 20s 234ms/step - loss: 0.9071 - accuracy: 0.7586 - val_loss: 1.1832 - val_accuracy: 0.5625\n",
      "Epoch 12/30\n",
      "84/84 [==============================] - 20s 243ms/step - loss: 0.8643 - accuracy: 0.8362 - val_loss: 1.0637 - val_accuracy: 0.7500\n",
      "Epoch 13/30\n",
      "84/84 [==============================] - 18s 213ms/step - loss: 0.8527 - accuracy: 0.8384 - val_loss: 1.0715 - val_accuracy: 0.7188\n",
      "Epoch 14/30\n",
      "84/84 [==============================] - 20s 235ms/step - loss: 0.8274 - accuracy: 0.8470 - val_loss: 1.1798 - val_accuracy: 0.6562\n",
      "Epoch 15/30\n",
      "84/84 [==============================] - 20s 239ms/step - loss: 0.8194 - accuracy: 0.8480 - val_loss: 1.0148 - val_accuracy: 0.7500\n",
      "Epoch 16/30\n",
      "84/84 [==============================] - 20s 240ms/step - loss: 0.8081 - accuracy: 0.8500 - val_loss: 1.0998 - val_accuracy: 0.6875\n",
      "Epoch 17/30\n",
      "84/84 [==============================] - 20s 239ms/step - loss: 0.8043 - accuracy: 0.8488 - val_loss: 0.9992 - val_accuracy: 0.7500\n",
      "Epoch 18/30\n",
      "84/84 [==============================] - 20s 234ms/step - loss: 0.7853 - accuracy: 0.8507 - val_loss: 1.0102 - val_accuracy: 0.7188\n",
      "Epoch 19/30\n",
      "84/84 [==============================] - 18s 215ms/step - loss: 0.7690 - accuracy: 0.8542 - val_loss: 1.2114 - val_accuracy: 0.5312\n",
      "Epoch 20/30\n",
      "84/84 [==============================] - 20s 236ms/step - loss: 0.7485 - accuracy: 0.8638 - val_loss: 0.9761 - val_accuracy: 0.7500\n",
      "Epoch 21/30\n",
      "84/84 [==============================] - 19s 222ms/step - loss: 0.7648 - accuracy: 0.8486 - val_loss: 1.0217 - val_accuracy: 0.7188\n",
      "Epoch 22/30\n",
      "84/84 [==============================] - 19s 225ms/step - loss: 0.7398 - accuracy: 0.8604 - val_loss: 0.9117 - val_accuracy: 0.7500\n",
      "Epoch 23/30\n",
      "84/84 [==============================] - 18s 217ms/step - loss: 0.7419 - accuracy: 0.8576 - val_loss: 1.0183 - val_accuracy: 0.6875\n",
      "Epoch 24/30\n",
      "84/84 [==============================] - 20s 236ms/step - loss: 0.7239 - accuracy: 0.8761 - val_loss: 0.9823 - val_accuracy: 0.7188\n",
      "Epoch 25/30\n",
      "84/84 [==============================] - 20s 233ms/step - loss: 0.7221 - accuracy: 0.8685 - val_loss: 0.9376 - val_accuracy: 0.7500\n",
      "Epoch 26/30\n",
      "84/84 [==============================] - 19s 228ms/step - loss: 0.7165 - accuracy: 0.8648 - val_loss: 0.9403 - val_accuracy: 0.7188\n",
      "Epoch 27/30\n",
      "84/84 [==============================] - 19s 231ms/step - loss: 0.6977 - accuracy: 0.8745 - val_loss: 0.9701 - val_accuracy: 0.7188\n",
      "Epoch 28/30\n",
      "84/84 [==============================] - 20s 238ms/step - loss: 0.6957 - accuracy: 0.8783 - val_loss: 0.9812 - val_accuracy: 0.7188\n",
      "Epoch 29/30\n",
      "84/84 [==============================] - 19s 224ms/step - loss: 0.6924 - accuracy: 0.8749 - val_loss: 0.9633 - val_accuracy: 0.7188\n",
      "Epoch 30/30\n",
      "84/84 [==============================] - 18s 219ms/step - loss: 0.6779 - accuracy: 0.8789 - val_loss: 0.9468 - val_accuracy: 0.7188\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_4174.2_images_False_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.743802\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.07573627 0.07464051 0.07543179 0.07370009]\n",
      "Training octnet for 0.075% of train size (aka 6261 images) with pretrained: True and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 23 trainable: 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/126 [>.............................] - ETA: 53s - loss: 4.3299 - accuracy: 0.3179 WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0335s vs `on_train_batch_begin` time: 0.1826s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0335s vs `on_train_batch_end` time: 0.1635s). Check your callbacks.\n",
      "126/126 [==============================] - 13s 96ms/step - loss: 3.2435 - accuracy: 0.4347 - val_loss: 5.2126 - val_accuracy: 0.4688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "126/126 [==============================] - 6s 45ms/step - loss: 1.6448 - accuracy: 0.5989 - val_loss: 1.5292 - val_accuracy: 0.5000\n",
      "Epoch 3/30\n",
      "126/126 [==============================] - 8s 66ms/step - loss: 1.2546 - accuracy: 0.6492 - val_loss: 0.8138 - val_accuracy: 0.6562\n",
      "Epoch 4/30\n",
      "126/126 [==============================] - 9s 75ms/step - loss: 0.9956 - accuracy: 0.6901 - val_loss: 0.7687 - val_accuracy: 0.6562\n",
      "Epoch 5/30\n",
      "126/126 [==============================] - 9s 74ms/step - loss: 0.8760 - accuracy: 0.7112 - val_loss: 1.2120 - val_accuracy: 0.5625\n",
      "Epoch 6/30\n",
      "126/126 [==============================] - 10s 81ms/step - loss: 0.7479 - accuracy: 0.7506 - val_loss: 0.7160 - val_accuracy: 0.7500\n",
      "Epoch 7/30\n",
      "126/126 [==============================] - 8s 64ms/step - loss: 0.6996 - accuracy: 0.7560 - val_loss: 0.5904 - val_accuracy: 0.7500\n",
      "Epoch 8/30\n",
      "126/126 [==============================] - 7s 55ms/step - loss: 0.6003 - accuracy: 0.7849 - val_loss: 0.7184 - val_accuracy: 0.7500\n",
      "Epoch 9/30\n",
      "126/126 [==============================] - 7s 53ms/step - loss: 0.5758 - accuracy: 0.7958 - val_loss: 0.6170 - val_accuracy: 0.7500\n",
      "Epoch 10/30\n",
      "126/126 [==============================] - 9s 69ms/step - loss: 0.5637 - accuracy: 0.7992 - val_loss: 0.6416 - val_accuracy: 0.7500\n",
      "Epoch 11/30\n",
      "126/126 [==============================] - 6s 48ms/step - loss: 0.5175 - accuracy: 0.8110 - val_loss: 0.6951 - val_accuracy: 0.7188\n",
      "Epoch 12/30\n",
      "126/126 [==============================] - 6s 49ms/step - loss: 0.5030 - accuracy: 0.8199 - val_loss: 0.6469 - val_accuracy: 0.7188\n",
      "Epoch 13/30\n",
      "126/126 [==============================] - 6s 47ms/step - loss: 0.4926 - accuracy: 0.8223 - val_loss: 0.7085 - val_accuracy: 0.7188\n",
      "Epoch 14/30\n",
      "126/126 [==============================] - 6s 48ms/step - loss: 0.4734 - accuracy: 0.8286 - val_loss: 0.7681 - val_accuracy: 0.6875\n",
      "Epoch 15/30\n",
      "126/126 [==============================] - 7s 54ms/step - loss: 0.4685 - accuracy: 0.8352 - val_loss: 0.6129 - val_accuracy: 0.7188\n",
      "Epoch 16/30\n",
      "126/126 [==============================] - 6s 52ms/step - loss: 0.4400 - accuracy: 0.8395 - val_loss: 0.5208 - val_accuracy: 0.7812\n",
      "Epoch 17/30\n",
      "126/126 [==============================] - 6s 46ms/step - loss: 0.4178 - accuracy: 0.8461 - val_loss: 0.5878 - val_accuracy: 0.7500\n",
      "Epoch 18/30\n",
      "126/126 [==============================] - 8s 67ms/step - loss: 0.4246 - accuracy: 0.8559 - val_loss: 0.7201 - val_accuracy: 0.7812\n",
      "Epoch 19/30\n",
      "126/126 [==============================] - 6s 45ms/step - loss: 0.3957 - accuracy: 0.8506 - val_loss: 0.6722 - val_accuracy: 0.7500\n",
      "Epoch 20/30\n",
      "126/126 [==============================] - 6s 47ms/step - loss: 0.3541 - accuracy: 0.8695 - val_loss: 0.6094 - val_accuracy: 0.7188\n",
      "Epoch 21/30\n",
      "126/126 [==============================] - 10s 79ms/step - loss: 0.3791 - accuracy: 0.8640 - val_loss: 0.6016 - val_accuracy: 0.7812\n",
      "Epoch 22/30\n",
      "126/126 [==============================] - 9s 68ms/step - loss: 0.3789 - accuracy: 0.8681 - val_loss: 0.6320 - val_accuracy: 0.7500\n",
      "Epoch 23/30\n",
      "126/126 [==============================] - 6s 45ms/step - loss: 0.3603 - accuracy: 0.8729 - val_loss: 0.5806 - val_accuracy: 0.7812\n",
      "Epoch 24/30\n",
      "126/126 [==============================] - 8s 60ms/step - loss: 0.3391 - accuracy: 0.8767 - val_loss: 0.5420 - val_accuracy: 0.7812\n",
      "Epoch 25/30\n",
      "126/126 [==============================] - 10s 79ms/step - loss: 0.3481 - accuracy: 0.8777 - val_loss: 0.5715 - val_accuracy: 0.7812\n",
      "Epoch 26/30\n",
      "126/126 [==============================] - 7s 56ms/step - loss: 0.3171 - accuracy: 0.8896 - val_loss: 0.5653 - val_accuracy: 0.7812\n",
      "Epoch 27/30\n",
      "126/126 [==============================] - 8s 63ms/step - loss: 0.3297 - accuracy: 0.8799 - val_loss: 0.6068 - val_accuracy: 0.7812\n",
      "Epoch 28/30\n",
      "126/126 [==============================] - 6s 45ms/step - loss: 0.3273 - accuracy: 0.8851 - val_loss: 0.5917 - val_accuracy: 0.7812\n",
      "Epoch 29/30\n",
      "126/126 [==============================] - 6s 46ms/step - loss: 0.3035 - accuracy: 0.8922 - val_loss: 0.5831 - val_accuracy: 0.7812\n",
      "Epoch 30/30\n",
      "126/126 [==============================] - 9s 73ms/step - loss: 0.2994 - accuracy: 0.8897 - val_loss: 0.6175 - val_accuracy: 0.7812\n",
      "INFO:tensorflow:Assets written to: ../octnet/octnet_30epochs_6261.3_images_False_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for octnet: 0.790289\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training resnet for 0.075% of train size (aka 6261 images) with pretrained: True and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 178 trainable: 178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/126 [>.............................] - ETA: 1:23 - loss: 1.3637 - accuracy: 0.3547WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1215s vs `on_train_batch_begin` time: 0.1600s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1215s vs `on_train_batch_end` time: 0.3245s). Check your callbacks.\n",
      "126/126 [==============================] - 39s 246ms/step - loss: 1.3282 - accuracy: 0.5940 - val_loss: 1.3246 - val_accuracy: 0.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "126/126 [==============================] - 27s 214ms/step - loss: 1.1919 - accuracy: 0.7482 - val_loss: 1.3163 - val_accuracy: 0.5000\n",
      "Epoch 3/30\n",
      "126/126 [==============================] - 28s 225ms/step - loss: 1.1117 - accuracy: 0.7384 - val_loss: 1.2931 - val_accuracy: 0.5000\n",
      "Epoch 4/30\n",
      "126/126 [==============================] - 28s 219ms/step - loss: 1.0281 - accuracy: 0.7374 - val_loss: 1.1331 - val_accuracy: 0.5000\n",
      "Epoch 5/30\n",
      "126/126 [==============================] - 27s 215ms/step - loss: 0.9617 - accuracy: 0.7373 - val_loss: 1.2518 - val_accuracy: 0.4375\n",
      "Epoch 6/30\n",
      "126/126 [==============================] - 26s 207ms/step - loss: 0.8945 - accuracy: 0.8029 - val_loss: 1.1759 - val_accuracy: 0.4688\n",
      "Epoch 7/30\n",
      "126/126 [==============================] - 29s 229ms/step - loss: 0.8433 - accuracy: 0.8288 - val_loss: 0.9190 - val_accuracy: 0.7500\n",
      "Epoch 8/30\n",
      "126/126 [==============================] - 29s 232ms/step - loss: 0.7859 - accuracy: 0.8375 - val_loss: 0.8978 - val_accuracy: 0.7188\n",
      "Epoch 9/30\n",
      "126/126 [==============================] - 29s 234ms/step - loss: 0.7533 - accuracy: 0.8549 - val_loss: 0.9166 - val_accuracy: 0.7188\n",
      "Epoch 10/30\n",
      "126/126 [==============================] - 29s 233ms/step - loss: 0.7244 - accuracy: 0.8524 - val_loss: 0.8754 - val_accuracy: 0.7188\n",
      "Epoch 11/30\n",
      "126/126 [==============================] - 29s 228ms/step - loss: 0.7159 - accuracy: 0.8436 - val_loss: 0.8573 - val_accuracy: 0.7188\n",
      "Epoch 12/30\n",
      "126/126 [==============================] - 28s 221ms/step - loss: 0.6801 - accuracy: 0.8543 - val_loss: 0.7960 - val_accuracy: 0.7500\n",
      "Epoch 13/30\n",
      "126/126 [==============================] - 28s 222ms/step - loss: 0.6510 - accuracy: 0.8635 - val_loss: 0.8217 - val_accuracy: 0.7188\n",
      "Epoch 14/30\n",
      "126/126 [==============================] - 28s 225ms/step - loss: 0.6359 - accuracy: 0.8630 - val_loss: 0.7668 - val_accuracy: 0.7500\n",
      "Epoch 15/30\n",
      "126/126 [==============================] - 28s 219ms/step - loss: 0.6093 - accuracy: 0.8733 - val_loss: 0.7996 - val_accuracy: 0.7188\n",
      "Epoch 16/30\n",
      "126/126 [==============================] - 27s 212ms/step - loss: 0.6128 - accuracy: 0.8620 - val_loss: 0.7442 - val_accuracy: 0.7500\n",
      "Epoch 17/30\n",
      "126/126 [==============================] - 27s 213ms/step - loss: 0.5933 - accuracy: 0.8710 - val_loss: 0.7373 - val_accuracy: 0.7500\n",
      "Epoch 18/30\n",
      "126/126 [==============================] - 27s 217ms/step - loss: 0.5767 - accuracy: 0.8782 - val_loss: 0.7273 - val_accuracy: 0.7500\n",
      "Epoch 19/30\n",
      "126/126 [==============================] - 28s 220ms/step - loss: 0.5605 - accuracy: 0.8779 - val_loss: 0.7198 - val_accuracy: 0.7500\n",
      "Epoch 20/30\n",
      "126/126 [==============================] - 27s 213ms/step - loss: 0.5652 - accuracy: 0.8747 - val_loss: 0.7133 - val_accuracy: 0.7500\n",
      "Epoch 21/30\n",
      "126/126 [==============================] - 27s 212ms/step - loss: 0.5606 - accuracy: 0.8779 - val_loss: 0.7075 - val_accuracy: 0.7500\n",
      "Epoch 22/30\n",
      "126/126 [==============================] - 28s 220ms/step - loss: 0.5368 - accuracy: 0.8808 - val_loss: 0.7039 - val_accuracy: 0.7500\n",
      "Epoch 23/30\n",
      "126/126 [==============================] - 28s 219ms/step - loss: 0.5338 - accuracy: 0.8819 - val_loss: 0.7066 - val_accuracy: 0.7500\n",
      "Epoch 24/30\n",
      "126/126 [==============================] - 27s 215ms/step - loss: 0.5332 - accuracy: 0.8763 - val_loss: 0.6935 - val_accuracy: 0.7500\n",
      "Epoch 25/30\n",
      "126/126 [==============================] - 26s 208ms/step - loss: 0.5368 - accuracy: 0.8748 - val_loss: 0.6899 - val_accuracy: 0.7500\n",
      "Epoch 26/30\n",
      "126/126 [==============================] - 27s 214ms/step - loss: 0.5253 - accuracy: 0.8786 - val_loss: 0.7366 - val_accuracy: 0.7500\n",
      "Epoch 27/30\n",
      "126/126 [==============================] - 28s 223ms/step - loss: 0.5058 - accuracy: 0.8864 - val_loss: 0.6838 - val_accuracy: 0.7500\n",
      "Epoch 28/30\n",
      "126/126 [==============================] - 27s 218ms/step - loss: 0.5164 - accuracy: 0.8783 - val_loss: 0.6807 - val_accuracy: 0.7500\n",
      "Epoch 29/30\n",
      "126/126 [==============================] - 27s 213ms/step - loss: 0.5075 - accuracy: 0.8813 - val_loss: 0.6792 - val_accuracy: 0.7500\n",
      "Epoch 30/30\n",
      "126/126 [==============================] - 26s 207ms/step - loss: 0.5087 - accuracy: 0.8850 - val_loss: 0.6764 - val_accuracy: 0.7500\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_6261.3_images_False_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.743802\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.09158275 0.08899341 0.08970744 0.08983287]\n",
      "Training octnet for 0.09% of train size (aka 7513 images) with pretrained: True and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 23 trainable: 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/151 [>.............................] - ETA: 59s - loss: 4.4406 - accuracy: 0.3797 WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0321s vs `on_train_batch_begin` time: 0.1608s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0321s vs `on_train_batch_end` time: 0.1583s). Check your callbacks.\n",
      "151/151 [==============================] - 10s 60ms/step - loss: 3.0532 - accuracy: 0.4574 - val_loss: 2.8340 - val_accuracy: 0.5000\n",
      "Epoch 2/30\n",
      "  1/151 [..............................] - ETA: 6s - loss: 1.7603 - accuracy: 0.5000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151/151 [==============================] - 7s 46ms/step - loss: 1.4581 - accuracy: 0.6066 - val_loss: 1.2523 - val_accuracy: 0.5625\n",
      "Epoch 3/30\n",
      "151/151 [==============================] - 7s 50ms/step - loss: 1.0593 - accuracy: 0.6858 - val_loss: 0.7803 - val_accuracy: 0.6875\n",
      "Epoch 4/30\n",
      "151/151 [==============================] - 8s 53ms/step - loss: 0.8524 - accuracy: 0.7140 - val_loss: 0.8309 - val_accuracy: 0.6562\n",
      "Epoch 5/30\n",
      "151/151 [==============================] - 8s 50ms/step - loss: 0.6889 - accuracy: 0.7536 - val_loss: 0.8343 - val_accuracy: 0.6875\n",
      "Epoch 6/30\n",
      "151/151 [==============================] - 7s 46ms/step - loss: 0.6550 - accuracy: 0.7745 - val_loss: 0.8151 - val_accuracy: 0.7188\n",
      "Epoch 7/30\n",
      "151/151 [==============================] - 7s 47ms/step - loss: 0.6030 - accuracy: 0.7821 - val_loss: 0.4865 - val_accuracy: 0.8125\n",
      "Epoch 8/30\n",
      "151/151 [==============================] - 7s 45ms/step - loss: 0.5509 - accuracy: 0.8054 - val_loss: 0.4704 - val_accuracy: 0.8125\n",
      "Epoch 9/30\n",
      "151/151 [==============================] - 11s 74ms/step - loss: 0.5143 - accuracy: 0.8256 - val_loss: 0.5321 - val_accuracy: 0.8125\n",
      "Epoch 10/30\n",
      "151/151 [==============================] - 7s 46ms/step - loss: 0.4736 - accuracy: 0.8252 - val_loss: 0.6677 - val_accuracy: 0.7812\n",
      "Epoch 11/30\n",
      "151/151 [==============================] - 7s 45ms/step - loss: 0.4514 - accuracy: 0.8362 - val_loss: 0.6598 - val_accuracy: 0.7812\n",
      "Epoch 12/30\n",
      "151/151 [==============================] - 8s 52ms/step - loss: 0.4182 - accuracy: 0.8439 - val_loss: 0.4528 - val_accuracy: 0.8125\n",
      "Epoch 13/30\n",
      "151/151 [==============================] - 7s 49ms/step - loss: 0.3906 - accuracy: 0.8619 - val_loss: 0.4627 - val_accuracy: 0.8438\n",
      "Epoch 14/30\n",
      "151/151 [==============================] - 7s 48ms/step - loss: 0.3683 - accuracy: 0.8711 - val_loss: 0.4952 - val_accuracy: 0.8125\n",
      "Epoch 15/30\n",
      "151/151 [==============================] - 8s 52ms/step - loss: 0.3518 - accuracy: 0.8855 - val_loss: 0.6497 - val_accuracy: 0.7812\n",
      "Epoch 16/30\n",
      "151/151 [==============================] - 7s 48ms/step - loss: 0.3591 - accuracy: 0.8591 - val_loss: 0.5349 - val_accuracy: 0.8125\n",
      "Epoch 17/30\n",
      "151/151 [==============================] - 7s 48ms/step - loss: 0.3427 - accuracy: 0.8753 - val_loss: 0.4648 - val_accuracy: 0.8438\n",
      "Epoch 18/30\n",
      "151/151 [==============================] - 8s 56ms/step - loss: 0.3113 - accuracy: 0.8902 - val_loss: 0.5113 - val_accuracy: 0.8125\n",
      "Epoch 19/30\n",
      "151/151 [==============================] - 7s 47ms/step - loss: 0.2897 - accuracy: 0.8993 - val_loss: 0.4662 - val_accuracy: 0.8438\n",
      "Epoch 20/30\n",
      "151/151 [==============================] - 7s 48ms/step - loss: 0.2915 - accuracy: 0.8947 - val_loss: 0.5438 - val_accuracy: 0.8125\n",
      "Epoch 21/30\n",
      "151/151 [==============================] - 7s 47ms/step - loss: 0.2801 - accuracy: 0.8973 - val_loss: 0.5495 - val_accuracy: 0.8125\n",
      "Epoch 22/30\n",
      "151/151 [==============================] - 8s 52ms/step - loss: 0.2717 - accuracy: 0.9055 - val_loss: 0.5557 - val_accuracy: 0.8125\n",
      "Epoch 23/30\n",
      "151/151 [==============================] - 11s 70ms/step - loss: 0.2718 - accuracy: 0.8993 - val_loss: 0.4908 - val_accuracy: 0.8125\n",
      "Epoch 24/30\n",
      "151/151 [==============================] - 8s 51ms/step - loss: 0.2456 - accuracy: 0.9151 - val_loss: 0.5093 - val_accuracy: 0.8125\n",
      "Epoch 25/30\n",
      "151/151 [==============================] - 8s 50ms/step - loss: 0.2469 - accuracy: 0.9117 - val_loss: 0.5384 - val_accuracy: 0.8125\n",
      "Epoch 26/30\n",
      "151/151 [==============================] - 7s 48ms/step - loss: 0.2286 - accuracy: 0.9111 - val_loss: 0.5164 - val_accuracy: 0.8438\n",
      "Epoch 27/30\n",
      "151/151 [==============================] - 7s 48ms/step - loss: 0.2308 - accuracy: 0.9219 - val_loss: 0.5499 - val_accuracy: 0.8438\n",
      "Epoch 28/30\n",
      "151/151 [==============================] - 7s 46ms/step - loss: 0.2154 - accuracy: 0.9251 - val_loss: 0.4944 - val_accuracy: 0.8438\n",
      "Epoch 29/30\n",
      "151/151 [==============================] - 7s 48ms/step - loss: 0.2201 - accuracy: 0.9218 - val_loss: 0.5861 - val_accuracy: 0.7812\n",
      "Epoch 30/30\n",
      "151/151 [==============================] - 7s 45ms/step - loss: 0.2259 - accuracy: 0.9171 - val_loss: 0.5740 - val_accuracy: 0.7812\n",
      "INFO:tensorflow:Assets written to: ../octnet/octnet_30epochs_7513.5599999999995_images_False_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for octnet: 0.877066\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training resnet for 0.09% of train size (aka 7513 images) with pretrained: True and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 178 trainable: 178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/151 [>.............................] - ETA: 2:48 - loss: 1.3923 - accuracy: 0.1811WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1425s vs `on_train_batch_begin` time: 0.1894s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1425s vs `on_train_batch_end` time: 0.6687s). Check your callbacks.\n",
      "151/151 [==============================] - 50s 275ms/step - loss: 1.3388 - accuracy: 0.5392 - val_loss: 1.3027 - val_accuracy: 0.4062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "151/151 [==============================] - 32s 214ms/step - loss: 1.1677 - accuracy: 0.7351 - val_loss: 1.3106 - val_accuracy: 0.5000\n",
      "Epoch 3/30\n",
      "151/151 [==============================] - 33s 219ms/step - loss: 1.0428 - accuracy: 0.7581 - val_loss: 1.2470 - val_accuracy: 0.5625\n",
      "Epoch 4/30\n",
      "151/151 [==============================] - 32s 210ms/step - loss: 0.9541 - accuracy: 0.8329 - val_loss: 1.2772 - val_accuracy: 0.4688\n",
      "Epoch 5/30\n",
      "151/151 [==============================] - 33s 219ms/step - loss: 0.8827 - accuracy: 0.8452 - val_loss: 1.5085 - val_accuracy: 0.3750\n",
      "Epoch 6/30\n",
      "151/151 [==============================] - 32s 214ms/step - loss: 0.8210 - accuracy: 0.8432 - val_loss: 1.2187 - val_accuracy: 0.6562\n",
      "Epoch 7/30\n",
      "151/151 [==============================] - 34s 223ms/step - loss: 0.7602 - accuracy: 0.8524 - val_loss: 0.9691 - val_accuracy: 0.7188\n",
      "Epoch 8/30\n",
      "151/151 [==============================] - 33s 218ms/step - loss: 0.7203 - accuracy: 0.8594 - val_loss: 0.8944 - val_accuracy: 0.7188\n",
      "Epoch 9/30\n",
      "151/151 [==============================] - 31s 205ms/step - loss: 0.7082 - accuracy: 0.8496 - val_loss: 0.8476 - val_accuracy: 0.7500\n",
      "Epoch 10/30\n",
      "151/151 [==============================] - 32s 210ms/step - loss: 0.6739 - accuracy: 0.8556 - val_loss: 0.7996 - val_accuracy: 0.7500\n",
      "Epoch 11/30\n",
      "151/151 [==============================] - 31s 207ms/step - loss: 0.6336 - accuracy: 0.8681 - val_loss: 1.0743 - val_accuracy: 0.5625\n",
      "Epoch 12/30\n",
      "151/151 [==============================] - 31s 206ms/step - loss: 0.6193 - accuracy: 0.8612 - val_loss: 0.8132 - val_accuracy: 0.7188\n",
      "Epoch 13/30\n",
      "151/151 [==============================] - 33s 216ms/step - loss: 0.5912 - accuracy: 0.8701 - val_loss: 0.7429 - val_accuracy: 0.7500\n",
      "Epoch 14/30\n",
      "151/151 [==============================] - 31s 208ms/step - loss: 0.5719 - accuracy: 0.8732 - val_loss: 0.7801 - val_accuracy: 0.7188\n",
      "Epoch 15/30\n",
      "151/151 [==============================] - 32s 212ms/step - loss: 0.5692 - accuracy: 0.8661 - val_loss: 0.7160 - val_accuracy: 0.7500\n",
      "Epoch 16/30\n",
      "151/151 [==============================] - 32s 209ms/step - loss: 0.5385 - accuracy: 0.8749 - val_loss: 0.7316 - val_accuracy: 0.7188\n",
      "Epoch 17/30\n",
      "151/151 [==============================] - 33s 216ms/step - loss: 0.5357 - accuracy: 0.8757 - val_loss: 0.7082 - val_accuracy: 0.7188\n",
      "Epoch 18/30\n",
      "151/151 [==============================] - 34s 225ms/step - loss: 0.5306 - accuracy: 0.8723 - val_loss: 0.7429 - val_accuracy: 0.7188\n",
      "Epoch 19/30\n",
      "151/151 [==============================] - 34s 225ms/step - loss: 0.5099 - accuracy: 0.8779 - val_loss: 0.7354 - val_accuracy: 0.7188\n",
      "Epoch 20/30\n",
      "151/151 [==============================] - 34s 228ms/step - loss: 0.5064 - accuracy: 0.8790 - val_loss: 0.6754 - val_accuracy: 0.7500\n",
      "Epoch 21/30\n",
      "151/151 [==============================] - 32s 213ms/step - loss: 0.4978 - accuracy: 0.8792 - val_loss: 0.7022 - val_accuracy: 0.7188\n",
      "Epoch 22/30\n",
      "151/151 [==============================] - 34s 226ms/step - loss: 0.4820 - accuracy: 0.8829 - val_loss: 0.6598 - val_accuracy: 0.7500\n",
      "Epoch 23/30\n",
      "151/151 [==============================] - 34s 227ms/step - loss: 0.4828 - accuracy: 0.8804 - val_loss: 0.6603 - val_accuracy: 0.7500\n",
      "Epoch 24/30\n",
      "151/151 [==============================] - 32s 214ms/step - loss: 0.4763 - accuracy: 0.8821 - val_loss: 0.6697 - val_accuracy: 0.7188\n",
      "Epoch 25/30\n",
      "151/151 [==============================] - 34s 222ms/step - loss: 0.4700 - accuracy: 0.8886 - val_loss: 0.6797 - val_accuracy: 0.7188\n",
      "Epoch 26/30\n",
      "151/151 [==============================] - 32s 215ms/step - loss: 0.4835 - accuracy: 0.8718 - val_loss: 0.6452 - val_accuracy: 0.7500\n",
      "Epoch 27/30\n",
      "151/151 [==============================] - 33s 219ms/step - loss: 0.4534 - accuracy: 0.8922 - val_loss: 0.6410 - val_accuracy: 0.7500\n",
      "Epoch 28/30\n",
      "151/151 [==============================] - 34s 225ms/step - loss: 0.4570 - accuracy: 0.8872 - val_loss: 0.6439 - val_accuracy: 0.7500\n",
      "Epoch 29/30\n",
      "151/151 [==============================] - 33s 219ms/step - loss: 0.4554 - accuracy: 0.8822 - val_loss: 0.6341 - val_accuracy: 0.7500\n",
      "Epoch 30/30\n",
      "151/151 [==============================] - 34s 225ms/step - loss: 0.4571 - accuracy: 0.8844 - val_loss: 0.6436 - val_accuracy: 0.7188\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_7513.5599999999995_images_False_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.743802\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.10089303 0.09931461 0.10028199 0.0998143 ]\n",
      "Training octnet for 0.1% of train size (aka 8348 images) with pretrained: True and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 23 trainable: 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/167 [>.............................] - ETA: 1:13 - loss: 5.1040 - accuracy: 0.3386WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0389s vs `on_train_batch_begin` time: 0.1643s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0389s vs `on_train_batch_end` time: 0.1929s). Check your callbacks.\n",
      "167/167 [==============================] - 13s 70ms/step - loss: 3.3377 - accuracy: 0.4528 - val_loss: 2.0155 - val_accuracy: 0.5625\n",
      "Epoch 2/30\n",
      "  1/167 [..............................] - ETA: 7s - loss: 1.5908 - accuracy: 0.6200"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "167/167 [==============================] - 8s 47ms/step - loss: 1.3914 - accuracy: 0.6165 - val_loss: 0.7702 - val_accuracy: 0.6562\n",
      "Epoch 3/30\n",
      "167/167 [==============================] - 14s 85ms/step - loss: 1.0250 - accuracy: 0.6816 - val_loss: 0.8202 - val_accuracy: 0.7500\n",
      "Epoch 4/30\n",
      "167/167 [==============================] - 9s 56ms/step - loss: 0.7679 - accuracy: 0.7337 - val_loss: 0.7134 - val_accuracy: 0.7188\n",
      "Epoch 5/30\n",
      "167/167 [==============================] - 8s 46ms/step - loss: 0.6893 - accuracy: 0.7546 - val_loss: 0.6121 - val_accuracy: 0.7500\n",
      "Epoch 6/30\n",
      "167/167 [==============================] - 9s 52ms/step - loss: 0.5900 - accuracy: 0.8017 - val_loss: 0.6744 - val_accuracy: 0.7812\n",
      "Epoch 7/30\n",
      "167/167 [==============================] - 8s 46ms/step - loss: 0.5549 - accuracy: 0.8020 - val_loss: 0.5402 - val_accuracy: 0.7812\n",
      "Epoch 8/30\n",
      "167/167 [==============================] - 8s 50ms/step - loss: 0.5212 - accuracy: 0.8155 - val_loss: 0.6068 - val_accuracy: 0.8125\n",
      "Epoch 9/30\n",
      "167/167 [==============================] - 13s 77ms/step - loss: 0.4542 - accuracy: 0.8367 - val_loss: 0.6194 - val_accuracy: 0.8125\n",
      "Epoch 10/30\n",
      "167/167 [==============================] - 14s 82ms/step - loss: 0.4414 - accuracy: 0.8452 - val_loss: 0.5349 - val_accuracy: 0.8125\n",
      "Epoch 11/30\n",
      "167/167 [==============================] - 10s 57ms/step - loss: 0.4069 - accuracy: 0.8555 - val_loss: 0.4576 - val_accuracy: 0.8438\n",
      "Epoch 12/30\n",
      "167/167 [==============================] - 14s 83ms/step - loss: 0.3807 - accuracy: 0.8614 - val_loss: 0.5081 - val_accuracy: 0.7812\n",
      "Epoch 13/30\n",
      "167/167 [==============================] - 10s 59ms/step - loss: 0.3569 - accuracy: 0.8661 - val_loss: 0.5416 - val_accuracy: 0.8438\n",
      "Epoch 14/30\n",
      "167/167 [==============================] - 9s 51ms/step - loss: 0.3404 - accuracy: 0.8781 - val_loss: 0.4166 - val_accuracy: 0.8438\n",
      "Epoch 15/30\n",
      "167/167 [==============================] - 8s 47ms/step - loss: 0.3072 - accuracy: 0.8845 - val_loss: 0.5165 - val_accuracy: 0.8125\n",
      "Epoch 16/30\n",
      "167/167 [==============================] - 9s 56ms/step - loss: 0.3079 - accuracy: 0.8884 - val_loss: 0.3619 - val_accuracy: 0.8750\n",
      "Epoch 17/30\n",
      "167/167 [==============================] - 8s 46ms/step - loss: 0.2868 - accuracy: 0.8943 - val_loss: 0.5202 - val_accuracy: 0.8750\n",
      "Epoch 18/30\n",
      "167/167 [==============================] - 8s 46ms/step - loss: 0.2617 - accuracy: 0.9079 - val_loss: 0.5205 - val_accuracy: 0.8438\n",
      "Epoch 19/30\n",
      "167/167 [==============================] - 8s 48ms/step - loss: 0.2597 - accuracy: 0.9078 - val_loss: 0.5193 - val_accuracy: 0.8750\n",
      "Epoch 20/30\n",
      "167/167 [==============================] - 8s 46ms/step - loss: 0.2533 - accuracy: 0.9098 - val_loss: 0.3676 - val_accuracy: 0.8750\n",
      "Epoch 21/30\n",
      "167/167 [==============================] - 8s 46ms/step - loss: 0.2279 - accuracy: 0.9151 - val_loss: 0.5607 - val_accuracy: 0.8750\n",
      "Epoch 22/30\n",
      "167/167 [==============================] - 9s 54ms/step - loss: 0.2172 - accuracy: 0.9217 - val_loss: 0.3931 - val_accuracy: 0.8750\n",
      "Epoch 23/30\n",
      "167/167 [==============================] - 9s 51ms/step - loss: 0.2113 - accuracy: 0.9217 - val_loss: 0.3938 - val_accuracy: 0.8750\n",
      "Epoch 24/30\n",
      "167/167 [==============================] - 11s 65ms/step - loss: 0.1981 - accuracy: 0.9277 - val_loss: 0.4806 - val_accuracy: 0.8750\n",
      "Epoch 25/30\n",
      "167/167 [==============================] - 9s 51ms/step - loss: 0.1882 - accuracy: 0.9306 - val_loss: 0.4862 - val_accuracy: 0.8750\n",
      "Epoch 26/30\n",
      "167/167 [==============================] - 8s 47ms/step - loss: 0.1958 - accuracy: 0.9318 - val_loss: 0.4434 - val_accuracy: 0.8750\n",
      "Epoch 27/30\n",
      "167/167 [==============================] - 8s 48ms/step - loss: 0.1848 - accuracy: 0.9355 - val_loss: 0.4648 - val_accuracy: 0.8750\n",
      "Epoch 28/30\n",
      "167/167 [==============================] - 8s 48ms/step - loss: 0.1773 - accuracy: 0.9370 - val_loss: 0.5132 - val_accuracy: 0.8750\n",
      "Epoch 29/30\n",
      "167/167 [==============================] - 9s 52ms/step - loss: 0.1603 - accuracy: 0.9426 - val_loss: 0.5601 - val_accuracy: 0.8750\n",
      "Epoch 30/30\n",
      "167/167 [==============================] - 8s 46ms/step - loss: 0.1770 - accuracy: 0.9343 - val_loss: 0.5145 - val_accuracy: 0.8750\n",
      "INFO:tensorflow:Assets written to: ../octnet/octnet_30epochs_8348.4_images_False_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for octnet: 0.871901\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training resnet for 0.1% of train size (aka 8348 images) with pretrained: True and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 178 trainable: 178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/167 [>.............................] - ETA: 1:54 - loss: 1.3942 - accuracy: 0.3326WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1258s vs `on_train_batch_begin` time: 0.1858s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1258s vs `on_train_batch_end` time: 0.3059s). Check your callbacks.\n",
      "167/167 [==============================] - 52s 263ms/step - loss: 1.3377 - accuracy: 0.5527 - val_loss: 1.3767 - val_accuracy: 0.3125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "167/167 [==============================] - 38s 228ms/step - loss: 1.1646 - accuracy: 0.7540 - val_loss: 1.2822 - val_accuracy: 0.5000\n",
      "Epoch 3/30\n",
      "167/167 [==============================] - 38s 229ms/step - loss: 1.0255 - accuracy: 0.7448 - val_loss: 1.3785 - val_accuracy: 0.4375\n",
      "Epoch 4/30\n",
      "167/167 [==============================] - 36s 215ms/step - loss: 0.9075 - accuracy: 0.8001 - val_loss: 1.0929 - val_accuracy: 0.6875\n",
      "Epoch 5/30\n",
      "167/167 [==============================] - 40s 237ms/step - loss: 0.8382 - accuracy: 0.8484 - val_loss: 1.0671 - val_accuracy: 0.5938\n",
      "Epoch 6/30\n",
      "167/167 [==============================] - 36s 215ms/step - loss: 0.7738 - accuracy: 0.8516 - val_loss: 0.8801 - val_accuracy: 0.7500\n",
      "Epoch 7/30\n",
      "167/167 [==============================] - 36s 213ms/step - loss: 0.7344 - accuracy: 0.8526 - val_loss: 0.9417 - val_accuracy: 0.7188\n",
      "Epoch 8/30\n",
      "167/167 [==============================] - 38s 229ms/step - loss: 0.6753 - accuracy: 0.8593 - val_loss: 0.8028 - val_accuracy: 0.7500\n",
      "Epoch 9/30\n",
      "167/167 [==============================] - 38s 230ms/step - loss: 0.6447 - accuracy: 0.8647 - val_loss: 0.7729 - val_accuracy: 0.7500\n",
      "Epoch 10/30\n",
      "167/167 [==============================] - 36s 216ms/step - loss: 0.6186 - accuracy: 0.8627 - val_loss: 0.9219 - val_accuracy: 0.7188\n",
      "Epoch 11/30\n",
      "167/167 [==============================] - 38s 225ms/step - loss: 0.5944 - accuracy: 0.8679 - val_loss: 0.7265 - val_accuracy: 0.7500\n",
      "Epoch 12/30\n",
      "167/167 [==============================] - 38s 226ms/step - loss: 0.5734 - accuracy: 0.8653 - val_loss: 0.7078 - val_accuracy: 0.7500\n",
      "Epoch 13/30\n",
      "167/167 [==============================] - 38s 230ms/step - loss: 0.5476 - accuracy: 0.8701 - val_loss: 0.6918 - val_accuracy: 0.7500\n",
      "Epoch 14/30\n",
      "167/167 [==============================] - 37s 222ms/step - loss: 0.5292 - accuracy: 0.8741 - val_loss: 0.6813 - val_accuracy: 0.7500\n",
      "Epoch 15/30\n",
      "167/167 [==============================] - 40s 239ms/step - loss: 0.5249 - accuracy: 0.8683 - val_loss: 0.6656 - val_accuracy: 0.7500\n",
      "Epoch 16/30\n",
      "167/167 [==============================] - 38s 229ms/step - loss: 0.5053 - accuracy: 0.8771 - val_loss: 0.6552 - val_accuracy: 0.7500\n",
      "Epoch 17/30\n",
      "167/167 [==============================] - 35s 211ms/step - loss: 0.4899 - accuracy: 0.8817 - val_loss: 0.6458 - val_accuracy: 0.7500\n",
      "Epoch 18/30\n",
      "167/167 [==============================] - 36s 215ms/step - loss: 0.4881 - accuracy: 0.8783 - val_loss: 0.6376 - val_accuracy: 0.7500\n",
      "Epoch 19/30\n",
      "167/167 [==============================] - 34s 206ms/step - loss: 0.4656 - accuracy: 0.8844 - val_loss: 0.6322 - val_accuracy: 0.7500\n",
      "Epoch 20/30\n",
      "167/167 [==============================] - 37s 219ms/step - loss: 0.4667 - accuracy: 0.8815 - val_loss: 0.6237 - val_accuracy: 0.7500\n",
      "Epoch 21/30\n",
      "167/167 [==============================] - 37s 223ms/step - loss: 0.4526 - accuracy: 0.8835 - val_loss: 0.6178 - val_accuracy: 0.7500\n",
      "Epoch 22/30\n",
      "167/167 [==============================] - 38s 227ms/step - loss: 0.4522 - accuracy: 0.8795 - val_loss: 0.6136 - val_accuracy: 0.7500\n",
      "Epoch 23/30\n",
      "167/167 [==============================] - 35s 212ms/step - loss: 0.4453 - accuracy: 0.8794 - val_loss: 0.6080 - val_accuracy: 0.7500\n",
      "Epoch 24/30\n",
      "167/167 [==============================] - 35s 209ms/step - loss: 0.4386 - accuracy: 0.8853 - val_loss: 0.6039 - val_accuracy: 0.7500\n",
      "Epoch 25/30\n",
      "167/167 [==============================] - 38s 225ms/step - loss: 0.4269 - accuracy: 0.8871 - val_loss: 0.6002 - val_accuracy: 0.7500\n",
      "Epoch 26/30\n",
      "167/167 [==============================] - 36s 215ms/step - loss: 0.4242 - accuracy: 0.8847 - val_loss: 0.5969 - val_accuracy: 0.7500\n",
      "Epoch 27/30\n",
      "167/167 [==============================] - 35s 209ms/step - loss: 0.4211 - accuracy: 0.8877 - val_loss: 0.5948 - val_accuracy: 0.7500\n",
      "Epoch 28/30\n",
      "167/167 [==============================] - 38s 227ms/step - loss: 0.4226 - accuracy: 0.8840 - val_loss: 0.5913 - val_accuracy: 0.7500\n",
      "Epoch 29/30\n",
      "167/167 [==============================] - 36s 218ms/step - loss: 0.4128 - accuracy: 0.8922 - val_loss: 0.5888 - val_accuracy: 0.7500\n",
      "Epoch 30/30\n",
      "167/167 [==============================] - 35s 212ms/step - loss: 0.4096 - accuracy: 0.8856 - val_loss: 0.5866 - val_accuracy: 0.7500\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_8348.4_images_False_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.747934\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.25251758 0.24784303 0.25484667 0.24524141]\n",
      "Training octnet for 0.25% of train size (aka 20871 images) with pretrained: True and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 23 trainable: 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/418 [..............................] - ETA: 2:39 - loss: 5.7111 - accuracy: 0.2292WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0286s vs `on_train_batch_begin` time: 0.1588s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0286s vs `on_train_batch_end` time: 0.1423s). Check your callbacks.\n",
      "418/418 [==============================] - 25s 58ms/step - loss: 2.6088 - accuracy: 0.5154 - val_loss: 0.9403 - val_accuracy: 0.5938\n",
      "Epoch 2/30\n",
      "  1/418 [..............................] - ETA: 20s - loss: 0.8983 - accuracy: 0.6200"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "418/418 [==============================] - 20s 48ms/step - loss: 0.9617 - accuracy: 0.7026 - val_loss: 0.7857 - val_accuracy: 0.5938\n",
      "Epoch 3/30\n",
      "418/418 [==============================] - 21s 51ms/step - loss: 0.6476 - accuracy: 0.7815 - val_loss: 0.8166 - val_accuracy: 0.7500\n",
      "Epoch 4/30\n",
      "418/418 [==============================] - 22s 52ms/step - loss: 0.5548 - accuracy: 0.8054 - val_loss: 0.5510 - val_accuracy: 0.7812\n",
      "Epoch 5/30\n",
      "418/418 [==============================] - 21s 51ms/step - loss: 0.4905 - accuracy: 0.8286 - val_loss: 0.5929 - val_accuracy: 0.7188\n",
      "Epoch 6/30\n",
      "418/418 [==============================] - 29s 69ms/step - loss: 0.4374 - accuracy: 0.8405 - val_loss: 0.4460 - val_accuracy: 0.7812\n",
      "Epoch 7/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 0.4139 - accuracy: 0.8568 - val_loss: 0.5130 - val_accuracy: 0.8438\n",
      "Epoch 8/30\n",
      "418/418 [==============================] - 32s 76ms/step - loss: 0.3783 - accuracy: 0.8637 - val_loss: 0.3981 - val_accuracy: 0.8125\n",
      "Epoch 9/30\n",
      "418/418 [==============================] - 26s 63ms/step - loss: 0.3402 - accuracy: 0.8813 - val_loss: 0.5376 - val_accuracy: 0.7812\n",
      "Epoch 10/30\n",
      "418/418 [==============================] - 24s 59ms/step - loss: 0.3245 - accuracy: 0.8878 - val_loss: 0.3314 - val_accuracy: 0.8438\n",
      "Epoch 11/30\n",
      "418/418 [==============================] - 22s 52ms/step - loss: 0.2876 - accuracy: 0.9012 - val_loss: 0.3693 - val_accuracy: 0.8125\n",
      "Epoch 12/30\n",
      "418/418 [==============================] - 26s 62ms/step - loss: 0.2739 - accuracy: 0.9049 - val_loss: 0.3348 - val_accuracy: 0.8125\n",
      "Epoch 13/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 0.2493 - accuracy: 0.9126 - val_loss: 0.3573 - val_accuracy: 0.8750\n",
      "Epoch 14/30\n",
      "418/418 [==============================] - 23s 54ms/step - loss: 0.2330 - accuracy: 0.9175 - val_loss: 0.2915 - val_accuracy: 0.8750\n",
      "Epoch 15/30\n",
      "418/418 [==============================] - 20s 47ms/step - loss: 0.2109 - accuracy: 0.9269 - val_loss: 0.3217 - val_accuracy: 0.9062\n",
      "Epoch 16/30\n",
      "418/418 [==============================] - 20s 49ms/step - loss: 0.1938 - accuracy: 0.9328 - val_loss: 0.3838 - val_accuracy: 0.8125\n",
      "Epoch 17/30\n",
      "418/418 [==============================] - 33s 80ms/step - loss: 0.1907 - accuracy: 0.9348 - val_loss: 0.3207 - val_accuracy: 0.8125\n",
      "Epoch 18/30\n",
      "418/418 [==============================] - 33s 78ms/step - loss: 0.1665 - accuracy: 0.9435 - val_loss: 0.3689 - val_accuracy: 0.8438\n",
      "Epoch 19/30\n",
      "418/418 [==============================] - 24s 56ms/step - loss: 0.1594 - accuracy: 0.9433 - val_loss: 0.4291 - val_accuracy: 0.8125\n",
      "Epoch 20/30\n",
      "418/418 [==============================] - 21s 51ms/step - loss: 0.1553 - accuracy: 0.9478 - val_loss: 0.2670 - val_accuracy: 0.9375\n",
      "Epoch 21/30\n",
      "418/418 [==============================] - 20s 48ms/step - loss: 0.1322 - accuracy: 0.9541 - val_loss: 0.2673 - val_accuracy: 0.9375\n",
      "Epoch 22/30\n",
      "418/418 [==============================] - 21s 50ms/step - loss: 0.1304 - accuracy: 0.9541 - val_loss: 0.3317 - val_accuracy: 0.8750\n",
      "Epoch 23/30\n",
      "418/418 [==============================] - 20s 49ms/step - loss: 0.1289 - accuracy: 0.9546 - val_loss: 0.2986 - val_accuracy: 0.9375\n",
      "Epoch 24/30\n",
      "418/418 [==============================] - 20s 47ms/step - loss: 0.1208 - accuracy: 0.9576 - val_loss: 0.2857 - val_accuracy: 0.9375\n",
      "Epoch 25/30\n",
      "418/418 [==============================] - 20s 47ms/step - loss: 0.1145 - accuracy: 0.9616 - val_loss: 0.3113 - val_accuracy: 0.9375\n",
      "Epoch 26/30\n",
      "418/418 [==============================] - 19s 46ms/step - loss: 0.1023 - accuracy: 0.9643 - val_loss: 0.2971 - val_accuracy: 0.9375\n",
      "Epoch 27/30\n",
      "418/418 [==============================] - 21s 51ms/step - loss: 0.1033 - accuracy: 0.9617 - val_loss: 0.3297 - val_accuracy: 0.9375\n",
      "Epoch 28/30\n",
      "418/418 [==============================] - 20s 47ms/step - loss: 0.0977 - accuracy: 0.9662 - val_loss: 0.4648 - val_accuracy: 0.8125\n",
      "Epoch 29/30\n",
      "418/418 [==============================] - 21s 50ms/step - loss: 0.0880 - accuracy: 0.9702 - val_loss: 0.4140 - val_accuracy: 0.8438\n",
      "Epoch 30/30\n",
      "418/418 [==============================] - 22s 52ms/step - loss: 0.0947 - accuracy: 0.9659 - val_loss: 0.3744 - val_accuracy: 0.8438\n",
      "INFO:tensorflow:Assets written to: ../octnet/octnet_30epochs_20871.0_images_False_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for octnet: 0.932851\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training resnet for 0.25% of train size (aka 20871 images) with pretrained: True and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 178 trainable: 178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/418 [..............................] - ETA: 4:34 - loss: 1.4107 - accuracy: 0.1093WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1195s vs `on_train_batch_begin` time: 0.1628s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1195s vs `on_train_batch_end` time: 0.2950s). Check your callbacks.\n",
      "418/418 [==============================] - 103s 226ms/step - loss: 1.2655 - accuracy: 0.6676 - val_loss: 1.4889 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "418/418 [==============================] - 91s 219ms/step - loss: 0.9857 - accuracy: 0.7499 - val_loss: 1.1538 - val_accuracy: 0.5000\n",
      "Epoch 3/30\n",
      "418/418 [==============================] - 90s 216ms/step - loss: 0.6881 - accuracy: 0.8793 - val_loss: 0.4961 - val_accuracy: 0.9688\n",
      "Epoch 4/30\n",
      "418/418 [==============================] - 90s 215ms/step - loss: 0.5219 - accuracy: 0.9133 - val_loss: 0.5821 - val_accuracy: 0.9062\n",
      "Epoch 5/30\n",
      "418/418 [==============================] - 89s 213ms/step - loss: 0.4112 - accuracy: 0.9315 - val_loss: 0.6163 - val_accuracy: 0.8750\n",
      "Epoch 6/30\n",
      "418/418 [==============================] - 92s 221ms/step - loss: 0.3617 - accuracy: 0.9367 - val_loss: 0.3390 - val_accuracy: 0.9375\n",
      "Epoch 7/30\n",
      "418/418 [==============================] - 91s 218ms/step - loss: 0.3250 - accuracy: 0.9379 - val_loss: 0.2009 - val_accuracy: 1.0000\n",
      "Epoch 8/30\n",
      "418/418 [==============================] - 88s 211ms/step - loss: 0.2709 - accuracy: 0.9521 - val_loss: 0.4356 - val_accuracy: 0.9062\n",
      "Epoch 9/30\n",
      "418/418 [==============================] - 89s 213ms/step - loss: 0.2587 - accuracy: 0.9505 - val_loss: 0.2098 - val_accuracy: 0.9688\n",
      "Epoch 10/30\n",
      "418/418 [==============================] - 90s 215ms/step - loss: 0.2337 - accuracy: 0.9554 - val_loss: 0.1399 - val_accuracy: 1.0000\n",
      "Epoch 11/30\n",
      "418/418 [==============================] - 90s 215ms/step - loss: 0.2091 - accuracy: 0.9604 - val_loss: 0.1476 - val_accuracy: 0.9688\n",
      "Epoch 12/30\n",
      "418/418 [==============================] - 94s 224ms/step - loss: 0.1867 - accuracy: 0.9664 - val_loss: 0.1259 - val_accuracy: 1.0000\n",
      "Epoch 13/30\n",
      "418/418 [==============================] - 91s 219ms/step - loss: 0.1718 - accuracy: 0.9692 - val_loss: 0.1129 - val_accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "418/418 [==============================] - 89s 212ms/step - loss: 0.1694 - accuracy: 0.9694 - val_loss: 0.0983 - val_accuracy: 1.0000\n",
      "Epoch 15/30\n",
      "418/418 [==============================] - 87s 209ms/step - loss: 0.1464 - accuracy: 0.9747 - val_loss: 0.1137 - val_accuracy: 0.9688\n",
      "Epoch 16/30\n",
      "418/418 [==============================] - 91s 218ms/step - loss: 0.1365 - accuracy: 0.9773 - val_loss: 0.0884 - val_accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "418/418 [==============================] - 97s 232ms/step - loss: 0.1346 - accuracy: 0.9777 - val_loss: 0.0813 - val_accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "418/418 [==============================] - 89s 214ms/step - loss: 0.1211 - accuracy: 0.9807 - val_loss: 0.1079 - val_accuracy: 0.9688\n",
      "Epoch 19/30\n",
      "418/418 [==============================] - 89s 213ms/step - loss: 0.1133 - accuracy: 0.9813 - val_loss: 0.0684 - val_accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "418/418 [==============================] - 93s 223ms/step - loss: 0.1079 - accuracy: 0.9831 - val_loss: 0.0671 - val_accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "418/418 [==============================] - 87s 209ms/step - loss: 0.1045 - accuracy: 0.9839 - val_loss: 0.0592 - val_accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "418/418 [==============================] - 91s 217ms/step - loss: 0.1012 - accuracy: 0.9849 - val_loss: 0.0601 - val_accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "418/418 [==============================] - 96s 230ms/step - loss: 0.0986 - accuracy: 0.9853 - val_loss: 0.0722 - val_accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "418/418 [==============================] - 93s 223ms/step - loss: 0.0907 - accuracy: 0.9874 - val_loss: 0.0537 - val_accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "418/418 [==============================] - 88s 210ms/step - loss: 0.0929 - accuracy: 0.9866 - val_loss: 0.0621 - val_accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "418/418 [==============================] - 91s 219ms/step - loss: 0.0855 - accuracy: 0.9882 - val_loss: 0.0589 - val_accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "418/418 [==============================] - 90s 215ms/step - loss: 0.0822 - accuracy: 0.9888 - val_loss: 0.0504 - val_accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "418/418 [==============================] - 90s 215ms/step - loss: 0.0825 - accuracy: 0.9886 - val_loss: 0.0614 - val_accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "418/418 [==============================] - 88s 210ms/step - loss: 0.0835 - accuracy: 0.9886 - val_loss: 0.0553 - val_accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "418/418 [==============================] - 92s 219ms/step - loss: 0.0812 - accuracy: 0.9885 - val_loss: 0.0569 - val_accuracy: 1.0000\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_20871.0_images_False_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.984504\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.40547216 0.3980379  0.40183292 0.38927577]\n",
      "Training octnet for 0.4% of train size (aka 33393 images) with pretrained: True and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 23 trainable: 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/668 [..............................] - ETA: 5:20 - loss: 5.3027 - accuracy: 0.3342WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0288s vs `on_train_batch_begin` time: 0.2198s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0288s vs `on_train_batch_end` time: 0.1622s). Check your callbacks.\n",
      "668/668 [==============================] - 40s 57ms/step - loss: 2.1368 - accuracy: 0.5618 - val_loss: 0.7552 - val_accuracy: 0.6562\n",
      "Epoch 2/30\n",
      "  1/668 [..............................] - ETA: 32s - loss: 0.9027 - accuracy: 0.6200"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "668/668 [==============================] - 32s 47ms/step - loss: 0.6799 - accuracy: 0.7604 - val_loss: 0.5562 - val_accuracy: 0.7188\n",
      "Epoch 3/30\n",
      "668/668 [==============================] - 39s 58ms/step - loss: 0.5147 - accuracy: 0.8185 - val_loss: 0.4522 - val_accuracy: 0.7188\n",
      "Epoch 4/30\n",
      "668/668 [==============================] - 37s 55ms/step - loss: 0.4419 - accuracy: 0.8442 - val_loss: 0.2299 - val_accuracy: 0.8438\n",
      "Epoch 5/30\n",
      "668/668 [==============================] - 36s 53ms/step - loss: 0.3676 - accuracy: 0.8692 - val_loss: 0.1074 - val_accuracy: 0.9688\n",
      "Epoch 6/30\n",
      "668/668 [==============================] - 31s 47ms/step - loss: 0.3234 - accuracy: 0.8914 - val_loss: 0.0737 - val_accuracy: 0.9688\n",
      "Epoch 7/30\n",
      "668/668 [==============================] - 33s 50ms/step - loss: 0.2913 - accuracy: 0.8997 - val_loss: 0.3673 - val_accuracy: 0.7812\n",
      "Epoch 8/30\n",
      "668/668 [==============================] - 33s 49ms/step - loss: 0.2662 - accuracy: 0.9082 - val_loss: 0.1175 - val_accuracy: 0.9375\n",
      "Epoch 9/30\n",
      "668/668 [==============================] - 36s 53ms/step - loss: 0.2446 - accuracy: 0.9178 - val_loss: 0.0830 - val_accuracy: 0.9688\n",
      "Epoch 10/30\n",
      "668/668 [==============================] - 32s 48ms/step - loss: 0.2169 - accuracy: 0.9279 - val_loss: 0.0871 - val_accuracy: 0.9688\n",
      "Epoch 11/30\n",
      "668/668 [==============================] - 31s 47ms/step - loss: 0.1920 - accuracy: 0.9356 - val_loss: 0.0311 - val_accuracy: 1.0000\n",
      "Epoch 12/30\n",
      "668/668 [==============================] - 32s 47ms/step - loss: 0.1713 - accuracy: 0.9418 - val_loss: 0.0675 - val_accuracy: 0.9688\n",
      "Epoch 13/30\n",
      "668/668 [==============================] - 32s 48ms/step - loss: 0.1554 - accuracy: 0.9455 - val_loss: 0.0314 - val_accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "668/668 [==============================] - 30s 46ms/step - loss: 0.1431 - accuracy: 0.9516 - val_loss: 0.0563 - val_accuracy: 0.9688\n",
      "Epoch 15/30\n",
      "668/668 [==============================] - 34s 51ms/step - loss: 0.1238 - accuracy: 0.9581 - val_loss: 0.0151 - val_accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "668/668 [==============================] - 33s 50ms/step - loss: 0.1216 - accuracy: 0.9588 - val_loss: 0.0133 - val_accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "668/668 [==============================] - 35s 52ms/step - loss: 0.1055 - accuracy: 0.9660 - val_loss: 0.0228 - val_accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "668/668 [==============================] - 32s 48ms/step - loss: 0.0959 - accuracy: 0.9677 - val_loss: 0.0145 - val_accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "668/668 [==============================] - 37s 56ms/step - loss: 0.0942 - accuracy: 0.9677 - val_loss: 0.0423 - val_accuracy: 0.9688\n",
      "Epoch 20/30\n",
      "668/668 [==============================] - 31s 46ms/step - loss: 0.0782 - accuracy: 0.9736 - val_loss: 0.0201 - val_accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "668/668 [==============================] - 33s 50ms/step - loss: 0.0710 - accuracy: 0.9765 - val_loss: 0.0074 - val_accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "668/668 [==============================] - 36s 53ms/step - loss: 0.0671 - accuracy: 0.9769 - val_loss: 0.0087 - val_accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "668/668 [==============================] - 33s 49ms/step - loss: 0.0656 - accuracy: 0.9778 - val_loss: 0.0088 - val_accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "668/668 [==============================] - 35s 52ms/step - loss: 0.0603 - accuracy: 0.9798 - val_loss: 0.0099 - val_accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "668/668 [==============================] - 33s 50ms/step - loss: 0.0615 - accuracy: 0.9786 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "668/668 [==============================] - 33s 50ms/step - loss: 0.0542 - accuracy: 0.9806 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "668/668 [==============================] - 31s 47ms/step - loss: 0.0500 - accuracy: 0.9823 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "668/668 [==============================] - 33s 50ms/step - loss: 0.0472 - accuracy: 0.9836 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "668/668 [==============================] - 39s 58ms/step - loss: 0.0495 - accuracy: 0.9840 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "668/668 [==============================] - 34s 51ms/step - loss: 0.0452 - accuracy: 0.9847 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
      "INFO:tensorflow:Assets written to: ../octnet/octnet_30epochs_33393.6_images_False_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for octnet: 0.967975\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training resnet for 0.4% of train size (aka 33393 images) with pretrained: True and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 178 trainable: 178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/668 [..............................] - ETA: 7:58 - loss: 1.4452 - accuracy: 0.0113WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1088s vs `on_train_batch_begin` time: 0.1947s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1088s vs `on_train_batch_end` time: 0.3189s). Check your callbacks.\n",
      "668/668 [==============================] - 163s 231ms/step - loss: 1.1971 - accuracy: 0.5118 - val_loss: 0.7964 - val_accuracy: 0.9375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "668/668 [==============================] - 154s 230ms/step - loss: 0.6308 - accuracy: 0.9189 - val_loss: 0.4560 - val_accuracy: 1.0000\n",
      "Epoch 3/30\n",
      "668/668 [==============================] - 142s 213ms/step - loss: 0.4339 - accuracy: 0.9324 - val_loss: 1.0825 - val_accuracy: 0.6250\n",
      "Epoch 4/30\n",
      "668/668 [==============================] - 147s 220ms/step - loss: 0.3236 - accuracy: 0.9455 - val_loss: 0.2629 - val_accuracy: 0.9688\n",
      "Epoch 5/30\n",
      "668/668 [==============================] - 145s 217ms/step - loss: 0.2672 - accuracy: 0.9507 - val_loss: 0.1483 - val_accuracy: 1.0000\n",
      "Epoch 6/30\n",
      "668/668 [==============================] - 146s 219ms/step - loss: 0.2255 - accuracy: 0.9549 - val_loss: 0.1481 - val_accuracy: 0.9688\n",
      "Epoch 7/30\n",
      "668/668 [==============================] - 150s 225ms/step - loss: 0.1963 - accuracy: 0.9609 - val_loss: 0.1662 - val_accuracy: 0.9688\n",
      "Epoch 8/30\n",
      "668/668 [==============================] - 147s 220ms/step - loss: 0.1729 - accuracy: 0.9642 - val_loss: 0.0985 - val_accuracy: 1.0000\n",
      "Epoch 9/30\n",
      "668/668 [==============================] - 142s 213ms/step - loss: 0.1553 - accuracy: 0.9676 - val_loss: 0.0680 - val_accuracy: 1.0000\n",
      "Epoch 10/30\n",
      "668/668 [==============================] - 143s 214ms/step - loss: 0.1387 - accuracy: 0.9711 - val_loss: 0.1322 - val_accuracy: 0.9375\n",
      "Epoch 11/30\n",
      "668/668 [==============================] - 144s 216ms/step - loss: 0.1293 - accuracy: 0.9720 - val_loss: 0.0645 - val_accuracy: 1.0000\n",
      "Epoch 12/30\n",
      "668/668 [==============================] - 145s 217ms/step - loss: 0.1121 - accuracy: 0.9777 - val_loss: 0.0807 - val_accuracy: 0.9688\n",
      "Epoch 13/30\n",
      "668/668 [==============================] - 152s 228ms/step - loss: 0.1021 - accuracy: 0.9789 - val_loss: 0.3256 - val_accuracy: 0.8750\n",
      "Epoch 14/30\n",
      "668/668 [==============================] - 150s 224ms/step - loss: 0.0875 - accuracy: 0.9829 - val_loss: 0.1108 - val_accuracy: 0.9688\n",
      "Epoch 15/30\n",
      "668/668 [==============================] - 150s 224ms/step - loss: 0.0839 - accuracy: 0.9844 - val_loss: 0.0366 - val_accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "668/668 [==============================] - 150s 224ms/step - loss: 0.0793 - accuracy: 0.9856 - val_loss: 0.1015 - val_accuracy: 0.9375\n",
      "Epoch 17/30\n",
      "668/668 [==============================] - 151s 226ms/step - loss: 0.0767 - accuracy: 0.9863 - val_loss: 0.0766 - val_accuracy: 0.9688\n",
      "Epoch 18/30\n",
      "668/668 [==============================] - 150s 224ms/step - loss: 0.0700 - accuracy: 0.9876 - val_loss: 0.2919 - val_accuracy: 0.9375\n",
      "Epoch 19/30\n",
      "668/668 [==============================] - 150s 225ms/step - loss: 0.0659 - accuracy: 0.9888 - val_loss: 0.2305 - val_accuracy: 0.9375\n",
      "Epoch 20/30\n",
      "668/668 [==============================] - 152s 228ms/step - loss: 0.0660 - accuracy: 0.9886 - val_loss: 0.1021 - val_accuracy: 0.9375\n",
      "Epoch 21/30\n",
      "668/668 [==============================] - 147s 221ms/step - loss: 0.0621 - accuracy: 0.9897 - val_loss: 0.0595 - val_accuracy: 0.9688\n",
      "Epoch 22/30\n",
      "668/668 [==============================] - 149s 223ms/step - loss: 0.0597 - accuracy: 0.9900 - val_loss: 0.0997 - val_accuracy: 0.9688\n",
      "Epoch 23/30\n",
      "668/668 [==============================] - 149s 222ms/step - loss: 0.0598 - accuracy: 0.9900 - val_loss: 0.0810 - val_accuracy: 0.9688\n",
      "Epoch 24/30\n",
      "668/668 [==============================] - 149s 223ms/step - loss: 0.0560 - accuracy: 0.9912 - val_loss: 0.0416 - val_accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "668/668 [==============================] - 150s 224ms/step - loss: 0.0549 - accuracy: 0.9907 - val_loss: 0.0788 - val_accuracy: 0.9375\n",
      "Epoch 26/30\n",
      "668/668 [==============================] - 151s 225ms/step - loss: 0.0544 - accuracy: 0.9907 - val_loss: 0.1538 - val_accuracy: 0.9375\n",
      "Epoch 27/30\n",
      "668/668 [==============================] - 150s 225ms/step - loss: 0.0533 - accuracy: 0.9912 - val_loss: 0.1688 - val_accuracy: 0.9688\n",
      "Epoch 28/30\n",
      "668/668 [==============================] - 151s 226ms/step - loss: 0.0544 - accuracy: 0.9910 - val_loss: 0.0923 - val_accuracy: 0.9688\n",
      "Epoch 29/30\n",
      "668/668 [==============================] - 151s 227ms/step - loss: 0.0518 - accuracy: 0.9915 - val_loss: 0.1582 - val_accuracy: 0.9688\n",
      "Epoch 30/30\n",
      "668/668 [==============================] - 151s 227ms/step - loss: 0.0494 - accuracy: 0.9921 - val_loss: 0.2202 - val_accuracy: 0.9375\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_33393.6_images_False_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.984504\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.5065552  0.49565919 0.50361297 0.49396472]\n",
      "Training octnet for 0.5% of train size (aka 41742 images) with pretrained: True and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 23 trainable: 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/835 [..............................] - ETA: 6:19 - loss: 4.7749 - accuracy: 0.3090WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0240s vs `on_train_batch_begin` time: 0.2027s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0240s vs `on_train_batch_end` time: 0.1616s). Check your callbacks.\n",
      "835/835 [==============================] - 54s 63ms/step - loss: 1.8560 - accuracy: 0.5842 - val_loss: 0.7963 - val_accuracy: 0.7188\n",
      "Epoch 2/30\n",
      "  1/835 [..............................] - ETA: 49s - loss: 0.9227 - accuracy: 0.7000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "835/835 [==============================] - 42s 50ms/step - loss: 0.6079 - accuracy: 0.7895 - val_loss: 0.4453 - val_accuracy: 0.7812\n",
      "Epoch 3/30\n",
      "835/835 [==============================] - 46s 55ms/step - loss: 0.4624 - accuracy: 0.8365 - val_loss: 0.2095 - val_accuracy: 0.9062\n",
      "Epoch 4/30\n",
      "835/835 [==============================] - 43s 51ms/step - loss: 0.3891 - accuracy: 0.8688 - val_loss: 0.1249 - val_accuracy: 0.9688\n",
      "Epoch 5/30\n",
      "835/835 [==============================] - 51s 61ms/step - loss: 0.3306 - accuracy: 0.8856 - val_loss: 0.1344 - val_accuracy: 0.9062\n",
      "Epoch 6/30\n",
      "835/835 [==============================] - 52s 63ms/step - loss: 0.2823 - accuracy: 0.9052 - val_loss: 0.1213 - val_accuracy: 0.9375\n",
      "Epoch 7/30\n",
      "835/835 [==============================] - 46s 55ms/step - loss: 0.2580 - accuracy: 0.9122 - val_loss: 0.0300 - val_accuracy: 1.0000\n",
      "Epoch 8/30\n",
      "835/835 [==============================] - 56s 67ms/step - loss: 0.2288 - accuracy: 0.9212 - val_loss: 0.0308 - val_accuracy: 1.0000\n",
      "Epoch 9/30\n",
      "835/835 [==============================] - 51s 62ms/step - loss: 0.2028 - accuracy: 0.9311 - val_loss: 0.0740 - val_accuracy: 0.9688\n",
      "Epoch 10/30\n",
      "835/835 [==============================] - 49s 59ms/step - loss: 0.1831 - accuracy: 0.9376 - val_loss: 0.0925 - val_accuracy: 0.9375\n",
      "Epoch 11/30\n",
      "835/835 [==============================] - 46s 55ms/step - loss: 0.1672 - accuracy: 0.9432 - val_loss: 0.1346 - val_accuracy: 0.9375\n",
      "Epoch 12/30\n",
      "835/835 [==============================] - 47s 56ms/step - loss: 0.1550 - accuracy: 0.9492 - val_loss: 0.0241 - val_accuracy: 1.0000\n",
      "Epoch 13/30\n",
      "835/835 [==============================] - 49s 59ms/step - loss: 0.1321 - accuracy: 0.9564 - val_loss: 0.0785 - val_accuracy: 0.9688\n",
      "Epoch 14/30\n",
      "835/835 [==============================] - 44s 52ms/step - loss: 0.1170 - accuracy: 0.9618 - val_loss: 0.0305 - val_accuracy: 0.9688\n",
      "Epoch 15/30\n",
      "835/835 [==============================] - 46s 56ms/step - loss: 0.1063 - accuracy: 0.9645 - val_loss: 0.0409 - val_accuracy: 0.9688\n",
      "Epoch 16/30\n",
      "835/835 [==============================] - 45s 54ms/step - loss: 0.0935 - accuracy: 0.9687 - val_loss: 0.0227 - val_accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "835/835 [==============================] - 43s 51ms/step - loss: 0.0826 - accuracy: 0.9723 - val_loss: 0.0367 - val_accuracy: 0.9688\n",
      "Epoch 18/30\n",
      "835/835 [==============================] - 46s 55ms/step - loss: 0.0783 - accuracy: 0.9732 - val_loss: 0.0495 - val_accuracy: 0.9688\n",
      "Epoch 19/30\n",
      "835/835 [==============================] - 44s 52ms/step - loss: 0.0708 - accuracy: 0.9762 - val_loss: 0.0316 - val_accuracy: 0.9688\n",
      "Epoch 20/30\n",
      "835/835 [==============================] - 48s 57ms/step - loss: 0.0599 - accuracy: 0.9796 - val_loss: 0.0990 - val_accuracy: 0.9688\n",
      "Epoch 21/30\n",
      "835/835 [==============================] - 45s 54ms/step - loss: 0.0596 - accuracy: 0.9796 - val_loss: 0.0994 - val_accuracy: 0.9688\n",
      "Epoch 22/30\n",
      "835/835 [==============================] - 51s 62ms/step - loss: 0.0527 - accuracy: 0.9827 - val_loss: 0.0556 - val_accuracy: 0.9688\n",
      "Epoch 23/30\n",
      "835/835 [==============================] - 53s 63ms/step - loss: 0.0446 - accuracy: 0.9844 - val_loss: 0.0342 - val_accuracy: 0.9688\n",
      "Epoch 24/30\n",
      "835/835 [==============================] - 48s 58ms/step - loss: 0.0468 - accuracy: 0.9846 - val_loss: 0.0335 - val_accuracy: 0.9688\n",
      "Epoch 25/30\n",
      "835/835 [==============================] - 50s 60ms/step - loss: 0.0437 - accuracy: 0.9847 - val_loss: 0.0206 - val_accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "835/835 [==============================] - 46s 56ms/step - loss: 0.0433 - accuracy: 0.9860 - val_loss: 0.0109 - val_accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "835/835 [==============================] - 43s 52ms/step - loss: 0.0369 - accuracy: 0.9879 - val_loss: 0.0288 - val_accuracy: 0.9688\n",
      "Epoch 28/30\n",
      "835/835 [==============================] - 45s 54ms/step - loss: 0.0376 - accuracy: 0.9874 - val_loss: 0.0511 - val_accuracy: 0.9688\n",
      "Epoch 29/30\n",
      "835/835 [==============================] - 43s 52ms/step - loss: 0.0353 - accuracy: 0.9878 - val_loss: 0.0464 - val_accuracy: 0.9688\n",
      "Epoch 30/30\n",
      "835/835 [==============================] - 46s 55ms/step - loss: 0.0372 - accuracy: 0.9873 - val_loss: 0.0316 - val_accuracy: 0.9688\n",
      "INFO:tensorflow:Assets written to: ../octnet/octnet_30epochs_41742.0_images_False_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for octnet: 0.966942\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training resnet for 0.5% of train size (aka 41742 images) with pretrained: True and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 178 trainable: 178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/835 [..............................] - ETA: 10:27 - loss: 1.3903 - accuracy: 0.0120WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1231s vs `on_train_batch_begin` time: 0.2180s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1231s vs `on_train_batch_end` time: 0.3152s). Check your callbacks.\n",
      "835/835 [==============================] - 199s 228ms/step - loss: 1.0969 - accuracy: 0.7824 - val_loss: 0.7937 - val_accuracy: 0.9062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "835/835 [==============================] - 187s 224ms/step - loss: 0.5345 - accuracy: 0.9424 - val_loss: 0.3646 - val_accuracy: 1.0000\n",
      "Epoch 3/30\n",
      "835/835 [==============================] - 185s 222ms/step - loss: 0.3425 - accuracy: 0.9504 - val_loss: 0.3730 - val_accuracy: 0.9375\n",
      "Epoch 4/30\n",
      "835/835 [==============================] - 184s 220ms/step - loss: 0.2487 - accuracy: 0.9589 - val_loss: 0.2772 - val_accuracy: 0.9688\n",
      "Epoch 5/30\n",
      "835/835 [==============================] - 189s 226ms/step - loss: 0.1984 - accuracy: 0.9644 - val_loss: 0.1681 - val_accuracy: 0.9688\n",
      "Epoch 6/30\n",
      "835/835 [==============================] - 185s 222ms/step - loss: 0.1500 - accuracy: 0.9731 - val_loss: 0.0743 - val_accuracy: 1.0000\n",
      "Epoch 7/30\n",
      "835/835 [==============================] - 184s 220ms/step - loss: 0.1254 - accuracy: 0.9766 - val_loss: 0.2044 - val_accuracy: 0.9375\n",
      "Epoch 8/30\n",
      "835/835 [==============================] - 183s 219ms/step - loss: 0.1056 - accuracy: 0.9813 - val_loss: 0.0460 - val_accuracy: 1.0000\n",
      "Epoch 9/30\n",
      "835/835 [==============================] - 184s 221ms/step - loss: 0.0957 - accuracy: 0.9819 - val_loss: 0.0479 - val_accuracy: 1.0000\n",
      "Epoch 10/30\n",
      "835/835 [==============================] - 183s 220ms/step - loss: 0.0775 - accuracy: 0.9865 - val_loss: 0.2296 - val_accuracy: 0.9375\n",
      "Epoch 11/30\n",
      "835/835 [==============================] - 185s 222ms/step - loss: 0.0788 - accuracy: 0.9853 - val_loss: 0.0285 - val_accuracy: 1.0000\n",
      "Epoch 12/30\n",
      "835/835 [==============================] - 185s 221ms/step - loss: 0.0681 - accuracy: 0.9879 - val_loss: 0.0241 - val_accuracy: 1.0000\n",
      "Epoch 13/30\n",
      "835/835 [==============================] - 187s 224ms/step - loss: 0.0554 - accuracy: 0.9909 - val_loss: 0.0393 - val_accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "835/835 [==============================] - 187s 224ms/step - loss: 0.0592 - accuracy: 0.9897 - val_loss: 0.0222 - val_accuracy: 1.0000\n",
      "Epoch 15/30\n",
      "835/835 [==============================] - 186s 222ms/step - loss: 0.0530 - accuracy: 0.9912 - val_loss: 0.0330 - val_accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "835/835 [==============================] - 188s 225ms/step - loss: 0.0550 - accuracy: 0.9906 - val_loss: 0.0410 - val_accuracy: 0.9688\n",
      "Epoch 17/30\n",
      "835/835 [==============================] - 183s 219ms/step - loss: 0.0491 - accuracy: 0.9921 - val_loss: 0.1644 - val_accuracy: 0.9688\n",
      "Epoch 18/30\n",
      "835/835 [==============================] - 190s 227ms/step - loss: 0.0461 - accuracy: 0.9925 - val_loss: 0.1163 - val_accuracy: 0.9688\n",
      "Epoch 19/30\n",
      "835/835 [==============================] - 188s 225ms/step - loss: 0.0502 - accuracy: 0.9918 - val_loss: 0.0246 - val_accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "835/835 [==============================] - 188s 226ms/step - loss: 0.0456 - accuracy: 0.9928 - val_loss: 0.0372 - val_accuracy: 0.9688\n",
      "Epoch 21/30\n",
      "835/835 [==============================] - 189s 226ms/step - loss: 0.0434 - accuracy: 0.9931 - val_loss: 0.0156 - val_accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "835/835 [==============================] - 189s 227ms/step - loss: 0.0410 - accuracy: 0.9934 - val_loss: 0.0204 - val_accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "835/835 [==============================] - 189s 226ms/step - loss: 0.0399 - accuracy: 0.9936 - val_loss: 0.0446 - val_accuracy: 0.9688\n",
      "Epoch 24/30\n",
      "835/835 [==============================] - 187s 223ms/step - loss: 0.0383 - accuracy: 0.9938 - val_loss: 0.0274 - val_accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "835/835 [==============================] - 185s 222ms/step - loss: 0.0398 - accuracy: 0.9935 - val_loss: 0.0367 - val_accuracy: 0.9688\n",
      "Epoch 26/30\n",
      "835/835 [==============================] - 189s 226ms/step - loss: 0.0362 - accuracy: 0.9944 - val_loss: 0.0147 - val_accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "835/835 [==============================] - 191s 229ms/step - loss: 0.0357 - accuracy: 0.9942 - val_loss: 0.0168 - val_accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "835/835 [==============================] - 190s 228ms/step - loss: 0.0344 - accuracy: 0.9941 - val_loss: 0.0189 - val_accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "835/835 [==============================] - 192s 229ms/step - loss: 0.0329 - accuracy: 0.9948 - val_loss: 0.0295 - val_accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "835/835 [==============================] - 192s 229ms/step - loss: 0.0321 - accuracy: 0.9950 - val_loss: 0.0140 - val_accuracy: 1.0000\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_41742.0_images_False_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.986570\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.60516816 0.59567262 0.60327811 0.5985376 ]\n",
      "Training octnet for 0.6% of train size (aka 50090 images) with pretrained: True and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 23 trainable: 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "   6/1002 [..............................] - ETA: 8:07 - loss: 4.7167 - accuracy: 0.3811WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0461s vs `on_train_batch_begin` time: 0.1681s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0461s vs `on_train_batch_end` time: 0.2040s). Check your callbacks.\n",
      "1002/1002 [==============================] - 59s 57ms/step - loss: 1.8269 - accuracy: 0.5709 - val_loss: 0.5520 - val_accuracy: 0.8125\n",
      "Epoch 2/30\n",
      "   1/1002 [..............................] - ETA: 43s - loss: 0.4566 - accuracy: 0.8200"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1002/1002 [==============================] - 61s 61ms/step - loss: 0.5647 - accuracy: 0.7990 - val_loss: 0.9131 - val_accuracy: 0.6562\n",
      "Epoch 3/30\n",
      "1002/1002 [==============================] - 56s 56ms/step - loss: 0.4427 - accuracy: 0.8449 - val_loss: 0.2868 - val_accuracy: 0.9062\n",
      "Epoch 4/30\n",
      "1002/1002 [==============================] - 52s 52ms/step - loss: 0.3650 - accuracy: 0.8740 - val_loss: 0.3101 - val_accuracy: 0.8750\n",
      "Epoch 5/30\n",
      "1002/1002 [==============================] - 61s 61ms/step - loss: 0.3019 - accuracy: 0.8961 - val_loss: 0.3288 - val_accuracy: 0.9062\n",
      "Epoch 6/30\n",
      "1002/1002 [==============================] - 59s 58ms/step - loss: 0.2663 - accuracy: 0.9110 - val_loss: 0.2545 - val_accuracy: 0.9062\n",
      "Epoch 7/30\n",
      "1002/1002 [==============================] - 57s 57ms/step - loss: 0.2405 - accuracy: 0.9209 - val_loss: 0.1276 - val_accuracy: 0.9688\n",
      "Epoch 8/30\n",
      "1002/1002 [==============================] - 59s 59ms/step - loss: 0.2154 - accuracy: 0.9271 - val_loss: 0.2467 - val_accuracy: 0.9062\n",
      "Epoch 9/30\n",
      "1002/1002 [==============================] - 60s 60ms/step - loss: 0.1915 - accuracy: 0.9362 - val_loss: 0.1632 - val_accuracy: 0.9375\n",
      "Epoch 10/30\n",
      "1002/1002 [==============================] - 56s 56ms/step - loss: 0.1707 - accuracy: 0.9425 - val_loss: 0.0154 - val_accuracy: 1.0000\n",
      "Epoch 11/30\n",
      "1002/1002 [==============================] - 57s 57ms/step - loss: 0.1517 - accuracy: 0.9487 - val_loss: 0.0147 - val_accuracy: 1.0000\n",
      "Epoch 12/30\n",
      "1002/1002 [==============================] - 59s 59ms/step - loss: 0.1384 - accuracy: 0.9521 - val_loss: 0.1499 - val_accuracy: 0.9375\n",
      "Epoch 13/30\n",
      "1002/1002 [==============================] - 57s 57ms/step - loss: 0.1247 - accuracy: 0.9582 - val_loss: 0.0106 - val_accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "1002/1002 [==============================] - 50s 50ms/step - loss: 0.1114 - accuracy: 0.9618 - val_loss: 0.0788 - val_accuracy: 0.9688\n",
      "Epoch 15/30\n",
      "1002/1002 [==============================] - 50s 50ms/step - loss: 0.0974 - accuracy: 0.9675 - val_loss: 0.1201 - val_accuracy: 0.9688\n",
      "Epoch 16/30\n",
      "1002/1002 [==============================] - 53s 53ms/step - loss: 0.0879 - accuracy: 0.9697 - val_loss: 0.0110 - val_accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "1002/1002 [==============================] - 57s 56ms/step - loss: 0.0858 - accuracy: 0.9702 - val_loss: 0.0148 - val_accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "1002/1002 [==============================] - 58s 58ms/step - loss: 0.0695 - accuracy: 0.9762 - val_loss: 0.0062 - val_accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "1002/1002 [==============================] - 61s 61ms/step - loss: 0.0695 - accuracy: 0.9770 - val_loss: 0.1429 - val_accuracy: 0.9688\n",
      "Epoch 20/30\n",
      "1002/1002 [==============================] - 53s 53ms/step - loss: 0.0602 - accuracy: 0.9794 - val_loss: 0.0362 - val_accuracy: 0.9688\n",
      "Epoch 21/30\n",
      "1002/1002 [==============================] - 51s 51ms/step - loss: 0.0576 - accuracy: 0.9816 - val_loss: 0.0257 - val_accuracy: 0.9688\n",
      "Epoch 22/30\n",
      "1002/1002 [==============================] - 50s 50ms/step - loss: 0.0581 - accuracy: 0.9807 - val_loss: 0.0829 - val_accuracy: 0.9688\n",
      "Epoch 23/30\n",
      "1002/1002 [==============================] - 50s 50ms/step - loss: 0.0443 - accuracy: 0.9849 - val_loss: 0.1182 - val_accuracy: 0.9688\n",
      "Epoch 24/30\n",
      "1002/1002 [==============================] - 56s 56ms/step - loss: 0.0469 - accuracy: 0.9849 - val_loss: 0.0737 - val_accuracy: 0.9688\n",
      "Epoch 25/30\n",
      "1002/1002 [==============================] - 50s 50ms/step - loss: 0.0446 - accuracy: 0.9852 - val_loss: 0.0818 - val_accuracy: 0.9688\n",
      "Epoch 26/30\n",
      "1002/1002 [==============================] - 50s 50ms/step - loss: 0.0434 - accuracy: 0.9854 - val_loss: 0.0508 - val_accuracy: 0.9688\n",
      "Epoch 27/30\n",
      "1002/1002 [==============================] - 53s 53ms/step - loss: 0.0392 - accuracy: 0.9870 - val_loss: 0.0542 - val_accuracy: 0.9688\n",
      "Epoch 28/30\n",
      "1002/1002 [==============================] - 51s 51ms/step - loss: 0.0393 - accuracy: 0.9875 - val_loss: 0.1094 - val_accuracy: 0.9688\n",
      "Epoch 29/30\n",
      "1002/1002 [==============================] - 58s 58ms/step - loss: 0.0366 - accuracy: 0.9874 - val_loss: 0.0991 - val_accuracy: 0.9688\n",
      "Epoch 30/30\n",
      "1002/1002 [==============================] - 74s 74ms/step - loss: 0.0336 - accuracy: 0.9892 - val_loss: 0.1073 - val_accuracy: 0.9688\n",
      "INFO:tensorflow:Assets written to: ../octnet/octnet_30epochs_50090.4_images_False_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for octnet: 0.974174\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training resnet for 0.6% of train size (aka 50090 images) with pretrained: True and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 178 trainable: 178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "   6/1002 [..............................] - ETA: 13:07 - loss: 1.3775 - accuracy: 0.0221  WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1151s vs `on_train_batch_begin` time: 0.2262s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1151s vs `on_train_batch_end` time: 0.3449s). Check your callbacks.\n",
      "1002/1002 [==============================] - 234s 225ms/step - loss: 1.1158 - accuracy: 0.7466 - val_loss: 0.7285 - val_accuracy: 0.9375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "1002/1002 [==============================] - 223s 222ms/step - loss: 0.4938 - accuracy: 0.9498 - val_loss: 0.3623 - val_accuracy: 0.9375\n",
      "Epoch 3/30\n",
      "1002/1002 [==============================] - 224s 223ms/step - loss: 0.2820 - accuracy: 0.9610 - val_loss: 0.2283 - val_accuracy: 0.9688\n",
      "Epoch 4/30\n",
      "1002/1002 [==============================] - 221s 220ms/step - loss: 0.1910 - accuracy: 0.9694 - val_loss: 0.1022 - val_accuracy: 1.0000\n",
      "Epoch 5/30\n",
      "1002/1002 [==============================] - 222s 222ms/step - loss: 0.1313 - accuracy: 0.9782 - val_loss: 0.0761 - val_accuracy: 1.0000\n",
      "Epoch 6/30\n",
      "1002/1002 [==============================] - 225s 225ms/step - loss: 0.1019 - accuracy: 0.9834 - val_loss: 0.0485 - val_accuracy: 1.0000\n",
      "Epoch 7/30\n",
      "1002/1002 [==============================] - 225s 225ms/step - loss: 0.0883 - accuracy: 0.9835 - val_loss: 0.0380 - val_accuracy: 1.0000\n",
      "Epoch 8/30\n",
      "1002/1002 [==============================] - 223s 222ms/step - loss: 0.0713 - accuracy: 0.9875 - val_loss: 0.0325 - val_accuracy: 1.0000\n",
      "Epoch 9/30\n",
      "1002/1002 [==============================] - 218s 218ms/step - loss: 0.0613 - accuracy: 0.9887 - val_loss: 0.1183 - val_accuracy: 0.9688\n",
      "Epoch 10/30\n",
      "1002/1002 [==============================] - 206s 205ms/step - loss: 0.0552 - accuracy: 0.9905 - val_loss: 0.0200 - val_accuracy: 1.0000\n",
      "Epoch 11/30\n",
      "1002/1002 [==============================] - 207s 207ms/step - loss: 0.0507 - accuracy: 0.9910 - val_loss: 0.0377 - val_accuracy: 1.0000\n",
      "Epoch 12/30\n",
      "1002/1002 [==============================] - 205s 205ms/step - loss: 0.0491 - accuracy: 0.9911 - val_loss: 0.0152 - val_accuracy: 1.0000\n",
      "Epoch 13/30\n",
      "1002/1002 [==============================] - 206s 206ms/step - loss: 0.0409 - accuracy: 0.9933 - val_loss: 0.0856 - val_accuracy: 0.9688\n",
      "Epoch 14/30\n",
      "1002/1002 [==============================] - 206s 205ms/step - loss: 0.0423 - accuracy: 0.9925 - val_loss: 0.0148 - val_accuracy: 1.0000\n",
      "Epoch 15/30\n",
      "1002/1002 [==============================] - 206s 205ms/step - loss: 0.0383 - accuracy: 0.9935 - val_loss: 0.0121 - val_accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "1002/1002 [==============================] - 206s 206ms/step - loss: 0.0360 - accuracy: 0.9939 - val_loss: 0.0144 - val_accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "1002/1002 [==============================] - 206s 206ms/step - loss: 0.0329 - accuracy: 0.9944 - val_loss: 0.0114 - val_accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "1002/1002 [==============================] - 206s 205ms/step - loss: 0.0346 - accuracy: 0.9939 - val_loss: 0.0114 - val_accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "1002/1002 [==============================] - 207s 207ms/step - loss: 0.0324 - accuracy: 0.9942 - val_loss: 0.0152 - val_accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "1002/1002 [==============================] - 206s 206ms/step - loss: 0.0297 - accuracy: 0.9950 - val_loss: 0.0109 - val_accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "1002/1002 [==============================] - 206s 206ms/step - loss: 0.0297 - accuracy: 0.9950 - val_loss: 0.0137 - val_accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "1002/1002 [==============================] - 206s 206ms/step - loss: 0.0290 - accuracy: 0.9952 - val_loss: 0.0103 - val_accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "1002/1002 [==============================] - 207s 206ms/step - loss: 0.0272 - accuracy: 0.9955 - val_loss: 0.0468 - val_accuracy: 0.9688\n",
      "Epoch 24/30\n",
      "1002/1002 [==============================] - 206s 206ms/step - loss: 0.0273 - accuracy: 0.9953 - val_loss: 0.0175 - val_accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "1002/1002 [==============================] - 206s 206ms/step - loss: 0.0263 - accuracy: 0.9955 - val_loss: 0.0119 - val_accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "1002/1002 [==============================] - 206s 205ms/step - loss: 0.0257 - accuracy: 0.9957 - val_loss: 0.0322 - val_accuracy: 0.9688\n",
      "Epoch 27/30\n",
      "1002/1002 [==============================] - 206s 206ms/step - loss: 0.0285 - accuracy: 0.9951 - val_loss: 0.0180 - val_accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "1002/1002 [==============================] - 206s 206ms/step - loss: 0.0246 - accuracy: 0.9953 - val_loss: 0.0146 - val_accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "1002/1002 [==============================] - 206s 206ms/step - loss: 0.0225 - accuracy: 0.9962 - val_loss: 0.0135 - val_accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "1002/1002 [==============================] - 207s 207ms/step - loss: 0.0248 - accuracy: 0.9958 - val_loss: 0.0202 - val_accuracy: 1.0000\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_50090.4_images_False_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.990702\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.75500665 0.74748018 0.75255552 0.74222377]\n",
      "Training octnet for 0.75% of train size (aka 62613 images) with pretrained: True and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 23 trainable: 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "   5/1253 [..............................] - ETA: 12:09 - loss: 5.6360 - accuracy: 0.3213WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0240s vs `on_train_batch_begin` time: 0.2205s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0240s vs `on_train_batch_end` time: 0.1603s). Check your callbacks.\n",
      "1253/1253 [==============================] - 65s 51ms/step - loss: 1.7609 - accuracy: 0.6071 - val_loss: 0.7507 - val_accuracy: 0.7188\n",
      "Epoch 2/30\n",
      "   1/1253 [..............................] - ETA: 58s - loss: 0.4039 - accuracy: 0.8600"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1253/1253 [==============================] - 63s 50ms/step - loss: 0.5428 - accuracy: 0.8093 - val_loss: 0.4702 - val_accuracy: 0.8125\n",
      "Epoch 3/30\n",
      "1253/1253 [==============================] - 64s 51ms/step - loss: 0.4184 - accuracy: 0.8550 - val_loss: 0.1707 - val_accuracy: 0.9062\n",
      "Epoch 4/30\n",
      "1253/1253 [==============================] - 61s 49ms/step - loss: 0.3270 - accuracy: 0.8894 - val_loss: 0.0962 - val_accuracy: 0.9688\n",
      "Epoch 5/30\n",
      "1253/1253 [==============================] - 61s 49ms/step - loss: 0.2779 - accuracy: 0.9076 - val_loss: 0.2251 - val_accuracy: 0.9375\n",
      "Epoch 6/30\n",
      "1253/1253 [==============================] - 61s 49ms/step - loss: 0.2421 - accuracy: 0.9189 - val_loss: 0.0893 - val_accuracy: 0.9688\n",
      "Epoch 7/30\n",
      "1253/1253 [==============================] - 59s 47ms/step - loss: 0.2172 - accuracy: 0.9273 - val_loss: 0.1068 - val_accuracy: 0.9688\n",
      "Epoch 8/30\n",
      "1253/1253 [==============================] - 63s 51ms/step - loss: 0.1929 - accuracy: 0.9364 - val_loss: 0.0541 - val_accuracy: 0.9688\n",
      "Epoch 9/30\n",
      "1253/1253 [==============================] - 62s 50ms/step - loss: 0.1749 - accuracy: 0.9415 - val_loss: 0.0720 - val_accuracy: 0.9375\n",
      "Epoch 10/30\n",
      "1253/1253 [==============================] - 62s 50ms/step - loss: 0.1480 - accuracy: 0.9503 - val_loss: 0.0312 - val_accuracy: 1.0000\n",
      "Epoch 11/30\n",
      "1253/1253 [==============================] - 61s 49ms/step - loss: 0.1318 - accuracy: 0.9572 - val_loss: 0.0690 - val_accuracy: 1.0000\n",
      "Epoch 12/30\n",
      "1253/1253 [==============================] - 61s 49ms/step - loss: 0.1124 - accuracy: 0.9620 - val_loss: 0.0391 - val_accuracy: 1.0000\n",
      "Epoch 13/30\n",
      "1253/1253 [==============================] - 61s 49ms/step - loss: 0.1061 - accuracy: 0.9645 - val_loss: 0.0532 - val_accuracy: 0.9688\n",
      "Epoch 14/30\n",
      "1253/1253 [==============================] - 59s 47ms/step - loss: 0.0903 - accuracy: 0.9695 - val_loss: 0.0199 - val_accuracy: 1.0000\n",
      "Epoch 15/30\n",
      "1253/1253 [==============================] - 61s 49ms/step - loss: 0.0838 - accuracy: 0.9716 - val_loss: 0.0247 - val_accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "1253/1253 [==============================] - 61s 48ms/step - loss: 0.0758 - accuracy: 0.9737 - val_loss: 0.0164 - val_accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "1253/1253 [==============================] - 62s 49ms/step - loss: 0.0668 - accuracy: 0.9783 - val_loss: 0.0164 - val_accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "1253/1253 [==============================] - 61s 49ms/step - loss: 0.0619 - accuracy: 0.9787 - val_loss: 0.0180 - val_accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "1253/1253 [==============================] - 63s 50ms/step - loss: 0.0532 - accuracy: 0.9819 - val_loss: 0.0146 - val_accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "1253/1253 [==============================] - 62s 49ms/step - loss: 0.0503 - accuracy: 0.9833 - val_loss: 0.0340 - val_accuracy: 0.9688\n",
      "Epoch 21/30\n",
      "1253/1253 [==============================] - 62s 49ms/step - loss: 0.0469 - accuracy: 0.9838 - val_loss: 0.1210 - val_accuracy: 0.9688\n",
      "Epoch 22/30\n",
      "1253/1253 [==============================] - 61s 49ms/step - loss: 0.0419 - accuracy: 0.9868 - val_loss: 0.0623 - val_accuracy: 0.9688\n",
      "Epoch 23/30\n",
      "1253/1253 [==============================] - 62s 50ms/step - loss: 0.0403 - accuracy: 0.9866 - val_loss: 0.0364 - val_accuracy: 0.9688\n",
      "Epoch 24/30\n",
      "1253/1253 [==============================] - 61s 49ms/step - loss: 0.0377 - accuracy: 0.9887 - val_loss: 0.0877 - val_accuracy: 0.9688\n",
      "Epoch 25/30\n",
      "1253/1253 [==============================] - 59s 47ms/step - loss: 0.0350 - accuracy: 0.9882 - val_loss: 0.1291 - val_accuracy: 0.9375\n",
      "Epoch 26/30\n",
      "1253/1253 [==============================] - 61s 49ms/step - loss: 0.0331 - accuracy: 0.9890 - val_loss: 0.1007 - val_accuracy: 0.9688\n",
      "Epoch 27/30\n",
      "1253/1253 [==============================] - 63s 50ms/step - loss: 0.0330 - accuracy: 0.9889 - val_loss: 0.1624 - val_accuracy: 0.9375\n",
      "Epoch 28/30\n",
      "1253/1253 [==============================] - 60s 48ms/step - loss: 0.0307 - accuracy: 0.9895 - val_loss: 0.0845 - val_accuracy: 0.9688\n",
      "Epoch 29/30\n",
      "1253/1253 [==============================] - 58s 47ms/step - loss: 0.0292 - accuracy: 0.9903 - val_loss: 0.0819 - val_accuracy: 0.9688\n",
      "Epoch 30/30\n",
      "1253/1253 [==============================] - 61s 49ms/step - loss: 0.0282 - accuracy: 0.9911 - val_loss: 0.1221 - val_accuracy: 0.9688\n",
      "INFO:tensorflow:Assets written to: ../octnet/octnet_30epochs_62613.0_images_False_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for octnet: 0.974174\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training resnet for 0.75% of train size (aka 62613 images) with pretrained: True and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 178 trainable: 178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "   6/1253 [..............................] - ETA: 14:37 - loss: 1.4005 - accuracy: 0.0089  WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1198s vs `on_train_batch_begin` time: 0.2100s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1198s vs `on_train_batch_end` time: 0.2856s). Check your callbacks.\n",
      "1253/1253 [==============================] - 269s 209ms/step - loss: 1.1042 - accuracy: 0.6997 - val_loss: 1.1378 - val_accuracy: 0.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "1253/1253 [==============================] - 258s 206ms/step - loss: 0.6799 - accuracy: 0.7906 - val_loss: 0.6564 - val_accuracy: 0.7500\n",
      "Epoch 3/30\n",
      "1253/1253 [==============================] - 258s 206ms/step - loss: 0.4251 - accuracy: 0.8861 - val_loss: 0.3536 - val_accuracy: 0.9375\n",
      "Epoch 4/30\n",
      "1253/1253 [==============================] - 257s 205ms/step - loss: 0.1996 - accuracy: 0.9675 - val_loss: 0.1119 - val_accuracy: 1.0000\n",
      "Epoch 5/30\n",
      "1253/1253 [==============================] - 258s 206ms/step - loss: 0.1229 - accuracy: 0.9781 - val_loss: 0.0561 - val_accuracy: 1.0000\n",
      "Epoch 6/30\n",
      "1253/1253 [==============================] - 258s 206ms/step - loss: 0.0911 - accuracy: 0.9824 - val_loss: 0.2324 - val_accuracy: 0.9375\n",
      "Epoch 7/30\n",
      "1253/1253 [==============================] - 258s 206ms/step - loss: 0.0718 - accuracy: 0.9862 - val_loss: 0.0440 - val_accuracy: 1.0000\n",
      "Epoch 8/30\n",
      "1253/1253 [==============================] - 258s 206ms/step - loss: 0.0552 - accuracy: 0.9899 - val_loss: 0.0770 - val_accuracy: 0.9688\n",
      "Epoch 9/30\n",
      "1253/1253 [==============================] - 257s 205ms/step - loss: 0.0512 - accuracy: 0.9905 - val_loss: 0.0416 - val_accuracy: 0.9688\n",
      "Epoch 10/30\n",
      "1253/1253 [==============================] - 258s 206ms/step - loss: 0.0406 - accuracy: 0.9925 - val_loss: 0.1200 - val_accuracy: 0.9688\n",
      "Epoch 11/30\n",
      "1253/1253 [==============================] - 258s 206ms/step - loss: 0.0395 - accuracy: 0.9928 - val_loss: 0.0881 - val_accuracy: 0.9688\n",
      "Epoch 12/30\n",
      "1253/1253 [==============================] - 259s 207ms/step - loss: 0.0367 - accuracy: 0.9934 - val_loss: 0.1873 - val_accuracy: 0.9688\n",
      "Epoch 13/30\n",
      "1253/1253 [==============================] - 258s 206ms/step - loss: 0.0358 - accuracy: 0.9937 - val_loss: 0.0836 - val_accuracy: 0.9688\n",
      "Epoch 14/30\n",
      " 684/1253 [===============>..............] - ETA: 1:57 - loss: 0.0294 - accuracy: 0.9950"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import datetime\n",
    "\n",
    "maxTrain = len(y_train)\n",
    "for newWeights in [True, False]:\n",
    "    tLayer = [False] if newWeights else [True, False] # do not train only last layer if new weights will be produced \n",
    "    for trainLastLayerOnly in tLayer:\n",
    "        for p in [0.01, 0.025, 0.05, 0.075, 0.09, 0.1, 0.25, 0.4, 0.5, 0.6, 0.75, 0.9, 1.0]:\n",
    "            #X_trn, X_tst, y_trn, y_tst\n",
    "            if p < 1:\n",
    "                X_t, _, y_t, _ = train_test_split(images, y_train, test_size=1-p, random_state=56789)\n",
    "            else:\n",
    "                X_t = images; y_t = y_train;\n",
    "            print(f\"Labels fraction: {sum(y_t == 1) / sum(y_train == 1)}\")\n",
    "            for net in [\"octnet\", \"resnet\"]:\n",
    "                print(f\"Training {net} for {p}% of train size (aka {len(X_t)} images) with pretrained: {not newWeights} and onlyLastLayersTrained: {trainLastLayerOnly}...\")\n",
    "                model, size, normalization = emptyModelGenerator(net, newWeights=newWeights, lastOnly=trainLastLayerOnly)\n",
    "                printTrainableLayers(model) # see if model is really well trained\n",
    "                X_trn = resizeIms(X_t, size)\n",
    "                #X_trn = normalizeIms(X_trn, normalization=normalization)\n",
    "                X_val = resizeIms(x_val, size)\n",
    "                #X_val = normalizeIms(X_val, normalization=normalization)\n",
    "                log_dir = f\"logs/{net}/fit/{p}trainSet_\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "                tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "                optimizer = Adam(learning_rate) # create new optimizers\n",
    "                time_callback = TimeHistory()\n",
    "                model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "                hist = model.fit(X_trn, y_t, epochs=epochs, validation_data = (X_val, y_validation), batch_size=batch_size,\n",
    "                            shuffle=True, max_queue_size=20,\n",
    "                            use_multiprocessing=True, workers=5, \n",
    "                            callbacks=[CustomCallback(fraction=0.9, model=net), tensorboard_callback, time_callback])\n",
    "                trainTime = sum(time_callback.times)\n",
    "                model.save(f\"../{net}/{net}_{epochs}epochs_{p*maxTrain}_images_{newWeights}_newWeights_{trainLastLayerOnly}_lastLayerOnly_{normalization}_normalization\")\n",
    "                tstAcc = testPredict(model, size, name=net) #, normalization=normalization)\n",
    "                results = results.append({\n",
    "                    'model': net, \n",
    "                    'train set images': len(X_t), \n",
    "                    'pretrained': not newWeights, \n",
    "                    'pretrained dataset': None if newWeights or net == \"octnet\" else (\"OCT2017,Srinivasan2014\" if net == \"opticnet\" else \"Imagenet\"),\n",
    "                    'Trained layers': \"Last dense\" if trainLastLayerOnly else \"All\", \n",
    "                    'epochs': epochs, \n",
    "                    'batch size': batch_size, \n",
    "                    'learning rate': learning_rate, \n",
    "                    'optimizer': optimizer._name,\n",
    "                    'training time (seconds)': trainTime, \n",
    "                    'train accuracy': hist.history[\"accuracy\"][-1], \n",
    "                    'train loss': hist.history[\"loss\"][-1],\n",
    "                    'validation accuracy': hist.history[\"val_accuracy\"][-1], \n",
    "                    'validation loss': hist.history[\"val_loss\"][-1], \n",
    "                    'test accuracy': tstAcc,\n",
    "                    #'normalization': normalization\n",
    "                }, ignore_index=True)\n",
    "                results.to_csv(\"Results_temp.csv\", index=False)\n",
    "                del model\n",
    "                del X_trn\n",
    "                del X_val\n",
    "                print(\"Done!\\n\" + '-'*50, end='\\n\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
