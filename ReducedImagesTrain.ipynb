{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "import os\n",
    "import cv2\n",
    "import pickle\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataPath = \"../../data/OCT/OCT2017/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of Classes Detected : 4\n"
     ]
    }
   ],
   "source": [
    "labels_available = os.listdir(os.path.join(dataPath, \"train\"))\n",
    "print(\"Total Number of Classes Detected :\",len(labels_available))\n",
    "\n",
    "labels_list = ['NORMAL',\"CNV\",\"DME\",\"DRUSEN\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NORMAL CNV DME DRUSEN "
     ]
    }
   ],
   "source": [
    "images=[]\n",
    "y_trn=[]\n",
    "for x in labels_list:\n",
    "    xPath = os.path.join(dataPath, \"train\", x)\n",
    "    myPicList = os.listdir(xPath)\n",
    "    for y in myPicList:\n",
    "        images.append(cv2.imread(os.path.join(xPath, y)))\n",
    "        y_trn.append(labels_list.index(x))\n",
    "    print(x ,end=\" \")\n",
    "\n",
    "y_train = to_categorical(y_trn,len(labels_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NORMAL CNV DME DRUSEN "
     ]
    }
   ],
   "source": [
    "x_val=[]\n",
    "y_val=[]\n",
    "for x in labels_list:\n",
    "    xPath = os.path.join(dataPath, \"val\", x)\n",
    "    myPicList = os.listdir(xPath)\n",
    "    for y in myPicList:\n",
    "        x_val.append(cv2.imread(os.path.join(xPath, y)))\n",
    "        y_val.append(labels_list.index(x))\n",
    "    print(x ,end=\" \")\n",
    "\n",
    "y_validation = to_categorical(y_val,len(labels_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NORMAL CNV DME DRUSEN "
     ]
    }
   ],
   "source": [
    "x_tst=[]\n",
    "y_tst=[]\n",
    "for x in labels_list:\n",
    "    xPath = os.path.join(dataPath, \"test\", x)\n",
    "    myPicList = os.listdir(xPath)\n",
    "    for y in myPicList:\n",
    "        x_tst.append(cv2.imread(os.path.join(xPath, y)))\n",
    "        y_tst.append(labels_list.index(x))\n",
    "    print(x ,end=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resizeIm(im, size):\n",
    "    if im.shape[2] == 1:\n",
    "        im = cv2.cvtColor(im,cv2.COLOR_GRAY2RGB)\n",
    "    return cv2.resize(im, size)\n",
    "\n",
    "def resizeIms(x, size):\n",
    "    return np.array(list(map(lambda im: resizeIm(im, size), x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self,fraction, model):\n",
    "        super(CustomCallback,self).__init__()\n",
    "        self.fraction = fraction\n",
    "        self.train_a = [];\n",
    "        self.val_a =[];\n",
    "        self.logPath = os.path.join(model, \"log.txt\")\n",
    "\n",
    "        if not os.path.isdir(model):\n",
    "            os.mkdir(model)\n",
    "\n",
    "        with open(self.logPath,'w') as f:\n",
    "            f.write('Starting of logging..\\n')\n",
    "\n",
    "        self.fig = plt.figure(figsize=(4,3))\n",
    "        self.ax = plt.subplot(1,1,1)\n",
    "        plt.ion()\n",
    "\n",
    "    def on_train_begin(self,logs=None):\n",
    "        self.fig.show()\n",
    "        self.fig.canvas.draw()\n",
    "\n",
    "    def on_train_end(self,logs=None):\n",
    "        with open(self.logPath,'a') as f:\n",
    "              f.write('End of logging..\\n')\n",
    "    \n",
    "    def on_epoch_begin(self,epoch,logs=None):\n",
    "        lr= tf.keras.backend.get_value(self.model.optimizer.lr)\n",
    "        lr *= self.fraction\n",
    "        tf.keras.backend.set_value(self.model.optimizer.lr,lr)\n",
    "        with open(self.logPath,'a') as f:\n",
    "            f.write('At epoch {:02d}, learning rate changed to {:.4f}\\n'.format(epoch,lr))\n",
    "    \n",
    "    def on_epoch_end(self,epoch,logs=None):\n",
    "        val_acc = logs.get('val_accuracy')\n",
    "        train_acc = logs.get('accuracy')\n",
    "        self.train_a.append(train_acc)\n",
    "        self.val_a.append(val_acc)\n",
    "        with open(self.logPath,'a') as f:\n",
    "            f.write('At epoch {:02d}, training accuracy: {:.3f}, validation accuracy: {:.3f}\\n'.format(epoch,train_acc,val_acc))\n",
    "        self.ax.clear()\n",
    "        self.ax.plot(range(1+epoch),self.train_a,label=\"Training\")\n",
    "        self.ax.plot(range(1+epoch),self.val_a,label=\"Validation\")\n",
    "        self.ax.set_xlabel('Epochs')\n",
    "        self.ax.set_ylabel('Accuracy')\n",
    "        self.ax.legend()\n",
    "        self.fig.canvas.draw()\n",
    "        self.fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xception base model\n",
    "from tensorflow.keras.applications.xception import Xception\n",
    "from tensorflow.keras.applications.xception import preprocess_input, decode_predictions\n",
    "xceptionNetModel = Xception(weights='imagenet')\n",
    "\n",
    "# opticnet base model\n",
    "opticNetModel = tf.keras.models.load_model('../Optic_net-4_classes-Kermany2018.hdf5')\n",
    "\n",
    "# resnet base model\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "\n",
    "resNetModel = ResNet50(weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emptyModelGenerator(model, newWeights=False):\n",
    "    model = model.lower()\n",
    "    if model == \"resnet\":\n",
    "        x = resNetModel.output\n",
    "        predictions = Dense(len(labels_list), activation='softmax')(x)\n",
    "        newModel = Model(inputs=resNetModel.input, outputs=predictions)\n",
    "        size = (224, 224)\n",
    "    elif model == \"xception\":\n",
    "        x = xceptionNetModel.output\n",
    "        predictions = Dense(len(labels_list), activation='softmax')(x)\n",
    "        newModel = Model(inputs=xceptionNetModel.input, outputs=predictions)\n",
    "        size = (299, 299)\n",
    "    elif model == \"opticnet\":\n",
    "        newModel = tf.keras.models.load_model('../Optic_net-4_classes-Kermany2018.hdf5')\n",
    "        size = (224, 224)\n",
    "    if newWeights:\n",
    "        newModel = tf.keras.models.clone_model(newModel)\n",
    "    return newModel, size\n",
    "\n",
    "\n",
    "def testPredict(model, size, name=None):\n",
    "    X_test = resizeIms(x_tst, size)\n",
    "    X_test = np.array(X_test)\n",
    "    Y_test = np.array(y_tst)\n",
    "    \n",
    "    prediction = model.predict(X_test)\n",
    "    preds = np.argmax(prediction, axis=1)\n",
    "    acc = sum(preds == Y_test) / len(Y_test)\n",
    "    print(f'Test acc for {name if name else \"model\"}: {acc:.6f}')\n",
    "    \n",
    "\n",
    "def computeConfussionMatrix(predictions, labels):\n",
    "    num_labels = len(labels_list)\n",
    "    cMatrix = np.zeros(shape=(num_labels, num_labels))\n",
    "    for i in len(predictions):\n",
    "        p = int(predictions[i])\n",
    "        t = int(predictions[i])\n",
    "        cMatrix[t, p] += 1\n",
    "    print(cMatrix)\n",
    "    ax = sns.heatmap(cMatrix, cmap=\"Blues\", annot=True, fmt=\"d\", xticklabels=labels_list, yticklabels=labels_list)\n",
    "    plt.xlabel(\"Predicted label\")\n",
    "    plt.ylabel(\"True label\")\n",
    "    plt.title(\"Confusion matrix\")\n",
    "    plt.show();\n",
    "    return cMatrix\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = Adam(learning_rate=0.001)\n",
    "epochs = 30\n",
    "batch_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels fraction: [0.49747292 0.50272813 0.49973564 0.49628598]\n",
      "Training xception for 0.5% of train size (aka 41742 images)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/835 [..............................] - ETA: 15:35 - loss: 1.3769 - accuracy: 0.4503WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1636s vs `on_train_batch_begin` time: 0.2542s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1636s vs `on_train_batch_end` time: 0.5502s). Check your callbacks.\n",
      "835/835 [==============================] - 666s 776ms/step - loss: 1.1016 - accuracy: 0.7752 - val_loss: 1.1335 - val_accuracy: 0.6875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "835/835 [==============================] - 643s 770ms/step - loss: 0.5634 - accuracy: 0.9163 - val_loss: 0.4026 - val_accuracy: 0.9688\n",
      "Epoch 3/30\n",
      "835/835 [==============================] - 647s 774ms/step - loss: 0.3853 - accuracy: 0.9298 - val_loss: 0.2393 - val_accuracy: 1.0000\n",
      "Epoch 4/30\n",
      "835/835 [==============================] - 645s 772ms/step - loss: 0.2879 - accuracy: 0.9424 - val_loss: 0.1655 - val_accuracy: 1.0000\n",
      "Epoch 5/30\n",
      "835/835 [==============================] - 643s 770ms/step - loss: 0.2185 - accuracy: 0.9545 - val_loss: 0.1176 - val_accuracy: 1.0000\n",
      "Epoch 6/30\n",
      "835/835 [==============================] - 645s 772ms/step - loss: 0.1805 - accuracy: 0.9630 - val_loss: 0.1282 - val_accuracy: 1.0000\n",
      "Epoch 7/30\n",
      "835/835 [==============================] - 647s 775ms/step - loss: 0.1425 - accuracy: 0.9691 - val_loss: 0.0654 - val_accuracy: 1.0000\n",
      "Epoch 8/30\n",
      "835/835 [==============================] - 645s 772ms/step - loss: 0.1202 - accuracy: 0.9738 - val_loss: 0.0542 - val_accuracy: 1.0000\n",
      "Epoch 9/30\n",
      "835/835 [==============================] - 645s 772ms/step - loss: 0.0950 - accuracy: 0.9806 - val_loss: 0.0436 - val_accuracy: 1.0000\n",
      "Epoch 10/30\n",
      "835/835 [==============================] - 646s 774ms/step - loss: 0.0840 - accuracy: 0.9823 - val_loss: 0.0396 - val_accuracy: 1.0000\n",
      "Epoch 11/30\n",
      "835/835 [==============================] - 646s 773ms/step - loss: 0.0706 - accuracy: 0.9859 - val_loss: 0.0300 - val_accuracy: 1.0000\n",
      "Epoch 12/30\n",
      "835/835 [==============================] - 648s 776ms/step - loss: 0.0561 - accuracy: 0.9902 - val_loss: 0.0307 - val_accuracy: 1.0000\n",
      "Epoch 13/30\n",
      "835/835 [==============================] - 646s 774ms/step - loss: 0.0520 - accuracy: 0.9910 - val_loss: 0.0317 - val_accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "835/835 [==============================] - 647s 774ms/step - loss: 0.0444 - accuracy: 0.9925 - val_loss: 0.1744 - val_accuracy: 0.9688\n",
      "Epoch 15/30\n",
      "835/835 [==============================] - 647s 775ms/step - loss: 0.0391 - accuracy: 0.9935 - val_loss: 0.1097 - val_accuracy: 0.9688\n",
      "Epoch 16/30\n",
      "835/835 [==============================] - 648s 776ms/step - loss: 0.0361 - accuracy: 0.9942 - val_loss: 0.2031 - val_accuracy: 0.9688\n",
      "Epoch 17/30\n",
      "835/835 [==============================] - 647s 775ms/step - loss: 0.0340 - accuracy: 0.9944 - val_loss: 0.1319 - val_accuracy: 0.9688\n",
      "Epoch 18/30\n",
      "835/835 [==============================] - 647s 774ms/step - loss: 0.0332 - accuracy: 0.9946 - val_loss: 0.1904 - val_accuracy: 0.9688\n",
      "Epoch 19/30\n",
      "835/835 [==============================] - 648s 776ms/step - loss: 0.0276 - accuracy: 0.9959 - val_loss: 0.1786 - val_accuracy: 0.9688\n",
      "Epoch 20/30\n",
      "835/835 [==============================] - 648s 776ms/step - loss: 0.0290 - accuracy: 0.9955 - val_loss: 0.1077 - val_accuracy: 0.9688\n",
      "Epoch 21/30\n",
      "835/835 [==============================] - 651s 780ms/step - loss: 0.0240 - accuracy: 0.9964 - val_loss: 0.1811 - val_accuracy: 0.9688\n",
      "Epoch 22/30\n",
      "835/835 [==============================] - 648s 776ms/step - loss: 0.0235 - accuracy: 0.9966 - val_loss: 0.1954 - val_accuracy: 0.9688\n",
      "Epoch 23/30\n",
      "835/835 [==============================] - 651s 779ms/step - loss: 0.0232 - accuracy: 0.9965 - val_loss: 0.1789 - val_accuracy: 0.9688\n",
      "Epoch 24/30\n",
      "835/835 [==============================] - 648s 776ms/step - loss: 0.0242 - accuracy: 0.9958 - val_loss: 0.1933 - val_accuracy: 0.9688\n",
      "Epoch 25/30\n",
      "835/835 [==============================] - 649s 778ms/step - loss: 0.0241 - accuracy: 0.9960 - val_loss: 0.1907 - val_accuracy: 0.9688\n",
      "Epoch 26/30\n",
      "835/835 [==============================] - 650s 779ms/step - loss: 0.0210 - accuracy: 0.9965 - val_loss: 0.2037 - val_accuracy: 0.9688\n",
      "Epoch 27/30\n",
      "835/835 [==============================] - 653s 782ms/step - loss: 0.0201 - accuracy: 0.9968 - val_loss: 0.1838 - val_accuracy: 0.9688\n",
      "Epoch 28/30\n",
      "835/835 [==============================] - 652s 781ms/step - loss: 0.0216 - accuracy: 0.9962 - val_loss: 0.1937 - val_accuracy: 0.9688\n",
      "Epoch 29/30\n",
      "835/835 [==============================] - 650s 778ms/step - loss: 0.0214 - accuracy: 0.9967 - val_loss: 0.2000 - val_accuracy: 0.9688\n",
      "Epoch 30/30\n",
      "835/835 [==============================] - 652s 781ms/step - loss: 0.0212 - accuracy: 0.9964 - val_loss: 0.2027 - val_accuracy: 0.9688\n",
      "INFO:tensorflow:Assets written to: ../xception/xception_30epochs_41742.0 images/assets\n",
      "Test acc for xception: 0.993802\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training resnet for 0.5% of train size (aka 41742 images)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/835 [..............................] - ETA: 10:06 - loss: 1.3765 - accuracy: 0.3756WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1016s vs `on_train_batch_begin` time: 0.1921s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1016s vs `on_train_batch_end` time: 0.3337s). Check your callbacks.\n",
      "835/835 [==============================] - 181s 206ms/step - loss: 1.1570 - accuracy: 0.7181 - val_loss: 1.6135 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "835/835 [==============================] - 168s 201ms/step - loss: 0.7454 - accuracy: 0.8181 - val_loss: 0.6963 - val_accuracy: 0.7500\n",
      "Epoch 3/30\n",
      "835/835 [==============================] - 168s 201ms/step - loss: 0.5136 - accuracy: 0.8763 - val_loss: 0.3840 - val_accuracy: 0.9375\n",
      "Epoch 4/30\n",
      "835/835 [==============================] - 168s 201ms/step - loss: 0.3773 - accuracy: 0.9136 - val_loss: 0.2403 - val_accuracy: 0.9688\n",
      "Epoch 5/30\n",
      "835/835 [==============================] - 167s 201ms/step - loss: 0.2824 - accuracy: 0.9366 - val_loss: 0.1469 - val_accuracy: 1.0000\n",
      "Epoch 6/30\n",
      "835/835 [==============================] - 168s 201ms/step - loss: 0.2295 - accuracy: 0.9463 - val_loss: 0.1301 - val_accuracy: 1.0000\n",
      "Epoch 7/30\n",
      "835/835 [==============================] - 168s 201ms/step - loss: 0.1968 - accuracy: 0.9533 - val_loss: 0.1423 - val_accuracy: 0.9688\n",
      "Epoch 8/30\n",
      "835/835 [==============================] - 168s 201ms/step - loss: 0.1668 - accuracy: 0.9593 - val_loss: 0.1995 - val_accuracy: 0.9375\n",
      "Epoch 9/30\n",
      "835/835 [==============================] - 168s 201ms/step - loss: 0.1503 - accuracy: 0.9621 - val_loss: 0.0805 - val_accuracy: 1.0000\n",
      "Epoch 10/30\n",
      "835/835 [==============================] - 168s 201ms/step - loss: 0.1280 - accuracy: 0.9693 - val_loss: 0.0608 - val_accuracy: 1.0000\n",
      "Epoch 11/30\n",
      "835/835 [==============================] - 168s 201ms/step - loss: 0.1060 - accuracy: 0.9744 - val_loss: 0.0487 - val_accuracy: 1.0000\n",
      "Epoch 12/30\n",
      "835/835 [==============================] - 168s 201ms/step - loss: 0.0942 - accuracy: 0.9778 - val_loss: 0.1287 - val_accuracy: 0.9688\n",
      "Epoch 13/30\n",
      "835/835 [==============================] - 168s 201ms/step - loss: 0.0812 - accuracy: 0.9818 - val_loss: 0.3164 - val_accuracy: 0.9375\n",
      "Epoch 14/30\n",
      "835/835 [==============================] - 167s 200ms/step - loss: 0.0721 - accuracy: 0.9849 - val_loss: 0.0516 - val_accuracy: 0.9688\n",
      "Epoch 15/30\n",
      "835/835 [==============================] - 168s 201ms/step - loss: 0.0614 - accuracy: 0.9884 - val_loss: 0.0257 - val_accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "835/835 [==============================] - 168s 201ms/step - loss: 0.0556 - accuracy: 0.9891 - val_loss: 0.0308 - val_accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "835/835 [==============================] - 168s 201ms/step - loss: 0.0494 - accuracy: 0.9911 - val_loss: 0.0714 - val_accuracy: 0.9688\n",
      "Epoch 18/30\n",
      "835/835 [==============================] - 168s 201ms/step - loss: 0.0434 - accuracy: 0.9928 - val_loss: 0.1529 - val_accuracy: 0.9688\n",
      "Epoch 19/30\n",
      "835/835 [==============================] - 168s 201ms/step - loss: 0.0401 - accuracy: 0.9931 - val_loss: 0.0764 - val_accuracy: 0.9688\n",
      "Epoch 20/30\n",
      "835/835 [==============================] - 168s 201ms/step - loss: 0.0343 - accuracy: 0.9946 - val_loss: 0.0486 - val_accuracy: 0.9688\n",
      "Epoch 21/30\n",
      "835/835 [==============================] - 168s 201ms/step - loss: 0.0352 - accuracy: 0.9937 - val_loss: 0.2852 - val_accuracy: 0.9375\n",
      "Epoch 22/30\n",
      "835/835 [==============================] - 168s 201ms/step - loss: 0.0337 - accuracy: 0.9945 - val_loss: 0.0272 - val_accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "835/835 [==============================] - 168s 201ms/step - loss: 0.0289 - accuracy: 0.9959 - val_loss: 0.0660 - val_accuracy: 0.9688\n",
      "Epoch 24/30\n",
      "835/835 [==============================] - 168s 201ms/step - loss: 0.0310 - accuracy: 0.9954 - val_loss: 0.2030 - val_accuracy: 0.9688\n",
      "Epoch 25/30\n",
      "835/835 [==============================] - 167s 200ms/step - loss: 0.0332 - accuracy: 0.9944 - val_loss: 0.1981 - val_accuracy: 0.9688\n",
      "Epoch 26/30\n",
      "835/835 [==============================] - 168s 201ms/step - loss: 0.0290 - accuracy: 0.9955 - val_loss: 0.2036 - val_accuracy: 0.9688\n",
      "Epoch 27/30\n",
      "835/835 [==============================] - 168s 201ms/step - loss: 0.0286 - accuracy: 0.9955 - val_loss: 0.1993 - val_accuracy: 0.9688\n",
      "Epoch 28/30\n",
      "835/835 [==============================] - 168s 201ms/step - loss: 0.0251 - accuracy: 0.9964 - val_loss: 0.2000 - val_accuracy: 0.9688\n",
      "Epoch 29/30\n",
      "835/835 [==============================] - 168s 201ms/step - loss: 0.0273 - accuracy: 0.9957 - val_loss: 0.2006 - val_accuracy: 0.9688\n",
      "Epoch 30/30\n",
      "835/835 [==============================] - 167s 201ms/step - loss: 0.0254 - accuracy: 0.9960 - val_loss: 0.2026 - val_accuracy: 0.9688\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_41742.0 images/assets\n",
      "Test acc for resnet: 0.992769\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training opticnet for 0.5% of train size (aka 41742 images)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/835 [..............................] - ETA: 25:43 - loss: 5.5450 - accuracy: 0.1421  WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.4632s vs `on_train_batch_end` time: 0.9945s). Check your callbacks.\n",
      "835/835 [==============================] - 1017s 1s/step - loss: 0.4047 - accuracy: 0.8849 - val_loss: 0.0784 - val_accuracy: 0.9688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "835/835 [==============================] - 990s 1s/step - loss: 0.1298 - accuracy: 0.9582 - val_loss: 0.0412 - val_accuracy: 1.0000\n",
      "Epoch 3/30\n",
      "835/835 [==============================] - 990s 1s/step - loss: 0.1065 - accuracy: 0.9628 - val_loss: 0.0778 - val_accuracy: 0.9688\n",
      "Epoch 4/30\n",
      "835/835 [==============================] - 991s 1s/step - loss: 0.0875 - accuracy: 0.9706 - val_loss: 0.0565 - val_accuracy: 0.9688\n",
      "Epoch 5/30\n",
      "835/835 [==============================] - 992s 1s/step - loss: 0.0701 - accuracy: 0.9768 - val_loss: 0.0392 - val_accuracy: 0.9688\n",
      "Epoch 6/30\n",
      "835/835 [==============================] - 990s 1s/step - loss: 0.0528 - accuracy: 0.9826 - val_loss: 0.0358 - val_accuracy: 0.9688\n",
      "Epoch 7/30\n",
      "835/835 [==============================] - 989s 1s/step - loss: 0.0438 - accuracy: 0.9857 - val_loss: 0.0476 - val_accuracy: 0.9688\n",
      "Epoch 8/30\n",
      "835/835 [==============================] - 990s 1s/step - loss: 0.0306 - accuracy: 0.9898 - val_loss: 0.0318 - val_accuracy: 1.0000\n",
      "Epoch 9/30\n",
      "835/835 [==============================] - 990s 1s/step - loss: 0.0290 - accuracy: 0.9911 - val_loss: 0.1699 - val_accuracy: 0.9688\n",
      "Epoch 10/30\n",
      "835/835 [==============================] - 989s 1s/step - loss: 0.0242 - accuracy: 0.9924 - val_loss: 0.2224 - val_accuracy: 0.9688\n",
      "Epoch 11/30\n",
      "835/835 [==============================] - 989s 1s/step - loss: 0.0149 - accuracy: 0.9952 - val_loss: 0.0518 - val_accuracy: 0.9688\n",
      "Epoch 12/30\n",
      "835/835 [==============================] - 989s 1s/step - loss: 0.0159 - accuracy: 0.9951 - val_loss: 0.1960 - val_accuracy: 0.9688\n",
      "Epoch 13/30\n",
      "835/835 [==============================] - 989s 1s/step - loss: 0.0100 - accuracy: 0.9970 - val_loss: 0.1254 - val_accuracy: 0.9688\n",
      "Epoch 14/30\n",
      "835/835 [==============================] - 988s 1s/step - loss: 0.0097 - accuracy: 0.9967 - val_loss: 0.1336 - val_accuracy: 0.9688\n",
      "Epoch 15/30\n",
      "835/835 [==============================] - 989s 1s/step - loss: 0.0093 - accuracy: 0.9970 - val_loss: 0.1712 - val_accuracy: 0.9688\n",
      "Epoch 16/30\n",
      "835/835 [==============================] - 988s 1s/step - loss: 0.0091 - accuracy: 0.9976 - val_loss: 0.2447 - val_accuracy: 0.9688\n",
      "Epoch 17/30\n",
      "835/835 [==============================] - 988s 1s/step - loss: 0.0067 - accuracy: 0.9973 - val_loss: 0.3029 - val_accuracy: 0.9688\n",
      "Epoch 18/30\n",
      "835/835 [==============================] - 988s 1s/step - loss: 0.0058 - accuracy: 0.9981 - val_loss: 0.2276 - val_accuracy: 0.9688\n",
      "Epoch 19/30\n",
      "835/835 [==============================] - 990s 1s/step - loss: 0.0045 - accuracy: 0.9981 - val_loss: 0.1234 - val_accuracy: 0.9688\n",
      "Epoch 20/30\n",
      "835/835 [==============================] - 989s 1s/step - loss: 0.0044 - accuracy: 0.9980 - val_loss: 0.1555 - val_accuracy: 0.9688\n",
      "Epoch 21/30\n",
      "835/835 [==============================] - 988s 1s/step - loss: 0.0050 - accuracy: 0.9978 - val_loss: 0.2224 - val_accuracy: 0.9688\n",
      "Epoch 22/30\n",
      "835/835 [==============================] - 987s 1s/step - loss: 0.0038 - accuracy: 0.9981 - val_loss: 0.2115 - val_accuracy: 0.9688\n",
      "Epoch 23/30\n",
      "835/835 [==============================] - 988s 1s/step - loss: 0.0032 - accuracy: 0.9984 - val_loss: 0.2331 - val_accuracy: 0.9688\n",
      "Epoch 24/30\n",
      "835/835 [==============================] - 988s 1s/step - loss: 0.0039 - accuracy: 0.9981 - val_loss: 0.1883 - val_accuracy: 0.9688\n",
      "Epoch 25/30\n",
      "835/835 [==============================] - 989s 1s/step - loss: 0.0039 - accuracy: 0.9977 - val_loss: 0.1853 - val_accuracy: 0.9688\n",
      "Epoch 26/30\n",
      "835/835 [==============================] - 988s 1s/step - loss: 0.0029 - accuracy: 0.9986 - val_loss: 0.2518 - val_accuracy: 0.9688\n",
      "Epoch 27/30\n",
      "835/835 [==============================] - 987s 1s/step - loss: 0.0026 - accuracy: 0.9984 - val_loss: 0.2021 - val_accuracy: 0.9688\n",
      "Epoch 28/30\n",
      "835/835 [==============================] - 989s 1s/step - loss: 0.0032 - accuracy: 0.9982 - val_loss: 0.2106 - val_accuracy: 0.9688\n",
      "Epoch 29/30\n",
      "835/835 [==============================] - 989s 1s/step - loss: 0.0025 - accuracy: 0.9984 - val_loss: 0.2451 - val_accuracy: 0.9688\n",
      "Epoch 30/30\n",
      "835/835 [==============================] - 989s 1s/step - loss: 0.0032 - accuracy: 0.9983 - val_loss: 0.2159 - val_accuracy: 0.9688\n",
      "INFO:tensorflow:Assets written to: ../opticnet/opticnet_30epochs_41742.0 images/assets\n",
      "Test acc for opticnet: 0.994835\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.59893597 0.60188147 0.60107508 0.59366295]\n",
      "Training xception for 0.6% of train size (aka 50090 images)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "   6/1002 [..............................] - ETA: 22:12 - loss: 1.3931 - accuracy: 0.4337WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1611s vs `on_train_batch_begin` time: 0.1866s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1611s vs `on_train_batch_end` time: 0.8856s). Check your callbacks.\n",
      "1002/1002 [==============================] - 795s 788ms/step - loss: 1.0753 - accuracy: 0.8199 - val_loss: 0.5800 - val_accuracy: 0.9375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "1002/1002 [==============================] - 787s 786ms/step - loss: 0.4466 - accuracy: 0.9467 - val_loss: 0.2469 - val_accuracy: 1.0000\n",
      "Epoch 3/30\n",
      "1002/1002 [==============================] - 785s 783ms/step - loss: 0.2669 - accuracy: 0.9599 - val_loss: 0.2590 - val_accuracy: 0.9688\n",
      "Epoch 4/30\n",
      "1002/1002 [==============================] - 787s 785ms/step - loss: 0.1806 - accuracy: 0.9696 - val_loss: 0.0937 - val_accuracy: 1.0000\n",
      "Epoch 5/30\n",
      "1002/1002 [==============================] - 787s 785ms/step - loss: 0.1288 - accuracy: 0.9784 - val_loss: 0.0782 - val_accuracy: 1.0000\n",
      "Epoch 6/30\n",
      "1002/1002 [==============================] - 791s 789ms/step - loss: 0.0955 - accuracy: 0.9832 - val_loss: 0.0480 - val_accuracy: 1.0000\n",
      "Epoch 7/30\n",
      "1002/1002 [==============================] - 790s 788ms/step - loss: 0.0734 - accuracy: 0.9873 - val_loss: 0.0484 - val_accuracy: 1.0000\n",
      "Epoch 8/30\n",
      "1002/1002 [==============================] - 787s 785ms/step - loss: 0.0600 - accuracy: 0.9892 - val_loss: 0.0256 - val_accuracy: 1.0000\n",
      "Epoch 9/30\n",
      "1002/1002 [==============================] - 790s 788ms/step - loss: 0.0478 - accuracy: 0.9918 - val_loss: 0.1374 - val_accuracy: 0.9688\n",
      "Epoch 10/30\n",
      "1002/1002 [==============================] - 785s 784ms/step - loss: 0.0394 - accuracy: 0.9936 - val_loss: 0.1152 - val_accuracy: 0.9688\n",
      "Epoch 11/30\n",
      "1002/1002 [==============================] - 790s 788ms/step - loss: 0.0366 - accuracy: 0.9940 - val_loss: 0.0922 - val_accuracy: 0.9688\n",
      "Epoch 12/30\n",
      "1002/1002 [==============================] - 785s 783ms/step - loss: 0.0318 - accuracy: 0.9949 - val_loss: 0.0604 - val_accuracy: 0.9688\n",
      "Epoch 13/30\n",
      "1002/1002 [==============================] - 790s 788ms/step - loss: 0.0307 - accuracy: 0.9950 - val_loss: 0.1715 - val_accuracy: 0.9688\n",
      "Epoch 14/30\n",
      "1002/1002 [==============================] - 786s 784ms/step - loss: 0.0288 - accuracy: 0.9953 - val_loss: 0.1805 - val_accuracy: 0.9688\n",
      "Epoch 15/30\n",
      "1002/1002 [==============================] - 787s 785ms/step - loss: 0.0277 - accuracy: 0.9953 - val_loss: 0.1945 - val_accuracy: 0.9688\n",
      "Epoch 16/30\n",
      "1002/1002 [==============================] - 788s 786ms/step - loss: 0.0259 - accuracy: 0.9954 - val_loss: 0.1071 - val_accuracy: 0.9688\n",
      "Epoch 17/30\n",
      "1002/1002 [==============================] - 785s 783ms/step - loss: 0.0241 - accuracy: 0.9955 - val_loss: 0.1311 - val_accuracy: 0.9688\n",
      "Epoch 18/30\n",
      "1002/1002 [==============================] - 786s 785ms/step - loss: 0.0250 - accuracy: 0.9958 - val_loss: 0.0994 - val_accuracy: 0.9688\n",
      "Epoch 19/30\n",
      "1002/1002 [==============================] - 791s 790ms/step - loss: 0.0224 - accuracy: 0.9960 - val_loss: 0.1920 - val_accuracy: 0.9688\n",
      "Epoch 20/30\n",
      "1002/1002 [==============================] - 790s 788ms/step - loss: 0.0202 - accuracy: 0.9967 - val_loss: 0.1802 - val_accuracy: 0.9688\n",
      "Epoch 21/30\n",
      "1002/1002 [==============================] - 786s 784ms/step - loss: 0.0215 - accuracy: 0.9958 - val_loss: 0.1898 - val_accuracy: 0.9688\n",
      "Epoch 22/30\n",
      "1002/1002 [==============================] - 791s 789ms/step - loss: 0.0181 - accuracy: 0.9967 - val_loss: 0.2055 - val_accuracy: 0.9688\n",
      "Epoch 23/30\n",
      "1002/1002 [==============================] - 790s 788ms/step - loss: 0.0186 - accuracy: 0.9964 - val_loss: 0.2250 - val_accuracy: 0.9688\n",
      "Epoch 24/30\n",
      "1002/1002 [==============================] - 789s 788ms/step - loss: 0.0201 - accuracy: 0.9964 - val_loss: 0.1987 - val_accuracy: 0.9688\n",
      "Epoch 25/30\n",
      "1002/1002 [==============================] - 786s 785ms/step - loss: 0.0196 - accuracy: 0.9964 - val_loss: 0.2069 - val_accuracy: 0.9688\n",
      "Epoch 26/30\n",
      "1002/1002 [==============================] - 789s 787ms/step - loss: 0.0178 - accuracy: 0.9968 - val_loss: 0.2066 - val_accuracy: 0.9688\n",
      "Epoch 27/30\n",
      "1002/1002 [==============================] - 788s 787ms/step - loss: 0.0165 - accuracy: 0.9969 - val_loss: 0.2110 - val_accuracy: 0.9688\n",
      "Epoch 28/30\n",
      "1002/1002 [==============================] - 788s 786ms/step - loss: 0.0166 - accuracy: 0.9968 - val_loss: 0.2134 - val_accuracy: 0.9688\n",
      "Epoch 29/30\n",
      "1002/1002 [==============================] - 789s 787ms/step - loss: 0.0193 - accuracy: 0.9965 - val_loss: 0.2134 - val_accuracy: 0.9688\n",
      "Epoch 30/30\n",
      "1002/1002 [==============================] - 788s 786ms/step - loss: 0.0152 - accuracy: 0.9973 - val_loss: 0.2150 - val_accuracy: 0.9688\n",
      "INFO:tensorflow:Assets written to: ../xception/xception_30epochs_50090.4 images/assets\n",
      "Test acc for xception: 0.993802\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training resnet for 0.6% of train size (aka 50090 images)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "   6/1002 [..............................] - ETA: 12:39 - loss: 1.4012 - accuracy: 0.2133WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1043s vs `on_train_batch_begin` time: 0.1820s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1043s vs `on_train_batch_end` time: 0.3733s). Check your callbacks.\n",
      "1002/1002 [==============================] - 214s 205ms/step - loss: 1.1230 - accuracy: 0.6852 - val_loss: 0.9502 - val_accuracy: 0.6562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "1002/1002 [==============================] - 201s 200ms/step - loss: 0.6479 - accuracy: 0.8201 - val_loss: 0.6466 - val_accuracy: 0.7188\n",
      "Epoch 3/30\n",
      "1002/1002 [==============================] - 201s 200ms/step - loss: 0.5192 - accuracy: 0.8249 - val_loss: 0.7320 - val_accuracy: 0.6875\n",
      "Epoch 4/30\n",
      "1002/1002 [==============================] - 201s 200ms/step - loss: 0.4483 - accuracy: 0.8362 - val_loss: 0.4409 - val_accuracy: 0.9062\n",
      "Epoch 5/30\n",
      "1002/1002 [==============================] - 201s 200ms/step - loss: 0.2585 - accuracy: 0.9610 - val_loss: 0.3977 - val_accuracy: 0.8750\n",
      "Epoch 6/30\n",
      "1002/1002 [==============================] - 202s 201ms/step - loss: 0.1700 - accuracy: 0.9674 - val_loss: 0.0827 - val_accuracy: 1.0000\n",
      "Epoch 7/30\n",
      "1002/1002 [==============================] - 201s 201ms/step - loss: 0.1266 - accuracy: 0.9751 - val_loss: 0.0572 - val_accuracy: 1.0000\n",
      "Epoch 8/30\n",
      "1002/1002 [==============================] - 201s 200ms/step - loss: 0.1009 - accuracy: 0.9795 - val_loss: 0.0537 - val_accuracy: 1.0000\n",
      "Epoch 9/30\n",
      "1002/1002 [==============================] - 201s 201ms/step - loss: 0.0865 - accuracy: 0.9822 - val_loss: 0.0328 - val_accuracy: 1.0000\n",
      "Epoch 10/30\n",
      "1002/1002 [==============================] - 201s 201ms/step - loss: 0.0697 - accuracy: 0.9857 - val_loss: 0.0281 - val_accuracy: 1.0000\n",
      "Epoch 11/30\n",
      "1002/1002 [==============================] - 201s 201ms/step - loss: 0.0552 - accuracy: 0.9897 - val_loss: 0.0298 - val_accuracy: 1.0000\n",
      "Epoch 12/30\n",
      "1002/1002 [==============================] - 202s 201ms/step - loss: 0.0492 - accuracy: 0.9909 - val_loss: 0.0335 - val_accuracy: 1.0000\n",
      "Epoch 13/30\n",
      "1002/1002 [==============================] - 201s 200ms/step - loss: 0.0463 - accuracy: 0.9909 - val_loss: 0.0209 - val_accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "1002/1002 [==============================] - 201s 200ms/step - loss: 0.0413 - accuracy: 0.9928 - val_loss: 0.2013 - val_accuracy: 0.9688\n",
      "Epoch 15/30\n",
      "1002/1002 [==============================] - 201s 200ms/step - loss: 0.0372 - accuracy: 0.9933 - val_loss: 0.1721 - val_accuracy: 0.9688\n",
      "Epoch 16/30\n",
      "1002/1002 [==============================] - 201s 201ms/step - loss: 0.0354 - accuracy: 0.9938 - val_loss: 0.0350 - val_accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "1002/1002 [==============================] - 201s 201ms/step - loss: 0.0332 - accuracy: 0.9943 - val_loss: 0.1406 - val_accuracy: 0.9688\n",
      "Epoch 18/30\n",
      "1002/1002 [==============================] - 201s 201ms/step - loss: 0.0330 - accuracy: 0.9942 - val_loss: 0.1958 - val_accuracy: 0.9688\n",
      "Epoch 19/30\n",
      "1002/1002 [==============================] - 201s 201ms/step - loss: 0.0301 - accuracy: 0.9950 - val_loss: 0.1366 - val_accuracy: 0.9688\n",
      "Epoch 20/30\n",
      "1002/1002 [==============================] - 201s 201ms/step - loss: 0.0267 - accuracy: 0.9953 - val_loss: 0.1278 - val_accuracy: 0.9688\n",
      "Epoch 21/30\n",
      "1002/1002 [==============================] - 202s 201ms/step - loss: 0.0252 - accuracy: 0.9954 - val_loss: 0.1649 - val_accuracy: 0.9688\n",
      "Epoch 22/30\n",
      "1002/1002 [==============================] - 201s 201ms/step - loss: 0.0248 - accuracy: 0.9956 - val_loss: 0.1970 - val_accuracy: 0.9688\n",
      "Epoch 23/30\n",
      "1002/1002 [==============================] - 201s 200ms/step - loss: 0.0251 - accuracy: 0.9952 - val_loss: 0.1766 - val_accuracy: 0.9688\n",
      "Epoch 24/30\n",
      "1002/1002 [==============================] - 201s 201ms/step - loss: 0.0234 - accuracy: 0.9957 - val_loss: 0.1608 - val_accuracy: 0.9688\n",
      "Epoch 25/30\n",
      "1002/1002 [==============================] - 201s 201ms/step - loss: 0.0215 - accuracy: 0.9965 - val_loss: 0.1835 - val_accuracy: 0.9688\n",
      "Epoch 26/30\n",
      "1002/1002 [==============================] - 201s 201ms/step - loss: 0.0206 - accuracy: 0.9964 - val_loss: 0.1414 - val_accuracy: 0.9688\n",
      "Epoch 27/30\n",
      "1002/1002 [==============================] - 201s 201ms/step - loss: 0.0213 - accuracy: 0.9961 - val_loss: 0.1414 - val_accuracy: 0.9688\n",
      "Epoch 28/30\n",
      "1002/1002 [==============================] - 201s 201ms/step - loss: 0.0216 - accuracy: 0.9959 - val_loss: 0.1429 - val_accuracy: 0.9688\n",
      "Epoch 29/30\n",
      "1002/1002 [==============================] - 201s 201ms/step - loss: 0.0206 - accuracy: 0.9963 - val_loss: 0.1615 - val_accuracy: 0.9688\n",
      "Epoch 30/30\n",
      "1002/1002 [==============================] - 201s 201ms/step - loss: 0.0209 - accuracy: 0.9959 - val_loss: 0.1622 - val_accuracy: 0.9688\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_50090.4 images/assets\n",
      "Test acc for resnet: 0.990702\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training opticnet for 0.6% of train size (aka 50090 images)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "   6/1002 [..............................] - ETA: 31:02 - loss: 5.4249 - accuracy: 0.1437  WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.4625s vs `on_train_batch_end` time: 1.0821s). Check your callbacks.\n",
      "1002/1002 [==============================] - 1206s 1s/step - loss: 0.3683 - accuracy: 0.8904 - val_loss: 0.0516 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "1002/1002 [==============================] - 1185s 1s/step - loss: 0.1284 - accuracy: 0.9570 - val_loss: 0.1179 - val_accuracy: 0.9688\n",
      "Epoch 3/30\n",
      "1002/1002 [==============================] - 1187s 1s/step - loss: 0.1045 - accuracy: 0.9644 - val_loss: 0.0366 - val_accuracy: 1.0000\n",
      "Epoch 4/30\n",
      "1002/1002 [==============================] - 1189s 1s/step - loss: 0.0872 - accuracy: 0.9711 - val_loss: 0.0219 - val_accuracy: 1.0000\n",
      "Epoch 5/30\n",
      "1002/1002 [==============================] - 1185s 1s/step - loss: 0.0715 - accuracy: 0.9757 - val_loss: 0.0454 - val_accuracy: 0.9688\n",
      "Epoch 6/30\n",
      "1002/1002 [==============================] - 1190s 1s/step - loss: 0.0559 - accuracy: 0.9809 - val_loss: 0.0562 - val_accuracy: 0.9688\n",
      "Epoch 7/30\n",
      "1002/1002 [==============================] - 1186s 1s/step - loss: 0.0416 - accuracy: 0.9859 - val_loss: 0.0425 - val_accuracy: 0.9688\n",
      "Epoch 8/30\n",
      "1002/1002 [==============================] - 1185s 1s/step - loss: 0.0332 - accuracy: 0.9891 - val_loss: 0.1952 - val_accuracy: 0.9688\n",
      "Epoch 9/30\n",
      "1002/1002 [==============================] - 1186s 1s/step - loss: 0.0247 - accuracy: 0.9921 - val_loss: 0.1281 - val_accuracy: 0.9688\n",
      "Epoch 10/30\n",
      "1002/1002 [==============================] - 1185s 1s/step - loss: 0.0241 - accuracy: 0.9919 - val_loss: 0.1342 - val_accuracy: 0.9688\n",
      "Epoch 11/30\n",
      "1002/1002 [==============================] - 1186s 1s/step - loss: 0.0200 - accuracy: 0.9934 - val_loss: 0.2771 - val_accuracy: 0.9688\n",
      "Epoch 12/30\n",
      "1002/1002 [==============================] - 1184s 1s/step - loss: 0.0150 - accuracy: 0.9952 - val_loss: 0.1555 - val_accuracy: 0.9688\n",
      "Epoch 13/30\n",
      "1002/1002 [==============================] - 1184s 1s/step - loss: 0.0113 - accuracy: 0.9966 - val_loss: 0.1674 - val_accuracy: 0.9688\n",
      "Epoch 14/30\n",
      "1002/1002 [==============================] - 1186s 1s/step - loss: 0.0103 - accuracy: 0.9968 - val_loss: 0.1982 - val_accuracy: 0.9688\n",
      "Epoch 15/30\n",
      "1002/1002 [==============================] - 1185s 1s/step - loss: 0.0114 - accuracy: 0.9962 - val_loss: 0.1135 - val_accuracy: 0.9688\n",
      "Epoch 16/30\n",
      "1002/1002 [==============================] - 1184s 1s/step - loss: 0.0074 - accuracy: 0.9973 - val_loss: 0.0496 - val_accuracy: 0.9688\n",
      "Epoch 17/30\n",
      "1002/1002 [==============================] - 1187s 1s/step - loss: 0.0064 - accuracy: 0.9979 - val_loss: 0.1148 - val_accuracy: 0.9688\n",
      "Epoch 18/30\n",
      "1002/1002 [==============================] - 1185s 1s/step - loss: 0.0063 - accuracy: 0.9977 - val_loss: 0.2740 - val_accuracy: 0.9688\n",
      "Epoch 19/30\n",
      "1002/1002 [==============================] - 1186s 1s/step - loss: 0.0057 - accuracy: 0.9978 - val_loss: 0.1570 - val_accuracy: 0.9688\n",
      "Epoch 20/30\n",
      "1002/1002 [==============================] - 1184s 1s/step - loss: 0.0061 - accuracy: 0.9976 - val_loss: 0.1590 - val_accuracy: 0.9688\n",
      "Epoch 21/30\n",
      "1002/1002 [==============================] - 1185s 1s/step - loss: 0.0046 - accuracy: 0.9977 - val_loss: 0.1605 - val_accuracy: 0.9688\n",
      "Epoch 22/30\n",
      "1002/1002 [==============================] - 1186s 1s/step - loss: 0.0049 - accuracy: 0.9978 - val_loss: 0.0973 - val_accuracy: 0.9688\n",
      "Epoch 23/30\n",
      "1002/1002 [==============================] - 1184s 1s/step - loss: 0.0047 - accuracy: 0.9976 - val_loss: 0.1073 - val_accuracy: 0.9688\n",
      "Epoch 24/30\n",
      "1002/1002 [==============================] - 1181s 1s/step - loss: 0.0049 - accuracy: 0.9977 - val_loss: 0.1455 - val_accuracy: 0.9688\n",
      "Epoch 25/30\n",
      "1002/1002 [==============================] - 1186s 1s/step - loss: 0.0041 - accuracy: 0.9978 - val_loss: 0.1819 - val_accuracy: 0.9688\n",
      "Epoch 26/30\n",
      "1002/1002 [==============================] - 1184s 1s/step - loss: 0.0038 - accuracy: 0.9979 - val_loss: 0.1637 - val_accuracy: 0.9688\n",
      "Epoch 27/30\n",
      "1002/1002 [==============================] - 1184s 1s/step - loss: 0.0033 - accuracy: 0.9978 - val_loss: 0.1781 - val_accuracy: 0.9688\n",
      "Epoch 28/30\n",
      "1002/1002 [==============================] - 1183s 1s/step - loss: 0.0029 - accuracy: 0.9986 - val_loss: 0.1624 - val_accuracy: 0.9688\n",
      "Epoch 29/30\n",
      "1002/1002 [==============================] - 1185s 1s/step - loss: 0.0030 - accuracy: 0.9984 - val_loss: 0.2019 - val_accuracy: 0.9688\n",
      "Epoch 30/30\n",
      "1002/1002 [==============================] - 1186s 1s/step - loss: 0.0033 - accuracy: 0.9980 - val_loss: 0.1819 - val_accuracy: 0.9688\n",
      "INFO:tensorflow:Assets written to: ../opticnet/opticnet_30epochs_50090.4 images/assets\n",
      "Test acc for opticnet: 0.997934\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.74755843 0.75183443 0.74955939 0.75011606]\n",
      "Training xception for 0.75% of train size (aka 62613 images)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "   6/1253 [..............................] - ETA: 28:45 - loss: 1.4155 - accuracy: 0.1172WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1610s vs `on_train_batch_begin` time: 0.1873s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1610s vs `on_train_batch_end` time: 0.9224s). Check your callbacks.\n",
      "1253/1253 [==============================] - 1078s 856ms/step - loss: 1.0394 - accuracy: 0.7599 - val_loss: 0.5100 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "1253/1253 [==============================] - 1069s 853ms/step - loss: 0.3764 - accuracy: 0.9619 - val_loss: 0.2058 - val_accuracy: 1.0000\n",
      "Epoch 3/30\n",
      "1253/1253 [==============================] - 1072s 856ms/step - loss: 0.2006 - accuracy: 0.9728 - val_loss: 0.1163 - val_accuracy: 1.0000\n",
      "Epoch 4/30\n",
      "1253/1253 [==============================] - 1067s 851ms/step - loss: 0.1285 - accuracy: 0.9800 - val_loss: 0.1151 - val_accuracy: 0.9688\n",
      "Epoch 5/30\n",
      "1253/1253 [==============================] - 1070s 854ms/step - loss: 0.0862 - accuracy: 0.9864 - val_loss: 0.1869 - val_accuracy: 0.9688\n",
      "Epoch 6/30\n",
      "1253/1253 [==============================] - 1072s 855ms/step - loss: 0.0637 - accuracy: 0.9891 - val_loss: 0.1775 - val_accuracy: 0.9688\n",
      "Epoch 7/30\n",
      "1253/1253 [==============================] - 1072s 856ms/step - loss: 0.0494 - accuracy: 0.9915 - val_loss: 0.1786 - val_accuracy: 0.9688\n",
      "Epoch 8/30\n",
      "1253/1253 [==============================] - 1067s 851ms/step - loss: 0.0421 - accuracy: 0.9920 - val_loss: 0.2024 - val_accuracy: 0.9688\n",
      "Epoch 9/30\n",
      "1253/1253 [==============================] - 1070s 854ms/step - loss: 0.0333 - accuracy: 0.9941 - val_loss: 0.0848 - val_accuracy: 0.9688\n",
      "Epoch 10/30\n",
      "1253/1253 [==============================] - 1056s 843ms/step - loss: 0.0322 - accuracy: 0.9938 - val_loss: 0.1217 - val_accuracy: 0.9688\n",
      "Epoch 11/30\n",
      "1253/1253 [==============================] - 1062s 848ms/step - loss: 0.0250 - accuracy: 0.9951 - val_loss: 0.2033 - val_accuracy: 0.9688\n",
      "Epoch 12/30\n",
      "1253/1253 [==============================] - 1070s 854ms/step - loss: 0.0237 - accuracy: 0.9956 - val_loss: 0.1699 - val_accuracy: 0.9688\n",
      "Epoch 13/30\n",
      "1253/1253 [==============================] - 1070s 854ms/step - loss: 0.0242 - accuracy: 0.9951 - val_loss: 0.2188 - val_accuracy: 0.9688\n",
      "Epoch 14/30\n",
      "1253/1253 [==============================] - 1073s 856ms/step - loss: 0.0225 - accuracy: 0.9957 - val_loss: 0.2020 - val_accuracy: 0.9688\n",
      "Epoch 15/30\n",
      "1253/1253 [==============================] - 1070s 854ms/step - loss: 0.0219 - accuracy: 0.9955 - val_loss: 0.1921 - val_accuracy: 0.9688\n",
      "Epoch 16/30\n",
      "1253/1253 [==============================] - 1073s 856ms/step - loss: 0.0180 - accuracy: 0.9963 - val_loss: 0.2048 - val_accuracy: 0.9688\n",
      "Epoch 17/30\n",
      "1253/1253 [==============================] - 1063s 849ms/step - loss: 0.0215 - accuracy: 0.9959 - val_loss: 0.1870 - val_accuracy: 0.9688\n",
      "Epoch 18/30\n",
      "1253/1253 [==============================] - 1070s 854ms/step - loss: 0.0175 - accuracy: 0.9963 - val_loss: 0.1869 - val_accuracy: 0.9688\n",
      "Epoch 19/30\n",
      "1253/1253 [==============================] - 1069s 854ms/step - loss: 0.0177 - accuracy: 0.9965 - val_loss: 0.2106 - val_accuracy: 0.9688\n",
      "Epoch 20/30\n",
      "1253/1253 [==============================] - 1069s 853ms/step - loss: 0.0182 - accuracy: 0.9963 - val_loss: 0.2196 - val_accuracy: 0.9688\n",
      "Epoch 21/30\n",
      "1253/1253 [==============================] - 1070s 854ms/step - loss: 0.0182 - accuracy: 0.9961 - val_loss: 0.2090 - val_accuracy: 0.9688\n",
      "Epoch 22/30\n",
      "1253/1253 [==============================] - 1069s 853ms/step - loss: 0.0168 - accuracy: 0.9963 - val_loss: 0.2146 - val_accuracy: 0.9688\n",
      "Epoch 23/30\n",
      "1253/1253 [==============================] - 1070s 854ms/step - loss: 0.0175 - accuracy: 0.9962 - val_loss: 0.2168 - val_accuracy: 0.9688\n",
      "Epoch 24/30\n",
      "1253/1253 [==============================] - 1072s 856ms/step - loss: 0.0158 - accuracy: 0.9965 - val_loss: 0.2141 - val_accuracy: 0.9688\n",
      "Epoch 25/30\n",
      "1253/1253 [==============================] - 1069s 854ms/step - loss: 0.0151 - accuracy: 0.9967 - val_loss: 0.2120 - val_accuracy: 0.9688\n",
      "Epoch 26/30\n",
      "1253/1253 [==============================] - 1072s 856ms/step - loss: 0.0145 - accuracy: 0.9967 - val_loss: 0.2160 - val_accuracy: 0.9688\n",
      "Epoch 27/30\n",
      "1253/1253 [==============================] - 1069s 853ms/step - loss: 0.0149 - accuracy: 0.9963 - val_loss: 0.2189 - val_accuracy: 0.9688\n",
      "Epoch 28/30\n",
      "1253/1253 [==============================] - 1069s 853ms/step - loss: 0.0150 - accuracy: 0.9966 - val_loss: 0.2192 - val_accuracy: 0.9688\n",
      "Epoch 29/30\n",
      "1253/1253 [==============================] - 1073s 856ms/step - loss: 0.0141 - accuracy: 0.9967 - val_loss: 0.2205 - val_accuracy: 0.9688\n",
      "Epoch 30/30\n",
      "1253/1253 [==============================] - 1070s 854ms/step - loss: 0.0159 - accuracy: 0.9963 - val_loss: 0.2181 - val_accuracy: 0.9688\n",
      "INFO:tensorflow:Assets written to: ../xception/xception_30epochs_62613.0 images/assets\n",
      "Test acc for xception: 0.996901\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training resnet for 0.75% of train size (aka 62613 images)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "   6/1253 [..............................] - ETA: 15:10 - loss: 1.4382 - accuracy: 0.0972WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1027s vs `on_train_batch_begin` time: 0.1898s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1027s vs `on_train_batch_end` time: 0.3420s). Check your callbacks.\n",
      "1253/1253 [==============================] - 260s 202ms/step - loss: 1.1082 - accuracy: 0.6893 - val_loss: 0.8691 - val_accuracy: 0.7188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "1253/1253 [==============================] - 250s 199ms/step - loss: 0.5633 - accuracy: 0.8612 - val_loss: 0.3228 - val_accuracy: 0.9688\n",
      "Epoch 3/30\n",
      "1253/1253 [==============================] - 250s 199ms/step - loss: 0.2558 - accuracy: 0.9578 - val_loss: 0.1463 - val_accuracy: 1.0000\n",
      "Epoch 4/30\n",
      "1253/1253 [==============================] - 250s 200ms/step - loss: 0.1654 - accuracy: 0.9683 - val_loss: 0.0791 - val_accuracy: 1.0000\n",
      "Epoch 5/30\n",
      "1253/1253 [==============================] - 250s 199ms/step - loss: 0.1155 - accuracy: 0.9766 - val_loss: 0.0602 - val_accuracy: 1.0000\n",
      "Epoch 6/30\n",
      "1253/1253 [==============================] - 250s 199ms/step - loss: 0.0852 - accuracy: 0.9825 - val_loss: 0.0763 - val_accuracy: 0.9688\n",
      "Epoch 7/30\n",
      "1253/1253 [==============================] - 250s 199ms/step - loss: 0.0723 - accuracy: 0.9847 - val_loss: 0.0569 - val_accuracy: 0.9688\n",
      "Epoch 8/30\n",
      "1253/1253 [==============================] - 250s 200ms/step - loss: 0.0566 - accuracy: 0.9883 - val_loss: 0.0711 - val_accuracy: 0.9688\n",
      "Epoch 9/30\n",
      "1253/1253 [==============================] - 250s 199ms/step - loss: 0.0458 - accuracy: 0.9910 - val_loss: 0.0963 - val_accuracy: 0.9688\n",
      "Epoch 10/30\n",
      "1253/1253 [==============================] - 250s 199ms/step - loss: 0.0417 - accuracy: 0.9915 - val_loss: 0.0781 - val_accuracy: 0.9688\n",
      "Epoch 11/30\n",
      "1253/1253 [==============================] - 250s 199ms/step - loss: 0.0353 - accuracy: 0.9933 - val_loss: 0.1348 - val_accuracy: 0.9688\n",
      "Epoch 12/30\n",
      "1253/1253 [==============================] - 250s 200ms/step - loss: 0.0333 - accuracy: 0.9938 - val_loss: 0.1584 - val_accuracy: 0.9688\n",
      "Epoch 13/30\n",
      "1253/1253 [==============================] - 250s 199ms/step - loss: 0.0277 - accuracy: 0.9947 - val_loss: 0.1850 - val_accuracy: 0.9688\n",
      "Epoch 14/30\n",
      "1253/1253 [==============================] - 250s 199ms/step - loss: 0.0288 - accuracy: 0.9944 - val_loss: 0.1527 - val_accuracy: 0.9688\n",
      "Epoch 15/30\n",
      "1253/1253 [==============================] - 250s 199ms/step - loss: 0.0272 - accuracy: 0.9947 - val_loss: 0.2396 - val_accuracy: 0.9375\n",
      "Epoch 16/30\n",
      "1253/1253 [==============================] - 250s 200ms/step - loss: 0.0248 - accuracy: 0.9952 - val_loss: 0.1280 - val_accuracy: 0.9688\n",
      "Epoch 17/30\n",
      "1253/1253 [==============================] - 250s 200ms/step - loss: 0.0257 - accuracy: 0.9949 - val_loss: 0.2096 - val_accuracy: 0.9688\n",
      "Epoch 18/30\n",
      "1253/1253 [==============================] - 250s 200ms/step - loss: 0.0234 - accuracy: 0.9954 - val_loss: 0.1800 - val_accuracy: 0.9688\n",
      "Epoch 19/30\n",
      "1253/1253 [==============================] - 250s 199ms/step - loss: 0.0216 - accuracy: 0.9957 - val_loss: 0.2024 - val_accuracy: 0.9688\n",
      "Epoch 20/30\n",
      "1253/1253 [==============================] - 250s 199ms/step - loss: 0.0221 - accuracy: 0.9955 - val_loss: 0.1519 - val_accuracy: 0.9688\n",
      "Epoch 21/30\n",
      "1253/1253 [==============================] - 250s 200ms/step - loss: 0.0212 - accuracy: 0.9955 - val_loss: 0.1785 - val_accuracy: 0.9688\n",
      "Epoch 22/30\n",
      "1253/1253 [==============================] - 250s 200ms/step - loss: 0.0205 - accuracy: 0.9953 - val_loss: 0.1088 - val_accuracy: 0.9688\n",
      "Epoch 23/30\n",
      "1253/1253 [==============================] - 250s 200ms/step - loss: 0.0177 - accuracy: 0.9960 - val_loss: 0.1639 - val_accuracy: 0.9688\n",
      "Epoch 24/30\n",
      "1253/1253 [==============================] - 250s 200ms/step - loss: 0.0172 - accuracy: 0.9965 - val_loss: 0.1892 - val_accuracy: 0.9688\n",
      "Epoch 25/30\n",
      "1253/1253 [==============================] - 250s 200ms/step - loss: 0.0177 - accuracy: 0.9963 - val_loss: 0.2038 - val_accuracy: 0.9688\n",
      "Epoch 26/30\n",
      "1253/1253 [==============================] - 250s 199ms/step - loss: 0.0172 - accuracy: 0.9960 - val_loss: 0.1743 - val_accuracy: 0.9688\n",
      "Epoch 27/30\n",
      "1253/1253 [==============================] - 250s 200ms/step - loss: 0.0164 - accuracy: 0.9964 - val_loss: 0.2061 - val_accuracy: 0.9688\n",
      "Epoch 28/30\n",
      "1253/1253 [==============================] - 250s 200ms/step - loss: 0.0175 - accuracy: 0.9960 - val_loss: 0.1443 - val_accuracy: 0.9688\n",
      "Epoch 29/30\n",
      "1253/1253 [==============================] - 250s 200ms/step - loss: 0.0155 - accuracy: 0.9966 - val_loss: 0.2158 - val_accuracy: 0.9688\n",
      "Epoch 30/30\n",
      "1253/1253 [==============================] - 250s 200ms/step - loss: 0.0151 - accuracy: 0.9965 - val_loss: 0.2182 - val_accuracy: 0.9688\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_62613.0 images/assets\n",
      "Test acc for resnet: 0.993802\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training opticnet for 0.75% of train size (aka 62613 images)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "   6/1253 [..............................] - ETA: 38:54 - loss: 5.7165 - accuracy: 0.0948  WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.4651s vs `on_train_batch_end` time: 1.0849s). Check your callbacks.\n",
      "1253/1253 [==============================] - 1502s 1s/step - loss: 0.3410 - accuracy: 0.9011 - val_loss: 0.0709 - val_accuracy: 0.9688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "1253/1253 [==============================] - 1483s 1s/step - loss: 0.1276 - accuracy: 0.9581 - val_loss: 0.0412 - val_accuracy: 0.9688\n",
      "Epoch 3/30\n",
      "1253/1253 [==============================] - 1483s 1s/step - loss: 0.1077 - accuracy: 0.9646 - val_loss: 0.0287 - val_accuracy: 1.0000\n",
      "Epoch 4/30\n",
      "1253/1253 [==============================] - 1483s 1s/step - loss: 0.0899 - accuracy: 0.9692 - val_loss: 0.0567 - val_accuracy: 0.9688\n",
      "Epoch 5/30\n",
      "1253/1253 [==============================] - 1483s 1s/step - loss: 0.0712 - accuracy: 0.9755 - val_loss: 0.0432 - val_accuracy: 1.0000\n",
      "Epoch 6/30\n",
      "1253/1253 [==============================] - 1485s 1s/step - loss: 0.0544 - accuracy: 0.9811 - val_loss: 0.0440 - val_accuracy: 0.9688\n",
      "Epoch 7/30\n",
      "1253/1253 [==============================] - 1486s 1s/step - loss: 0.0465 - accuracy: 0.9841 - val_loss: 0.0158 - val_accuracy: 1.0000\n",
      "Epoch 8/30\n",
      "1253/1253 [==============================] - 1486s 1s/step - loss: 0.0348 - accuracy: 0.9883 - val_loss: 0.0282 - val_accuracy: 0.9688\n",
      "Epoch 9/30\n",
      "1253/1253 [==============================] - 1487s 1s/step - loss: 0.0260 - accuracy: 0.9918 - val_loss: 0.0042 - val_accuracy: 1.0000\n",
      "Epoch 10/30\n",
      "1253/1253 [==============================] - 1487s 1s/step - loss: 0.0217 - accuracy: 0.9930 - val_loss: 0.0076 - val_accuracy: 1.0000\n",
      "Epoch 11/30\n",
      "1253/1253 [==============================] - 1486s 1s/step - loss: 0.0199 - accuracy: 0.9936 - val_loss: 0.0108 - val_accuracy: 1.0000\n",
      "Epoch 12/30\n",
      "1253/1253 [==============================] - 1487s 1s/step - loss: 0.0173 - accuracy: 0.9944 - val_loss: 0.1554 - val_accuracy: 0.9688\n",
      "Epoch 13/30\n",
      "1253/1253 [==============================] - 1487s 1s/step - loss: 0.0130 - accuracy: 0.9957 - val_loss: 0.0344 - val_accuracy: 0.9688\n",
      "Epoch 14/30\n",
      "1253/1253 [==============================] - 1487s 1s/step - loss: 0.0117 - accuracy: 0.9962 - val_loss: 0.1694 - val_accuracy: 0.9688\n",
      "Epoch 15/30\n",
      "1253/1253 [==============================] - 1488s 1s/step - loss: 0.0105 - accuracy: 0.9964 - val_loss: 0.0772 - val_accuracy: 0.9688\n",
      "Epoch 16/30\n",
      "1253/1253 [==============================] - 1488s 1s/step - loss: 0.0102 - accuracy: 0.9964 - val_loss: 0.1274 - val_accuracy: 0.9688\n",
      "Epoch 17/30\n",
      "1253/1253 [==============================] - 1488s 1s/step - loss: 0.0071 - accuracy: 0.9974 - val_loss: 0.1152 - val_accuracy: 0.9688\n",
      "Epoch 18/30\n",
      "1253/1253 [==============================] - 1489s 1s/step - loss: 0.0066 - accuracy: 0.9977 - val_loss: 0.0818 - val_accuracy: 0.9688\n",
      "Epoch 19/30\n",
      "1253/1253 [==============================] - 1489s 1s/step - loss: 0.0074 - accuracy: 0.9967 - val_loss: 0.1299 - val_accuracy: 0.9688\n",
      "Epoch 20/30\n",
      "1253/1253 [==============================] - 1489s 1s/step - loss: 0.0056 - accuracy: 0.9973 - val_loss: 0.0906 - val_accuracy: 0.9688\n",
      "Epoch 21/30\n",
      "1253/1253 [==============================] - 1490s 1s/step - loss: 0.0052 - accuracy: 0.9974 - val_loss: 0.1094 - val_accuracy: 0.9688\n",
      "Epoch 22/30\n",
      "1253/1253 [==============================] - 1491s 1s/step - loss: 0.0054 - accuracy: 0.9974 - val_loss: 0.1146 - val_accuracy: 0.9688\n",
      "Epoch 23/30\n",
      "1253/1253 [==============================] - 1491s 1s/step - loss: 0.0042 - accuracy: 0.9977 - val_loss: 0.1429 - val_accuracy: 0.9688\n",
      "Epoch 24/30\n",
      "1253/1253 [==============================] - 1490s 1s/step - loss: 0.0051 - accuracy: 0.9969 - val_loss: 0.1462 - val_accuracy: 0.9688\n",
      "Epoch 25/30\n",
      "1253/1253 [==============================] - 1490s 1s/step - loss: 0.0044 - accuracy: 0.9976 - val_loss: 0.1123 - val_accuracy: 0.9688\n",
      "Epoch 26/30\n",
      "1253/1253 [==============================] - 1488s 1s/step - loss: 0.0041 - accuracy: 0.9971 - val_loss: 0.1199 - val_accuracy: 0.9688\n",
      "Epoch 27/30\n",
      "1253/1253 [==============================] - 1488s 1s/step - loss: 0.0037 - accuracy: 0.9975 - val_loss: 0.1549 - val_accuracy: 0.9688\n",
      "Epoch 28/30\n",
      "1253/1253 [==============================] - 1488s 1s/step - loss: 0.0040 - accuracy: 0.9977 - val_loss: 0.1813 - val_accuracy: 0.9688\n",
      "Epoch 29/30\n",
      "1253/1253 [==============================] - 1488s 1s/step - loss: 0.0039 - accuracy: 0.9975 - val_loss: 0.1896 - val_accuracy: 0.9688\n",
      "Epoch 30/30\n",
      "1253/1253 [==============================] - 1487s 1s/step - loss: 0.0043 - accuracy: 0.9967 - val_loss: 0.1563 - val_accuracy: 0.9688\n",
      "INFO:tensorflow:Assets written to: ../opticnet/opticnet_30epochs_62613.0 images/assets\n",
      "Test acc for opticnet: 0.995868\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.899981   0.90095417 0.89672189 0.9001857 ]\n",
      "Training xception for 0.9% of train size (aka 75135 images)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "   6/1503 [..............................] - ETA: 31:54 - loss: 1.3859 - accuracy: 0.1476WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1612s vs `on_train_batch_begin` time: 0.1904s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1612s vs `on_train_batch_end` time: 0.8308s). Check your callbacks.\n",
      "1503/1503 [==============================] - 1159s 767ms/step - loss: 0.9729 - accuracy: 0.8700 - val_loss: 0.3737 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "1503/1503 [==============================] - 1150s 765ms/step - loss: 0.2833 - accuracy: 0.9758 - val_loss: 0.1437 - val_accuracy: 1.0000\n",
      "Epoch 3/30\n",
      "1503/1503 [==============================] - 1150s 765ms/step - loss: 0.1363 - accuracy: 0.9836 - val_loss: 0.0735 - val_accuracy: 1.0000\n",
      "Epoch 4/30\n",
      "1503/1503 [==============================] - 1149s 765ms/step - loss: 0.0817 - accuracy: 0.9879 - val_loss: 0.0722 - val_accuracy: 0.9688\n",
      "Epoch 5/30\n",
      "1503/1503 [==============================] - 1152s 766ms/step - loss: 0.0546 - accuracy: 0.9911 - val_loss: 0.0567 - val_accuracy: 0.9688\n",
      "Epoch 6/30\n",
      "1503/1503 [==============================] - 1150s 765ms/step - loss: 0.0411 - accuracy: 0.9924 - val_loss: 0.0276 - val_accuracy: 1.0000\n",
      "Epoch 7/30\n",
      "1503/1503 [==============================] - 1149s 764ms/step - loss: 0.0354 - accuracy: 0.9929 - val_loss: 0.0172 - val_accuracy: 1.0000\n",
      "Epoch 8/30\n",
      "1503/1503 [==============================] - 1148s 764ms/step - loss: 0.0311 - accuracy: 0.9938 - val_loss: 0.0307 - val_accuracy: 0.9688\n",
      "Epoch 9/30\n",
      "1503/1503 [==============================] - 1146s 763ms/step - loss: 0.0271 - accuracy: 0.9942 - val_loss: 0.0195 - val_accuracy: 1.0000\n",
      "Epoch 10/30\n",
      "1503/1503 [==============================] - 1143s 760ms/step - loss: 0.0209 - accuracy: 0.9952 - val_loss: 0.0250 - val_accuracy: 1.0000\n",
      "Epoch 11/30\n",
      "1503/1503 [==============================] - 1146s 763ms/step - loss: 0.0239 - accuracy: 0.9945 - val_loss: 0.0351 - val_accuracy: 0.9688\n",
      "Epoch 12/30\n",
      "1503/1503 [==============================] - 1145s 762ms/step - loss: 0.0203 - accuracy: 0.9952 - val_loss: 0.0265 - val_accuracy: 0.9688\n",
      "Epoch 13/30\n",
      "1503/1503 [==============================] - 1142s 760ms/step - loss: 0.0190 - accuracy: 0.9952 - val_loss: 0.0265 - val_accuracy: 0.9688\n",
      "Epoch 14/30\n",
      "1503/1503 [==============================] - 1146s 762ms/step - loss: 0.0165 - accuracy: 0.9960 - val_loss: 0.0401 - val_accuracy: 0.9688\n",
      "Epoch 15/30\n",
      "1503/1503 [==============================] - 1146s 763ms/step - loss: 0.0172 - accuracy: 0.9960 - val_loss: 0.0274 - val_accuracy: 0.9688\n",
      "Epoch 16/30\n",
      "1503/1503 [==============================] - 1145s 762ms/step - loss: 0.0170 - accuracy: 0.9960 - val_loss: 0.0351 - val_accuracy: 0.9688\n",
      "Epoch 17/30\n",
      "1503/1503 [==============================] - 1145s 762ms/step - loss: 0.0147 - accuracy: 0.9964 - val_loss: 0.0181 - val_accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "1503/1503 [==============================] - 1145s 762ms/step - loss: 0.0159 - accuracy: 0.9962 - val_loss: 0.0259 - val_accuracy: 0.9688\n",
      "Epoch 19/30\n",
      "1503/1503 [==============================] - 1146s 762ms/step - loss: 0.0148 - accuracy: 0.9963 - val_loss: 0.0264 - val_accuracy: 0.9688\n",
      "Epoch 20/30\n",
      "1503/1503 [==============================] - 1146s 762ms/step - loss: 0.0142 - accuracy: 0.9961 - val_loss: 0.0311 - val_accuracy: 0.9688\n",
      "Epoch 21/30\n",
      "1503/1503 [==============================] - 1146s 762ms/step - loss: 0.0137 - accuracy: 0.9963 - val_loss: 0.0206 - val_accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "1503/1503 [==============================] - 1146s 763ms/step - loss: 0.0148 - accuracy: 0.9965 - val_loss: 0.0246 - val_accuracy: 0.9688\n",
      "Epoch 23/30\n",
      "1503/1503 [==============================] - 1146s 762ms/step - loss: 0.0131 - accuracy: 0.9965 - val_loss: 0.0239 - val_accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "1503/1503 [==============================] - 1146s 762ms/step - loss: 0.0132 - accuracy: 0.9963 - val_loss: 0.0237 - val_accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "1503/1503 [==============================] - 1146s 762ms/step - loss: 0.0142 - accuracy: 0.9962 - val_loss: 0.0216 - val_accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "1503/1503 [==============================] - 1142s 760ms/step - loss: 0.0138 - accuracy: 0.9965 - val_loss: 0.0219 - val_accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "1503/1503 [==============================] - 1146s 763ms/step - loss: 0.0133 - accuracy: 0.9966 - val_loss: 0.0213 - val_accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "1503/1503 [==============================] - 1147s 763ms/step - loss: 0.0134 - accuracy: 0.9967 - val_loss: 0.0212 - val_accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "1503/1503 [==============================] - 1146s 762ms/step - loss: 0.0136 - accuracy: 0.9965 - val_loss: 0.0189 - val_accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "1503/1503 [==============================] - 1145s 762ms/step - loss: 0.0145 - accuracy: 0.9967 - val_loss: 0.0237 - val_accuracy: 1.0000\n",
      "INFO:tensorflow:Assets written to: ../xception/xception_30epochs_75135.6 images/assets\n",
      "Test acc for xception: 0.997934\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training resnet for 0.9% of train size (aka 75135 images)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "   6/1503 [..............................] - ETA: 18:20 - loss: 1.4346 - accuracy: 0.0000e+00WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1056s vs `on_train_batch_begin` time: 0.1908s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1056s vs `on_train_batch_end` time: 0.3435s). Check your callbacks.\n",
      "1503/1503 [==============================] - 311s 202ms/step - loss: 1.0123 - accuracy: 0.8254 - val_loss: 0.8519 - val_accuracy: 0.7188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "1503/1503 [==============================] - 300s 200ms/step - loss: 0.3121 - accuracy: 0.9661 - val_loss: 0.2070 - val_accuracy: 0.9375\n",
      "Epoch 3/30\n",
      "1503/1503 [==============================] - 300s 200ms/step - loss: 0.1535 - accuracy: 0.9773 - val_loss: 0.0695 - val_accuracy: 1.0000\n",
      "Epoch 4/30\n",
      "1503/1503 [==============================] - 300s 200ms/step - loss: 0.0942 - accuracy: 0.9844 - val_loss: 0.0443 - val_accuracy: 1.0000\n",
      "Epoch 5/30\n",
      "1503/1503 [==============================] - 300s 200ms/step - loss: 0.0662 - accuracy: 0.9874 - val_loss: 0.0300 - val_accuracy: 1.0000\n",
      "Epoch 6/30\n",
      "1503/1503 [==============================] - 300s 200ms/step - loss: 0.0513 - accuracy: 0.9901 - val_loss: 0.0303 - val_accuracy: 1.0000\n",
      "Epoch 7/30\n",
      "1503/1503 [==============================] - 300s 200ms/step - loss: 0.0434 - accuracy: 0.9907 - val_loss: 0.0275 - val_accuracy: 1.0000\n",
      "Epoch 8/30\n",
      "1503/1503 [==============================] - 300s 200ms/step - loss: 0.0368 - accuracy: 0.9925 - val_loss: 0.0197 - val_accuracy: 1.0000\n",
      "Epoch 9/30\n",
      "1503/1503 [==============================] - 300s 200ms/step - loss: 0.0334 - accuracy: 0.9928 - val_loss: 0.0121 - val_accuracy: 1.0000\n",
      "Epoch 10/30\n",
      "1503/1503 [==============================] - 300s 200ms/step - loss: 0.0273 - accuracy: 0.9942 - val_loss: 0.0097 - val_accuracy: 1.0000\n",
      "Epoch 11/30\n",
      "1503/1503 [==============================] - 300s 200ms/step - loss: 0.0260 - accuracy: 0.9946 - val_loss: 0.0147 - val_accuracy: 1.0000\n",
      "Epoch 12/30\n",
      "1503/1503 [==============================] - 300s 200ms/step - loss: 0.0244 - accuracy: 0.9946 - val_loss: 0.0304 - val_accuracy: 0.9688\n",
      "Epoch 13/30\n",
      "1503/1503 [==============================] - 300s 200ms/step - loss: 0.0229 - accuracy: 0.9951 - val_loss: 0.0355 - val_accuracy: 0.9688\n",
      "Epoch 14/30\n",
      "1503/1503 [==============================] - 300s 199ms/step - loss: 0.0219 - accuracy: 0.9950 - val_loss: 0.0082 - val_accuracy: 1.0000\n",
      "Epoch 15/30\n",
      "1503/1503 [==============================] - 300s 200ms/step - loss: 0.0201 - accuracy: 0.9953 - val_loss: 0.0163 - val_accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "1503/1503 [==============================] - 300s 200ms/step - loss: 0.0169 - accuracy: 0.9960 - val_loss: 0.0121 - val_accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "1503/1503 [==============================] - 300s 200ms/step - loss: 0.0190 - accuracy: 0.9953 - val_loss: 0.0211 - val_accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "1503/1503 [==============================] - 300s 200ms/step - loss: 0.0178 - accuracy: 0.9953 - val_loss: 0.0259 - val_accuracy: 0.9688\n",
      "Epoch 19/30\n",
      "1503/1503 [==============================] - 300s 200ms/step - loss: 0.0158 - accuracy: 0.9958 - val_loss: 0.0369 - val_accuracy: 0.9688\n",
      "Epoch 20/30\n",
      "1503/1503 [==============================] - 300s 200ms/step - loss: 0.0161 - accuracy: 0.9962 - val_loss: 0.0253 - val_accuracy: 0.9688\n",
      "Epoch 21/30\n",
      "1503/1503 [==============================] - 300s 200ms/step - loss: 0.0145 - accuracy: 0.9961 - val_loss: 0.0282 - val_accuracy: 0.9688\n",
      "Epoch 22/30\n",
      "1503/1503 [==============================] - 300s 200ms/step - loss: 0.0160 - accuracy: 0.9961 - val_loss: 0.0296 - val_accuracy: 0.9688\n",
      "Epoch 23/30\n",
      "1503/1503 [==============================] - 300s 200ms/step - loss: 0.0145 - accuracy: 0.9960 - val_loss: 0.0291 - val_accuracy: 0.9688\n",
      "Epoch 24/30\n",
      "1503/1503 [==============================] - 300s 200ms/step - loss: 0.0150 - accuracy: 0.9961 - val_loss: 0.0313 - val_accuracy: 0.9688\n",
      "Epoch 25/30\n",
      "1503/1503 [==============================] - 300s 200ms/step - loss: 0.0144 - accuracy: 0.9960 - val_loss: 0.0333 - val_accuracy: 0.9688\n",
      "Epoch 26/30\n",
      "1503/1503 [==============================] - 300s 199ms/step - loss: 0.0139 - accuracy: 0.9962 - val_loss: 0.0331 - val_accuracy: 0.9688\n",
      "Epoch 27/30\n",
      "1503/1503 [==============================] - 300s 199ms/step - loss: 0.0140 - accuracy: 0.9964 - val_loss: 0.0227 - val_accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "1503/1503 [==============================] - 300s 199ms/step - loss: 0.0139 - accuracy: 0.9964 - val_loss: 0.0261 - val_accuracy: 0.9688\n",
      "Epoch 29/30\n",
      "1503/1503 [==============================] - 300s 199ms/step - loss: 0.0143 - accuracy: 0.9962 - val_loss: 0.0256 - val_accuracy: 0.9688\n",
      "Epoch 30/30\n",
      "1503/1503 [==============================] - 300s 199ms/step - loss: 0.0127 - accuracy: 0.9964 - val_loss: 0.0238 - val_accuracy: 1.0000\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_75135.6 images/assets\n",
      "Test acc for resnet: 0.998967\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training opticnet for 0.9% of train size (aka 75135 images)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "   6/1503 [..............................] - ETA: 47:09 - loss: 5.4619 - accuracy: 0.1554  WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.4634s vs `on_train_batch_end` time: 1.0965s). Check your callbacks.\n",
      "1503/1503 [==============================] - 1794s 1s/step - loss: 0.3126 - accuracy: 0.9093 - val_loss: 0.0106 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "1503/1503 [==============================] - 1774s 1s/step - loss: 0.1243 - accuracy: 0.9589 - val_loss: 0.0632 - val_accuracy: 0.9688\n",
      "Epoch 3/30\n",
      "1503/1503 [==============================] - 1775s 1s/step - loss: 0.1074 - accuracy: 0.9637 - val_loss: 0.0685 - val_accuracy: 0.9688\n",
      "Epoch 4/30\n",
      "1503/1503 [==============================] - 1775s 1s/step - loss: 0.0848 - accuracy: 0.9712 - val_loss: 0.0408 - val_accuracy: 0.9688\n",
      "Epoch 5/30\n",
      "1503/1503 [==============================] - 1746s 1s/step - loss: 0.0683 - accuracy: 0.9773 - val_loss: 0.0378 - val_accuracy: 0.9688\n",
      "Epoch 6/30\n",
      "1503/1503 [==============================] - 1749s 1s/step - loss: 0.0562 - accuracy: 0.9805 - val_loss: 0.0307 - val_accuracy: 0.9688\n",
      "Epoch 7/30\n",
      "1503/1503 [==============================] - 1746s 1s/step - loss: 0.0496 - accuracy: 0.9830 - val_loss: 0.0942 - val_accuracy: 0.9688\n",
      "Epoch 8/30\n",
      "1503/1503 [==============================] - 1775s 1s/step - loss: 0.0386 - accuracy: 0.9871 - val_loss: 0.0047 - val_accuracy: 1.0000\n",
      "Epoch 9/30\n",
      "1503/1503 [==============================] - 1778s 1s/step - loss: 0.0277 - accuracy: 0.9908 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
      "Epoch 10/30\n",
      "1503/1503 [==============================] - 1778s 1s/step - loss: 0.0229 - accuracy: 0.9924 - val_loss: 0.1540 - val_accuracy: 0.9688\n",
      "Epoch 11/30\n",
      "1503/1503 [==============================] - 1779s 1s/step - loss: 0.0186 - accuracy: 0.9940 - val_loss: 0.0632 - val_accuracy: 0.9688\n",
      "Epoch 12/30\n",
      "1503/1503 [==============================] - 1780s 1s/step - loss: 0.0155 - accuracy: 0.9948 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
      "Epoch 13/30\n",
      "1503/1503 [==============================] - 1779s 1s/step - loss: 0.0133 - accuracy: 0.9953 - val_loss: 0.0093 - val_accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "1503/1503 [==============================] - 1778s 1s/step - loss: 0.0141 - accuracy: 0.9951 - val_loss: 0.0107 - val_accuracy: 1.0000\n",
      "Epoch 15/30\n",
      "1503/1503 [==============================] - 1781s 1s/step - loss: 0.0109 - accuracy: 0.9961 - val_loss: 0.0319 - val_accuracy: 0.9688\n",
      "Epoch 16/30\n",
      "1503/1503 [==============================] - 1781s 1s/step - loss: 0.0095 - accuracy: 0.9965 - val_loss: 0.0059 - val_accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "1503/1503 [==============================] - 1775s 1s/step - loss: 0.0090 - accuracy: 0.9967 - val_loss: 0.0736 - val_accuracy: 0.9688\n",
      "Epoch 18/30\n",
      "1503/1503 [==============================] - 1771s 1s/step - loss: 0.0079 - accuracy: 0.9967 - val_loss: 0.0341 - val_accuracy: 0.9688\n",
      "Epoch 19/30\n",
      "1503/1503 [==============================] - 1771s 1s/step - loss: 0.0078 - accuracy: 0.9966 - val_loss: 0.0071 - val_accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "1503/1503 [==============================] - 1774s 1s/step - loss: 0.0072 - accuracy: 0.9963 - val_loss: 0.0111 - val_accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "1503/1503 [==============================] - 1778s 1s/step - loss: 0.0068 - accuracy: 0.9962 - val_loss: 0.0221 - val_accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "1503/1503 [==============================] - 1778s 1s/step - loss: 0.0064 - accuracy: 0.9965 - val_loss: 0.0182 - val_accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "1503/1503 [==============================] - 1778s 1s/step - loss: 0.0059 - accuracy: 0.9967 - val_loss: 0.0170 - val_accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "1503/1503 [==============================] - 1778s 1s/step - loss: 0.0050 - accuracy: 0.9970 - val_loss: 0.0171 - val_accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "1503/1503 [==============================] - 1775s 1s/step - loss: 0.0049 - accuracy: 0.9969 - val_loss: 0.0173 - val_accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "1503/1503 [==============================] - 1776s 1s/step - loss: 0.0049 - accuracy: 0.9970 - val_loss: 0.0162 - val_accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "1503/1503 [==============================] - 1769s 1s/step - loss: 0.0043 - accuracy: 0.9969 - val_loss: 0.0115 - val_accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "1503/1503 [==============================] - 1771s 1s/step - loss: 0.0046 - accuracy: 0.9971 - val_loss: 0.0139 - val_accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "1503/1503 [==============================] - 1779s 1s/step - loss: 0.0041 - accuracy: 0.9972 - val_loss: 0.0173 - val_accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "1503/1503 [==============================] - 1778s 1s/step - loss: 0.0043 - accuracy: 0.9971 - val_loss: 0.0166 - val_accuracy: 1.0000\n",
      "INFO:tensorflow:Assets written to: ../opticnet/opticnet_30epochs_75135.6 images/assets\n",
      "Test acc for opticnet: 1.000000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import datetime\n",
    "\n",
    "maxTrain = len(y_train)\n",
    "#for p in [0.01, 0.025, 0.05, 0.075, 0.09]:\n",
    "for p in [0.5, 0.6, 0.75, 0.9]:\n",
    "    #X_trn, X_tst, y_trn, y_tst\n",
    "    X_t, _, y_t, _ = train_test_split(images, y_train, test_size=1-p, random_state=123)\n",
    "    print(f\"Labels fraction: {sum(y_t == 1) / sum(y_train == 1)}\")\n",
    "    for net in [\"xception\", \"resnet\", \"opticnet\"]:\n",
    "        print(f\"Training {net} for {p}% of train size (aka {len(X_t)} images)...\")\n",
    "        model, size = emptyModelGenerator(net, False)\n",
    "        X_trn = resizeIms(X_t, size)\n",
    "        X_val = resizeIms(x_val, size)\n",
    "        log_dir = f\"logs/{net}/fit/{p}trainSet_\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "        tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "        optim = Adam(learning_rate=0.001)\n",
    "        model.compile(optimizer=optim, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "        hist = model.fit(X_trn, y_t, epochs=epochs, validation_data = (X_val, y_validation), batch_size=batch_size,\n",
    "                    shuffle=True, max_queue_size=20,\n",
    "                    use_multiprocessing=True, workers=5, \n",
    "                    callbacks=[CustomCallback(fraction=0.9, model=net), tensorboard_callback])\n",
    "        model.save(f\"../{net}/{net}_{epochs}epochs_{p*maxTrain} images\")\n",
    "        testPredict(model, size, name=net)\n",
    "        del model\n",
    "        del X_trn\n",
    "        del X_val\n",
    "        print(\"Done!\\n\" + '-'*50, end='\\n\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
