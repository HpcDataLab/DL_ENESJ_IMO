{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "import os\n",
    "import cv2\n",
    "import pickle\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataPath = \"../../data/OCT/OCT2017/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of Classes Detected : 4\n"
     ]
    }
   ],
   "source": [
    "labels_available = os.listdir(os.path.join(dataPath, \"train\"))\n",
    "print(\"Total Number of Classes Detected :\",len(labels_available))\n",
    "\n",
    "labels_list = ['NORMAL',\"CNV\",\"DME\",\"DRUSEN\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NORMAL CNV DME DRUSEN "
     ]
    }
   ],
   "source": [
    "images=[]\n",
    "y_trn=[]\n",
    "for x in labels_list:\n",
    "    xPath = os.path.join(dataPath, \"train\", x)\n",
    "    myPicList = os.listdir(xPath)\n",
    "    for y in myPicList:\n",
    "        images.append(cv2.imread(os.path.join(xPath, y)))\n",
    "        y_trn.append(labels_list.index(x))\n",
    "    print(x ,end=\" \")\n",
    "\n",
    "y_train = to_categorical(y_trn,len(labels_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NORMAL CNV DME DRUSEN "
     ]
    }
   ],
   "source": [
    "x_val=[]\n",
    "y_val=[]\n",
    "for x in labels_list:\n",
    "    xPath = os.path.join(dataPath, \"val\", x)\n",
    "    myPicList = os.listdir(xPath)\n",
    "    for y in myPicList:\n",
    "        x_val.append(cv2.imread(os.path.join(xPath, y)))\n",
    "        y_val.append(labels_list.index(x))\n",
    "    print(x ,end=\" \")\n",
    "\n",
    "y_validation = to_categorical(y_val,len(labels_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NORMAL CNV DME DRUSEN "
     ]
    }
   ],
   "source": [
    "x_tst=[]\n",
    "y_tst=[]\n",
    "for x in labels_list:\n",
    "    xPath = os.path.join(dataPath, \"test\", x)\n",
    "    myPicList = os.listdir(xPath)\n",
    "    for y in myPicList:\n",
    "        x_tst.append(cv2.imread(os.path.join(xPath, y)))\n",
    "        y_tst.append(labels_list.index(x))\n",
    "    print(x ,end=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resizeIm(im, size):\n",
    "    if im.shape[2] == 1:\n",
    "        im = cv2.cvtColor(im,cv2.COLOR_GRAY2RGB)\n",
    "    return cv2.resize(im, size)\n",
    "\n",
    "def resizeIms(x, size):\n",
    "    return np.array(list(map(lambda im: resizeIm(im, size), x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self,fraction, model):\n",
    "        super(CustomCallback,self).__init__()\n",
    "        self.fraction = fraction\n",
    "        self.train_a = [];\n",
    "        self.val_a =[];\n",
    "        self.logPath = os.path.join(model, \"log.txt\")\n",
    "\n",
    "        if not os.path.isdir(model):\n",
    "            os.mkdir(model)\n",
    "\n",
    "        with open(self.logPath,'w') as f:\n",
    "            f.write('Starting of logging..\\n')\n",
    "\n",
    "        self.fig = plt.figure(figsize=(4,3))\n",
    "        self.ax = plt.subplot(1,1,1)\n",
    "        plt.ion()\n",
    "\n",
    "    def on_train_begin(self,logs=None):\n",
    "        self.fig.show()\n",
    "        self.fig.canvas.draw()\n",
    "\n",
    "    def on_train_end(self,logs=None):\n",
    "        with open(self.logPath,'a') as f:\n",
    "              f.write('End of logging..\\n')\n",
    "    \n",
    "    def on_epoch_begin(self,epoch,logs=None):\n",
    "        lr= tf.keras.backend.get_value(self.model.optimizer.lr)\n",
    "        lr *= self.fraction\n",
    "        tf.keras.backend.set_value(self.model.optimizer.lr,lr)\n",
    "        with open(self.logPath,'a') as f:\n",
    "            f.write('At epoch {:02d}, learning rate changed to {:.4f}\\n'.format(epoch,lr))\n",
    "    \n",
    "    def on_epoch_end(self,epoch,logs=None):\n",
    "        val_acc = logs.get('val_accuracy')\n",
    "        train_acc = logs.get('accuracy')\n",
    "        self.train_a.append(train_acc)\n",
    "        self.val_a.append(val_acc)\n",
    "        with open(self.logPath,'a') as f:\n",
    "            f.write('At epoch {:02d}, training accuracy: {:.3f}, validation accuracy: {:.3f}\\n'.format(epoch,train_acc,val_acc))\n",
    "        self.ax.clear()\n",
    "        self.ax.plot(range(1+epoch),self.train_a,label=\"Training\")\n",
    "        self.ax.plot(range(1+epoch),self.val_a,label=\"Validation\")\n",
    "        self.ax.set_xlabel('Epochs')\n",
    "        self.ax.set_ylabel('Accuracy')\n",
    "        self.ax.legend()\n",
    "        self.fig.canvas.draw()\n",
    "        self.fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xception base model\n",
    "from tensorflow.keras.applications.xception import Xception\n",
    "from tensorflow.keras.applications.xception import preprocess_input, decode_predictions\n",
    "xceptionNetModel = Xception(weights='imagenet')\n",
    "\n",
    "# opticnet base model\n",
    "opticNetModel = tf.keras.models.load_model('../Optic_net-4_classes-Kermany2018.hdf5')\n",
    "\n",
    "# resnet base model\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "\n",
    "resNetModel = ResNet50(weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emptyModelGenerator(model, newWeights=False, lastOnly=False):\n",
    "    model = model.lower()\n",
    "    if model == \"resnet\":\n",
    "        x = resNetModel.output\n",
    "        predictions = Dense(len(labels_list), activation='softmax')(x)\n",
    "        newModel = Model(inputs=resNetModel.input, outputs=predictions)\n",
    "        size = (224, 224)\n",
    "    elif model == \"xception\":\n",
    "        x = xceptionNetModel.output\n",
    "        predictions = Dense(len(labels_list), activation='softmax')(x)\n",
    "        newModel = Model(inputs=xceptionNetModel.input, outputs=predictions)\n",
    "        size = (299, 299)\n",
    "    elif model == \"opticnet\":\n",
    "        newModel = tf.keras.models.load_model('../Optic_net-4_classes-Kermany2018.hdf5')\n",
    "        size = (224, 224)\n",
    "    if newWeights:\n",
    "        newModel = tf.keras.models.clone_model(newModel)\n",
    "    if lastOnly:\n",
    "        newModel = lastDenseTrainable(newModel) # block all layer except the last dense ones\n",
    "    return newModel, size\n",
    "\n",
    "\n",
    "def lastDenseTrainable(model):\n",
    "    model.trainable = False\n",
    "    for i in range(1, len(model.layers)):\n",
    "        if model.layers[-i].__class__.__name__ == \"Dense\":\n",
    "            model.layers[-i].trainable= True\n",
    "        elif model.layers[-i].__class__.__name__ == \"Activation\":\n",
    "            continue\n",
    "        else:\n",
    "            break\n",
    "    return model\n",
    "    \n",
    "\n",
    "def testPredict(model, size, name=None):\n",
    "    X_test = resizeIms(x_tst, size)\n",
    "    X_test = np.array(X_test)\n",
    "    Y_test = np.array(y_tst)\n",
    "    \n",
    "    prediction = model.predict(X_test)\n",
    "    preds = np.argmax(prediction, axis=1)\n",
    "    acc = sum(preds == Y_test) / len(Y_test)\n",
    "    print(f'Test acc for {name if name else \"model\"}: {acc:.6f}')\n",
    "    \n",
    "\n",
    "def computeConfussionMatrix(predictions, labels):\n",
    "    num_labels = len(labels_list)\n",
    "    cMatrix = np.zeros(shape=(num_labels, num_labels))\n",
    "    for i in len(predictions):\n",
    "        p = int(predictions[i])\n",
    "        t = int(predictions[i])\n",
    "        cMatrix[t, p] += 1\n",
    "    print(cMatrix)\n",
    "    ax = sns.heatmap(cMatrix, cmap=\"Blues\", annot=True, fmt=\"d\", xticklabels=labels_list, yticklabels=labels_list)\n",
    "    plt.xlabel(\"Predicted label\")\n",
    "    plt.ylabel(\"True label\")\n",
    "    plt.title(\"Confusion matrix\")\n",
    "    plt.show();\n",
    "    return cMatrix\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "**************************************************\n",
      "Model: xception\n",
      "**************************************************\n",
      "predictions True\n",
      "dense_63 True\n",
      "\n",
      "Total: 135 trainable: 2\n",
      "Model: \"model_63\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 299, 299, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, 149, 149, 32) 864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_bn (BatchNormaliza (None, 149, 149, 32) 128         block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_act (Activation)   (None, 149, 149, 32) 0           block1_conv1_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, 147, 147, 64) 18432       block1_conv1_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_bn (BatchNormaliza (None, 147, 147, 64) 256         block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_act (Activation)   (None, 147, 147, 64) 0           block1_conv2_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv1 (SeparableConv2 (None, 147, 147, 128 8768        block1_conv2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv1_bn (BatchNormal (None, 147, 147, 128 512         block2_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2_act (Activation (None, 147, 147, 128 0           block2_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2 (SeparableConv2 (None, 147, 147, 128 17536       block2_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2_bn (BatchNormal (None, 147, 147, 128 512         block2_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 74, 74, 128)  8192        block1_conv2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, 74, 74, 128)  0           block2_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 74, 74, 128)  512         conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 74, 74, 128)  0           block2_pool[0][0]                \n",
      "                                                                 batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1_act (Activation (None, 74, 74, 128)  0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1 (SeparableConv2 (None, 74, 74, 256)  33920       block3_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1_bn (BatchNormal (None, 74, 74, 256)  1024        block3_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2_act (Activation (None, 74, 74, 256)  0           block3_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2 (SeparableConv2 (None, 74, 74, 256)  67840       block3_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2_bn (BatchNormal (None, 74, 74, 256)  1024        block3_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 37, 37, 256)  32768       add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, 37, 37, 256)  0           block3_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 37, 37, 256)  1024        conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 37, 37, 256)  0           block3_pool[0][0]                \n",
      "                                                                 batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1_act (Activation (None, 37, 37, 256)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1 (SeparableConv2 (None, 37, 37, 728)  188672      block4_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1_bn (BatchNormal (None, 37, 37, 728)  2912        block4_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2_act (Activation (None, 37, 37, 728)  0           block4_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2 (SeparableConv2 (None, 37, 37, 728)  536536      block4_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2_bn (BatchNormal (None, 37, 37, 728)  2912        block4_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 19, 19, 728)  186368      add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)      (None, 19, 19, 728)  0           block4_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 19, 19, 728)  2912        conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 19, 19, 728)  0           block4_pool[0][0]                \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1_act (Activation (None, 19, 19, 728)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1 (SeparableConv2 (None, 19, 19, 728)  536536      block5_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1_bn (BatchNormal (None, 19, 19, 728)  2912        block5_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2_act (Activation (None, 19, 19, 728)  0           block5_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2 (SeparableConv2 (None, 19, 19, 728)  536536      block5_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2_bn (BatchNormal (None, 19, 19, 728)  2912        block5_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3_act (Activation (None, 19, 19, 728)  0           block5_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3 (SeparableConv2 (None, 19, 19, 728)  536536      block5_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3_bn (BatchNormal (None, 19, 19, 728)  2912        block5_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 19, 19, 728)  0           block5_sepconv3_bn[0][0]         \n",
      "                                                                 add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1_act (Activation (None, 19, 19, 728)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1 (SeparableConv2 (None, 19, 19, 728)  536536      block6_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1_bn (BatchNormal (None, 19, 19, 728)  2912        block6_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2_act (Activation (None, 19, 19, 728)  0           block6_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2 (SeparableConv2 (None, 19, 19, 728)  536536      block6_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2_bn (BatchNormal (None, 19, 19, 728)  2912        block6_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3_act (Activation (None, 19, 19, 728)  0           block6_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3 (SeparableConv2 (None, 19, 19, 728)  536536      block6_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3_bn (BatchNormal (None, 19, 19, 728)  2912        block6_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 19, 19, 728)  0           block6_sepconv3_bn[0][0]         \n",
      "                                                                 add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1_act (Activation (None, 19, 19, 728)  0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1 (SeparableConv2 (None, 19, 19, 728)  536536      block7_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1_bn (BatchNormal (None, 19, 19, 728)  2912        block7_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2_act (Activation (None, 19, 19, 728)  0           block7_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2 (SeparableConv2 (None, 19, 19, 728)  536536      block7_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2_bn (BatchNormal (None, 19, 19, 728)  2912        block7_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3_act (Activation (None, 19, 19, 728)  0           block7_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3 (SeparableConv2 (None, 19, 19, 728)  536536      block7_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3_bn (BatchNormal (None, 19, 19, 728)  2912        block7_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 19, 19, 728)  0           block7_sepconv3_bn[0][0]         \n",
      "                                                                 add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1_act (Activation (None, 19, 19, 728)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1 (SeparableConv2 (None, 19, 19, 728)  536536      block8_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1_bn (BatchNormal (None, 19, 19, 728)  2912        block8_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2_act (Activation (None, 19, 19, 728)  0           block8_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2 (SeparableConv2 (None, 19, 19, 728)  536536      block8_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2_bn (BatchNormal (None, 19, 19, 728)  2912        block8_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3_act (Activation (None, 19, 19, 728)  0           block8_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3 (SeparableConv2 (None, 19, 19, 728)  536536      block8_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3_bn (BatchNormal (None, 19, 19, 728)  2912        block8_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 19, 19, 728)  0           block8_sepconv3_bn[0][0]         \n",
      "                                                                 add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1_act (Activation (None, 19, 19, 728)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1 (SeparableConv2 (None, 19, 19, 728)  536536      block9_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1_bn (BatchNormal (None, 19, 19, 728)  2912        block9_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2_act (Activation (None, 19, 19, 728)  0           block9_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2 (SeparableConv2 (None, 19, 19, 728)  536536      block9_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2_bn (BatchNormal (None, 19, 19, 728)  2912        block9_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3_act (Activation (None, 19, 19, 728)  0           block9_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3 (SeparableConv2 (None, 19, 19, 728)  536536      block9_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3_bn (BatchNormal (None, 19, 19, 728)  2912        block9_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 19, 19, 728)  0           block9_sepconv3_bn[0][0]         \n",
      "                                                                 add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1_act (Activatio (None, 19, 19, 728)  0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1 (SeparableConv (None, 19, 19, 728)  536536      block10_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1_bn (BatchNorma (None, 19, 19, 728)  2912        block10_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2_act (Activatio (None, 19, 19, 728)  0           block10_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2 (SeparableConv (None, 19, 19, 728)  536536      block10_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2_bn (BatchNorma (None, 19, 19, 728)  2912        block10_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3_act (Activatio (None, 19, 19, 728)  0           block10_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3 (SeparableConv (None, 19, 19, 728)  536536      block10_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3_bn (BatchNorma (None, 19, 19, 728)  2912        block10_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 19, 19, 728)  0           block10_sepconv3_bn[0][0]        \n",
      "                                                                 add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1_act (Activatio (None, 19, 19, 728)  0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1 (SeparableConv (None, 19, 19, 728)  536536      block11_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1_bn (BatchNorma (None, 19, 19, 728)  2912        block11_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2_act (Activatio (None, 19, 19, 728)  0           block11_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2 (SeparableConv (None, 19, 19, 728)  536536      block11_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2_bn (BatchNorma (None, 19, 19, 728)  2912        block11_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3_act (Activatio (None, 19, 19, 728)  0           block11_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3 (SeparableConv (None, 19, 19, 728)  536536      block11_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3_bn (BatchNorma (None, 19, 19, 728)  2912        block11_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 19, 19, 728)  0           block11_sepconv3_bn[0][0]        \n",
      "                                                                 add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1_act (Activatio (None, 19, 19, 728)  0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1 (SeparableConv (None, 19, 19, 728)  536536      block12_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1_bn (BatchNorma (None, 19, 19, 728)  2912        block12_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2_act (Activatio (None, 19, 19, 728)  0           block12_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2 (SeparableConv (None, 19, 19, 728)  536536      block12_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2_bn (BatchNorma (None, 19, 19, 728)  2912        block12_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3_act (Activatio (None, 19, 19, 728)  0           block12_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3 (SeparableConv (None, 19, 19, 728)  536536      block12_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3_bn (BatchNorma (None, 19, 19, 728)  2912        block12_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 19, 19, 728)  0           block12_sepconv3_bn[0][0]        \n",
      "                                                                 add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1_act (Activatio (None, 19, 19, 728)  0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1 (SeparableConv (None, 19, 19, 728)  536536      block13_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1_bn (BatchNorma (None, 19, 19, 728)  2912        block13_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2_act (Activatio (None, 19, 19, 728)  0           block13_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2 (SeparableConv (None, 19, 19, 1024) 752024      block13_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2_bn (BatchNorma (None, 19, 19, 1024) 4096        block13_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 10, 10, 1024) 745472      add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_pool (MaxPooling2D)     (None, 10, 10, 1024) 0           block13_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 10, 10, 1024) 4096        conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 10, 10, 1024) 0           block13_pool[0][0]               \n",
      "                                                                 batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1 (SeparableConv (None, 10, 10, 1536) 1582080     add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1_bn (BatchNorma (None, 10, 10, 1536) 6144        block14_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1_act (Activatio (None, 10, 10, 1536) 0           block14_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2 (SeparableConv (None, 10, 10, 2048) 3159552     block14_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2_bn (BatchNorma (None, 10, 10, 2048) 8192        block14_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2_act (Activatio (None, 10, 10, 2048) 0           block14_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "avg_pool (GlobalAveragePooling2 (None, 2048)         0           block14_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "predictions (Dense)             (None, 1000)         2049000     avg_pool[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_63 (Dense)                (None, 4)            4004        predictions[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 22,914,484\n",
      "Trainable params: 0\n",
      "Non-trainable params: 22,914,484\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "\n",
      "\n",
      "**************************************************\n",
      "Model: resnet\n",
      "**************************************************\n",
      "predictions True\n",
      "dense_64 True\n",
      "\n",
      "Total: 178 trainable: 2\n",
      "Model: \"model_64\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1_bn (BatchNormalization)   (None, 112, 112, 64) 256         conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1_relu (Activation)         (None, 112, 112, 64) 0           conv1_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)       (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 56, 56, 64)   4160        pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 56, 56, 64)   0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_relu (Activation (None, 56, 56, 64)   0           conv2_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)    (None, 56, 56, 256)  16640       pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_add (Add)          (None, 56, 56, 256)  0           conv2_block1_0_bn[0][0]          \n",
      "                                                                 conv2_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_out (Activation)   (None, 56, 56, 256)  0           conv2_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 56, 56, 64)   0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_relu (Activation (None, 56, 56, 64)   0           conv2_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_add (Add)          (None, 56, 56, 256)  0           conv2_block1_out[0][0]           \n",
      "                                                                 conv2_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_out (Activation)   (None, 56, 56, 256)  0           conv2_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 56, 56, 64)   0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_relu (Activation (None, 56, 56, 64)   0           conv2_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_add (Add)          (None, 56, 56, 256)  0           conv2_block2_out[0][0]           \n",
      "                                                                 conv2_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_out (Activation)   (None, 56, 56, 256)  0           conv2_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 28, 28, 128)  32896       conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 28, 28, 128)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_relu (Activation (None, 28, 28, 128)  0           conv3_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)    (None, 28, 28, 512)  131584      conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_add (Add)          (None, 28, 28, 512)  0           conv3_block1_0_bn[0][0]          \n",
      "                                                                 conv3_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_out (Activation)   (None, 28, 28, 512)  0           conv3_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 28, 28, 128)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_relu (Activation (None, 28, 28, 128)  0           conv3_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_add (Add)          (None, 28, 28, 512)  0           conv3_block1_out[0][0]           \n",
      "                                                                 conv3_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_out (Activation)   (None, 28, 28, 512)  0           conv3_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 28, 28, 128)  0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_relu (Activation (None, 28, 28, 128)  0           conv3_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_add (Add)          (None, 28, 28, 512)  0           conv3_block2_out[0][0]           \n",
      "                                                                 conv3_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_out (Activation)   (None, 28, 28, 512)  0           conv3_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 28, 28, 128)  0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_relu (Activation (None, 28, 28, 128)  0           conv3_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_add (Add)          (None, 28, 28, 512)  0           conv3_block3_out[0][0]           \n",
      "                                                                 conv3_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_out (Activation)   (None, 28, 28, 512)  0           conv3_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 14, 14, 256)  131328      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 14, 14, 256)  0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_relu (Activation (None, 14, 14, 256)  0           conv4_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)    (None, 14, 14, 1024) 525312      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_0_bn[0][0]          \n",
      "                                                                 conv4_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_out (Activation)   (None, 14, 14, 1024) 0           conv4_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 14, 14, 256)  0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_relu (Activation (None, 14, 14, 256)  0           conv4_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_out[0][0]           \n",
      "                                                                 conv4_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_out (Activation)   (None, 14, 14, 1024) 0           conv4_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 14, 14, 256)  0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_relu (Activation (None, 14, 14, 256)  0           conv4_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_add (Add)          (None, 14, 14, 1024) 0           conv4_block2_out[0][0]           \n",
      "                                                                 conv4_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_out (Activation)   (None, 14, 14, 1024) 0           conv4_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 14, 14, 256)  0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_relu (Activation (None, 14, 14, 256)  0           conv4_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_add (Add)          (None, 14, 14, 1024) 0           conv4_block3_out[0][0]           \n",
      "                                                                 conv4_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_out (Activation)   (None, 14, 14, 1024) 0           conv4_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 14, 14, 256)  0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_relu (Activation (None, 14, 14, 256)  0           conv4_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_add (Add)          (None, 14, 14, 1024) 0           conv4_block4_out[0][0]           \n",
      "                                                                 conv4_block5_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_out (Activation)   (None, 14, 14, 1024) 0           conv4_block5_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 14, 14, 256)  0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_relu (Activation (None, 14, 14, 256)  0           conv4_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_add (Add)          (None, 14, 14, 1024) 0           conv4_block5_out[0][0]           \n",
      "                                                                 conv4_block6_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_out (Activation)   (None, 14, 14, 1024) 0           conv4_block6_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 7, 7, 512)    524800      conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 7, 7, 512)    0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_relu (Activation (None, 7, 7, 512)    0           conv5_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_conv (Conv2D)    (None, 7, 7, 2048)   2099200     conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_0_bn[0][0]          \n",
      "                                                                 conv5_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_out (Activation)   (None, 7, 7, 2048)   0           conv5_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 7, 7, 512)    0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_relu (Activation (None, 7, 7, 512)    0           conv5_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_out[0][0]           \n",
      "                                                                 conv5_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_out (Activation)   (None, 7, 7, 2048)   0           conv5_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 7, 7, 512)    0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_relu (Activation (None, 7, 7, 512)    0           conv5_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_add (Add)          (None, 7, 7, 2048)   0           conv5_block2_out[0][0]           \n",
      "                                                                 conv5_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_out (Activation)   (None, 7, 7, 2048)   0           conv5_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "avg_pool (GlobalAveragePooling2 (None, 2048)         0           conv5_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "predictions (Dense)             (None, 1000)         2049000     avg_pool[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_64 (Dense)                (None, 4)            4004        predictions[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 25,640,716\n",
      "Trainable params: 0\n",
      "Non-trainable params: 25,640,716\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "\n",
      "\n",
      "**************************************************\n",
      "Model: opticnet\n",
      "**************************************************\n",
      "Dense_1 True\n",
      "Dense_2 True\n",
      "\n",
      "Total: 276 trainable: 2\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "CONV1 (Conv2D)                  (None, 112, 112, 64) 9472        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "BN1 (BatchNormalization)        (None, 112, 112, 64) 256         CONV1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "RELU1 (Activation)              (None, 112, 112, 64) 0           BN1[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "RC0/branch1/bn_1 (BatchNormaliz (None, 112, 112, 64) 256         RELU1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "RC0/branch1/relu_1 (Activation) (None, 112, 112, 64) 0           RC0/branch1/bn_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "RC0/branch1/conv_1 (Conv2D)     (None, 112, 112, 64) 4160        RC0/branch1/relu_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "RC0/branch1/bn_2 (BatchNormaliz (None, 112, 112, 64) 256         RC0/branch1/conv_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "RC0/branch1/relu_2 (Activation) (None, 112, 112, 64) 0           RC0/branch1/bn_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "RC0/branch1/conv_2 (Conv2D)     (None, 112, 112, 64) 16448       RC0/branch1/relu_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "RC0/branch1/bn_3 (BatchNormaliz (None, 112, 112, 64) 256         RC0/branch1/conv_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "RC0/branch2/bn_1 (BatchNormaliz (None, 112, 112, 64) 256         RELU1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "RC0/branch1/relu_3 (Activation) (None, 112, 112, 64) 0           RC0/branch1/bn_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "RC0/branch2/relu_1 (Activation) (None, 112, 112, 64) 0           RC0/branch2/bn_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "RC0/branch1/conv_3 (Conv2D)     (None, 112, 112, 256 16640       RC0/branch1/relu_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "RC0/branch2/conv_1 (Conv2D)     (None, 112, 112, 256 16640       RC0/branch2/relu_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "RC0/Add (Add)                   (None, 112, 112, 256 0           RC0/branch1/conv_3[0][0]         \n",
      "                                                                 RC0/branch2/conv_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "IDC1/id_1/branch1/bn_1 (BatchNo (None, 112, 112, 256 1024        RC0/Add[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "IDC1/id_1/branch1/relu_1 (Activ (None, 112, 112, 256 0           IDC1/id_1/branch1/bn_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "IDC1/id_1/branch1/conv_1 (Conv2 (None, 112, 112, 32) 8224        IDC1/id_1/branch1/relu_1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "IDC1/id_1/branch1/ConvBn_2 (Bat (None, 112, 112, 32) 128         IDC1/id_1/branch1/conv_1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "IDC1/id_1/branch1/SepBn_2 (Batc (None, 112, 112, 32) 128         IDC1/id_1/branch1/conv_1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "IDC1/id_1/branch1/ConvRelu_2 (A (None, 112, 112, 32) 0           IDC1/id_1/branch1/ConvBn_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "IDC1/id_1/branch1/SepRelu_2 (Ac (None, 112, 112, 32) 0           IDC1/id_1/branch1/SepBn_2[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "IDC1/id_1/branch1/Conv_2 (Conv2 (None, 112, 112, 32) 4128        IDC1/id_1/branch1/ConvRelu_2[0][0\n",
      "__________________________________________________________________________________________________\n",
      "IDC1/id_1/branch1/SepConv_2 (Se (None, 112, 112, 32) 1184        IDC1/id_1/branch1/SepRelu_2[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "IDC1/id_1/Add-2branches (Add)   (None, 112, 112, 32) 0           IDC1/id_1/branch1/Conv_2[0][0]   \n",
      "                                                                 IDC1/id_1/branch1/SepConv_2[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "IDC1/id_1/branch1/bn_3 (BatchNo (None, 112, 112, 32) 128         IDC1/id_1/Add-2branches[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "IDC1/id_1/branch1/relu_3 (Activ (None, 112, 112, 32) 0           IDC1/id_1/branch1/bn_3[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "IDC1/id_1/branch1/conv_3 (Conv2 (None, 112, 112, 256 8448        IDC1/id_1/branch1/relu_3[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "IDC1/id_1/Add (Add)             (None, 112, 112, 256 0           RC0/Add[0][0]                    \n",
      "                                                                 IDC1/id_1/branch1/conv_3[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "IDC1/id_2/branch1/bn_1 (BatchNo (None, 112, 112, 256 1024        IDC1/id_1/Add[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "IDC1/id_2/branch1/relu_1 (Activ (None, 112, 112, 256 0           IDC1/id_2/branch1/bn_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "IDC1/id_2/branch1/conv_1 (Conv2 (None, 112, 112, 32) 8224        IDC1/id_2/branch1/relu_1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "IDC1/id_2/branch1/ConvBn_2 (Bat (None, 112, 112, 32) 128         IDC1/id_2/branch1/conv_1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "IDC1/id_2/branch1/SepBn_2 (Batc (None, 112, 112, 32) 128         IDC1/id_2/branch1/conv_1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "IDC1/id_2/branch1/ConvRelu_2 (A (None, 112, 112, 32) 0           IDC1/id_2/branch1/ConvBn_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "IDC1/id_2/branch1/SepRelu_2 (Ac (None, 112, 112, 32) 0           IDC1/id_2/branch1/SepBn_2[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "IDC1/id_2/branch1/Conv_2 (Conv2 (None, 112, 112, 32) 4128        IDC1/id_2/branch1/ConvRelu_2[0][0\n",
      "__________________________________________________________________________________________________\n",
      "IDC1/id_2/branch1/SepConv_2 (Se (None, 112, 112, 32) 1184        IDC1/id_2/branch1/SepRelu_2[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "IDC1/id_2/Add-2branches (Add)   (None, 112, 112, 32) 0           IDC1/id_2/branch1/Conv_2[0][0]   \n",
      "                                                                 IDC1/id_2/branch1/SepConv_2[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "IDC1/id_2/branch1/bn_3 (BatchNo (None, 112, 112, 32) 128         IDC1/id_2/Add-2branches[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "IDC1/id_2/branch1/relu_3 (Activ (None, 112, 112, 32) 0           IDC1/id_2/branch1/bn_3[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "IDC1/id_2/branch1/conv_3 (Conv2 (None, 112, 112, 256 8448        IDC1/id_2/branch1/relu_3[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "IDC1/id_2/Add (Add)             (None, 112, 112, 256 0           IDC1/id_1/Add[0][0]              \n",
      "                                                                 IDC1/id_2/branch1/conv_3[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "IDC1/id_3/branch1/bn_1 (BatchNo (None, 112, 112, 256 1024        IDC1/id_2/Add[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "IDC1/id_3/branch1/relu_1 (Activ (None, 112, 112, 256 0           IDC1/id_3/branch1/bn_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "IDC1/id_3/branch1/conv_1 (Conv2 (None, 112, 112, 32) 8224        IDC1/id_3/branch1/relu_1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "IDC1/id_3/branch1/ConvBn_2 (Bat (None, 112, 112, 32) 128         IDC1/id_3/branch1/conv_1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "IDC1/id_3/branch1/SepBn_2 (Batc (None, 112, 112, 32) 128         IDC1/id_3/branch1/conv_1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "IDC1/id_3/branch1/ConvRelu_2 (A (None, 112, 112, 32) 0           IDC1/id_3/branch1/ConvBn_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "IDC1/id_3/branch1/SepRelu_2 (Ac (None, 112, 112, 32) 0           IDC1/id_3/branch1/SepBn_2[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "IDC1/id_3/branch1/Conv_2 (Conv2 (None, 112, 112, 32) 4128        IDC1/id_3/branch1/ConvRelu_2[0][0\n",
      "__________________________________________________________________________________________________\n",
      "IDC1/id_3/branch1/SepConv_2 (Se (None, 112, 112, 32) 1184        IDC1/id_3/branch1/SepRelu_2[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "IDC1/id_3/Add-2branches (Add)   (None, 112, 112, 32) 0           IDC1/id_3/branch1/Conv_2[0][0]   \n",
      "                                                                 IDC1/id_3/branch1/SepConv_2[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "IDC1/id_3/branch1/bn_3 (BatchNo (None, 112, 112, 32) 128         IDC1/id_3/Add-2branches[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "IDC1/id_3/branch1/relu_3 (Activ (None, 112, 112, 32) 0           IDC1/id_3/branch1/bn_3[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "IDC1/id_3/branch1/conv_3 (Conv2 (None, 112, 112, 256 8448        IDC1/id_3/branch1/relu_3[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "IDC1/id_3/Add (Add)             (None, 112, 112, 256 0           IDC1/id_2/Add[0][0]              \n",
      "                                                                 IDC1/id_3/branch1/conv_3[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "IDC1/id_4/branch1/bn_1 (BatchNo (None, 112, 112, 256 1024        IDC1/id_3/Add[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "IDC1/id_4/branch1/relu_1 (Activ (None, 112, 112, 256 0           IDC1/id_4/branch1/bn_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "IDC1/id_4/branch1/conv_1 (Conv2 (None, 112, 112, 32) 8224        IDC1/id_4/branch1/relu_1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "IDC1/id_4/branch1/ConvBn_2 (Bat (None, 112, 112, 32) 128         IDC1/id_4/branch1/conv_1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "IDC1/id_4/branch1/SepBn_2 (Batc (None, 112, 112, 32) 128         IDC1/id_4/branch1/conv_1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "IDC1/id_4/branch1/ConvRelu_2 (A (None, 112, 112, 32) 0           IDC1/id_4/branch1/ConvBn_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "IDC1/id_4/branch1/SepRelu_2 (Ac (None, 112, 112, 32) 0           IDC1/id_4/branch1/SepBn_2[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "IDC1/id_4/branch1/Conv_2 (Conv2 (None, 112, 112, 32) 4128        IDC1/id_4/branch1/ConvRelu_2[0][0\n",
      "__________________________________________________________________________________________________\n",
      "IDC1/id_4/branch1/SepConv_2 (Se (None, 112, 112, 32) 1184        IDC1/id_4/branch1/SepRelu_2[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "IDC1/id_4/Add-2branches (Add)   (None, 112, 112, 32) 0           IDC1/id_4/branch1/Conv_2[0][0]   \n",
      "                                                                 IDC1/id_4/branch1/SepConv_2[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "IDC1/id_4/branch1/bn_3 (BatchNo (None, 112, 112, 32) 128         IDC1/id_4/Add-2branches[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "Mask1/Downsample1 (MaxPooling2D (None, 56, 56, 256)  0           RC0/Add[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "IDC1/id_4/branch1/relu_3 (Activ (None, 112, 112, 32) 0           IDC1/id_4/branch1/bn_3[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "Mask1/Upsample1 (UpSampling2D)  (None, 112, 112, 256 0           Mask1/Downsample1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "IDC1/id_4/branch1/conv_3 (Conv2 (None, 112, 112, 256 8448        IDC1/id_4/branch1/relu_3[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "Mask1/Activate (Activation)     (None, 112, 112, 256 0           Mask1/Upsample1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "IDC1/id_4/Add (Add)             (None, 112, 112, 256 0           IDC1/id_3/Add[0][0]              \n",
      "                                                                 IDC1/id_4/branch1/conv_3[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "Mutiply1 (Multiply)             (None, 112, 112, 256 0           Mask1/Activate[0][0]             \n",
      "                                                                 IDC1/id_4/Add[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Add1 (Add)                      (None, 112, 112, 256 0           Mutiply1[0][0]                   \n",
      "                                                                 Mask1/Activate[0][0]             \n",
      "                                                                 IDC1/id_4/Add[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "RC1/branch1/bn_1 (BatchNormaliz (None, 112, 112, 256 1024        Add1[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "RC1/branch1/relu_1 (Activation) (None, 112, 112, 256 0           RC1/branch1/bn_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "RC1/branch1/conv_1 (Conv2D)     (None, 112, 112, 128 32896       RC1/branch1/relu_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "RC1/branch1/bn_2 (BatchNormaliz (None, 112, 112, 128 512         RC1/branch1/conv_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "RC1/branch1/relu_2 (Activation) (None, 112, 112, 128 0           RC1/branch1/bn_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "RC1/branch1/conv_2 (Conv2D)     (None, 56, 56, 128)  65664       RC1/branch1/relu_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "RC1/branch1/bn_3 (BatchNormaliz (None, 56, 56, 128)  512         RC1/branch1/conv_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "RC1/branch2/bn_1 (BatchNormaliz (None, 112, 112, 256 1024        Add1[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "RC1/branch1/relu_3 (Activation) (None, 56, 56, 128)  0           RC1/branch1/bn_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "RC1/branch2/relu_1 (Activation) (None, 112, 112, 256 0           RC1/branch2/bn_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "RC1/branch1/conv_3 (Conv2D)     (None, 56, 56, 512)  66048       RC1/branch1/relu_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "RC1/branch2/conv_1 (Conv2D)     (None, 56, 56, 512)  131584      RC1/branch2/relu_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "RC1/Add (Add)                   (None, 56, 56, 512)  0           RC1/branch1/conv_3[0][0]         \n",
      "                                                                 RC1/branch2/conv_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "IDC2/id_1/branch1/bn_1 (BatchNo (None, 56, 56, 512)  2048        RC1/Add[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "IDC2/id_1/branch1/relu_1 (Activ (None, 56, 56, 512)  0           IDC2/id_1/branch1/bn_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "IDC2/id_1/branch1/conv_1 (Conv2 (None, 56, 56, 64)   32832       IDC2/id_1/branch1/relu_1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "IDC2/id_1/branch1/ConvBn_2 (Bat (None, 56, 56, 64)   256         IDC2/id_1/branch1/conv_1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "IDC2/id_1/branch1/SepBn_2 (Batc (None, 56, 56, 64)   256         IDC2/id_1/branch1/conv_1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "IDC2/id_1/branch1/ConvRelu_2 (A (None, 56, 56, 64)   0           IDC2/id_1/branch1/ConvBn_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "IDC2/id_1/branch1/SepRelu_2 (Ac (None, 56, 56, 64)   0           IDC2/id_1/branch1/SepBn_2[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "IDC2/id_1/branch1/Conv_2 (Conv2 (None, 56, 56, 64)   16448       IDC2/id_1/branch1/ConvRelu_2[0][0\n",
      "__________________________________________________________________________________________________\n",
      "IDC2/id_1/branch1/SepConv_2 (Se (None, 56, 56, 64)   4416        IDC2/id_1/branch1/SepRelu_2[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "IDC2/id_1/Add-2branches (Add)   (None, 56, 56, 64)   0           IDC2/id_1/branch1/Conv_2[0][0]   \n",
      "                                                                 IDC2/id_1/branch1/SepConv_2[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "IDC2/id_1/branch1/bn_3 (BatchNo (None, 56, 56, 64)   256         IDC2/id_1/Add-2branches[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "IDC2/id_1/branch1/relu_3 (Activ (None, 56, 56, 64)   0           IDC2/id_1/branch1/bn_3[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "IDC2/id_1/branch1/conv_3 (Conv2 (None, 56, 56, 512)  33280       IDC2/id_1/branch1/relu_3[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "IDC2/id_1/Add (Add)             (None, 56, 56, 512)  0           RC1/Add[0][0]                    \n",
      "                                                                 IDC2/id_1/branch1/conv_3[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "IDC2/id_2/branch1/bn_1 (BatchNo (None, 56, 56, 512)  2048        IDC2/id_1/Add[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "IDC2/id_2/branch1/relu_1 (Activ (None, 56, 56, 512)  0           IDC2/id_2/branch1/bn_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "IDC2/id_2/branch1/conv_1 (Conv2 (None, 56, 56, 64)   32832       IDC2/id_2/branch1/relu_1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "IDC2/id_2/branch1/ConvBn_2 (Bat (None, 56, 56, 64)   256         IDC2/id_2/branch1/conv_1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "IDC2/id_2/branch1/SepBn_2 (Batc (None, 56, 56, 64)   256         IDC2/id_2/branch1/conv_1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "IDC2/id_2/branch1/ConvRelu_2 (A (None, 56, 56, 64)   0           IDC2/id_2/branch1/ConvBn_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "IDC2/id_2/branch1/SepRelu_2 (Ac (None, 56, 56, 64)   0           IDC2/id_2/branch1/SepBn_2[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "IDC2/id_2/branch1/Conv_2 (Conv2 (None, 56, 56, 64)   16448       IDC2/id_2/branch1/ConvRelu_2[0][0\n",
      "__________________________________________________________________________________________________\n",
      "IDC2/id_2/branch1/SepConv_2 (Se (None, 56, 56, 64)   4416        IDC2/id_2/branch1/SepRelu_2[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "IDC2/id_2/Add-2branches (Add)   (None, 56, 56, 64)   0           IDC2/id_2/branch1/Conv_2[0][0]   \n",
      "                                                                 IDC2/id_2/branch1/SepConv_2[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "IDC2/id_2/branch1/bn_3 (BatchNo (None, 56, 56, 64)   256         IDC2/id_2/Add-2branches[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "IDC2/id_2/branch1/relu_3 (Activ (None, 56, 56, 64)   0           IDC2/id_2/branch1/bn_3[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "IDC2/id_2/branch1/conv_3 (Conv2 (None, 56, 56, 512)  33280       IDC2/id_2/branch1/relu_3[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "IDC2/id_2/Add (Add)             (None, 56, 56, 512)  0           IDC2/id_1/Add[0][0]              \n",
      "                                                                 IDC2/id_2/branch1/conv_3[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "IDC2/id_3/branch1/bn_1 (BatchNo (None, 56, 56, 512)  2048        IDC2/id_2/Add[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "IDC2/id_3/branch1/relu_1 (Activ (None, 56, 56, 512)  0           IDC2/id_3/branch1/bn_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "IDC2/id_3/branch1/conv_1 (Conv2 (None, 56, 56, 64)   32832       IDC2/id_3/branch1/relu_1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "IDC2/id_3/branch1/ConvBn_2 (Bat (None, 56, 56, 64)   256         IDC2/id_3/branch1/conv_1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "IDC2/id_3/branch1/SepBn_2 (Batc (None, 56, 56, 64)   256         IDC2/id_3/branch1/conv_1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "IDC2/id_3/branch1/ConvRelu_2 (A (None, 56, 56, 64)   0           IDC2/id_3/branch1/ConvBn_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "IDC2/id_3/branch1/SepRelu_2 (Ac (None, 56, 56, 64)   0           IDC2/id_3/branch1/SepBn_2[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "IDC2/id_3/branch1/Conv_2 (Conv2 (None, 56, 56, 64)   16448       IDC2/id_3/branch1/ConvRelu_2[0][0\n",
      "__________________________________________________________________________________________________\n",
      "IDC2/id_3/branch1/SepConv_2 (Se (None, 56, 56, 64)   4416        IDC2/id_3/branch1/SepRelu_2[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "IDC2/id_3/Add-2branches (Add)   (None, 56, 56, 64)   0           IDC2/id_3/branch1/Conv_2[0][0]   \n",
      "                                                                 IDC2/id_3/branch1/SepConv_2[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "IDC2/id_3/branch1/bn_3 (BatchNo (None, 56, 56, 64)   256         IDC2/id_3/Add-2branches[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "IDC2/id_3/branch1/relu_3 (Activ (None, 56, 56, 64)   0           IDC2/id_3/branch1/bn_3[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "IDC2/id_3/branch1/conv_3 (Conv2 (None, 56, 56, 512)  33280       IDC2/id_3/branch1/relu_3[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "IDC2/id_3/Add (Add)             (None, 56, 56, 512)  0           IDC2/id_2/Add[0][0]              \n",
      "                                                                 IDC2/id_3/branch1/conv_3[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "IDC2/id_4/branch1/bn_1 (BatchNo (None, 56, 56, 512)  2048        IDC2/id_3/Add[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "IDC2/id_4/branch1/relu_1 (Activ (None, 56, 56, 512)  0           IDC2/id_4/branch1/bn_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "IDC2/id_4/branch1/conv_1 (Conv2 (None, 56, 56, 64)   32832       IDC2/id_4/branch1/relu_1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "IDC2/id_4/branch1/ConvBn_2 (Bat (None, 56, 56, 64)   256         IDC2/id_4/branch1/conv_1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "IDC2/id_4/branch1/SepBn_2 (Batc (None, 56, 56, 64)   256         IDC2/id_4/branch1/conv_1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "IDC2/id_4/branch1/ConvRelu_2 (A (None, 56, 56, 64)   0           IDC2/id_4/branch1/ConvBn_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "IDC2/id_4/branch1/SepRelu_2 (Ac (None, 56, 56, 64)   0           IDC2/id_4/branch1/SepBn_2[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "IDC2/id_4/branch1/Conv_2 (Conv2 (None, 56, 56, 64)   16448       IDC2/id_4/branch1/ConvRelu_2[0][0\n",
      "__________________________________________________________________________________________________\n",
      "IDC2/id_4/branch1/SepConv_2 (Se (None, 56, 56, 64)   4416        IDC2/id_4/branch1/SepRelu_2[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "IDC2/id_4/Add-2branches (Add)   (None, 56, 56, 64)   0           IDC2/id_4/branch1/Conv_2[0][0]   \n",
      "                                                                 IDC2/id_4/branch1/SepConv_2[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "IDC2/id_4/branch1/bn_3 (BatchNo (None, 56, 56, 64)   256         IDC2/id_4/Add-2branches[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "Mask2/Downsample1 (MaxPooling2D (None, 28, 28, 512)  0           RC1/Add[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "IDC2/id_4/branch1/relu_3 (Activ (None, 56, 56, 64)   0           IDC2/id_4/branch1/bn_3[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "Mask2/Upsample1 (UpSampling2D)  (None, 56, 56, 512)  0           Mask2/Downsample1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "IDC2/id_4/branch1/conv_3 (Conv2 (None, 56, 56, 512)  33280       IDC2/id_4/branch1/relu_3[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "Mask2/Activate (Activation)     (None, 56, 56, 512)  0           Mask2/Upsample1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "IDC2/id_4/Add (Add)             (None, 56, 56, 512)  0           IDC2/id_3/Add[0][0]              \n",
      "                                                                 IDC2/id_4/branch1/conv_3[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "Mutiply2 (Multiply)             (None, 56, 56, 512)  0           Mask2/Activate[0][0]             \n",
      "                                                                 IDC2/id_4/Add[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Add2 (Add)                      (None, 56, 56, 512)  0           Mutiply2[0][0]                   \n",
      "                                                                 Mask2/Activate[0][0]             \n",
      "                                                                 IDC2/id_4/Add[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "RC2/branch1/bn_1 (BatchNormaliz (None, 56, 56, 512)  2048        Add2[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "RC2/branch1/relu_1 (Activation) (None, 56, 56, 512)  0           RC2/branch1/bn_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "RC2/branch1/conv_1 (Conv2D)     (None, 56, 56, 256)  131328      RC2/branch1/relu_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "RC2/branch1/bn_2 (BatchNormaliz (None, 56, 56, 256)  1024        RC2/branch1/conv_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "RC2/branch1/relu_2 (Activation) (None, 56, 56, 256)  0           RC2/branch1/bn_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "RC2/branch1/conv_2 (Conv2D)     (None, 28, 28, 256)  262400      RC2/branch1/relu_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "RC2/branch1/bn_3 (BatchNormaliz (None, 28, 28, 256)  1024        RC2/branch1/conv_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "RC2/branch2/bn_1 (BatchNormaliz (None, 56, 56, 512)  2048        Add2[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "RC2/branch1/relu_3 (Activation) (None, 28, 28, 256)  0           RC2/branch1/bn_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "RC2/branch2/relu_1 (Activation) (None, 56, 56, 512)  0           RC2/branch2/bn_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "RC2/branch1/conv_3 (Conv2D)     (None, 28, 28, 1024) 263168      RC2/branch1/relu_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "RC2/branch2/conv_1 (Conv2D)     (None, 28, 28, 1024) 525312      RC2/branch2/relu_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "RC2/Add (Add)                   (None, 28, 28, 1024) 0           RC2/branch1/conv_3[0][0]         \n",
      "                                                                 RC2/branch2/conv_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "IDC3/id_1/branch1/bn_1 (BatchNo (None, 28, 28, 1024) 4096        RC2/Add[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "IDC3/id_1/branch1/relu_1 (Activ (None, 28, 28, 1024) 0           IDC3/id_1/branch1/bn_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "IDC3/id_1/branch1/conv_1 (Conv2 (None, 28, 28, 128)  131200      IDC3/id_1/branch1/relu_1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "IDC3/id_1/branch1/ConvBn_2 (Bat (None, 28, 28, 128)  512         IDC3/id_1/branch1/conv_1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "IDC3/id_1/branch1/SepBn_2 (Batc (None, 28, 28, 128)  512         IDC3/id_1/branch1/conv_1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "IDC3/id_1/branch1/ConvRelu_2 (A (None, 28, 28, 128)  0           IDC3/id_1/branch1/ConvBn_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "IDC3/id_1/branch1/SepRelu_2 (Ac (None, 28, 28, 128)  0           IDC3/id_1/branch1/SepBn_2[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "IDC3/id_1/branch1/Conv_2 (Conv2 (None, 28, 28, 128)  65664       IDC3/id_1/branch1/ConvRelu_2[0][0\n",
      "__________________________________________________________________________________________________\n",
      "IDC3/id_1/branch1/SepConv_2 (Se (None, 28, 28, 128)  17024       IDC3/id_1/branch1/SepRelu_2[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "IDC3/id_1/Add-2branches (Add)   (None, 28, 28, 128)  0           IDC3/id_1/branch1/Conv_2[0][0]   \n",
      "                                                                 IDC3/id_1/branch1/SepConv_2[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "IDC3/id_1/branch1/bn_3 (BatchNo (None, 28, 28, 128)  512         IDC3/id_1/Add-2branches[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "IDC3/id_1/branch1/relu_3 (Activ (None, 28, 28, 128)  0           IDC3/id_1/branch1/bn_3[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "IDC3/id_1/branch1/conv_3 (Conv2 (None, 28, 28, 1024) 132096      IDC3/id_1/branch1/relu_3[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "IDC3/id_1/Add (Add)             (None, 28, 28, 1024) 0           RC2/Add[0][0]                    \n",
      "                                                                 IDC3/id_1/branch1/conv_3[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "IDC3/id_2/branch1/bn_1 (BatchNo (None, 28, 28, 1024) 4096        IDC3/id_1/Add[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "IDC3/id_2/branch1/relu_1 (Activ (None, 28, 28, 1024) 0           IDC3/id_2/branch1/bn_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "IDC3/id_2/branch1/conv_1 (Conv2 (None, 28, 28, 128)  131200      IDC3/id_2/branch1/relu_1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "IDC3/id_2/branch1/ConvBn_2 (Bat (None, 28, 28, 128)  512         IDC3/id_2/branch1/conv_1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "IDC3/id_2/branch1/SepBn_2 (Batc (None, 28, 28, 128)  512         IDC3/id_2/branch1/conv_1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "IDC3/id_2/branch1/ConvRelu_2 (A (None, 28, 28, 128)  0           IDC3/id_2/branch1/ConvBn_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "IDC3/id_2/branch1/SepRelu_2 (Ac (None, 28, 28, 128)  0           IDC3/id_2/branch1/SepBn_2[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "IDC3/id_2/branch1/Conv_2 (Conv2 (None, 28, 28, 128)  65664       IDC3/id_2/branch1/ConvRelu_2[0][0\n",
      "__________________________________________________________________________________________________\n",
      "IDC3/id_2/branch1/SepConv_2 (Se (None, 28, 28, 128)  17024       IDC3/id_2/branch1/SepRelu_2[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "IDC3/id_2/Add-2branches (Add)   (None, 28, 28, 128)  0           IDC3/id_2/branch1/Conv_2[0][0]   \n",
      "                                                                 IDC3/id_2/branch1/SepConv_2[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "IDC3/id_2/branch1/bn_3 (BatchNo (None, 28, 28, 128)  512         IDC3/id_2/Add-2branches[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "IDC3/id_2/branch1/relu_3 (Activ (None, 28, 28, 128)  0           IDC3/id_2/branch1/bn_3[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "IDC3/id_2/branch1/conv_3 (Conv2 (None, 28, 28, 1024) 132096      IDC3/id_2/branch1/relu_3[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "IDC3/id_2/Add (Add)             (None, 28, 28, 1024) 0           IDC3/id_1/Add[0][0]              \n",
      "                                                                 IDC3/id_2/branch1/conv_3[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "IDC3/id_3/branch1/bn_1 (BatchNo (None, 28, 28, 1024) 4096        IDC3/id_2/Add[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "IDC3/id_3/branch1/relu_1 (Activ (None, 28, 28, 1024) 0           IDC3/id_3/branch1/bn_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "IDC3/id_3/branch1/conv_1 (Conv2 (None, 28, 28, 128)  131200      IDC3/id_3/branch1/relu_1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "IDC3/id_3/branch1/ConvBn_2 (Bat (None, 28, 28, 128)  512         IDC3/id_3/branch1/conv_1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "IDC3/id_3/branch1/SepBn_2 (Batc (None, 28, 28, 128)  512         IDC3/id_3/branch1/conv_1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "IDC3/id_3/branch1/ConvRelu_2 (A (None, 28, 28, 128)  0           IDC3/id_3/branch1/ConvBn_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "IDC3/id_3/branch1/SepRelu_2 (Ac (None, 28, 28, 128)  0           IDC3/id_3/branch1/SepBn_2[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "IDC3/id_3/branch1/Conv_2 (Conv2 (None, 28, 28, 128)  65664       IDC3/id_3/branch1/ConvRelu_2[0][0\n",
      "__________________________________________________________________________________________________\n",
      "IDC3/id_3/branch1/SepConv_2 (Se (None, 28, 28, 128)  17024       IDC3/id_3/branch1/SepRelu_2[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "IDC3/id_3/Add-2branches (Add)   (None, 28, 28, 128)  0           IDC3/id_3/branch1/Conv_2[0][0]   \n",
      "                                                                 IDC3/id_3/branch1/SepConv_2[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "IDC3/id_3/branch1/bn_3 (BatchNo (None, 28, 28, 128)  512         IDC3/id_3/Add-2branches[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "Mask3/Downsample1 (MaxPooling2D (None, 14, 14, 1024) 0           RC2/Add[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "IDC3/id_3/branch1/relu_3 (Activ (None, 28, 28, 128)  0           IDC3/id_3/branch1/bn_3[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "Mask3/Upsample1 (UpSampling2D)  (None, 28, 28, 1024) 0           Mask3/Downsample1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "IDC3/id_3/branch1/conv_3 (Conv2 (None, 28, 28, 1024) 132096      IDC3/id_3/branch1/relu_3[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "Mask3/Activate (Activation)     (None, 28, 28, 1024) 0           Mask3/Upsample1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "IDC3/id_3/Add (Add)             (None, 28, 28, 1024) 0           IDC3/id_2/Add[0][0]              \n",
      "                                                                 IDC3/id_3/branch1/conv_3[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "Mutiply3 (Multiply)             (None, 28, 28, 1024) 0           Mask3/Activate[0][0]             \n",
      "                                                                 IDC3/id_3/Add[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Add3 (Add)                      (None, 28, 28, 1024) 0           Mutiply3[0][0]                   \n",
      "                                                                 Mask3/Activate[0][0]             \n",
      "                                                                 IDC3/id_3/Add[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "RC3/branch1/bn_1 (BatchNormaliz (None, 28, 28, 1024) 4096        Add3[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "RC3/branch1/relu_1 (Activation) (None, 28, 28, 1024) 0           RC3/branch1/bn_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "RC3/branch1/conv_1 (Conv2D)     (None, 28, 28, 512)  524800      RC3/branch1/relu_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "RC3/branch1/bn_2 (BatchNormaliz (None, 28, 28, 512)  2048        RC3/branch1/conv_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "RC3/branch1/relu_2 (Activation) (None, 28, 28, 512)  0           RC3/branch1/bn_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "RC3/branch1/conv_2 (Conv2D)     (None, 14, 14, 512)  1049088     RC3/branch1/relu_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "RC3/branch1/bn_3 (BatchNormaliz (None, 14, 14, 512)  2048        RC3/branch1/conv_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "RC3/branch2/bn_1 (BatchNormaliz (None, 28, 28, 1024) 4096        Add3[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "RC3/branch1/relu_3 (Activation) (None, 14, 14, 512)  0           RC3/branch1/bn_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "RC3/branch2/relu_1 (Activation) (None, 28, 28, 1024) 0           RC3/branch2/bn_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "RC3/branch1/conv_3 (Conv2D)     (None, 14, 14, 2048) 1050624     RC3/branch1/relu_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "RC3/branch2/conv_1 (Conv2D)     (None, 14, 14, 2048) 2099200     RC3/branch2/relu_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "RC3/Add (Add)                   (None, 14, 14, 2048) 0           RC3/branch1/conv_3[0][0]         \n",
      "                                                                 RC3/branch2/conv_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "IDC4/id_1/branch1/bn_1 (BatchNo (None, 14, 14, 2048) 8192        RC3/Add[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "IDC4/id_1/branch1/relu_1 (Activ (None, 14, 14, 2048) 0           IDC4/id_1/branch1/bn_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "IDC4/id_1/branch1/conv_1 (Conv2 (None, 14, 14, 256)  524544      IDC4/id_1/branch1/relu_1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "IDC4/id_1/branch1/ConvBn_2 (Bat (None, 14, 14, 256)  1024        IDC4/id_1/branch1/conv_1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "IDC4/id_1/branch1/SepBn_2 (Batc (None, 14, 14, 256)  1024        IDC4/id_1/branch1/conv_1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "IDC4/id_1/branch1/ConvRelu_2 (A (None, 14, 14, 256)  0           IDC4/id_1/branch1/ConvBn_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "IDC4/id_1/branch1/SepRelu_2 (Ac (None, 14, 14, 256)  0           IDC4/id_1/branch1/SepBn_2[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "IDC4/id_1/branch1/Conv_2 (Conv2 (None, 14, 14, 256)  262400      IDC4/id_1/branch1/ConvRelu_2[0][0\n",
      "__________________________________________________________________________________________________\n",
      "IDC4/id_1/branch1/SepConv_2 (Se (None, 14, 14, 256)  66816       IDC4/id_1/branch1/SepRelu_2[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "IDC4/id_1/Add-2branches (Add)   (None, 14, 14, 256)  0           IDC4/id_1/branch1/Conv_2[0][0]   \n",
      "                                                                 IDC4/id_1/branch1/SepConv_2[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "IDC4/id_1/branch1/bn_3 (BatchNo (None, 14, 14, 256)  1024        IDC4/id_1/Add-2branches[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "IDC4/id_1/branch1/relu_3 (Activ (None, 14, 14, 256)  0           IDC4/id_1/branch1/bn_3[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "IDC4/id_1/branch1/conv_3 (Conv2 (None, 14, 14, 2048) 526336      IDC4/id_1/branch1/relu_3[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "IDC4/id_1/Add (Add)             (None, 14, 14, 2048) 0           RC3/Add[0][0]                    \n",
      "                                                                 IDC4/id_1/branch1/conv_3[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "IDC4/id_2/branch1/bn_1 (BatchNo (None, 14, 14, 2048) 8192        IDC4/id_1/Add[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "IDC4/id_2/branch1/relu_1 (Activ (None, 14, 14, 2048) 0           IDC4/id_2/branch1/bn_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "IDC4/id_2/branch1/conv_1 (Conv2 (None, 14, 14, 256)  524544      IDC4/id_2/branch1/relu_1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "IDC4/id_2/branch1/ConvBn_2 (Bat (None, 14, 14, 256)  1024        IDC4/id_2/branch1/conv_1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "IDC4/id_2/branch1/SepBn_2 (Batc (None, 14, 14, 256)  1024        IDC4/id_2/branch1/conv_1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "IDC4/id_2/branch1/ConvRelu_2 (A (None, 14, 14, 256)  0           IDC4/id_2/branch1/ConvBn_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "IDC4/id_2/branch1/SepRelu_2 (Ac (None, 14, 14, 256)  0           IDC4/id_2/branch1/SepBn_2[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "IDC4/id_2/branch1/Conv_2 (Conv2 (None, 14, 14, 256)  262400      IDC4/id_2/branch1/ConvRelu_2[0][0\n",
      "__________________________________________________________________________________________________\n",
      "IDC4/id_2/branch1/SepConv_2 (Se (None, 14, 14, 256)  66816       IDC4/id_2/branch1/SepRelu_2[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "IDC4/id_2/Add-2branches (Add)   (None, 14, 14, 256)  0           IDC4/id_2/branch1/Conv_2[0][0]   \n",
      "                                                                 IDC4/id_2/branch1/SepConv_2[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "IDC4/id_2/branch1/bn_3 (BatchNo (None, 14, 14, 256)  1024        IDC4/id_2/Add-2branches[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "IDC4/id_2/branch1/relu_3 (Activ (None, 14, 14, 256)  0           IDC4/id_2/branch1/bn_3[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "IDC4/id_2/branch1/conv_3 (Conv2 (None, 14, 14, 2048) 526336      IDC4/id_2/branch1/relu_3[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "IDC4/id_2/Add (Add)             (None, 14, 14, 2048) 0           IDC4/id_1/Add[0][0]              \n",
      "                                                                 IDC4/id_2/branch1/conv_3[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "IDC4/id_3/branch1/bn_1 (BatchNo (None, 14, 14, 2048) 8192        IDC4/id_2/Add[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "IDC4/id_3/branch1/relu_1 (Activ (None, 14, 14, 2048) 0           IDC4/id_3/branch1/bn_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "IDC4/id_3/branch1/conv_1 (Conv2 (None, 14, 14, 256)  524544      IDC4/id_3/branch1/relu_1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "IDC4/id_3/branch1/ConvBn_2 (Bat (None, 14, 14, 256)  1024        IDC4/id_3/branch1/conv_1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "IDC4/id_3/branch1/SepBn_2 (Batc (None, 14, 14, 256)  1024        IDC4/id_3/branch1/conv_1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "IDC4/id_3/branch1/ConvRelu_2 (A (None, 14, 14, 256)  0           IDC4/id_3/branch1/ConvBn_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "IDC4/id_3/branch1/SepRelu_2 (Ac (None, 14, 14, 256)  0           IDC4/id_3/branch1/SepBn_2[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "IDC4/id_3/branch1/Conv_2 (Conv2 (None, 14, 14, 256)  262400      IDC4/id_3/branch1/ConvRelu_2[0][0\n",
      "__________________________________________________________________________________________________\n",
      "IDC4/id_3/branch1/SepConv_2 (Se (None, 14, 14, 256)  66816       IDC4/id_3/branch1/SepRelu_2[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "IDC4/id_3/Add-2branches (Add)   (None, 14, 14, 256)  0           IDC4/id_3/branch1/Conv_2[0][0]   \n",
      "                                                                 IDC4/id_3/branch1/SepConv_2[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "IDC4/id_3/branch1/bn_3 (BatchNo (None, 14, 14, 256)  1024        IDC4/id_3/Add-2branches[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "Mask4/Downsample1 (MaxPooling2D (None, 7, 7, 2048)   0           RC3/Add[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "IDC4/id_3/branch1/relu_3 (Activ (None, 14, 14, 256)  0           IDC4/id_3/branch1/bn_3[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "Mask4/Upsample1 (UpSampling2D)  (None, 14, 14, 2048) 0           Mask4/Downsample1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "IDC4/id_3/branch1/conv_3 (Conv2 (None, 14, 14, 2048) 526336      IDC4/id_3/branch1/relu_3[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "Mask4/Activate (Activation)     (None, 14, 14, 2048) 0           Mask4/Upsample1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "IDC4/id_3/Add (Add)             (None, 14, 14, 2048) 0           IDC4/id_2/Add[0][0]              \n",
      "                                                                 IDC4/id_3/branch1/conv_3[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "Mutiply4 (Multiply)             (None, 14, 14, 2048) 0           Mask4/Activate[0][0]             \n",
      "                                                                 IDC4/id_3/Add[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Add4 (Add)                      (None, 14, 14, 2048) 0           Mutiply4[0][0]                   \n",
      "                                                                 Mask4/Activate[0][0]             \n",
      "                                                                 IDC4/id_3/Add[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_avg_pool (GlobalAverageP (None, 2048)         0           Add4[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "Dense_1 (Dense)                 (None, 256)          524544      global_avg_pool[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "Dense_2 (Dense)                 (None, 4)            1028        Dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "classifier (Activation)         (None, 4)            0           Dense_2[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 12,495,492\n",
      "Trainable params: 0\n",
      "Non-trainable params: 12,495,492\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "models = [\"xception\", \"resnet\", \"opticnet\"]\n",
    "\n",
    "for mod in models:\n",
    "    print(\"\\n\\n\" + (\"*\"*50) + \"\\nModel: \" + mod + '\\n' + (\"*\"*50))\n",
    "    m = emptyModelGenerator(mod, newWeights=False, lastOnly=True)[0]\n",
    "    #m.trainable = False\n",
    "    a = 0\n",
    "    for l in m.layers:\n",
    "        #l.trainable = True\n",
    "        if l.trainable:\n",
    "            print(l.name, l.trainable)\n",
    "            a += 1\n",
    "            #print(l.trainable_weights)\n",
    "    print(f\"\\nTotal: {len(m.layers)} trainable: {a}\")\n",
    "    print(m.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "optim = Adam(learning_rate=0.001)\n",
    "epochs = 30\n",
    "batch_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels fraction: [0.01037431 0.00938046 0.01092704 0.01021356]\n",
      "Training xception for 0.01% of train size (aka 834 images)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      " 6/17 [=========>....................] - ETA: 5s - loss: 1.3976 - accuracy: 0.0000e+00WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1168s vs `on_train_batch_begin` time: 0.1217s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1168s vs `on_train_batch_end` time: 0.2108s). Check your callbacks.\n",
      "17/17 [==============================] - 8s 317ms/step - loss: 1.3934 - accuracy: 0.1090 - val_loss: 1.3862 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "17/17 [==============================] - 2s 122ms/step - loss: 1.3655 - accuracy: 0.4152 - val_loss: 1.3672 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "17/17 [==============================] - 2s 122ms/step - loss: 1.3400 - accuracy: 0.4136 - val_loss: 1.3506 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "17/17 [==============================] - 2s 122ms/step - loss: 1.3205 - accuracy: 0.6227 - val_loss: 1.3359 - val_accuracy: 0.5000\n",
      "Epoch 5/30\n",
      "17/17 [==============================] - 2s 122ms/step - loss: 1.3030 - accuracy: 0.7304 - val_loss: 1.3229 - val_accuracy: 0.5000\n",
      "Epoch 6/30\n",
      "17/17 [==============================] - 2s 121ms/step - loss: 1.2810 - accuracy: 0.7611 - val_loss: 1.3114 - val_accuracy: 0.5000\n",
      "Epoch 7/30\n",
      "17/17 [==============================] - 2s 121ms/step - loss: 1.2698 - accuracy: 0.7279 - val_loss: 1.3009 - val_accuracy: 0.5000\n",
      "Epoch 8/30\n",
      "17/17 [==============================] - 2s 122ms/step - loss: 1.2527 - accuracy: 0.7448 - val_loss: 1.2917 - val_accuracy: 0.5000\n",
      "Epoch 9/30\n",
      "17/17 [==============================] - 2s 122ms/step - loss: 1.2419 - accuracy: 0.7452 - val_loss: 1.2834 - val_accuracy: 0.5000\n",
      "Epoch 10/30\n",
      "17/17 [==============================] - 2s 122ms/step - loss: 1.2333 - accuracy: 0.7332 - val_loss: 1.2761 - val_accuracy: 0.5000\n",
      "Epoch 11/30\n",
      "17/17 [==============================] - 2s 123ms/step - loss: 1.2256 - accuracy: 0.7163 - val_loss: 1.2695 - val_accuracy: 0.5000\n",
      "Epoch 12/30\n",
      "17/17 [==============================] - 2s 123ms/step - loss: 1.2107 - accuracy: 0.7522 - val_loss: 1.2637 - val_accuracy: 0.5000\n",
      "Epoch 13/30\n",
      "17/17 [==============================] - 2s 124ms/step - loss: 1.2026 - accuracy: 0.7587 - val_loss: 1.2584 - val_accuracy: 0.5000\n",
      "Epoch 14/30\n",
      "17/17 [==============================] - 2s 123ms/step - loss: 1.2001 - accuracy: 0.7375 - val_loss: 1.2536 - val_accuracy: 0.5000\n",
      "Epoch 15/30\n",
      "17/17 [==============================] - 2s 123ms/step - loss: 1.1881 - accuracy: 0.7586 - val_loss: 1.2494 - val_accuracy: 0.5000\n",
      "Epoch 16/30\n",
      "17/17 [==============================] - 2s 123ms/step - loss: 1.1894 - accuracy: 0.7331 - val_loss: 1.2456 - val_accuracy: 0.5000\n",
      "Epoch 17/30\n",
      "17/17 [==============================] - 2s 123ms/step - loss: 1.1866 - accuracy: 0.7319 - val_loss: 1.2422 - val_accuracy: 0.5000\n",
      "Epoch 18/30\n",
      "17/17 [==============================] - 2s 124ms/step - loss: 1.1755 - accuracy: 0.7577 - val_loss: 1.2392 - val_accuracy: 0.5000\n",
      "Epoch 19/30\n",
      "17/17 [==============================] - 2s 124ms/step - loss: 1.1779 - accuracy: 0.7308 - val_loss: 1.2365 - val_accuracy: 0.5000\n",
      "Epoch 20/30\n",
      "17/17 [==============================] - 2s 125ms/step - loss: 1.1723 - accuracy: 0.7377 - val_loss: 1.2340 - val_accuracy: 0.5000\n",
      "Epoch 21/30\n",
      "17/17 [==============================] - 2s 124ms/step - loss: 1.1636 - accuracy: 0.7579 - val_loss: 1.2318 - val_accuracy: 0.5000\n",
      "Epoch 22/30\n",
      "17/17 [==============================] - 2s 124ms/step - loss: 1.1630 - accuracy: 0.7465 - val_loss: 1.2299 - val_accuracy: 0.5000\n",
      "Epoch 23/30\n",
      "17/17 [==============================] - 2s 124ms/step - loss: 1.1563 - accuracy: 0.7587 - val_loss: 1.2281 - val_accuracy: 0.5000\n",
      "Epoch 24/30\n",
      "17/17 [==============================] - 2s 125ms/step - loss: 1.1649 - accuracy: 0.7228 - val_loss: 1.2265 - val_accuracy: 0.5000\n",
      "Epoch 25/30\n",
      "17/17 [==============================] - 2s 125ms/step - loss: 1.1570 - accuracy: 0.7400 - val_loss: 1.2251 - val_accuracy: 0.5000\n",
      "Epoch 26/30\n",
      "17/17 [==============================] - 2s 125ms/step - loss: 1.1542 - accuracy: 0.7452 - val_loss: 1.2238 - val_accuracy: 0.5000\n",
      "Epoch 27/30\n",
      "17/17 [==============================] - 2s 125ms/step - loss: 1.1597 - accuracy: 0.7245 - val_loss: 1.2226 - val_accuracy: 0.5000\n",
      "Epoch 28/30\n",
      "17/17 [==============================] - 2s 126ms/step - loss: 1.1490 - accuracy: 0.7585 - val_loss: 1.2216 - val_accuracy: 0.5000\n",
      "Epoch 29/30\n",
      "17/17 [==============================] - 2s 126ms/step - loss: 1.1483 - accuracy: 0.7529 - val_loss: 1.2206 - val_accuracy: 0.5000\n",
      "Epoch 30/30\n",
      "17/17 [==============================] - 2s 125ms/step - loss: 1.1505 - accuracy: 0.7459 - val_loss: 1.2198 - val_accuracy: 0.5000\n",
      "INFO:tensorflow:Assets written to: ../xception/xception_30epochs_834.84 images/assets\n",
      "Test acc for xception: 0.500000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training resnet for 0.01% of train size (aka 834 images)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      " 6/17 [=========>....................] - ETA: 4s - loss: 1.3923 - accuracy: 0.1938WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0612s vs `on_train_batch_begin` time: 0.1286s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0612s vs `on_train_batch_end` time: 0.1772s). Check your callbacks.\n",
      "17/17 [==============================] - 9s 272ms/step - loss: 1.3869 - accuracy: 0.3144 - val_loss: 1.3643 - val_accuracy: 0.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "17/17 [==============================] - 1s 62ms/step - loss: 1.3549 - accuracy: 0.5256 - val_loss: 1.3384 - val_accuracy: 0.7500\n",
      "Epoch 3/30\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.3234 - accuracy: 0.8180 - val_loss: 1.3228 - val_accuracy: 0.7500\n",
      "Epoch 4/30\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.2999 - accuracy: 0.8808 - val_loss: 1.3102 - val_accuracy: 0.7500\n",
      "Epoch 5/30\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.2806 - accuracy: 0.8843 - val_loss: 1.2997 - val_accuracy: 0.7500\n",
      "Epoch 6/30\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.2593 - accuracy: 0.9126 - val_loss: 1.2907 - val_accuracy: 0.7500\n",
      "Epoch 7/30\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.2498 - accuracy: 0.8867 - val_loss: 1.2829 - val_accuracy: 0.7500\n",
      "Epoch 8/30\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.2349 - accuracy: 0.8994 - val_loss: 1.2759 - val_accuracy: 0.7500\n",
      "Epoch 9/30\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.2252 - accuracy: 0.8893 - val_loss: 1.2699 - val_accuracy: 0.7500\n",
      "Epoch 10/30\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.2140 - accuracy: 0.9009 - val_loss: 1.2646 - val_accuracy: 0.7500\n",
      "Epoch 11/30\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.2084 - accuracy: 0.8892 - val_loss: 1.2598 - val_accuracy: 0.7500\n",
      "Epoch 12/30\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.1969 - accuracy: 0.9059 - val_loss: 1.2556 - val_accuracy: 0.7500\n",
      "Epoch 13/30\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.1859 - accuracy: 0.9041 - val_loss: 1.2519 - val_accuracy: 0.7500\n",
      "Epoch 14/30\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.1874 - accuracy: 0.8841 - val_loss: 1.2485 - val_accuracy: 0.7500\n",
      "Epoch 15/30\n",
      "17/17 [==============================] - 1s 62ms/step - loss: 1.1791 - accuracy: 0.8928 - val_loss: 1.2456 - val_accuracy: 0.7500\n",
      "Epoch 16/30\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.1830 - accuracy: 0.8875 - val_loss: 1.2429 - val_accuracy: 0.7500\n",
      "Epoch 17/30\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.1733 - accuracy: 0.8878 - val_loss: 1.2405 - val_accuracy: 0.7500\n",
      "Epoch 18/30\n",
      "17/17 [==============================] - 1s 62ms/step - loss: 1.1691 - accuracy: 0.8897 - val_loss: 1.2384 - val_accuracy: 0.7500\n",
      "Epoch 19/30\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.1608 - accuracy: 0.9014 - val_loss: 1.2365 - val_accuracy: 0.7500\n",
      "Epoch 20/30\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.1617 - accuracy: 0.8865 - val_loss: 1.2348 - val_accuracy: 0.7500\n",
      "Epoch 21/30\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.1668 - accuracy: 0.8823 - val_loss: 1.2333 - val_accuracy: 0.7500\n",
      "Epoch 22/30\n",
      "17/17 [==============================] - 1s 62ms/step - loss: 1.1612 - accuracy: 0.8856 - val_loss: 1.2319 - val_accuracy: 0.7500\n",
      "Epoch 23/30\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.1530 - accuracy: 0.9002 - val_loss: 1.2307 - val_accuracy: 0.7500\n",
      "Epoch 24/30\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.1498 - accuracy: 0.9011 - val_loss: 1.2296 - val_accuracy: 0.7500\n",
      "Epoch 25/30\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.1537 - accuracy: 0.8778 - val_loss: 1.2286 - val_accuracy: 0.7500\n",
      "Epoch 26/30\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.1534 - accuracy: 0.8777 - val_loss: 1.2277 - val_accuracy: 0.7500\n",
      "Epoch 27/30\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.1449 - accuracy: 0.9070 - val_loss: 1.2270 - val_accuracy: 0.7500\n",
      "Epoch 28/30\n",
      "17/17 [==============================] - 1s 62ms/step - loss: 1.1461 - accuracy: 0.8872 - val_loss: 1.2262 - val_accuracy: 0.7500\n",
      "Epoch 29/30\n",
      "17/17 [==============================] - 1s 62ms/step - loss: 1.1379 - accuracy: 0.9095 - val_loss: 1.2256 - val_accuracy: 0.7500\n",
      "Epoch 30/30\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.1459 - accuracy: 0.8858 - val_loss: 1.2250 - val_accuracy: 0.7500\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_834.84 images/assets\n",
      "Test acc for resnet: 0.748967\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training opticnet for 0.01% of train size (aka 834 images)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      " 6/17 [=========>....................] - ETA: 19s - loss: 5.3921 - accuracy: 0.1659 WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.4635s vs `on_train_batch_end` time: 1.0362s). Check your callbacks.\n",
      "17/17 [==============================] - 36s 1s/step - loss: 3.1891 - accuracy: 0.3948 - val_loss: 17.2634 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.4889 - accuracy: 0.8126 - val_loss: 6.0526 - val_accuracy: 0.3125\n",
      "Epoch 3/30\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2488 - accuracy: 0.9082 - val_loss: 2.9684 - val_accuracy: 0.4062\n",
      "Epoch 4/30\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2143 - accuracy: 0.9387 - val_loss: 0.2815 - val_accuracy: 0.9062\n",
      "Epoch 5/30\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.0780 - accuracy: 0.9822 - val_loss: 0.2624 - val_accuracy: 0.9375\n",
      "Epoch 6/30\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.0582 - accuracy: 0.9833 - val_loss: 0.3248 - val_accuracy: 0.8750\n",
      "Epoch 7/30\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.0320 - accuracy: 0.9891 - val_loss: 0.1841 - val_accuracy: 0.9062\n",
      "Epoch 8/30\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.0138 - accuracy: 1.0000 - val_loss: 0.3094 - val_accuracy: 0.9062\n",
      "Epoch 9/30\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.0177 - accuracy: 0.9931 - val_loss: 0.1597 - val_accuracy: 0.9688\n",
      "Epoch 10/30\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.1106 - val_accuracy: 0.9375\n",
      "Epoch 11/30\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.1026 - val_accuracy: 0.9375\n",
      "Epoch 12/30\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0990 - val_accuracy: 0.9688\n",
      "Epoch 13/30\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.1319 - val_accuracy: 0.9688\n",
      "Epoch 14/30\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0974 - val_accuracy: 0.9688\n",
      "Epoch 15/30\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.1082 - val_accuracy: 0.9688\n",
      "Epoch 16/30\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0982 - val_accuracy: 0.9688\n",
      "Epoch 17/30\n",
      "17/17 [==============================] - 20s 1s/step - loss: 7.6864e-04 - accuracy: 1.0000 - val_loss: 0.0898 - val_accuracy: 0.9688\n",
      "Epoch 18/30\n",
      "17/17 [==============================] - 20s 1s/step - loss: 6.5176e-04 - accuracy: 1.0000 - val_loss: 0.0872 - val_accuracy: 0.9688\n",
      "Epoch 19/30\n",
      "17/17 [==============================] - 20s 1s/step - loss: 5.2478e-04 - accuracy: 1.0000 - val_loss: 0.0774 - val_accuracy: 0.9688\n",
      "Epoch 20/30\n",
      "17/17 [==============================] - 20s 1s/step - loss: 6.0161e-04 - accuracy: 1.0000 - val_loss: 0.0741 - val_accuracy: 0.9688\n",
      "Epoch 21/30\n",
      "17/17 [==============================] - 20s 1s/step - loss: 7.1403e-04 - accuracy: 1.0000 - val_loss: 0.0626 - val_accuracy: 0.9688\n",
      "Epoch 22/30\n",
      "17/17 [==============================] - 20s 1s/step - loss: 5.1046e-04 - accuracy: 1.0000 - val_loss: 0.0628 - val_accuracy: 0.9688\n",
      "Epoch 23/30\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0737 - val_accuracy: 0.9688\n",
      "Epoch 24/30\n",
      "17/17 [==============================] - 20s 1s/step - loss: 5.4544e-04 - accuracy: 1.0000 - val_loss: 0.0753 - val_accuracy: 0.9688\n",
      "Epoch 25/30\n",
      "17/17 [==============================] - 20s 1s/step - loss: 4.0344e-04 - accuracy: 1.0000 - val_loss: 0.0754 - val_accuracy: 0.9688\n",
      "Epoch 26/30\n",
      "17/17 [==============================] - 20s 1s/step - loss: 5.8460e-04 - accuracy: 1.0000 - val_loss: 0.0725 - val_accuracy: 0.9688\n",
      "Epoch 27/30\n",
      "17/17 [==============================] - 20s 1s/step - loss: 6.1560e-04 - accuracy: 1.0000 - val_loss: 0.0726 - val_accuracy: 0.9688\n",
      "Epoch 28/30\n",
      "17/17 [==============================] - 20s 1s/step - loss: 8.7849e-04 - accuracy: 1.0000 - val_loss: 0.0744 - val_accuracy: 0.9688\n",
      "Epoch 29/30\n",
      "17/17 [==============================] - 20s 1s/step - loss: 6.6356e-04 - accuracy: 1.0000 - val_loss: 0.0768 - val_accuracy: 0.9688\n",
      "Epoch 30/30\n",
      "17/17 [==============================] - 20s 1s/step - loss: 4.0106e-04 - accuracy: 1.0000 - val_loss: 0.0792 - val_accuracy: 0.9688\n",
      "INFO:tensorflow:Assets written to: ../opticnet/opticnet_30epochs_834.84 images/assets\n",
      "Test acc for opticnet: 0.984504\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.02485275 0.02486225 0.02511456 0.02588208]\n",
      "Training xception for 0.025% of train size (aka 2087 images)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      " 6/42 [===>..........................] - ETA: 21s - loss: 1.4105 - accuracy: 0.0000e+00WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1240s vs `on_train_batch_begin` time: 0.1435s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1240s vs `on_train_batch_end` time: 0.2437s). Check your callbacks.\n",
      "42/42 [==============================] - 14s 222ms/step - loss: 1.3940 - accuracy: 0.1008 - val_loss: 1.3528 - val_accuracy: 0.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "42/42 [==============================] - 5s 123ms/step - loss: 1.3248 - accuracy: 0.7661 - val_loss: 1.3084 - val_accuracy: 0.5000\n",
      "Epoch 3/30\n",
      "42/42 [==============================] - 5s 124ms/step - loss: 1.2658 - accuracy: 0.7666 - val_loss: 1.2702 - val_accuracy: 0.5000\n",
      "Epoch 4/30\n",
      "42/42 [==============================] - 5s 124ms/step - loss: 1.2167 - accuracy: 0.7586 - val_loss: 1.2367 - val_accuracy: 0.5000\n",
      "Epoch 5/30\n",
      "42/42 [==============================] - 5s 123ms/step - loss: 1.1765 - accuracy: 0.7676 - val_loss: 1.2077 - val_accuracy: 0.7500\n",
      "Epoch 6/30\n",
      "42/42 [==============================] - 5s 124ms/step - loss: 1.1368 - accuracy: 0.8949 - val_loss: 1.1820 - val_accuracy: 0.7500\n",
      "Epoch 7/30\n",
      "42/42 [==============================] - 5s 125ms/step - loss: 1.1025 - accuracy: 0.8961 - val_loss: 1.1599 - val_accuracy: 0.7500\n",
      "Epoch 8/30\n",
      "42/42 [==============================] - 5s 124ms/step - loss: 1.0728 - accuracy: 0.9046 - val_loss: 1.1400 - val_accuracy: 0.9688\n",
      "Epoch 9/30\n",
      "42/42 [==============================] - 5s 125ms/step - loss: 1.0525 - accuracy: 0.9950 - val_loss: 1.1227 - val_accuracy: 0.9688\n",
      "Epoch 10/30\n",
      "42/42 [==============================] - 5s 125ms/step - loss: 1.0299 - accuracy: 0.9961 - val_loss: 1.1071 - val_accuracy: 0.9688\n",
      "Epoch 11/30\n",
      "42/42 [==============================] - 5s 125ms/step - loss: 1.0076 - accuracy: 0.9967 - val_loss: 1.0934 - val_accuracy: 0.9688\n",
      "Epoch 12/30\n",
      "42/42 [==============================] - 5s 125ms/step - loss: 0.9958 - accuracy: 0.9973 - val_loss: 1.0810 - val_accuracy: 0.9688\n",
      "Epoch 13/30\n",
      "42/42 [==============================] - 5s 125ms/step - loss: 0.9706 - accuracy: 0.9978 - val_loss: 1.0703 - val_accuracy: 0.9688\n",
      "Epoch 14/30\n",
      "42/42 [==============================] - 5s 125ms/step - loss: 0.9682 - accuracy: 0.9981 - val_loss: 1.0605 - val_accuracy: 0.9688\n",
      "Epoch 15/30\n",
      "42/42 [==============================] - 5s 125ms/step - loss: 0.9524 - accuracy: 0.9990 - val_loss: 1.0520 - val_accuracy: 0.9688\n",
      "Epoch 16/30\n",
      "42/42 [==============================] - 5s 125ms/step - loss: 0.9409 - accuracy: 0.9981 - val_loss: 1.0441 - val_accuracy: 0.9688\n",
      "Epoch 17/30\n",
      "42/42 [==============================] - 5s 125ms/step - loss: 0.9340 - accuracy: 0.9977 - val_loss: 1.0374 - val_accuracy: 0.9688\n",
      "Epoch 18/30\n",
      "42/42 [==============================] - 5s 125ms/step - loss: 0.9254 - accuracy: 0.9980 - val_loss: 1.0312 - val_accuracy: 0.9688\n",
      "Epoch 19/30\n",
      "42/42 [==============================] - 5s 125ms/step - loss: 0.9155 - accuracy: 0.9974 - val_loss: 1.0257 - val_accuracy: 0.9688\n",
      "Epoch 20/30\n",
      "42/42 [==============================] - 5s 125ms/step - loss: 0.9118 - accuracy: 0.9987 - val_loss: 1.0206 - val_accuracy: 0.9688\n",
      "Epoch 21/30\n",
      "42/42 [==============================] - 5s 126ms/step - loss: 0.9000 - accuracy: 0.9962 - val_loss: 1.0161 - val_accuracy: 0.9688\n",
      "Epoch 22/30\n",
      "42/42 [==============================] - 5s 125ms/step - loss: 0.8952 - accuracy: 0.9983 - val_loss: 1.0122 - val_accuracy: 0.9688\n",
      "Epoch 23/30\n",
      "42/42 [==============================] - 5s 126ms/step - loss: 0.8846 - accuracy: 0.9982 - val_loss: 1.0086 - val_accuracy: 0.9688\n",
      "Epoch 24/30\n",
      "42/42 [==============================] - 5s 126ms/step - loss: 0.8953 - accuracy: 0.9975 - val_loss: 1.0054 - val_accuracy: 0.9688\n",
      "Epoch 25/30\n",
      "42/42 [==============================] - 5s 125ms/step - loss: 0.8887 - accuracy: 0.9984 - val_loss: 1.0026 - val_accuracy: 0.9688\n",
      "Epoch 26/30\n",
      "42/42 [==============================] - 5s 126ms/step - loss: 0.8856 - accuracy: 0.9978 - val_loss: 0.9999 - val_accuracy: 0.9688\n",
      "Epoch 27/30\n",
      "42/42 [==============================] - 5s 125ms/step - loss: 0.8821 - accuracy: 0.9984 - val_loss: 0.9976 - val_accuracy: 0.9688\n",
      "Epoch 28/30\n",
      "42/42 [==============================] - 5s 126ms/step - loss: 0.8748 - accuracy: 0.9983 - val_loss: 0.9956 - val_accuracy: 0.9688\n",
      "Epoch 29/30\n",
      "42/42 [==============================] - 5s 125ms/step - loss: 0.8734 - accuracy: 0.9964 - val_loss: 0.9937 - val_accuracy: 0.9688\n",
      "Epoch 30/30\n",
      "42/42 [==============================] - 5s 125ms/step - loss: 0.8727 - accuracy: 0.9982 - val_loss: 0.9920 - val_accuracy: 0.9688\n",
      "INFO:tensorflow:Assets written to: ../xception/xception_30epochs_2087.1 images/assets\n",
      "Test acc for xception: 0.990702\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training resnet for 0.025% of train size (aka 2087 images)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      " 6/42 [===>..........................] - ETA: 14s - loss: 1.4040 - accuracy: 0.0012    WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0605s vs `on_train_batch_begin` time: 0.1296s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0605s vs `on_train_batch_end` time: 0.1585s). Check your callbacks.\n",
      "42/42 [==============================] - 9s 143ms/step - loss: 1.3898 - accuracy: 0.2879 - val_loss: 1.3609 - val_accuracy: 0.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "42/42 [==============================] - 2s 58ms/step - loss: 1.3081 - accuracy: 0.7363 - val_loss: 1.3110 - val_accuracy: 0.5000\n",
      "Epoch 3/30\n",
      "42/42 [==============================] - 2s 59ms/step - loss: 1.2381 - accuracy: 0.7562 - val_loss: 1.2730 - val_accuracy: 0.5000\n",
      "Epoch 4/30\n",
      "42/42 [==============================] - 2s 59ms/step - loss: 1.1844 - accuracy: 0.7599 - val_loss: 1.2408 - val_accuracy: 0.5000\n",
      "Epoch 5/30\n",
      "42/42 [==============================] - 2s 58ms/step - loss: 1.1440 - accuracy: 0.7541 - val_loss: 1.2132 - val_accuracy: 0.5000\n",
      "Epoch 6/30\n",
      "42/42 [==============================] - 2s 58ms/step - loss: 1.1004 - accuracy: 0.7685 - val_loss: 1.1892 - val_accuracy: 0.5000\n",
      "Epoch 7/30\n",
      "42/42 [==============================] - 2s 59ms/step - loss: 1.0744 - accuracy: 0.7563 - val_loss: 1.1677 - val_accuracy: 0.5000\n",
      "Epoch 8/30\n",
      "42/42 [==============================] - 2s 58ms/step - loss: 1.0432 - accuracy: 0.7642 - val_loss: 1.1495 - val_accuracy: 0.5000\n",
      "Epoch 9/30\n",
      "42/42 [==============================] - 2s 58ms/step - loss: 1.0245 - accuracy: 0.7493 - val_loss: 1.1331 - val_accuracy: 0.5000\n",
      "Epoch 10/30\n",
      "42/42 [==============================] - 2s 58ms/step - loss: 1.0083 - accuracy: 0.7407 - val_loss: 1.1187 - val_accuracy: 0.5000\n",
      "Epoch 11/30\n",
      "42/42 [==============================] - 2s 58ms/step - loss: 0.9850 - accuracy: 0.7501 - val_loss: 1.1057 - val_accuracy: 0.5000\n",
      "Epoch 12/30\n",
      "42/42 [==============================] - 2s 58ms/step - loss: 0.9686 - accuracy: 0.7547 - val_loss: 1.0942 - val_accuracy: 0.5000\n",
      "Epoch 13/30\n",
      "42/42 [==============================] - 2s 58ms/step - loss: 0.9448 - accuracy: 0.7756 - val_loss: 1.0842 - val_accuracy: 0.5000\n",
      "Epoch 14/30\n",
      "42/42 [==============================] - 2s 59ms/step - loss: 0.9432 - accuracy: 0.7520 - val_loss: 1.0751 - val_accuracy: 0.5000\n",
      "Epoch 15/30\n",
      "42/42 [==============================] - 2s 59ms/step - loss: 0.9263 - accuracy: 0.8623 - val_loss: 1.0668 - val_accuracy: 0.7500\n",
      "Epoch 16/30\n",
      "42/42 [==============================] - 2s 58ms/step - loss: 0.9294 - accuracy: 0.8770 - val_loss: 1.0592 - val_accuracy: 0.7500\n",
      "Epoch 17/30\n",
      "42/42 [==============================] - 2s 59ms/step - loss: 0.9042 - accuracy: 0.9003 - val_loss: 1.0528 - val_accuracy: 0.7500\n",
      "Epoch 18/30\n",
      "42/42 [==============================] - 2s 58ms/step - loss: 0.9010 - accuracy: 0.8947 - val_loss: 1.0469 - val_accuracy: 0.7500\n",
      "Epoch 19/30\n",
      "42/42 [==============================] - 2s 58ms/step - loss: 0.8990 - accuracy: 0.8883 - val_loss: 1.0415 - val_accuracy: 0.7500\n",
      "Epoch 20/30\n",
      "42/42 [==============================] - 2s 58ms/step - loss: 0.8908 - accuracy: 0.8874 - val_loss: 1.0368 - val_accuracy: 0.7500\n",
      "Epoch 21/30\n",
      "42/42 [==============================] - 2s 58ms/step - loss: 0.8841 - accuracy: 0.8890 - val_loss: 1.0325 - val_accuracy: 0.7500\n",
      "Epoch 22/30\n",
      "42/42 [==============================] - 2s 58ms/step - loss: 0.8841 - accuracy: 0.8872 - val_loss: 1.0288 - val_accuracy: 0.7500\n",
      "Epoch 23/30\n",
      "42/42 [==============================] - 2s 58ms/step - loss: 0.8792 - accuracy: 0.8902 - val_loss: 1.0253 - val_accuracy: 0.7500\n",
      "Epoch 24/30\n",
      "42/42 [==============================] - 2s 58ms/step - loss: 0.8675 - accuracy: 0.9011 - val_loss: 1.0221 - val_accuracy: 0.7500\n",
      "Epoch 25/30\n",
      "42/42 [==============================] - 2s 58ms/step - loss: 0.8597 - accuracy: 0.9004 - val_loss: 1.0194 - val_accuracy: 0.7500\n",
      "Epoch 26/30\n",
      "42/42 [==============================] - 2s 58ms/step - loss: 0.8654 - accuracy: 0.8882 - val_loss: 1.0169 - val_accuracy: 0.7500\n",
      "Epoch 27/30\n",
      "42/42 [==============================] - 2s 58ms/step - loss: 0.8598 - accuracy: 0.8884 - val_loss: 1.0147 - val_accuracy: 0.7500\n",
      "Epoch 28/30\n",
      "42/42 [==============================] - 2s 58ms/step - loss: 0.8690 - accuracy: 0.8776 - val_loss: 1.0126 - val_accuracy: 0.7500\n",
      "Epoch 29/30\n",
      "42/42 [==============================] - 2s 58ms/step - loss: 0.8546 - accuracy: 0.8958 - val_loss: 1.0109 - val_accuracy: 0.7500\n",
      "Epoch 30/30\n",
      "42/42 [==============================] - 2s 58ms/step - loss: 0.8556 - accuracy: 0.8905 - val_loss: 1.0092 - val_accuracy: 0.7500\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_2087.1 images/assets\n",
      "Test acc for resnet: 0.747934\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training opticnet for 0.025% of train size (aka 2087 images)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      " 6/42 [===>..........................] - ETA: 1:03 - loss: 5.4330 - accuracy: 0.1586WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.4658s vs `on_train_batch_end` time: 1.0418s). Check your callbacks.\n",
      "42/42 [==============================] - 69s 1s/step - loss: 2.0184 - accuracy: 0.5642 - val_loss: 3.6616 - val_accuracy: 0.3438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "42/42 [==============================] - 49s 1s/step - loss: 0.3089 - accuracy: 0.8997 - val_loss: 0.5432 - val_accuracy: 0.8125\n",
      "Epoch 3/30\n",
      "42/42 [==============================] - 49s 1s/step - loss: 0.1405 - accuracy: 0.9597 - val_loss: 0.1465 - val_accuracy: 0.9375\n",
      "Epoch 4/30\n",
      "42/42 [==============================] - 50s 1s/step - loss: 0.0934 - accuracy: 0.9721 - val_loss: 0.3138 - val_accuracy: 0.8438\n",
      "Epoch 5/30\n",
      "42/42 [==============================] - 49s 1s/step - loss: 0.0608 - accuracy: 0.9812 - val_loss: 0.4008 - val_accuracy: 0.9062\n",
      "Epoch 6/30\n",
      "42/42 [==============================] - 49s 1s/step - loss: 0.0655 - accuracy: 0.9770 - val_loss: 0.0211 - val_accuracy: 1.0000\n",
      "Epoch 7/30\n",
      "42/42 [==============================] - 50s 1s/step - loss: 0.0375 - accuracy: 0.9867 - val_loss: 0.0053 - val_accuracy: 1.0000\n",
      "Epoch 8/30\n",
      "42/42 [==============================] - 50s 1s/step - loss: 0.0122 - accuracy: 0.9966 - val_loss: 0.0105 - val_accuracy: 1.0000\n",
      "Epoch 9/30\n",
      "42/42 [==============================] - 50s 1s/step - loss: 0.0070 - accuracy: 0.9970 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
      "Epoch 10/30\n",
      "42/42 [==============================] - 50s 1s/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 9.9000e-04 - val_accuracy: 1.0000\n",
      "Epoch 11/30\n",
      "42/42 [==============================] - 49s 1s/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 5.8180e-04 - val_accuracy: 1.0000\n",
      "Epoch 12/30\n",
      "42/42 [==============================] - 50s 1s/step - loss: 0.0043 - accuracy: 0.9993 - val_loss: 2.8489e-04 - val_accuracy: 1.0000\n",
      "Epoch 13/30\n",
      "42/42 [==============================] - 49s 1s/step - loss: 9.6807e-04 - accuracy: 1.0000 - val_loss: 2.9568e-04 - val_accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "42/42 [==============================] - 50s 1s/step - loss: 4.3540e-04 - accuracy: 1.0000 - val_loss: 4.5543e-04 - val_accuracy: 1.0000\n",
      "Epoch 15/30\n",
      "42/42 [==============================] - 50s 1s/step - loss: 0.0011 - accuracy: 0.9999 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "42/42 [==============================] - 50s 1s/step - loss: 3.5993e-04 - accuracy: 1.0000 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "42/42 [==============================] - 50s 1s/step - loss: 3.7071e-04 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "42/42 [==============================] - 50s 1s/step - loss: 2.9853e-04 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "42/42 [==============================] - 50s 1s/step - loss: 2.2089e-04 - accuracy: 1.0000 - val_loss: 8.7532e-04 - val_accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "42/42 [==============================] - 49s 1s/step - loss: 2.5020e-04 - accuracy: 1.0000 - val_loss: 7.2509e-04 - val_accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "42/42 [==============================] - 49s 1s/step - loss: 1.9798e-04 - accuracy: 1.0000 - val_loss: 8.1013e-04 - val_accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "42/42 [==============================] - 50s 1s/step - loss: 1.9384e-04 - accuracy: 1.0000 - val_loss: 9.0290e-04 - val_accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "42/42 [==============================] - 50s 1s/step - loss: 2.9525e-04 - accuracy: 1.0000 - val_loss: 7.7789e-04 - val_accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "42/42 [==============================] - 50s 1s/step - loss: 5.2192e-04 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "42/42 [==============================] - 50s 1s/step - loss: 1.6677e-04 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "42/42 [==============================] - 50s 1s/step - loss: 1.9643e-04 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "42/42 [==============================] - 50s 1s/step - loss: 1.7098e-04 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "42/42 [==============================] - 49s 1s/step - loss: 1.2796e-04 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "42/42 [==============================] - 49s 1s/step - loss: 1.1416e-04 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "42/42 [==============================] - 49s 1s/step - loss: 1.6778e-04 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
      "INFO:tensorflow:Assets written to: ../opticnet/opticnet_30epochs_2087.1 images/assets\n",
      "Test acc for opticnet: 0.990702\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.04905947 0.05004704 0.05049348 0.05199629]\n",
      "Training xception for 0.05% of train size (aka 4174 images)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      " 6/84 [=>............................] - ETA: 45s - loss: 1.3898 - accuracy: 0.1216WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1183s vs `on_train_batch_begin` time: 0.1633s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1183s vs `on_train_batch_end` time: 0.2280s). Check your callbacks.\n",
      "84/84 [==============================] - 17s 167ms/step - loss: 1.3567 - accuracy: 0.4965 - val_loss: 1.2939 - val_accuracy: 0.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "84/84 [==============================] - 10s 121ms/step - loss: 1.2234 - accuracy: 0.8588 - val_loss: 1.2092 - val_accuracy: 0.7188\n",
      "Epoch 3/30\n",
      "84/84 [==============================] - 10s 122ms/step - loss: 1.1204 - accuracy: 0.8935 - val_loss: 1.1381 - val_accuracy: 0.9688\n",
      "Epoch 4/30\n",
      "84/84 [==============================] - 10s 123ms/step - loss: 1.0322 - accuracy: 0.9967 - val_loss: 1.0777 - val_accuracy: 0.9688\n",
      "Epoch 5/30\n",
      "84/84 [==============================] - 10s 123ms/step - loss: 0.9608 - accuracy: 0.9964 - val_loss: 1.0262 - val_accuracy: 0.9688\n",
      "Epoch 6/30\n",
      "84/84 [==============================] - 10s 124ms/step - loss: 0.9013 - accuracy: 0.9978 - val_loss: 0.9823 - val_accuracy: 0.9688\n",
      "Epoch 7/30\n",
      "84/84 [==============================] - 10s 124ms/step - loss: 0.8600 - accuracy: 0.9974 - val_loss: 0.9435 - val_accuracy: 0.9688\n",
      "Epoch 8/30\n",
      "84/84 [==============================] - 10s 123ms/step - loss: 0.8139 - accuracy: 0.9966 - val_loss: 0.9107 - val_accuracy: 0.9688\n",
      "Epoch 9/30\n",
      "84/84 [==============================] - 10s 123ms/step - loss: 0.7805 - accuracy: 0.9987 - val_loss: 0.8820 - val_accuracy: 0.9688\n",
      "Epoch 10/30\n",
      "84/84 [==============================] - 10s 124ms/step - loss: 0.7496 - accuracy: 0.9974 - val_loss: 0.8565 - val_accuracy: 0.9688\n",
      "Epoch 11/30\n",
      "84/84 [==============================] - 10s 124ms/step - loss: 0.7217 - accuracy: 0.9969 - val_loss: 0.8340 - val_accuracy: 0.9688\n",
      "Epoch 12/30\n",
      "84/84 [==============================] - 10s 125ms/step - loss: 0.7041 - accuracy: 0.9983 - val_loss: 0.8141 - val_accuracy: 0.9688\n",
      "Epoch 13/30\n",
      "84/84 [==============================] - 10s 124ms/step - loss: 0.6805 - accuracy: 0.9978 - val_loss: 0.7967 - val_accuracy: 0.9688\n",
      "Epoch 14/30\n",
      "84/84 [==============================] - 10s 124ms/step - loss: 0.6633 - accuracy: 0.9988 - val_loss: 0.7815 - val_accuracy: 0.9688\n",
      "Epoch 15/30\n",
      "84/84 [==============================] - 10s 124ms/step - loss: 0.6534 - accuracy: 0.9982 - val_loss: 0.7677 - val_accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "84/84 [==============================] - 10s 124ms/step - loss: 0.6368 - accuracy: 0.9972 - val_loss: 0.7554 - val_accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "84/84 [==============================] - 10s 124ms/step - loss: 0.6272 - accuracy: 0.9974 - val_loss: 0.7444 - val_accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "84/84 [==============================] - 10s 124ms/step - loss: 0.6123 - accuracy: 0.9972 - val_loss: 0.7349 - val_accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "84/84 [==============================] - 10s 125ms/step - loss: 0.6033 - accuracy: 0.9974 - val_loss: 0.7261 - val_accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "84/84 [==============================] - 10s 124ms/step - loss: 0.5946 - accuracy: 0.9982 - val_loss: 0.7182 - val_accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "84/84 [==============================] - 10s 124ms/step - loss: 0.5858 - accuracy: 0.9973 - val_loss: 0.7113 - val_accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "84/84 [==============================] - 10s 124ms/step - loss: 0.5888 - accuracy: 0.9974 - val_loss: 0.7047 - val_accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "84/84 [==============================] - 10s 124ms/step - loss: 0.5776 - accuracy: 0.9975 - val_loss: 0.6992 - val_accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "84/84 [==============================] - 10s 124ms/step - loss: 0.5710 - accuracy: 0.9967 - val_loss: 0.6942 - val_accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "84/84 [==============================] - 10s 124ms/step - loss: 0.5595 - accuracy: 0.9978 - val_loss: 0.6896 - val_accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "84/84 [==============================] - 10s 124ms/step - loss: 0.5626 - accuracy: 0.9977 - val_loss: 0.6855 - val_accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "84/84 [==============================] - 10s 124ms/step - loss: 0.5589 - accuracy: 0.9963 - val_loss: 0.6818 - val_accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "84/84 [==============================] - 10s 124ms/step - loss: 0.5588 - accuracy: 0.9982 - val_loss: 0.6784 - val_accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "84/84 [==============================] - 10s 125ms/step - loss: 0.5494 - accuracy: 0.9983 - val_loss: 0.6755 - val_accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "84/84 [==============================] - 10s 124ms/step - loss: 0.5487 - accuracy: 0.9978 - val_loss: 0.6727 - val_accuracy: 1.0000\n",
      "INFO:tensorflow:Assets written to: ../xception/xception_30epochs_4174.2 images/assets\n",
      "Test acc for xception: 0.998967\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training resnet for 0.05% of train size (aka 4174 images)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      " 6/84 [=>............................] - ETA: 31s - loss: 1.3977 - accuracy: 0.0926WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0610s vs `on_train_batch_begin` time: 0.1268s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0610s vs `on_train_batch_end` time: 0.1609s). Check your callbacks.\n",
      "84/84 [==============================] - 12s 98ms/step - loss: 1.3627 - accuracy: 0.4798 - val_loss: 1.2931 - val_accuracy: 0.7188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "84/84 [==============================] - 5s 57ms/step - loss: 1.2294 - accuracy: 0.8644 - val_loss: 1.2088 - val_accuracy: 0.7188\n",
      "Epoch 3/30\n",
      "84/84 [==============================] - 5s 57ms/step - loss: 1.1241 - accuracy: 0.8642 - val_loss: 1.1380 - val_accuracy: 0.7188\n",
      "Epoch 4/30\n",
      "84/84 [==============================] - 5s 57ms/step - loss: 1.0401 - accuracy: 0.8661 - val_loss: 1.0781 - val_accuracy: 0.9688\n",
      "Epoch 5/30\n",
      "84/84 [==============================] - 5s 57ms/step - loss: 0.9657 - accuracy: 0.9953 - val_loss: 1.0277 - val_accuracy: 0.9688\n",
      "Epoch 6/30\n",
      "84/84 [==============================] - 5s 57ms/step - loss: 0.9055 - accuracy: 0.9960 - val_loss: 0.9825 - val_accuracy: 0.9688\n",
      "Epoch 7/30\n",
      "84/84 [==============================] - 5s 58ms/step - loss: 0.8620 - accuracy: 0.9978 - val_loss: 0.9436 - val_accuracy: 0.9688\n",
      "Epoch 8/30\n",
      "84/84 [==============================] - 5s 58ms/step - loss: 0.8207 - accuracy: 0.9968 - val_loss: 0.9106 - val_accuracy: 0.9688\n",
      "Epoch 9/30\n",
      "84/84 [==============================] - 5s 58ms/step - loss: 0.7854 - accuracy: 0.9971 - val_loss: 0.8821 - val_accuracy: 0.9688\n",
      "Epoch 10/30\n",
      "84/84 [==============================] - 5s 58ms/step - loss: 0.7527 - accuracy: 0.9953 - val_loss: 0.8571 - val_accuracy: 0.9688\n",
      "Epoch 11/30\n",
      "84/84 [==============================] - 5s 58ms/step - loss: 0.7300 - accuracy: 0.9970 - val_loss: 0.8343 - val_accuracy: 0.9688\n",
      "Epoch 12/30\n",
      "84/84 [==============================] - 5s 58ms/step - loss: 0.7041 - accuracy: 0.9968 - val_loss: 0.8146 - val_accuracy: 0.9688\n",
      "Epoch 13/30\n",
      "84/84 [==============================] - 5s 57ms/step - loss: 0.6879 - accuracy: 0.9978 - val_loss: 0.7972 - val_accuracy: 0.9688\n",
      "Epoch 14/30\n",
      "84/84 [==============================] - 5s 57ms/step - loss: 0.6674 - accuracy: 0.9973 - val_loss: 0.7817 - val_accuracy: 0.9688\n",
      "Epoch 15/30\n",
      "84/84 [==============================] - 5s 58ms/step - loss: 0.6565 - accuracy: 0.9953 - val_loss: 0.7677 - val_accuracy: 0.9688\n",
      "Epoch 16/30\n",
      "84/84 [==============================] - 5s 57ms/step - loss: 0.6408 - accuracy: 0.9966 - val_loss: 0.7555 - val_accuracy: 0.9688\n",
      "Epoch 17/30\n",
      "84/84 [==============================] - 5s 57ms/step - loss: 0.6276 - accuracy: 0.9956 - val_loss: 0.7446 - val_accuracy: 0.9688\n",
      "Epoch 18/30\n",
      "84/84 [==============================] - 5s 57ms/step - loss: 0.6174 - accuracy: 0.9970 - val_loss: 0.7350 - val_accuracy: 0.9688\n",
      "Epoch 19/30\n",
      "84/84 [==============================] - 5s 58ms/step - loss: 0.6060 - accuracy: 0.9979 - val_loss: 0.7261 - val_accuracy: 0.9688\n",
      "Epoch 20/30\n",
      "84/84 [==============================] - 5s 58ms/step - loss: 0.6041 - accuracy: 0.9974 - val_loss: 0.7183 - val_accuracy: 0.9688\n",
      "Epoch 21/30\n",
      "84/84 [==============================] - 5s 58ms/step - loss: 0.5965 - accuracy: 0.9954 - val_loss: 0.7112 - val_accuracy: 0.9688\n",
      "Epoch 22/30\n",
      "84/84 [==============================] - 5s 58ms/step - loss: 0.5862 - accuracy: 0.9952 - val_loss: 0.7050 - val_accuracy: 0.9688\n",
      "Epoch 23/30\n",
      "84/84 [==============================] - 5s 58ms/step - loss: 0.5799 - accuracy: 0.9963 - val_loss: 0.6993 - val_accuracy: 0.9688\n",
      "Epoch 24/30\n",
      "84/84 [==============================] - 5s 57ms/step - loss: 0.5759 - accuracy: 0.9982 - val_loss: 0.6942 - val_accuracy: 0.9688\n",
      "Epoch 25/30\n",
      "84/84 [==============================] - 5s 58ms/step - loss: 0.5730 - accuracy: 0.9971 - val_loss: 0.6896 - val_accuracy: 0.9688\n",
      "Epoch 26/30\n",
      "84/84 [==============================] - 5s 58ms/step - loss: 0.5642 - accuracy: 0.9982 - val_loss: 0.6854 - val_accuracy: 0.9688\n",
      "Epoch 27/30\n",
      "84/84 [==============================] - 5s 58ms/step - loss: 0.5623 - accuracy: 0.9971 - val_loss: 0.6818 - val_accuracy: 0.9688\n",
      "Epoch 28/30\n",
      "84/84 [==============================] - 5s 58ms/step - loss: 0.5578 - accuracy: 0.9978 - val_loss: 0.6784 - val_accuracy: 0.9688\n",
      "Epoch 29/30\n",
      "84/84 [==============================] - 5s 58ms/step - loss: 0.5531 - accuracy: 0.9968 - val_loss: 0.6754 - val_accuracy: 0.9688\n",
      "Epoch 30/30\n",
      "84/84 [==============================] - 5s 57ms/step - loss: 0.5471 - accuracy: 0.9969 - val_loss: 0.6727 - val_accuracy: 0.9688\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_4174.2 images/assets\n",
      "Test acc for resnet: 0.994835\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training opticnet for 0.05% of train size (aka 4174 images)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      " 6/84 [=>............................] - ETA: 2:18 - loss: 5.7391 - accuracy: 0.1297WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.4649s vs `on_train_batch_end` time: 1.0479s). Check your callbacks.\n",
      "84/84 [==============================] - 117s 1s/step - loss: 1.3922 - accuracy: 0.6778 - val_loss: 0.3540 - val_accuracy: 0.8438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "84/84 [==============================] - 99s 1s/step - loss: 0.1906 - accuracy: 0.9386 - val_loss: 0.0792 - val_accuracy: 0.9688\n",
      "Epoch 3/30\n",
      "84/84 [==============================] - 98s 1s/step - loss: 0.1018 - accuracy: 0.9680 - val_loss: 0.0934 - val_accuracy: 0.9688\n",
      "Epoch 4/30\n",
      "84/84 [==============================] - 98s 1s/step - loss: 0.0718 - accuracy: 0.9739 - val_loss: 0.1043 - val_accuracy: 1.0000\n",
      "Epoch 5/30\n",
      "84/84 [==============================] - 98s 1s/step - loss: 0.0590 - accuracy: 0.9804 - val_loss: 0.0197 - val_accuracy: 1.0000\n",
      "Epoch 6/30\n",
      "84/84 [==============================] - 97s 1s/step - loss: 0.0567 - accuracy: 0.9808 - val_loss: 0.0316 - val_accuracy: 1.0000\n",
      "Epoch 7/30\n",
      "84/84 [==============================] - 97s 1s/step - loss: 0.0199 - accuracy: 0.9924 - val_loss: 0.0091 - val_accuracy: 1.0000\n",
      "Epoch 8/30\n",
      "84/84 [==============================] - 98s 1s/step - loss: 0.0173 - accuracy: 0.9943 - val_loss: 1.4137e-04 - val_accuracy: 1.0000\n",
      "Epoch 9/30\n",
      "84/84 [==============================] - 99s 1s/step - loss: 0.0051 - accuracy: 0.9985 - val_loss: 3.3739e-04 - val_accuracy: 1.0000\n",
      "Epoch 10/30\n",
      "84/84 [==============================] - 99s 1s/step - loss: 0.0094 - accuracy: 0.9979 - val_loss: 0.0036 - val_accuracy: 1.0000\n",
      "Epoch 11/30\n",
      "84/84 [==============================] - 99s 1s/step - loss: 0.0104 - accuracy: 0.9970 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
      "Epoch 12/30\n",
      "84/84 [==============================] - 99s 1s/step - loss: 0.0131 - accuracy: 0.9963 - val_loss: 0.0140 - val_accuracy: 1.0000\n",
      "Epoch 13/30\n",
      "84/84 [==============================] - 99s 1s/step - loss: 0.0056 - accuracy: 0.9974 - val_loss: 1.8545e-04 - val_accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "84/84 [==============================] - 99s 1s/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.0239e-04 - val_accuracy: 1.0000\n",
      "Epoch 15/30\n",
      "84/84 [==============================] - 99s 1s/step - loss: 4.4042e-04 - accuracy: 1.0000 - val_loss: 1.6491e-05 - val_accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "84/84 [==============================] - 99s 1s/step - loss: 3.0804e-04 - accuracy: 1.0000 - val_loss: 1.1895e-05 - val_accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "84/84 [==============================] - 99s 1s/step - loss: 1.6746e-04 - accuracy: 1.0000 - val_loss: 9.3987e-06 - val_accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "84/84 [==============================] - 99s 1s/step - loss: 1.9505e-04 - accuracy: 1.0000 - val_loss: 6.4670e-06 - val_accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "84/84 [==============================] - 99s 1s/step - loss: 1.5247e-04 - accuracy: 1.0000 - val_loss: 7.1264e-06 - val_accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "84/84 [==============================] - 99s 1s/step - loss: 2.2000e-04 - accuracy: 1.0000 - val_loss: 6.7501e-06 - val_accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "84/84 [==============================] - 99s 1s/step - loss: 1.5900e-04 - accuracy: 1.0000 - val_loss: 6.4782e-06 - val_accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "84/84 [==============================] - 99s 1s/step - loss: 1.3882e-04 - accuracy: 1.0000 - val_loss: 5.0850e-06 - val_accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "84/84 [==============================] - 99s 1s/step - loss: 9.4742e-05 - accuracy: 1.0000 - val_loss: 4.6640e-06 - val_accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "84/84 [==============================] - 99s 1s/step - loss: 7.3637e-05 - accuracy: 1.0000 - val_loss: 4.2654e-06 - val_accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "84/84 [==============================] - 99s 1s/step - loss: 2.1418e-04 - accuracy: 1.0000 - val_loss: 3.9823e-06 - val_accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "84/84 [==============================] - 99s 1s/step - loss: 7.4716e-05 - accuracy: 1.0000 - val_loss: 3.9823e-06 - val_accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "84/84 [==============================] - 99s 1s/step - loss: 1.2091e-04 - accuracy: 1.0000 - val_loss: 6.1764e-06 - val_accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "84/84 [==============================] - 99s 1s/step - loss: 1.4717e-04 - accuracy: 1.0000 - val_loss: 4.4852e-06 - val_accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "84/84 [==============================] - 99s 1s/step - loss: 8.7071e-05 - accuracy: 1.0000 - val_loss: 3.8072e-06 - val_accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "84/84 [==============================] - 99s 1s/step - loss: 7.6100e-05 - accuracy: 1.0000 - val_loss: 3.4757e-06 - val_accuracy: 1.0000\n",
      "INFO:tensorflow:Assets written to: ../opticnet/opticnet_30epochs_4174.2 images/assets\n",
      "Test acc for opticnet: 0.987603\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.07474824 0.07533934 0.07472682 0.0746286 ]\n",
      "Training xception for 0.075% of train size (aka 6261 images)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/126 [>.............................] - ETA: 1:05 - loss: 1.4062 - accuracy: 0.1948WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1192s vs `on_train_batch_begin` time: 0.1569s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1192s vs `on_train_batch_end` time: 0.1996s). Check your callbacks.\n",
      "126/126 [==============================] - 22s 149ms/step - loss: 1.3534 - accuracy: 0.5156 - val_loss: 1.2583 - val_accuracy: 0.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "126/126 [==============================] - 15s 122ms/step - loss: 1.1612 - accuracy: 0.7659 - val_loss: 1.1382 - val_accuracy: 0.5000\n",
      "Epoch 3/30\n",
      "126/126 [==============================] - 16s 123ms/step - loss: 1.0158 - accuracy: 0.8138 - val_loss: 1.0403 - val_accuracy: 0.7188\n",
      "Epoch 4/30\n",
      "126/126 [==============================] - 16s 123ms/step - loss: 0.9076 - accuracy: 0.9095 - val_loss: 0.9602 - val_accuracy: 0.9688\n",
      "Epoch 5/30\n",
      "126/126 [==============================] - 16s 123ms/step - loss: 0.8151 - accuracy: 0.9978 - val_loss: 0.8936 - val_accuracy: 0.9688\n",
      "Epoch 6/30\n",
      "126/126 [==============================] - 16s 123ms/step - loss: 0.7501 - accuracy: 0.9970 - val_loss: 0.8368 - val_accuracy: 0.9688\n",
      "Epoch 7/30\n",
      "126/126 [==============================] - 16s 123ms/step - loss: 0.6925 - accuracy: 0.9973 - val_loss: 0.7883 - val_accuracy: 1.0000\n",
      "Epoch 8/30\n",
      "126/126 [==============================] - 16s 124ms/step - loss: 0.6499 - accuracy: 0.9969 - val_loss: 0.7465 - val_accuracy: 1.0000\n",
      "Epoch 9/30\n",
      "126/126 [==============================] - 16s 124ms/step - loss: 0.6013 - accuracy: 0.9975 - val_loss: 0.7107 - val_accuracy: 1.0000\n",
      "Epoch 10/30\n",
      "126/126 [==============================] - 16s 124ms/step - loss: 0.5699 - accuracy: 0.9977 - val_loss: 0.6797 - val_accuracy: 1.0000\n",
      "Epoch 11/30\n",
      "126/126 [==============================] - 16s 124ms/step - loss: 0.5486 - accuracy: 0.9973 - val_loss: 0.6523 - val_accuracy: 1.0000\n",
      "Epoch 12/30\n",
      "126/126 [==============================] - 16s 124ms/step - loss: 0.5233 - accuracy: 0.9963 - val_loss: 0.6285 - val_accuracy: 1.0000\n",
      "Epoch 13/30\n",
      "126/126 [==============================] - 16s 124ms/step - loss: 0.5015 - accuracy: 0.9974 - val_loss: 0.6079 - val_accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "126/126 [==============================] - 16s 124ms/step - loss: 0.4834 - accuracy: 0.9969 - val_loss: 0.5893 - val_accuracy: 1.0000\n",
      "Epoch 15/30\n",
      "126/126 [==============================] - 16s 124ms/step - loss: 0.4677 - accuracy: 0.9979 - val_loss: 0.5731 - val_accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "126/126 [==============================] - 16s 124ms/step - loss: 0.4529 - accuracy: 0.9968 - val_loss: 0.5585 - val_accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "126/126 [==============================] - 16s 125ms/step - loss: 0.4405 - accuracy: 0.9975 - val_loss: 0.5458 - val_accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "126/126 [==============================] - 16s 125ms/step - loss: 0.4295 - accuracy: 0.9979 - val_loss: 0.5344 - val_accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "126/126 [==============================] - 16s 125ms/step - loss: 0.4170 - accuracy: 0.9985 - val_loss: 0.5243 - val_accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "126/126 [==============================] - 16s 125ms/step - loss: 0.4129 - accuracy: 0.9969 - val_loss: 0.5153 - val_accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "126/126 [==============================] - 16s 124ms/step - loss: 0.4071 - accuracy: 0.9974 - val_loss: 0.5071 - val_accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "126/126 [==============================] - 16s 124ms/step - loss: 0.4012 - accuracy: 0.9964 - val_loss: 0.4999 - val_accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "126/126 [==============================] - 16s 124ms/step - loss: 0.3892 - accuracy: 0.9979 - val_loss: 0.4934 - val_accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "126/126 [==============================] - 16s 124ms/step - loss: 0.3845 - accuracy: 0.9972 - val_loss: 0.4877 - val_accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "126/126 [==============================] - 16s 124ms/step - loss: 0.3797 - accuracy: 0.9969 - val_loss: 0.4825 - val_accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "126/126 [==============================] - 16s 124ms/step - loss: 0.3766 - accuracy: 0.9979 - val_loss: 0.4775 - val_accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "126/126 [==============================] - 16s 124ms/step - loss: 0.3716 - accuracy: 0.9972 - val_loss: 0.4732 - val_accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "126/126 [==============================] - 16s 124ms/step - loss: 0.3670 - accuracy: 0.9981 - val_loss: 0.4693 - val_accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "126/126 [==============================] - 16s 124ms/step - loss: 0.3686 - accuracy: 0.9974 - val_loss: 0.4658 - val_accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "126/126 [==============================] - 16s 124ms/step - loss: 0.3598 - accuracy: 0.9977 - val_loss: 0.4628 - val_accuracy: 1.0000\n",
      "INFO:tensorflow:Assets written to: ../xception/xception_30epochs_6261.3 images/assets\n",
      "Test acc for xception: 0.998967\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training resnet for 0.075% of train size (aka 6261 images)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/126 [>.............................] - ETA: 47s - loss: 1.4051 - accuracy: 0.1014WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0601s vs `on_train_batch_begin` time: 0.1270s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0601s vs `on_train_batch_end` time: 0.1559s). Check your callbacks.\n",
      "126/126 [==============================] - 14s 83ms/step - loss: 1.3528 - accuracy: 0.4292 - val_loss: 1.2434 - val_accuracy: 0.7500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "126/126 [==============================] - 7s 57ms/step - loss: 1.1641 - accuracy: 0.8607 - val_loss: 1.1235 - val_accuracy: 0.9688\n",
      "Epoch 3/30\n",
      "126/126 [==============================] - 7s 57ms/step - loss: 1.0189 - accuracy: 0.9956 - val_loss: 1.0280 - val_accuracy: 0.9688\n",
      "Epoch 4/30\n",
      "126/126 [==============================] - 7s 57ms/step - loss: 0.9102 - accuracy: 0.9957 - val_loss: 0.9470 - val_accuracy: 0.9688\n",
      "Epoch 5/30\n",
      "126/126 [==============================] - 7s 57ms/step - loss: 0.8182 - accuracy: 0.9966 - val_loss: 0.8815 - val_accuracy: 0.9688\n",
      "Epoch 6/30\n",
      "126/126 [==============================] - 7s 57ms/step - loss: 0.7511 - accuracy: 0.9977 - val_loss: 0.8250 - val_accuracy: 0.9688\n",
      "Epoch 7/30\n",
      "126/126 [==============================] - 7s 57ms/step - loss: 0.6925 - accuracy: 0.9979 - val_loss: 0.7751 - val_accuracy: 1.0000\n",
      "Epoch 8/30\n",
      "126/126 [==============================] - 7s 58ms/step - loss: 0.6439 - accuracy: 0.9961 - val_loss: 0.7346 - val_accuracy: 1.0000\n",
      "Epoch 9/30\n",
      "126/126 [==============================] - 7s 57ms/step - loss: 0.6039 - accuracy: 0.9983 - val_loss: 0.6986 - val_accuracy: 1.0000\n",
      "Epoch 10/30\n",
      "126/126 [==============================] - 7s 58ms/step - loss: 0.5728 - accuracy: 0.9978 - val_loss: 0.6677 - val_accuracy: 1.0000\n",
      "Epoch 11/30\n",
      "126/126 [==============================] - 7s 58ms/step - loss: 0.5427 - accuracy: 0.9983 - val_loss: 0.6413 - val_accuracy: 1.0000\n",
      "Epoch 12/30\n",
      "126/126 [==============================] - 7s 57ms/step - loss: 0.5214 - accuracy: 0.9981 - val_loss: 0.6173 - val_accuracy: 1.0000\n",
      "Epoch 13/30\n",
      "126/126 [==============================] - 7s 57ms/step - loss: 0.5005 - accuracy: 0.9982 - val_loss: 0.5966 - val_accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "126/126 [==============================] - 7s 58ms/step - loss: 0.4822 - accuracy: 0.9982 - val_loss: 0.5779 - val_accuracy: 1.0000\n",
      "Epoch 15/30\n",
      "126/126 [==============================] - 7s 58ms/step - loss: 0.4654 - accuracy: 0.9967 - val_loss: 0.5618 - val_accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "126/126 [==============================] - 7s 58ms/step - loss: 0.4522 - accuracy: 0.9986 - val_loss: 0.5474 - val_accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "126/126 [==============================] - 7s 58ms/step - loss: 0.4417 - accuracy: 0.9980 - val_loss: 0.5348 - val_accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "126/126 [==============================] - 7s 58ms/step - loss: 0.4303 - accuracy: 0.9985 - val_loss: 0.5235 - val_accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "126/126 [==============================] - 7s 57ms/step - loss: 0.4191 - accuracy: 0.9977 - val_loss: 0.5134 - val_accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "126/126 [==============================] - 7s 57ms/step - loss: 0.4127 - accuracy: 0.9980 - val_loss: 0.5043 - val_accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "126/126 [==============================] - 7s 57ms/step - loss: 0.4009 - accuracy: 0.9986 - val_loss: 0.4962 - val_accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "126/126 [==============================] - 7s 57ms/step - loss: 0.3972 - accuracy: 0.9977 - val_loss: 0.4888 - val_accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "126/126 [==============================] - 7s 57ms/step - loss: 0.3900 - accuracy: 0.9975 - val_loss: 0.4823 - val_accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "126/126 [==============================] - 7s 57ms/step - loss: 0.3853 - accuracy: 0.9990 - val_loss: 0.4766 - val_accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "126/126 [==============================] - 7s 57ms/step - loss: 0.3816 - accuracy: 0.9984 - val_loss: 0.4713 - val_accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "126/126 [==============================] - 7s 58ms/step - loss: 0.3763 - accuracy: 0.9976 - val_loss: 0.4664 - val_accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "126/126 [==============================] - 7s 57ms/step - loss: 0.3707 - accuracy: 0.9985 - val_loss: 0.4622 - val_accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "126/126 [==============================] - 7s 58ms/step - loss: 0.3675 - accuracy: 0.9982 - val_loss: 0.4583 - val_accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "126/126 [==============================] - 7s 57ms/step - loss: 0.3638 - accuracy: 0.9980 - val_loss: 0.4549 - val_accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "126/126 [==============================] - 7s 58ms/step - loss: 0.3635 - accuracy: 0.9985 - val_loss: 0.4518 - val_accuracy: 1.0000\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_6261.3 images/assets\n",
      "Test acc for resnet: 0.995868\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training opticnet for 0.075% of train size (aka 6261 images)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/126 [>.............................] - ETA: 3:30 - loss: 5.4602 - accuracy: 0.1609WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.4673s vs `on_train_batch_end` time: 1.0272s). Check your callbacks.\n",
      "126/126 [==============================] - 163s 1s/step - loss: 1.0799 - accuracy: 0.7434 - val_loss: 0.0924 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "126/126 [==============================] - 145s 1s/step - loss: 0.1447 - accuracy: 0.9524 - val_loss: 0.0655 - val_accuracy: 1.0000\n",
      "Epoch 3/30\n",
      "126/126 [==============================] - 145s 1s/step - loss: 0.1178 - accuracy: 0.9602 - val_loss: 0.5802 - val_accuracy: 0.7812\n",
      "Epoch 4/30\n",
      "126/126 [==============================] - 146s 1s/step - loss: 0.0660 - accuracy: 0.9785 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
      "Epoch 5/30\n",
      "126/126 [==============================] - 148s 1s/step - loss: 0.0558 - accuracy: 0.9828 - val_loss: 0.2240 - val_accuracy: 0.9688\n",
      "Epoch 6/30\n",
      "126/126 [==============================] - 148s 1s/step - loss: 0.0682 - accuracy: 0.9751 - val_loss: 0.0077 - val_accuracy: 1.0000\n",
      "Epoch 7/30\n",
      "126/126 [==============================] - 148s 1s/step - loss: 0.0405 - accuracy: 0.9872 - val_loss: 0.0036 - val_accuracy: 1.0000\n",
      "Epoch 8/30\n",
      "126/126 [==============================] - 148s 1s/step - loss: 0.0095 - accuracy: 0.9960 - val_loss: 0.1812 - val_accuracy: 0.9375\n",
      "Epoch 9/30\n",
      "126/126 [==============================] - 148s 1s/step - loss: 0.0264 - accuracy: 0.9903 - val_loss: 7.5444e-04 - val_accuracy: 1.0000\n",
      "Epoch 10/30\n",
      "126/126 [==============================] - 148s 1s/step - loss: 0.0075 - accuracy: 0.9980 - val_loss: 6.8425e-05 - val_accuracy: 1.0000\n",
      "Epoch 11/30\n",
      "126/126 [==============================] - 145s 1s/step - loss: 0.0045 - accuracy: 0.9990 - val_loss: 3.9061e-05 - val_accuracy: 1.0000\n",
      "Epoch 12/30\n",
      "126/126 [==============================] - 145s 1s/step - loss: 0.0017 - accuracy: 0.9997 - val_loss: 2.2994e-04 - val_accuracy: 1.0000\n",
      "Epoch 13/30\n",
      "126/126 [==============================] - 148s 1s/step - loss: 0.0366 - accuracy: 0.9875 - val_loss: 3.9245e-04 - val_accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "126/126 [==============================] - 147s 1s/step - loss: 0.0060 - accuracy: 0.9979 - val_loss: 7.2242e-05 - val_accuracy: 1.0000\n",
      "Epoch 15/30\n",
      "126/126 [==============================] - 145s 1s/step - loss: 0.0011 - accuracy: 0.9999 - val_loss: 2.2604e-05 - val_accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "126/126 [==============================] - 147s 1s/step - loss: 0.0022 - accuracy: 0.9991 - val_loss: 1.8472e-05 - val_accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "126/126 [==============================] - 148s 1s/step - loss: 7.8714e-04 - accuracy: 0.9998 - val_loss: 7.1115e-06 - val_accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "126/126 [==============================] - 148s 1s/step - loss: 3.0435e-04 - accuracy: 0.9999 - val_loss: 5.1073e-06 - val_accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "126/126 [==============================] - 148s 1s/step - loss: 3.9319e-04 - accuracy: 1.0000 - val_loss: 2.9132e-06 - val_accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "126/126 [==============================] - 148s 1s/step - loss: 6.4870e-04 - accuracy: 0.9997 - val_loss: 2.7604e-06 - val_accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "126/126 [==============================] - 148s 1s/step - loss: 3.7667e-04 - accuracy: 0.9998 - val_loss: 2.4289e-06 - val_accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "126/126 [==============================] - 148s 1s/step - loss: 4.8822e-04 - accuracy: 0.9995 - val_loss: 2.0563e-06 - val_accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "126/126 [==============================] - 148s 1s/step - loss: 6.0161e-04 - accuracy: 0.9997 - val_loss: 2.4289e-06 - val_accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "126/126 [==============================] - 148s 1s/step - loss: 3.8160e-04 - accuracy: 0.9999 - val_loss: 2.0079e-06 - val_accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "126/126 [==============================] - 148s 1s/step - loss: 8.5473e-05 - accuracy: 1.0000 - val_loss: 1.7732e-06 - val_accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "126/126 [==============================] - 148s 1s/step - loss: 2.2631e-04 - accuracy: 0.9999 - val_loss: 1.7583e-06 - val_accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "126/126 [==============================] - 148s 1s/step - loss: 0.0010 - accuracy: 0.9997 - val_loss: 1.5274e-06 - val_accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "126/126 [==============================] - 148s 1s/step - loss: 2.3372e-04 - accuracy: 1.0000 - val_loss: 1.4380e-06 - val_accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "126/126 [==============================] - 148s 1s/step - loss: 1.0017e-04 - accuracy: 1.0000 - val_loss: 1.2703e-06 - val_accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "126/126 [==============================] - 148s 1s/step - loss: 1.3968e-04 - accuracy: 1.0000 - val_loss: 1.1623e-06 - val_accuracy: 1.0000\n",
      "INFO:tensorflow:Assets written to: ../opticnet/opticnet_30epochs_6261.3 images/assets\n",
      "Test acc for opticnet: 0.991736\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.09029071 0.09041795 0.08909059 0.08844011]\n",
      "Training xception for 0.09% of train size (aka 7513 images)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/151 [>.............................] - ETA: 1:17 - loss: 1.3661 - accuracy: 0.2531WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1177s vs `on_train_batch_begin` time: 0.1493s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1177s vs `on_train_batch_end` time: 0.1961s). Check your callbacks.\n",
      "151/151 [==============================] - 25s 144ms/step - loss: 1.3046 - accuracy: 0.8175 - val_loss: 1.1700 - val_accuracy: 0.9688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "151/151 [==============================] - 18s 122ms/step - loss: 1.0832 - accuracy: 0.9963 - val_loss: 1.0386 - val_accuracy: 0.9688\n",
      "Epoch 3/30\n",
      "151/151 [==============================] - 19s 123ms/step - loss: 0.9255 - accuracy: 0.9980 - val_loss: 0.9366 - val_accuracy: 0.9688\n",
      "Epoch 4/30\n",
      "151/151 [==============================] - 19s 124ms/step - loss: 0.8050 - accuracy: 0.9977 - val_loss: 0.8542 - val_accuracy: 0.9688\n",
      "Epoch 5/30\n",
      "151/151 [==============================] - 19s 124ms/step - loss: 0.7121 - accuracy: 0.9983 - val_loss: 0.7858 - val_accuracy: 0.9688\n",
      "Epoch 6/30\n",
      "151/151 [==============================] - 19s 124ms/step - loss: 0.6355 - accuracy: 0.9981 - val_loss: 0.7279 - val_accuracy: 0.9688\n",
      "Epoch 7/30\n",
      "151/151 [==============================] - 19s 124ms/step - loss: 0.5837 - accuracy: 0.9983 - val_loss: 0.6797 - val_accuracy: 0.9688\n",
      "Epoch 8/30\n",
      "151/151 [==============================] - 19s 124ms/step - loss: 0.5351 - accuracy: 0.9980 - val_loss: 0.6372 - val_accuracy: 0.9688\n",
      "Epoch 9/30\n",
      "151/151 [==============================] - 19s 123ms/step - loss: 0.4955 - accuracy: 0.9984 - val_loss: 0.6013 - val_accuracy: 0.9688\n",
      "Epoch 10/30\n",
      "151/151 [==============================] - 19s 124ms/step - loss: 0.4694 - accuracy: 0.9967 - val_loss: 0.5711 - val_accuracy: 0.9688\n",
      "Epoch 11/30\n",
      "151/151 [==============================] - 19s 124ms/step - loss: 0.4365 - accuracy: 0.9980 - val_loss: 0.5431 - val_accuracy: 0.9688\n",
      "Epoch 12/30\n",
      "151/151 [==============================] - 19s 124ms/step - loss: 0.4181 - accuracy: 0.9982 - val_loss: 0.5198 - val_accuracy: 0.9688\n",
      "Epoch 13/30\n",
      "151/151 [==============================] - 19s 124ms/step - loss: 0.3953 - accuracy: 0.9973 - val_loss: 0.5001 - val_accuracy: 0.9688\n",
      "Epoch 14/30\n",
      "151/151 [==============================] - 19s 124ms/step - loss: 0.3766 - accuracy: 0.9983 - val_loss: 0.4823 - val_accuracy: 0.9688\n",
      "Epoch 15/30\n",
      "151/151 [==============================] - 19s 124ms/step - loss: 0.3654 - accuracy: 0.9977 - val_loss: 0.4663 - val_accuracy: 0.9688\n",
      "Epoch 16/30\n",
      "151/151 [==============================] - 19s 124ms/step - loss: 0.3552 - accuracy: 0.9966 - val_loss: 0.4530 - val_accuracy: 0.9688\n",
      "Epoch 17/30\n",
      "151/151 [==============================] - 19s 124ms/step - loss: 0.3379 - accuracy: 0.9973 - val_loss: 0.4411 - val_accuracy: 0.9688\n",
      "Epoch 18/30\n",
      "151/151 [==============================] - 19s 124ms/step - loss: 0.3304 - accuracy: 0.9978 - val_loss: 0.4303 - val_accuracy: 0.9688\n",
      "Epoch 19/30\n",
      "151/151 [==============================] - 19s 124ms/step - loss: 0.3191 - accuracy: 0.9982 - val_loss: 0.4207 - val_accuracy: 0.9688\n",
      "Epoch 20/30\n",
      "151/151 [==============================] - 19s 123ms/step - loss: 0.3128 - accuracy: 0.9982 - val_loss: 0.4121 - val_accuracy: 0.9688\n",
      "Epoch 21/30\n",
      "151/151 [==============================] - 19s 124ms/step - loss: 0.3087 - accuracy: 0.9974 - val_loss: 0.4047 - val_accuracy: 0.9688\n",
      "Epoch 22/30\n",
      "151/151 [==============================] - 19s 124ms/step - loss: 0.3018 - accuracy: 0.9975 - val_loss: 0.3984 - val_accuracy: 0.9688\n",
      "Epoch 23/30\n",
      "151/151 [==============================] - 19s 124ms/step - loss: 0.2973 - accuracy: 0.9967 - val_loss: 0.3920 - val_accuracy: 0.9688\n",
      "Epoch 24/30\n",
      "151/151 [==============================] - 19s 124ms/step - loss: 0.2905 - accuracy: 0.9989 - val_loss: 0.3865 - val_accuracy: 0.9688\n",
      "Epoch 25/30\n",
      "151/151 [==============================] - 19s 124ms/step - loss: 0.2846 - accuracy: 0.9980 - val_loss: 0.3808 - val_accuracy: 0.9688\n",
      "Epoch 26/30\n",
      "151/151 [==============================] - 19s 124ms/step - loss: 0.2820 - accuracy: 0.9976 - val_loss: 0.3767 - val_accuracy: 0.9688\n",
      "Epoch 27/30\n",
      "151/151 [==============================] - 19s 123ms/step - loss: 0.2780 - accuracy: 0.9971 - val_loss: 0.3727 - val_accuracy: 0.9688\n",
      "Epoch 28/30\n",
      "151/151 [==============================] - 19s 123ms/step - loss: 0.2740 - accuracy: 0.9979 - val_loss: 0.3691 - val_accuracy: 0.9688\n",
      "Epoch 29/30\n",
      "151/151 [==============================] - 19s 124ms/step - loss: 0.2733 - accuracy: 0.9975 - val_loss: 0.3659 - val_accuracy: 0.9688\n",
      "Epoch 30/30\n",
      "151/151 [==============================] - 19s 124ms/step - loss: 0.2722 - accuracy: 0.9975 - val_loss: 0.3630 - val_accuracy: 0.9688\n",
      "INFO:tensorflow:Assets written to: ../xception/xception_30epochs_7513.5599999999995 images/assets\n",
      "Test acc for xception: 0.993802\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training resnet for 0.09% of train size (aka 7513 images)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/151 [>.............................] - ETA: 57s - loss: 1.4054 - accuracy: 0.0000e+00 WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0595s vs `on_train_batch_begin` time: 0.1264s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0595s vs `on_train_batch_end` time: 0.1529s). Check your callbacks.\n",
      "151/151 [==============================] - 15s 78ms/step - loss: 1.3484 - accuracy: 0.4301 - val_loss: 1.2442 - val_accuracy: 0.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "151/151 [==============================] - 9s 57ms/step - loss: 1.1303 - accuracy: 0.8107 - val_loss: 1.1052 - val_accuracy: 0.7500\n",
      "Epoch 3/30\n",
      "151/151 [==============================] - 9s 57ms/step - loss: 0.9651 - accuracy: 0.9008 - val_loss: 0.9943 - val_accuracy: 0.7500\n",
      "Epoch 4/30\n",
      "151/151 [==============================] - 9s 57ms/step - loss: 0.8459 - accuracy: 0.9510 - val_loss: 0.9037 - val_accuracy: 0.9688\n",
      "Epoch 5/30\n",
      "151/151 [==============================] - 9s 57ms/step - loss: 0.7489 - accuracy: 0.9973 - val_loss: 0.8284 - val_accuracy: 0.9688\n",
      "Epoch 6/30\n",
      "151/151 [==============================] - 9s 57ms/step - loss: 0.6801 - accuracy: 0.9972 - val_loss: 0.7661 - val_accuracy: 0.9688\n",
      "Epoch 7/30\n",
      "151/151 [==============================] - 9s 57ms/step - loss: 0.6183 - accuracy: 0.9969 - val_loss: 0.7124 - val_accuracy: 1.0000\n",
      "Epoch 8/30\n",
      "151/151 [==============================] - 9s 58ms/step - loss: 0.5691 - accuracy: 0.9978 - val_loss: 0.6684 - val_accuracy: 0.9688\n",
      "Epoch 9/30\n",
      "151/151 [==============================] - 9s 57ms/step - loss: 0.5347 - accuracy: 0.9975 - val_loss: 0.6283 - val_accuracy: 1.0000\n",
      "Epoch 10/30\n",
      "151/151 [==============================] - 9s 58ms/step - loss: 0.4968 - accuracy: 0.9981 - val_loss: 0.5945 - val_accuracy: 1.0000\n",
      "Epoch 11/30\n",
      "151/151 [==============================] - 9s 58ms/step - loss: 0.4633 - accuracy: 0.9973 - val_loss: 0.5644 - val_accuracy: 1.0000\n",
      "Epoch 12/30\n",
      "151/151 [==============================] - 9s 57ms/step - loss: 0.4447 - accuracy: 0.9968 - val_loss: 0.5397 - val_accuracy: 1.0000\n",
      "Epoch 13/30\n",
      "151/151 [==============================] - 9s 57ms/step - loss: 0.4271 - accuracy: 0.9969 - val_loss: 0.5173 - val_accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "151/151 [==============================] - 9s 58ms/step - loss: 0.4021 - accuracy: 0.9985 - val_loss: 0.4984 - val_accuracy: 1.0000\n",
      "Epoch 15/30\n",
      "151/151 [==============================] - 9s 57ms/step - loss: 0.3890 - accuracy: 0.9975 - val_loss: 0.4811 - val_accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "151/151 [==============================] - 9s 57ms/step - loss: 0.3746 - accuracy: 0.9975 - val_loss: 0.4662 - val_accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "151/151 [==============================] - 9s 57ms/step - loss: 0.3595 - accuracy: 0.9976 - val_loss: 0.4528 - val_accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "151/151 [==============================] - 9s 57ms/step - loss: 0.3502 - accuracy: 0.9982 - val_loss: 0.4410 - val_accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "151/151 [==============================] - 9s 57ms/step - loss: 0.3456 - accuracy: 0.9972 - val_loss: 0.4304 - val_accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "151/151 [==============================] - 9s 57ms/step - loss: 0.3348 - accuracy: 0.9972 - val_loss: 0.4209 - val_accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "151/151 [==============================] - 9s 57ms/step - loss: 0.3258 - accuracy: 0.9980 - val_loss: 0.4127 - val_accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "151/151 [==============================] - 9s 57ms/step - loss: 0.3187 - accuracy: 0.9982 - val_loss: 0.4051 - val_accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "151/151 [==============================] - 9s 57ms/step - loss: 0.3177 - accuracy: 0.9980 - val_loss: 0.3984 - val_accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "151/151 [==============================] - 9s 57ms/step - loss: 0.3094 - accuracy: 0.9983 - val_loss: 0.3924 - val_accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "151/151 [==============================] - 9s 57ms/step - loss: 0.3046 - accuracy: 0.9973 - val_loss: 0.3870 - val_accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "151/151 [==============================] - 9s 57ms/step - loss: 0.3021 - accuracy: 0.9980 - val_loss: 0.3821 - val_accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "151/151 [==============================] - 9s 57ms/step - loss: 0.2967 - accuracy: 0.9982 - val_loss: 0.3776 - val_accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "151/151 [==============================] - 9s 57ms/step - loss: 0.2947 - accuracy: 0.9984 - val_loss: 0.3737 - val_accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "151/151 [==============================] - 9s 57ms/step - loss: 0.2888 - accuracy: 0.9981 - val_loss: 0.3701 - val_accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "151/151 [==============================] - 9s 57ms/step - loss: 0.2843 - accuracy: 0.9987 - val_loss: 0.3671 - val_accuracy: 1.0000\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_7513.5599999999995 images/assets\n",
      "Test acc for resnet: 0.993802\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training opticnet for 0.09% of train size (aka 7513 images)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/151 [>.............................] - ETA: 4:16 - loss: 5.2201 - accuracy: 0.1781WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.4668s vs `on_train_batch_end` time: 1.0536s). Check your callbacks.\n",
      "151/151 [==============================] - 193s 1s/step - loss: 0.9546 - accuracy: 0.7633 - val_loss: 0.0754 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "151/151 [==============================] - 174s 1s/step - loss: 0.1452 - accuracy: 0.9540 - val_loss: 0.1540 - val_accuracy: 0.9688\n",
      "Epoch 3/30\n",
      "151/151 [==============================] - 174s 1s/step - loss: 0.1178 - accuracy: 0.9623 - val_loss: 0.1100 - val_accuracy: 1.0000\n",
      "Epoch 4/30\n",
      "151/151 [==============================] - 174s 1s/step - loss: 0.0746 - accuracy: 0.9777 - val_loss: 0.1368 - val_accuracy: 0.9375\n",
      "Epoch 5/30\n",
      "151/151 [==============================] - 177s 1s/step - loss: 0.0616 - accuracy: 0.9810 - val_loss: 0.0298 - val_accuracy: 1.0000\n",
      "Epoch 6/30\n",
      "151/151 [==============================] - 177s 1s/step - loss: 0.0441 - accuracy: 0.9866 - val_loss: 0.0517 - val_accuracy: 0.9688\n",
      "Epoch 7/30\n",
      "151/151 [==============================] - 177s 1s/step - loss: 0.0389 - accuracy: 0.9878 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
      "Epoch 8/30\n",
      "151/151 [==============================] - 174s 1s/step - loss: 0.0284 - accuracy: 0.9897 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
      "Epoch 9/30\n",
      "151/151 [==============================] - 174s 1s/step - loss: 0.0146 - accuracy: 0.9943 - val_loss: 0.0150 - val_accuracy: 1.0000\n",
      "Epoch 10/30\n",
      "151/151 [==============================] - 174s 1s/step - loss: 0.0103 - accuracy: 0.9973 - val_loss: 0.0057 - val_accuracy: 1.0000\n",
      "Epoch 11/30\n",
      "151/151 [==============================] - 177s 1s/step - loss: 0.0089 - accuracy: 0.9969 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
      "Epoch 12/30\n",
      "151/151 [==============================] - 175s 1s/step - loss: 0.0169 - accuracy: 0.9950 - val_loss: 5.7328e-04 - val_accuracy: 1.0000\n",
      "Epoch 13/30\n",
      "151/151 [==============================] - 175s 1s/step - loss: 0.0038 - accuracy: 0.9993 - val_loss: 0.0042 - val_accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "151/151 [==============================] - 176s 1s/step - loss: 0.0037 - accuracy: 0.9988 - val_loss: 0.0036 - val_accuracy: 1.0000\n",
      "Epoch 15/30\n",
      "151/151 [==============================] - 177s 1s/step - loss: 0.0049 - accuracy: 0.9984 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "151/151 [==============================] - 177s 1s/step - loss: 0.0012 - accuracy: 0.9996 - val_loss: 1.4978e-04 - val_accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "151/151 [==============================] - 177s 1s/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 1.2460e-04 - val_accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "151/151 [==============================] - 178s 1s/step - loss: 0.0023 - accuracy: 0.9995 - val_loss: 4.1754e-05 - val_accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "151/151 [==============================] - 178s 1s/step - loss: 0.0010 - accuracy: 0.9997 - val_loss: 1.2265e-04 - val_accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "151/151 [==============================] - 177s 1s/step - loss: 0.0012 - accuracy: 0.9994 - val_loss: 6.1696e-05 - val_accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "151/151 [==============================] - 176s 1s/step - loss: 0.0011 - accuracy: 0.9997 - val_loss: 6.4732e-05 - val_accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "151/151 [==============================] - 175s 1s/step - loss: 0.0015 - accuracy: 0.9991 - val_loss: 1.8532e-04 - val_accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "151/151 [==============================] - 174s 1s/step - loss: 0.0020 - accuracy: 0.9997 - val_loss: 8.5274e-05 - val_accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "151/151 [==============================] - 174s 1s/step - loss: 8.5431e-04 - accuracy: 0.9995 - val_loss: 8.3623e-05 - val_accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "151/151 [==============================] - 174s 1s/step - loss: 0.0010 - accuracy: 0.9993 - val_loss: 8.8612e-05 - val_accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "151/151 [==============================] - 177s 1s/step - loss: 6.5491e-04 - accuracy: 0.9997 - val_loss: 5.7671e-05 - val_accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "151/151 [==============================] - 177s 1s/step - loss: 5.2405e-04 - accuracy: 0.9997 - val_loss: 6.1274e-05 - val_accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "151/151 [==============================] - 177s 1s/step - loss: 4.8080e-04 - accuracy: 0.9999 - val_loss: 7.0711e-05 - val_accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "151/151 [==============================] - 176s 1s/step - loss: 0.0010 - accuracy: 0.9994 - val_loss: 4.9519e-05 - val_accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "151/151 [==============================] - 175s 1s/step - loss: 7.1594e-04 - accuracy: 0.9995 - val_loss: 6.0758e-05 - val_accuracy: 1.0000\n",
      "INFO:tensorflow:Assets written to: ../opticnet/opticnet_30epochs_7513.5599999999995 images/assets\n",
      "Test acc for opticnet: 0.992769\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import datetime\n",
    "\n",
    "maxTrain = len(y_train)\n",
    "#for p in [1.0]:\n",
    "#for p in [0.1, 0.25, 0.4, 0.5, 0.6, 0.75, 0.9]:\n",
    "for p in [0.01, 0.025, 0.05, 0.075, 0.09]:\n",
    "    #X_trn, X_tst, y_trn, y_tst\n",
    "    if p < 1:\n",
    "        X_t, _, y_t, _ = train_test_split(images, y_train, test_size=1-p, random_state=123)\n",
    "    else:\n",
    "        X_t = images; y_t = y_train;\n",
    "    print(f\"Labels fraction: {sum(y_t == 1) / sum(y_train == 1)}\")\n",
    "    for net in [\"xception\", \"resnet\", \"opticnet\"]:\n",
    "        print(f\"Training {net} for {p}% of train size (aka {len(X_t)} images)...\")\n",
    "        model, size = emptyModelGenerator(net, False)\n",
    "        X_trn = resizeIms(X_t, size)\n",
    "        X_val = resizeIms(x_val, size)\n",
    "        log_dir = f\"logs/{net}/fit/{p}trainSet_\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "        tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "        optim = Adam(learning_rate=0.001)\n",
    "        model.compile(optimizer=optim, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "        hist = model.fit(X_trn, y_t, epochs=epochs, validation_data = (X_val, y_validation), batch_size=batch_size,\n",
    "                    shuffle=True, max_queue_size=20,\n",
    "                    use_multiprocessing=True, workers=5, \n",
    "                    callbacks=[CustomCallback(fraction=0.9, model=net), tensorboard_callback])\n",
    "        model.save(f\"../{net}/{net}_{epochs}epochs_{p*maxTrain} images\")\n",
    "        testPredict(model, size, name=net)\n",
    "        del model\n",
    "        del X_trn\n",
    "        del X_val\n",
    "        print(\"Done!\\n\" + '-'*50, end='\\n\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
