{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "import os\n",
    "import cv2\n",
    "import pickle\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataPath = \"../../data/OCT/OCT2017/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of Classes Detected : 4\n"
     ]
    }
   ],
   "source": [
    "labels_available = os.listdir(os.path.join(dataPath, \"train\"))\n",
    "print(\"Total Number of Classes Detected :\",len(labels_available))\n",
    "\n",
    "labels_list = ['NORMAL',\"CNV\",\"DME\",\"DRUSEN\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NORMAL CNV DME DRUSEN "
     ]
    }
   ],
   "source": [
    "images=[]\n",
    "y_trn=[]\n",
    "for x in labels_list:\n",
    "    xPath = os.path.join(dataPath, \"train\", x)\n",
    "    myPicList = os.listdir(xPath)\n",
    "    for y in myPicList:\n",
    "        images.append(cv2.imread(os.path.join(xPath, y)))\n",
    "        y_trn.append(labels_list.index(x))\n",
    "    print(x ,end=\" \")\n",
    "\n",
    "y_train = to_categorical(y_trn,len(labels_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NORMAL CNV DME DRUSEN "
     ]
    }
   ],
   "source": [
    "x_val=[]\n",
    "y_val=[]\n",
    "for x in labels_list:\n",
    "    xPath = os.path.join(dataPath, \"val\", x)\n",
    "    myPicList = os.listdir(xPath)\n",
    "    for y in myPicList:\n",
    "        x_val.append(cv2.imread(os.path.join(xPath, y)))\n",
    "        y_val.append(labels_list.index(x))\n",
    "    print(x ,end=\" \")\n",
    "\n",
    "y_validation = to_categorical(y_val,len(labels_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NORMAL CNV DME DRUSEN "
     ]
    }
   ],
   "source": [
    "x_tst=[]\n",
    "y_tst=[]\n",
    "for x in labels_list:\n",
    "    xPath = os.path.join(dataPath, \"test\", x)\n",
    "    myPicList = os.listdir(xPath)\n",
    "    for y in myPicList:\n",
    "        x_tst.append(cv2.imread(os.path.join(xPath, y)))\n",
    "        y_tst.append(labels_list.index(x))\n",
    "    print(x ,end=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resizeIm(im, size):\n",
    "    if im.shape[2] == 1:\n",
    "        im = cv2.cvtColor(im,cv2.COLOR_GRAY2RGB)\n",
    "    return cv2.resize(im, size)\n",
    "\n",
    "def resizeIms(x, size):\n",
    "    return np.array(list(map(lambda im: resizeIm(im, size), x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self,fraction, model):\n",
    "        super(CustomCallback,self).__init__()\n",
    "        self.fraction = fraction\n",
    "        self.train_a = [];\n",
    "        self.val_a =[];\n",
    "        self.logPath = os.path.join(model, \"log.txt\")\n",
    "\n",
    "        if not os.path.isdir(model):\n",
    "            os.mkdir(model)\n",
    "\n",
    "        with open(self.logPath,'w') as f:\n",
    "            f.write('Starting of logging..\\n')\n",
    "\n",
    "        self.fig = plt.figure(figsize=(4,3))\n",
    "        self.ax = plt.subplot(1,1,1)\n",
    "        plt.ion()\n",
    "\n",
    "    def on_train_begin(self,logs=None):\n",
    "        self.fig.show()\n",
    "        self.fig.canvas.draw()\n",
    "\n",
    "    def on_train_end(self,logs=None):\n",
    "        with open(self.logPath,'a') as f:\n",
    "              f.write('End of logging..\\n')\n",
    "    \n",
    "    def on_epoch_begin(self,epoch,logs=None):\n",
    "        lr= tf.keras.backend.get_value(self.model.optimizer.lr)\n",
    "        lr *= self.fraction\n",
    "        tf.keras.backend.set_value(self.model.optimizer.lr,lr)\n",
    "        with open(self.logPath,'a') as f:\n",
    "            f.write('At epoch {:02d}, learning rate changed to {:.4f}\\n'.format(epoch,lr))\n",
    "    \n",
    "    def on_epoch_end(self,epoch,logs=None):\n",
    "        val_acc = logs.get('val_accuracy')\n",
    "        train_acc = logs.get('accuracy')\n",
    "        self.train_a.append(train_acc)\n",
    "        self.val_a.append(val_acc)\n",
    "        with open(self.logPath,'a') as f:\n",
    "            f.write('At epoch {:02d}, training accuracy: {:.3f}, validation accuracy: {:.3f}\\n'.format(epoch,train_acc,val_acc))\n",
    "        self.ax.clear()\n",
    "        self.ax.plot(range(1+epoch),self.train_a,label=\"Training\")\n",
    "        self.ax.plot(range(1+epoch),self.val_a,label=\"Validation\")\n",
    "        self.ax.set_xlabel('Epochs')\n",
    "        self.ax.set_ylabel('Accuracy')\n",
    "        self.ax.legend()\n",
    "        self.fig.canvas.draw()\n",
    "        self.fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xception base model\n",
    "from tensorflow.keras.applications.xception import Xception\n",
    "from tensorflow.keras.applications.xception import preprocess_input, decode_predictions\n",
    "xceptionNetModel = Xception(weights='imagenet')\n",
    "\n",
    "# opticnet base model\n",
    "opticNetModel = tf.keras.models.load_model('../Optic_net-4_classes-Kermany2018.hdf5')\n",
    "\n",
    "# resnet base model\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "\n",
    "resNetModel = ResNet50(weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emptyModelGenerator(model, newWeights=False, lastOnly=False):\n",
    "    model = model.lower()\n",
    "    if model == \"resnet\":\n",
    "        x = resNetModel.output\n",
    "        predictions = Dense(len(labels_list), activation='softmax')(x)\n",
    "        newModel = Model(inputs=resNetModel.input, outputs=predictions)\n",
    "        size = (224, 224)\n",
    "    elif model == \"xception\":\n",
    "        x = xceptionNetModel.output\n",
    "        predictions = Dense(len(labels_list), activation='softmax')(x)\n",
    "        newModel = Model(inputs=xceptionNetModel.input, outputs=predictions)\n",
    "        size = (299, 299)\n",
    "    elif model == \"opticnet\":\n",
    "        newModel = tf.keras.models.load_model('../Optic_net-4_classes-Kermany2018.hdf5')\n",
    "        size = (224, 224)\n",
    "    if newWeights:\n",
    "        newModel = tf.keras.models.clone_model(newModel)\n",
    "    if lastOnly:\n",
    "        newModel = lastDenseTrainable(newModel) # block all layer except the last dense ones\n",
    "    return newModel, size\n",
    "\n",
    "\n",
    "def lastDenseTrainable(model):\n",
    "    model.trainable = False\n",
    "    for i in range(1, len(model.layers)):\n",
    "        if model.layers[-i].__class__.__name__ == \"Dense\":\n",
    "            model.layers[-i].trainable= True\n",
    "        elif model.layers[-i].__class__.__name__ == \"Activation\":\n",
    "            continue\n",
    "        else:\n",
    "            break\n",
    "    return model\n",
    "    \n",
    "\n",
    "def testPredict(model, size, name=None):\n",
    "    X_test = resizeIms(x_tst, size)\n",
    "    X_test = np.array(X_test)\n",
    "    Y_test = np.array(y_tst)\n",
    "    \n",
    "    prediction = model.predict(X_test)\n",
    "    preds = np.argmax(prediction, axis=1)\n",
    "    acc = sum(preds == Y_test) / len(Y_test)\n",
    "    print(f'Test acc for {name if name else \"model\"}: {acc:.6f}')\n",
    "    \n",
    "\n",
    "def computeConfussionMatrix(predictions, labels):\n",
    "    num_labels = len(labels_list)\n",
    "    cMatrix = np.zeros(shape=(num_labels, num_labels))\n",
    "    for i in len(predictions):\n",
    "        p = int(predictions[i])\n",
    "        t = int(predictions[i])\n",
    "        cMatrix[t, p] += 1\n",
    "    print(cMatrix)\n",
    "    ax = sns.heatmap(cMatrix, cmap=\"Blues\", annot=True, fmt=\"d\", xticklabels=labels_list, yticklabels=labels_list)\n",
    "    plt.xlabel(\"Predicted label\")\n",
    "    plt.ylabel(\"True label\")\n",
    "    plt.title(\"Confusion matrix\")\n",
    "    plt.show();\n",
    "    return cMatrix\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "models = [\"xception\", \"resnet\", \"opticnet\"]\n",
    "\n",
    "for mod in models:\n",
    "    print(\"\\n\\n\" + (\"*\"*50) + \"\\nModel: \" + mod + '\\n' + (\"*\"*50))\n",
    "    m = emptyModelGenerator(mod, newWeights=False, lastOnly=True)[0]\n",
    "    #m.trainable = False\n",
    "    a = 0\n",
    "    for l in m.layers:\n",
    "        #l.trainable = True\n",
    "        if l.trainable:\n",
    "            print(l.name, l.trainable)\n",
    "            a += 1\n",
    "            #print(l.trainable_weights)\n",
    "    print(f\"\\nTotal: {len(m.layers)} trainable: {a}\")\n",
    "    print(m.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "optim = Adam(learning_rate=0.001)\n",
    "epochs = 30\n",
    "batch_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels fraction: [0.04905947 0.05004704 0.05049348 0.05199629]\n",
      "Training xception for 0.05% of train size (aka 4174 images)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      " 6/84 [=>............................] - ETA: 40s - loss: 1.3897 - accuracy: 0.2315WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1199s vs `on_train_batch_begin` time: 0.2025s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1199s vs `on_train_batch_end` time: 0.1294s). Check your callbacks.\n",
      "84/84 [==============================] - 16s 157ms/step - loss: 1.3881 - accuracy: 0.2693 - val_loss: 1.3860 - val_accuracy: 0.2188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "84/84 [==============================] - 10s 120ms/step - loss: 1.3873 - accuracy: 0.2835 - val_loss: 1.3860 - val_accuracy: 0.2188\n",
      "Epoch 3/30\n",
      "84/84 [==============================] - 10s 121ms/step - loss: 1.3887 - accuracy: 0.2573 - val_loss: 1.3860 - val_accuracy: 0.2188\n",
      "Epoch 4/30\n",
      "84/84 [==============================] - 10s 121ms/step - loss: 1.3876 - accuracy: 0.2740 - val_loss: 1.3860 - val_accuracy: 0.2188\n",
      "Epoch 5/30\n",
      "84/84 [==============================] - 10s 122ms/step - loss: 1.3875 - accuracy: 0.2794 - val_loss: 1.3860 - val_accuracy: 0.2188\n",
      "Epoch 6/30\n",
      "84/84 [==============================] - 10s 122ms/step - loss: 1.3884 - accuracy: 0.2684 - val_loss: 1.3860 - val_accuracy: 0.2188\n",
      "Epoch 7/30\n",
      "84/84 [==============================] - 10s 123ms/step - loss: 1.3880 - accuracy: 0.2736 - val_loss: 1.3860 - val_accuracy: 0.2188\n",
      "Epoch 8/30\n",
      "84/84 [==============================] - 10s 123ms/step - loss: 1.3875 - accuracy: 0.2737 - val_loss: 1.3860 - val_accuracy: 0.2188\n",
      "Epoch 9/30\n",
      "84/84 [==============================] - 10s 123ms/step - loss: 1.3878 - accuracy: 0.2747 - val_loss: 1.3860 - val_accuracy: 0.2188\n",
      "Epoch 10/30\n",
      "84/84 [==============================] - 10s 123ms/step - loss: 1.3875 - accuracy: 0.2766 - val_loss: 1.3860 - val_accuracy: 0.2188\n",
      "Epoch 11/30\n",
      "84/84 [==============================] - 10s 123ms/step - loss: 1.3883 - accuracy: 0.2655 - val_loss: 1.3860 - val_accuracy: 0.2188\n",
      "Epoch 12/30\n",
      "84/84 [==============================] - 10s 123ms/step - loss: 1.3878 - accuracy: 0.2774 - val_loss: 1.3860 - val_accuracy: 0.2188\n",
      "Epoch 13/30\n",
      "84/84 [==============================] - 10s 123ms/step - loss: 1.3881 - accuracy: 0.2668 - val_loss: 1.3860 - val_accuracy: 0.2188\n",
      "Epoch 14/30\n",
      "84/84 [==============================] - 10s 123ms/step - loss: 1.3877 - accuracy: 0.2722 - val_loss: 1.3860 - val_accuracy: 0.2188\n",
      "Epoch 15/30\n",
      "84/84 [==============================] - 10s 123ms/step - loss: 1.3872 - accuracy: 0.2854 - val_loss: 1.3860 - val_accuracy: 0.2188\n",
      "Epoch 16/30\n",
      "84/84 [==============================] - 10s 123ms/step - loss: 1.3878 - accuracy: 0.2715 - val_loss: 1.3860 - val_accuracy: 0.2188\n",
      "Epoch 17/30\n",
      "84/84 [==============================] - 10s 123ms/step - loss: 1.3883 - accuracy: 0.2606 - val_loss: 1.3860 - val_accuracy: 0.2188\n",
      "Epoch 18/30\n",
      "84/84 [==============================] - 10s 123ms/step - loss: 1.3875 - accuracy: 0.2783 - val_loss: 1.3860 - val_accuracy: 0.2188\n",
      "Epoch 19/30\n",
      "84/84 [==============================] - 10s 123ms/step - loss: 1.3877 - accuracy: 0.2779 - val_loss: 1.3860 - val_accuracy: 0.2188\n",
      "Epoch 20/30\n",
      "84/84 [==============================] - 10s 123ms/step - loss: 1.3877 - accuracy: 0.2742 - val_loss: 1.3860 - val_accuracy: 0.2188\n",
      "Epoch 21/30\n",
      "84/84 [==============================] - 10s 123ms/step - loss: 1.3881 - accuracy: 0.2684 - val_loss: 1.3860 - val_accuracy: 0.2188\n",
      "Epoch 22/30\n",
      "84/84 [==============================] - 10s 123ms/step - loss: 1.3876 - accuracy: 0.2777 - val_loss: 1.3860 - val_accuracy: 0.2188\n",
      "Epoch 23/30\n",
      "84/84 [==============================] - 10s 124ms/step - loss: 1.3877 - accuracy: 0.2716 - val_loss: 1.3860 - val_accuracy: 0.2188\n",
      "Epoch 24/30\n",
      "84/84 [==============================] - 10s 123ms/step - loss: 1.3881 - accuracy: 0.2669 - val_loss: 1.3860 - val_accuracy: 0.2188\n",
      "Epoch 25/30\n",
      "84/84 [==============================] - 10s 124ms/step - loss: 1.3876 - accuracy: 0.2723 - val_loss: 1.3860 - val_accuracy: 0.2188\n",
      "Epoch 26/30\n",
      "84/84 [==============================] - 10s 123ms/step - loss: 1.3877 - accuracy: 0.2752 - val_loss: 1.3860 - val_accuracy: 0.2188\n",
      "Epoch 27/30\n",
      "84/84 [==============================] - 10s 124ms/step - loss: 1.3878 - accuracy: 0.2760 - val_loss: 1.3860 - val_accuracy: 0.2188\n",
      "Epoch 28/30\n",
      "84/84 [==============================] - 10s 123ms/step - loss: 1.3879 - accuracy: 0.2727 - val_loss: 1.3860 - val_accuracy: 0.2188\n",
      "Epoch 29/30\n",
      "84/84 [==============================] - 10s 123ms/step - loss: 1.3877 - accuracy: 0.2741 - val_loss: 1.3860 - val_accuracy: 0.2188\n",
      "Epoch 30/30\n",
      "84/84 [==============================] - 10s 123ms/step - loss: 1.3874 - accuracy: 0.2780 - val_loss: 1.3860 - val_accuracy: 0.2188\n",
      "INFO:tensorflow:Assets written to: ../xception/xception_30epochs_4174.2_images_False_newWeights_True_lastLayerOnly/assets\n",
      "Test acc for xception: 0.241736\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training resnet for 0.05% of train size (aka 4174 images)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      " 6/84 [=>............................] - ETA: 38s - loss: 1.3819 - accuracy: 0.3302WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0599s vs `on_train_batch_begin` time: 0.1994s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0599s vs `on_train_batch_end` time: 0.1646s). Check your callbacks.\n",
      "84/84 [==============================] - 12s 101ms/step - loss: 1.3803 - accuracy: 0.3531 - val_loss: 1.3903 - val_accuracy: 0.1250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "84/84 [==============================] - 5s 58ms/step - loss: 1.3799 - accuracy: 0.3417 - val_loss: 1.3903 - val_accuracy: 0.1250\n",
      "Epoch 3/30\n",
      "84/84 [==============================] - 5s 58ms/step - loss: 1.3809 - accuracy: 0.3354 - val_loss: 1.3903 - val_accuracy: 0.1250\n",
      "Epoch 4/30\n",
      "84/84 [==============================] - 5s 58ms/step - loss: 1.3802 - accuracy: 0.3503 - val_loss: 1.3903 - val_accuracy: 0.1250\n",
      "Epoch 5/30\n",
      "84/84 [==============================] - 5s 58ms/step - loss: 1.3796 - accuracy: 0.3632 - val_loss: 1.3903 - val_accuracy: 0.1250\n",
      "Epoch 6/30\n",
      "84/84 [==============================] - 5s 58ms/step - loss: 1.3805 - accuracy: 0.3506 - val_loss: 1.3903 - val_accuracy: 0.1250\n",
      "Epoch 7/30\n",
      "84/84 [==============================] - 5s 58ms/step - loss: 1.3799 - accuracy: 0.3644 - val_loss: 1.3903 - val_accuracy: 0.1250\n",
      "Epoch 8/30\n",
      "84/84 [==============================] - 5s 58ms/step - loss: 1.3801 - accuracy: 0.3592 - val_loss: 1.3903 - val_accuracy: 0.1250\n",
      "Epoch 9/30\n",
      "84/84 [==============================] - 5s 58ms/step - loss: 1.3801 - accuracy: 0.3513 - val_loss: 1.3903 - val_accuracy: 0.1250\n",
      "Epoch 10/30\n",
      "84/84 [==============================] - 5s 58ms/step - loss: 1.3801 - accuracy: 0.3552 - val_loss: 1.3903 - val_accuracy: 0.1250\n",
      "Epoch 11/30\n",
      "84/84 [==============================] - 5s 58ms/step - loss: 1.3801 - accuracy: 0.3553 - val_loss: 1.3903 - val_accuracy: 0.1250\n",
      "Epoch 12/30\n",
      "84/84 [==============================] - 5s 58ms/step - loss: 1.3798 - accuracy: 0.3601 - val_loss: 1.3903 - val_accuracy: 0.1250\n",
      "Epoch 13/30\n",
      "84/84 [==============================] - 5s 58ms/step - loss: 1.3803 - accuracy: 0.3490 - val_loss: 1.3903 - val_accuracy: 0.1250\n",
      "Epoch 14/30\n",
      "84/84 [==============================] - 5s 58ms/step - loss: 1.3800 - accuracy: 0.3633 - val_loss: 1.3903 - val_accuracy: 0.1250\n",
      "Epoch 15/30\n",
      "84/84 [==============================] - 5s 58ms/step - loss: 1.3802 - accuracy: 0.3427 - val_loss: 1.3903 - val_accuracy: 0.1250\n",
      "Epoch 16/30\n",
      "84/84 [==============================] - 5s 58ms/step - loss: 1.3801 - accuracy: 0.3522 - val_loss: 1.3903 - val_accuracy: 0.1250\n",
      "Epoch 17/30\n",
      "84/84 [==============================] - 5s 58ms/step - loss: 1.3800 - accuracy: 0.3583 - val_loss: 1.3903 - val_accuracy: 0.1250\n",
      "Epoch 18/30\n",
      "84/84 [==============================] - 5s 58ms/step - loss: 1.3807 - accuracy: 0.3435 - val_loss: 1.3903 - val_accuracy: 0.1250\n",
      "Epoch 19/30\n",
      "84/84 [==============================] - 5s 58ms/step - loss: 1.3804 - accuracy: 0.3552 - val_loss: 1.3903 - val_accuracy: 0.1250\n",
      "Epoch 20/30\n",
      "84/84 [==============================] - 5s 58ms/step - loss: 1.3803 - accuracy: 0.3527 - val_loss: 1.3903 - val_accuracy: 0.1250\n",
      "Epoch 21/30\n",
      "84/84 [==============================] - 5s 58ms/step - loss: 1.3802 - accuracy: 0.3461 - val_loss: 1.3903 - val_accuracy: 0.1250\n",
      "Epoch 22/30\n",
      "84/84 [==============================] - 5s 58ms/step - loss: 1.3805 - accuracy: 0.3485 - val_loss: 1.3903 - val_accuracy: 0.1250\n",
      "Epoch 23/30\n",
      "84/84 [==============================] - 5s 58ms/step - loss: 1.3801 - accuracy: 0.3569 - val_loss: 1.3903 - val_accuracy: 0.1250\n",
      "Epoch 24/30\n",
      "84/84 [==============================] - 5s 58ms/step - loss: 1.3798 - accuracy: 0.3653 - val_loss: 1.3903 - val_accuracy: 0.1250\n",
      "Epoch 25/30\n",
      "84/84 [==============================] - 5s 58ms/step - loss: 1.3809 - accuracy: 0.3415 - val_loss: 1.3903 - val_accuracy: 0.1250\n",
      "Epoch 26/30\n",
      "84/84 [==============================] - 5s 58ms/step - loss: 1.3803 - accuracy: 0.3472 - val_loss: 1.3903 - val_accuracy: 0.1250\n",
      "Epoch 27/30\n",
      "84/84 [==============================] - 5s 58ms/step - loss: 1.3803 - accuracy: 0.3476 - val_loss: 1.3903 - val_accuracy: 0.1250\n",
      "Epoch 28/30\n",
      "84/84 [==============================] - 5s 58ms/step - loss: 1.3798 - accuracy: 0.3550 - val_loss: 1.3903 - val_accuracy: 0.1250\n",
      "Epoch 29/30\n",
      "84/84 [==============================] - 5s 58ms/step - loss: 1.3804 - accuracy: 0.3502 - val_loss: 1.3903 - val_accuracy: 0.1250\n",
      "Epoch 30/30\n",
      "84/84 [==============================] - 5s 58ms/step - loss: 1.3801 - accuracy: 0.3436 - val_loss: 1.3903 - val_accuracy: 0.1250\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_4174.2_images_False_newWeights_True_lastLayerOnly/assets\n",
      "Test acc for resnet: 0.271694\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training opticnet for 0.05% of train size (aka 4174 images)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "84/84 [==============================] - 35s 346ms/step - loss: 287.4536 - accuracy: 0.1314 - val_loss: 217.3077 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "84/84 [==============================] - 24s 287ms/step - loss: 290.4877 - accuracy: 0.1310 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "84/84 [==============================] - 24s 288ms/step - loss: 284.3105 - accuracy: 0.1474 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "84/84 [==============================] - 24s 288ms/step - loss: 287.5139 - accuracy: 0.1389 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "84/84 [==============================] - 24s 288ms/step - loss: 278.9944 - accuracy: 0.1452 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "84/84 [==============================] - 24s 288ms/step - loss: 292.9185 - accuracy: 0.1289 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "84/84 [==============================] - 24s 288ms/step - loss: 287.7464 - accuracy: 0.1378 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "84/84 [==============================] - 24s 288ms/step - loss: 285.6307 - accuracy: 0.1476 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "84/84 [==============================] - 24s 288ms/step - loss: 294.2682 - accuracy: 0.1302 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "84/84 [==============================] - 24s 288ms/step - loss: 291.8895 - accuracy: 0.1306 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "84/84 [==============================] - 24s 288ms/step - loss: 287.0962 - accuracy: 0.1324 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "84/84 [==============================] - 24s 289ms/step - loss: 291.8174 - accuracy: 0.1371 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "84/84 [==============================] - 24s 289ms/step - loss: 288.1400 - accuracy: 0.1444 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "84/84 [==============================] - 24s 288ms/step - loss: 288.4815 - accuracy: 0.1393 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "84/84 [==============================] - 24s 288ms/step - loss: 291.4075 - accuracy: 0.1289 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "84/84 [==============================] - 24s 288ms/step - loss: 287.3299 - accuracy: 0.1384 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "84/84 [==============================] - 24s 288ms/step - loss: 290.8428 - accuracy: 0.1395 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "84/84 [==============================] - 24s 288ms/step - loss: 286.6274 - accuracy: 0.1336 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "84/84 [==============================] - 24s 288ms/step - loss: 291.4396 - accuracy: 0.1338 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "84/84 [==============================] - 24s 288ms/step - loss: 292.5585 - accuracy: 0.1365 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "84/84 [==============================] - 24s 288ms/step - loss: 289.5166 - accuracy: 0.1386 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "84/84 [==============================] - 24s 288ms/step - loss: 292.0957 - accuracy: 0.1362 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "84/84 [==============================] - 24s 288ms/step - loss: 292.3435 - accuracy: 0.1310 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "84/84 [==============================] - 24s 288ms/step - loss: 290.8023 - accuracy: 0.1332 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "84/84 [==============================] - 24s 288ms/step - loss: 289.1524 - accuracy: 0.1391 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "84/84 [==============================] - 24s 288ms/step - loss: 288.6044 - accuracy: 0.1425 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "84/84 [==============================] - 24s 289ms/step - loss: 289.7780 - accuracy: 0.1323 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "84/84 [==============================] - 24s 288ms/step - loss: 295.4792 - accuracy: 0.1314 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "84/84 [==============================] - 24s 288ms/step - loss: 287.1249 - accuracy: 0.1318 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "84/84 [==============================] - 24s 288ms/step - loss: 288.7119 - accuracy: 0.1378 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../opticnet/opticnet_30epochs_4174.2_images_False_newWeights_True_lastLayerOnly/assets\n",
      "Test acc for opticnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.07474824 0.07533934 0.07472682 0.0746286 ]\n",
      "Training xception for 0.075% of train size (aka 6261 images)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/126 [>.............................] - ETA: 1:11 - loss: 1.3951 - accuracy: 0.1604WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1170s vs `on_train_batch_begin` time: 0.1953s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1170s vs `on_train_batch_end` time: 0.2035s). Check your callbacks.\n",
      "126/126 [==============================] - 22s 149ms/step - loss: 1.3943 - accuracy: 0.1434 - val_loss: 1.3844 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "126/126 [==============================] - 15s 121ms/step - loss: 1.3943 - accuracy: 0.1463 - val_loss: 1.3844 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "126/126 [==============================] - 15s 122ms/step - loss: 1.3946 - accuracy: 0.1457 - val_loss: 1.3844 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "126/126 [==============================] - 15s 122ms/step - loss: 1.3943 - accuracy: 0.1466 - val_loss: 1.3844 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "126/126 [==============================] - 15s 123ms/step - loss: 1.3939 - accuracy: 0.1429 - val_loss: 1.3844 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "126/126 [==============================] - 15s 123ms/step - loss: 1.3945 - accuracy: 0.1404 - val_loss: 1.3844 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "126/126 [==============================] - 15s 123ms/step - loss: 1.3944 - accuracy: 0.1493 - val_loss: 1.3844 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "126/126 [==============================] - 15s 123ms/step - loss: 1.3949 - accuracy: 0.1417 - val_loss: 1.3844 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "126/126 [==============================] - 15s 123ms/step - loss: 1.3948 - accuracy: 0.1409 - val_loss: 1.3844 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "126/126 [==============================] - 15s 123ms/step - loss: 1.3942 - accuracy: 0.1489 - val_loss: 1.3844 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "126/126 [==============================] - 15s 123ms/step - loss: 1.3945 - accuracy: 0.1412 - val_loss: 1.3844 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "126/126 [==============================] - 15s 123ms/step - loss: 1.3948 - accuracy: 0.1401 - val_loss: 1.3844 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "126/126 [==============================] - 16s 123ms/step - loss: 1.3942 - accuracy: 0.1417 - val_loss: 1.3844 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "126/126 [==============================] - 15s 123ms/step - loss: 1.3945 - accuracy: 0.1443 - val_loss: 1.3844 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "126/126 [==============================] - 16s 123ms/step - loss: 1.3942 - accuracy: 0.1501 - val_loss: 1.3844 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "126/126 [==============================] - 16s 123ms/step - loss: 1.3944 - accuracy: 0.1399 - val_loss: 1.3844 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "126/126 [==============================] - 15s 123ms/step - loss: 1.3947 - accuracy: 0.1474 - val_loss: 1.3844 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "126/126 [==============================] - 16s 123ms/step - loss: 1.3946 - accuracy: 0.1413 - val_loss: 1.3844 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "126/126 [==============================] - 15s 123ms/step - loss: 1.3942 - accuracy: 0.1491 - val_loss: 1.3844 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "126/126 [==============================] - 16s 123ms/step - loss: 1.3943 - accuracy: 0.1474 - val_loss: 1.3844 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "126/126 [==============================] - 16s 123ms/step - loss: 1.3946 - accuracy: 0.1481 - val_loss: 1.3844 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "126/126 [==============================] - 15s 123ms/step - loss: 1.3945 - accuracy: 0.1454 - val_loss: 1.3844 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "126/126 [==============================] - 15s 123ms/step - loss: 1.3944 - accuracy: 0.1433 - val_loss: 1.3844 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "126/126 [==============================] - 15s 123ms/step - loss: 1.3944 - accuracy: 0.1404 - val_loss: 1.3844 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "126/126 [==============================] - 15s 123ms/step - loss: 1.3948 - accuracy: 0.1429 - val_loss: 1.3844 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "126/126 [==============================] - 15s 123ms/step - loss: 1.3951 - accuracy: 0.1390 - val_loss: 1.3844 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "126/126 [==============================] - 15s 123ms/step - loss: 1.3948 - accuracy: 0.1446 - val_loss: 1.3844 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "126/126 [==============================] - 15s 123ms/step - loss: 1.3940 - accuracy: 0.1456 - val_loss: 1.3844 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "126/126 [==============================] - 15s 123ms/step - loss: 1.3948 - accuracy: 0.1371 - val_loss: 1.3844 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "126/126 [==============================] - 16s 123ms/step - loss: 1.3941 - accuracy: 0.1454 - val_loss: 1.3844 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../xception/xception_30epochs_6261.3_images_False_newWeights_True_lastLayerOnly/assets\n",
      "Test acc for xception: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training resnet for 0.075% of train size (aka 6261 images)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/126 [>.............................] - ETA: 1:00 - loss: 1.3847 - accuracy: 0.3121WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0604s vs `on_train_batch_begin` time: 0.1984s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0604s vs `on_train_batch_end` time: 0.1685s). Check your callbacks.\n",
      "126/126 [==============================] - 14s 87ms/step - loss: 1.3824 - accuracy: 0.3659 - val_loss: 1.3860 - val_accuracy: 0.3125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "126/126 [==============================] - 7s 57ms/step - loss: 1.3819 - accuracy: 0.3762 - val_loss: 1.3860 - val_accuracy: 0.3125\n",
      "Epoch 3/30\n",
      "126/126 [==============================] - 7s 57ms/step - loss: 1.3815 - accuracy: 0.3738 - val_loss: 1.3860 - val_accuracy: 0.3125\n",
      "Epoch 4/30\n",
      "126/126 [==============================] - 7s 57ms/step - loss: 1.3819 - accuracy: 0.3738 - val_loss: 1.3860 - val_accuracy: 0.3125\n",
      "Epoch 5/30\n",
      "126/126 [==============================] - 7s 57ms/step - loss: 1.3825 - accuracy: 0.3620 - val_loss: 1.3860 - val_accuracy: 0.3125\n",
      "Epoch 6/30\n",
      "126/126 [==============================] - 7s 58ms/step - loss: 1.3820 - accuracy: 0.3644 - val_loss: 1.3860 - val_accuracy: 0.3125\n",
      "Epoch 7/30\n",
      "126/126 [==============================] - 7s 58ms/step - loss: 1.3817 - accuracy: 0.3738 - val_loss: 1.3860 - val_accuracy: 0.3125\n",
      "Epoch 8/30\n",
      "126/126 [==============================] - 7s 58ms/step - loss: 1.3818 - accuracy: 0.3695 - val_loss: 1.3860 - val_accuracy: 0.3125\n",
      "Epoch 9/30\n",
      "126/126 [==============================] - 7s 57ms/step - loss: 1.3821 - accuracy: 0.3699 - val_loss: 1.3860 - val_accuracy: 0.3125\n",
      "Epoch 10/30\n",
      "126/126 [==============================] - 7s 57ms/step - loss: 1.3819 - accuracy: 0.3690 - val_loss: 1.3860 - val_accuracy: 0.3125\n",
      "Epoch 11/30\n",
      "126/126 [==============================] - 7s 58ms/step - loss: 1.3821 - accuracy: 0.3745 - val_loss: 1.3860 - val_accuracy: 0.3125\n",
      "Epoch 12/30\n",
      "126/126 [==============================] - 7s 57ms/step - loss: 1.3820 - accuracy: 0.3674 - val_loss: 1.3860 - val_accuracy: 0.3125\n",
      "Epoch 13/30\n",
      "126/126 [==============================] - 7s 58ms/step - loss: 1.3819 - accuracy: 0.3726 - val_loss: 1.3860 - val_accuracy: 0.3125\n",
      "Epoch 14/30\n",
      "126/126 [==============================] - 7s 57ms/step - loss: 1.3819 - accuracy: 0.3705 - val_loss: 1.3860 - val_accuracy: 0.3125\n",
      "Epoch 15/30\n",
      "126/126 [==============================] - 7s 58ms/step - loss: 1.3817 - accuracy: 0.3824 - val_loss: 1.3860 - val_accuracy: 0.3125\n",
      "Epoch 16/30\n",
      "126/126 [==============================] - 7s 57ms/step - loss: 1.3818 - accuracy: 0.3709 - val_loss: 1.3860 - val_accuracy: 0.3125\n",
      "Epoch 17/30\n",
      "126/126 [==============================] - 7s 57ms/step - loss: 1.3817 - accuracy: 0.3821 - val_loss: 1.3860 - val_accuracy: 0.3125\n",
      "Epoch 18/30\n",
      "126/126 [==============================] - 7s 58ms/step - loss: 1.3821 - accuracy: 0.3683 - val_loss: 1.3860 - val_accuracy: 0.3125\n",
      "Epoch 19/30\n",
      "126/126 [==============================] - 7s 58ms/step - loss: 1.3821 - accuracy: 0.3706 - val_loss: 1.3860 - val_accuracy: 0.3125\n",
      "Epoch 20/30\n",
      "126/126 [==============================] - 7s 57ms/step - loss: 1.3819 - accuracy: 0.3808 - val_loss: 1.3860 - val_accuracy: 0.3125\n",
      "Epoch 21/30\n",
      "126/126 [==============================] - 7s 58ms/step - loss: 1.3823 - accuracy: 0.3659 - val_loss: 1.3860 - val_accuracy: 0.3125\n",
      "Epoch 22/30\n",
      "126/126 [==============================] - 7s 58ms/step - loss: 1.3821 - accuracy: 0.3802 - val_loss: 1.3860 - val_accuracy: 0.3125\n",
      "Epoch 23/30\n",
      "126/126 [==============================] - 7s 58ms/step - loss: 1.3818 - accuracy: 0.3563 - val_loss: 1.3860 - val_accuracy: 0.3125\n",
      "Epoch 24/30\n",
      "126/126 [==============================] - 7s 58ms/step - loss: 1.3819 - accuracy: 0.3766 - val_loss: 1.3860 - val_accuracy: 0.3125\n",
      "Epoch 25/30\n",
      "126/126 [==============================] - 7s 58ms/step - loss: 1.3821 - accuracy: 0.3641 - val_loss: 1.3860 - val_accuracy: 0.3125\n",
      "Epoch 26/30\n",
      "126/126 [==============================] - 7s 58ms/step - loss: 1.3823 - accuracy: 0.3595 - val_loss: 1.3860 - val_accuracy: 0.3125\n",
      "Epoch 27/30\n",
      "126/126 [==============================] - 7s 58ms/step - loss: 1.3818 - accuracy: 0.3707 - val_loss: 1.3860 - val_accuracy: 0.3125\n",
      "Epoch 28/30\n",
      "126/126 [==============================] - 7s 58ms/step - loss: 1.3817 - accuracy: 0.3766 - val_loss: 1.3860 - val_accuracy: 0.3125\n",
      "Epoch 29/30\n",
      "126/126 [==============================] - 7s 57ms/step - loss: 1.3821 - accuracy: 0.3716 - val_loss: 1.3860 - val_accuracy: 0.3125\n",
      "Epoch 30/30\n",
      "126/126 [==============================] - 7s 57ms/step - loss: 1.3821 - accuracy: 0.3676 - val_loss: 1.3860 - val_accuracy: 0.3125\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_6261.3_images_False_newWeights_True_lastLayerOnly/assets\n",
      "Test acc for resnet: 0.275826\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training opticnet for 0.075% of train size (aka 6261 images)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "126/126 [==============================] - 48s 331ms/step - loss: 296.8740 - accuracy: 0.1346 - val_loss: 217.3077 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "126/126 [==============================] - 36s 288ms/step - loss: 294.6772 - accuracy: 0.1295 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "126/126 [==============================] - 36s 289ms/step - loss: 293.2280 - accuracy: 0.1286 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "126/126 [==============================] - 36s 289ms/step - loss: 294.2714 - accuracy: 0.1330 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "126/126 [==============================] - 36s 289ms/step - loss: 286.7834 - accuracy: 0.1383 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "126/126 [==============================] - 36s 289ms/step - loss: 291.7553 - accuracy: 0.1336 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "126/126 [==============================] - 36s 289ms/step - loss: 288.8177 - accuracy: 0.1325 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "126/126 [==============================] - 36s 289ms/step - loss: 293.4028 - accuracy: 0.1315 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "126/126 [==============================] - 36s 289ms/step - loss: 289.1024 - accuracy: 0.1336 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "126/126 [==============================] - 36s 290ms/step - loss: 295.3751 - accuracy: 0.1320 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "126/126 [==============================] - 36s 290ms/step - loss: 290.2255 - accuracy: 0.1331 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "126/126 [==============================] - 36s 289ms/step - loss: 290.3143 - accuracy: 0.1350 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "126/126 [==============================] - 36s 289ms/step - loss: 290.7795 - accuracy: 0.1382 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "126/126 [==============================] - 36s 289ms/step - loss: 290.2686 - accuracy: 0.1416 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "126/126 [==============================] - 36s 289ms/step - loss: 288.2622 - accuracy: 0.1367 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "126/126 [==============================] - 36s 289ms/step - loss: 288.3755 - accuracy: 0.1369 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "126/126 [==============================] - 36s 289ms/step - loss: 293.5176 - accuracy: 0.1320 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "126/126 [==============================] - 36s 289ms/step - loss: 290.0610 - accuracy: 0.1400 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "126/126 [==============================] - 36s 289ms/step - loss: 292.4530 - accuracy: 0.1328 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "126/126 [==============================] - 36s 289ms/step - loss: 295.8560 - accuracy: 0.1245 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "126/126 [==============================] - 36s 289ms/step - loss: 288.5650 - accuracy: 0.1307 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "126/126 [==============================] - 36s 289ms/step - loss: 291.4961 - accuracy: 0.1322 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "126/126 [==============================] - 36s 289ms/step - loss: 292.9985 - accuracy: 0.1340 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "126/126 [==============================] - 36s 289ms/step - loss: 293.9627 - accuracy: 0.1350 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "126/126 [==============================] - 36s 289ms/step - loss: 288.2878 - accuracy: 0.1351 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "126/126 [==============================] - 36s 289ms/step - loss: 292.6915 - accuracy: 0.1381 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "126/126 [==============================] - 36s 289ms/step - loss: 293.9449 - accuracy: 0.1311 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "126/126 [==============================] - 36s 289ms/step - loss: 292.0498 - accuracy: 0.1381 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "126/126 [==============================] - 36s 289ms/step - loss: 294.4188 - accuracy: 0.1282 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "126/126 [==============================] - 36s 289ms/step - loss: 292.2525 - accuracy: 0.1422 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../opticnet/opticnet_30epochs_6261.3_images_False_newWeights_True_lastLayerOnly/assets\n",
      "Test acc for opticnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.09029071 0.09041795 0.08909059 0.08844011]\n",
      "Training xception for 0.09% of train size (aka 7513 images)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/151 [>.............................] - ETA: 1:26 - loss: 1.3853 - accuracy: 0.4439WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1179s vs `on_train_batch_begin` time: 0.1942s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1179s vs `on_train_batch_end` time: 0.2057s). Check your callbacks.\n",
      "151/151 [==============================] - 25s 145ms/step - loss: 1.3849 - accuracy: 0.4213 - val_loss: 1.3858 - val_accuracy: 0.3125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "151/151 [==============================] - 18s 122ms/step - loss: 1.3848 - accuracy: 0.4225 - val_loss: 1.3858 - val_accuracy: 0.3125\n",
      "Epoch 3/30\n",
      "151/151 [==============================] - 18s 122ms/step - loss: 1.3850 - accuracy: 0.4152 - val_loss: 1.3858 - val_accuracy: 0.3125\n",
      "Epoch 4/30\n",
      "151/151 [==============================] - 19s 123ms/step - loss: 1.3845 - accuracy: 0.4298 - val_loss: 1.3858 - val_accuracy: 0.3125\n",
      "Epoch 5/30\n",
      "151/151 [==============================] - 19s 123ms/step - loss: 1.3842 - accuracy: 0.4305 - val_loss: 1.3858 - val_accuracy: 0.3125\n",
      "Epoch 6/30\n",
      "151/151 [==============================] - 19s 123ms/step - loss: 1.3844 - accuracy: 0.4298 - val_loss: 1.3858 - val_accuracy: 0.3125\n",
      "Epoch 7/30\n",
      "151/151 [==============================] - 19s 123ms/step - loss: 1.3847 - accuracy: 0.4210 - val_loss: 1.3858 - val_accuracy: 0.3125\n",
      "Epoch 8/30\n",
      "151/151 [==============================] - 19s 123ms/step - loss: 1.3846 - accuracy: 0.4219 - val_loss: 1.3858 - val_accuracy: 0.3125\n",
      "Epoch 9/30\n",
      "151/151 [==============================] - 19s 123ms/step - loss: 1.3849 - accuracy: 0.4168 - val_loss: 1.3858 - val_accuracy: 0.3125\n",
      "Epoch 10/30\n",
      "151/151 [==============================] - 19s 123ms/step - loss: 1.3846 - accuracy: 0.4281 - val_loss: 1.3858 - val_accuracy: 0.3125\n",
      "Epoch 11/30\n",
      "151/151 [==============================] - 19s 123ms/step - loss: 1.3845 - accuracy: 0.4254 - val_loss: 1.3858 - val_accuracy: 0.3125\n",
      "Epoch 12/30\n",
      "151/151 [==============================] - 19s 123ms/step - loss: 1.3846 - accuracy: 0.4281 - val_loss: 1.3858 - val_accuracy: 0.3125\n",
      "Epoch 13/30\n",
      "151/151 [==============================] - 19s 123ms/step - loss: 1.3849 - accuracy: 0.4207 - val_loss: 1.3858 - val_accuracy: 0.3125\n",
      "Epoch 14/30\n",
      "151/151 [==============================] - 19s 123ms/step - loss: 1.3843 - accuracy: 0.4258 - val_loss: 1.3858 - val_accuracy: 0.3125\n",
      "Epoch 15/30\n",
      "151/151 [==============================] - 19s 123ms/step - loss: 1.3845 - accuracy: 0.4244 - val_loss: 1.3858 - val_accuracy: 0.3125\n",
      "Epoch 16/30\n",
      "151/151 [==============================] - 19s 123ms/step - loss: 1.3848 - accuracy: 0.4220 - val_loss: 1.3858 - val_accuracy: 0.3125\n",
      "Epoch 17/30\n",
      "151/151 [==============================] - 19s 123ms/step - loss: 1.3843 - accuracy: 0.4290 - val_loss: 1.3858 - val_accuracy: 0.3125\n",
      "Epoch 18/30\n",
      "151/151 [==============================] - 19s 123ms/step - loss: 1.3848 - accuracy: 0.4229 - val_loss: 1.3858 - val_accuracy: 0.3125\n",
      "Epoch 19/30\n",
      "151/151 [==============================] - 19s 123ms/step - loss: 1.3848 - accuracy: 0.4298 - val_loss: 1.3858 - val_accuracy: 0.3125\n",
      "Epoch 20/30\n",
      "151/151 [==============================] - 19s 123ms/step - loss: 1.3845 - accuracy: 0.4325 - val_loss: 1.3858 - val_accuracy: 0.3125\n",
      "Epoch 21/30\n",
      "151/151 [==============================] - 19s 123ms/step - loss: 1.3849 - accuracy: 0.4202 - val_loss: 1.3858 - val_accuracy: 0.3125\n",
      "Epoch 22/30\n",
      "151/151 [==============================] - 19s 123ms/step - loss: 1.3845 - accuracy: 0.4252 - val_loss: 1.3858 - val_accuracy: 0.3125\n",
      "Epoch 23/30\n",
      "151/151 [==============================] - 19s 123ms/step - loss: 1.3846 - accuracy: 0.4244 - val_loss: 1.3858 - val_accuracy: 0.3125\n",
      "Epoch 24/30\n",
      "151/151 [==============================] - 19s 123ms/step - loss: 1.3846 - accuracy: 0.4243 - val_loss: 1.3858 - val_accuracy: 0.3125\n",
      "Epoch 25/30\n",
      "151/151 [==============================] - 19s 124ms/step - loss: 1.3851 - accuracy: 0.4206 - val_loss: 1.3858 - val_accuracy: 0.3125\n",
      "Epoch 26/30\n",
      "151/151 [==============================] - 19s 123ms/step - loss: 1.3845 - accuracy: 0.4237 - val_loss: 1.3858 - val_accuracy: 0.3125\n",
      "Epoch 27/30\n",
      "151/151 [==============================] - 19s 123ms/step - loss: 1.3843 - accuracy: 0.4271 - val_loss: 1.3858 - val_accuracy: 0.3125\n",
      "Epoch 28/30\n",
      "151/151 [==============================] - 19s 123ms/step - loss: 1.3848 - accuracy: 0.4193 - val_loss: 1.3858 - val_accuracy: 0.3125\n",
      "Epoch 29/30\n",
      "151/151 [==============================] - 19s 123ms/step - loss: 1.3844 - accuracy: 0.4221 - val_loss: 1.3858 - val_accuracy: 0.3125\n",
      "Epoch 30/30\n",
      "151/151 [==============================] - 19s 123ms/step - loss: 1.3845 - accuracy: 0.4322 - val_loss: 1.3858 - val_accuracy: 0.3125\n",
      "INFO:tensorflow:Assets written to: ../xception/xception_30epochs_7513.5599999999995_images_False_newWeights_True_lastLayerOnly/assets\n",
      "Test acc for xception: 0.260331\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training resnet for 0.09% of train size (aka 7513 images)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/151 [>.............................] - ETA: 1:12 - loss: 1.3898 - accuracy: 0.2817WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0605s vs `on_train_batch_begin` time: 0.1963s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0605s vs `on_train_batch_end` time: 0.1691s). Check your callbacks.\n",
      "151/151 [==============================] - 16s 82ms/step - loss: 1.3895 - accuracy: 0.2863 - val_loss: 1.3856 - val_accuracy: 0.3125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "151/151 [==============================] - 9s 57ms/step - loss: 1.3897 - accuracy: 0.2824 - val_loss: 1.3856 - val_accuracy: 0.3125\n",
      "Epoch 3/30\n",
      "151/151 [==============================] - 9s 57ms/step - loss: 1.3897 - accuracy: 0.2817 - val_loss: 1.3856 - val_accuracy: 0.3125\n",
      "Epoch 4/30\n",
      "151/151 [==============================] - 9s 57ms/step - loss: 1.3899 - accuracy: 0.2724 - val_loss: 1.3856 - val_accuracy: 0.3125\n",
      "Epoch 5/30\n",
      "151/151 [==============================] - 9s 58ms/step - loss: 1.3900 - accuracy: 0.2744 - val_loss: 1.3856 - val_accuracy: 0.3125\n",
      "Epoch 6/30\n",
      "151/151 [==============================] - 9s 57ms/step - loss: 1.3899 - accuracy: 0.2818 - val_loss: 1.3856 - val_accuracy: 0.3125\n",
      "Epoch 7/30\n",
      "151/151 [==============================] - 9s 58ms/step - loss: 1.3902 - accuracy: 0.2840 - val_loss: 1.3856 - val_accuracy: 0.3125\n",
      "Epoch 8/30\n",
      "151/151 [==============================] - 9s 58ms/step - loss: 1.3897 - accuracy: 0.2850 - val_loss: 1.3856 - val_accuracy: 0.3125\n",
      "Epoch 9/30\n",
      "151/151 [==============================] - 9s 58ms/step - loss: 1.3897 - accuracy: 0.2774 - val_loss: 1.3856 - val_accuracy: 0.3125\n",
      "Epoch 10/30\n",
      "151/151 [==============================] - 9s 58ms/step - loss: 1.3892 - accuracy: 0.2926 - val_loss: 1.3856 - val_accuracy: 0.3125\n",
      "Epoch 11/30\n",
      "151/151 [==============================] - 9s 58ms/step - loss: 1.3895 - accuracy: 0.2897 - val_loss: 1.3856 - val_accuracy: 0.3125\n",
      "Epoch 12/30\n",
      "151/151 [==============================] - 9s 58ms/step - loss: 1.3901 - accuracy: 0.2728 - val_loss: 1.3856 - val_accuracy: 0.3125\n",
      "Epoch 13/30\n",
      "151/151 [==============================] - 9s 58ms/step - loss: 1.3897 - accuracy: 0.2774 - val_loss: 1.3856 - val_accuracy: 0.3125\n",
      "Epoch 14/30\n",
      "151/151 [==============================] - 9s 58ms/step - loss: 1.3897 - accuracy: 0.2806 - val_loss: 1.3856 - val_accuracy: 0.3125\n",
      "Epoch 15/30\n",
      "151/151 [==============================] - 9s 58ms/step - loss: 1.3897 - accuracy: 0.2838 - val_loss: 1.3856 - val_accuracy: 0.3125\n",
      "Epoch 16/30\n",
      "151/151 [==============================] - 9s 58ms/step - loss: 1.3901 - accuracy: 0.2755 - val_loss: 1.3856 - val_accuracy: 0.3125\n",
      "Epoch 17/30\n",
      "151/151 [==============================] - 9s 58ms/step - loss: 1.3900 - accuracy: 0.2744 - val_loss: 1.3856 - val_accuracy: 0.3125\n",
      "Epoch 18/30\n",
      "151/151 [==============================] - 9s 58ms/step - loss: 1.3898 - accuracy: 0.2764 - val_loss: 1.3856 - val_accuracy: 0.3125\n",
      "Epoch 19/30\n",
      "151/151 [==============================] - 9s 58ms/step - loss: 1.3898 - accuracy: 0.2738 - val_loss: 1.3856 - val_accuracy: 0.3125\n",
      "Epoch 20/30\n",
      "151/151 [==============================] - 9s 58ms/step - loss: 1.3895 - accuracy: 0.2814 - val_loss: 1.3856 - val_accuracy: 0.3125\n",
      "Epoch 21/30\n",
      "151/151 [==============================] - 9s 58ms/step - loss: 1.3897 - accuracy: 0.2764 - val_loss: 1.3856 - val_accuracy: 0.3125\n",
      "Epoch 22/30\n",
      "151/151 [==============================] - 9s 58ms/step - loss: 1.3897 - accuracy: 0.2834 - val_loss: 1.3856 - val_accuracy: 0.3125\n",
      "Epoch 23/30\n",
      "151/151 [==============================] - 9s 58ms/step - loss: 1.3899 - accuracy: 0.2757 - val_loss: 1.3856 - val_accuracy: 0.3125\n",
      "Epoch 24/30\n",
      "151/151 [==============================] - 9s 58ms/step - loss: 1.3900 - accuracy: 0.2713 - val_loss: 1.3856 - val_accuracy: 0.3125\n",
      "Epoch 25/30\n",
      "151/151 [==============================] - 9s 58ms/step - loss: 1.3897 - accuracy: 0.2727 - val_loss: 1.3856 - val_accuracy: 0.3125\n",
      "Epoch 26/30\n",
      "151/151 [==============================] - 9s 58ms/step - loss: 1.3901 - accuracy: 0.2767 - val_loss: 1.3856 - val_accuracy: 0.3125\n",
      "Epoch 27/30\n",
      "151/151 [==============================] - 9s 58ms/step - loss: 1.3896 - accuracy: 0.2830 - val_loss: 1.3856 - val_accuracy: 0.3125\n",
      "Epoch 28/30\n",
      "151/151 [==============================] - 9s 58ms/step - loss: 1.3901 - accuracy: 0.2724 - val_loss: 1.3856 - val_accuracy: 0.3125\n",
      "Epoch 29/30\n",
      "151/151 [==============================] - 9s 58ms/step - loss: 1.3895 - accuracy: 0.2875 - val_loss: 1.3856 - val_accuracy: 0.3125\n",
      "Epoch 30/30\n",
      "151/151 [==============================] - 9s 58ms/step - loss: 1.3897 - accuracy: 0.2827 - val_loss: 1.3856 - val_accuracy: 0.3125\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_7513.5599999999995_images_False_newWeights_True_lastLayerOnly/assets\n",
      "Test acc for resnet: 0.322314\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training opticnet for 0.09% of train size (aka 7513 images)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "151/151 [==============================] - 57s 324ms/step - loss: 295.2381 - accuracy: 0.1339 - val_loss: 217.3077 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "151/151 [==============================] - 44s 289ms/step - loss: 292.3315 - accuracy: 0.1373 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "151/151 [==============================] - 44s 289ms/step - loss: 292.7173 - accuracy: 0.1338 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "151/151 [==============================] - 44s 289ms/step - loss: 293.2608 - accuracy: 0.1313 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "151/151 [==============================] - 44s 289ms/step - loss: 288.7603 - accuracy: 0.1356 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "151/151 [==============================] - 44s 289ms/step - loss: 295.0763 - accuracy: 0.1320 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "151/151 [==============================] - 44s 289ms/step - loss: 290.8441 - accuracy: 0.1356 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "151/151 [==============================] - 44s 289ms/step - loss: 293.8853 - accuracy: 0.1294 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "151/151 [==============================] - 44s 290ms/step - loss: 292.3675 - accuracy: 0.1350 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "151/151 [==============================] - 44s 289ms/step - loss: 291.8362 - accuracy: 0.1397 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "151/151 [==============================] - 44s 289ms/step - loss: 294.7705 - accuracy: 0.1285 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "151/151 [==============================] - 44s 289ms/step - loss: 287.7742 - accuracy: 0.1398 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "151/151 [==============================] - 44s 289ms/step - loss: 293.3691 - accuracy: 0.1312 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "151/151 [==============================] - 44s 289ms/step - loss: 292.3049 - accuracy: 0.1355 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "151/151 [==============================] - 44s 289ms/step - loss: 292.1474 - accuracy: 0.1301 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "151/151 [==============================] - 44s 289ms/step - loss: 290.3697 - accuracy: 0.1340 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "151/151 [==============================] - 44s 289ms/step - loss: 292.9809 - accuracy: 0.1318 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "151/151 [==============================] - 44s 289ms/step - loss: 290.7296 - accuracy: 0.1413 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "151/151 [==============================] - 44s 289ms/step - loss: 294.6421 - accuracy: 0.1294 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "151/151 [==============================] - 44s 289ms/step - loss: 293.2464 - accuracy: 0.1388 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "151/151 [==============================] - 44s 289ms/step - loss: 294.0767 - accuracy: 0.1361 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "151/151 [==============================] - 44s 289ms/step - loss: 294.9677 - accuracy: 0.1307 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "151/151 [==============================] - 44s 289ms/step - loss: 294.1438 - accuracy: 0.1313 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "151/151 [==============================] - 44s 289ms/step - loss: 290.4497 - accuracy: 0.1314 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "151/151 [==============================] - 44s 289ms/step - loss: 292.1253 - accuracy: 0.1332 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "151/151 [==============================] - 44s 289ms/step - loss: 286.8951 - accuracy: 0.1397 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "151/151 [==============================] - 44s 289ms/step - loss: 293.1045 - accuracy: 0.1309 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "151/151 [==============================] - 44s 289ms/step - loss: 292.9435 - accuracy: 0.1355 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "151/151 [==============================] - 44s 289ms/step - loss: 293.4434 - accuracy: 0.1357 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "151/151 [==============================] - 44s 289ms/step - loss: 290.3784 - accuracy: 0.1335 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../opticnet/opticnet_30epochs_7513.5599999999995_images_False_newWeights_True_lastLayerOnly/assets\n",
      "Test acc for opticnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.10115903 0.10044349 0.09834332 0.09668059]\n",
      "Training xception for 0.1% of train size (aka 8348 images)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/167 [>.............................] - ETA: 1:43 - loss: 1.3871 - accuracy: 0.1307WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1188s vs `on_train_batch_begin` time: 0.2027s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1188s vs `on_train_batch_end` time: 0.2319s). Check your callbacks.\n",
      "167/167 [==============================] - 27s 145ms/step - loss: 1.3865 - accuracy: 0.1355 - val_loss: 1.3879 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "167/167 [==============================] - 20s 122ms/step - loss: 1.3865 - accuracy: 0.1317 - val_loss: 1.3879 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "167/167 [==============================] - 21s 123ms/step - loss: 1.3870 - accuracy: 0.1252 - val_loss: 1.3879 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "167/167 [==============================] - 21s 124ms/step - loss: 1.3866 - accuracy: 0.1314 - val_loss: 1.3879 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "167/167 [==============================] - 21s 124ms/step - loss: 1.3867 - accuracy: 0.1294 - val_loss: 1.3879 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "167/167 [==============================] - 21s 124ms/step - loss: 1.3867 - accuracy: 0.1255 - val_loss: 1.3879 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "167/167 [==============================] - 21s 124ms/step - loss: 1.3865 - accuracy: 0.1326 - val_loss: 1.3879 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "167/167 [==============================] - 21s 124ms/step - loss: 1.3867 - accuracy: 0.1327 - val_loss: 1.3879 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "167/167 [==============================] - 21s 124ms/step - loss: 1.3862 - accuracy: 0.1258 - val_loss: 1.3879 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "167/167 [==============================] - 21s 124ms/step - loss: 1.3860 - accuracy: 0.1352 - val_loss: 1.3879 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "167/167 [==============================] - 21s 124ms/step - loss: 1.3867 - accuracy: 0.1232 - val_loss: 1.3879 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "167/167 [==============================] - 21s 124ms/step - loss: 1.3866 - accuracy: 0.1296 - val_loss: 1.3879 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "167/167 [==============================] - 21s 124ms/step - loss: 1.3863 - accuracy: 0.1292 - val_loss: 1.3879 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "167/167 [==============================] - 21s 124ms/step - loss: 1.3862 - accuracy: 0.1301 - val_loss: 1.3879 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "167/167 [==============================] - 21s 124ms/step - loss: 1.3870 - accuracy: 0.1253 - val_loss: 1.3879 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "167/167 [==============================] - 21s 124ms/step - loss: 1.3871 - accuracy: 0.1274 - val_loss: 1.3879 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "167/167 [==============================] - 21s 124ms/step - loss: 1.3863 - accuracy: 0.1261 - val_loss: 1.3879 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "167/167 [==============================] - 21s 124ms/step - loss: 1.3867 - accuracy: 0.1279 - val_loss: 1.3879 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "167/167 [==============================] - 21s 124ms/step - loss: 1.3859 - accuracy: 0.1338 - val_loss: 1.3879 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "167/167 [==============================] - 21s 124ms/step - loss: 1.3868 - accuracy: 0.1299 - val_loss: 1.3879 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "167/167 [==============================] - 21s 124ms/step - loss: 1.3870 - accuracy: 0.1233 - val_loss: 1.3879 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "167/167 [==============================] - 21s 124ms/step - loss: 1.3864 - accuracy: 0.1281 - val_loss: 1.3879 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "167/167 [==============================] - 21s 124ms/step - loss: 1.3863 - accuracy: 0.1298 - val_loss: 1.3879 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "167/167 [==============================] - 21s 124ms/step - loss: 1.3864 - accuracy: 0.1287 - val_loss: 1.3879 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "167/167 [==============================] - 21s 124ms/step - loss: 1.3863 - accuracy: 0.1340 - val_loss: 1.3879 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "167/167 [==============================] - 21s 124ms/step - loss: 1.3864 - accuracy: 0.1317 - val_loss: 1.3879 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "167/167 [==============================] - 21s 124ms/step - loss: 1.3868 - accuracy: 0.1275 - val_loss: 1.3879 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "167/167 [==============================] - 21s 124ms/step - loss: 1.3867 - accuracy: 0.1298 - val_loss: 1.3879 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "167/167 [==============================] - 21s 124ms/step - loss: 1.3866 - accuracy: 0.1307 - val_loss: 1.3879 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "167/167 [==============================] - 21s 124ms/step - loss: 1.3867 - accuracy: 0.1288 - val_loss: 1.3879 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../xception/xception_30epochs_8348.4_images_False_newWeights_True_lastLayerOnly/assets\n",
      "Test acc for xception: 0.242769\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training resnet for 0.1% of train size (aka 8348 images)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/167 [>.............................] - ETA: 1:21 - loss: 1.3849 - accuracy: 0.3123WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0605s vs `on_train_batch_begin` time: 0.1979s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0605s vs `on_train_batch_end` time: 0.1717s). Check your callbacks.\n",
      "167/167 [==============================] - 17s 80ms/step - loss: 1.3829 - accuracy: 0.3259 - val_loss: 1.3804 - val_accuracy: 0.3750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "167/167 [==============================] - 10s 57ms/step - loss: 1.3830 - accuracy: 0.3156 - val_loss: 1.3804 - val_accuracy: 0.3750\n",
      "Epoch 3/30\n",
      "167/167 [==============================] - 10s 57ms/step - loss: 1.3830 - accuracy: 0.3266 - val_loss: 1.3804 - val_accuracy: 0.3750\n",
      "Epoch 4/30\n",
      "167/167 [==============================] - 10s 58ms/step - loss: 1.3829 - accuracy: 0.3235 - val_loss: 1.3804 - val_accuracy: 0.3750\n",
      "Epoch 5/30\n",
      "167/167 [==============================] - 10s 58ms/step - loss: 1.3829 - accuracy: 0.3158 - val_loss: 1.3804 - val_accuracy: 0.3750\n",
      "Epoch 6/30\n",
      "167/167 [==============================] - 10s 58ms/step - loss: 1.3826 - accuracy: 0.3221 - val_loss: 1.3804 - val_accuracy: 0.3750\n",
      "Epoch 7/30\n",
      "167/167 [==============================] - 10s 58ms/step - loss: 1.3831 - accuracy: 0.3226 - val_loss: 1.3804 - val_accuracy: 0.3750\n",
      "Epoch 8/30\n",
      "167/167 [==============================] - 10s 58ms/step - loss: 1.3831 - accuracy: 0.3213 - val_loss: 1.3804 - val_accuracy: 0.3750\n",
      "Epoch 9/30\n",
      "167/167 [==============================] - 10s 58ms/step - loss: 1.3828 - accuracy: 0.3206 - val_loss: 1.3804 - val_accuracy: 0.3750\n",
      "Epoch 10/30\n",
      "167/167 [==============================] - 10s 58ms/step - loss: 1.3831 - accuracy: 0.3194 - val_loss: 1.3804 - val_accuracy: 0.3750\n",
      "Epoch 11/30\n",
      "167/167 [==============================] - 10s 58ms/step - loss: 1.3830 - accuracy: 0.3273 - val_loss: 1.3804 - val_accuracy: 0.3750\n",
      "Epoch 12/30\n",
      "167/167 [==============================] - 10s 58ms/step - loss: 1.3826 - accuracy: 0.3326 - val_loss: 1.3804 - val_accuracy: 0.3750\n",
      "Epoch 13/30\n",
      "167/167 [==============================] - 10s 58ms/step - loss: 1.3823 - accuracy: 0.3323 - val_loss: 1.3804 - val_accuracy: 0.3750\n",
      "Epoch 14/30\n",
      "167/167 [==============================] - 10s 58ms/step - loss: 1.3832 - accuracy: 0.3221 - val_loss: 1.3804 - val_accuracy: 0.3750\n",
      "Epoch 15/30\n",
      "167/167 [==============================] - 10s 58ms/step - loss: 1.3827 - accuracy: 0.3228 - val_loss: 1.3804 - val_accuracy: 0.3750\n",
      "Epoch 16/30\n",
      "167/167 [==============================] - 10s 58ms/step - loss: 1.3830 - accuracy: 0.3161 - val_loss: 1.3804 - val_accuracy: 0.3750\n",
      "Epoch 17/30\n",
      "167/167 [==============================] - 10s 58ms/step - loss: 1.3830 - accuracy: 0.3220 - val_loss: 1.3804 - val_accuracy: 0.3750\n",
      "Epoch 18/30\n",
      "167/167 [==============================] - 10s 58ms/step - loss: 1.3825 - accuracy: 0.3296 - val_loss: 1.3804 - val_accuracy: 0.3750\n",
      "Epoch 19/30\n",
      "167/167 [==============================] - 10s 58ms/step - loss: 1.3827 - accuracy: 0.3244 - val_loss: 1.3804 - val_accuracy: 0.3750\n",
      "Epoch 20/30\n",
      "167/167 [==============================] - 10s 58ms/step - loss: 1.3826 - accuracy: 0.3261 - val_loss: 1.3804 - val_accuracy: 0.3750\n",
      "Epoch 21/30\n",
      "167/167 [==============================] - 10s 58ms/step - loss: 1.3831 - accuracy: 0.3209 - val_loss: 1.3804 - val_accuracy: 0.3750\n",
      "Epoch 22/30\n",
      "167/167 [==============================] - 10s 58ms/step - loss: 1.3834 - accuracy: 0.3194 - val_loss: 1.3804 - val_accuracy: 0.3750\n",
      "Epoch 23/30\n",
      "167/167 [==============================] - 10s 58ms/step - loss: 1.3827 - accuracy: 0.3226 - val_loss: 1.3804 - val_accuracy: 0.3750\n",
      "Epoch 24/30\n",
      "167/167 [==============================] - 10s 58ms/step - loss: 1.3829 - accuracy: 0.3252 - val_loss: 1.3804 - val_accuracy: 0.3750\n",
      "Epoch 25/30\n",
      "167/167 [==============================] - 10s 58ms/step - loss: 1.3833 - accuracy: 0.3090 - val_loss: 1.3804 - val_accuracy: 0.3750\n",
      "Epoch 26/30\n",
      "167/167 [==============================] - 10s 58ms/step - loss: 1.3827 - accuracy: 0.3221 - val_loss: 1.3804 - val_accuracy: 0.3750\n",
      "Epoch 27/30\n",
      "167/167 [==============================] - 10s 58ms/step - loss: 1.3830 - accuracy: 0.3258 - val_loss: 1.3804 - val_accuracy: 0.3750\n",
      "Epoch 28/30\n",
      "167/167 [==============================] - 10s 58ms/step - loss: 1.3828 - accuracy: 0.3219 - val_loss: 1.3804 - val_accuracy: 0.3750\n",
      "Epoch 29/30\n",
      "167/167 [==============================] - 10s 58ms/step - loss: 1.3829 - accuracy: 0.3313 - val_loss: 1.3804 - val_accuracy: 0.3750\n",
      "Epoch 30/30\n",
      "167/167 [==============================] - 10s 58ms/step - loss: 1.3831 - accuracy: 0.3172 - val_loss: 1.3804 - val_accuracy: 0.3750\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_8348.4_images_False_newWeights_True_lastLayerOnly/assets\n",
      "Test acc for resnet: 0.301653\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training opticnet for 0.1% of train size (aka 8348 images)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "167/167 [==============================] - 61s 330ms/step - loss: 294.4036 - accuracy: 0.1315 - val_loss: 217.3077 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "167/167 [==============================] - 48s 290ms/step - loss: 290.4336 - accuracy: 0.1347 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "167/167 [==============================] - 48s 290ms/step - loss: 291.9538 - accuracy: 0.1373 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "167/167 [==============================] - 48s 290ms/step - loss: 290.5166 - accuracy: 0.1356 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "167/167 [==============================] - 49s 290ms/step - loss: 293.3930 - accuracy: 0.1388 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "167/167 [==============================] - 48s 290ms/step - loss: 291.4330 - accuracy: 0.1349 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "167/167 [==============================] - 48s 290ms/step - loss: 292.3781 - accuracy: 0.1310 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "167/167 [==============================] - 48s 290ms/step - loss: 291.2276 - accuracy: 0.1311 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "167/167 [==============================] - 48s 290ms/step - loss: 293.3082 - accuracy: 0.1304 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "167/167 [==============================] - 48s 290ms/step - loss: 294.3426 - accuracy: 0.1296 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "167/167 [==============================] - 48s 290ms/step - loss: 291.3517 - accuracy: 0.1334 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "167/167 [==============================] - 48s 290ms/step - loss: 293.4453 - accuracy: 0.1336 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "167/167 [==============================] - 49s 291ms/step - loss: 297.1586 - accuracy: 0.1266 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "167/167 [==============================] - 48s 290ms/step - loss: 291.4320 - accuracy: 0.1327 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "167/167 [==============================] - 48s 290ms/step - loss: 291.5423 - accuracy: 0.1364 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "167/167 [==============================] - 48s 290ms/step - loss: 295.1308 - accuracy: 0.1317 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "167/167 [==============================] - 48s 290ms/step - loss: 289.3670 - accuracy: 0.1400 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "167/167 [==============================] - 48s 290ms/step - loss: 293.5645 - accuracy: 0.1338 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "167/167 [==============================] - 48s 290ms/step - loss: 290.5599 - accuracy: 0.1324 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "167/167 [==============================] - 48s 290ms/step - loss: 288.2155 - accuracy: 0.1374 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "167/167 [==============================] - 48s 290ms/step - loss: 291.9089 - accuracy: 0.1271 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "167/167 [==============================] - 49s 291ms/step - loss: 294.7339 - accuracy: 0.1290 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "167/167 [==============================] - 48s 290ms/step - loss: 297.2938 - accuracy: 0.1293 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "167/167 [==============================] - 48s 290ms/step - loss: 290.9743 - accuracy: 0.1342 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "167/167 [==============================] - 48s 290ms/step - loss: 293.9136 - accuracy: 0.1336 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "167/167 [==============================] - 48s 290ms/step - loss: 295.4668 - accuracy: 0.1291 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "167/167 [==============================] - 48s 290ms/step - loss: 291.4299 - accuracy: 0.1327 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "167/167 [==============================] - 48s 290ms/step - loss: 291.8743 - accuracy: 0.1352 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "167/167 [==============================] - 48s 290ms/step - loss: 294.6258 - accuracy: 0.1329 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "167/167 [==============================] - 48s 290ms/step - loss: 296.4585 - accuracy: 0.1284 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../opticnet/opticnet_30epochs_8348.4_images_False_newWeights_True_lastLayerOnly/assets\n",
      "Test acc for opticnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.25069352 0.25362183 0.24735636 0.23572423]\n",
      "Training xception for 0.25% of train size (aka 20871 images)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/418 [..............................] - ETA: 4:09 - loss: 1.4004 - accuracy: 0.1574WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1194s vs `on_train_batch_begin` time: 0.1950s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1194s vs `on_train_batch_end` time: 0.2098s). Check your callbacks.\n",
      "418/418 [==============================] - 57s 130ms/step - loss: 1.3995 - accuracy: 0.1753 - val_loss: 1.3900 - val_accuracy: 0.2188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "418/418 [==============================] - 51s 123ms/step - loss: 1.3999 - accuracy: 0.1708 - val_loss: 1.3900 - val_accuracy: 0.2188\n",
      "Epoch 3/30\n",
      "418/418 [==============================] - 51s 123ms/step - loss: 1.3997 - accuracy: 0.1726 - val_loss: 1.3900 - val_accuracy: 0.2188\n",
      "Epoch 4/30\n",
      "418/418 [==============================] - 51s 123ms/step - loss: 1.3999 - accuracy: 0.1699 - val_loss: 1.3900 - val_accuracy: 0.2188\n",
      "Epoch 5/30\n",
      "418/418 [==============================] - 51s 123ms/step - loss: 1.3999 - accuracy: 0.1694 - val_loss: 1.3900 - val_accuracy: 0.2188\n",
      "Epoch 6/30\n",
      "418/418 [==============================] - 52s 123ms/step - loss: 1.3996 - accuracy: 0.1725 - val_loss: 1.3900 - val_accuracy: 0.2188\n",
      "Epoch 7/30\n",
      "418/418 [==============================] - 52s 123ms/step - loss: 1.3998 - accuracy: 0.1720 - val_loss: 1.3900 - val_accuracy: 0.2188\n",
      "Epoch 8/30\n",
      "418/418 [==============================] - 51s 123ms/step - loss: 1.4001 - accuracy: 0.1683 - val_loss: 1.3900 - val_accuracy: 0.2188\n",
      "Epoch 9/30\n",
      "418/418 [==============================] - 51s 123ms/step - loss: 1.3998 - accuracy: 0.1703 - val_loss: 1.3900 - val_accuracy: 0.2188\n",
      "Epoch 10/30\n",
      "418/418 [==============================] - 52s 123ms/step - loss: 1.3999 - accuracy: 0.1714 - val_loss: 1.3900 - val_accuracy: 0.2188\n",
      "Epoch 11/30\n",
      "418/418 [==============================] - 52s 123ms/step - loss: 1.4000 - accuracy: 0.1690 - val_loss: 1.3900 - val_accuracy: 0.2188\n",
      "Epoch 12/30\n",
      "418/418 [==============================] - 52s 123ms/step - loss: 1.3996 - accuracy: 0.1717 - val_loss: 1.3900 - val_accuracy: 0.2188\n",
      "Epoch 13/30\n",
      "418/418 [==============================] - 52s 123ms/step - loss: 1.3997 - accuracy: 0.1725 - val_loss: 1.3900 - val_accuracy: 0.2188\n",
      "Epoch 14/30\n",
      "418/418 [==============================] - 51s 123ms/step - loss: 1.3997 - accuracy: 0.1706 - val_loss: 1.3900 - val_accuracy: 0.2188\n",
      "Epoch 15/30\n",
      "418/418 [==============================] - 51s 123ms/step - loss: 1.3997 - accuracy: 0.1718 - val_loss: 1.3900 - val_accuracy: 0.2188\n",
      "Epoch 16/30\n",
      "418/418 [==============================] - 51s 123ms/step - loss: 1.3996 - accuracy: 0.1730 - val_loss: 1.3900 - val_accuracy: 0.2188\n",
      "Epoch 17/30\n",
      "418/418 [==============================] - 52s 123ms/step - loss: 1.3993 - accuracy: 0.1774 - val_loss: 1.3900 - val_accuracy: 0.2188\n",
      "Epoch 18/30\n",
      "418/418 [==============================] - 52s 123ms/step - loss: 1.3998 - accuracy: 0.1715 - val_loss: 1.3900 - val_accuracy: 0.2188\n",
      "Epoch 19/30\n",
      "418/418 [==============================] - 51s 123ms/step - loss: 1.3997 - accuracy: 0.1732 - val_loss: 1.3900 - val_accuracy: 0.2188\n",
      "Epoch 20/30\n",
      "418/418 [==============================] - 51s 123ms/step - loss: 1.4002 - accuracy: 0.1675 - val_loss: 1.3900 - val_accuracy: 0.2188\n",
      "Epoch 21/30\n",
      "418/418 [==============================] - 51s 123ms/step - loss: 1.4000 - accuracy: 0.1685 - val_loss: 1.3900 - val_accuracy: 0.2188\n",
      "Epoch 22/30\n",
      "418/418 [==============================] - 51s 123ms/step - loss: 1.3998 - accuracy: 0.1711 - val_loss: 1.3900 - val_accuracy: 0.2188\n",
      "Epoch 23/30\n",
      "418/418 [==============================] - 51s 123ms/step - loss: 1.3994 - accuracy: 0.1723 - val_loss: 1.3900 - val_accuracy: 0.2188\n",
      "Epoch 24/30\n",
      "418/418 [==============================] - 52s 123ms/step - loss: 1.4000 - accuracy: 0.1692 - val_loss: 1.3900 - val_accuracy: 0.2188\n",
      "Epoch 25/30\n",
      "418/418 [==============================] - 52s 123ms/step - loss: 1.3992 - accuracy: 0.1787 - val_loss: 1.3900 - val_accuracy: 0.2188\n",
      "Epoch 26/30\n",
      "418/418 [==============================] - 52s 124ms/step - loss: 1.3997 - accuracy: 0.1716 - val_loss: 1.3900 - val_accuracy: 0.2188\n",
      "Epoch 27/30\n",
      "418/418 [==============================] - 51s 123ms/step - loss: 1.3996 - accuracy: 0.1731 - val_loss: 1.3900 - val_accuracy: 0.2188\n",
      "Epoch 28/30\n",
      "418/418 [==============================] - 52s 123ms/step - loss: 1.3997 - accuracy: 0.1721 - val_loss: 1.3900 - val_accuracy: 0.2188\n",
      "Epoch 29/30\n",
      "418/418 [==============================] - 52s 123ms/step - loss: 1.3994 - accuracy: 0.1747 - val_loss: 1.3900 - val_accuracy: 0.2188\n",
      "Epoch 30/30\n",
      "418/418 [==============================] - 52s 123ms/step - loss: 1.3999 - accuracy: 0.1697 - val_loss: 1.3900 - val_accuracy: 0.2188\n",
      "INFO:tensorflow:Assets written to: ../xception/xception_30epochs_20871.0_images_False_newWeights_True_lastLayerOnly/assets\n",
      "Test acc for xception: 0.267562\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training resnet for 0.25% of train size (aka 20871 images)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/418 [..............................] - ETA: 3:26 - loss: 1.3838 - accuracy: 0.2637WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0600s vs `on_train_batch_begin` time: 0.1961s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0600s vs `on_train_batch_end` time: 0.1721s). Check your callbacks.\n",
      "418/418 [==============================] - 32s 69ms/step - loss: 1.3843 - accuracy: 0.2379 - val_loss: 1.3914 - val_accuracy: 0.1250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "418/418 [==============================] - 24s 57ms/step - loss: 1.3842 - accuracy: 0.2401 - val_loss: 1.3914 - val_accuracy: 0.1250\n",
      "Epoch 3/30\n",
      "418/418 [==============================] - 24s 57ms/step - loss: 1.3843 - accuracy: 0.2360 - val_loss: 1.3914 - val_accuracy: 0.1250\n",
      "Epoch 4/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3841 - accuracy: 0.2386 - val_loss: 1.3914 - val_accuracy: 0.1250\n",
      "Epoch 5/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3841 - accuracy: 0.2390 - val_loss: 1.3914 - val_accuracy: 0.1250\n",
      "Epoch 6/30\n",
      "418/418 [==============================] - 24s 57ms/step - loss: 1.3842 - accuracy: 0.2390 - val_loss: 1.3914 - val_accuracy: 0.1250\n",
      "Epoch 7/30\n",
      "418/418 [==============================] - 24s 57ms/step - loss: 1.3846 - accuracy: 0.2377 - val_loss: 1.3914 - val_accuracy: 0.1250\n",
      "Epoch 8/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3847 - accuracy: 0.2301 - val_loss: 1.3914 - val_accuracy: 0.1250\n",
      "Epoch 9/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3844 - accuracy: 0.2337 - val_loss: 1.3914 - val_accuracy: 0.1250\n",
      "Epoch 10/30\n",
      "418/418 [==============================] - 24s 57ms/step - loss: 1.3844 - accuracy: 0.2340 - val_loss: 1.3914 - val_accuracy: 0.1250\n",
      "Epoch 11/30\n",
      "418/418 [==============================] - 24s 57ms/step - loss: 1.3844 - accuracy: 0.2386 - val_loss: 1.3914 - val_accuracy: 0.1250\n",
      "Epoch 12/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3843 - accuracy: 0.2379 - val_loss: 1.3914 - val_accuracy: 0.1250\n",
      "Epoch 13/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3843 - accuracy: 0.2386 - val_loss: 1.3914 - val_accuracy: 0.1250\n",
      "Epoch 14/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3843 - accuracy: 0.2410 - val_loss: 1.3914 - val_accuracy: 0.1250\n",
      "Epoch 15/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3842 - accuracy: 0.2381 - val_loss: 1.3914 - val_accuracy: 0.1250\n",
      "Epoch 16/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3845 - accuracy: 0.2355 - val_loss: 1.3914 - val_accuracy: 0.1250\n",
      "Epoch 17/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3843 - accuracy: 0.2354 - val_loss: 1.3914 - val_accuracy: 0.1250\n",
      "Epoch 18/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3844 - accuracy: 0.2357 - val_loss: 1.3914 - val_accuracy: 0.1250\n",
      "Epoch 19/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3843 - accuracy: 0.2377 - val_loss: 1.3914 - val_accuracy: 0.1250\n",
      "Epoch 20/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3843 - accuracy: 0.2369 - val_loss: 1.3914 - val_accuracy: 0.1250\n",
      "Epoch 21/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3843 - accuracy: 0.2366 - val_loss: 1.3914 - val_accuracy: 0.1250\n",
      "Epoch 22/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3843 - accuracy: 0.2371 - val_loss: 1.3914 - val_accuracy: 0.1250\n",
      "Epoch 23/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3842 - accuracy: 0.2398 - val_loss: 1.3914 - val_accuracy: 0.1250\n",
      "Epoch 24/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3842 - accuracy: 0.2388 - val_loss: 1.3914 - val_accuracy: 0.1250\n",
      "Epoch 25/30\n",
      "418/418 [==============================] - 24s 57ms/step - loss: 1.3842 - accuracy: 0.2355 - val_loss: 1.3914 - val_accuracy: 0.1250\n",
      "Epoch 26/30\n",
      "418/418 [==============================] - 24s 57ms/step - loss: 1.3844 - accuracy: 0.2358 - val_loss: 1.3914 - val_accuracy: 0.1250\n",
      "Epoch 27/30\n",
      "418/418 [==============================] - 24s 57ms/step - loss: 1.3843 - accuracy: 0.2382 - val_loss: 1.3914 - val_accuracy: 0.1250\n",
      "Epoch 28/30\n",
      "418/418 [==============================] - 24s 57ms/step - loss: 1.3842 - accuracy: 0.2382 - val_loss: 1.3914 - val_accuracy: 0.1250\n",
      "Epoch 29/30\n",
      "418/418 [==============================] - 24s 57ms/step - loss: 1.3844 - accuracy: 0.2367 - val_loss: 1.3914 - val_accuracy: 0.1250\n",
      "Epoch 30/30\n",
      "418/418 [==============================] - 24s 57ms/step - loss: 1.3844 - accuracy: 0.2356 - val_loss: 1.3914 - val_accuracy: 0.1250\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_20871.0_images_False_newWeights_True_lastLayerOnly/assets\n",
      "Test acc for resnet: 0.206612\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training opticnet for 0.25% of train size (aka 20871 images)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "418/418 [==============================] - 134s 301ms/step - loss: 290.3599 - accuracy: 0.1352 - val_loss: 217.3077 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "418/418 [==============================] - 121s 290ms/step - loss: 290.5452 - accuracy: 0.1346 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "418/418 [==============================] - 121s 290ms/step - loss: 291.1805 - accuracy: 0.1354 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "418/418 [==============================] - 121s 289ms/step - loss: 292.4952 - accuracy: 0.1340 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "418/418 [==============================] - 121s 290ms/step - loss: 289.3793 - accuracy: 0.1358 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "418/418 [==============================] - 121s 290ms/step - loss: 290.7895 - accuracy: 0.1369 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "418/418 [==============================] - 121s 289ms/step - loss: 292.2795 - accuracy: 0.1311 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "418/418 [==============================] - 121s 289ms/step - loss: 291.1915 - accuracy: 0.1360 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "418/418 [==============================] - 121s 289ms/step - loss: 287.8114 - accuracy: 0.1361 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "418/418 [==============================] - 121s 289ms/step - loss: 292.0220 - accuracy: 0.1322 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "418/418 [==============================] - 121s 289ms/step - loss: 289.9216 - accuracy: 0.1347 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "418/418 [==============================] - 121s 289ms/step - loss: 291.4128 - accuracy: 0.1348 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "418/418 [==============================] - 121s 289ms/step - loss: 290.9532 - accuracy: 0.1382 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "418/418 [==============================] - 121s 289ms/step - loss: 290.7730 - accuracy: 0.1357 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "418/418 [==============================] - 121s 289ms/step - loss: 289.1975 - accuracy: 0.1375 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "418/418 [==============================] - 121s 289ms/step - loss: 290.7327 - accuracy: 0.1351 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "418/418 [==============================] - 121s 289ms/step - loss: 292.3047 - accuracy: 0.1369 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "418/418 [==============================] - 121s 289ms/step - loss: 288.3344 - accuracy: 0.1353 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "418/418 [==============================] - 121s 289ms/step - loss: 289.6981 - accuracy: 0.1361 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "418/418 [==============================] - 121s 290ms/step - loss: 291.4473 - accuracy: 0.1338 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "418/418 [==============================] - 121s 289ms/step - loss: 291.0970 - accuracy: 0.1340 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "418/418 [==============================] - 121s 289ms/step - loss: 292.8146 - accuracy: 0.1329 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "418/418 [==============================] - 121s 290ms/step - loss: 291.3159 - accuracy: 0.1354 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "418/418 [==============================] - 121s 289ms/step - loss: 294.3879 - accuracy: 0.1300 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "418/418 [==============================] - 121s 289ms/step - loss: 290.9518 - accuracy: 0.1370 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "418/418 [==============================] - 121s 289ms/step - loss: 290.7936 - accuracy: 0.1347 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "418/418 [==============================] - 121s 290ms/step - loss: 290.8506 - accuracy: 0.1335 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "418/418 [==============================] - 121s 290ms/step - loss: 291.3074 - accuracy: 0.1366 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "418/418 [==============================] - 121s 290ms/step - loss: 291.9751 - accuracy: 0.1339 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "418/418 [==============================] - 121s 289ms/step - loss: 292.5195 - accuracy: 0.1349 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../opticnet/opticnet_30epochs_20871.0_images_False_newWeights_True_lastLayerOnly/assets\n",
      "Test acc for opticnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.39840395 0.40263405 0.40033486 0.39298979]\n",
      "Training xception for 0.4% of train size (aka 33393 images)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/668 [..............................] - ETA: 6:37 - loss: 1.4137 - accuracy: 0.2696WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1200s vs `on_train_batch_begin` time: 0.1954s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1200s vs `on_train_batch_end` time: 0.2052s). Check your callbacks.\n",
      "668/668 [==============================] - 88s 127ms/step - loss: 1.4068 - accuracy: 0.2843 - val_loss: 1.3925 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "668/668 [==============================] - 83s 124ms/step - loss: 1.4067 - accuracy: 0.2796 - val_loss: 1.3925 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "668/668 [==============================] - 83s 124ms/step - loss: 1.4067 - accuracy: 0.2818 - val_loss: 1.3925 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "668/668 [==============================] - 83s 124ms/step - loss: 1.4069 - accuracy: 0.2806 - val_loss: 1.3925 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "668/668 [==============================] - 83s 124ms/step - loss: 1.4069 - accuracy: 0.2840 - val_loss: 1.3925 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "668/668 [==============================] - 83s 124ms/step - loss: 1.4063 - accuracy: 0.2860 - val_loss: 1.3925 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "668/668 [==============================] - 83s 124ms/step - loss: 1.4071 - accuracy: 0.2801 - val_loss: 1.3925 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "668/668 [==============================] - 83s 124ms/step - loss: 1.4071 - accuracy: 0.2798 - val_loss: 1.3925 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "668/668 [==============================] - 83s 124ms/step - loss: 1.4070 - accuracy: 0.2838 - val_loss: 1.3925 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "668/668 [==============================] - 83s 124ms/step - loss: 1.4072 - accuracy: 0.2785 - val_loss: 1.3925 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "668/668 [==============================] - 83s 124ms/step - loss: 1.4069 - accuracy: 0.2840 - val_loss: 1.3925 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "668/668 [==============================] - 83s 124ms/step - loss: 1.4075 - accuracy: 0.2779 - val_loss: 1.3925 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "668/668 [==============================] - 83s 124ms/step - loss: 1.4071 - accuracy: 0.2828 - val_loss: 1.3925 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "668/668 [==============================] - 83s 124ms/step - loss: 1.4066 - accuracy: 0.2842 - val_loss: 1.3925 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "668/668 [==============================] - 83s 124ms/step - loss: 1.4073 - accuracy: 0.2786 - val_loss: 1.3925 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "668/668 [==============================] - 83s 124ms/step - loss: 1.4069 - accuracy: 0.2812 - val_loss: 1.3925 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "668/668 [==============================] - 83s 124ms/step - loss: 1.4073 - accuracy: 0.2802 - val_loss: 1.3925 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "668/668 [==============================] - 83s 124ms/step - loss: 1.4065 - accuracy: 0.2815 - val_loss: 1.3925 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "668/668 [==============================] - 83s 124ms/step - loss: 1.4069 - accuracy: 0.2827 - val_loss: 1.3925 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "668/668 [==============================] - 83s 124ms/step - loss: 1.4072 - accuracy: 0.2799 - val_loss: 1.3925 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "668/668 [==============================] - 83s 124ms/step - loss: 1.4061 - accuracy: 0.2893 - val_loss: 1.3925 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "668/668 [==============================] - 83s 124ms/step - loss: 1.4069 - accuracy: 0.2821 - val_loss: 1.3925 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "668/668 [==============================] - 83s 124ms/step - loss: 1.4067 - accuracy: 0.2838 - val_loss: 1.3925 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "668/668 [==============================] - 83s 124ms/step - loss: 1.4068 - accuracy: 0.2789 - val_loss: 1.3925 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "668/668 [==============================] - 83s 124ms/step - loss: 1.4067 - accuracy: 0.2804 - val_loss: 1.3925 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "668/668 [==============================] - 83s 124ms/step - loss: 1.4070 - accuracy: 0.2830 - val_loss: 1.3925 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "668/668 [==============================] - 83s 124ms/step - loss: 1.4075 - accuracy: 0.2789 - val_loss: 1.3925 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "668/668 [==============================] - 83s 124ms/step - loss: 1.4070 - accuracy: 0.2815 - val_loss: 1.3925 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "668/668 [==============================] - 83s 124ms/step - loss: 1.4066 - accuracy: 0.2830 - val_loss: 1.3925 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "668/668 [==============================] - 83s 124ms/step - loss: 1.4069 - accuracy: 0.2831 - val_loss: 1.3925 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../xception/xception_30epochs_33393.6_images_False_newWeights_True_lastLayerOnly/assets\n",
      "Test acc for xception: 0.242769\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training resnet for 0.4% of train size (aka 33393 images)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/668 [..............................] - ETA: 5:50 - loss: 1.3865 - accuracy: 0.2136WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0618s vs `on_train_batch_begin` time: 0.2006s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0618s vs `on_train_batch_end` time: 0.1892s). Check your callbacks.\n",
      "668/668 [==============================] - 46s 63ms/step - loss: 1.3867 - accuracy: 0.2340 - val_loss: 1.3854 - val_accuracy: 0.2812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "668/668 [==============================] - 38s 57ms/step - loss: 1.3867 - accuracy: 0.2300 - val_loss: 1.3854 - val_accuracy: 0.2812\n",
      "Epoch 3/30\n",
      "668/668 [==============================] - 39s 58ms/step - loss: 1.3867 - accuracy: 0.2303 - val_loss: 1.3854 - val_accuracy: 0.2812\n",
      "Epoch 4/30\n",
      "668/668 [==============================] - 39s 58ms/step - loss: 1.3869 - accuracy: 0.2320 - val_loss: 1.3854 - val_accuracy: 0.2812\n",
      "Epoch 5/30\n",
      "668/668 [==============================] - 39s 58ms/step - loss: 1.3869 - accuracy: 0.2325 - val_loss: 1.3854 - val_accuracy: 0.2812\n",
      "Epoch 6/30\n",
      "668/668 [==============================] - 39s 58ms/step - loss: 1.3869 - accuracy: 0.2290 - val_loss: 1.3854 - val_accuracy: 0.2812\n",
      "Epoch 7/30\n",
      "668/668 [==============================] - 39s 58ms/step - loss: 1.3869 - accuracy: 0.2302 - val_loss: 1.3854 - val_accuracy: 0.2812\n",
      "Epoch 8/30\n",
      "668/668 [==============================] - 39s 58ms/step - loss: 1.3869 - accuracy: 0.2288 - val_loss: 1.3854 - val_accuracy: 0.2812\n",
      "Epoch 9/30\n",
      "668/668 [==============================] - 39s 58ms/step - loss: 1.3869 - accuracy: 0.2294 - val_loss: 1.3854 - val_accuracy: 0.2812\n",
      "Epoch 10/30\n",
      "668/668 [==============================] - 39s 58ms/step - loss: 1.3867 - accuracy: 0.2289 - val_loss: 1.3854 - val_accuracy: 0.2812\n",
      "Epoch 11/30\n",
      "668/668 [==============================] - 39s 58ms/step - loss: 1.3869 - accuracy: 0.2276 - val_loss: 1.3854 - val_accuracy: 0.2812\n",
      "Epoch 12/30\n",
      "668/668 [==============================] - 39s 58ms/step - loss: 1.3868 - accuracy: 0.2277 - val_loss: 1.3854 - val_accuracy: 0.2812\n",
      "Epoch 13/30\n",
      "668/668 [==============================] - 39s 58ms/step - loss: 1.3869 - accuracy: 0.2288 - val_loss: 1.3854 - val_accuracy: 0.2812\n",
      "Epoch 14/30\n",
      "668/668 [==============================] - 39s 58ms/step - loss: 1.3868 - accuracy: 0.2301 - val_loss: 1.3854 - val_accuracy: 0.2812\n",
      "Epoch 15/30\n",
      "668/668 [==============================] - 39s 58ms/step - loss: 1.3867 - accuracy: 0.2321 - val_loss: 1.3854 - val_accuracy: 0.2812\n",
      "Epoch 16/30\n",
      "668/668 [==============================] - 39s 58ms/step - loss: 1.3867 - accuracy: 0.2306 - val_loss: 1.3854 - val_accuracy: 0.2812\n",
      "Epoch 17/30\n",
      "668/668 [==============================] - 38s 58ms/step - loss: 1.3867 - accuracy: 0.2328 - val_loss: 1.3854 - val_accuracy: 0.2812\n",
      "Epoch 18/30\n",
      "668/668 [==============================] - 39s 58ms/step - loss: 1.3868 - accuracy: 0.2296 - val_loss: 1.3854 - val_accuracy: 0.2812\n",
      "Epoch 19/30\n",
      "668/668 [==============================] - 38s 58ms/step - loss: 1.3868 - accuracy: 0.2302 - val_loss: 1.3854 - val_accuracy: 0.2812\n",
      "Epoch 20/30\n",
      "668/668 [==============================] - 39s 58ms/step - loss: 1.3869 - accuracy: 0.2272 - val_loss: 1.3854 - val_accuracy: 0.2812\n",
      "Epoch 21/30\n",
      "668/668 [==============================] - 39s 58ms/step - loss: 1.3866 - accuracy: 0.2310 - val_loss: 1.3854 - val_accuracy: 0.2812\n",
      "Epoch 22/30\n",
      "668/668 [==============================] - 39s 58ms/step - loss: 1.3867 - accuracy: 0.2315 - val_loss: 1.3854 - val_accuracy: 0.2812\n",
      "Epoch 23/30\n",
      "668/668 [==============================] - 39s 58ms/step - loss: 1.3869 - accuracy: 0.2297 - val_loss: 1.3854 - val_accuracy: 0.2812\n",
      "Epoch 24/30\n",
      "668/668 [==============================] - 39s 58ms/step - loss: 1.3869 - accuracy: 0.2299 - val_loss: 1.3854 - val_accuracy: 0.2812\n",
      "Epoch 25/30\n",
      "668/668 [==============================] - 39s 58ms/step - loss: 1.3867 - accuracy: 0.2264 - val_loss: 1.3854 - val_accuracy: 0.2812\n",
      "Epoch 26/30\n",
      "668/668 [==============================] - 39s 58ms/step - loss: 1.3868 - accuracy: 0.2277 - val_loss: 1.3854 - val_accuracy: 0.2812\n",
      "Epoch 27/30\n",
      "668/668 [==============================] - 39s 58ms/step - loss: 1.3867 - accuracy: 0.2305 - val_loss: 1.3854 - val_accuracy: 0.2812\n",
      "Epoch 28/30\n",
      "668/668 [==============================] - 39s 58ms/step - loss: 1.3867 - accuracy: 0.2315 - val_loss: 1.3854 - val_accuracy: 0.2812\n",
      "Epoch 29/30\n",
      "668/668 [==============================] - 39s 58ms/step - loss: 1.3868 - accuracy: 0.2302 - val_loss: 1.3854 - val_accuracy: 0.2812\n",
      "Epoch 30/30\n",
      "668/668 [==============================] - 39s 58ms/step - loss: 1.3870 - accuracy: 0.2242 - val_loss: 1.3854 - val_accuracy: 0.2812\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_33393.6_images_False_newWeights_True_lastLayerOnly/assets\n",
      "Test acc for resnet: 0.293388\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training opticnet for 0.4% of train size (aka 33393 images)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "668/668 [==============================] - 208s 297ms/step - loss: 289.0764 - accuracy: 0.1338 - val_loss: 217.3077 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "668/668 [==============================] - 194s 290ms/step - loss: 291.6837 - accuracy: 0.1355 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "668/668 [==============================] - 193s 290ms/step - loss: 289.8160 - accuracy: 0.1316 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "668/668 [==============================] - 194s 290ms/step - loss: 289.7472 - accuracy: 0.1359 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "668/668 [==============================] - 193s 290ms/step - loss: 290.3164 - accuracy: 0.1360 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "668/668 [==============================] - 193s 290ms/step - loss: 290.9508 - accuracy: 0.1356 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "668/668 [==============================] - 193s 289ms/step - loss: 289.2716 - accuracy: 0.1365 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "668/668 [==============================] - 193s 290ms/step - loss: 291.7561 - accuracy: 0.1330 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "668/668 [==============================] - 193s 290ms/step - loss: 290.3211 - accuracy: 0.1357 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "668/668 [==============================] - 193s 290ms/step - loss: 290.8450 - accuracy: 0.1331 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "668/668 [==============================] - 194s 290ms/step - loss: 289.0854 - accuracy: 0.1377 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "668/668 [==============================] - 193s 289ms/step - loss: 290.0211 - accuracy: 0.1360 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "668/668 [==============================] - 193s 290ms/step - loss: 289.0635 - accuracy: 0.1401 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "668/668 [==============================] - 193s 289ms/step - loss: 291.2037 - accuracy: 0.1333 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "668/668 [==============================] - 193s 290ms/step - loss: 289.4417 - accuracy: 0.1359 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "668/668 [==============================] - 194s 290ms/step - loss: 288.0396 - accuracy: 0.1385 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "668/668 [==============================] - 194s 290ms/step - loss: 289.2122 - accuracy: 0.1357 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "668/668 [==============================] - 193s 289ms/step - loss: 289.5106 - accuracy: 0.1382 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "668/668 [==============================] - 193s 290ms/step - loss: 290.1348 - accuracy: 0.1351 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "668/668 [==============================] - 193s 290ms/step - loss: 290.6021 - accuracy: 0.1353 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "668/668 [==============================] - 194s 290ms/step - loss: 289.6628 - accuracy: 0.1366 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "668/668 [==============================] - 193s 290ms/step - loss: 291.4691 - accuracy: 0.1329 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "668/668 [==============================] - 194s 290ms/step - loss: 290.1423 - accuracy: 0.1366 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "668/668 [==============================] - 193s 290ms/step - loss: 289.0857 - accuracy: 0.1339 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "668/668 [==============================] - 194s 290ms/step - loss: 290.6045 - accuracy: 0.1336 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "668/668 [==============================] - 194s 290ms/step - loss: 289.6808 - accuracy: 0.1372 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "668/668 [==============================] - 193s 290ms/step - loss: 290.8151 - accuracy: 0.1348 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "668/668 [==============================] - 193s 290ms/step - loss: 288.4911 - accuracy: 0.1404 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "668/668 [==============================] - 194s 290ms/step - loss: 290.2824 - accuracy: 0.1345 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "668/668 [==============================] - 193s 290ms/step - loss: 291.3597 - accuracy: 0.1351 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../opticnet/opticnet_30epochs_33393.6_images_False_newWeights_True_lastLayerOnly/assets\n",
      "Test acc for opticnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.49747292 0.50272813 0.49973564 0.49628598]\n",
      "Training xception for 0.5% of train size (aka 41742 images)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/835 [..............................] - ETA: 8:21 - loss: 1.3722 - accuracy: 0.4003 WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1237s vs `on_train_batch_begin` time: 0.1952s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1237s vs `on_train_batch_end` time: 0.2058s). Check your callbacks.\n",
      "835/835 [==============================] - 109s 126ms/step - loss: 1.3715 - accuracy: 0.4354 - val_loss: 1.3857 - val_accuracy: 0.2812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "835/835 [==============================] - 103s 124ms/step - loss: 1.3717 - accuracy: 0.4341 - val_loss: 1.3857 - val_accuracy: 0.2812\n",
      "Epoch 3/30\n",
      "835/835 [==============================] - 104s 124ms/step - loss: 1.3717 - accuracy: 0.4332 - val_loss: 1.3857 - val_accuracy: 0.2812\n",
      "Epoch 4/30\n",
      "835/835 [==============================] - 104s 124ms/step - loss: 1.3717 - accuracy: 0.4357 - val_loss: 1.3857 - val_accuracy: 0.2812\n",
      "Epoch 5/30\n",
      "835/835 [==============================] - 104s 124ms/step - loss: 1.3719 - accuracy: 0.4330 - val_loss: 1.3857 - val_accuracy: 0.2812\n",
      "Epoch 6/30\n",
      "835/835 [==============================] - 104s 124ms/step - loss: 1.3718 - accuracy: 0.4322 - val_loss: 1.3857 - val_accuracy: 0.2812\n",
      "Epoch 7/30\n",
      "835/835 [==============================] - 104s 124ms/step - loss: 1.3713 - accuracy: 0.4389 - val_loss: 1.3857 - val_accuracy: 0.2812\n",
      "Epoch 8/30\n",
      "835/835 [==============================] - 104s 124ms/step - loss: 1.3717 - accuracy: 0.4351 - val_loss: 1.3857 - val_accuracy: 0.2812\n",
      "Epoch 9/30\n",
      "835/835 [==============================] - 104s 124ms/step - loss: 1.3718 - accuracy: 0.4341 - val_loss: 1.3857 - val_accuracy: 0.2812\n",
      "Epoch 10/30\n",
      "835/835 [==============================] - 104s 124ms/step - loss: 1.3718 - accuracy: 0.4375 - val_loss: 1.3857 - val_accuracy: 0.2812\n",
      "Epoch 11/30\n",
      "835/835 [==============================] - 104s 124ms/step - loss: 1.3714 - accuracy: 0.4394 - val_loss: 1.3857 - val_accuracy: 0.2812\n",
      "Epoch 12/30\n",
      "835/835 [==============================] - 104s 124ms/step - loss: 1.3712 - accuracy: 0.4410 - val_loss: 1.3857 - val_accuracy: 0.2812\n",
      "Epoch 13/30\n",
      "835/835 [==============================] - 104s 124ms/step - loss: 1.3716 - accuracy: 0.4356 - val_loss: 1.3857 - val_accuracy: 0.2812\n",
      "Epoch 14/30\n",
      "835/835 [==============================] - 104s 124ms/step - loss: 1.3716 - accuracy: 0.4358 - val_loss: 1.3857 - val_accuracy: 0.2812\n",
      "Epoch 15/30\n",
      "835/835 [==============================] - 104s 124ms/step - loss: 1.3717 - accuracy: 0.4336 - val_loss: 1.3857 - val_accuracy: 0.2812\n",
      "Epoch 16/30\n",
      "835/835 [==============================] - 104s 124ms/step - loss: 1.3718 - accuracy: 0.4329 - val_loss: 1.3857 - val_accuracy: 0.2812\n",
      "Epoch 17/30\n",
      "835/835 [==============================] - 104s 124ms/step - loss: 1.3714 - accuracy: 0.4378 - val_loss: 1.3857 - val_accuracy: 0.2812\n",
      "Epoch 18/30\n",
      "835/835 [==============================] - 104s 124ms/step - loss: 1.3720 - accuracy: 0.4288 - val_loss: 1.3857 - val_accuracy: 0.2812\n",
      "Epoch 19/30\n",
      "835/835 [==============================] - 104s 124ms/step - loss: 1.3716 - accuracy: 0.4356 - val_loss: 1.3857 - val_accuracy: 0.2812\n",
      "Epoch 20/30\n",
      "835/835 [==============================] - 104s 124ms/step - loss: 1.3717 - accuracy: 0.4358 - val_loss: 1.3857 - val_accuracy: 0.2812\n",
      "Epoch 21/30\n",
      "835/835 [==============================] - 104s 124ms/step - loss: 1.3720 - accuracy: 0.4323 - val_loss: 1.3857 - val_accuracy: 0.2812\n",
      "Epoch 22/30\n",
      "835/835 [==============================] - 104s 124ms/step - loss: 1.3719 - accuracy: 0.4379 - val_loss: 1.3857 - val_accuracy: 0.2812\n",
      "Epoch 23/30\n",
      "835/835 [==============================] - 104s 124ms/step - loss: 1.3717 - accuracy: 0.4370 - val_loss: 1.3857 - val_accuracy: 0.2812\n",
      "Epoch 24/30\n",
      "835/835 [==============================] - 104s 124ms/step - loss: 1.3717 - accuracy: 0.4338 - val_loss: 1.3857 - val_accuracy: 0.2812\n",
      "Epoch 25/30\n",
      "835/835 [==============================] - 104s 124ms/step - loss: 1.3718 - accuracy: 0.4350 - val_loss: 1.3857 - val_accuracy: 0.2812\n",
      "Epoch 26/30\n",
      "835/835 [==============================] - 104s 124ms/step - loss: 1.3714 - accuracy: 0.4390 - val_loss: 1.3857 - val_accuracy: 0.2812\n",
      "Epoch 27/30\n",
      "835/835 [==============================] - 104s 124ms/step - loss: 1.3717 - accuracy: 0.4368 - val_loss: 1.3857 - val_accuracy: 0.2812\n",
      "Epoch 28/30\n",
      "835/835 [==============================] - 104s 124ms/step - loss: 1.3714 - accuracy: 0.4381 - val_loss: 1.3857 - val_accuracy: 0.2812\n",
      "Epoch 29/30\n",
      "835/835 [==============================] - 104s 124ms/step - loss: 1.3717 - accuracy: 0.4343 - val_loss: 1.3857 - val_accuracy: 0.2812\n",
      "Epoch 30/30\n",
      "835/835 [==============================] - 104s 124ms/step - loss: 1.3718 - accuracy: 0.4317 - val_loss: 1.3857 - val_accuracy: 0.2812\n",
      "INFO:tensorflow:Assets written to: ../xception/xception_30epochs_41742.0_images_False_newWeights_True_lastLayerOnly/assets\n",
      "Test acc for xception: 0.259298\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training resnet for 0.5% of train size (aka 41742 images)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/835 [..............................] - ETA: 7:34 - loss: 1.3829 - accuracy: 0.3097WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0613s vs `on_train_batch_begin` time: 0.2026s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0613s vs `on_train_batch_end` time: 0.2034s). Check your callbacks.\n",
      "835/835 [==============================] - 57s 62ms/step - loss: 1.3838 - accuracy: 0.2963 - val_loss: 1.3835 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "835/835 [==============================] - 48s 58ms/step - loss: 1.3841 - accuracy: 0.2958 - val_loss: 1.3835 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "835/835 [==============================] - 48s 58ms/step - loss: 1.3840 - accuracy: 0.2914 - val_loss: 1.3835 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "835/835 [==============================] - 48s 58ms/step - loss: 1.3840 - accuracy: 0.2953 - val_loss: 1.3835 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "835/835 [==============================] - 48s 58ms/step - loss: 1.3840 - accuracy: 0.3016 - val_loss: 1.3835 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "835/835 [==============================] - 48s 58ms/step - loss: 1.3840 - accuracy: 0.2958 - val_loss: 1.3835 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "835/835 [==============================] - 48s 58ms/step - loss: 1.3840 - accuracy: 0.2941 - val_loss: 1.3835 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "835/835 [==============================] - 48s 58ms/step - loss: 1.3841 - accuracy: 0.2958 - val_loss: 1.3835 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "835/835 [==============================] - 48s 58ms/step - loss: 1.3841 - accuracy: 0.2963 - val_loss: 1.3835 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "835/835 [==============================] - 48s 58ms/step - loss: 1.3840 - accuracy: 0.2959 - val_loss: 1.3835 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "835/835 [==============================] - 48s 58ms/step - loss: 1.3839 - accuracy: 0.2927 - val_loss: 1.3835 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "835/835 [==============================] - 48s 58ms/step - loss: 1.3841 - accuracy: 0.2968 - val_loss: 1.3835 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "835/835 [==============================] - 48s 58ms/step - loss: 1.3840 - accuracy: 0.2970 - val_loss: 1.3835 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "835/835 [==============================] - 48s 58ms/step - loss: 1.3840 - accuracy: 0.2934 - val_loss: 1.3835 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "835/835 [==============================] - 48s 58ms/step - loss: 1.3840 - accuracy: 0.2953 - val_loss: 1.3835 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "835/835 [==============================] - 48s 58ms/step - loss: 1.3840 - accuracy: 0.2954 - val_loss: 1.3835 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "835/835 [==============================] - 48s 58ms/step - loss: 1.3840 - accuracy: 0.2955 - val_loss: 1.3835 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "835/835 [==============================] - 48s 58ms/step - loss: 1.3841 - accuracy: 0.2961 - val_loss: 1.3835 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "835/835 [==============================] - 48s 58ms/step - loss: 1.3840 - accuracy: 0.3003 - val_loss: 1.3835 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "835/835 [==============================] - 48s 58ms/step - loss: 1.3840 - accuracy: 0.2954 - val_loss: 1.3835 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "835/835 [==============================] - 48s 58ms/step - loss: 1.3841 - accuracy: 0.2962 - val_loss: 1.3835 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "835/835 [==============================] - 48s 58ms/step - loss: 1.3841 - accuracy: 0.2943 - val_loss: 1.3835 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "835/835 [==============================] - 48s 58ms/step - loss: 1.3839 - accuracy: 0.3008 - val_loss: 1.3835 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "835/835 [==============================] - 48s 58ms/step - loss: 1.3840 - accuracy: 0.2970 - val_loss: 1.3835 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "835/835 [==============================] - 48s 58ms/step - loss: 1.3839 - accuracy: 0.2994 - val_loss: 1.3835 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "835/835 [==============================] - 48s 58ms/step - loss: 1.3840 - accuracy: 0.2928 - val_loss: 1.3835 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "835/835 [==============================] - 48s 58ms/step - loss: 1.3840 - accuracy: 0.2943 - val_loss: 1.3835 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "835/835 [==============================] - 48s 58ms/step - loss: 1.3841 - accuracy: 0.2960 - val_loss: 1.3835 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "835/835 [==============================] - 48s 58ms/step - loss: 1.3840 - accuracy: 0.2982 - val_loss: 1.3835 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "835/835 [==============================] - 48s 58ms/step - loss: 1.3842 - accuracy: 0.2919 - val_loss: 1.3835 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_41742.0_images_False_newWeights_True_lastLayerOnly/assets\n",
      "Test acc for resnet: 0.333678\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training opticnet for 0.5% of train size (aka 41742 images)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "835/835 [==============================] - 254s 297ms/step - loss: 289.8649 - accuracy: 0.1353 - val_loss: 217.3077 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "835/835 [==============================] - 242s 289ms/step - loss: 288.9312 - accuracy: 0.1374 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "835/835 [==============================] - 242s 290ms/step - loss: 290.2527 - accuracy: 0.1341 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "835/835 [==============================] - 242s 290ms/step - loss: 290.4711 - accuracy: 0.1325 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "835/835 [==============================] - 242s 290ms/step - loss: 290.5204 - accuracy: 0.1329 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "835/835 [==============================] - 242s 290ms/step - loss: 288.4061 - accuracy: 0.1375 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "835/835 [==============================] - 242s 289ms/step - loss: 289.8166 - accuracy: 0.1351 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "835/835 [==============================] - 242s 290ms/step - loss: 289.0768 - accuracy: 0.1374 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "835/835 [==============================] - 242s 289ms/step - loss: 290.7179 - accuracy: 0.1343 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "835/835 [==============================] - 242s 290ms/step - loss: 290.6327 - accuracy: 0.1331 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "835/835 [==============================] - 242s 289ms/step - loss: 289.7996 - accuracy: 0.1368 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "835/835 [==============================] - 242s 289ms/step - loss: 288.6416 - accuracy: 0.1376 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "835/835 [==============================] - 242s 289ms/step - loss: 290.6122 - accuracy: 0.1342 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "835/835 [==============================] - 242s 290ms/step - loss: 289.1233 - accuracy: 0.1390 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "835/835 [==============================] - 242s 289ms/step - loss: 288.4781 - accuracy: 0.1384 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "835/835 [==============================] - 242s 290ms/step - loss: 290.7862 - accuracy: 0.1349 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "835/835 [==============================] - 242s 290ms/step - loss: 288.4342 - accuracy: 0.1360 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "835/835 [==============================] - 242s 290ms/step - loss: 290.3411 - accuracy: 0.1368 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "835/835 [==============================] - 242s 289ms/step - loss: 291.1649 - accuracy: 0.1334 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "835/835 [==============================] - 242s 290ms/step - loss: 289.1852 - accuracy: 0.1360 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "835/835 [==============================] - 242s 290ms/step - loss: 291.1303 - accuracy: 0.1339 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "835/835 [==============================] - 242s 289ms/step - loss: 290.8517 - accuracy: 0.1363 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "835/835 [==============================] - 242s 290ms/step - loss: 291.4400 - accuracy: 0.1337 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "835/835 [==============================] - 242s 290ms/step - loss: 288.7664 - accuracy: 0.1380 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "835/835 [==============================] - 242s 290ms/step - loss: 289.8942 - accuracy: 0.1364 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "835/835 [==============================] - 242s 290ms/step - loss: 290.2522 - accuracy: 0.1356 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "835/835 [==============================] - 242s 289ms/step - loss: 290.0009 - accuracy: 0.1349 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "835/835 [==============================] - 242s 290ms/step - loss: 289.4043 - accuracy: 0.1376 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "835/835 [==============================] - 242s 290ms/step - loss: 290.2862 - accuracy: 0.1370 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "835/835 [==============================] - 242s 290ms/step - loss: 290.0511 - accuracy: 0.1354 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../opticnet/opticnet_30epochs_41742.0_images_False_newWeights_True_lastLayerOnly/assets\n",
      "Test acc for opticnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.59893597 0.60188147 0.60107508 0.59366295]\n",
      "Training xception for 0.6% of train size (aka 50090 images)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "   6/1002 [..............................] - ETA: 11:02 - loss: 1.3790 - accuracy: 0.4182WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1183s vs `on_train_batch_begin` time: 0.1940s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1183s vs `on_train_batch_end` time: 0.2623s). Check your callbacks.\n",
      "1002/1002 [==============================] - 133s 127ms/step - loss: 1.3779 - accuracy: 0.4102 - val_loss: 1.3866 - val_accuracy: 0.3125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "1002/1002 [==============================] - 124s 124ms/step - loss: 1.3779 - accuracy: 0.4112 - val_loss: 1.3866 - val_accuracy: 0.3125\n",
      "Epoch 3/30\n",
      "1002/1002 [==============================] - 125s 124ms/step - loss: 1.3780 - accuracy: 0.4082 - val_loss: 1.3866 - val_accuracy: 0.3125\n",
      "Epoch 4/30\n",
      "1002/1002 [==============================] - 125s 125ms/step - loss: 1.3780 - accuracy: 0.4111 - val_loss: 1.3866 - val_accuracy: 0.3125\n",
      "Epoch 5/30\n",
      "1002/1002 [==============================] - 125s 125ms/step - loss: 1.3780 - accuracy: 0.4117 - val_loss: 1.3866 - val_accuracy: 0.3125\n",
      "Epoch 6/30\n",
      "1002/1002 [==============================] - 125s 125ms/step - loss: 1.3778 - accuracy: 0.4124 - val_loss: 1.3866 - val_accuracy: 0.3125\n",
      "Epoch 7/30\n",
      "1002/1002 [==============================] - 125s 124ms/step - loss: 1.3778 - accuracy: 0.4127 - val_loss: 1.3866 - val_accuracy: 0.3125\n",
      "Epoch 8/30\n",
      "1002/1002 [==============================] - 125s 124ms/step - loss: 1.3782 - accuracy: 0.4095 - val_loss: 1.3866 - val_accuracy: 0.3125\n",
      "Epoch 9/30\n",
      "1002/1002 [==============================] - 125s 124ms/step - loss: 1.3781 - accuracy: 0.4124 - val_loss: 1.3866 - val_accuracy: 0.3125\n",
      "Epoch 10/30\n",
      "1002/1002 [==============================] - 125s 125ms/step - loss: 1.3777 - accuracy: 0.4102 - val_loss: 1.3866 - val_accuracy: 0.3125\n",
      "Epoch 11/30\n",
      "1002/1002 [==============================] - 125s 124ms/step - loss: 1.3779 - accuracy: 0.4141 - val_loss: 1.3866 - val_accuracy: 0.3125\n",
      "Epoch 12/30\n",
      "1002/1002 [==============================] - 125s 124ms/step - loss: 1.3783 - accuracy: 0.4116 - val_loss: 1.3866 - val_accuracy: 0.3125\n",
      "Epoch 13/30\n",
      "1002/1002 [==============================] - 125s 125ms/step - loss: 1.3779 - accuracy: 0.4136 - val_loss: 1.3866 - val_accuracy: 0.3125\n",
      "Epoch 14/30\n",
      "1002/1002 [==============================] - 125s 124ms/step - loss: 1.3778 - accuracy: 0.4118 - val_loss: 1.3866 - val_accuracy: 0.3125\n",
      "Epoch 15/30\n",
      "1002/1002 [==============================] - 125s 125ms/step - loss: 1.3782 - accuracy: 0.4078 - val_loss: 1.3866 - val_accuracy: 0.3125\n",
      "Epoch 16/30\n",
      "1002/1002 [==============================] - 125s 125ms/step - loss: 1.3777 - accuracy: 0.4117 - val_loss: 1.3866 - val_accuracy: 0.3125\n",
      "Epoch 17/30\n",
      "1002/1002 [==============================] - 125s 125ms/step - loss: 1.3779 - accuracy: 0.4124 - val_loss: 1.3866 - val_accuracy: 0.3125\n",
      "Epoch 18/30\n",
      "1002/1002 [==============================] - 125s 125ms/step - loss: 1.3780 - accuracy: 0.4106 - val_loss: 1.3866 - val_accuracy: 0.3125\n",
      "Epoch 19/30\n",
      "1002/1002 [==============================] - 125s 125ms/step - loss: 1.3779 - accuracy: 0.4151 - val_loss: 1.3866 - val_accuracy: 0.3125\n",
      "Epoch 20/30\n",
      "1002/1002 [==============================] - 125s 125ms/step - loss: 1.3781 - accuracy: 0.4123 - val_loss: 1.3866 - val_accuracy: 0.3125\n",
      "Epoch 21/30\n",
      "1002/1002 [==============================] - 125s 125ms/step - loss: 1.3783 - accuracy: 0.4121 - val_loss: 1.3866 - val_accuracy: 0.3125\n",
      "Epoch 22/30\n",
      "1002/1002 [==============================] - 125s 125ms/step - loss: 1.3783 - accuracy: 0.4108 - val_loss: 1.3866 - val_accuracy: 0.3125\n",
      "Epoch 23/30\n",
      "1002/1002 [==============================] - 125s 125ms/step - loss: 1.3781 - accuracy: 0.4087 - val_loss: 1.3866 - val_accuracy: 0.3125\n",
      "Epoch 24/30\n",
      "1002/1002 [==============================] - 125s 124ms/step - loss: 1.3780 - accuracy: 0.4111 - val_loss: 1.3866 - val_accuracy: 0.3125\n",
      "Epoch 25/30\n",
      "1002/1002 [==============================] - 125s 124ms/step - loss: 1.3780 - accuracy: 0.4098 - val_loss: 1.3866 - val_accuracy: 0.3125\n",
      "Epoch 26/30\n",
      "1002/1002 [==============================] - 125s 124ms/step - loss: 1.3781 - accuracy: 0.4103 - val_loss: 1.3866 - val_accuracy: 0.3125\n",
      "Epoch 27/30\n",
      "1002/1002 [==============================] - 125s 124ms/step - loss: 1.3779 - accuracy: 0.4084 - val_loss: 1.3866 - val_accuracy: 0.3125\n",
      "Epoch 28/30\n",
      "1002/1002 [==============================] - 125s 124ms/step - loss: 1.3779 - accuracy: 0.4121 - val_loss: 1.3866 - val_accuracy: 0.3125\n",
      "Epoch 29/30\n",
      "1002/1002 [==============================] - 125s 124ms/step - loss: 1.3781 - accuracy: 0.4090 - val_loss: 1.3866 - val_accuracy: 0.3125\n",
      "Epoch 30/30\n",
      "1002/1002 [==============================] - 125s 124ms/step - loss: 1.3780 - accuracy: 0.4125 - val_loss: 1.3866 - val_accuracy: 0.3125\n",
      "INFO:tensorflow:Assets written to: ../xception/xception_30epochs_50090.4_images_False_newWeights_True_lastLayerOnly/assets\n",
      "Test acc for xception: 0.253099\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training resnet for 0.6% of train size (aka 50090 images)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "   6/1002 [..............................] - ETA: 9:02 - loss: 1.3855 - accuracy: 0.2739 WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0617s vs `on_train_batch_begin` time: 0.2026s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0617s vs `on_train_batch_end` time: 0.2004s). Check your callbacks.\n",
      "1002/1002 [==============================] - 65s 61ms/step - loss: 1.3860 - accuracy: 0.2942 - val_loss: 1.3831 - val_accuracy: 0.2188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "1002/1002 [==============================] - 58s 58ms/step - loss: 1.3862 - accuracy: 0.2919 - val_loss: 1.3831 - val_accuracy: 0.2188\n",
      "Epoch 3/30\n",
      "1002/1002 [==============================] - 58s 58ms/step - loss: 1.3862 - accuracy: 0.2931 - val_loss: 1.3831 - val_accuracy: 0.2188\n",
      "Epoch 4/30\n",
      "1002/1002 [==============================] - 58s 58ms/step - loss: 1.3861 - accuracy: 0.2930 - val_loss: 1.3831 - val_accuracy: 0.2188\n",
      "Epoch 5/30\n",
      "1002/1002 [==============================] - 58s 58ms/step - loss: 1.3861 - accuracy: 0.2929 - val_loss: 1.3831 - val_accuracy: 0.2188\n",
      "Epoch 6/30\n",
      "1002/1002 [==============================] - 58s 58ms/step - loss: 1.3861 - accuracy: 0.2948 - val_loss: 1.3831 - val_accuracy: 0.2188\n",
      "Epoch 7/30\n",
      "1002/1002 [==============================] - 58s 58ms/step - loss: 1.3860 - accuracy: 0.2960 - val_loss: 1.3831 - val_accuracy: 0.2188\n",
      "Epoch 8/30\n",
      "1002/1002 [==============================] - 58s 58ms/step - loss: 1.3860 - accuracy: 0.2956 - val_loss: 1.3831 - val_accuracy: 0.2188\n",
      "Epoch 9/30\n",
      "1002/1002 [==============================] - 58s 58ms/step - loss: 1.3861 - accuracy: 0.2934 - val_loss: 1.3831 - val_accuracy: 0.2188\n",
      "Epoch 10/30\n",
      "1002/1002 [==============================] - 58s 58ms/step - loss: 1.3860 - accuracy: 0.2935 - val_loss: 1.3831 - val_accuracy: 0.2188\n",
      "Epoch 11/30\n",
      "1002/1002 [==============================] - 58s 58ms/step - loss: 1.3861 - accuracy: 0.2942 - val_loss: 1.3831 - val_accuracy: 0.2188\n",
      "Epoch 12/30\n",
      "1002/1002 [==============================] - 58s 58ms/step - loss: 1.3861 - accuracy: 0.2917 - val_loss: 1.3831 - val_accuracy: 0.2188\n",
      "Epoch 13/30\n",
      "1002/1002 [==============================] - 58s 58ms/step - loss: 1.3861 - accuracy: 0.2907 - val_loss: 1.3831 - val_accuracy: 0.2188\n",
      "Epoch 14/30\n",
      "1002/1002 [==============================] - 58s 58ms/step - loss: 1.3859 - accuracy: 0.2970 - val_loss: 1.3831 - val_accuracy: 0.2188\n",
      "Epoch 15/30\n",
      "1002/1002 [==============================] - 58s 58ms/step - loss: 1.3861 - accuracy: 0.2938 - val_loss: 1.3831 - val_accuracy: 0.2188\n",
      "Epoch 16/30\n",
      "1002/1002 [==============================] - 58s 58ms/step - loss: 1.3862 - accuracy: 0.2898 - val_loss: 1.3831 - val_accuracy: 0.2188\n",
      "Epoch 17/30\n",
      "1002/1002 [==============================] - 58s 58ms/step - loss: 1.3860 - accuracy: 0.2933 - val_loss: 1.3831 - val_accuracy: 0.2188\n",
      "Epoch 18/30\n",
      "1002/1002 [==============================] - 58s 58ms/step - loss: 1.3860 - accuracy: 0.2954 - val_loss: 1.3831 - val_accuracy: 0.2188\n",
      "Epoch 19/30\n",
      "1002/1002 [==============================] - 58s 58ms/step - loss: 1.3861 - accuracy: 0.2970 - val_loss: 1.3831 - val_accuracy: 0.2188\n",
      "Epoch 20/30\n",
      "1002/1002 [==============================] - 58s 58ms/step - loss: 1.3860 - accuracy: 0.2948 - val_loss: 1.3831 - val_accuracy: 0.2188\n",
      "Epoch 21/30\n",
      "1002/1002 [==============================] - 58s 58ms/step - loss: 1.3861 - accuracy: 0.2924 - val_loss: 1.3831 - val_accuracy: 0.2188\n",
      "Epoch 22/30\n",
      "1002/1002 [==============================] - 58s 58ms/step - loss: 1.3861 - accuracy: 0.2935 - val_loss: 1.3831 - val_accuracy: 0.2188\n",
      "Epoch 23/30\n",
      "1002/1002 [==============================] - 58s 58ms/step - loss: 1.3859 - accuracy: 0.2947 - val_loss: 1.3831 - val_accuracy: 0.2188\n",
      "Epoch 24/30\n",
      "1002/1002 [==============================] - 58s 58ms/step - loss: 1.3860 - accuracy: 0.2923 - val_loss: 1.3831 - val_accuracy: 0.2188\n",
      "Epoch 25/30\n",
      "1002/1002 [==============================] - 58s 58ms/step - loss: 1.3861 - accuracy: 0.2937 - val_loss: 1.3831 - val_accuracy: 0.2188\n",
      "Epoch 26/30\n",
      "1002/1002 [==============================] - 58s 58ms/step - loss: 1.3861 - accuracy: 0.2940 - val_loss: 1.3831 - val_accuracy: 0.2188\n",
      "Epoch 27/30\n",
      "1002/1002 [==============================] - 58s 58ms/step - loss: 1.3861 - accuracy: 0.2921 - val_loss: 1.3831 - val_accuracy: 0.2188\n",
      "Epoch 28/30\n",
      "1002/1002 [==============================] - 58s 58ms/step - loss: 1.3860 - accuracy: 0.2940 - val_loss: 1.3831 - val_accuracy: 0.2188\n",
      "Epoch 29/30\n",
      "1002/1002 [==============================] - 58s 58ms/step - loss: 1.3861 - accuracy: 0.2928 - val_loss: 1.3831 - val_accuracy: 0.2188\n",
      "Epoch 30/30\n",
      "1002/1002 [==============================] - 58s 58ms/step - loss: 1.3860 - accuracy: 0.2937 - val_loss: 1.3831 - val_accuracy: 0.2188\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_50090.4_images_False_newWeights_True_lastLayerOnly/assets\n",
      "Test acc for resnet: 0.302686\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training opticnet for 0.6% of train size (aka 50090 images)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1002/1002 [==============================] - 303s 296ms/step - loss: 289.2169 - accuracy: 0.1359 - val_loss: 217.3077 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "1002/1002 [==============================] - 290s 290ms/step - loss: 289.7912 - accuracy: 0.1333 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "1002/1002 [==============================] - 290s 290ms/step - loss: 288.8716 - accuracy: 0.1363 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "1002/1002 [==============================] - 290s 290ms/step - loss: 289.4641 - accuracy: 0.1362 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "1002/1002 [==============================] - 290s 290ms/step - loss: 290.3223 - accuracy: 0.1342 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "1002/1002 [==============================] - 290s 290ms/step - loss: 289.4682 - accuracy: 0.1347 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "1002/1002 [==============================] - 290s 290ms/step - loss: 288.4618 - accuracy: 0.1376 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "1002/1002 [==============================] - 290s 290ms/step - loss: 288.1618 - accuracy: 0.1360 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "1002/1002 [==============================] - 290s 290ms/step - loss: 288.1583 - accuracy: 0.1362 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "1002/1002 [==============================] - 290s 290ms/step - loss: 289.0729 - accuracy: 0.1343 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "1002/1002 [==============================] - 290s 290ms/step - loss: 289.5167 - accuracy: 0.1339 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "1002/1002 [==============================] - 290s 290ms/step - loss: 289.2528 - accuracy: 0.1380 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "1002/1002 [==============================] - 290s 290ms/step - loss: 289.1531 - accuracy: 0.1352 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "1002/1002 [==============================] - 290s 290ms/step - loss: 286.2836 - accuracy: 0.1391 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "1002/1002 [==============================] - 290s 290ms/step - loss: 288.6001 - accuracy: 0.1356 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "1002/1002 [==============================] - 290s 290ms/step - loss: 288.8635 - accuracy: 0.1357 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "1002/1002 [==============================] - 290s 290ms/step - loss: 288.1820 - accuracy: 0.1356 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "1002/1002 [==============================] - 290s 290ms/step - loss: 289.5064 - accuracy: 0.1352 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "1002/1002 [==============================] - 290s 290ms/step - loss: 289.2723 - accuracy: 0.1360 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "1002/1002 [==============================] - 290s 290ms/step - loss: 288.9125 - accuracy: 0.1370 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "1002/1002 [==============================] - 290s 290ms/step - loss: 289.2381 - accuracy: 0.1342 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "1002/1002 [==============================] - 290s 290ms/step - loss: 289.4908 - accuracy: 0.1340 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "1002/1002 [==============================] - 290s 290ms/step - loss: 288.3427 - accuracy: 0.1366 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "1002/1002 [==============================] - 291s 290ms/step - loss: 288.8611 - accuracy: 0.1381 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "1002/1002 [==============================] - 290s 290ms/step - loss: 291.0896 - accuracy: 0.1347 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "1002/1002 [==============================] - 290s 290ms/step - loss: 288.1132 - accuracy: 0.1365 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "1002/1002 [==============================] - 290s 290ms/step - loss: 288.6871 - accuracy: 0.1351 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "1002/1002 [==============================] - 290s 290ms/step - loss: 289.1261 - accuracy: 0.1364 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "1002/1002 [==============================] - 290s 290ms/step - loss: 289.4170 - accuracy: 0.1350 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "1002/1002 [==============================] - 290s 290ms/step - loss: 287.8871 - accuracy: 0.1379 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../opticnet/opticnet_30epochs_50090.4_images_False_newWeights_True_lastLayerOnly/assets\n",
      "Test acc for opticnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.74755843 0.75183443 0.74955939 0.75011606]\n",
      "Training xception for 0.75% of train size (aka 62613 images)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "   6/1253 [..............................] - ETA: 12:30 - loss: 1.3855 - accuracy: 0.1194WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1225s vs `on_train_batch_begin` time: 0.1960s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1225s vs `on_train_batch_end` time: 0.2034s). Check your callbacks.\n",
      "1253/1253 [==============================] - 159s 124ms/step - loss: 1.3857 - accuracy: 0.1374 - val_loss: 1.3863 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "1253/1253 [==============================] - 154s 123ms/step - loss: 1.3856 - accuracy: 0.1404 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "1253/1253 [==============================] - 155s 123ms/step - loss: 1.3856 - accuracy: 0.1403 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "1253/1253 [==============================] - 154s 123ms/step - loss: 1.3857 - accuracy: 0.1393 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "1253/1253 [==============================] - 155s 123ms/step - loss: 1.3857 - accuracy: 0.1394 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "1253/1253 [==============================] - 155s 123ms/step - loss: 1.3857 - accuracy: 0.1413 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "1253/1253 [==============================] - 154s 123ms/step - loss: 1.3856 - accuracy: 0.1392 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "1253/1253 [==============================] - 154s 123ms/step - loss: 1.3857 - accuracy: 0.1405 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "1253/1253 [==============================] - 155s 123ms/step - loss: 1.3856 - accuracy: 0.1399 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "1253/1253 [==============================] - 155s 123ms/step - loss: 1.3856 - accuracy: 0.1373 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "1253/1253 [==============================] - 154s 123ms/step - loss: 1.3857 - accuracy: 0.1373 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "1253/1253 [==============================] - 154s 123ms/step - loss: 1.3856 - accuracy: 0.1406 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "1253/1253 [==============================] - 155s 123ms/step - loss: 1.3856 - accuracy: 0.1398 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "1253/1253 [==============================] - 155s 123ms/step - loss: 1.3856 - accuracy: 0.1384 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "1253/1253 [==============================] - 154s 123ms/step - loss: 1.3856 - accuracy: 0.1413 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "1253/1253 [==============================] - 154s 123ms/step - loss: 1.3856 - accuracy: 0.1384 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "1253/1253 [==============================] - 154s 123ms/step - loss: 1.3855 - accuracy: 0.1382 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "1253/1253 [==============================] - 154s 123ms/step - loss: 1.3856 - accuracy: 0.1389 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "1253/1253 [==============================] - 154s 123ms/step - loss: 1.3857 - accuracy: 0.1400 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "1253/1253 [==============================] - 154s 123ms/step - loss: 1.3855 - accuracy: 0.1408 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "1253/1253 [==============================] - 154s 123ms/step - loss: 1.3855 - accuracy: 0.1433 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "1253/1253 [==============================] - 154s 123ms/step - loss: 1.3856 - accuracy: 0.1409 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "1253/1253 [==============================] - 154s 123ms/step - loss: 1.3857 - accuracy: 0.1371 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "1253/1253 [==============================] - 154s 123ms/step - loss: 1.3856 - accuracy: 0.1387 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "1253/1253 [==============================] - 154s 123ms/step - loss: 1.3856 - accuracy: 0.1402 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "1253/1253 [==============================] - 154s 123ms/step - loss: 1.3856 - accuracy: 0.1401 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "1253/1253 [==============================] - 154s 123ms/step - loss: 1.3856 - accuracy: 0.1396 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "1253/1253 [==============================] - 154s 123ms/step - loss: 1.3857 - accuracy: 0.1374 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "1253/1253 [==============================] - 154s 123ms/step - loss: 1.3857 - accuracy: 0.1397 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "1253/1253 [==============================] - 154s 123ms/step - loss: 1.3856 - accuracy: 0.1393 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../xception/xception_30epochs_62613.0_images_False_newWeights_True_lastLayerOnly/assets\n",
      "Test acc for xception: 0.247934\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training resnet for 0.75% of train size (aka 62613 images)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "   6/1253 [..............................] - ETA: 10:35 - loss: 1.3898 - accuracy: 0.2223WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0617s vs `on_train_batch_begin` time: 0.1971s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0617s vs `on_train_batch_end` time: 0.1767s). Check your callbacks.\n",
      "1253/1253 [==============================] - 79s 60ms/step - loss: 1.3923 - accuracy: 0.1664 - val_loss: 1.3892 - val_accuracy: 0.1875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "1253/1253 [==============================] - 72s 57ms/step - loss: 1.3924 - accuracy: 0.1632 - val_loss: 1.3892 - val_accuracy: 0.1875\n",
      "Epoch 3/30\n",
      "1253/1253 [==============================] - 72s 57ms/step - loss: 1.3922 - accuracy: 0.1667 - val_loss: 1.3892 - val_accuracy: 0.1875\n",
      "Epoch 4/30\n",
      "1253/1253 [==============================] - 72s 57ms/step - loss: 1.3923 - accuracy: 0.1650 - val_loss: 1.3892 - val_accuracy: 0.1875\n",
      "Epoch 5/30\n",
      "1253/1253 [==============================] - 72s 57ms/step - loss: 1.3924 - accuracy: 0.1626 - val_loss: 1.3892 - val_accuracy: 0.1875\n",
      "Epoch 6/30\n",
      "1253/1253 [==============================] - 72s 58ms/step - loss: 1.3925 - accuracy: 0.1637 - val_loss: 1.3892 - val_accuracy: 0.1875\n",
      "Epoch 7/30\n",
      "1253/1253 [==============================] - 72s 57ms/step - loss: 1.3925 - accuracy: 0.1630 - val_loss: 1.3892 - val_accuracy: 0.1875\n",
      "Epoch 8/30\n",
      "1253/1253 [==============================] - 72s 57ms/step - loss: 1.3923 - accuracy: 0.1658 - val_loss: 1.3892 - val_accuracy: 0.1875\n",
      "Epoch 9/30\n",
      "1253/1253 [==============================] - 72s 58ms/step - loss: 1.3925 - accuracy: 0.1651 - val_loss: 1.3892 - val_accuracy: 0.1875\n",
      "Epoch 10/30\n",
      "1253/1253 [==============================] - 72s 58ms/step - loss: 1.3923 - accuracy: 0.1657 - val_loss: 1.3892 - val_accuracy: 0.1875\n",
      "Epoch 11/30\n",
      "1253/1253 [==============================] - 72s 58ms/step - loss: 1.3925 - accuracy: 0.1619 - val_loss: 1.3892 - val_accuracy: 0.1875\n",
      "Epoch 12/30\n",
      "1253/1253 [==============================] - 72s 58ms/step - loss: 1.3924 - accuracy: 0.1639 - val_loss: 1.3892 - val_accuracy: 0.1875\n",
      "Epoch 13/30\n",
      "1253/1253 [==============================] - 72s 57ms/step - loss: 1.3923 - accuracy: 0.1658 - val_loss: 1.3892 - val_accuracy: 0.1875\n",
      "Epoch 14/30\n",
      "1253/1253 [==============================] - 72s 58ms/step - loss: 1.3923 - accuracy: 0.1646 - val_loss: 1.3892 - val_accuracy: 0.1875\n",
      "Epoch 15/30\n",
      "1253/1253 [==============================] - 72s 58ms/step - loss: 1.3924 - accuracy: 0.1653 - val_loss: 1.3892 - val_accuracy: 0.1875\n",
      "Epoch 16/30\n",
      "1253/1253 [==============================] - 72s 58ms/step - loss: 1.3925 - accuracy: 0.1643 - val_loss: 1.3892 - val_accuracy: 0.1875\n",
      "Epoch 17/30\n",
      "1253/1253 [==============================] - 72s 57ms/step - loss: 1.3925 - accuracy: 0.1615 - val_loss: 1.3892 - val_accuracy: 0.1875\n",
      "Epoch 18/30\n",
      "1253/1253 [==============================] - 72s 57ms/step - loss: 1.3925 - accuracy: 0.1635 - val_loss: 1.3892 - val_accuracy: 0.1875\n",
      "Epoch 19/30\n",
      "1253/1253 [==============================] - 72s 58ms/step - loss: 1.3924 - accuracy: 0.1656 - val_loss: 1.3892 - val_accuracy: 0.1875\n",
      "Epoch 20/30\n",
      "1253/1253 [==============================] - 72s 57ms/step - loss: 1.3923 - accuracy: 0.1655 - val_loss: 1.3892 - val_accuracy: 0.1875\n",
      "Epoch 21/30\n",
      "1253/1253 [==============================] - 72s 58ms/step - loss: 1.3924 - accuracy: 0.1637 - val_loss: 1.3892 - val_accuracy: 0.1875\n",
      "Epoch 22/30\n",
      "1253/1253 [==============================] - 72s 57ms/step - loss: 1.3923 - accuracy: 0.1657 - val_loss: 1.3892 - val_accuracy: 0.1875\n",
      "Epoch 23/30\n",
      "1253/1253 [==============================] - 72s 58ms/step - loss: 1.3923 - accuracy: 0.1662 - val_loss: 1.3892 - val_accuracy: 0.1875\n",
      "Epoch 24/30\n",
      "1253/1253 [==============================] - 72s 57ms/step - loss: 1.3923 - accuracy: 0.1659 - val_loss: 1.3892 - val_accuracy: 0.1875\n",
      "Epoch 25/30\n",
      "1253/1253 [==============================] - 72s 58ms/step - loss: 1.3923 - accuracy: 0.1668 - val_loss: 1.3892 - val_accuracy: 0.1875\n",
      "Epoch 26/30\n",
      "1253/1253 [==============================] - 72s 58ms/step - loss: 1.3925 - accuracy: 0.1653 - val_loss: 1.3892 - val_accuracy: 0.1875\n",
      "Epoch 27/30\n",
      "1253/1253 [==============================] - 72s 58ms/step - loss: 1.3923 - accuracy: 0.1653 - val_loss: 1.3892 - val_accuracy: 0.1875\n",
      "Epoch 28/30\n",
      "1253/1253 [==============================] - 72s 58ms/step - loss: 1.3924 - accuracy: 0.1611 - val_loss: 1.3892 - val_accuracy: 0.1875\n",
      "Epoch 29/30\n",
      "1253/1253 [==============================] - 72s 57ms/step - loss: 1.3924 - accuracy: 0.1646 - val_loss: 1.3892 - val_accuracy: 0.1875\n",
      "Epoch 30/30\n",
      "1253/1253 [==============================] - 72s 57ms/step - loss: 1.3924 - accuracy: 0.1640 - val_loss: 1.3892 - val_accuracy: 0.1875\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_62613.0_images_False_newWeights_True_lastLayerOnly/assets\n",
      "Test acc for resnet: 0.258264\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training opticnet for 0.75% of train size (aka 62613 images)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1253/1253 [==============================] - 376s 293ms/step - loss: 289.8785 - accuracy: 0.1331 - val_loss: 217.3077 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "1253/1253 [==============================] - 362s 289ms/step - loss: 289.2493 - accuracy: 0.1359 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "1253/1253 [==============================] - 362s 289ms/step - loss: 289.2393 - accuracy: 0.1340 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "1253/1253 [==============================] - 362s 289ms/step - loss: 288.7500 - accuracy: 0.1344 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "1253/1253 [==============================] - 362s 289ms/step - loss: 289.4170 - accuracy: 0.1331 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "1253/1253 [==============================] - 362s 289ms/step - loss: 289.0371 - accuracy: 0.1350 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "1253/1253 [==============================] - 362s 289ms/step - loss: 287.9952 - accuracy: 0.1383 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "1253/1253 [==============================] - 362s 289ms/step - loss: 290.3072 - accuracy: 0.1368 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "1253/1253 [==============================] - 362s 289ms/step - loss: 290.4138 - accuracy: 0.1322 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "1253/1253 [==============================] - 362s 289ms/step - loss: 288.5206 - accuracy: 0.1353 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "1253/1253 [==============================] - 362s 289ms/step - loss: 289.6460 - accuracy: 0.1335 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "1253/1253 [==============================] - 362s 289ms/step - loss: 289.1141 - accuracy: 0.1333 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "1253/1253 [==============================] - 362s 289ms/step - loss: 288.5890 - accuracy: 0.1361 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "1253/1253 [==============================] - 362s 289ms/step - loss: 288.8325 - accuracy: 0.1371 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "1253/1253 [==============================] - 362s 289ms/step - loss: 288.5138 - accuracy: 0.1375 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "1253/1253 [==============================] - 362s 289ms/step - loss: 287.8972 - accuracy: 0.1373 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "1253/1253 [==============================] - 362s 289ms/step - loss: 288.0190 - accuracy: 0.1378 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "1253/1253 [==============================] - 362s 289ms/step - loss: 289.1180 - accuracy: 0.1346 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "1253/1253 [==============================] - 362s 289ms/step - loss: 288.7846 - accuracy: 0.1365 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "1253/1253 [==============================] - 362s 289ms/step - loss: 289.5313 - accuracy: 0.1352 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "1253/1253 [==============================] - 362s 289ms/step - loss: 290.2984 - accuracy: 0.1354 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "1253/1253 [==============================] - 362s 289ms/step - loss: 288.5364 - accuracy: 0.1358 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "1253/1253 [==============================] - 362s 289ms/step - loss: 290.3608 - accuracy: 0.1340 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "1253/1253 [==============================] - 362s 289ms/step - loss: 288.8431 - accuracy: 0.1363 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "1253/1253 [==============================] - 362s 289ms/step - loss: 289.7148 - accuracy: 0.1346 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "1253/1253 [==============================] - 362s 289ms/step - loss: 288.3790 - accuracy: 0.1345 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "1253/1253 [==============================] - 362s 289ms/step - loss: 289.1492 - accuracy: 0.1362 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "1253/1253 [==============================] - 362s 289ms/step - loss: 289.3025 - accuracy: 0.1355 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "1253/1253 [==============================] - 362s 289ms/step - loss: 288.8591 - accuracy: 0.1366 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "1253/1253 [==============================] - 362s 289ms/step - loss: 289.6305 - accuracy: 0.1352 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../opticnet/opticnet_30epochs_62613.0_images_False_newWeights_True_lastLayerOnly/assets\n",
      "Test acc for opticnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.899981   0.90095417 0.89672189 0.9001857 ]\n",
      "Training xception for 0.9% of train size (aka 75135 images)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "   6/1503 [..............................] - ETA: 53:52 - loss: 1.3782 - accuracy: 0.1568  WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1195s vs `on_train_batch_begin` time: 1.4456s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1195s vs `on_train_batch_end` time: 0.2547s). Check your callbacks.\n",
      "1503/1503 [==============================] - 198s 130ms/step - loss: 1.3797 - accuracy: 0.1215 - val_loss: 1.3839 - val_accuracy: 0.2812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "1503/1503 [==============================] - 186s 123ms/step - loss: 1.3795 - accuracy: 0.1215 - val_loss: 1.3839 - val_accuracy: 0.2812\n",
      "Epoch 3/30\n",
      "1503/1503 [==============================] - 186s 123ms/step - loss: 1.3798 - accuracy: 0.1217 - val_loss: 1.3839 - val_accuracy: 0.2812\n",
      "Epoch 4/30\n",
      "1503/1503 [==============================] - 186s 123ms/step - loss: 1.3799 - accuracy: 0.1226 - val_loss: 1.3839 - val_accuracy: 0.2812\n",
      "Epoch 5/30\n",
      "1503/1503 [==============================] - 186s 123ms/step - loss: 1.3797 - accuracy: 0.1226 - val_loss: 1.3839 - val_accuracy: 0.2812\n",
      "Epoch 6/30\n",
      "1503/1503 [==============================] - 185s 123ms/step - loss: 1.3799 - accuracy: 0.1200 - val_loss: 1.3839 - val_accuracy: 0.2812\n",
      "Epoch 7/30\n",
      "1503/1503 [==============================] - 186s 123ms/step - loss: 1.3796 - accuracy: 0.1215 - val_loss: 1.3839 - val_accuracy: 0.2812\n",
      "Epoch 8/30\n",
      "1503/1503 [==============================] - 185s 123ms/step - loss: 1.3796 - accuracy: 0.1221 - val_loss: 1.3839 - val_accuracy: 0.2812\n",
      "Epoch 9/30\n",
      "1503/1503 [==============================] - 185s 123ms/step - loss: 1.3798 - accuracy: 0.1216 - val_loss: 1.3839 - val_accuracy: 0.2812\n",
      "Epoch 10/30\n",
      "1503/1503 [==============================] - 186s 123ms/step - loss: 1.3797 - accuracy: 0.1223 - val_loss: 1.3839 - val_accuracy: 0.2812\n",
      "Epoch 11/30\n",
      "1503/1503 [==============================] - 186s 124ms/step - loss: 1.3796 - accuracy: 0.1208 - val_loss: 1.3839 - val_accuracy: 0.2812\n",
      "Epoch 12/30\n",
      "1503/1503 [==============================] - 186s 124ms/step - loss: 1.3798 - accuracy: 0.1211 - val_loss: 1.3839 - val_accuracy: 0.2812\n",
      "Epoch 13/30\n",
      "1503/1503 [==============================] - 185s 123ms/step - loss: 1.3796 - accuracy: 0.1211 - val_loss: 1.3839 - val_accuracy: 0.2812\n",
      "Epoch 14/30\n",
      "1503/1503 [==============================] - 185s 123ms/step - loss: 1.3796 - accuracy: 0.1243 - val_loss: 1.3839 - val_accuracy: 0.2812\n",
      "Epoch 15/30\n",
      "1503/1503 [==============================] - 185s 123ms/step - loss: 1.3796 - accuracy: 0.1218 - val_loss: 1.3839 - val_accuracy: 0.2812\n",
      "Epoch 16/30\n",
      "1503/1503 [==============================] - 185s 123ms/step - loss: 1.3796 - accuracy: 0.1229 - val_loss: 1.3839 - val_accuracy: 0.2812\n",
      "Epoch 17/30\n",
      "1503/1503 [==============================] - 185s 123ms/step - loss: 1.3799 - accuracy: 0.1194 - val_loss: 1.3839 - val_accuracy: 0.2812\n",
      "Epoch 18/30\n",
      "1503/1503 [==============================] - 185s 123ms/step - loss: 1.3799 - accuracy: 0.1199 - val_loss: 1.3839 - val_accuracy: 0.2812\n",
      "Epoch 19/30\n",
      "1503/1503 [==============================] - 185s 123ms/step - loss: 1.3796 - accuracy: 0.1224 - val_loss: 1.3839 - val_accuracy: 0.2812\n",
      "Epoch 20/30\n",
      "1503/1503 [==============================] - 186s 123ms/step - loss: 1.3798 - accuracy: 0.1221 - val_loss: 1.3839 - val_accuracy: 0.2812\n",
      "Epoch 21/30\n",
      "1503/1503 [==============================] - 186s 123ms/step - loss: 1.3797 - accuracy: 0.1207 - val_loss: 1.3839 - val_accuracy: 0.2812\n",
      "Epoch 22/30\n",
      "1503/1503 [==============================] - 186s 123ms/step - loss: 1.3799 - accuracy: 0.1194 - val_loss: 1.3839 - val_accuracy: 0.2812\n",
      "Epoch 23/30\n",
      "1503/1503 [==============================] - 185s 123ms/step - loss: 1.3798 - accuracy: 0.1217 - val_loss: 1.3839 - val_accuracy: 0.2812\n",
      "Epoch 24/30\n",
      "1503/1503 [==============================] - 185s 123ms/step - loss: 1.3798 - accuracy: 0.1195 - val_loss: 1.3839 - val_accuracy: 0.2812\n",
      "Epoch 25/30\n",
      "1503/1503 [==============================] - 185s 123ms/step - loss: 1.3797 - accuracy: 0.1221 - val_loss: 1.3839 - val_accuracy: 0.2812\n",
      "Epoch 26/30\n",
      "1503/1503 [==============================] - 185s 123ms/step - loss: 1.3796 - accuracy: 0.1213 - val_loss: 1.3839 - val_accuracy: 0.2812\n",
      "Epoch 27/30\n",
      "1503/1503 [==============================] - 186s 123ms/step - loss: 1.3797 - accuracy: 0.1215 - val_loss: 1.3839 - val_accuracy: 0.2812\n",
      "Epoch 28/30\n",
      "1503/1503 [==============================] - 185s 123ms/step - loss: 1.3799 - accuracy: 0.1213 - val_loss: 1.3839 - val_accuracy: 0.2812\n",
      "Epoch 29/30\n",
      "1503/1503 [==============================] - 186s 123ms/step - loss: 1.3797 - accuracy: 0.1212 - val_loss: 1.3839 - val_accuracy: 0.2812\n",
      "Epoch 30/30\n",
      "1503/1503 [==============================] - 185s 123ms/step - loss: 1.3800 - accuracy: 0.1225 - val_loss: 1.3839 - val_accuracy: 0.2812\n",
      "INFO:tensorflow:Assets written to: ../xception/xception_30epochs_75135.6_images_False_newWeights_True_lastLayerOnly/assets\n",
      "Test acc for xception: 0.246901\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training resnet for 0.9% of train size (aka 75135 images)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "   6/1503 [..............................] - ETA: 13:39 - loss: 1.3825 - accuracy: 0.2293WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0612s vs `on_train_batch_begin` time: 0.1922s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0612s vs `on_train_batch_end` time: 0.2135s). Check your callbacks.\n",
      "1503/1503 [==============================] - 95s 60ms/step - loss: 1.3827 - accuracy: 0.2654 - val_loss: 1.3806 - val_accuracy: 0.3438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "1503/1503 [==============================] - 86s 57ms/step - loss: 1.3828 - accuracy: 0.2643 - val_loss: 1.3806 - val_accuracy: 0.3438\n",
      "Epoch 3/30\n",
      "1503/1503 [==============================] - 86s 58ms/step - loss: 1.3826 - accuracy: 0.2661 - val_loss: 1.3806 - val_accuracy: 0.3438\n",
      "Epoch 4/30\n",
      "1503/1503 [==============================] - 86s 58ms/step - loss: 1.3826 - accuracy: 0.2673 - val_loss: 1.3806 - val_accuracy: 0.3438\n",
      "Epoch 5/30\n",
      "1503/1503 [==============================] - 86s 57ms/step - loss: 1.3828 - accuracy: 0.2663 - val_loss: 1.3806 - val_accuracy: 0.3438\n",
      "Epoch 6/30\n",
      "1503/1503 [==============================] - 86s 57ms/step - loss: 1.3828 - accuracy: 0.2643 - val_loss: 1.3806 - val_accuracy: 0.3438\n",
      "Epoch 7/30\n",
      "1503/1503 [==============================] - 86s 57ms/step - loss: 1.3827 - accuracy: 0.2660 - val_loss: 1.3806 - val_accuracy: 0.3438\n",
      "Epoch 8/30\n",
      "1503/1503 [==============================] - 87s 58ms/step - loss: 1.3826 - accuracy: 0.2671 - val_loss: 1.3806 - val_accuracy: 0.3438\n",
      "Epoch 9/30\n",
      "1503/1503 [==============================] - 87s 58ms/step - loss: 1.3828 - accuracy: 0.2661 - val_loss: 1.3806 - val_accuracy: 0.3438\n",
      "Epoch 10/30\n",
      "1503/1503 [==============================] - 86s 58ms/step - loss: 1.3826 - accuracy: 0.2688 - val_loss: 1.3806 - val_accuracy: 0.3438\n",
      "Epoch 11/30\n",
      "1503/1503 [==============================] - 87s 58ms/step - loss: 1.3827 - accuracy: 0.2680 - val_loss: 1.3806 - val_accuracy: 0.3438\n",
      "Epoch 12/30\n",
      "1503/1503 [==============================] - 86s 57ms/step - loss: 1.3825 - accuracy: 0.2692 - val_loss: 1.3806 - val_accuracy: 0.3438\n",
      "Epoch 13/30\n",
      "1503/1503 [==============================] - 86s 58ms/step - loss: 1.3827 - accuracy: 0.2662 - val_loss: 1.3806 - val_accuracy: 0.3438\n",
      "Epoch 14/30\n",
      "1503/1503 [==============================] - 87s 58ms/step - loss: 1.3826 - accuracy: 0.2674 - val_loss: 1.3806 - val_accuracy: 0.3438\n",
      "Epoch 15/30\n",
      "1503/1503 [==============================] - 86s 57ms/step - loss: 1.3825 - accuracy: 0.2700 - val_loss: 1.3806 - val_accuracy: 0.3438\n",
      "Epoch 16/30\n",
      "1503/1503 [==============================] - 86s 57ms/step - loss: 1.3826 - accuracy: 0.2667 - val_loss: 1.3806 - val_accuracy: 0.3438\n",
      "Epoch 17/30\n",
      "1503/1503 [==============================] - 86s 57ms/step - loss: 1.3826 - accuracy: 0.2674 - val_loss: 1.3806 - val_accuracy: 0.3438\n",
      "Epoch 18/30\n",
      "1503/1503 [==============================] - 86s 57ms/step - loss: 1.3827 - accuracy: 0.2684 - val_loss: 1.3806 - val_accuracy: 0.3438\n",
      "Epoch 19/30\n",
      "1503/1503 [==============================] - 87s 58ms/step - loss: 1.3826 - accuracy: 0.2688 - val_loss: 1.3806 - val_accuracy: 0.3438\n",
      "Epoch 20/30\n",
      "1503/1503 [==============================] - 86s 58ms/step - loss: 1.3827 - accuracy: 0.2661 - val_loss: 1.3806 - val_accuracy: 0.3438\n",
      "Epoch 21/30\n",
      "1503/1503 [==============================] - 87s 58ms/step - loss: 1.3826 - accuracy: 0.2671 - val_loss: 1.3806 - val_accuracy: 0.3438\n",
      "Epoch 22/30\n",
      "1503/1503 [==============================] - 87s 58ms/step - loss: 1.3827 - accuracy: 0.2659 - val_loss: 1.3806 - val_accuracy: 0.3438\n",
      "Epoch 23/30\n",
      "1503/1503 [==============================] - 86s 57ms/step - loss: 1.3827 - accuracy: 0.2683 - val_loss: 1.3806 - val_accuracy: 0.3438\n",
      "Epoch 24/30\n",
      "1503/1503 [==============================] - 86s 58ms/step - loss: 1.3826 - accuracy: 0.2684 - val_loss: 1.3806 - val_accuracy: 0.3438\n",
      "Epoch 25/30\n",
      "1503/1503 [==============================] - 86s 58ms/step - loss: 1.3827 - accuracy: 0.2642 - val_loss: 1.3806 - val_accuracy: 0.3438\n",
      "Epoch 26/30\n",
      "1503/1503 [==============================] - 86s 58ms/step - loss: 1.3826 - accuracy: 0.2651 - val_loss: 1.3806 - val_accuracy: 0.3438\n",
      "Epoch 27/30\n",
      "1503/1503 [==============================] - 86s 58ms/step - loss: 1.3827 - accuracy: 0.2649 - val_loss: 1.3806 - val_accuracy: 0.3438\n",
      "Epoch 28/30\n",
      "1503/1503 [==============================] - 87s 58ms/step - loss: 1.3826 - accuracy: 0.2679 - val_loss: 1.3806 - val_accuracy: 0.3438\n",
      "Epoch 29/30\n",
      "1503/1503 [==============================] - 86s 57ms/step - loss: 1.3826 - accuracy: 0.2666 - val_loss: 1.3806 - val_accuracy: 0.3438\n",
      "Epoch 30/30\n",
      "1503/1503 [==============================] - 87s 58ms/step - loss: 1.3827 - accuracy: 0.2658 - val_loss: 1.3806 - val_accuracy: 0.3438\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_75135.6_images_False_newWeights_True_lastLayerOnly/assets\n",
      "Test acc for resnet: 0.241736\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training opticnet for 0.9% of train size (aka 75135 images)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1503/1503 [==============================] - 447s 293ms/step - loss: 289.1018 - accuracy: 0.1337 - val_loss: 217.3077 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "1503/1503 [==============================] - 435s 289ms/step - loss: 288.0937 - accuracy: 0.1377 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "1503/1503 [==============================] - 435s 289ms/step - loss: 287.9167 - accuracy: 0.1376 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "1503/1503 [==============================] - 435s 289ms/step - loss: 289.5664 - accuracy: 0.1359 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "1503/1503 [==============================] - 435s 289ms/step - loss: 288.9598 - accuracy: 0.1350 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "1503/1503 [==============================] - 435s 289ms/step - loss: 287.1926 - accuracy: 0.1390 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "1503/1503 [==============================] - 435s 290ms/step - loss: 289.5254 - accuracy: 0.1353 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "1503/1503 [==============================] - 435s 289ms/step - loss: 289.2363 - accuracy: 0.1337 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "1503/1503 [==============================] - 435s 289ms/step - loss: 287.6568 - accuracy: 0.1354 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "1503/1503 [==============================] - 435s 289ms/step - loss: 288.3455 - accuracy: 0.1349 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "1503/1503 [==============================] - 435s 289ms/step - loss: 288.3623 - accuracy: 0.1361 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "1503/1503 [==============================] - 435s 289ms/step - loss: 288.9428 - accuracy: 0.1367 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "1503/1503 [==============================] - 435s 289ms/step - loss: 287.8807 - accuracy: 0.1361 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "1503/1503 [==============================] - 435s 289ms/step - loss: 287.8468 - accuracy: 0.1369 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "1503/1503 [==============================] - 434s 289ms/step - loss: 287.6963 - accuracy: 0.1370 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "1503/1503 [==============================] - 435s 289ms/step - loss: 288.2991 - accuracy: 0.1346 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "1503/1503 [==============================] - 434s 289ms/step - loss: 287.8747 - accuracy: 0.1363 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "1503/1503 [==============================] - 435s 289ms/step - loss: 289.3583 - accuracy: 0.1345 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "1503/1503 [==============================] - 434s 289ms/step - loss: 288.5984 - accuracy: 0.1350 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "1503/1503 [==============================] - 434s 289ms/step - loss: 289.9169 - accuracy: 0.1342 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "1503/1503 [==============================] - 434s 289ms/step - loss: 288.6119 - accuracy: 0.1339 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "1503/1503 [==============================] - 434s 289ms/step - loss: 288.7753 - accuracy: 0.1354 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "1503/1503 [==============================] - 434s 289ms/step - loss: 289.4428 - accuracy: 0.1349 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "1503/1503 [==============================] - 435s 289ms/step - loss: 287.6989 - accuracy: 0.1349 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "1503/1503 [==============================] - 434s 289ms/step - loss: 288.0012 - accuracy: 0.1356 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "1503/1503 [==============================] - 434s 289ms/step - loss: 287.4385 - accuracy: 0.1369 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "1503/1503 [==============================] - 434s 289ms/step - loss: 288.0437 - accuracy: 0.1364 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "1503/1503 [==============================] - 434s 289ms/step - loss: 288.9571 - accuracy: 0.1361 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "1503/1503 [==============================] - 434s 289ms/step - loss: 288.6177 - accuracy: 0.1368 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "1503/1503 [==============================] - 434s 289ms/step - loss: 289.0997 - accuracy: 0.1342 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../opticnet/opticnet_30epochs_75135.6_images_False_newWeights_True_lastLayerOnly/assets\n",
      "Test acc for opticnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [1. 1. 1. 1.]\n",
      "Training xception for 1.0% of train size (aka 83484 images)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "   6/1670 [..............................] - ETA: 18:10 - loss: 1.3880 - accuracy: 0.2481WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1153s vs `on_train_batch_begin` time: 0.1966s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1153s vs `on_train_batch_end` time: 0.2536s). Check your callbacks.\n",
      "1670/1670 [==============================] - 211s 123ms/step - loss: 1.3814 - accuracy: 0.2855 - val_loss: 1.3820 - val_accuracy: 0.3125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "1670/1670 [==============================] - 206s 123ms/step - loss: 1.3818 - accuracy: 0.2823 - val_loss: 1.3820 - val_accuracy: 0.3125\n",
      "Epoch 3/30\n",
      "1670/1670 [==============================] - 206s 123ms/step - loss: 1.3817 - accuracy: 0.2830 - val_loss: 1.3820 - val_accuracy: 0.3125\n",
      "Epoch 4/30\n",
      "1670/1670 [==============================] - 206s 123ms/step - loss: 1.3816 - accuracy: 0.2837 - val_loss: 1.3820 - val_accuracy: 0.3125\n",
      "Epoch 5/30\n",
      "1670/1670 [==============================] - 206s 123ms/step - loss: 1.3816 - accuracy: 0.2828 - val_loss: 1.3820 - val_accuracy: 0.3125\n",
      "Epoch 6/30\n",
      "1670/1670 [==============================] - 206s 123ms/step - loss: 1.3815 - accuracy: 0.2846 - val_loss: 1.3820 - val_accuracy: 0.3125\n",
      "Epoch 7/30\n",
      "1670/1670 [==============================] - 206s 123ms/step - loss: 1.3815 - accuracy: 0.2847 - val_loss: 1.3820 - val_accuracy: 0.3125\n",
      "Epoch 8/30\n",
      "1670/1670 [==============================] - 206s 123ms/step - loss: 1.3816 - accuracy: 0.2820 - val_loss: 1.3820 - val_accuracy: 0.3125\n",
      "Epoch 9/30\n",
      "1670/1670 [==============================] - 206s 123ms/step - loss: 1.3816 - accuracy: 0.2837 - val_loss: 1.3820 - val_accuracy: 0.3125\n",
      "Epoch 10/30\n",
      "1670/1670 [==============================] - 206s 123ms/step - loss: 1.3816 - accuracy: 0.2826 - val_loss: 1.3820 - val_accuracy: 0.3125\n",
      "Epoch 11/30\n",
      "1670/1670 [==============================] - 206s 123ms/step - loss: 1.3818 - accuracy: 0.2816 - val_loss: 1.3820 - val_accuracy: 0.3125\n",
      "Epoch 12/30\n",
      "1670/1670 [==============================] - 206s 123ms/step - loss: 1.3818 - accuracy: 0.2816 - val_loss: 1.3820 - val_accuracy: 0.3125\n",
      "Epoch 13/30\n",
      "1670/1670 [==============================] - 206s 123ms/step - loss: 1.3818 - accuracy: 0.2813 - val_loss: 1.3820 - val_accuracy: 0.3125\n",
      "Epoch 14/30\n",
      "1670/1670 [==============================] - 206s 123ms/step - loss: 1.3817 - accuracy: 0.2823 - val_loss: 1.3820 - val_accuracy: 0.3125\n",
      "Epoch 15/30\n",
      "1670/1670 [==============================] - 206s 123ms/step - loss: 1.3816 - accuracy: 0.2834 - val_loss: 1.3820 - val_accuracy: 0.3125\n",
      "Epoch 16/30\n",
      "1670/1670 [==============================] - 206s 123ms/step - loss: 1.3820 - accuracy: 0.2800 - val_loss: 1.3820 - val_accuracy: 0.3125\n",
      "Epoch 17/30\n",
      "1670/1670 [==============================] - 206s 123ms/step - loss: 1.3817 - accuracy: 0.2831 - val_loss: 1.3820 - val_accuracy: 0.3125\n",
      "Epoch 18/30\n",
      "1670/1670 [==============================] - 206s 123ms/step - loss: 1.3816 - accuracy: 0.2840 - val_loss: 1.3820 - val_accuracy: 0.3125\n",
      "Epoch 19/30\n",
      "1670/1670 [==============================] - 206s 123ms/step - loss: 1.3817 - accuracy: 0.2821 - val_loss: 1.3820 - val_accuracy: 0.3125\n",
      "Epoch 20/30\n",
      "1670/1670 [==============================] - 206s 123ms/step - loss: 1.3815 - accuracy: 0.2854 - val_loss: 1.3820 - val_accuracy: 0.3125\n",
      "Epoch 21/30\n",
      "1670/1670 [==============================] - 206s 123ms/step - loss: 1.3815 - accuracy: 0.2844 - val_loss: 1.3820 - val_accuracy: 0.3125\n",
      "Epoch 22/30\n",
      "1670/1670 [==============================] - 206s 123ms/step - loss: 1.3816 - accuracy: 0.2830 - val_loss: 1.3820 - val_accuracy: 0.3125\n",
      "Epoch 23/30\n",
      "1670/1670 [==============================] - 206s 124ms/step - loss: 1.3817 - accuracy: 0.2825 - val_loss: 1.3820 - val_accuracy: 0.3125\n",
      "Epoch 24/30\n",
      "1670/1670 [==============================] - 206s 124ms/step - loss: 1.3816 - accuracy: 0.2829 - val_loss: 1.3820 - val_accuracy: 0.3125\n",
      "Epoch 25/30\n",
      "1670/1670 [==============================] - 206s 124ms/step - loss: 1.3814 - accuracy: 0.2849 - val_loss: 1.3820 - val_accuracy: 0.3125\n",
      "Epoch 26/30\n",
      "1670/1670 [==============================] - 206s 123ms/step - loss: 1.3818 - accuracy: 0.2808 - val_loss: 1.3820 - val_accuracy: 0.3125\n",
      "Epoch 27/30\n",
      "1670/1670 [==============================] - 206s 123ms/step - loss: 1.3814 - accuracy: 0.2857 - val_loss: 1.3820 - val_accuracy: 0.3125\n",
      "Epoch 28/30\n",
      "1670/1670 [==============================] - 206s 123ms/step - loss: 1.3816 - accuracy: 0.2828 - val_loss: 1.3820 - val_accuracy: 0.3125\n",
      "Epoch 29/30\n",
      "1670/1670 [==============================] - 206s 123ms/step - loss: 1.3818 - accuracy: 0.2819 - val_loss: 1.3820 - val_accuracy: 0.3125\n",
      "Epoch 30/30\n",
      "1670/1670 [==============================] - 206s 123ms/step - loss: 1.3815 - accuracy: 0.2843 - val_loss: 1.3820 - val_accuracy: 0.3125\n",
      "INFO:tensorflow:Assets written to: ../xception/xception_30epochs_83484.0_images_False_newWeights_True_lastLayerOnly/assets\n",
      "Test acc for xception: 0.234504\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training resnet for 1.0% of train size (aka 83484 images)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "   6/1670 [..............................] - ETA: 14:16 - loss: 1.3874 - accuracy: 0.2439WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0603s vs `on_train_batch_begin` time: 0.1979s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0603s vs `on_train_batch_end` time: 0.1810s). Check your callbacks.\n",
      "1670/1670 [==============================] - 101s 59ms/step - loss: 1.3856 - accuracy: 0.2825 - val_loss: 1.3847 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "1670/1670 [==============================] - 95s 57ms/step - loss: 1.3856 - accuracy: 0.2824 - val_loss: 1.3847 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "1670/1670 [==============================] - 95s 57ms/step - loss: 1.3857 - accuracy: 0.2816 - val_loss: 1.3847 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "1670/1670 [==============================] - 95s 57ms/step - loss: 1.3856 - accuracy: 0.2825 - val_loss: 1.3847 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "1670/1670 [==============================] - 95s 57ms/step - loss: 1.3858 - accuracy: 0.2786 - val_loss: 1.3847 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "1670/1670 [==============================] - 95s 57ms/step - loss: 1.3856 - accuracy: 0.2802 - val_loss: 1.3847 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "1670/1670 [==============================] - 95s 57ms/step - loss: 1.3856 - accuracy: 0.2828 - val_loss: 1.3847 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "1670/1670 [==============================] - 95s 57ms/step - loss: 1.3857 - accuracy: 0.2817 - val_loss: 1.3847 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "1670/1670 [==============================] - 95s 57ms/step - loss: 1.3856 - accuracy: 0.2823 - val_loss: 1.3847 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "1670/1670 [==============================] - 95s 57ms/step - loss: 1.3856 - accuracy: 0.2835 - val_loss: 1.3847 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "1670/1670 [==============================] - 95s 57ms/step - loss: 1.3856 - accuracy: 0.2840 - val_loss: 1.3847 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "1670/1670 [==============================] - 95s 57ms/step - loss: 1.3857 - accuracy: 0.2826 - val_loss: 1.3847 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "1670/1670 [==============================] - 95s 57ms/step - loss: 1.3857 - accuracy: 0.2820 - val_loss: 1.3847 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "1670/1670 [==============================] - 95s 57ms/step - loss: 1.3857 - accuracy: 0.2798 - val_loss: 1.3847 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "1670/1670 [==============================] - 95s 57ms/step - loss: 1.3856 - accuracy: 0.2814 - val_loss: 1.3847 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "1670/1670 [==============================] - 95s 57ms/step - loss: 1.3856 - accuracy: 0.2812 - val_loss: 1.3847 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "1670/1670 [==============================] - 95s 57ms/step - loss: 1.3856 - accuracy: 0.2800 - val_loss: 1.3847 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "1670/1670 [==============================] - 95s 57ms/step - loss: 1.3855 - accuracy: 0.2822 - val_loss: 1.3847 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "1670/1670 [==============================] - 95s 57ms/step - loss: 1.3856 - accuracy: 0.2827 - val_loss: 1.3847 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "1670/1670 [==============================] - 95s 57ms/step - loss: 1.3857 - accuracy: 0.2814 - val_loss: 1.3847 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "1670/1670 [==============================] - 95s 57ms/step - loss: 1.3857 - accuracy: 0.2833 - val_loss: 1.3847 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "1670/1670 [==============================] - 95s 57ms/step - loss: 1.3857 - accuracy: 0.2793 - val_loss: 1.3847 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "1670/1670 [==============================] - 95s 57ms/step - loss: 1.3855 - accuracy: 0.2850 - val_loss: 1.3847 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "1670/1670 [==============================] - 95s 57ms/step - loss: 1.3856 - accuracy: 0.2833 - val_loss: 1.3847 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "1670/1670 [==============================] - 95s 57ms/step - loss: 1.3857 - accuracy: 0.2814 - val_loss: 1.3847 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "1670/1670 [==============================] - 95s 57ms/step - loss: 1.3857 - accuracy: 0.2809 - val_loss: 1.3847 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "1670/1670 [==============================] - 95s 57ms/step - loss: 1.3856 - accuracy: 0.2842 - val_loss: 1.3847 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "1670/1670 [==============================] - 95s 57ms/step - loss: 1.3856 - accuracy: 0.2812 - val_loss: 1.3847 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "1670/1670 [==============================] - 95s 57ms/step - loss: 1.3856 - accuracy: 0.2826 - val_loss: 1.3847 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "1670/1670 [==============================] - 95s 57ms/step - loss: 1.3856 - accuracy: 0.2842 - val_loss: 1.3847 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_83484.0_images_False_newWeights_True_lastLayerOnly/assets\n",
      "Test acc for resnet: 0.279959\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training opticnet for 1.0% of train size (aka 83484 images)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1670/1670 [==============================] - 496s 292ms/step - loss: 288.0411 - accuracy: 0.1367 - val_loss: 217.3077 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "1670/1670 [==============================] - 483s 289ms/step - loss: 288.2129 - accuracy: 0.1358 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "1670/1670 [==============================] - 483s 289ms/step - loss: 288.6876 - accuracy: 0.1362 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "1670/1670 [==============================] - 483s 289ms/step - loss: 289.2081 - accuracy: 0.1351 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "1670/1670 [==============================] - 483s 289ms/step - loss: 288.5124 - accuracy: 0.1368 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "1670/1670 [==============================] - 483s 289ms/step - loss: 288.3070 - accuracy: 0.1377 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "1670/1670 [==============================] - 483s 289ms/step - loss: 288.5540 - accuracy: 0.1366 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "1670/1670 [==============================] - 483s 289ms/step - loss: 287.8690 - accuracy: 0.1372 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "1670/1670 [==============================] - 483s 289ms/step - loss: 287.9226 - accuracy: 0.1363 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "1670/1670 [==============================] - 483s 289ms/step - loss: 288.2909 - accuracy: 0.1367 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "1670/1670 [==============================] - 484s 290ms/step - loss: 288.1204 - accuracy: 0.1390 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "1670/1670 [==============================] - 485s 290ms/step - loss: 287.8419 - accuracy: 0.1367 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "1670/1670 [==============================] - 484s 290ms/step - loss: 288.5077 - accuracy: 0.1359 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "1670/1670 [==============================] - 484s 290ms/step - loss: 288.9188 - accuracy: 0.1348 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "1670/1670 [==============================] - 483s 289ms/step - loss: 288.6090 - accuracy: 0.1350 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "1670/1670 [==============================] - 483s 289ms/step - loss: 289.4746 - accuracy: 0.1375 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "1670/1670 [==============================] - 483s 289ms/step - loss: 289.6492 - accuracy: 0.1356 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "1670/1670 [==============================] - 483s 289ms/step - loss: 288.4661 - accuracy: 0.1359 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "1670/1670 [==============================] - 483s 290ms/step - loss: 289.8534 - accuracy: 0.1347 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "1670/1670 [==============================] - 483s 289ms/step - loss: 289.0616 - accuracy: 0.1359 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "1670/1670 [==============================] - 483s 290ms/step - loss: 288.3768 - accuracy: 0.1373 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "1670/1670 [==============================] - 484s 290ms/step - loss: 289.0297 - accuracy: 0.1356 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "1670/1670 [==============================] - 483s 289ms/step - loss: 289.0612 - accuracy: 0.1357 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "1670/1670 [==============================] - 483s 289ms/step - loss: 289.5307 - accuracy: 0.1359 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "1670/1670 [==============================] - 484s 290ms/step - loss: 288.1589 - accuracy: 0.1363 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "1670/1670 [==============================] - 484s 290ms/step - loss: 289.1489 - accuracy: 0.1358 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "1670/1670 [==============================] - 483s 289ms/step - loss: 288.9680 - accuracy: 0.1357 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "1670/1670 [==============================] - 483s 289ms/step - loss: 289.5774 - accuracy: 0.1357 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "1670/1670 [==============================] - 483s 289ms/step - loss: 287.6082 - accuracy: 0.1390 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "1670/1670 [==============================] - 483s 289ms/step - loss: 289.2829 - accuracy: 0.1349 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../opticnet/opticnet_30epochs_83484.0_images_False_newWeights_True_lastLayerOnly/assets\n",
      "Test acc for opticnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import datetime\n",
    "\n",
    "newWeights=False; trainLastLayerOnly=True\n",
    "\n",
    "maxTrain = len(y_train)\n",
    "#for p in [1.0]:\n",
    "#for p in [0.1, 0.25, 0.4, 0.5, 0.6, 0.75, 0.9]:\n",
    "for p in [0.05, 0.075, 0.09, 0.1, 0.25, 0.4, 0.5, 0.6, 0.75, 0.9, 1.0]:\n",
    "    #X_trn, X_tst, y_trn, y_tst\n",
    "    if p < 1:\n",
    "        X_t, _, y_t, _ = train_test_split(images, y_train, test_size=1-p, random_state=123)\n",
    "    else:\n",
    "        X_t = images; y_t = y_train;\n",
    "    print(f\"Labels fraction: {sum(y_t == 1) / sum(y_train == 1)}\")\n",
    "    for net in [\"xception\", \"resnet\", \"opticnet\"]:\n",
    "        print(f\"Training {net} for {p}% of train size (aka {len(X_t)} images)...\")\n",
    "        model, size = emptyModelGenerator(net, newWeights=newWeights, lastOnly=trainLastLayerOnly)\n",
    "        X_trn = resizeIms(X_t, size)\n",
    "        X_val = resizeIms(x_val, size)\n",
    "        log_dir = f\"logs/{net}/fit/{p}trainSet_\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "        tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "        optim = Adam(learning_rate=0.001)\n",
    "        model.compile(optimizer=optim, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "        hist = model.fit(X_trn, y_t, epochs=epochs, validation_data = (X_val, y_validation), batch_size=batch_size,\n",
    "                    shuffle=True, max_queue_size=20,\n",
    "                    use_multiprocessing=True, workers=5, \n",
    "                    callbacks=[CustomCallback(fraction=0.9, model=net), tensorboard_callback])\n",
    "        model.save(f\"../{net}/{net}_{epochs}epochs_{p*maxTrain}_images_{newWeights}_newWeights_{trainLastLayerOnly}_lastLayerOnly\")\n",
    "        testPredict(model, size, name=net)\n",
    "        del model\n",
    "        del X_trn\n",
    "        del X_val\n",
    "        print(\"Done!\\n\" + '-'*50, end='\\n\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
