{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "import os\n",
    "import cv2\n",
    "import pickle\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version is: 2.4.1\n"
     ]
    }
   ],
   "source": [
    "print(f\"Tensorflow version is: {tf.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataPath = \"../../data/OCT/OCT2017/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of Classes Detected : 4\n"
     ]
    }
   ],
   "source": [
    "labels_available = os.listdir(os.path.join(dataPath, \"train\"))\n",
    "print(\"Total Number of Classes Detected :\",len(labels_available))\n",
    "\n",
    "labels_list = ['NORMAL',\"CNV\",\"DME\",\"DRUSEN\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NORMAL CNV DME DRUSEN "
     ]
    }
   ],
   "source": [
    "images=[]\n",
    "y_trn=[]\n",
    "for x in labels_list:\n",
    "    xPath = os.path.join(dataPath, \"train\", x)\n",
    "    myPicList = os.listdir(xPath)\n",
    "    for y in myPicList:\n",
    "        images.append(cv2.imread(os.path.join(xPath, y)))\n",
    "        y_trn.append(labels_list.index(x))\n",
    "    print(x ,end=\" \")\n",
    "\n",
    "y_train = to_categorical(y_trn,len(labels_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NORMAL CNV DME DRUSEN "
     ]
    }
   ],
   "source": [
    "x_val=[]\n",
    "y_val=[]\n",
    "for x in labels_list:\n",
    "    xPath = os.path.join(dataPath, \"val\", x)\n",
    "    myPicList = os.listdir(xPath)\n",
    "    for y in myPicList:\n",
    "        x_val.append(cv2.imread(os.path.join(xPath, y)))\n",
    "        y_val.append(labels_list.index(x))\n",
    "    print(x ,end=\" \")\n",
    "\n",
    "y_validation = to_categorical(y_val,len(labels_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NORMAL CNV DME DRUSEN "
     ]
    }
   ],
   "source": [
    "x_tst=[]\n",
    "y_tst=[]\n",
    "for x in labels_list:\n",
    "    xPath = os.path.join(dataPath, \"test\", x)\n",
    "    myPicList = os.listdir(xPath)\n",
    "    for y in myPicList:\n",
    "        x_tst.append(cv2.imread(os.path.join(xPath, y)))\n",
    "        y_tst.append(labels_list.index(x))\n",
    "    print(x ,end=\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of images per category and set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label\t\tTrain\t\tValidation\t\tTest\n",
      "NORMAL\t\t26315\t\t8\t\t\t242\n",
      "CNV\t\t37205\t\t8\t\t\t242\n",
      "DME\t\t11348\t\t8\t\t\t242\n",
      "DRUSEN\t\t8616\t\t8\t\t\t242\n"
     ]
    }
   ],
   "source": [
    "def getNumberOfItems(labels, itemLabel):\n",
    "    return sum(list(map(lambda x: x == itemLabel, labels))) \n",
    "\n",
    "\n",
    "print(\"Label\\t\\tTrain\\t\\tValidation\\t\\tTest\")\n",
    "for i, label in enumerate(labels_list):\n",
    "    print(f\"{label}\\t\\t{getNumberOfItems(y_trn, i)}\\t\\t{getNumberOfItems(y_val, i)}\\t\\t\\t{getNumberOfItems(y_tst, i)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resizeIm(im, size):\n",
    "    if im.shape[2] == 1:\n",
    "        im = cv2.cvtColor(im,cv2.COLOR_GRAY2RGB)\n",
    "    return cv2.resize(im, size)\n",
    "\n",
    "def resizeIms(x, size):\n",
    "    return np.array(list(map(lambda im: resizeIm(im, size), x)))\n",
    "\n",
    "# Substract the mean specified by Mean (https://www.mathworks.com/help/deeplearning/ref/nnet.cnn.layer.imageinputlayer.html)\n",
    "# Substract mean by channel\n",
    "def zerocenter(x):\n",
    "    return (x - np.mean(x, axis=(0, 1))) / (2*np.std(x, axis=(0, 1)))\n",
    "\n",
    "# Rescale the input to be in the range [-1, 1] using the minimum and maximum values specified by Min and Max, respectively. (https://www.mathworks.com/help/deeplearning/ref/nnet.cnn.layer.imageinputlayer.html)\n",
    "# Compute using the formula: $x\\prime = 2 * \\frac{x - \\min{x}}{\\max{x} - \\min{x}} - 1$ taken from: https://stats.stackexchange.com/a/178629\n",
    "def rescaleSymmetric(x):\n",
    "    x = zerocenter(x)\n",
    "    return 2 * (x - np.min(x, axis=(0, 1)))/np.ptp(x, axis=(0, 1)) - 1\n",
    "\n",
    "def normalizeIms(x, normalization):\n",
    "    if normalization == \"zerocenter\":\n",
    "        func = zerocenter\n",
    "    elif normalization == \"rescale-symmetric\":\n",
    "        func = rescaleSymmetric\n",
    "    else:\n",
    "        return x\n",
    "    return np.array(list(map(lambda im: func(im), x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self,fraction, model):\n",
    "        super(CustomCallback,self).__init__()\n",
    "        self.fraction = fraction\n",
    "        self.train_a = [];\n",
    "        self.val_a =[];\n",
    "        self.logPath = os.path.join(model, \"log.txt\")\n",
    "\n",
    "        if not os.path.isdir(model):\n",
    "            os.mkdir(model)\n",
    "\n",
    "        with open(self.logPath,'w') as f:\n",
    "            f.write('Starting of logging..\\n')\n",
    "\n",
    "        self.fig = plt.figure(figsize=(4,3))\n",
    "        self.ax = plt.subplot(1,1,1)\n",
    "        plt.ion()\n",
    "\n",
    "    def on_train_begin(self,logs=None):\n",
    "        self.fig.show()\n",
    "        self.fig.canvas.draw()\n",
    "\n",
    "    def on_train_end(self,logs=None):\n",
    "        with open(self.logPath,'a') as f:\n",
    "              f.write('End of logging..\\n')\n",
    "    \n",
    "    def on_epoch_begin(self,epoch,logs=None):\n",
    "        lr= tf.keras.backend.get_value(self.model.optimizer.lr)\n",
    "        lr *= self.fraction\n",
    "        tf.keras.backend.set_value(self.model.optimizer.lr,lr)\n",
    "        with open(self.logPath,'a') as f:\n",
    "            f.write('At epoch {:02d}, learning rate changed to {:.4f}\\n'.format(epoch,lr))\n",
    "    \n",
    "    def on_epoch_end(self,epoch,logs=None):\n",
    "        val_acc = logs.get('val_accuracy')\n",
    "        train_acc = logs.get('accuracy')\n",
    "        self.train_a.append(train_acc)\n",
    "        self.val_a.append(val_acc)\n",
    "        with open(self.logPath,'a') as f:\n",
    "            f.write('At epoch {:02d}, training accuracy: {:.3f}, validation accuracy: {:.3f}\\n'.format(epoch,train_acc,val_acc))\n",
    "        self.ax.clear()\n",
    "        self.ax.plot(range(1+epoch),self.train_a,label=\"Training\")\n",
    "        self.ax.plot(range(1+epoch),self.val_a,label=\"Validation\")\n",
    "        self.ax.set_xlabel('Epochs')\n",
    "        self.ax.set_ylabel('Accuracy')\n",
    "        self.ax.legend()\n",
    "        self.fig.canvas.draw()\n",
    "        self.fig.show()\n",
    "        \n",
    "class TimeHistory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.times = []\n",
    "\n",
    "    def on_epoch_begin(self, batch, logs={}):\n",
    "        self.epoch_time_start = time.time()\n",
    "\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.times.append(time.time() - self.epoch_time_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "# xception base model\n",
    "#from tensorflow.keras.applications.xception import Xception\n",
    "#from tensorflow.keras.applications.xception import preprocess_input, decode_predictions\n",
    "#xceptionNetModel = Xception(weights='imagenet')\n",
    "#xceptionNetModel.save(\"../Xception.hdf5\")\n",
    "\n",
    "xceptionNetModel = tf.keras.models.load_model('../Xception.hdf5')\n",
    "\n",
    "# opticnet base model\n",
    "opticNetModel = tf.keras.models.load_model('../Optic_net-4_classes-Kermany2018.hdf5')\n",
    "\n",
    "# resnet base model\n",
    "#from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "#from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "#resNetModel = ResNet50(weights='imagenet')\n",
    "#resNetModel.save(\"../Resnet50.hdf5\")\n",
    "\n",
    "resNetModel = tf.keras.models.load_model('../Resnet50.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 221, 221, 32)      4736      \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 221, 221, 32)      128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 110, 110, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 104, 104, 32)      50208     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 104, 104, 32)      128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 52, 52, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 48, 48, 64)        51264     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 48, 48, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 24, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 20, 20, 128)       204928    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 20, 20, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 10, 10, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 8, 8, 256)         295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d (AveragePo (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               131200    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4)                 132       \n",
      "_________________________________________________________________\n",
      "softmax (Softmax)            (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 743,812\n",
      "Trainable params: 742,788\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "conv_init = tf.keras.initializers.RandomNormal(mean=0., stddev=1.) # convolutional layer with zero mean and 1 sd\n",
    "#batch_init = tf.keras.initializers.RandomNormal(mean=1., stddev=0.02) # non-sense here\n",
    "\n",
    "octnet = keras.models.Sequential() # empty model\n",
    "\n",
    "octnet.add(keras.layers.Conv2D(32, (7, 7), activation=\"relu\", use_bias=True, input_shape=(227, 227, 3), kernel_initializer=conv_init))\n",
    "octnet.add(keras.layers.BatchNormalization())\n",
    "octnet.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "octnet.add(keras.layers.Conv2D(32, (7, 7), activation=\"relu\", use_bias=True, kernel_initializer=conv_init))\n",
    "octnet.add(keras.layers.BatchNormalization())\n",
    "octnet.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "octnet.add(keras.layers.Conv2D(64, (5, 5), activation=\"relu\", use_bias=True, kernel_initializer=conv_init))\n",
    "octnet.add(keras.layers.BatchNormalization())\n",
    "octnet.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "octnet.add(keras.layers.Conv2D(128, (5, 5), activation=\"relu\", use_bias=True, kernel_initializer=conv_init))\n",
    "octnet.add(keras.layers.BatchNormalization())\n",
    "octnet.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "octnet.add(keras.layers.Conv2D(256, (3, 3), activation=\"relu\", use_bias=True, kernel_initializer=conv_init))\n",
    "octnet.add(keras.layers.BatchNormalization())\n",
    "octnet.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "#octnet.add(keras.layers.Conv2D(512, (3, 3), activation=\"relu\", use_bias=True))\n",
    "#octnet.add(keras.layers.BatchNormalization())\n",
    "#octnet.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "octnet.add(keras.layers.AveragePooling2D())\n",
    "octnet.add(keras.layers.Flatten())\n",
    "octnet.add(keras.layers.Dense(128))\n",
    "octnet.add(keras.layers.Dropout(0.5))\n",
    "octnet.add(keras.layers.Dense(32))\n",
    "octnet.add(keras.layers.Dropout(0.5))\n",
    "octnet.add(keras.layers.Dense(4))\n",
    "octnet.add(keras.layers.Softmax())\n",
    "\n",
    "octnet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emptyModelGenerator(model, newWeights=False, lastOnly=False):\n",
    "    model = model.lower() # lower case model name\n",
    "    if model == \"resnet\":\n",
    "        x = resNetModel.output\n",
    "        predictions = Dense(len(labels_list), activation='softmax')(x)\n",
    "        newModel = Model(inputs=resNetModel.input, outputs=predictions)\n",
    "        size = (224, 224)\n",
    "        normalization = \"zerocenter\"\n",
    "    elif model == \"xception\":\n",
    "        x = xceptionNetModel.output\n",
    "        predictions = Dense(len(labels_list), activation='softmax')(x)\n",
    "        newModel = Model(inputs=xceptionNetModel.input, outputs=predictions)\n",
    "        size = (299, 299)\n",
    "        normalization = \"rescale-symmetric\"\n",
    "    elif model == \"opticnet\":\n",
    "        newModel = tf.keras.models.load_model('../Optic_net-4_classes-Kermany2018.hdf5')\n",
    "        size = (224, 224)\n",
    "        normalization = \"rescale-symmetric\"\n",
    "    elif model == \"octnet\":\n",
    "        newModel = tf.keras.models.clone_model(octnet)\n",
    "        size = (227, 227)\n",
    "        normalization = \"zerocenter\"\n",
    "    if newWeights:\n",
    "        newModel = tf.keras.models.clone_model(newModel)\n",
    "    if lastOnly:\n",
    "        newModel = lastDenseTrainable(newModel) # block all layer except the last dense ones\n",
    "    else:\n",
    "        newModel.trainable = True\n",
    "    return newModel, size, normalization\n",
    "\n",
    "\n",
    "def lastDenseTrainable(model):\n",
    "    model.trainable = False\n",
    "    for i in range(1, len(model.layers)):\n",
    "        if model.layers[-i].__class__.__name__ == \"Dense\":\n",
    "            model.layers[-i].trainable= True\n",
    "        elif model.layers[-i].__class__.__name__ == \"Activation\":\n",
    "            continue\n",
    "        else:\n",
    "            break\n",
    "    return model\n",
    "    \n",
    "\n",
    "def testPredict(model, size, name=None, normalization=None):\n",
    "    X_test = resizeIms(x_tst, size)\n",
    "    if normalization:\n",
    "        X_test = normalizeIms(X_test, normalization)\n",
    "    X_test = np.array(X_test)\n",
    "    Y_test = np.array(y_tst)\n",
    "    \n",
    "    prediction = model.predict(X_test)\n",
    "    preds = np.argmax(prediction, axis=1)\n",
    "    acc = sum(preds == Y_test) / len(Y_test)\n",
    "    print(f'Test acc for {name if name else \"model\"}: {acc:.6f}')\n",
    "    return acc\n",
    "    \n",
    "\n",
    "def computeConfussionMatrix(predictions, labels):\n",
    "    num_labels = len(labels_list)\n",
    "    cMatrix = np.zeros(shape=(num_labels, num_labels))\n",
    "    for i in len(predictions):\n",
    "        p = int(predictions[i])\n",
    "        t = int(predictions[i])\n",
    "        cMatrix[t, p] += 1\n",
    "    print(cMatrix)\n",
    "    ax = sns.heatmap(cMatrix, cmap=\"Blues\", annot=True, fmt=\"d\", xticklabels=labels_list, yticklabels=labels_list)\n",
    "    plt.xlabel(\"Predicted label\")\n",
    "    plt.ylabel(\"True label\")\n",
    "    plt.title(\"Confusion matrix\")\n",
    "    plt.show();\n",
    "    return cMatrix\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "**************************************************\n",
      "Model: xception\n",
      "**************************************************\n",
      "\n",
      "Total: 135 trainable: 2\n",
      "\n",
      "\n",
      "**************************************************\n",
      "Model: resnet\n",
      "**************************************************\n",
      "\n",
      "Total: 178 trainable: 2\n",
      "\n",
      "\n",
      "**************************************************\n",
      "Model: opticnet\n",
      "**************************************************\n",
      "\n",
      "Total: 276 trainable: 2\n",
      "\n",
      "\n",
      "**************************************************\n",
      "Model: octnet\n",
      "**************************************************\n",
      "\n",
      "Total: 23 trainable: 0\n"
     ]
    }
   ],
   "source": [
    "models = [\"xception\", \"resnet\", \"opticnet\", \"octnet\"]\n",
    "\n",
    "def printTrainableLayers(m):\n",
    "    a = 0\n",
    "    for l in m.layers:\n",
    "        #l.trainable = True\n",
    "        if l.trainable:\n",
    "            #print(l.name, l.trainable)\n",
    "            a += 1\n",
    "    print(f\"\\nTotal: {len(m.layers)} trainable: {a}\")\n",
    "\n",
    "for mod in models:\n",
    "    print(\"\\n\\n\" + (\"*\"*50) + \"\\nModel: \" + mod + '\\n' + (\"*\"*50))\n",
    "    m = emptyModelGenerator(mod, newWeights=False, lastOnly=True)[0]\n",
    "    printTrainableLayers(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "momentum = 0.9\n",
    "optim = lambda lr: Adam(learning_rate=lr)\n",
    "#optim = lambda lr, momentum: SGD(learning_rate=lr, momentum=momentum)\n",
    "epochs = 30\n",
    "batch_size = 50\n",
    "#batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "results = pd.read_csv(\"Results_temp.csv\")\n",
    "results[\"normalization\"] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pandas as pd\n",
    "#res = pd.read_csv(\"Results_temp.csv\")\n",
    "#res.to_csv(\"Results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels fraction: [0.25251758 0.24784303 0.25484667 0.24524141]\n",
      "Training resnet for 0.25% of train size (aka 20871 images) with pretrained: False and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 178 trainable: 178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/418 [..............................] - ETA: 5:13 - loss: 1.3091 - accuracy: 0.4643WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1111s vs `on_train_batch_begin` time: 0.1278s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1111s vs `on_train_batch_end` time: 0.4189s). Check your callbacks.\n",
      "418/418 [==============================] - 93s 205ms/step - loss: 1.2403 - accuracy: 0.4332 - val_loss: 1.5260 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "418/418 [==============================] - 83s 199ms/step - loss: 1.2453 - accuracy: 0.4334 - val_loss: 1.5730 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "418/418 [==============================] - 83s 200ms/step - loss: 1.2365 - accuracy: 0.4362 - val_loss: 1.4865 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "418/418 [==============================] - 84s 200ms/step - loss: 1.2421 - accuracy: 0.4386 - val_loss: 1.6391 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "418/418 [==============================] - 84s 200ms/step - loss: 1.2374 - accuracy: 0.4363 - val_loss: 1.5385 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "418/418 [==============================] - 84s 200ms/step - loss: 1.2329 - accuracy: 0.4383 - val_loss: 1.5932 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "418/418 [==============================] - 84s 200ms/step - loss: 1.2309 - accuracy: 0.4436 - val_loss: 1.4822 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "418/418 [==============================] - 84s 200ms/step - loss: 1.2313 - accuracy: 0.4451 - val_loss: 1.6208 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "418/418 [==============================] - 84s 200ms/step - loss: 1.2346 - accuracy: 0.4429 - val_loss: 1.5959 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "418/418 [==============================] - 84s 201ms/step - loss: 1.2350 - accuracy: 0.4402 - val_loss: 1.5463 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "418/418 [==============================] - 84s 201ms/step - loss: 1.2400 - accuracy: 0.4342 - val_loss: 1.5186 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "418/418 [==============================] - 84s 200ms/step - loss: 1.2354 - accuracy: 0.4428 - val_loss: 1.5426 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "418/418 [==============================] - 84s 201ms/step - loss: 1.2306 - accuracy: 0.4464 - val_loss: 1.5481 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "418/418 [==============================] - 84s 201ms/step - loss: 1.2300 - accuracy: 0.4431 - val_loss: 1.5311 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "418/418 [==============================] - 84s 200ms/step - loss: 1.2324 - accuracy: 0.4433 - val_loss: 1.5534 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "418/418 [==============================] - 83s 200ms/step - loss: 1.2238 - accuracy: 0.4526 - val_loss: 1.5566 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "418/418 [==============================] - 84s 200ms/step - loss: 1.2362 - accuracy: 0.4372 - val_loss: 1.5505 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "418/418 [==============================] - 84s 200ms/step - loss: 1.2324 - accuracy: 0.4429 - val_loss: 1.5600 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "418/418 [==============================] - 83s 200ms/step - loss: 1.2291 - accuracy: 0.4405 - val_loss: 1.5646 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "418/418 [==============================] - 84s 200ms/step - loss: 1.2275 - accuracy: 0.4463 - val_loss: 1.5179 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "418/418 [==============================] - 83s 199ms/step - loss: 1.2309 - accuracy: 0.4392 - val_loss: 1.5587 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "418/418 [==============================] - 84s 201ms/step - loss: 1.2270 - accuracy: 0.4498 - val_loss: 1.5726 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "418/418 [==============================] - 84s 200ms/step - loss: 1.2334 - accuracy: 0.4367 - val_loss: 1.5630 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "418/418 [==============================] - 84s 200ms/step - loss: 1.2371 - accuracy: 0.4401 - val_loss: 1.5443 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "418/418 [==============================] - 83s 199ms/step - loss: 1.2359 - accuracy: 0.4336 - val_loss: 1.5390 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "418/418 [==============================] - 84s 200ms/step - loss: 1.2207 - accuracy: 0.4507 - val_loss: 1.5350 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "418/418 [==============================] - 84s 200ms/step - loss: 1.2319 - accuracy: 0.4380 - val_loss: 1.5410 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "418/418 [==============================] - 83s 199ms/step - loss: 1.2250 - accuracy: 0.4451 - val_loss: 1.5397 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "418/418 [==============================] - 83s 199ms/step - loss: 1.2308 - accuracy: 0.4423 - val_loss: 1.5645 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "418/418 [==============================] - 83s 199ms/step - loss: 1.2270 - accuracy: 0.4460 - val_loss: 1.5377 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_20871_images_True_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.25251758 0.24784303 0.25484667 0.24524141]\n",
      "Training resnet for 0.25% of train size (aka 20871 images) with pretrained: False and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 178 trainable: 178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/418 [..............................] - ETA: 4:46 - loss: 1.3249 - accuracy: 0.3376WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1020s vs `on_train_batch_begin` time: 0.1419s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1020s vs `on_train_batch_end` time: 0.3599s). Check your callbacks.\n",
      "418/418 [==============================] - 92s 204ms/step - loss: 1.2433 - accuracy: 0.4321 - val_loss: 1.5946 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "418/418 [==============================] - 82s 196ms/step - loss: 1.2322 - accuracy: 0.4377 - val_loss: 1.4846 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "418/418 [==============================] - 82s 197ms/step - loss: 1.2348 - accuracy: 0.4416 - val_loss: 1.5259 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "418/418 [==============================] - 82s 197ms/step - loss: 1.2427 - accuracy: 0.4313 - val_loss: 1.5836 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "418/418 [==============================] - 82s 197ms/step - loss: 1.2415 - accuracy: 0.4379 - val_loss: 1.6162 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "418/418 [==============================] - 82s 196ms/step - loss: 1.2394 - accuracy: 0.4350 - val_loss: 1.6499 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "418/418 [==============================] - 82s 196ms/step - loss: 1.2365 - accuracy: 0.4381 - val_loss: 1.6207 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "418/418 [==============================] - 82s 196ms/step - loss: 1.2401 - accuracy: 0.4358 - val_loss: 1.5437 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "418/418 [==============================] - 82s 196ms/step - loss: 1.2373 - accuracy: 0.4411 - val_loss: 1.5730 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "418/418 [==============================] - 82s 196ms/step - loss: 1.2287 - accuracy: 0.4440 - val_loss: 1.5724 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "418/418 [==============================] - 82s 196ms/step - loss: 1.2338 - accuracy: 0.4367 - val_loss: 1.5737 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "418/418 [==============================] - 82s 197ms/step - loss: 1.2392 - accuracy: 0.4343 - val_loss: 1.5600 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "418/418 [==============================] - 82s 196ms/step - loss: 1.2337 - accuracy: 0.4406 - val_loss: 1.5506 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "418/418 [==============================] - 82s 197ms/step - loss: 1.2281 - accuracy: 0.4458 - val_loss: 1.5430 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "418/418 [==============================] - 82s 196ms/step - loss: 1.2395 - accuracy: 0.4354 - val_loss: 1.6086 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "418/418 [==============================] - 82s 196ms/step - loss: 1.2271 - accuracy: 0.4465 - val_loss: 1.5771 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "418/418 [==============================] - 82s 196ms/step - loss: 1.2255 - accuracy: 0.4443 - val_loss: 1.5246 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "418/418 [==============================] - 82s 196ms/step - loss: 1.2294 - accuracy: 0.4394 - val_loss: 1.5537 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "418/418 [==============================] - 82s 196ms/step - loss: 1.2324 - accuracy: 0.4365 - val_loss: 1.5704 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "418/418 [==============================] - 82s 197ms/step - loss: 1.2384 - accuracy: 0.4335 - val_loss: 1.5673 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "418/418 [==============================] - 82s 196ms/step - loss: 1.2380 - accuracy: 0.4384 - val_loss: 1.5659 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "418/418 [==============================] - 82s 197ms/step - loss: 1.2302 - accuracy: 0.4451 - val_loss: 1.5838 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "418/418 [==============================] - 82s 196ms/step - loss: 1.2285 - accuracy: 0.4450 - val_loss: 1.5635 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "418/418 [==============================] - 82s 197ms/step - loss: 1.2269 - accuracy: 0.4438 - val_loss: 1.5352 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "418/418 [==============================] - 82s 196ms/step - loss: 1.2296 - accuracy: 0.4458 - val_loss: 1.5686 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "418/418 [==============================] - 82s 196ms/step - loss: 1.2339 - accuracy: 0.4404 - val_loss: 1.5678 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "418/418 [==============================] - 82s 196ms/step - loss: 1.2358 - accuracy: 0.4431 - val_loss: 1.5459 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "418/418 [==============================] - 82s 197ms/step - loss: 1.2288 - accuracy: 0.4437 - val_loss: 1.5628 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "418/418 [==============================] - 82s 196ms/step - loss: 1.2269 - accuracy: 0.4469 - val_loss: 1.5578 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "418/418 [==============================] - 82s 197ms/step - loss: 1.2352 - accuracy: 0.4409 - val_loss: 1.5418 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_20871_images_True_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.25251758 0.24784303 0.25484667 0.24524141]\n",
      "Training resnet for 0.25% of train size (aka 20871 images) with pretrained: False and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 178 trainable: 178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/418 [..............................] - ETA: 4:57 - loss: 1.3569 - accuracy: 0.3562WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1086s vs `on_train_batch_begin` time: 0.1367s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1086s vs `on_train_batch_end` time: 0.3819s). Check your callbacks.\n",
      "418/418 [==============================] - 94s 207ms/step - loss: 1.2380 - accuracy: 0.4374 - val_loss: 1.5793 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "418/418 [==============================] - 83s 200ms/step - loss: 1.2374 - accuracy: 0.4396 - val_loss: 1.6083 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "418/418 [==============================] - 83s 200ms/step - loss: 1.2414 - accuracy: 0.4361 - val_loss: 1.5917 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "418/418 [==============================] - 84s 200ms/step - loss: 1.2379 - accuracy: 0.4404 - val_loss: 1.5934 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "418/418 [==============================] - 84s 200ms/step - loss: 1.2363 - accuracy: 0.4422 - val_loss: 1.5281 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "418/418 [==============================] - 83s 199ms/step - loss: 1.2369 - accuracy: 0.4385 - val_loss: 1.5545 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "418/418 [==============================] - 84s 200ms/step - loss: 1.2286 - accuracy: 0.4424 - val_loss: 1.5772 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "418/418 [==============================] - 84s 200ms/step - loss: 1.2308 - accuracy: 0.4437 - val_loss: 1.5308 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "418/418 [==============================] - 84s 200ms/step - loss: 1.2299 - accuracy: 0.4434 - val_loss: 1.5523 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "418/418 [==============================] - 84s 200ms/step - loss: 1.2322 - accuracy: 0.4425 - val_loss: 1.6161 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "418/418 [==============================] - 83s 200ms/step - loss: 1.2330 - accuracy: 0.4409 - val_loss: 1.5530 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "418/418 [==============================] - 84s 200ms/step - loss: 1.2314 - accuracy: 0.4445 - val_loss: 1.5290 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "418/418 [==============================] - 84s 200ms/step - loss: 1.2311 - accuracy: 0.4457 - val_loss: 1.5589 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "418/418 [==============================] - 83s 200ms/step - loss: 1.2280 - accuracy: 0.4466 - val_loss: 1.5737 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "418/418 [==============================] - 84s 200ms/step - loss: 1.2303 - accuracy: 0.4438 - val_loss: 1.5520 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "418/418 [==============================] - 84s 200ms/step - loss: 1.2355 - accuracy: 0.4417 - val_loss: 1.5745 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "418/418 [==============================] - 83s 200ms/step - loss: 1.2351 - accuracy: 0.4420 - val_loss: 1.5665 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "418/418 [==============================] - 84s 200ms/step - loss: 1.2391 - accuracy: 0.4393 - val_loss: 1.5744 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "418/418 [==============================] - 84s 201ms/step - loss: 1.2298 - accuracy: 0.4453 - val_loss: 1.5561 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "418/418 [==============================] - 83s 200ms/step - loss: 1.2309 - accuracy: 0.4419 - val_loss: 1.5442 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "418/418 [==============================] - 83s 199ms/step - loss: 1.2378 - accuracy: 0.4394 - val_loss: 1.5910 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "418/418 [==============================] - 83s 199ms/step - loss: 1.2296 - accuracy: 0.4399 - val_loss: 1.5591 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "418/418 [==============================] - 83s 200ms/step - loss: 1.2353 - accuracy: 0.4374 - val_loss: 1.5705 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "418/418 [==============================] - 84s 200ms/step - loss: 1.2295 - accuracy: 0.4467 - val_loss: 1.5690 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "418/418 [==============================] - 83s 200ms/step - loss: 1.2365 - accuracy: 0.4373 - val_loss: 1.5583 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "418/418 [==============================] - 83s 200ms/step - loss: 1.2308 - accuracy: 0.4485 - val_loss: 1.5652 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "418/418 [==============================] - 83s 200ms/step - loss: 1.2341 - accuracy: 0.4364 - val_loss: 1.5593 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "418/418 [==============================] - 83s 200ms/step - loss: 1.2323 - accuracy: 0.4427 - val_loss: 1.5562 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "418/418 [==============================] - 83s 200ms/step - loss: 1.2304 - accuracy: 0.4428 - val_loss: 1.5618 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "418/418 [==============================] - 83s 200ms/step - loss: 1.2261 - accuracy: 0.4423 - val_loss: 1.5521 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_20871_images_True_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.25251758 0.24784303 0.25484667 0.24524141]\n",
      "Training resnet for 0.25% of train size (aka 20871 images) with pretrained: False and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 178 trainable: 178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/418 [..............................] - ETA: 4:29 - loss: 1.3519 - accuracy: 0.3510WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0997s vs `on_train_batch_begin` time: 0.1374s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0997s vs `on_train_batch_end` time: 0.3347s). Check your callbacks.\n",
      "418/418 [==============================] - 92s 204ms/step - loss: 1.2447 - accuracy: 0.4297 - val_loss: 1.5408 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "418/418 [==============================] - 83s 197ms/step - loss: 1.2400 - accuracy: 0.4333 - val_loss: 1.5858 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "418/418 [==============================] - 83s 198ms/step - loss: 1.2351 - accuracy: 0.4389 - val_loss: 1.5108 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "418/418 [==============================] - 83s 198ms/step - loss: 1.2335 - accuracy: 0.4433 - val_loss: 1.5768 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "418/418 [==============================] - 83s 198ms/step - loss: 1.2447 - accuracy: 0.4344 - val_loss: 1.5959 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "418/418 [==============================] - 83s 197ms/step - loss: 1.2296 - accuracy: 0.4440 - val_loss: 1.5505 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "418/418 [==============================] - 82s 197ms/step - loss: 1.2369 - accuracy: 0.4405 - val_loss: 1.6088 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "418/418 [==============================] - 82s 197ms/step - loss: 1.2346 - accuracy: 0.4417 - val_loss: 1.5175 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "418/418 [==============================] - 82s 197ms/step - loss: 1.2348 - accuracy: 0.4413 - val_loss: 1.5799 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "418/418 [==============================] - 83s 197ms/step - loss: 1.2319 - accuracy: 0.4463 - val_loss: 1.5440 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "418/418 [==============================] - 82s 197ms/step - loss: 1.2336 - accuracy: 0.4405 - val_loss: 1.5552 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "418/418 [==============================] - 82s 197ms/step - loss: 1.2319 - accuracy: 0.4385 - val_loss: 1.5733 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "418/418 [==============================] - 82s 197ms/step - loss: 1.2290 - accuracy: 0.4418 - val_loss: 1.5547 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "418/418 [==============================] - 82s 197ms/step - loss: 1.2323 - accuracy: 0.4414 - val_loss: 1.5441 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "418/418 [==============================] - 83s 197ms/step - loss: 1.2345 - accuracy: 0.4422 - val_loss: 1.5798 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "418/418 [==============================] - 83s 197ms/step - loss: 1.2365 - accuracy: 0.4417 - val_loss: 1.5475 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "418/418 [==============================] - 82s 197ms/step - loss: 1.2297 - accuracy: 0.4427 - val_loss: 1.5332 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "418/418 [==============================] - 82s 197ms/step - loss: 1.2346 - accuracy: 0.4420 - val_loss: 1.5524 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "418/418 [==============================] - 82s 197ms/step - loss: 1.2306 - accuracy: 0.4396 - val_loss: 1.5545 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "418/418 [==============================] - 82s 197ms/step - loss: 1.2354 - accuracy: 0.4396 - val_loss: 1.5728 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "418/418 [==============================] - 83s 197ms/step - loss: 1.2264 - accuracy: 0.4414 - val_loss: 1.5451 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "418/418 [==============================] - 83s 197ms/step - loss: 1.2321 - accuracy: 0.4423 - val_loss: 1.5673 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "418/418 [==============================] - 82s 197ms/step - loss: 1.2302 - accuracy: 0.4433 - val_loss: 1.5692 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "418/418 [==============================] - 82s 197ms/step - loss: 1.2334 - accuracy: 0.4427 - val_loss: 1.5484 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "418/418 [==============================] - 83s 198ms/step - loss: 1.2354 - accuracy: 0.4414 - val_loss: 1.5675 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "418/418 [==============================] - 83s 197ms/step - loss: 1.2330 - accuracy: 0.4411 - val_loss: 1.5631 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "418/418 [==============================] - 82s 197ms/step - loss: 1.2310 - accuracy: 0.4425 - val_loss: 1.5563 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "418/418 [==============================] - 82s 197ms/step - loss: 1.2325 - accuracy: 0.4399 - val_loss: 1.5497 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "418/418 [==============================] - 82s 197ms/step - loss: 1.2283 - accuracy: 0.4447 - val_loss: 1.5519 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "418/418 [==============================] - 82s 197ms/step - loss: 1.2278 - accuracy: 0.4461 - val_loss: 1.5528 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_20871_images_True_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.25251758 0.24784303 0.25484667 0.24524141]\n",
      "Training resnet for 0.25% of train size (aka 20871 images) with pretrained: False and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 178 trainable: 178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/418 [..............................] - ETA: 4:57 - loss: 1.3693 - accuracy: 0.3002WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1076s vs `on_train_batch_begin` time: 0.1361s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1076s vs `on_train_batch_end` time: 0.3821s). Check your callbacks.\n",
      "418/418 [==============================] - 95s 209ms/step - loss: 1.2509 - accuracy: 0.4333 - val_loss: 1.5660 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "418/418 [==============================] - 84s 200ms/step - loss: 1.2318 - accuracy: 0.4432 - val_loss: 1.5724 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "418/418 [==============================] - 84s 201ms/step - loss: 1.2364 - accuracy: 0.4398 - val_loss: 1.5750 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "418/418 [==============================] - 84s 201ms/step - loss: 1.2319 - accuracy: 0.4451 - val_loss: 1.5663 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "418/418 [==============================] - 84s 201ms/step - loss: 1.2319 - accuracy: 0.4412 - val_loss: 1.5872 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "418/418 [==============================] - 84s 201ms/step - loss: 1.2308 - accuracy: 0.4402 - val_loss: 1.5502 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "418/418 [==============================] - 84s 200ms/step - loss: 1.2261 - accuracy: 0.4402 - val_loss: 1.5496 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "418/418 [==============================] - 84s 201ms/step - loss: 1.2343 - accuracy: 0.4393 - val_loss: 1.5633 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "418/418 [==============================] - 84s 200ms/step - loss: 1.2326 - accuracy: 0.4421 - val_loss: 1.5579 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "418/418 [==============================] - 84s 201ms/step - loss: 1.2332 - accuracy: 0.4422 - val_loss: 1.5731 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "418/418 [==============================] - 84s 201ms/step - loss: 1.2347 - accuracy: 0.4368 - val_loss: 1.5664 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "418/418 [==============================] - 84s 201ms/step - loss: 1.2252 - accuracy: 0.4431 - val_loss: 1.5505 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "418/418 [==============================] - 84s 200ms/step - loss: 1.2298 - accuracy: 0.4455 - val_loss: 1.5561 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "418/418 [==============================] - 84s 201ms/step - loss: 1.2325 - accuracy: 0.4413 - val_loss: 1.5607 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "418/418 [==============================] - 84s 201ms/step - loss: 1.2371 - accuracy: 0.4401 - val_loss: 1.5560 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "418/418 [==============================] - 84s 201ms/step - loss: 1.2295 - accuracy: 0.4402 - val_loss: 1.5565 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "418/418 [==============================] - 84s 200ms/step - loss: 1.2391 - accuracy: 0.4318 - val_loss: 1.5622 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "418/418 [==============================] - 84s 200ms/step - loss: 1.2285 - accuracy: 0.4427 - val_loss: 1.5530 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "418/418 [==============================] - 84s 200ms/step - loss: 1.2282 - accuracy: 0.4410 - val_loss: 1.5536 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "418/418 [==============================] - 84s 201ms/step - loss: 1.2292 - accuracy: 0.4400 - val_loss: 1.5571 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "418/418 [==============================] - 84s 200ms/step - loss: 1.2288 - accuracy: 0.4465 - val_loss: 1.5561 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "418/418 [==============================] - 84s 200ms/step - loss: 1.2336 - accuracy: 0.4382 - val_loss: 1.5561 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "418/418 [==============================] - 84s 200ms/step - loss: 1.2323 - accuracy: 0.4404 - val_loss: 1.5598 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "418/418 [==============================] - 84s 201ms/step - loss: 1.2296 - accuracy: 0.4426 - val_loss: 1.5573 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "418/418 [==============================] - 84s 201ms/step - loss: 1.2320 - accuracy: 0.4405 - val_loss: 1.5582 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "418/418 [==============================] - 84s 201ms/step - loss: 1.2290 - accuracy: 0.4440 - val_loss: 1.5572 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "418/418 [==============================] - 84s 200ms/step - loss: 1.2331 - accuracy: 0.4426 - val_loss: 1.5577 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "418/418 [==============================] - 84s 200ms/step - loss: 1.2281 - accuracy: 0.4439 - val_loss: 1.5566 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "418/418 [==============================] - 84s 201ms/step - loss: 1.2322 - accuracy: 0.4423 - val_loss: 1.5571 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "418/418 [==============================] - 84s 201ms/step - loss: 1.2332 - accuracy: 0.4390 - val_loss: 1.5579 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_20871_images_True_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.25251758 0.24784303 0.25484667 0.24524141]\n",
      "Training resnet for 0.25% of train size (aka 20871 images) with pretrained: False and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 178 trainable: 178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/418 [..............................] - ETA: 4:42 - loss: 1.3644 - accuracy: 0.3849WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1009s vs `on_train_batch_begin` time: 0.1391s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1009s vs `on_train_batch_end` time: 0.3565s). Check your callbacks.\n",
      "418/418 [==============================] - 95s 207ms/step - loss: 1.2485 - accuracy: 0.4447 - val_loss: 1.5456 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "418/418 [==============================] - 83s 198ms/step - loss: 1.2310 - accuracy: 0.4381 - val_loss: 1.5323 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "418/418 [==============================] - 83s 198ms/step - loss: 1.2306 - accuracy: 0.4441 - val_loss: 1.5576 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "418/418 [==============================] - 83s 198ms/step - loss: 1.2324 - accuracy: 0.4421 - val_loss: 1.5636 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "418/418 [==============================] - 83s 197ms/step - loss: 1.2282 - accuracy: 0.4429 - val_loss: 1.5582 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "418/418 [==============================] - 82s 197ms/step - loss: 1.2260 - accuracy: 0.4461 - val_loss: 1.5604 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "418/418 [==============================] - 82s 197ms/step - loss: 1.2377 - accuracy: 0.4403 - val_loss: 1.5700 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "418/418 [==============================] - 82s 197ms/step - loss: 1.2287 - accuracy: 0.4412 - val_loss: 1.5508 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "418/418 [==============================] - 82s 197ms/step - loss: 1.2292 - accuracy: 0.4418 - val_loss: 1.5680 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "418/418 [==============================] - 82s 197ms/step - loss: 1.2307 - accuracy: 0.4462 - val_loss: 1.5581 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "418/418 [==============================] - 82s 197ms/step - loss: 1.2296 - accuracy: 0.4437 - val_loss: 1.5494 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "418/418 [==============================] - 83s 198ms/step - loss: 1.2248 - accuracy: 0.4490 - val_loss: 1.5542 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "418/418 [==============================] - 83s 198ms/step - loss: 1.2270 - accuracy: 0.4470 - val_loss: 1.5631 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "418/418 [==============================] - 82s 197ms/step - loss: 1.2306 - accuracy: 0.4430 - val_loss: 1.5473 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "418/418 [==============================] - 82s 197ms/step - loss: 1.2331 - accuracy: 0.4415 - val_loss: 1.5632 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "418/418 [==============================] - 82s 197ms/step - loss: 1.2294 - accuracy: 0.4435 - val_loss: 1.5523 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "418/418 [==============================] - 82s 197ms/step - loss: 1.2323 - accuracy: 0.4401 - val_loss: 1.5621 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "418/418 [==============================] - 83s 197ms/step - loss: 1.2344 - accuracy: 0.4449 - val_loss: 1.5548 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "418/418 [==============================] - 82s 197ms/step - loss: 1.2344 - accuracy: 0.4404 - val_loss: 1.5545 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "418/418 [==============================] - 82s 197ms/step - loss: 1.2375 - accuracy: 0.4357 - val_loss: 1.5653 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "418/418 [==============================] - 82s 197ms/step - loss: 1.2258 - accuracy: 0.4434 - val_loss: 1.5519 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "418/418 [==============================] - 82s 197ms/step - loss: 1.2330 - accuracy: 0.4403 - val_loss: 1.5555 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "418/418 [==============================] - 82s 197ms/step - loss: 1.2305 - accuracy: 0.4431 - val_loss: 1.5596 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "418/418 [==============================] - 83s 198ms/step - loss: 1.2277 - accuracy: 0.4494 - val_loss: 1.5575 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "418/418 [==============================] - 83s 198ms/step - loss: 1.2350 - accuracy: 0.4344 - val_loss: 1.5585 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "418/418 [==============================] - 83s 197ms/step - loss: 1.2328 - accuracy: 0.4411 - val_loss: 1.5578 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "418/418 [==============================] - 82s 197ms/step - loss: 1.2390 - accuracy: 0.4368 - val_loss: 1.5606 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "418/418 [==============================] - 82s 197ms/step - loss: 1.2316 - accuracy: 0.4430 - val_loss: 1.5580 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "418/418 [==============================] - 82s 197ms/step - loss: 1.2273 - accuracy: 0.4430 - val_loss: 1.5567 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "418/418 [==============================] - 83s 197ms/step - loss: 1.2275 - accuracy: 0.4426 - val_loss: 1.5563 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_20871_images_True_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.25251758 0.24784303 0.25484667 0.24524141]\n",
      "Training resnet for 0.25% of train size (aka 20871 images) with pretrained: False and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 178 trainable: 178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/418 [..............................] - ETA: 4:58 - loss: 1.3714 - accuracy: 0.3816WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1087s vs `on_train_batch_begin` time: 0.1360s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1087s vs `on_train_batch_end` time: 0.3864s). Check your callbacks.\n",
      "418/418 [==============================] - 94s 209ms/step - loss: 1.2652 - accuracy: 0.4358 - val_loss: 1.5745 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "418/418 [==============================] - 84s 201ms/step - loss: 1.2303 - accuracy: 0.4445 - val_loss: 1.5659 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "418/418 [==============================] - 84s 201ms/step - loss: 1.2321 - accuracy: 0.4428 - val_loss: 1.5656 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "418/418 [==============================] - 84s 201ms/step - loss: 1.2310 - accuracy: 0.4422 - val_loss: 1.5464 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "418/418 [==============================] - 84s 201ms/step - loss: 1.2347 - accuracy: 0.4397 - val_loss: 1.5716 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "418/418 [==============================] - 84s 201ms/step - loss: 1.2280 - accuracy: 0.4439 - val_loss: 1.5564 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "418/418 [==============================] - 84s 200ms/step - loss: 1.2368 - accuracy: 0.4384 - val_loss: 1.5602 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "418/418 [==============================] - 84s 200ms/step - loss: 1.2256 - accuracy: 0.4468 - val_loss: 1.5514 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "418/418 [==============================] - 84s 200ms/step - loss: 1.2316 - accuracy: 0.4390 - val_loss: 1.5552 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "418/418 [==============================] - 84s 201ms/step - loss: 1.2252 - accuracy: 0.4509 - val_loss: 1.5507 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "418/418 [==============================] - 84s 200ms/step - loss: 1.2300 - accuracy: 0.4394 - val_loss: 1.5494 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "418/418 [==============================] - 84s 200ms/step - loss: 1.2355 - accuracy: 0.4401 - val_loss: 1.5613 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "418/418 [==============================] - 84s 201ms/step - loss: 1.2323 - accuracy: 0.4404 - val_loss: 1.5582 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "418/418 [==============================] - 84s 201ms/step - loss: 1.2326 - accuracy: 0.4409 - val_loss: 1.5577 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "418/418 [==============================] - 84s 200ms/step - loss: 1.2396 - accuracy: 0.4379 - val_loss: 1.5645 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "418/418 [==============================] - 84s 200ms/step - loss: 1.2327 - accuracy: 0.4401 - val_loss: 1.5597 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "418/418 [==============================] - 84s 201ms/step - loss: 1.2266 - accuracy: 0.4475 - val_loss: 1.5532 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "418/418 [==============================] - 84s 201ms/step - loss: 1.2292 - accuracy: 0.4441 - val_loss: 1.5540 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "418/418 [==============================] - 84s 201ms/step - loss: 1.2284 - accuracy: 0.4469 - val_loss: 1.5556 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "418/418 [==============================] - 84s 201ms/step - loss: 1.2309 - accuracy: 0.4429 - val_loss: 1.5554 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "418/418 [==============================] - 84s 200ms/step - loss: 1.2314 - accuracy: 0.4433 - val_loss: 1.5569 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "418/418 [==============================] - 84s 200ms/step - loss: 1.2338 - accuracy: 0.4367 - val_loss: 1.5567 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "418/418 [==============================] - 84s 201ms/step - loss: 1.2350 - accuracy: 0.4411 - val_loss: 1.5577 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "418/418 [==============================] - 84s 201ms/step - loss: 1.2302 - accuracy: 0.4421 - val_loss: 1.5569 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "418/418 [==============================] - 84s 201ms/step - loss: 1.2293 - accuracy: 0.4438 - val_loss: 1.5579 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "418/418 [==============================] - 84s 201ms/step - loss: 1.2298 - accuracy: 0.4410 - val_loss: 1.5573 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "418/418 [==============================] - 84s 200ms/step - loss: 1.2270 - accuracy: 0.4453 - val_loss: 1.5569 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "418/418 [==============================] - 84s 201ms/step - loss: 1.2296 - accuracy: 0.4432 - val_loss: 1.5569 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "418/418 [==============================] - 84s 201ms/step - loss: 1.2295 - accuracy: 0.4393 - val_loss: 1.5571 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "418/418 [==============================] - 84s 201ms/step - loss: 1.2316 - accuracy: 0.4419 - val_loss: 1.5566 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_20871_images_True_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.25251758 0.24784303 0.25484667 0.24524141]\n",
      "Training resnet for 0.25% of train size (aka 20871 images) with pretrained: False and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 178 trainable: 178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/418 [..............................] - ETA: 4:29 - loss: 1.3699 - accuracy: 0.3152WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1032s vs `on_train_batch_begin` time: 0.1370s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1032s vs `on_train_batch_end` time: 0.3340s). Check your callbacks.\n",
      "418/418 [==============================] - 93s 208ms/step - loss: 1.2594 - accuracy: 0.4373 - val_loss: 1.5513 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "418/418 [==============================] - 85s 203ms/step - loss: 1.2279 - accuracy: 0.4428 - val_loss: 1.5565 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "418/418 [==============================] - 84s 202ms/step - loss: 1.2314 - accuracy: 0.4381 - val_loss: 1.5653 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "418/418 [==============================] - 84s 201ms/step - loss: 1.2268 - accuracy: 0.4466 - val_loss: 1.5721 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "418/418 [==============================] - 84s 200ms/step - loss: 1.2329 - accuracy: 0.4409 - val_loss: 1.5615 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "418/418 [==============================] - 84s 200ms/step - loss: 1.2307 - accuracy: 0.4373 - val_loss: 1.5593 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "418/418 [==============================] - 84s 200ms/step - loss: 1.2353 - accuracy: 0.4362 - val_loss: 1.5627 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "418/418 [==============================] - 84s 200ms/step - loss: 1.2387 - accuracy: 0.4371 - val_loss: 1.5693 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "418/418 [==============================] - 84s 200ms/step - loss: 1.2271 - accuracy: 0.4398 - val_loss: 1.5482 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "418/418 [==============================] - 84s 200ms/step - loss: 1.2276 - accuracy: 0.4445 - val_loss: 1.5582 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "418/418 [==============================] - 84s 201ms/step - loss: 1.2334 - accuracy: 0.4421 - val_loss: 1.5641 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "418/418 [==============================] - 84s 201ms/step - loss: 1.2301 - accuracy: 0.4474 - val_loss: 1.5516 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "418/418 [==============================] - 84s 200ms/step - loss: 1.2371 - accuracy: 0.4355 - val_loss: 1.5639 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "418/418 [==============================] - 84s 200ms/step - loss: 1.2296 - accuracy: 0.4397 - val_loss: 1.5554 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "418/418 [==============================] - 84s 200ms/step - loss: 1.2345 - accuracy: 0.4388 - val_loss: 1.5605 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "418/418 [==============================] - 84s 201ms/step - loss: 1.2248 - accuracy: 0.4482 - val_loss: 1.5540 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "418/418 [==============================] - 84s 201ms/step - loss: 1.2330 - accuracy: 0.4393 - val_loss: 1.5577 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "418/418 [==============================] - 84s 201ms/step - loss: 1.2302 - accuracy: 0.4469 - val_loss: 1.5557 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "418/418 [==============================] - 84s 201ms/step - loss: 1.2298 - accuracy: 0.4446 - val_loss: 1.5569 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "418/418 [==============================] - 84s 201ms/step - loss: 1.2268 - accuracy: 0.4453 - val_loss: 1.5557 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "418/418 [==============================] - 84s 200ms/step - loss: 1.2279 - accuracy: 0.4430 - val_loss: 1.5550 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "418/418 [==============================] - 84s 201ms/step - loss: 1.2303 - accuracy: 0.4439 - val_loss: 1.5560 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "418/418 [==============================] - 84s 200ms/step - loss: 1.2265 - accuracy: 0.4418 - val_loss: 1.5558 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "418/418 [==============================] - 84s 201ms/step - loss: 1.2330 - accuracy: 0.4423 - val_loss: 1.5558 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "418/418 [==============================] - 84s 201ms/step - loss: 1.2325 - accuracy: 0.4400 - val_loss: 1.5565 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "418/418 [==============================] - 84s 200ms/step - loss: 1.2281 - accuracy: 0.4464 - val_loss: 1.5558 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "418/418 [==============================] - 84s 200ms/step - loss: 1.2361 - accuracy: 0.4381 - val_loss: 1.5576 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "418/418 [==============================] - 84s 200ms/step - loss: 1.2294 - accuracy: 0.4382 - val_loss: 1.5565 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "418/418 [==============================] - 84s 200ms/step - loss: 1.2316 - accuracy: 0.4367 - val_loss: 1.5569 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "418/418 [==============================] - 84s 200ms/step - loss: 1.2391 - accuracy: 0.4366 - val_loss: 1.5575 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_20871_images_True_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.25251758 0.24784303 0.25484667 0.24524141]\n",
      "Training resnet for 0.25% of train size (aka 20871 images) with pretrained: True and onlyLastLayersTrained: True...\n",
      "\n",
      "Total: 178 trainable: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/418 [..............................] - ETA: 2:50 - loss: 1.3914 - accuracy: 0.0861WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0607s vs `on_train_batch_begin` time: 0.1369s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0607s vs `on_train_batch_end` time: 0.1574s). Check your callbacks.\n",
      "418/418 [==============================] - 30s 64ms/step - loss: 1.3913 - accuracy: 0.0974 - val_loss: 1.3909 - val_accuracy: 0.2188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "418/418 [==============================] - 24s 57ms/step - loss: 1.3911 - accuracy: 0.1005 - val_loss: 1.3909 - val_accuracy: 0.2188\n",
      "Epoch 3/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3906 - accuracy: 0.1063 - val_loss: 1.3909 - val_accuracy: 0.2188\n",
      "Epoch 4/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3906 - accuracy: 0.1014 - val_loss: 1.3909 - val_accuracy: 0.2188\n",
      "Epoch 5/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3906 - accuracy: 0.1017 - val_loss: 1.3909 - val_accuracy: 0.2188\n",
      "Epoch 6/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3910 - accuracy: 0.0994 - val_loss: 1.3909 - val_accuracy: 0.2188\n",
      "Epoch 7/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3909 - accuracy: 0.0964 - val_loss: 1.3909 - val_accuracy: 0.2188\n",
      "Epoch 8/30\n",
      "418/418 [==============================] - 25s 59ms/step - loss: 1.3910 - accuracy: 0.1006 - val_loss: 1.3909 - val_accuracy: 0.2188\n",
      "Epoch 9/30\n",
      "418/418 [==============================] - 25s 59ms/step - loss: 1.3906 - accuracy: 0.1030 - val_loss: 1.3909 - val_accuracy: 0.2188\n",
      "Epoch 10/30\n",
      "418/418 [==============================] - 24s 59ms/step - loss: 1.3912 - accuracy: 0.0992 - val_loss: 1.3909 - val_accuracy: 0.2188\n",
      "Epoch 11/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3908 - accuracy: 0.1006 - val_loss: 1.3909 - val_accuracy: 0.2188\n",
      "Epoch 12/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3911 - accuracy: 0.1003 - val_loss: 1.3909 - val_accuracy: 0.2188\n",
      "Epoch 13/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3907 - accuracy: 0.0987 - val_loss: 1.3909 - val_accuracy: 0.2188\n",
      "Epoch 14/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3910 - accuracy: 0.1004 - val_loss: 1.3909 - val_accuracy: 0.2188\n",
      "Epoch 15/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3912 - accuracy: 0.0986 - val_loss: 1.3909 - val_accuracy: 0.2188\n",
      "Epoch 16/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3907 - accuracy: 0.1074 - val_loss: 1.3909 - val_accuracy: 0.2188\n",
      "Epoch 17/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3907 - accuracy: 0.1002 - val_loss: 1.3909 - val_accuracy: 0.2188\n",
      "Epoch 18/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3907 - accuracy: 0.1032 - val_loss: 1.3909 - val_accuracy: 0.2188\n",
      "Epoch 19/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3911 - accuracy: 0.1008 - val_loss: 1.3909 - val_accuracy: 0.2188\n",
      "Epoch 20/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3910 - accuracy: 0.0983 - val_loss: 1.3909 - val_accuracy: 0.2188\n",
      "Epoch 21/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3914 - accuracy: 0.0957 - val_loss: 1.3909 - val_accuracy: 0.2188\n",
      "Epoch 22/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3909 - accuracy: 0.0990 - val_loss: 1.3909 - val_accuracy: 0.2188\n",
      "Epoch 23/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3909 - accuracy: 0.1004 - val_loss: 1.3909 - val_accuracy: 0.2188\n",
      "Epoch 24/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3908 - accuracy: 0.0964 - val_loss: 1.3909 - val_accuracy: 0.2188\n",
      "Epoch 25/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3909 - accuracy: 0.1010 - val_loss: 1.3909 - val_accuracy: 0.2188\n",
      "Epoch 26/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3910 - accuracy: 0.0991 - val_loss: 1.3909 - val_accuracy: 0.2188\n",
      "Epoch 27/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3913 - accuracy: 0.0986 - val_loss: 1.3909 - val_accuracy: 0.2188\n",
      "Epoch 28/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3907 - accuracy: 0.0997 - val_loss: 1.3909 - val_accuracy: 0.2188\n",
      "Epoch 29/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3906 - accuracy: 0.1036 - val_loss: 1.3909 - val_accuracy: 0.2188\n",
      "Epoch 30/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3910 - accuracy: 0.0985 - val_loss: 1.3909 - val_accuracy: 0.2188\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_20871_images_False_newWeights_True_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.242769\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.25251758 0.24784303 0.25484667 0.24524141]\n",
      "Training resnet for 0.25% of train size (aka 20871 images) with pretrained: True and onlyLastLayersTrained: True...\n",
      "\n",
      "Total: 178 trainable: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/418 [..............................] - ETA: 2:48 - loss: 1.3841 - accuracy: 0.0048WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0609s vs `on_train_batch_begin` time: 0.1366s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0609s vs `on_train_batch_end` time: 0.1547s). Check your callbacks.\n",
      "418/418 [==============================] - 30s 64ms/step - loss: 1.3833 - accuracy: 0.0022 - val_loss: 1.3948 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "418/418 [==============================] - 24s 57ms/step - loss: 1.3835 - accuracy: 0.0028 - val_loss: 1.3948 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3833 - accuracy: 0.0022 - val_loss: 1.3948 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3834 - accuracy: 0.0023 - val_loss: 1.3948 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3833 - accuracy: 0.0029 - val_loss: 1.3948 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3834 - accuracy: 0.0021 - val_loss: 1.3948 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3834 - accuracy: 0.0028 - val_loss: 1.3948 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3833 - accuracy: 0.0024 - val_loss: 1.3948 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/30\n",
      "418/418 [==============================] - 24s 59ms/step - loss: 1.3835 - accuracy: 0.0023 - val_loss: 1.3948 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/30\n",
      "418/418 [==============================] - 24s 59ms/step - loss: 1.3834 - accuracy: 0.0024 - val_loss: 1.3948 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3830 - accuracy: 0.0018 - val_loss: 1.3948 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3834 - accuracy: 0.0026 - val_loss: 1.3948 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3837 - accuracy: 0.0026 - val_loss: 1.3948 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3834 - accuracy: 0.0027 - val_loss: 1.3948 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3833 - accuracy: 0.0032 - val_loss: 1.3948 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3832 - accuracy: 0.0022 - val_loss: 1.3948 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3834 - accuracy: 0.0022 - val_loss: 1.3948 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3833 - accuracy: 0.0023 - val_loss: 1.3948 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3832 - accuracy: 0.0021 - val_loss: 1.3948 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3832 - accuracy: 0.0024 - val_loss: 1.3948 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3832 - accuracy: 0.0021 - val_loss: 1.3948 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3834 - accuracy: 0.0019 - val_loss: 1.3948 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3836 - accuracy: 0.0024 - val_loss: 1.3948 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/30\n",
      "418/418 [==============================] - 25s 59ms/step - loss: 1.3834 - accuracy: 0.0026 - val_loss: 1.3948 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3833 - accuracy: 0.0029 - val_loss: 1.3948 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3831 - accuracy: 0.0025 - val_loss: 1.3948 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3834 - accuracy: 0.0025 - val_loss: 1.3948 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3832 - accuracy: 0.0026 - val_loss: 1.3948 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3833 - accuracy: 0.0025 - val_loss: 1.3948 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3835 - accuracy: 0.0022 - val_loss: 1.3948 - val_accuracy: 0.0000e+00\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_20871_images_False_newWeights_True_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.003099\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.25251758 0.24784303 0.25484667 0.24524141]\n",
      "Training resnet for 0.25% of train size (aka 20871 images) with pretrained: True and onlyLastLayersTrained: True...\n",
      "\n",
      "Total: 178 trainable: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/418 [..............................] - ETA: 2:52 - loss: 1.4085 - accuracy: 0.0000e+00WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0612s vs `on_train_batch_begin` time: 0.1379s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0612s vs `on_train_batch_end` time: 0.1608s). Check your callbacks.\n",
      "418/418 [==============================] - 30s 64ms/step - loss: 1.4065 - accuracy: 0.0013 - val_loss: 1.4059 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "418/418 [==============================] - 24s 57ms/step - loss: 1.4066 - accuracy: 6.9519e-04 - val_loss: 1.4059 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.4066 - accuracy: 8.8272e-04 - val_loss: 1.4059 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.4069 - accuracy: 0.0010 - val_loss: 1.4059 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/30\n",
      "418/418 [==============================] - 25s 59ms/step - loss: 1.4062 - accuracy: 8.7815e-04 - val_loss: 1.4059 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/30\n",
      "418/418 [==============================] - 24s 59ms/step - loss: 1.4065 - accuracy: 0.0012 - val_loss: 1.4059 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/30\n",
      "418/418 [==============================] - 25s 59ms/step - loss: 1.4067 - accuracy: 0.0010 - val_loss: 1.4059 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/30\n",
      "418/418 [==============================] - 24s 59ms/step - loss: 1.4064 - accuracy: 8.4178e-04 - val_loss: 1.4059 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.4064 - accuracy: 9.5946e-04 - val_loss: 1.4059 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.4066 - accuracy: 9.6671e-04 - val_loss: 1.4059 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.4067 - accuracy: 7.0986e-04 - val_loss: 1.4059 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.4069 - accuracy: 7.4286e-04 - val_loss: 1.4059 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.4068 - accuracy: 9.2092e-04 - val_loss: 1.4059 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.4064 - accuracy: 9.5108e-04 - val_loss: 1.4059 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.4066 - accuracy: 9.1248e-04 - val_loss: 1.4059 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.4067 - accuracy: 6.0601e-04 - val_loss: 1.4059 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.4062 - accuracy: 8.0040e-04 - val_loss: 1.4059 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.4069 - accuracy: 6.2878e-04 - val_loss: 1.4059 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.4064 - accuracy: 0.0013 - val_loss: 1.4059 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.4065 - accuracy: 4.0039e-04 - val_loss: 1.4059 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.4062 - accuracy: 0.0011 - val_loss: 1.4059 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.4066 - accuracy: 7.6494e-04 - val_loss: 1.4059 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.4062 - accuracy: 0.0011 - val_loss: 1.4059 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.4066 - accuracy: 6.2745e-04 - val_loss: 1.4059 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.4065 - accuracy: 7.4573e-04 - val_loss: 1.4059 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.4064 - accuracy: 0.0010 - val_loss: 1.4059 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.4066 - accuracy: 9.6196e-04 - val_loss: 1.4059 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.4062 - accuracy: 7.9219e-04 - val_loss: 1.4059 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.4064 - accuracy: 0.0012 - val_loss: 1.4059 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.4067 - accuracy: 5.5079e-04 - val_loss: 1.4059 - val_accuracy: 0.0000e+00\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_20871_images_False_newWeights_True_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.001033\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.25251758 0.24784303 0.25484667 0.24524141]\n",
      "Training resnet for 0.25% of train size (aka 20871 images) with pretrained: True and onlyLastLayersTrained: True...\n",
      "\n",
      "Total: 178 trainable: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/418 [..............................] - ETA: 2:50 - loss: 1.3911 - accuracy: 0.4550WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0609s vs `on_train_batch_begin` time: 0.1366s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0609s vs `on_train_batch_end` time: 0.1577s). Check your callbacks.\n",
      "418/418 [==============================] - 30s 64ms/step - loss: 1.3948 - accuracy: 0.4196 - val_loss: 1.3789 - val_accuracy: 0.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "418/418 [==============================] - 24s 57ms/step - loss: 1.3948 - accuracy: 0.4212 - val_loss: 1.3789 - val_accuracy: 0.5000\n",
      "Epoch 3/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3947 - accuracy: 0.4197 - val_loss: 1.3789 - val_accuracy: 0.5000\n",
      "Epoch 4/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3951 - accuracy: 0.4183 - val_loss: 1.3789 - val_accuracy: 0.5000\n",
      "Epoch 5/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3945 - accuracy: 0.4260 - val_loss: 1.3789 - val_accuracy: 0.5000\n",
      "Epoch 6/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3945 - accuracy: 0.4231 - val_loss: 1.3789 - val_accuracy: 0.5000\n",
      "Epoch 7/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3951 - accuracy: 0.4169 - val_loss: 1.3789 - val_accuracy: 0.5000\n",
      "Epoch 8/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3948 - accuracy: 0.4208 - val_loss: 1.3789 - val_accuracy: 0.5000\n",
      "Epoch 9/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3950 - accuracy: 0.4158 - val_loss: 1.3789 - val_accuracy: 0.5000\n",
      "Epoch 10/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3946 - accuracy: 0.4194 - val_loss: 1.3789 - val_accuracy: 0.5000\n",
      "Epoch 11/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3947 - accuracy: 0.4173 - val_loss: 1.3789 - val_accuracy: 0.5000\n",
      "Epoch 12/30\n",
      "418/418 [==============================] - 24s 57ms/step - loss: 1.3944 - accuracy: 0.4217 - val_loss: 1.3789 - val_accuracy: 0.5000\n",
      "Epoch 13/30\n",
      "418/418 [==============================] - 24s 57ms/step - loss: 1.3946 - accuracy: 0.4222 - val_loss: 1.3789 - val_accuracy: 0.5000\n",
      "Epoch 14/30\n",
      "418/418 [==============================] - 24s 57ms/step - loss: 1.3947 - accuracy: 0.4184 - val_loss: 1.3789 - val_accuracy: 0.5000\n",
      "Epoch 15/30\n",
      "418/418 [==============================] - 24s 57ms/step - loss: 1.3946 - accuracy: 0.4201 - val_loss: 1.3789 - val_accuracy: 0.5000\n",
      "Epoch 16/30\n",
      "418/418 [==============================] - 24s 57ms/step - loss: 1.3947 - accuracy: 0.4213 - val_loss: 1.3789 - val_accuracy: 0.5000\n",
      "Epoch 17/30\n",
      "418/418 [==============================] - 24s 57ms/step - loss: 1.3947 - accuracy: 0.4192 - val_loss: 1.3789 - val_accuracy: 0.5000\n",
      "Epoch 18/30\n",
      "418/418 [==============================] - 24s 57ms/step - loss: 1.3944 - accuracy: 0.4248 - val_loss: 1.3789 - val_accuracy: 0.5000\n",
      "Epoch 19/30\n",
      "418/418 [==============================] - 24s 57ms/step - loss: 1.3946 - accuracy: 0.4223 - val_loss: 1.3789 - val_accuracy: 0.5000\n",
      "Epoch 20/30\n",
      "418/418 [==============================] - 24s 57ms/step - loss: 1.3949 - accuracy: 0.4195 - val_loss: 1.3789 - val_accuracy: 0.5000\n",
      "Epoch 21/30\n",
      "418/418 [==============================] - 24s 57ms/step - loss: 1.3948 - accuracy: 0.4186 - val_loss: 1.3789 - val_accuracy: 0.5000\n",
      "Epoch 22/30\n",
      "418/418 [==============================] - 24s 57ms/step - loss: 1.3950 - accuracy: 0.4153 - val_loss: 1.3789 - val_accuracy: 0.5000\n",
      "Epoch 23/30\n",
      "418/418 [==============================] - 24s 57ms/step - loss: 1.3947 - accuracy: 0.4201 - val_loss: 1.3789 - val_accuracy: 0.5000\n",
      "Epoch 24/30\n",
      "418/418 [==============================] - 24s 57ms/step - loss: 1.3944 - accuracy: 0.4225 - val_loss: 1.3789 - val_accuracy: 0.5000\n",
      "Epoch 25/30\n",
      "418/418 [==============================] - 24s 57ms/step - loss: 1.3945 - accuracy: 0.4221 - val_loss: 1.3789 - val_accuracy: 0.5000\n",
      "Epoch 26/30\n",
      "418/418 [==============================] - 24s 57ms/step - loss: 1.3952 - accuracy: 0.4113 - val_loss: 1.3789 - val_accuracy: 0.5000\n",
      "Epoch 27/30\n",
      "418/418 [==============================] - 24s 57ms/step - loss: 1.3943 - accuracy: 0.4284 - val_loss: 1.3789 - val_accuracy: 0.5000\n",
      "Epoch 28/30\n",
      "418/418 [==============================] - 24s 57ms/step - loss: 1.3946 - accuracy: 0.4225 - val_loss: 1.3789 - val_accuracy: 0.5000\n",
      "Epoch 29/30\n",
      "418/418 [==============================] - 24s 57ms/step - loss: 1.3939 - accuracy: 0.4257 - val_loss: 1.3789 - val_accuracy: 0.5000\n",
      "Epoch 30/30\n",
      "418/418 [==============================] - 24s 57ms/step - loss: 1.3945 - accuracy: 0.4233 - val_loss: 1.3789 - val_accuracy: 0.5000\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_20871_images_False_newWeights_True_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.496901\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.25251758 0.24784303 0.25484667 0.24524141]\n",
      "Training resnet for 0.25% of train size (aka 20871 images) with pretrained: True and onlyLastLayersTrained: True...\n",
      "\n",
      "Total: 178 trainable: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/418 [..............................] - ETA: 2:50 - loss: 1.3860 - accuracy: 0.4389WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0601s vs `on_train_batch_begin` time: 0.1368s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0601s vs `on_train_batch_end` time: 0.1592s). Check your callbacks.\n",
      "418/418 [==============================] - 30s 65ms/step - loss: 1.3840 - accuracy: 0.4414 - val_loss: 1.3934 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3834 - accuracy: 0.4450 - val_loss: 1.3934 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3838 - accuracy: 0.4400 - val_loss: 1.3934 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3834 - accuracy: 0.4469 - val_loss: 1.3934 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "418/418 [==============================] - 24s 59ms/step - loss: 1.3840 - accuracy: 0.4392 - val_loss: 1.3934 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "418/418 [==============================] - 24s 59ms/step - loss: 1.3844 - accuracy: 0.4336 - val_loss: 1.3934 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "418/418 [==============================] - 24s 59ms/step - loss: 1.3842 - accuracy: 0.4373 - val_loss: 1.3934 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "418/418 [==============================] - 25s 59ms/step - loss: 1.3835 - accuracy: 0.4453 - val_loss: 1.3934 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3842 - accuracy: 0.4376 - val_loss: 1.3934 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3838 - accuracy: 0.4444 - val_loss: 1.3934 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3840 - accuracy: 0.4405 - val_loss: 1.3934 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3837 - accuracy: 0.4436 - val_loss: 1.3934 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3841 - accuracy: 0.4367 - val_loss: 1.3934 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3833 - accuracy: 0.4481 - val_loss: 1.3934 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3843 - accuracy: 0.4351 - val_loss: 1.3934 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3835 - accuracy: 0.4451 - val_loss: 1.3934 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3839 - accuracy: 0.4403 - val_loss: 1.3934 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3833 - accuracy: 0.4451 - val_loss: 1.3934 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3840 - accuracy: 0.4391 - val_loss: 1.3934 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3842 - accuracy: 0.4357 - val_loss: 1.3934 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3836 - accuracy: 0.4438 - val_loss: 1.3934 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3840 - accuracy: 0.4416 - val_loss: 1.3934 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3835 - accuracy: 0.4415 - val_loss: 1.3934 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3836 - accuracy: 0.4432 - val_loss: 1.3934 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3840 - accuracy: 0.4403 - val_loss: 1.3934 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3838 - accuracy: 0.4420 - val_loss: 1.3934 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3839 - accuracy: 0.4404 - val_loss: 1.3934 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3836 - accuracy: 0.4428 - val_loss: 1.3934 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3834 - accuracy: 0.4429 - val_loss: 1.3934 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3841 - accuracy: 0.4405 - val_loss: 1.3934 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_20871_images_False_newWeights_True_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.25251758 0.24784303 0.25484667 0.24524141]\n",
      "Training resnet for 0.25% of train size (aka 20871 images) with pretrained: True and onlyLastLayersTrained: True...\n",
      "\n",
      "Total: 178 trainable: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/418 [..............................] - ETA: 2:51 - loss: 1.3696 - accuracy: 0.4242WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0601s vs `on_train_batch_begin` time: 0.1366s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0601s vs `on_train_batch_end` time: 0.1601s). Check your callbacks.\n",
      "418/418 [==============================] - 30s 64ms/step - loss: 1.3687 - accuracy: 0.4396 - val_loss: 1.3901 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "418/418 [==============================] - 24s 57ms/step - loss: 1.3689 - accuracy: 0.4394 - val_loss: 1.3901 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3685 - accuracy: 0.4423 - val_loss: 1.3901 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3684 - accuracy: 0.4460 - val_loss: 1.3901 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3683 - accuracy: 0.4428 - val_loss: 1.3901 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3684 - accuracy: 0.4428 - val_loss: 1.3901 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3685 - accuracy: 0.4431 - val_loss: 1.3901 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "418/418 [==============================] - 24s 59ms/step - loss: 1.3688 - accuracy: 0.4403 - val_loss: 1.3901 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3688 - accuracy: 0.4409 - val_loss: 1.3901 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3691 - accuracy: 0.4371 - val_loss: 1.3901 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3684 - accuracy: 0.4456 - val_loss: 1.3901 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3684 - accuracy: 0.4449 - val_loss: 1.3901 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3688 - accuracy: 0.4393 - val_loss: 1.3901 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3691 - accuracy: 0.4407 - val_loss: 1.3901 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3689 - accuracy: 0.4396 - val_loss: 1.3901 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3683 - accuracy: 0.4476 - val_loss: 1.3901 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3687 - accuracy: 0.4413 - val_loss: 1.3901 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3686 - accuracy: 0.4438 - val_loss: 1.3901 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3684 - accuracy: 0.4429 - val_loss: 1.3901 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3686 - accuracy: 0.4447 - val_loss: 1.3901 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3685 - accuracy: 0.4413 - val_loss: 1.3901 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3683 - accuracy: 0.4457 - val_loss: 1.3901 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3684 - accuracy: 0.4416 - val_loss: 1.3901 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3686 - accuracy: 0.4414 - val_loss: 1.3901 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3684 - accuracy: 0.4479 - val_loss: 1.3901 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3686 - accuracy: 0.4387 - val_loss: 1.3901 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3690 - accuracy: 0.4383 - val_loss: 1.3901 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3685 - accuracy: 0.4429 - val_loss: 1.3901 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3685 - accuracy: 0.4427 - val_loss: 1.3901 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3689 - accuracy: 0.4393 - val_loss: 1.3901 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_20871_images_False_newWeights_True_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.25251758 0.24784303 0.25484667 0.24524141]\n",
      "Training resnet for 0.25% of train size (aka 20871 images) with pretrained: True and onlyLastLayersTrained: True...\n",
      "\n",
      "Total: 178 trainable: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/418 [..............................] - ETA: 2:51 - loss: 1.3887 - accuracy: 0.0000e+00WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0585s vs `on_train_batch_begin` time: 0.1383s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0585s vs `on_train_batch_end` time: 0.1606s). Check your callbacks.\n",
      "418/418 [==============================] - 30s 64ms/step - loss: 1.3883 - accuracy: 8.2808e-04 - val_loss: 1.3884 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "418/418 [==============================] - 24s 57ms/step - loss: 1.3881 - accuracy: 5.7760e-04 - val_loss: 1.3884 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3881 - accuracy: 0.0010 - val_loss: 1.3884 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3882 - accuracy: 7.1251e-04 - val_loss: 1.3884 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3882 - accuracy: 0.0011 - val_loss: 1.3884 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3882 - accuracy: 5.6707e-04 - val_loss: 1.3884 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/30\n",
      "418/418 [==============================] - 24s 59ms/step - loss: 1.3883 - accuracy: 6.9799e-04 - val_loss: 1.3884 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3882 - accuracy: 9.0446e-04 - val_loss: 1.3884 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3882 - accuracy: 8.9250e-04 - val_loss: 1.3884 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3883 - accuracy: 9.2402e-04 - val_loss: 1.3884 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3881 - accuracy: 6.2517e-04 - val_loss: 1.3884 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3882 - accuracy: 8.4304e-04 - val_loss: 1.3884 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3882 - accuracy: 4.9451e-04 - val_loss: 1.3884 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3882 - accuracy: 6.1961e-04 - val_loss: 1.3884 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3881 - accuracy: 5.8118e-04 - val_loss: 1.3884 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3882 - accuracy: 4.9446e-04 - val_loss: 1.3884 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3882 - accuracy: 5.0567e-04 - val_loss: 1.3884 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3882 - accuracy: 8.0058e-04 - val_loss: 1.3884 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3882 - accuracy: 8.3434e-04 - val_loss: 1.3884 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3882 - accuracy: 6.2295e-04 - val_loss: 1.3884 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3882 - accuracy: 8.6153e-04 - val_loss: 1.3884 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3882 - accuracy: 5.8732e-04 - val_loss: 1.3884 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3882 - accuracy: 7.2591e-04 - val_loss: 1.3884 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3882 - accuracy: 3.2954e-04 - val_loss: 1.3884 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3882 - accuracy: 8.1875e-04 - val_loss: 1.3884 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3881 - accuracy: 7.0150e-04 - val_loss: 1.3884 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3883 - accuracy: 6.8555e-04 - val_loss: 1.3884 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3883 - accuracy: 8.8638e-04 - val_loss: 1.3884 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3883 - accuracy: 5.5701e-04 - val_loss: 1.3884 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3883 - accuracy: 7.7707e-04 - val_loss: 1.3884 - val_accuracy: 0.0000e+00\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_20871_images_False_newWeights_True_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.004132\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.25251758 0.24784303 0.25484667 0.24524141]\n",
      "Training resnet for 0.25% of train size (aka 20871 images) with pretrained: True and onlyLastLayersTrained: True...\n",
      "\n",
      "Total: 178 trainable: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/418 [..............................] - ETA: 3:00 - loss: 1.3776 - accuracy: 0.5697WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0602s vs `on_train_batch_begin` time: 0.1361s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0602s vs `on_train_batch_end` time: 0.1787s). Check your callbacks.\n",
      "418/418 [==============================] - 31s 65ms/step - loss: 1.3769 - accuracy: 0.5753 - val_loss: 1.3838 - val_accuracy: 0.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "418/418 [==============================] - 24s 57ms/step - loss: 1.3762 - accuracy: 0.5833 - val_loss: 1.3838 - val_accuracy: 0.5000\n",
      "Epoch 3/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3769 - accuracy: 0.5760 - val_loss: 1.3838 - val_accuracy: 0.5000\n",
      "Epoch 4/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3769 - accuracy: 0.5755 - val_loss: 1.3838 - val_accuracy: 0.5000\n",
      "Epoch 5/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3764 - accuracy: 0.5814 - val_loss: 1.3838 - val_accuracy: 0.5000\n",
      "Epoch 6/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3765 - accuracy: 0.5808 - val_loss: 1.3838 - val_accuracy: 0.5000\n",
      "Epoch 7/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3765 - accuracy: 0.5801 - val_loss: 1.3838 - val_accuracy: 0.5000\n",
      "Epoch 8/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3766 - accuracy: 0.5790 - val_loss: 1.3838 - val_accuracy: 0.5000\n",
      "Epoch 9/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3767 - accuracy: 0.5780 - val_loss: 1.3838 - val_accuracy: 0.5000\n",
      "Epoch 10/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3768 - accuracy: 0.5778 - val_loss: 1.3838 - val_accuracy: 0.5000\n",
      "Epoch 11/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3771 - accuracy: 0.5735 - val_loss: 1.3838 - val_accuracy: 0.5000\n",
      "Epoch 12/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3766 - accuracy: 0.5794 - val_loss: 1.3838 - val_accuracy: 0.5000\n",
      "Epoch 13/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3771 - accuracy: 0.5741 - val_loss: 1.3838 - val_accuracy: 0.5000\n",
      "Epoch 14/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3772 - accuracy: 0.5724 - val_loss: 1.3838 - val_accuracy: 0.5000\n",
      "Epoch 15/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3766 - accuracy: 0.5789 - val_loss: 1.3838 - val_accuracy: 0.5000\n",
      "Epoch 16/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3769 - accuracy: 0.5764 - val_loss: 1.3838 - val_accuracy: 0.5000\n",
      "Epoch 17/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3768 - accuracy: 0.5770 - val_loss: 1.3838 - val_accuracy: 0.5000\n",
      "Epoch 18/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3766 - accuracy: 0.5791 - val_loss: 1.3838 - val_accuracy: 0.5000\n",
      "Epoch 19/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3762 - accuracy: 0.5841 - val_loss: 1.3838 - val_accuracy: 0.5000\n",
      "Epoch 20/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3767 - accuracy: 0.5787 - val_loss: 1.3838 - val_accuracy: 0.5000\n",
      "Epoch 21/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3768 - accuracy: 0.5770 - val_loss: 1.3838 - val_accuracy: 0.5000\n",
      "Epoch 22/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3769 - accuracy: 0.5764 - val_loss: 1.3838 - val_accuracy: 0.5000\n",
      "Epoch 23/30\n",
      "418/418 [==============================] - 24s 57ms/step - loss: 1.3767 - accuracy: 0.5785 - val_loss: 1.3838 - val_accuracy: 0.5000\n",
      "Epoch 24/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3768 - accuracy: 0.5763 - val_loss: 1.3838 - val_accuracy: 0.5000\n",
      "Epoch 25/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3769 - accuracy: 0.5765 - val_loss: 1.3838 - val_accuracy: 0.5000\n",
      "Epoch 26/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3771 - accuracy: 0.5734 - val_loss: 1.3838 - val_accuracy: 0.5000\n",
      "Epoch 27/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3778 - accuracy: 0.5663 - val_loss: 1.3838 - val_accuracy: 0.5000\n",
      "Epoch 28/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3766 - accuracy: 0.5795 - val_loss: 1.3838 - val_accuracy: 0.5000\n",
      "Epoch 29/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3769 - accuracy: 0.5764 - val_loss: 1.3838 - val_accuracy: 0.5000\n",
      "Epoch 30/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3769 - accuracy: 0.5765 - val_loss: 1.3838 - val_accuracy: 0.5000\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_20871_images_False_newWeights_True_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.500000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.25251758 0.24784303 0.25484667 0.24524141]\n",
      "Training resnet for 0.25% of train size (aka 20871 images) with pretrained: True and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 178 trainable: 178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/418 [..............................] - ETA: 5:12 - loss: 1.3285 - accuracy: 0.3066WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1129s vs `on_train_batch_begin` time: 0.1444s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1129s vs `on_train_batch_end` time: 0.4001s). Check your callbacks.\n",
      "418/418 [==============================] - 96s 210ms/step - loss: 1.2517 - accuracy: 0.4318 - val_loss: 1.5047 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "418/418 [==============================] - 84s 201ms/step - loss: 1.2457 - accuracy: 0.4342 - val_loss: 1.5635 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "418/418 [==============================] - 84s 202ms/step - loss: 1.2418 - accuracy: 0.4378 - val_loss: 1.5471 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "418/418 [==============================] - 84s 202ms/step - loss: 1.2428 - accuracy: 0.4395 - val_loss: 1.5561 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "418/418 [==============================] - 84s 200ms/step - loss: 1.2408 - accuracy: 0.4333 - val_loss: 1.6401 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "418/418 [==============================] - 84s 200ms/step - loss: 1.2452 - accuracy: 0.4330 - val_loss: 1.5774 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "418/418 [==============================] - 84s 200ms/step - loss: 1.2323 - accuracy: 0.4444 - val_loss: 1.5862 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "418/418 [==============================] - 84s 200ms/step - loss: 1.2317 - accuracy: 0.4422 - val_loss: 1.5941 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "418/418 [==============================] - 84s 200ms/step - loss: 1.2243 - accuracy: 0.4517 - val_loss: 1.6033 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "418/418 [==============================] - 84s 200ms/step - loss: 1.2334 - accuracy: 0.4402 - val_loss: 1.5532 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "418/418 [==============================] - 83s 200ms/step - loss: 1.2345 - accuracy: 0.4351 - val_loss: 1.6055 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "418/418 [==============================] - 83s 200ms/step - loss: 1.2375 - accuracy: 0.4370 - val_loss: 1.5490 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "418/418 [==============================] - 84s 200ms/step - loss: 1.2343 - accuracy: 0.4387 - val_loss: 1.5504 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "418/418 [==============================] - 84s 200ms/step - loss: 1.2312 - accuracy: 0.4431 - val_loss: 1.5561 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "418/418 [==============================] - 84s 200ms/step - loss: 1.2301 - accuracy: 0.4432 - val_loss: 1.5913 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "418/418 [==============================] - 84s 200ms/step - loss: 1.2366 - accuracy: 0.4371 - val_loss: 1.5776 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "418/418 [==============================] - 84s 200ms/step - loss: 1.2272 - accuracy: 0.4420 - val_loss: 1.5339 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "418/418 [==============================] - 84s 200ms/step - loss: 1.2337 - accuracy: 0.4436 - val_loss: 1.5417 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "418/418 [==============================] - 83s 200ms/step - loss: 1.2310 - accuracy: 0.4458 - val_loss: 1.5695 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "418/418 [==============================] - 84s 200ms/step - loss: 1.2236 - accuracy: 0.4469 - val_loss: 1.5853 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "418/418 [==============================] - 84s 200ms/step - loss: 1.2300 - accuracy: 0.4427 - val_loss: 1.5612 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "418/418 [==============================] - 84s 200ms/step - loss: 1.2308 - accuracy: 0.4464 - val_loss: 1.5620 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "418/418 [==============================] - 84s 200ms/step - loss: 1.2350 - accuracy: 0.4404 - val_loss: 1.5475 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "418/418 [==============================] - 84s 200ms/step - loss: 1.2284 - accuracy: 0.4470 - val_loss: 1.5614 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "418/418 [==============================] - 83s 200ms/step - loss: 1.2317 - accuracy: 0.4428 - val_loss: 1.5513 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "418/418 [==============================] - 83s 200ms/step - loss: 1.2283 - accuracy: 0.4427 - val_loss: 1.5719 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "418/418 [==============================] - 84s 200ms/step - loss: 1.2328 - accuracy: 0.4384 - val_loss: 1.5676 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "418/418 [==============================] - 84s 200ms/step - loss: 1.2324 - accuracy: 0.4434 - val_loss: 1.5537 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "418/418 [==============================] - 84s 200ms/step - loss: 1.2292 - accuracy: 0.4430 - val_loss: 1.5697 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "418/418 [==============================] - 84s 200ms/step - loss: 1.2301 - accuracy: 0.4434 - val_loss: 1.5410 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_20871_images_False_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.25251758 0.24784303 0.25484667 0.24524141]\n",
      "Training resnet for 0.25% of train size (aka 20871 images) with pretrained: True and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 178 trainable: 178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/418 [..............................] - ETA: 4:52 - loss: 1.3117 - accuracy: 0.4441WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1046s vs `on_train_batch_begin` time: 0.1457s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1046s vs `on_train_batch_end` time: 0.3660s). Check your callbacks.\n",
      "418/418 [==============================] - 94s 205ms/step - loss: 1.2432 - accuracy: 0.4387 - val_loss: 1.6405 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "418/418 [==============================] - 83s 198ms/step - loss: 1.2393 - accuracy: 0.4379 - val_loss: 1.5447 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "418/418 [==============================] - 83s 198ms/step - loss: 1.2448 - accuracy: 0.4302 - val_loss: 1.5949 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "418/418 [==============================] - 83s 198ms/step - loss: 1.2389 - accuracy: 0.4420 - val_loss: 1.5393 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "418/418 [==============================] - 82s 197ms/step - loss: 1.2425 - accuracy: 0.4365 - val_loss: 1.5645 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "418/418 [==============================] - 82s 197ms/step - loss: 1.2401 - accuracy: 0.4345 - val_loss: 1.5599 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "418/418 [==============================] - 82s 197ms/step - loss: 1.2355 - accuracy: 0.4381 - val_loss: 1.5195 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "418/418 [==============================] - 82s 197ms/step - loss: 1.2343 - accuracy: 0.4407 - val_loss: 1.6285 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "418/418 [==============================] - 82s 197ms/step - loss: 1.2287 - accuracy: 0.4431 - val_loss: 1.5469 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "418/418 [==============================] - 82s 197ms/step - loss: 1.2413 - accuracy: 0.4360 - val_loss: 1.5319 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "418/418 [==============================] - 82s 197ms/step - loss: 1.2367 - accuracy: 0.4351 - val_loss: 1.5704 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "418/418 [==============================] - 82s 197ms/step - loss: 1.2362 - accuracy: 0.4389 - val_loss: 1.5761 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "418/418 [==============================] - 82s 197ms/step - loss: 1.2360 - accuracy: 0.4391 - val_loss: 1.5784 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "418/418 [==============================] - 82s 197ms/step - loss: 1.2364 - accuracy: 0.4368 - val_loss: 1.5461 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "418/418 [==============================] - 82s 197ms/step - loss: 1.2345 - accuracy: 0.4366 - val_loss: 1.5691 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "418/418 [==============================] - 82s 197ms/step - loss: 1.2318 - accuracy: 0.4428 - val_loss: 1.5269 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "418/418 [==============================] - 82s 197ms/step - loss: 1.2352 - accuracy: 0.4411 - val_loss: 1.5373 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "418/418 [==============================] - 82s 196ms/step - loss: 1.2380 - accuracy: 0.4363 - val_loss: 1.5670 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "418/418 [==============================] - 82s 196ms/step - loss: 1.2341 - accuracy: 0.4399 - val_loss: 1.5581 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "418/418 [==============================] - 82s 196ms/step - loss: 1.2314 - accuracy: 0.4410 - val_loss: 1.5713 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "418/418 [==============================] - 82s 196ms/step - loss: 1.2378 - accuracy: 0.4400 - val_loss: 1.5352 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "418/418 [==============================] - 82s 197ms/step - loss: 1.2265 - accuracy: 0.4481 - val_loss: 1.5572 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "418/418 [==============================] - 82s 197ms/step - loss: 1.2343 - accuracy: 0.4420 - val_loss: 1.5632 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "418/418 [==============================] - 82s 196ms/step - loss: 1.2357 - accuracy: 0.4441 - val_loss: 1.5287 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "418/418 [==============================] - 82s 196ms/step - loss: 1.2370 - accuracy: 0.4422 - val_loss: 1.5596 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "418/418 [==============================] - 82s 197ms/step - loss: 1.2326 - accuracy: 0.4392 - val_loss: 1.5636 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "418/418 [==============================] - 82s 197ms/step - loss: 1.2313 - accuracy: 0.4386 - val_loss: 1.5613 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "418/418 [==============================] - 82s 196ms/step - loss: 1.2249 - accuracy: 0.4414 - val_loss: 1.5443 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "418/418 [==============================] - 82s 196ms/step - loss: 1.2336 - accuracy: 0.4400 - val_loss: 1.5602 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "418/418 [==============================] - 82s 196ms/step - loss: 1.2315 - accuracy: 0.4456 - val_loss: 1.5556 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_20871_images_False_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.25251758 0.24784303 0.25484667 0.24524141]\n",
      "Training resnet for 0.25% of train size (aka 20871 images) with pretrained: True and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 178 trainable: 178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/418 [..............................] - ETA: 4:56 - loss: 1.3261 - accuracy: 0.3531WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1097s vs `on_train_batch_begin` time: 0.1395s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1097s vs `on_train_batch_end` time: 0.3757s). Check your callbacks.\n",
      "418/418 [==============================] - 94s 207ms/step - loss: 1.2403 - accuracy: 0.4383 - val_loss: 1.5387 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "418/418 [==============================] - 84s 200ms/step - loss: 1.2312 - accuracy: 0.4321 - val_loss: 1.5677 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "418/418 [==============================] - 84s 201ms/step - loss: 1.2347 - accuracy: 0.4478 - val_loss: 1.5215 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "418/418 [==============================] - 84s 200ms/step - loss: 1.2295 - accuracy: 0.4450 - val_loss: 1.5619 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "418/418 [==============================] - 84s 200ms/step - loss: 1.2368 - accuracy: 0.4400 - val_loss: 1.5845 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "418/418 [==============================] - 83s 199ms/step - loss: 1.2350 - accuracy: 0.4449 - val_loss: 1.5548 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "418/418 [==============================] - 83s 199ms/step - loss: 1.2288 - accuracy: 0.4479 - val_loss: 1.5463 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "418/418 [==============================] - 83s 199ms/step - loss: 1.2322 - accuracy: 0.4411 - val_loss: 1.5834 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "418/418 [==============================] - 84s 200ms/step - loss: 1.2405 - accuracy: 0.4404 - val_loss: 1.5899 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "418/418 [==============================] - 83s 200ms/step - loss: 1.2338 - accuracy: 0.4418 - val_loss: 1.5268 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "418/418 [==============================] - 83s 199ms/step - loss: 1.2364 - accuracy: 0.4383 - val_loss: 1.5303 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "418/418 [==============================] - 83s 199ms/step - loss: 1.2310 - accuracy: 0.4408 - val_loss: 1.5232 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "418/418 [==============================] - 83s 199ms/step - loss: 1.2275 - accuracy: 0.4466 - val_loss: 1.5658 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "418/418 [==============================] - 83s 199ms/step - loss: 1.2343 - accuracy: 0.4408 - val_loss: 1.5517 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "418/418 [==============================] - 83s 199ms/step - loss: 1.2310 - accuracy: 0.4394 - val_loss: 1.5405 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "418/418 [==============================] - 83s 199ms/step - loss: 1.2336 - accuracy: 0.4414 - val_loss: 1.5510 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "418/418 [==============================] - 83s 199ms/step - loss: 1.2319 - accuracy: 0.4367 - val_loss: 1.5357 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "418/418 [==============================] - 83s 199ms/step - loss: 1.2352 - accuracy: 0.4401 - val_loss: 1.5479 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "418/418 [==============================] - 83s 199ms/step - loss: 1.2320 - accuracy: 0.4422 - val_loss: 1.5891 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "418/418 [==============================] - 83s 199ms/step - loss: 1.2298 - accuracy: 0.4411 - val_loss: 1.5517 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "418/418 [==============================] - 83s 199ms/step - loss: 1.2284 - accuracy: 0.4459 - val_loss: 1.5395 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "418/418 [==============================] - 83s 199ms/step - loss: 1.2299 - accuracy: 0.4381 - val_loss: 1.5574 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "418/418 [==============================] - 83s 199ms/step - loss: 1.2308 - accuracy: 0.4423 - val_loss: 1.5635 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "418/418 [==============================] - 83s 199ms/step - loss: 1.2299 - accuracy: 0.4393 - val_loss: 1.5394 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "418/418 [==============================] - 83s 199ms/step - loss: 1.2382 - accuracy: 0.4348 - val_loss: 1.5544 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "418/418 [==============================] - 83s 199ms/step - loss: 1.2353 - accuracy: 0.4357 - val_loss: 1.5573 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "418/418 [==============================] - 83s 199ms/step - loss: 1.2302 - accuracy: 0.4402 - val_loss: 1.5647 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "418/418 [==============================] - 83s 199ms/step - loss: 1.2348 - accuracy: 0.4400 - val_loss: 1.5666 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "418/418 [==============================] - 83s 199ms/step - loss: 1.2388 - accuracy: 0.4420 - val_loss: 1.5725 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "418/418 [==============================] - 83s 199ms/step - loss: 1.2348 - accuracy: 0.4398 - val_loss: 1.5523 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_20871_images_False_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.25251758 0.24784303 0.25484667 0.24524141]\n",
      "Training resnet for 0.25% of train size (aka 20871 images) with pretrained: True and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 178 trainable: 178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/418 [..............................] - ETA: 4:35 - loss: 1.3274 - accuracy: 0.4353WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1041s vs `on_train_batch_begin` time: 0.1392s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1041s vs `on_train_batch_end` time: 0.3418s). Check your callbacks.\n",
      "418/418 [==============================] - 92s 204ms/step - loss: 1.2455 - accuracy: 0.4368 - val_loss: 1.5593 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "418/418 [==============================] - 82s 196ms/step - loss: 1.2334 - accuracy: 0.4402 - val_loss: 1.5873 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "418/418 [==============================] - 82s 197ms/step - loss: 1.2456 - accuracy: 0.4334 - val_loss: 1.5660 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "418/418 [==============================] - 82s 197ms/step - loss: 1.2307 - accuracy: 0.4432 - val_loss: 1.5810 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "418/418 [==============================] - 82s 197ms/step - loss: 1.2408 - accuracy: 0.4249 - val_loss: 1.5739 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "418/418 [==============================] - 82s 197ms/step - loss: 1.2331 - accuracy: 0.4388 - val_loss: 1.6014 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "418/418 [==============================] - 82s 196ms/step - loss: 1.2381 - accuracy: 0.4412 - val_loss: 1.5646 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "418/418 [==============================] - 82s 196ms/step - loss: 1.2333 - accuracy: 0.4390 - val_loss: 1.5370 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "418/418 [==============================] - 82s 196ms/step - loss: 1.2352 - accuracy: 0.4395 - val_loss: 1.5945 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "418/418 [==============================] - 82s 196ms/step - loss: 1.2345 - accuracy: 0.4419 - val_loss: 1.5700 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "418/418 [==============================] - 82s 197ms/step - loss: 1.2321 - accuracy: 0.4426 - val_loss: 1.5746 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "418/418 [==============================] - 82s 196ms/step - loss: 1.2329 - accuracy: 0.4404 - val_loss: 1.5666 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "418/418 [==============================] - 82s 196ms/step - loss: 1.2326 - accuracy: 0.4430 - val_loss: 1.5458 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "418/418 [==============================] - 82s 197ms/step - loss: 1.2329 - accuracy: 0.4394 - val_loss: 1.5851 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "418/418 [==============================] - 82s 197ms/step - loss: 1.2370 - accuracy: 0.4380 - val_loss: 1.5545 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "418/418 [==============================] - 82s 197ms/step - loss: 1.2347 - accuracy: 0.4423 - val_loss: 1.5683 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "418/418 [==============================] - 82s 196ms/step - loss: 1.2304 - accuracy: 0.4420 - val_loss: 1.5264 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "418/418 [==============================] - 82s 196ms/step - loss: 1.2281 - accuracy: 0.4452 - val_loss: 1.5389 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "418/418 [==============================] - 82s 196ms/step - loss: 1.2323 - accuracy: 0.4414 - val_loss: 1.5678 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "418/418 [==============================] - 82s 196ms/step - loss: 1.2306 - accuracy: 0.4421 - val_loss: 1.5692 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "418/418 [==============================] - 82s 196ms/step - loss: 1.2307 - accuracy: 0.4415 - val_loss: 1.5589 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "418/418 [==============================] - 82s 196ms/step - loss: 1.2359 - accuracy: 0.4374 - val_loss: 1.5494 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "418/418 [==============================] - 82s 196ms/step - loss: 1.2434 - accuracy: 0.4327 - val_loss: 1.5799 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "418/418 [==============================] - 82s 196ms/step - loss: 1.2348 - accuracy: 0.4360 - val_loss: 1.5495 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "418/418 [==============================] - 82s 197ms/step - loss: 1.2280 - accuracy: 0.4489 - val_loss: 1.5557 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "418/418 [==============================] - 82s 196ms/step - loss: 1.2248 - accuracy: 0.4501 - val_loss: 1.5520 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "418/418 [==============================] - 82s 196ms/step - loss: 1.2280 - accuracy: 0.4480 - val_loss: 1.5511 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "418/418 [==============================] - 82s 196ms/step - loss: 1.2345 - accuracy: 0.4386 - val_loss: 1.5728 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "418/418 [==============================] - 82s 196ms/step - loss: 1.2291 - accuracy: 0.4413 - val_loss: 1.5631 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "418/418 [==============================] - 82s 196ms/step - loss: 1.2357 - accuracy: 0.4379 - val_loss: 1.5650 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_20871_images_False_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.25251758 0.24784303 0.25484667 0.24524141]\n",
      "Training resnet for 0.25% of train size (aka 20871 images) with pretrained: True and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 178 trainable: 178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/418 [..............................] - ETA: 5:20 - loss: 1.3825 - accuracy: 0.2682WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1135s vs `on_train_batch_begin` time: 0.1440s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1135s vs `on_train_batch_end` time: 0.4151s). Check your callbacks.\n",
      "418/418 [==============================] - 96s 208ms/step - loss: 1.2555 - accuracy: 0.4344 - val_loss: 1.5441 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "418/418 [==============================] - 83s 200ms/step - loss: 1.2253 - accuracy: 0.4427 - val_loss: 1.5752 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "418/418 [==============================] - 84s 201ms/step - loss: 1.2321 - accuracy: 0.4421 - val_loss: 1.5708 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "418/418 [==============================] - 84s 200ms/step - loss: 1.2316 - accuracy: 0.4402 - val_loss: 1.5602 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "418/418 [==============================] - 84s 200ms/step - loss: 1.2253 - accuracy: 0.4452 - val_loss: 1.5373 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "418/418 [==============================] - 83s 200ms/step - loss: 1.2326 - accuracy: 0.4382 - val_loss: 1.5622 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "418/418 [==============================] - 83s 200ms/step - loss: 1.2355 - accuracy: 0.4395 - val_loss: 1.5591 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "418/418 [==============================] - 83s 200ms/step - loss: 1.2298 - accuracy: 0.4441 - val_loss: 1.5579 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "418/418 [==============================] - 84s 200ms/step - loss: 1.2212 - accuracy: 0.4463 - val_loss: 1.5575 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "418/418 [==============================] - 84s 200ms/step - loss: 1.2292 - accuracy: 0.4456 - val_loss: 1.5472 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "418/418 [==============================] - 84s 200ms/step - loss: 1.2250 - accuracy: 0.4477 - val_loss: 1.5484 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "418/418 [==============================] - 84s 200ms/step - loss: 1.2350 - accuracy: 0.4390 - val_loss: 1.5618 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "418/418 [==============================] - 84s 200ms/step - loss: 1.2316 - accuracy: 0.4406 - val_loss: 1.5502 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "418/418 [==============================] - 84s 200ms/step - loss: 1.2328 - accuracy: 0.4378 - val_loss: 1.5530 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "418/418 [==============================] - 84s 200ms/step - loss: 1.2357 - accuracy: 0.4395 - val_loss: 1.5590 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "418/418 [==============================] - 84s 200ms/step - loss: 1.2301 - accuracy: 0.4438 - val_loss: 1.5582 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "418/418 [==============================] - 84s 200ms/step - loss: 1.2369 - accuracy: 0.4328 - val_loss: 1.5632 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "418/418 [==============================] - 84s 200ms/step - loss: 1.2291 - accuracy: 0.4443 - val_loss: 1.5526 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "418/418 [==============================] - 84s 200ms/step - loss: 1.2245 - accuracy: 0.4436 - val_loss: 1.5514 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "418/418 [==============================] - 84s 200ms/step - loss: 1.2329 - accuracy: 0.4419 - val_loss: 1.5596 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "418/418 [==============================] - 84s 200ms/step - loss: 1.2337 - accuracy: 0.4392 - val_loss: 1.5556 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "418/418 [==============================] - 84s 200ms/step - loss: 1.2228 - accuracy: 0.4429 - val_loss: 1.5495 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "418/418 [==============================] - 84s 200ms/step - loss: 1.2360 - accuracy: 0.4404 - val_loss: 1.5607 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "418/418 [==============================] - 83s 199ms/step - loss: 1.2259 - accuracy: 0.4453 - val_loss: 1.5528 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "418/418 [==============================] - 83s 200ms/step - loss: 1.2328 - accuracy: 0.4425 - val_loss: 1.5580 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "418/418 [==============================] - 83s 199ms/step - loss: 1.2294 - accuracy: 0.4411 - val_loss: 1.5574 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "418/418 [==============================] - 83s 199ms/step - loss: 1.2339 - accuracy: 0.4394 - val_loss: 1.5599 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "418/418 [==============================] - 83s 200ms/step - loss: 1.2352 - accuracy: 0.4399 - val_loss: 1.5594 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "418/418 [==============================] - 83s 199ms/step - loss: 1.2269 - accuracy: 0.4463 - val_loss: 1.5576 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "418/418 [==============================] - 83s 199ms/step - loss: 1.2294 - accuracy: 0.4494 - val_loss: 1.5571 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_20871_images_False_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.25251758 0.24784303 0.25484667 0.24524141]\n",
      "Training resnet for 0.25% of train size (aka 20871 images) with pretrained: True and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 178 trainable: 178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/418 [..............................] - ETA: 4:32 - loss: 1.3655 - accuracy: 0.4835WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1006s vs `on_train_batch_begin` time: 0.1393s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1006s vs `on_train_batch_end` time: 0.3377s). Check your callbacks.\n",
      "418/418 [==============================] - 92s 204ms/step - loss: 1.2502 - accuracy: 0.4416 - val_loss: 1.5524 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "418/418 [==============================] - 82s 197ms/step - loss: 1.2298 - accuracy: 0.4419 - val_loss: 1.5460 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "418/418 [==============================] - 82s 197ms/step - loss: 1.2289 - accuracy: 0.4449 - val_loss: 1.5596 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "418/418 [==============================] - 82s 197ms/step - loss: 1.2279 - accuracy: 0.4447 - val_loss: 1.5441 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "418/418 [==============================] - 82s 197ms/step - loss: 1.2350 - accuracy: 0.4405 - val_loss: 1.5544 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "418/418 [==============================] - 82s 197ms/step - loss: 1.2319 - accuracy: 0.4423 - val_loss: 1.5422 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "418/418 [==============================] - 82s 197ms/step - loss: 1.2375 - accuracy: 0.4378 - val_loss: 1.5920 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "418/418 [==============================] - 82s 197ms/step - loss: 1.2315 - accuracy: 0.4435 - val_loss: 1.5614 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "418/418 [==============================] - 82s 197ms/step - loss: 1.2305 - accuracy: 0.4451 - val_loss: 1.5615 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "418/418 [==============================] - 82s 196ms/step - loss: 1.2292 - accuracy: 0.4416 - val_loss: 1.5562 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "418/418 [==============================] - 82s 197ms/step - loss: 1.2341 - accuracy: 0.4400 - val_loss: 1.5665 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "418/418 [==============================] - 82s 197ms/step - loss: 1.2338 - accuracy: 0.4393 - val_loss: 1.5571 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "418/418 [==============================] - 82s 197ms/step - loss: 1.2289 - accuracy: 0.4414 - val_loss: 1.5598 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "418/418 [==============================] - 82s 197ms/step - loss: 1.2273 - accuracy: 0.4452 - val_loss: 1.5600 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "418/418 [==============================] - 82s 197ms/step - loss: 1.2293 - accuracy: 0.4465 - val_loss: 1.5559 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "418/418 [==============================] - 82s 197ms/step - loss: 1.2283 - accuracy: 0.4461 - val_loss: 1.5600 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "418/418 [==============================] - 82s 197ms/step - loss: 1.2342 - accuracy: 0.4411 - val_loss: 1.5610 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "418/418 [==============================] - 82s 196ms/step - loss: 1.2282 - accuracy: 0.4435 - val_loss: 1.5531 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "418/418 [==============================] - 82s 197ms/step - loss: 1.2288 - accuracy: 0.4487 - val_loss: 1.5525 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "418/418 [==============================] - 82s 196ms/step - loss: 1.2292 - accuracy: 0.4409 - val_loss: 1.5521 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "418/418 [==============================] - 82s 196ms/step - loss: 1.2311 - accuracy: 0.4413 - val_loss: 1.5561 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "418/418 [==============================] - 82s 197ms/step - loss: 1.2311 - accuracy: 0.4392 - val_loss: 1.5578 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "418/418 [==============================] - 82s 197ms/step - loss: 1.2286 - accuracy: 0.4428 - val_loss: 1.5573 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "418/418 [==============================] - 82s 197ms/step - loss: 1.2275 - accuracy: 0.4446 - val_loss: 1.5556 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "418/418 [==============================] - 82s 197ms/step - loss: 1.2309 - accuracy: 0.4421 - val_loss: 1.5555 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "418/418 [==============================] - 82s 197ms/step - loss: 1.2261 - accuracy: 0.4478 - val_loss: 1.5522 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "418/418 [==============================] - 82s 197ms/step - loss: 1.2252 - accuracy: 0.4498 - val_loss: 1.5528 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "418/418 [==============================] - 82s 197ms/step - loss: 1.2302 - accuracy: 0.4464 - val_loss: 1.5556 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "418/418 [==============================] - 82s 197ms/step - loss: 1.2333 - accuracy: 0.4431 - val_loss: 1.5582 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "418/418 [==============================] - 82s 197ms/step - loss: 1.2355 - accuracy: 0.4348 - val_loss: 1.5582 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_20871_images_False_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.25251758 0.24784303 0.25484667 0.24524141]\n",
      "Training resnet for 0.25% of train size (aka 20871 images) with pretrained: True and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 178 trainable: 178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/418 [..............................] - ETA: 5:20 - loss: 1.3591 - accuracy: 0.4813WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1123s vs `on_train_batch_begin` time: 0.1439s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1123s vs `on_train_batch_end` time: 0.4157s). Check your callbacks.\n",
      "418/418 [==============================] - 96s 208ms/step - loss: 1.2607 - accuracy: 0.4453 - val_loss: 1.5581 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "418/418 [==============================] - 83s 200ms/step - loss: 1.2300 - accuracy: 0.4426 - val_loss: 1.5487 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "418/418 [==============================] - 84s 200ms/step - loss: 1.2342 - accuracy: 0.4389 - val_loss: 1.5630 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "418/418 [==============================] - 84s 200ms/step - loss: 1.2307 - accuracy: 0.4419 - val_loss: 1.5565 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "418/418 [==============================] - 84s 200ms/step - loss: 1.2253 - accuracy: 0.4481 - val_loss: 1.5552 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "418/418 [==============================] - 84s 200ms/step - loss: 1.2357 - accuracy: 0.4394 - val_loss: 1.5529 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "418/418 [==============================] - 84s 200ms/step - loss: 1.2305 - accuracy: 0.4407 - val_loss: 1.5546 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "418/418 [==============================] - 84s 200ms/step - loss: 1.2276 - accuracy: 0.4437 - val_loss: 1.5488 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "418/418 [==============================] - 84s 200ms/step - loss: 1.2316 - accuracy: 0.4406 - val_loss: 1.5603 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "418/418 [==============================] - 83s 200ms/step - loss: 1.2339 - accuracy: 0.4371 - val_loss: 1.5588 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "418/418 [==============================] - 83s 200ms/step - loss: 1.2307 - accuracy: 0.4375 - val_loss: 1.5555 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "418/418 [==============================] - 83s 200ms/step - loss: 1.2257 - accuracy: 0.4435 - val_loss: 1.5497 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "418/418 [==============================] - 83s 200ms/step - loss: 1.2329 - accuracy: 0.4404 - val_loss: 1.5574 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "418/418 [==============================] - 83s 200ms/step - loss: 1.2344 - accuracy: 0.4377 - val_loss: 1.5633 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "418/418 [==============================] - 83s 200ms/step - loss: 1.2226 - accuracy: 0.4451 - val_loss: 1.5517 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "418/418 [==============================] - 83s 200ms/step - loss: 1.2317 - accuracy: 0.4391 - val_loss: 1.5578 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "418/418 [==============================] - 83s 200ms/step - loss: 1.2310 - accuracy: 0.4399 - val_loss: 1.5570 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "418/418 [==============================] - 84s 200ms/step - loss: 1.2346 - accuracy: 0.4387 - val_loss: 1.5596 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "418/418 [==============================] - 83s 199ms/step - loss: 1.2327 - accuracy: 0.4419 - val_loss: 1.5588 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "418/418 [==============================] - 83s 199ms/step - loss: 1.2290 - accuracy: 0.4428 - val_loss: 1.5556 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "418/418 [==============================] - 84s 200ms/step - loss: 1.2328 - accuracy: 0.4437 - val_loss: 1.5557 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "418/418 [==============================] - 84s 200ms/step - loss: 1.2372 - accuracy: 0.4420 - val_loss: 1.5596 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "418/418 [==============================] - 83s 199ms/step - loss: 1.2286 - accuracy: 0.4443 - val_loss: 1.5584 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "418/418 [==============================] - 83s 199ms/step - loss: 1.2292 - accuracy: 0.4453 - val_loss: 1.5566 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "418/418 [==============================] - 83s 199ms/step - loss: 1.2359 - accuracy: 0.4383 - val_loss: 1.5574 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "418/418 [==============================] - 83s 200ms/step - loss: 1.2278 - accuracy: 0.4439 - val_loss: 1.5567 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "418/418 [==============================] - 83s 200ms/step - loss: 1.2403 - accuracy: 0.4361 - val_loss: 1.5583 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "418/418 [==============================] - 83s 200ms/step - loss: 1.2349 - accuracy: 0.4363 - val_loss: 1.5585 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "418/418 [==============================] - 84s 200ms/step - loss: 1.2328 - accuracy: 0.4418 - val_loss: 1.5574 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "418/418 [==============================] - 84s 200ms/step - loss: 1.2271 - accuracy: 0.4424 - val_loss: 1.5568 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_20871_images_False_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.25251758 0.24784303 0.25484667 0.24524141]\n",
      "Training resnet for 0.25% of train size (aka 20871 images) with pretrained: True and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 178 trainable: 178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/418 [..............................] - ETA: 4:45 - loss: 1.3836 - accuracy: 0.1014WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1037s vs `on_train_batch_begin` time: 0.1506s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1037s vs `on_train_batch_end` time: 0.3494s). Check your callbacks.\n",
      "418/418 [==============================] - 92s 204ms/step - loss: 1.2671 - accuracy: 0.4242 - val_loss: 1.5500 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "418/418 [==============================] - 82s 196ms/step - loss: 1.2346 - accuracy: 0.4402 - val_loss: 1.5529 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "418/418 [==============================] - 82s 197ms/step - loss: 1.2313 - accuracy: 0.4464 - val_loss: 1.5567 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "418/418 [==============================] - 82s 197ms/step - loss: 1.2290 - accuracy: 0.4427 - val_loss: 1.5496 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "418/418 [==============================] - 82s 197ms/step - loss: 1.2316 - accuracy: 0.4397 - val_loss: 1.5471 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "418/418 [==============================] - 82s 197ms/step - loss: 1.2331 - accuracy: 0.4446 - val_loss: 1.5627 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "418/418 [==============================] - 82s 197ms/step - loss: 1.2347 - accuracy: 0.4393 - val_loss: 1.5601 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "418/418 [==============================] - 82s 196ms/step - loss: 1.2294 - accuracy: 0.4419 - val_loss: 1.5575 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "418/418 [==============================] - 82s 197ms/step - loss: 1.2257 - accuracy: 0.4475 - val_loss: 1.5440 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "418/418 [==============================] - 82s 196ms/step - loss: 1.2241 - accuracy: 0.4474 - val_loss: 1.5435 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "418/418 [==============================] - 82s 196ms/step - loss: 1.2287 - accuracy: 0.4450 - val_loss: 1.5607 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "418/418 [==============================] - 82s 196ms/step - loss: 1.2327 - accuracy: 0.4413 - val_loss: 1.5532 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "418/418 [==============================] - 82s 196ms/step - loss: 1.2301 - accuracy: 0.4464 - val_loss: 1.5611 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "418/418 [==============================] - 82s 197ms/step - loss: 1.2303 - accuracy: 0.4407 - val_loss: 1.5556 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "418/418 [==============================] - 82s 197ms/step - loss: 1.2256 - accuracy: 0.4490 - val_loss: 1.5528 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "418/418 [==============================] - 82s 196ms/step - loss: 1.2327 - accuracy: 0.4442 - val_loss: 1.5574 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "418/418 [==============================] - 82s 196ms/step - loss: 1.2303 - accuracy: 0.4431 - val_loss: 1.5563 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "418/418 [==============================] - 82s 196ms/step - loss: 1.2324 - accuracy: 0.4411 - val_loss: 1.5583 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "418/418 [==============================] - 82s 196ms/step - loss: 1.2361 - accuracy: 0.4383 - val_loss: 1.5615 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "418/418 [==============================] - 82s 196ms/step - loss: 1.2353 - accuracy: 0.4375 - val_loss: 1.5579 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "418/418 [==============================] - 82s 196ms/step - loss: 1.2268 - accuracy: 0.4469 - val_loss: 1.5555 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "418/418 [==============================] - 82s 197ms/step - loss: 1.2278 - accuracy: 0.4489 - val_loss: 1.5553 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "418/418 [==============================] - 82s 196ms/step - loss: 1.2266 - accuracy: 0.4439 - val_loss: 1.5555 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "418/418 [==============================] - 82s 196ms/step - loss: 1.2366 - accuracy: 0.4389 - val_loss: 1.5583 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "418/418 [==============================] - 82s 197ms/step - loss: 1.2384 - accuracy: 0.4358 - val_loss: 1.5589 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "418/418 [==============================] - 82s 196ms/step - loss: 1.2337 - accuracy: 0.4398 - val_loss: 1.5572 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "418/418 [==============================] - 82s 197ms/step - loss: 1.2341 - accuracy: 0.4408 - val_loss: 1.5576 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "418/418 [==============================] - 82s 197ms/step - loss: 1.2300 - accuracy: 0.4459 - val_loss: 1.5565 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "418/418 [==============================] - 82s 197ms/step - loss: 1.2286 - accuracy: 0.4422 - val_loss: 1.5566 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "418/418 [==============================] - 82s 196ms/step - loss: 1.2264 - accuracy: 0.4396 - val_loss: 1.5563 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_20871_images_False_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import datetime\n",
    "\n",
    "maxTrain = len(y_train)\n",
    "for newWeights in [True, False]:\n",
    "    tLayer = [False] if newWeights else [True, False] # do not train only last layer if new weights will be produced \n",
    "    for trainLastLayerOnly in tLayer:\n",
    "        #for p in [0.01, 0.025, 0.05, 0.075, 0.09, 0.1, 0.25, 0.4, 0.5, 0.6, 0.75, 0.9, 1.0]:\n",
    "        p = 0.25\n",
    "        for learning_rate in [0.1, 0.05, 0.01, 0.005]:\n",
    "            for amsgrad in [True, False]:\n",
    "                #X_trn, X_tst, y_trn, y_tst\n",
    "                if p < 1:\n",
    "                    X_t, _, y_t, _ = train_test_split(images, y_train, test_size=1-p, random_state=56789)\n",
    "                else:\n",
    "                    X_t = images; y_t = y_train;\n",
    "                print(f\"Labels fraction: {sum(y_t == 1) / sum(y_train == 1)}\")\n",
    "                for net in [\"resnet\"]:\n",
    "                    print(f\"Training {net} for {p}% of train size (aka {len(X_t)} images) with pretrained: {not newWeights} and onlyLastLayersTrained: {trainLastLayerOnly}...\")\n",
    "                    model, size, normalization = emptyModelGenerator(net, newWeights=newWeights, lastOnly=trainLastLayerOnly)\n",
    "                    printTrainableLayers(model) # see if model is really well trained\n",
    "                    X_trn = resizeIms(X_t, size)\n",
    "                    #X_trn = normalizeIms(X_trn, normalization=normalization)\n",
    "                    X_val = resizeIms(x_val, size)\n",
    "                    #X_val = normalizeIms(X_val, normalization=normalization)\n",
    "                    log_dir = f\"logs/{net}/fit/{p}trainSet_\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "                    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "                    optimizer = Adam(learning_rate, amsgrad=amsgrad) #SGD(learning_rate=learning_rate, momentum=momentum) # # create new optimizers\n",
    "                    time_callback = TimeHistory()\n",
    "                    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "                    hist = model.fit(X_trn, y_t, epochs=epochs, validation_data = (X_val, y_validation), batch_size=batch_size,\n",
    "                                shuffle=True, max_queue_size=20,\n",
    "                                use_multiprocessing=True, workers=5, \n",
    "                                callbacks=[CustomCallback(fraction=0.9, model=net), tensorboard_callback, time_callback])\n",
    "                    trainTime = sum(time_callback.times)\n",
    "                    model.save(f\"../{net}/{net}_{epochs}epochs_{p*maxTrain:.0f}_images_{newWeights}_newWeights_{trainLastLayerOnly}_lastLayerOnly_{normalization}_normalization\")\n",
    "                    tstAcc = testPredict(model, size, name=net) #, normalization=normalization)\n",
    "                    results = results.append({\n",
    "                        'model': net, \n",
    "                        'train set images': len(X_t), \n",
    "                        'pretrained': not newWeights, \n",
    "                        'pretrained dataset': None if newWeights or net == \"octnet\" else (\"OCT2017,Srinivasan2014\" if net == \"opticnet\" else \"Imagenet\"),\n",
    "                        'Trained layers': \"Last dense\" if trainLastLayerOnly else \"All\", \n",
    "                        'epochs': epochs, \n",
    "                        'batch size': batch_size, \n",
    "                        'learning rate': f\"{learning_rate}_{momentum}\" if optimizer._name == \"SGD\" else learning_rate, \n",
    "                        'optimizer': \"Amsgrad\" if (optimizer._name == \"Adam\" and amsgrad) else optimizer._name,\n",
    "                        'training time (seconds)': trainTime, \n",
    "                        'train accuracy': hist.history[\"accuracy\"][-1], \n",
    "                        'train loss': hist.history[\"loss\"][-1],\n",
    "                        'validation accuracy': hist.history[\"val_accuracy\"][-1], \n",
    "                        'validation loss': hist.history[\"val_loss\"][-1], \n",
    "                        'test accuracy': tstAcc,\n",
    "                        #'normalization': normalization\n",
    "                    }, ignore_index=True)\n",
    "                    results.to_csv(\"Results_temp.csv\", index=False)\n",
    "                    del model\n",
    "                    del X_trn\n",
    "                    del X_val\n",
    "                    print(\"Done!\\n\" + '-'*50, end='\\n\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
