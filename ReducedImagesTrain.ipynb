{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "import os\n",
    "import cv2\n",
    "import pickle\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version is: 2.4.1\n"
     ]
    }
   ],
   "source": [
    "print(f\"Tensorflow version is: {tf.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataPath = \"../../data/OCT/OCT2017/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of Classes Detected : 4\n"
     ]
    }
   ],
   "source": [
    "labels_available = os.listdir(os.path.join(dataPath, \"train\"))\n",
    "print(\"Total Number of Classes Detected :\",len(labels_available))\n",
    "\n",
    "labels_list = ['NORMAL',\"CNV\",\"DME\",\"DRUSEN\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NORMAL CNV DME DRUSEN "
     ]
    }
   ],
   "source": [
    "images=[]\n",
    "y_trn=[]\n",
    "for x in labels_list:\n",
    "    xPath = os.path.join(dataPath, \"train\", x)\n",
    "    myPicList = os.listdir(xPath)\n",
    "    for y in myPicList:\n",
    "        images.append(cv2.imread(os.path.join(xPath, y)))\n",
    "        y_trn.append(labels_list.index(x))\n",
    "    print(x ,end=\" \")\n",
    "\n",
    "y_train = to_categorical(y_trn,len(labels_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NORMAL CNV DME DRUSEN "
     ]
    }
   ],
   "source": [
    "x_val=[]\n",
    "y_val=[]\n",
    "for x in labels_list:\n",
    "    xPath = os.path.join(dataPath, \"val\", x)\n",
    "    myPicList = os.listdir(xPath)\n",
    "    for y in myPicList:\n",
    "        x_val.append(cv2.imread(os.path.join(xPath, y)))\n",
    "        y_val.append(labels_list.index(x))\n",
    "    print(x ,end=\" \")\n",
    "\n",
    "y_validation = to_categorical(y_val,len(labels_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NORMAL CNV DME DRUSEN "
     ]
    }
   ],
   "source": [
    "x_tst=[]\n",
    "y_tst=[]\n",
    "for x in labels_list:\n",
    "    xPath = os.path.join(dataPath, \"test\", x)\n",
    "    myPicList = os.listdir(xPath)\n",
    "    for y in myPicList:\n",
    "        x_tst.append(cv2.imread(os.path.join(xPath, y)))\n",
    "        y_tst.append(labels_list.index(x))\n",
    "    print(x ,end=\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of images per category and set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label\t\tTrain\t\tValidation\t\tTest\n",
      "NORMAL\t\t26315\t\t8\t\t\t242\n",
      "CNV\t\t37205\t\t8\t\t\t242\n",
      "DME\t\t11348\t\t8\t\t\t242\n",
      "DRUSEN\t\t8616\t\t8\t\t\t242\n"
     ]
    }
   ],
   "source": [
    "def getNumberOfItems(labels, itemLabel):\n",
    "    return sum(list(map(lambda x: x == itemLabel, labels))) \n",
    "\n",
    "\n",
    "print(\"Label\\t\\tTrain\\t\\tValidation\\t\\tTest\")\n",
    "for i, label in enumerate(labels_list):\n",
    "    print(f\"{label}\\t\\t{getNumberOfItems(y_trn, i)}\\t\\t{getNumberOfItems(y_val, i)}\\t\\t\\t{getNumberOfItems(y_tst, i)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resizeIm(im, size):\n",
    "    if im.shape[2] == 1:\n",
    "        im = cv2.cvtColor(im,cv2.COLOR_GRAY2RGB)\n",
    "    return cv2.resize(im, size)\n",
    "\n",
    "def resizeIms(x, size):\n",
    "    return np.array(list(map(lambda im: resizeIm(im, size), x)))\n",
    "\n",
    "# Substract the mean specified by Mean (https://www.mathworks.com/help/deeplearning/ref/nnet.cnn.layer.imageinputlayer.html)\n",
    "# Substract mean by channel\n",
    "def zerocenter(x):\n",
    "    return (x - np.mean(x, axis=(0, 1))) / (2*np.std(x, axis=(0, 1)))\n",
    "\n",
    "# Rescale the input to be in the range [-1, 1] using the minimum and maximum values specified by Min and Max, respectively. (https://www.mathworks.com/help/deeplearning/ref/nnet.cnn.layer.imageinputlayer.html)\n",
    "# Compute using the formula: $x\\prime = 2 * \\frac{x - \\min{x}}{\\max{x} - \\min{x}} - 1$ taken from: https://stats.stackexchange.com/a/178629\n",
    "def rescaleSymmetric(x):\n",
    "    x = zerocenter(x)\n",
    "    return 2 * (x - np.min(x, axis=(0, 1)))/np.ptp(x, axis=(0, 1)) - 1\n",
    "\n",
    "def normalizeIms(x, normalization):\n",
    "    if normalization == \"zerocenter\":\n",
    "        func = zerocenter\n",
    "    elif normalization == \"rescale-symmetric\":\n",
    "        func = rescaleSymmetric\n",
    "    else:\n",
    "        return x\n",
    "    return np.array(list(map(lambda im: func(im), x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self,fraction, model):\n",
    "        super(CustomCallback,self).__init__()\n",
    "        self.fraction = fraction\n",
    "        self.train_a = [];\n",
    "        self.val_a =[];\n",
    "        self.logPath = os.path.join(model, \"log.txt\")\n",
    "\n",
    "        if not os.path.isdir(model):\n",
    "            os.mkdir(model)\n",
    "\n",
    "        with open(self.logPath,'w') as f:\n",
    "            f.write('Starting of logging..\\n')\n",
    "\n",
    "        self.fig = plt.figure(figsize=(4,3))\n",
    "        self.ax = plt.subplot(1,1,1)\n",
    "        plt.ion()\n",
    "\n",
    "    def on_train_begin(self,logs=None):\n",
    "        self.fig.show()\n",
    "        self.fig.canvas.draw()\n",
    "\n",
    "    def on_train_end(self,logs=None):\n",
    "        with open(self.logPath,'a') as f:\n",
    "              f.write('End of logging..\\n')\n",
    "    \n",
    "    def on_epoch_begin(self,epoch,logs=None):\n",
    "        lr= tf.keras.backend.get_value(self.model.optimizer.lr)\n",
    "        lr *= self.fraction\n",
    "        tf.keras.backend.set_value(self.model.optimizer.lr,lr)\n",
    "        with open(self.logPath,'a') as f:\n",
    "            f.write('At epoch {:02d}, learning rate changed to {:.4f}\\n'.format(epoch,lr))\n",
    "    \n",
    "    def on_epoch_end(self,epoch,logs=None):\n",
    "        val_acc = logs.get('val_accuracy')\n",
    "        train_acc = logs.get('accuracy')\n",
    "        self.train_a.append(train_acc)\n",
    "        self.val_a.append(val_acc)\n",
    "        with open(self.logPath,'a') as f:\n",
    "            f.write('At epoch {:02d}, training accuracy: {:.3f}, validation accuracy: {:.3f}\\n'.format(epoch,train_acc,val_acc))\n",
    "        self.ax.clear()\n",
    "        self.ax.plot(range(1+epoch),self.train_a,label=\"Training\")\n",
    "        self.ax.plot(range(1+epoch),self.val_a,label=\"Validation\")\n",
    "        self.ax.set_xlabel('Epochs')\n",
    "        self.ax.set_ylabel('Accuracy')\n",
    "        self.ax.legend()\n",
    "        self.fig.canvas.draw()\n",
    "        self.fig.show()\n",
    "        \n",
    "class TimeHistory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.times = []\n",
    "\n",
    "    def on_epoch_begin(self, batch, logs={}):\n",
    "        self.epoch_time_start = time.time()\n",
    "\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.times.append(time.time() - self.epoch_time_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "# xception base model\n",
    "#from tensorflow.keras.applications.xception import Xception\n",
    "#from tensorflow.keras.applications.xception import preprocess_input, decode_predictions\n",
    "#xceptionNetModel = Xception(weights='imagenet')\n",
    "#xceptionNetModel.save(\"../Xception.hdf5\")\n",
    "\n",
    "xceptionNetModel = tf.keras.models.load_model('../Xception.hdf5')\n",
    "\n",
    "# opticnet base model\n",
    "opticNetModel = tf.keras.models.load_model('../Optic_net-4_classes-Kermany2018.hdf5')\n",
    "\n",
    "# resnet base model\n",
    "#from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "#from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "#resNetModel = ResNet50(weights='imagenet')\n",
    "#resNetModel.save(\"../Resnet50.hdf5\")\n",
    "\n",
    "resNetModel = tf.keras.models.load_model('../Resnet50.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 221, 221, 32)      4736      \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 221, 221, 32)      128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 110, 110, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 104, 104, 32)      50208     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 104, 104, 32)      128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 52, 52, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 48, 48, 64)        51264     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 48, 48, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 24, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 20, 20, 128)       204928    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 20, 20, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 10, 10, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 8, 8, 256)         295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d (AveragePo (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               131200    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4)                 132       \n",
      "_________________________________________________________________\n",
      "softmax (Softmax)            (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 743,812\n",
      "Trainable params: 742,788\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "conv_init = tf.keras.initializers.RandomNormal(mean=0., stddev=1.) # convolutional layer with zero mean and 1 sd\n",
    "#batch_init = tf.keras.initializers.RandomNormal(mean=1., stddev=0.02) # non-sense here\n",
    "\n",
    "octnet = keras.models.Sequential() # empty model\n",
    "\n",
    "octnet.add(keras.layers.Conv2D(32, (7, 7), activation=\"relu\", use_bias=True, input_shape=(227, 227, 3), kernel_initializer=conv_init))\n",
    "octnet.add(keras.layers.BatchNormalization())\n",
    "octnet.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "octnet.add(keras.layers.Conv2D(32, (7, 7), activation=\"relu\", use_bias=True, kernel_initializer=conv_init))\n",
    "octnet.add(keras.layers.BatchNormalization())\n",
    "octnet.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "octnet.add(keras.layers.Conv2D(64, (5, 5), activation=\"relu\", use_bias=True, kernel_initializer=conv_init))\n",
    "octnet.add(keras.layers.BatchNormalization())\n",
    "octnet.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "octnet.add(keras.layers.Conv2D(128, (5, 5), activation=\"relu\", use_bias=True, kernel_initializer=conv_init))\n",
    "octnet.add(keras.layers.BatchNormalization())\n",
    "octnet.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "octnet.add(keras.layers.Conv2D(256, (3, 3), activation=\"relu\", use_bias=True, kernel_initializer=conv_init))\n",
    "octnet.add(keras.layers.BatchNormalization())\n",
    "octnet.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "#octnet.add(keras.layers.Conv2D(512, (3, 3), activation=\"relu\", use_bias=True))\n",
    "#octnet.add(keras.layers.BatchNormalization())\n",
    "#octnet.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "octnet.add(keras.layers.AveragePooling2D())\n",
    "octnet.add(keras.layers.Flatten())\n",
    "octnet.add(keras.layers.Dense(128))\n",
    "octnet.add(keras.layers.Dropout(0.5))\n",
    "octnet.add(keras.layers.Dense(32))\n",
    "octnet.add(keras.layers.Dropout(0.5))\n",
    "octnet.add(keras.layers.Dense(4))\n",
    "octnet.add(keras.layers.Softmax())\n",
    "\n",
    "octnet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emptyModelGenerator(model, newWeights=False, lastOnly=False):\n",
    "    model = model.lower() # lower case model name\n",
    "    if model == \"resnet\":\n",
    "        x = resNetModel.output\n",
    "        predictions = Dense(len(labels_list), activation='softmax')(x)\n",
    "        newModel = Model(inputs=resNetModel.input, outputs=predictions)\n",
    "        size = (224, 224)\n",
    "        normalization = \"zerocenter\"\n",
    "    elif model == \"xception\":\n",
    "        x = xceptionNetModel.output\n",
    "        predictions = Dense(len(labels_list), activation='softmax')(x)\n",
    "        newModel = Model(inputs=xceptionNetModel.input, outputs=predictions)\n",
    "        size = (299, 299)\n",
    "        normalization = \"rescale-symmetric\"\n",
    "    elif model == \"opticnet\":\n",
    "        newModel = tf.keras.models.load_model('../Optic_net-4_classes-Kermany2018.hdf5')\n",
    "        size = (224, 224)\n",
    "        normalization = \"rescale-symmetric\"\n",
    "    elif model == \"octnet\":\n",
    "        newModel = tf.keras.models.clone_model(octnet)\n",
    "        size = (227, 227)\n",
    "        normalization = \"zerocenter\"\n",
    "    if newWeights:\n",
    "        newModel = tf.keras.models.clone_model(newModel)\n",
    "    if lastOnly:\n",
    "        newModel = lastDenseTrainable(newModel) # block all layer except the last dense ones\n",
    "    else:\n",
    "        newModel.trainable = True\n",
    "    return newModel, size, normalization\n",
    "\n",
    "\n",
    "def lastDenseTrainable(model):\n",
    "    model.trainable = False\n",
    "    for i in range(1, len(model.layers)):\n",
    "        if model.layers[-i].__class__.__name__ == \"Dense\":\n",
    "            model.layers[-i].trainable= True\n",
    "        elif model.layers[-i].__class__.__name__ == \"Activation\":\n",
    "            continue\n",
    "        else:\n",
    "            break\n",
    "    return model\n",
    "    \n",
    "\n",
    "def testPredict(model, size, name=None, normalization=None):\n",
    "    X_test = resizeIms(x_tst, size)\n",
    "    if normalization:\n",
    "        X_test = normalizeIms(X_test, normalization)\n",
    "    X_test = np.array(X_test)\n",
    "    Y_test = np.array(y_tst)\n",
    "    \n",
    "    prediction = model.predict(X_test)\n",
    "    preds = np.argmax(prediction, axis=1)\n",
    "    acc = sum(preds == Y_test) / len(Y_test)\n",
    "    print(f'Test acc for {name if name else \"model\"}: {acc:.6f}')\n",
    "    return acc\n",
    "    \n",
    "\n",
    "def computeConfussionMatrix(predictions, labels):\n",
    "    num_labels = len(labels_list)\n",
    "    cMatrix = np.zeros(shape=(num_labels, num_labels))\n",
    "    for i in len(predictions):\n",
    "        p = int(predictions[i])\n",
    "        t = int(predictions[i])\n",
    "        cMatrix[t, p] += 1\n",
    "    print(cMatrix)\n",
    "    ax = sns.heatmap(cMatrix, cmap=\"Blues\", annot=True, fmt=\"d\", xticklabels=labels_list, yticklabels=labels_list)\n",
    "    plt.xlabel(\"Predicted label\")\n",
    "    plt.ylabel(\"True label\")\n",
    "    plt.title(\"Confusion matrix\")\n",
    "    plt.show();\n",
    "    return cMatrix\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "**************************************************\n",
      "Model: xception\n",
      "**************************************************\n",
      "\n",
      "Total: 135 trainable: 2\n",
      "\n",
      "\n",
      "**************************************************\n",
      "Model: resnet\n",
      "**************************************************\n",
      "\n",
      "Total: 178 trainable: 2\n",
      "\n",
      "\n",
      "**************************************************\n",
      "Model: opticnet\n",
      "**************************************************\n",
      "\n",
      "Total: 276 trainable: 2\n",
      "\n",
      "\n",
      "**************************************************\n",
      "Model: octnet\n",
      "**************************************************\n",
      "\n",
      "Total: 23 trainable: 0\n"
     ]
    }
   ],
   "source": [
    "models = [\"xception\", \"resnet\", \"opticnet\", \"octnet\"]\n",
    "\n",
    "def printTrainableLayers(m):\n",
    "    a = 0\n",
    "    for l in m.layers:\n",
    "        #l.trainable = True\n",
    "        if l.trainable:\n",
    "            #print(l.name, l.trainable)\n",
    "            a += 1\n",
    "    print(f\"\\nTotal: {len(m.layers)} trainable: {a}\")\n",
    "\n",
    "for mod in models:\n",
    "    print(\"\\n\\n\" + (\"*\"*50) + \"\\nModel: \" + mod + '\\n' + (\"*\"*50))\n",
    "    m = emptyModelGenerator(mod, newWeights=False, lastOnly=True)[0]\n",
    "    printTrainableLayers(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "momentum = 0.9\n",
    "optim = lambda lr: Adam(learning_rate=lr)\n",
    "#optim = lambda lr, momentum: SGD(learning_rate=lr, momentum=momentum)\n",
    "epochs = 30\n",
    "batch_size = 50\n",
    "#batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "results = pd.read_csv(\"Results_temp.csv\")\n",
    "results[\"normalization\"] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pandas as pd\n",
    "#res = pd.read_csv(\"Results_temp.csv\")\n",
    "#res.to_csv(\"Results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels fraction: [0.0100703  0.01042871 0.00845964 0.00986537]\n",
      "Training resnet for 0.01% of train size (aka 834 images) with pretrained: False and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 178 trainable: 178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      " 6/17 [=========>....................] - ETA: 5s - loss: 1.3783 - accuracy: 0.4255WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0995s vs `on_train_batch_begin` time: 0.1782s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0995s vs `on_train_batch_end` time: 0.1817s). Check your callbacks.\n",
      "17/17 [==============================] - 24s 476ms/step - loss: 1.3555 - accuracy: 0.4476 - val_loss: 1.4112 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "17/17 [==============================] - 3s 198ms/step - loss: 1.2508 - accuracy: 0.4676 - val_loss: 1.4479 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "17/17 [==============================] - 3s 192ms/step - loss: 1.1932 - accuracy: 0.5055 - val_loss: 1.4690 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "17/17 [==============================] - 3s 192ms/step - loss: 1.2082 - accuracy: 0.4452 - val_loss: 1.4799 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "17/17 [==============================] - 3s 193ms/step - loss: 1.1977 - accuracy: 0.4710 - val_loss: 1.4861 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "17/17 [==============================] - 3s 193ms/step - loss: 1.1917 - accuracy: 0.4732 - val_loss: 1.4915 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "17/17 [==============================] - 3s 193ms/step - loss: 1.1973 - accuracy: 0.4654 - val_loss: 1.4944 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "17/17 [==============================] - 3s 194ms/step - loss: 1.2013 - accuracy: 0.4450 - val_loss: 1.4991 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "17/17 [==============================] - 3s 199ms/step - loss: 1.2200 - accuracy: 0.4594 - val_loss: 1.5036 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "17/17 [==============================] - 3s 194ms/step - loss: 1.2122 - accuracy: 0.4715 - val_loss: 1.5080 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "17/17 [==============================] - 3s 194ms/step - loss: 1.1905 - accuracy: 0.4716 - val_loss: 1.5131 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "17/17 [==============================] - 3s 195ms/step - loss: 1.1953 - accuracy: 0.4704 - val_loss: 1.5197 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "17/17 [==============================] - 3s 195ms/step - loss: 1.1912 - accuracy: 0.4680 - val_loss: 1.5262 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "17/17 [==============================] - 3s 195ms/step - loss: 1.1869 - accuracy: 0.4840 - val_loss: 1.5331 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "17/17 [==============================] - 3s 198ms/step - loss: 1.1976 - accuracy: 0.4648 - val_loss: 1.5386 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "17/17 [==============================] - 3s 196ms/step - loss: 1.1978 - accuracy: 0.4769 - val_loss: 1.5449 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "17/17 [==============================] - 3s 195ms/step - loss: 1.2092 - accuracy: 0.4571 - val_loss: 1.5505 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "17/17 [==============================] - 3s 196ms/step - loss: 1.1746 - accuracy: 0.4723 - val_loss: 1.5576 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "17/17 [==============================] - 3s 196ms/step - loss: 1.1797 - accuracy: 0.4885 - val_loss: 1.5629 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "17/17 [==============================] - 3s 195ms/step - loss: 1.2045 - accuracy: 0.4602 - val_loss: 1.5677 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "17/17 [==============================] - 3s 196ms/step - loss: 1.1876 - accuracy: 0.4661 - val_loss: 1.5710 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "17/17 [==============================] - 3s 198ms/step - loss: 1.1998 - accuracy: 0.4790 - val_loss: 1.5747 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "17/17 [==============================] - 3s 196ms/step - loss: 1.2038 - accuracy: 0.4704 - val_loss: 1.5768 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "17/17 [==============================] - 3s 196ms/step - loss: 1.2347 - accuracy: 0.4320 - val_loss: 1.5782 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "17/17 [==============================] - 3s 196ms/step - loss: 1.1877 - accuracy: 0.4756 - val_loss: 1.5802 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "17/17 [==============================] - 3s 196ms/step - loss: 1.1895 - accuracy: 0.4780 - val_loss: 1.5817 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "17/17 [==============================] - 3s 196ms/step - loss: 1.1844 - accuracy: 0.4785 - val_loss: 1.5825 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "17/17 [==============================] - 3s 201ms/step - loss: 1.2097 - accuracy: 0.4625 - val_loss: 1.5837 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "17/17 [==============================] - 3s 197ms/step - loss: 1.1981 - accuracy: 0.4532 - val_loss: 1.5844 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "17/17 [==============================] - 3s 196ms/step - loss: 1.1800 - accuracy: 0.4803 - val_loss: 1.5853 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_835_images_True_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.02496675 0.02607176 0.02264716 0.02356082]\n",
      "Training resnet for 0.025% of train size (aka 2087 images) with pretrained: False and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 178 trainable: 178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      " 6/42 [===>..........................] - ETA: 24s - loss: 1.3801 - accuracy: 0.3358WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1029s vs `on_train_batch_begin` time: 0.1551s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1029s vs `on_train_batch_end` time: 0.3422s). Check your callbacks.\n",
      "42/42 [==============================] - 20s 313ms/step - loss: 1.3285 - accuracy: 0.4216 - val_loss: 1.4728 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "42/42 [==============================] - 8s 194ms/step - loss: 1.2264 - accuracy: 0.4576 - val_loss: 1.5054 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "42/42 [==============================] - 8s 196ms/step - loss: 1.2217 - accuracy: 0.4500 - val_loss: 1.5106 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "42/42 [==============================] - 8s 196ms/step - loss: 1.2080 - accuracy: 0.4602 - val_loss: 1.5214 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "42/42 [==============================] - 8s 197ms/step - loss: 1.1865 - accuracy: 0.4836 - val_loss: 1.5280 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "42/42 [==============================] - 8s 199ms/step - loss: 1.1986 - accuracy: 0.4647 - val_loss: 1.5462 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "42/42 [==============================] - 8s 197ms/step - loss: 1.2059 - accuracy: 0.4483 - val_loss: 1.5619 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "42/42 [==============================] - 8s 197ms/step - loss: 1.2001 - accuracy: 0.4717 - val_loss: 1.5682 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "42/42 [==============================] - 8s 197ms/step - loss: 1.2019 - accuracy: 0.4582 - val_loss: 1.5772 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "42/42 [==============================] - 8s 199ms/step - loss: 1.2100 - accuracy: 0.4576 - val_loss: 1.5828 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "42/42 [==============================] - 8s 197ms/step - loss: 1.2064 - accuracy: 0.4570 - val_loss: 1.5820 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "42/42 [==============================] - 8s 198ms/step - loss: 1.2070 - accuracy: 0.4660 - val_loss: 1.5853 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "42/42 [==============================] - 8s 197ms/step - loss: 1.2028 - accuracy: 0.4683 - val_loss: 1.5855 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "42/42 [==============================] - 8s 197ms/step - loss: 1.2093 - accuracy: 0.4575 - val_loss: 1.5869 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "42/42 [==============================] - 8s 199ms/step - loss: 1.1849 - accuracy: 0.4891 - val_loss: 1.5853 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "42/42 [==============================] - 8s 197ms/step - loss: 1.1878 - accuracy: 0.4891 - val_loss: 1.5843 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "42/42 [==============================] - 8s 198ms/step - loss: 1.2305 - accuracy: 0.4463 - val_loss: 1.5867 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "42/42 [==============================] - 8s 197ms/step - loss: 1.2095 - accuracy: 0.4655 - val_loss: 1.5870 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "42/42 [==============================] - 8s 197ms/step - loss: 1.2176 - accuracy: 0.4512 - val_loss: 1.5869 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "42/42 [==============================] - 8s 200ms/step - loss: 1.2070 - accuracy: 0.4693 - val_loss: 1.5869 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "42/42 [==============================] - 8s 198ms/step - loss: 1.1965 - accuracy: 0.4699 - val_loss: 1.5865 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "42/42 [==============================] - 8s 198ms/step - loss: 1.1968 - accuracy: 0.4729 - val_loss: 1.5861 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "42/42 [==============================] - 8s 199ms/step - loss: 1.2046 - accuracy: 0.4714 - val_loss: 1.5859 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "42/42 [==============================] - 8s 197ms/step - loss: 1.1791 - accuracy: 0.4827 - val_loss: 1.5849 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "42/42 [==============================] - 8s 197ms/step - loss: 1.2229 - accuracy: 0.4526 - val_loss: 1.5856 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "42/42 [==============================] - 8s 198ms/step - loss: 1.2146 - accuracy: 0.4520 - val_loss: 1.5851 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "42/42 [==============================] - 8s 198ms/step - loss: 1.2170 - accuracy: 0.4527 - val_loss: 1.5849 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "42/42 [==============================] - 8s 199ms/step - loss: 1.1886 - accuracy: 0.4701 - val_loss: 1.5846 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "42/42 [==============================] - 8s 198ms/step - loss: 1.2267 - accuracy: 0.4509 - val_loss: 1.5843 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "42/42 [==============================] - 8s 198ms/step - loss: 1.1978 - accuracy: 0.4748 - val_loss: 1.5840 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_2087_images_True_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.05050352 0.04929445 0.05137469 0.04967502]\n",
      "Training resnet for 0.05% of train size (aka 4174 images) with pretrained: False and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 178 trainable: 178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      " 6/84 [=>............................] - ETA: 53s - loss: 1.3791 - accuracy: 0.4351 WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1017s vs `on_train_batch_begin` time: 0.1528s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1017s vs `on_train_batch_end` time: 0.3463s). Check your callbacks.\n",
      "84/84 [==============================] - 27s 251ms/step - loss: 1.3090 - accuracy: 0.4421 - val_loss: 1.4981 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "84/84 [==============================] - 16s 196ms/step - loss: 1.2344 - accuracy: 0.4475 - val_loss: 1.5057 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "84/84 [==============================] - 17s 197ms/step - loss: 1.2334 - accuracy: 0.4393 - val_loss: 1.5165 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "84/84 [==============================] - 17s 199ms/step - loss: 1.2314 - accuracy: 0.4468 - val_loss: 1.5407 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "84/84 [==============================] - 17s 198ms/step - loss: 1.2327 - accuracy: 0.4357 - val_loss: 1.5565 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "84/84 [==============================] - 17s 197ms/step - loss: 1.2238 - accuracy: 0.4389 - val_loss: 1.5075 - val_accuracy: 0.3438\n",
      "Epoch 7/30\n",
      "84/84 [==============================] - 17s 198ms/step - loss: 1.0893 - accuracy: 0.6955 - val_loss: 1.4422 - val_accuracy: 0.4062\n",
      "Epoch 8/30\n",
      "84/84 [==============================] - 17s 198ms/step - loss: 1.0020 - accuracy: 0.7107 - val_loss: 1.6401 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "84/84 [==============================] - 17s 197ms/step - loss: 0.9197 - accuracy: 0.7173 - val_loss: 1.6726 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "84/84 [==============================] - 17s 197ms/step - loss: 0.8743 - accuracy: 0.7213 - val_loss: 1.6800 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "84/84 [==============================] - 17s 197ms/step - loss: 0.8196 - accuracy: 0.7416 - val_loss: 1.5786 - val_accuracy: 0.3125\n",
      "Epoch 12/30\n",
      "84/84 [==============================] - 17s 198ms/step - loss: 0.8166 - accuracy: 0.7336 - val_loss: 1.1930 - val_accuracy: 0.5000\n",
      "Epoch 13/30\n",
      "84/84 [==============================] - 17s 198ms/step - loss: 0.7819 - accuracy: 0.7380 - val_loss: 1.6611 - val_accuracy: 0.3438\n",
      "Epoch 14/30\n",
      "84/84 [==============================] - 17s 198ms/step - loss: 0.7413 - accuracy: 0.7540 - val_loss: 1.2552 - val_accuracy: 0.5000\n",
      "Epoch 15/30\n",
      "84/84 [==============================] - 17s 199ms/step - loss: 0.7392 - accuracy: 0.7447 - val_loss: 1.1511 - val_accuracy: 0.5000\n",
      "Epoch 16/30\n",
      "84/84 [==============================] - 17s 198ms/step - loss: 0.6958 - accuracy: 0.7604 - val_loss: 1.1405 - val_accuracy: 0.5000\n",
      "Epoch 17/30\n",
      "84/84 [==============================] - 17s 198ms/step - loss: 0.6934 - accuracy: 0.7499 - val_loss: 1.5939 - val_accuracy: 0.3438\n",
      "Epoch 18/30\n",
      "84/84 [==============================] - 17s 199ms/step - loss: 0.6913 - accuracy: 0.7464 - val_loss: 1.1184 - val_accuracy: 0.5000\n",
      "Epoch 19/30\n",
      "84/84 [==============================] - 17s 198ms/step - loss: 0.6667 - accuracy: 0.7573 - val_loss: 1.2365 - val_accuracy: 0.5000\n",
      "Epoch 20/30\n",
      "84/84 [==============================] - 17s 198ms/step - loss: 0.6484 - accuracy: 0.7516 - val_loss: 1.2690 - val_accuracy: 0.5000\n",
      "Epoch 21/30\n",
      "84/84 [==============================] - 17s 198ms/step - loss: 0.6027 - accuracy: 0.7673 - val_loss: 1.0818 - val_accuracy: 0.5000\n",
      "Epoch 22/30\n",
      "84/84 [==============================] - 17s 198ms/step - loss: 0.5942 - accuracy: 0.7658 - val_loss: 1.2323 - val_accuracy: 0.4688\n",
      "Epoch 23/30\n",
      "84/84 [==============================] - 17s 198ms/step - loss: 0.5764 - accuracy: 0.7650 - val_loss: 1.0941 - val_accuracy: 0.5000\n",
      "Epoch 24/30\n",
      "84/84 [==============================] - 17s 198ms/step - loss: 0.5627 - accuracy: 0.7609 - val_loss: 1.0391 - val_accuracy: 0.5000\n",
      "Epoch 25/30\n",
      "84/84 [==============================] - 17s 197ms/step - loss: 0.5549 - accuracy: 0.7577 - val_loss: 1.1145 - val_accuracy: 0.5000\n",
      "Epoch 26/30\n",
      "84/84 [==============================] - 17s 197ms/step - loss: 0.5191 - accuracy: 0.7815 - val_loss: 1.0652 - val_accuracy: 0.5312\n",
      "Epoch 27/30\n",
      "84/84 [==============================] - 17s 197ms/step - loss: 0.5029 - accuracy: 0.7915 - val_loss: 0.9647 - val_accuracy: 0.5312\n",
      "Epoch 28/30\n",
      "84/84 [==============================] - 17s 199ms/step - loss: 0.5076 - accuracy: 0.7809 - val_loss: 0.9657 - val_accuracy: 0.5000\n",
      "Epoch 29/30\n",
      "84/84 [==============================] - 17s 198ms/step - loss: 0.4891 - accuracy: 0.8032 - val_loss: 0.9865 - val_accuracy: 0.5625\n",
      "Epoch 30/30\n",
      "84/84 [==============================] - 17s 199ms/step - loss: 0.4633 - accuracy: 0.8227 - val_loss: 0.9923 - val_accuracy: 0.5625\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_4174_images_True_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.575413\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.07573627 0.07464051 0.07543179 0.07370009]\n",
      "Training resnet for 0.075% of train size (aka 6261 images) with pretrained: False and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 178 trainable: 178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/126 [>.............................] - ETA: 1:22 - loss: 1.3795 - accuracy: 0.4017WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1010s vs `on_train_batch_begin` time: 0.1524s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1010s vs `on_train_batch_end` time: 0.3450s). Check your callbacks.\n",
      "126/126 [==============================] - 35s 230ms/step - loss: 1.2852 - accuracy: 0.4420 - val_loss: 1.4790 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "126/126 [==============================] - 25s 195ms/step - loss: 1.2334 - accuracy: 0.4385 - val_loss: 1.5096 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "126/126 [==============================] - 25s 196ms/step - loss: 1.2213 - accuracy: 0.4485 - val_loss: 1.5426 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "126/126 [==============================] - 25s 197ms/step - loss: 1.2192 - accuracy: 0.4523 - val_loss: 1.5584 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "126/126 [==============================] - 25s 197ms/step - loss: 1.2293 - accuracy: 0.4354 - val_loss: 1.5668 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "126/126 [==============================] - 25s 198ms/step - loss: 1.2305 - accuracy: 0.4415 - val_loss: 1.5783 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "126/126 [==============================] - 25s 197ms/step - loss: 1.2130 - accuracy: 0.4378 - val_loss: 1.7492 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "126/126 [==============================] - 25s 197ms/step - loss: 1.0503 - accuracy: 0.5966 - val_loss: 1.8379 - val_accuracy: 0.2812\n",
      "Epoch 9/30\n",
      "126/126 [==============================] - 25s 197ms/step - loss: 0.9546 - accuracy: 0.7067 - val_loss: 1.7513 - val_accuracy: 0.3750\n",
      "Epoch 10/30\n",
      "126/126 [==============================] - 25s 197ms/step - loss: 0.9021 - accuracy: 0.7155 - val_loss: 1.3517 - val_accuracy: 0.4062\n",
      "Epoch 11/30\n",
      "126/126 [==============================] - 25s 198ms/step - loss: 0.8555 - accuracy: 0.7284 - val_loss: 1.3564 - val_accuracy: 0.3750\n",
      "Epoch 12/30\n",
      "126/126 [==============================] - 25s 197ms/step - loss: 0.7897 - accuracy: 0.7420 - val_loss: 1.4925 - val_accuracy: 0.5000\n",
      "Epoch 13/30\n",
      "126/126 [==============================] - 25s 198ms/step - loss: 0.7566 - accuracy: 0.7465 - val_loss: 1.1385 - val_accuracy: 0.5000\n",
      "Epoch 14/30\n",
      "126/126 [==============================] - 25s 197ms/step - loss: 0.7276 - accuracy: 0.7464 - val_loss: 1.3098 - val_accuracy: 0.3750\n",
      "Epoch 15/30\n",
      "126/126 [==============================] - 25s 197ms/step - loss: 0.6883 - accuracy: 0.7551 - val_loss: 1.1105 - val_accuracy: 0.5000\n",
      "Epoch 16/30\n",
      "126/126 [==============================] - 25s 197ms/step - loss: 0.6747 - accuracy: 0.7439 - val_loss: 1.2127 - val_accuracy: 0.5000\n",
      "Epoch 17/30\n",
      "126/126 [==============================] - 25s 198ms/step - loss: 0.6339 - accuracy: 0.7527 - val_loss: 1.0605 - val_accuracy: 0.5000\n",
      "Epoch 18/30\n",
      "126/126 [==============================] - 25s 197ms/step - loss: 0.6016 - accuracy: 0.7584 - val_loss: 1.0739 - val_accuracy: 0.5312\n",
      "Epoch 19/30\n",
      "126/126 [==============================] - 25s 198ms/step - loss: 0.5770 - accuracy: 0.8207 - val_loss: 1.0372 - val_accuracy: 0.5938\n",
      "Epoch 20/30\n",
      "126/126 [==============================] - 25s 198ms/step - loss: 0.5681 - accuracy: 0.8268 - val_loss: 1.5318 - val_accuracy: 0.3438\n",
      "Epoch 21/30\n",
      "126/126 [==============================] - 25s 197ms/step - loss: 0.5535 - accuracy: 0.8257 - val_loss: 1.0638 - val_accuracy: 0.5625\n",
      "Epoch 22/30\n",
      "126/126 [==============================] - 25s 197ms/step - loss: 0.5170 - accuracy: 0.8404 - val_loss: 1.0414 - val_accuracy: 0.5625\n",
      "Epoch 23/30\n",
      "126/126 [==============================] - 25s 197ms/step - loss: 0.5144 - accuracy: 0.8474 - val_loss: 1.2766 - val_accuracy: 0.3750\n",
      "Epoch 24/30\n",
      "126/126 [==============================] - 25s 197ms/step - loss: 0.4701 - accuracy: 0.8572 - val_loss: 1.1129 - val_accuracy: 0.5312\n",
      "Epoch 25/30\n",
      "126/126 [==============================] - 25s 197ms/step - loss: 0.4489 - accuracy: 0.8652 - val_loss: 1.4093 - val_accuracy: 0.4062\n",
      "Epoch 26/30\n",
      "126/126 [==============================] - 25s 198ms/step - loss: 0.4375 - accuracy: 0.8672 - val_loss: 0.7928 - val_accuracy: 0.6875\n",
      "Epoch 27/30\n",
      "126/126 [==============================] - 25s 197ms/step - loss: 0.4134 - accuracy: 0.8748 - val_loss: 0.8378 - val_accuracy: 0.6875\n",
      "Epoch 28/30\n",
      "126/126 [==============================] - 25s 197ms/step - loss: 0.3995 - accuracy: 0.8747 - val_loss: 1.7055 - val_accuracy: 0.3750\n",
      "Epoch 29/30\n",
      "126/126 [==============================] - 25s 197ms/step - loss: 0.3895 - accuracy: 0.8796 - val_loss: 1.4970 - val_accuracy: 0.4062\n",
      "Epoch 30/30\n",
      "126/126 [==============================] - 25s 197ms/step - loss: 0.3887 - accuracy: 0.8800 - val_loss: 0.8183 - val_accuracy: 0.6250\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_6261_images_True_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.664256\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.09158275 0.08899341 0.08970744 0.08983287]\n",
      "Training resnet for 0.09% of train size (aka 7513 images) with pretrained: False and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 178 trainable: 178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/151 [>.............................] - ETA: 1:39 - loss: 1.3811 - accuracy: 0.3429WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1024s vs `on_train_batch_begin` time: 0.1519s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1024s vs `on_train_batch_end` time: 0.3449s). Check your callbacks.\n",
      "151/151 [==============================] - 40s 225ms/step - loss: 1.2869 - accuracy: 0.4266 - val_loss: 1.5421 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "151/151 [==============================] - 30s 196ms/step - loss: 1.2330 - accuracy: 0.4350 - val_loss: 1.5479 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "151/151 [==============================] - 30s 197ms/step - loss: 1.2268 - accuracy: 0.4477 - val_loss: 1.5680 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "151/151 [==============================] - 30s 197ms/step - loss: 1.2342 - accuracy: 0.4385 - val_loss: 1.5711 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "151/151 [==============================] - 30s 197ms/step - loss: 1.1082 - accuracy: 0.5301 - val_loss: 1.5877 - val_accuracy: 0.3125\n",
      "Epoch 6/30\n",
      "151/151 [==============================] - 30s 198ms/step - loss: 0.9378 - accuracy: 0.7036 - val_loss: 1.9840 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "151/151 [==============================] - 30s 198ms/step - loss: 0.8450 - accuracy: 0.7297 - val_loss: 2.0808 - val_accuracy: 0.1562\n",
      "Epoch 8/30\n",
      "151/151 [==============================] - 30s 198ms/step - loss: 0.8035 - accuracy: 0.7370 - val_loss: 1.1928 - val_accuracy: 0.5000\n",
      "Epoch 9/30\n",
      "151/151 [==============================] - 30s 198ms/step - loss: 0.7551 - accuracy: 0.7398 - val_loss: 1.2112 - val_accuracy: 0.5000\n",
      "Epoch 10/30\n",
      "151/151 [==============================] - 30s 197ms/step - loss: 0.6818 - accuracy: 0.7594 - val_loss: 1.0953 - val_accuracy: 0.5000\n",
      "Epoch 11/30\n",
      "151/151 [==============================] - 30s 198ms/step - loss: 0.6665 - accuracy: 0.7498 - val_loss: 1.1502 - val_accuracy: 0.5000\n",
      "Epoch 12/30\n",
      "151/151 [==============================] - 30s 198ms/step - loss: 0.6066 - accuracy: 0.7591 - val_loss: 0.9588 - val_accuracy: 0.5000\n",
      "Epoch 13/30\n",
      "151/151 [==============================] - 30s 198ms/step - loss: 0.5786 - accuracy: 0.7569 - val_loss: 1.0267 - val_accuracy: 0.5312\n",
      "Epoch 14/30\n",
      "151/151 [==============================] - 30s 198ms/step - loss: 0.5507 - accuracy: 0.8060 - val_loss: 1.6900 - val_accuracy: 0.3125\n",
      "Epoch 15/30\n",
      "151/151 [==============================] - 30s 198ms/step - loss: 0.5189 - accuracy: 0.8466 - val_loss: 1.2327 - val_accuracy: 0.6562\n",
      "Epoch 16/30\n",
      "151/151 [==============================] - 30s 198ms/step - loss: 0.5013 - accuracy: 0.8452 - val_loss: 2.1873 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "151/151 [==============================] - 30s 199ms/step - loss: 0.5066 - accuracy: 0.8374 - val_loss: 1.9701 - val_accuracy: 0.3125\n",
      "Epoch 18/30\n",
      "151/151 [==============================] - 30s 198ms/step - loss: 0.4732 - accuracy: 0.8470 - val_loss: 0.7527 - val_accuracy: 0.7500\n",
      "Epoch 19/30\n",
      "151/151 [==============================] - 30s 198ms/step - loss: 0.4168 - accuracy: 0.8645 - val_loss: 2.6023 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "151/151 [==============================] - 30s 198ms/step - loss: 0.3991 - accuracy: 0.8691 - val_loss: 1.0301 - val_accuracy: 0.4688\n",
      "Epoch 21/30\n",
      "151/151 [==============================] - 30s 198ms/step - loss: 0.3823 - accuracy: 0.8749 - val_loss: 1.0796 - val_accuracy: 0.6562\n",
      "Epoch 22/30\n",
      "151/151 [==============================] - 30s 199ms/step - loss: 0.3668 - accuracy: 0.8782 - val_loss: 0.7172 - val_accuracy: 0.6562\n",
      "Epoch 23/30\n",
      "151/151 [==============================] - 30s 198ms/step - loss: 0.3620 - accuracy: 0.8770 - val_loss: 0.5695 - val_accuracy: 0.7188\n",
      "Epoch 24/30\n",
      "151/151 [==============================] - 30s 198ms/step - loss: 0.3321 - accuracy: 0.8830 - val_loss: 0.7774 - val_accuracy: 0.5938\n",
      "Epoch 25/30\n",
      "151/151 [==============================] - 30s 197ms/step - loss: 0.3169 - accuracy: 0.8922 - val_loss: 0.5715 - val_accuracy: 0.7500\n",
      "Epoch 26/30\n",
      "151/151 [==============================] - 30s 198ms/step - loss: 0.3064 - accuracy: 0.8886 - val_loss: 0.6643 - val_accuracy: 0.6875\n",
      "Epoch 27/30\n",
      "151/151 [==============================] - 30s 199ms/step - loss: 0.3026 - accuracy: 0.8897 - val_loss: 0.5498 - val_accuracy: 0.7500\n",
      "Epoch 28/30\n",
      "151/151 [==============================] - 30s 198ms/step - loss: 0.2885 - accuracy: 0.8925 - val_loss: 0.5185 - val_accuracy: 0.7500\n",
      "Epoch 29/30\n",
      "151/151 [==============================] - 30s 198ms/step - loss: 0.2916 - accuracy: 0.8874 - val_loss: 0.5481 - val_accuracy: 0.7500\n",
      "Epoch 30/30\n",
      "151/151 [==============================] - 30s 197ms/step - loss: 0.2718 - accuracy: 0.8978 - val_loss: 0.5590 - val_accuracy: 0.7500\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_7514_images_True_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.736570\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.10089303 0.09931461 0.10028199 0.0998143 ]\n",
      "Training resnet for 0.1% of train size (aka 8348 images) with pretrained: False and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 178 trainable: 178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/167 [>.............................] - ETA: 1:49 - loss: 1.3796 - accuracy: 0.3578WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1012s vs `on_train_batch_begin` time: 0.1512s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1012s vs `on_train_batch_end` time: 0.3437s). Check your callbacks.\n",
      "167/167 [==============================] - 43s 226ms/step - loss: 1.2774 - accuracy: 0.4285 - val_loss: 1.4932 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "167/167 [==============================] - 33s 198ms/step - loss: 1.2305 - accuracy: 0.4485 - val_loss: 1.5384 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "167/167 [==============================] - 33s 199ms/step - loss: 1.2375 - accuracy: 0.4375 - val_loss: 1.5581 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "167/167 [==============================] - 33s 199ms/step - loss: 1.2291 - accuracy: 0.4438 - val_loss: 1.5510 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "167/167 [==============================] - 33s 199ms/step - loss: 1.2403 - accuracy: 0.4395 - val_loss: 1.5642 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "167/167 [==============================] - 33s 199ms/step - loss: 1.2310 - accuracy: 0.4418 - val_loss: 1.5494 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "167/167 [==============================] - 33s 200ms/step - loss: 1.2157 - accuracy: 0.4513 - val_loss: 1.5375 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "167/167 [==============================] - 33s 199ms/step - loss: 1.2340 - accuracy: 0.4488 - val_loss: 1.5600 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "167/167 [==============================] - 33s 198ms/step - loss: 1.2220 - accuracy: 0.4437 - val_loss: 1.5558 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "167/167 [==============================] - 33s 199ms/step - loss: 1.2426 - accuracy: 0.4322 - val_loss: 1.5603 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "167/167 [==============================] - 33s 199ms/step - loss: 1.2403 - accuracy: 0.4318 - val_loss: 1.5641 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "167/167 [==============================] - 33s 199ms/step - loss: 1.2243 - accuracy: 0.4446 - val_loss: 1.5595 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "167/167 [==============================] - 33s 199ms/step - loss: 1.2188 - accuracy: 0.4541 - val_loss: 1.5498 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "167/167 [==============================] - 33s 199ms/step - loss: 1.2296 - accuracy: 0.4483 - val_loss: 1.5488 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "167/167 [==============================] - 33s 199ms/step - loss: 1.2327 - accuracy: 0.4424 - val_loss: 1.5568 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "167/167 [==============================] - 33s 199ms/step - loss: 1.2234 - accuracy: 0.4512 - val_loss: 1.5589 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "167/167 [==============================] - 33s 199ms/step - loss: 1.2319 - accuracy: 0.4440 - val_loss: 1.5558 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "167/167 [==============================] - 33s 199ms/step - loss: 1.2288 - accuracy: 0.4475 - val_loss: 1.5630 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "167/167 [==============================] - 33s 199ms/step - loss: 1.2188 - accuracy: 0.4470 - val_loss: 1.5279 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "167/167 [==============================] - 33s 199ms/step - loss: 1.2188 - accuracy: 0.4450 - val_loss: 1.4983 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "167/167 [==============================] - 33s 199ms/step - loss: 1.1758 - accuracy: 0.5217 - val_loss: 1.4789 - val_accuracy: 0.2812\n",
      "Epoch 22/30\n",
      "167/167 [==============================] - 33s 199ms/step - loss: 1.1118 - accuracy: 0.6947 - val_loss: 1.5197 - val_accuracy: 0.3750\n",
      "Epoch 23/30\n",
      "167/167 [==============================] - 33s 199ms/step - loss: 1.0475 - accuracy: 0.7233 - val_loss: 1.4765 - val_accuracy: 0.4375\n",
      "Epoch 24/30\n",
      "167/167 [==============================] - 33s 200ms/step - loss: 1.0136 - accuracy: 0.7278 - val_loss: 1.5487 - val_accuracy: 0.3750\n",
      "Epoch 25/30\n",
      "167/167 [==============================] - 33s 199ms/step - loss: 0.9841 - accuracy: 0.7282 - val_loss: 1.4693 - val_accuracy: 0.3438\n",
      "Epoch 26/30\n",
      "167/167 [==============================] - 33s 199ms/step - loss: 0.9646 - accuracy: 0.7230 - val_loss: 1.3162 - val_accuracy: 0.5000\n",
      "Epoch 27/30\n",
      "167/167 [==============================] - 33s 199ms/step - loss: 0.9266 - accuracy: 0.7310 - val_loss: 1.6051 - val_accuracy: 0.3125\n",
      "Epoch 28/30\n",
      "167/167 [==============================] - 33s 199ms/step - loss: 0.9014 - accuracy: 0.7326 - val_loss: 1.7362 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "167/167 [==============================] - 33s 199ms/step - loss: 0.8834 - accuracy: 0.7367 - val_loss: 1.2933 - val_accuracy: 0.5000\n",
      "Epoch 30/30\n",
      "167/167 [==============================] - 33s 199ms/step - loss: 0.8650 - accuracy: 0.7398 - val_loss: 1.5638 - val_accuracy: 0.3125\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_8348_images_True_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.335744\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.25251758 0.24784303 0.25484667 0.24524141]\n",
      "Training resnet for 0.25% of train size (aka 20871 images) with pretrained: False and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 178 trainable: 178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/418 [..............................] - ETA: 4:38 - loss: 1.3801 - accuracy: 0.3396WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0995s vs `on_train_batch_begin` time: 0.1477s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0995s vs `on_train_batch_end` time: 0.3434s). Check your callbacks.\n",
      "418/418 [==============================] - 94s 211ms/step - loss: 1.2425 - accuracy: 0.4553 - val_loss: 1.5704 - val_accuracy: 0.3125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "418/418 [==============================] - 83s 199ms/step - loss: 0.8194 - accuracy: 0.7215 - val_loss: 1.1316 - val_accuracy: 0.5000\n",
      "Epoch 3/30\n",
      "418/418 [==============================] - 83s 199ms/step - loss: 0.6809 - accuracy: 0.7569 - val_loss: 0.7685 - val_accuracy: 0.7500\n",
      "Epoch 4/30\n",
      "418/418 [==============================] - 83s 199ms/step - loss: 0.5740 - accuracy: 0.8147 - val_loss: 1.0957 - val_accuracy: 0.5938\n",
      "Epoch 5/30\n",
      "418/418 [==============================] - 83s 199ms/step - loss: 0.5127 - accuracy: 0.8332 - val_loss: 0.6415 - val_accuracy: 0.7812\n",
      "Epoch 6/30\n",
      "418/418 [==============================] - 83s 200ms/step - loss: 0.4734 - accuracy: 0.8569 - val_loss: 0.6946 - val_accuracy: 0.8125\n",
      "Epoch 7/30\n",
      "418/418 [==============================] - 83s 199ms/step - loss: 0.4192 - accuracy: 0.8801 - val_loss: 0.3035 - val_accuracy: 1.0000\n",
      "Epoch 8/30\n",
      "418/418 [==============================] - 83s 199ms/step - loss: 0.3745 - accuracy: 0.9004 - val_loss: 2.0178 - val_accuracy: 0.3438\n",
      "Epoch 9/30\n",
      "418/418 [==============================] - 83s 199ms/step - loss: 0.3385 - accuracy: 0.9100 - val_loss: 0.7682 - val_accuracy: 0.7500\n",
      "Epoch 10/30\n",
      "418/418 [==============================] - 83s 199ms/step - loss: 0.3008 - accuracy: 0.9248 - val_loss: 0.2368 - val_accuracy: 1.0000\n",
      "Epoch 11/30\n",
      "418/418 [==============================] - 83s 199ms/step - loss: 0.2790 - accuracy: 0.9327 - val_loss: 0.6154 - val_accuracy: 0.8750\n",
      "Epoch 12/30\n",
      "418/418 [==============================] - 83s 199ms/step - loss: 0.2506 - accuracy: 0.9424 - val_loss: 0.4998 - val_accuracy: 0.9062\n",
      "Epoch 13/30\n",
      "418/418 [==============================] - 83s 199ms/step - loss: 0.2184 - accuracy: 0.9487 - val_loss: 0.1259 - val_accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "418/418 [==============================] - 83s 199ms/step - loss: 0.2142 - accuracy: 0.9464 - val_loss: 0.1076 - val_accuracy: 1.0000\n",
      "Epoch 15/30\n",
      "418/418 [==============================] - 83s 200ms/step - loss: 0.1865 - accuracy: 0.9559 - val_loss: 0.2386 - val_accuracy: 0.9688\n",
      "Epoch 16/30\n",
      "418/418 [==============================] - 83s 199ms/step - loss: 0.1715 - accuracy: 0.9612 - val_loss: 0.0832 - val_accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "418/418 [==============================] - 83s 199ms/step - loss: 0.1394 - accuracy: 0.9708 - val_loss: 0.0754 - val_accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "418/418 [==============================] - 83s 199ms/step - loss: 0.1238 - accuracy: 0.9745 - val_loss: 0.0731 - val_accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "418/418 [==============================] - 83s 199ms/step - loss: 0.1001 - accuracy: 0.9825 - val_loss: 0.1251 - val_accuracy: 0.9688\n",
      "Epoch 20/30\n",
      "418/418 [==============================] - 83s 199ms/step - loss: 0.0936 - accuracy: 0.9843 - val_loss: 0.0599 - val_accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "418/418 [==============================] - 83s 199ms/step - loss: 0.0845 - accuracy: 0.9862 - val_loss: 0.0618 - val_accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "418/418 [==============================] - 83s 199ms/step - loss: 0.0825 - accuracy: 0.9869 - val_loss: 0.0539 - val_accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "418/418 [==============================] - 83s 199ms/step - loss: 0.0795 - accuracy: 0.9882 - val_loss: 0.0515 - val_accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "418/418 [==============================] - 83s 199ms/step - loss: 0.0665 - accuracy: 0.9908 - val_loss: 0.0570 - val_accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "418/418 [==============================] - 83s 199ms/step - loss: 0.0643 - accuracy: 0.9922 - val_loss: 0.0499 - val_accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "418/418 [==============================] - 83s 199ms/step - loss: 0.0628 - accuracy: 0.9922 - val_loss: 0.0593 - val_accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "418/418 [==============================] - 83s 198ms/step - loss: 0.0619 - accuracy: 0.9922 - val_loss: 0.0545 - val_accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "418/418 [==============================] - 83s 199ms/step - loss: 0.0626 - accuracy: 0.9923 - val_loss: 0.0483 - val_accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "418/418 [==============================] - 83s 199ms/step - loss: 0.0569 - accuracy: 0.9931 - val_loss: 0.0438 - val_accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "418/418 [==============================] - 83s 199ms/step - loss: 0.0588 - accuracy: 0.9927 - val_loss: 0.0434 - val_accuracy: 1.0000\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_20871_images_True_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.987603\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.40547216 0.3980379  0.40183292 0.38927577]\n",
      "Training resnet for 0.4% of train size (aka 33393 images) with pretrained: False and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 178 trainable: 178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/668 [..............................] - ETA: 7:29 - loss: 1.3808 - accuracy: 0.2403WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1011s vs `on_train_batch_begin` time: 0.1466s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1011s vs `on_train_batch_end` time: 0.3455s). Check your callbacks.\n",
      "668/668 [==============================] - 142s 205ms/step - loss: 1.2385 - accuracy: 0.4492 - val_loss: 1.5396 - val_accuracy: 0.3438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "668/668 [==============================] - 133s 199ms/step - loss: 0.7946 - accuracy: 0.7290 - val_loss: 1.0035 - val_accuracy: 0.5000\n",
      "Epoch 3/30\n",
      "668/668 [==============================] - 133s 199ms/step - loss: 0.6262 - accuracy: 0.7960 - val_loss: 1.0967 - val_accuracy: 0.5000\n",
      "Epoch 4/30\n",
      "668/668 [==============================] - 133s 199ms/step - loss: 0.5150 - accuracy: 0.8225 - val_loss: 1.1781 - val_accuracy: 0.6250\n",
      "Epoch 5/30\n",
      "668/668 [==============================] - 133s 199ms/step - loss: 0.4338 - accuracy: 0.8726 - val_loss: 2.2220 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "668/668 [==============================] - 133s 199ms/step - loss: 0.3775 - accuracy: 0.8968 - val_loss: 0.8060 - val_accuracy: 0.7812\n",
      "Epoch 7/30\n",
      "668/668 [==============================] - 133s 198ms/step - loss: 0.3269 - accuracy: 0.9141 - val_loss: 0.3007 - val_accuracy: 0.9375\n",
      "Epoch 8/30\n",
      "668/668 [==============================] - 133s 199ms/step - loss: 0.2897 - accuracy: 0.9234 - val_loss: 0.1333 - val_accuracy: 1.0000\n",
      "Epoch 9/30\n",
      "668/668 [==============================] - 133s 199ms/step - loss: 0.2528 - accuracy: 0.9320 - val_loss: 0.1482 - val_accuracy: 0.9688\n",
      "Epoch 10/30\n",
      "668/668 [==============================] - 133s 199ms/step - loss: 0.2194 - accuracy: 0.9417 - val_loss: 0.0803 - val_accuracy: 1.0000\n",
      "Epoch 11/30\n",
      "668/668 [==============================] - 132s 198ms/step - loss: 0.2003 - accuracy: 0.9464 - val_loss: 0.2877 - val_accuracy: 0.9062\n",
      "Epoch 12/30\n",
      "668/668 [==============================] - 133s 198ms/step - loss: 0.1681 - accuracy: 0.9576 - val_loss: 0.0561 - val_accuracy: 1.0000\n",
      "Epoch 13/30\n",
      "668/668 [==============================] - 133s 199ms/step - loss: 0.1459 - accuracy: 0.9637 - val_loss: 0.0492 - val_accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "668/668 [==============================] - 133s 199ms/step - loss: 0.1197 - accuracy: 0.9704 - val_loss: 0.1561 - val_accuracy: 0.9375\n",
      "Epoch 15/30\n",
      "668/668 [==============================] - 133s 199ms/step - loss: 0.1090 - accuracy: 0.9748 - val_loss: 0.1008 - val_accuracy: 0.9688\n",
      "Epoch 16/30\n",
      "668/668 [==============================] - 133s 199ms/step - loss: 0.0935 - accuracy: 0.9790 - val_loss: 0.0387 - val_accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "668/668 [==============================] - 133s 199ms/step - loss: 0.0821 - accuracy: 0.9830 - val_loss: 0.0773 - val_accuracy: 0.9688\n",
      "Epoch 18/30\n",
      "668/668 [==============================] - 133s 199ms/step - loss: 0.0788 - accuracy: 0.9836 - val_loss: 0.0317 - val_accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "668/668 [==============================] - 133s 199ms/step - loss: 0.0680 - accuracy: 0.9869 - val_loss: 0.0304 - val_accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "668/668 [==============================] - 133s 199ms/step - loss: 0.0625 - accuracy: 0.9888 - val_loss: 0.0295 - val_accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "668/668 [==============================] - 133s 199ms/step - loss: 0.0543 - accuracy: 0.9910 - val_loss: 0.0287 - val_accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "668/668 [==============================] - 133s 199ms/step - loss: 0.0498 - accuracy: 0.9927 - val_loss: 0.0270 - val_accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "668/668 [==============================] - 132s 198ms/step - loss: 0.0509 - accuracy: 0.9920 - val_loss: 0.0258 - val_accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "668/668 [==============================] - 133s 199ms/step - loss: 0.0479 - accuracy: 0.9926 - val_loss: 0.0280 - val_accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "668/668 [==============================] - 133s 199ms/step - loss: 0.0484 - accuracy: 0.9929 - val_loss: 0.0246 - val_accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "668/668 [==============================] - 133s 198ms/step - loss: 0.0394 - accuracy: 0.9948 - val_loss: 0.0240 - val_accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "668/668 [==============================] - 133s 199ms/step - loss: 0.0407 - accuracy: 0.9946 - val_loss: 0.0234 - val_accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "668/668 [==============================] - 133s 199ms/step - loss: 0.0379 - accuracy: 0.9950 - val_loss: 0.0229 - val_accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "668/668 [==============================] - 133s 199ms/step - loss: 0.0360 - accuracy: 0.9955 - val_loss: 0.0228 - val_accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "668/668 [==============================] - 133s 199ms/step - loss: 0.0373 - accuracy: 0.9949 - val_loss: 0.0222 - val_accuracy: 1.0000\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_33394_images_True_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.987603\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.5065552  0.49565919 0.50361297 0.49396472]\n",
      "Training resnet for 0.5% of train size (aka 41742 images) with pretrained: False and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 178 trainable: 178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/835 [..............................] - ETA: 10:15 - loss: 1.3814 - accuracy: 0.2883WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1019s vs `on_train_batch_begin` time: 0.1575s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1019s vs `on_train_batch_end` time: 0.3834s). Check your callbacks.\n",
      "835/835 [==============================] - 177s 205ms/step - loss: 1.2438 - accuracy: 0.4390 - val_loss: 1.5615 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "835/835 [==============================] - 166s 199ms/step - loss: 1.2002 - accuracy: 0.4710 - val_loss: 1.5726 - val_accuracy: 0.3750\n",
      "Epoch 3/30\n",
      "835/835 [==============================] - 166s 198ms/step - loss: 0.7084 - accuracy: 0.7527 - val_loss: 2.6253 - val_accuracy: 0.2812\n",
      "Epoch 4/30\n",
      "835/835 [==============================] - 166s 198ms/step - loss: 0.5329 - accuracy: 0.8345 - val_loss: 0.7480 - val_accuracy: 0.7500\n",
      "Epoch 5/30\n",
      "835/835 [==============================] - 165s 198ms/step - loss: 0.4567 - accuracy: 0.8629 - val_loss: 1.3001 - val_accuracy: 0.5625\n",
      "Epoch 6/30\n",
      "835/835 [==============================] - 165s 198ms/step - loss: 0.3823 - accuracy: 0.8910 - val_loss: 0.2563 - val_accuracy: 0.9688\n",
      "Epoch 7/30\n",
      "835/835 [==============================] - 166s 198ms/step - loss: 0.2975 - accuracy: 0.9190 - val_loss: 0.5780 - val_accuracy: 0.8438\n",
      "Epoch 8/30\n",
      "835/835 [==============================] - 165s 198ms/step - loss: 0.2589 - accuracy: 0.9289 - val_loss: 0.0815 - val_accuracy: 1.0000\n",
      "Epoch 9/30\n",
      "835/835 [==============================] - 165s 198ms/step - loss: 0.2139 - accuracy: 0.9418 - val_loss: 0.1115 - val_accuracy: 0.9688\n",
      "Epoch 10/30\n",
      "835/835 [==============================] - 165s 198ms/step - loss: 0.1902 - accuracy: 0.9490 - val_loss: 0.0618 - val_accuracy: 1.0000\n",
      "Epoch 11/30\n",
      "835/835 [==============================] - 165s 198ms/step - loss: 0.1705 - accuracy: 0.9546 - val_loss: 0.0799 - val_accuracy: 1.0000\n",
      "Epoch 12/30\n",
      "835/835 [==============================] - 166s 198ms/step - loss: 0.1532 - accuracy: 0.9598 - val_loss: 0.1737 - val_accuracy: 0.9375\n",
      "Epoch 13/30\n",
      "835/835 [==============================] - 165s 198ms/step - loss: 0.1296 - accuracy: 0.9669 - val_loss: 0.0413 - val_accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "835/835 [==============================] - 166s 198ms/step - loss: 0.1129 - accuracy: 0.9727 - val_loss: 0.0882 - val_accuracy: 0.9688\n",
      "Epoch 15/30\n",
      "835/835 [==============================] - 166s 198ms/step - loss: 0.1007 - accuracy: 0.9757 - val_loss: 0.0398 - val_accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "835/835 [==============================] - 166s 199ms/step - loss: 0.0888 - accuracy: 0.9793 - val_loss: 0.0293 - val_accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "835/835 [==============================] - 166s 199ms/step - loss: 0.0787 - accuracy: 0.9824 - val_loss: 0.0278 - val_accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "835/835 [==============================] - 166s 199ms/step - loss: 0.0687 - accuracy: 0.9862 - val_loss: 0.0244 - val_accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "835/835 [==============================] - 166s 199ms/step - loss: 0.0614 - accuracy: 0.9876 - val_loss: 0.0511 - val_accuracy: 0.9688\n",
      "Epoch 20/30\n",
      "835/835 [==============================] - 166s 199ms/step - loss: 0.0556 - accuracy: 0.9896 - val_loss: 0.0216 - val_accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "835/835 [==============================] - 166s 199ms/step - loss: 0.0516 - accuracy: 0.9906 - val_loss: 0.0218 - val_accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "835/835 [==============================] - 166s 199ms/step - loss: 0.0430 - accuracy: 0.9929 - val_loss: 0.0200 - val_accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "835/835 [==============================] - 166s 199ms/step - loss: 0.0416 - accuracy: 0.9931 - val_loss: 0.0203 - val_accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "835/835 [==============================] - 166s 199ms/step - loss: 0.0366 - accuracy: 0.9943 - val_loss: 0.0391 - val_accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "835/835 [==============================] - 166s 199ms/step - loss: 0.0361 - accuracy: 0.9946 - val_loss: 0.0186 - val_accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "835/835 [==============================] - 166s 199ms/step - loss: 0.0330 - accuracy: 0.9954 - val_loss: 0.0180 - val_accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "835/835 [==============================] - 166s 199ms/step - loss: 0.0325 - accuracy: 0.9954 - val_loss: 0.0184 - val_accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "835/835 [==============================] - 166s 199ms/step - loss: 0.0311 - accuracy: 0.9952 - val_loss: 0.0173 - val_accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "835/835 [==============================] - 166s 199ms/step - loss: 0.0310 - accuracy: 0.9950 - val_loss: 0.0170 - val_accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "835/835 [==============================] - 166s 199ms/step - loss: 0.0280 - accuracy: 0.9960 - val_loss: 0.0172 - val_accuracy: 1.0000\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_41742_images_True_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.987603\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.60516816 0.59567262 0.60327811 0.5985376 ]\n",
      "Training resnet for 0.6% of train size (aka 50090 images) with pretrained: False and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 178 trainable: 178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "   6/1002 [..............................] - ETA: 11:08 - loss: 1.3810 - accuracy: 0.4277WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0994s vs `on_train_batch_begin` time: 0.1478s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0994s vs `on_train_batch_end` time: 0.3403s). Check your callbacks.\n",
      "1002/1002 [==============================] - 211s 204ms/step - loss: 1.2050 - accuracy: 0.4746 - val_loss: 1.1909 - val_accuracy: 0.4375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "1002/1002 [==============================] - 200s 200ms/step - loss: 0.6575 - accuracy: 0.7723 - val_loss: 1.1897 - val_accuracy: 0.6562\n",
      "Epoch 3/30\n",
      "1002/1002 [==============================] - 200s 199ms/step - loss: 0.4667 - accuracy: 0.8509 - val_loss: 0.8986 - val_accuracy: 0.6875\n",
      "Epoch 4/30\n",
      "1002/1002 [==============================] - 199s 199ms/step - loss: 0.3771 - accuracy: 0.8940 - val_loss: 0.2124 - val_accuracy: 1.0000\n",
      "Epoch 5/30\n",
      "1002/1002 [==============================] - 199s 199ms/step - loss: 0.2926 - accuracy: 0.9225 - val_loss: 0.1343 - val_accuracy: 1.0000\n",
      "Epoch 6/30\n",
      "1002/1002 [==============================] - 199s 199ms/step - loss: 0.2413 - accuracy: 0.9352 - val_loss: 0.0826 - val_accuracy: 1.0000\n",
      "Epoch 7/30\n",
      "1002/1002 [==============================] - 200s 199ms/step - loss: 0.1901 - accuracy: 0.9478 - val_loss: 0.1872 - val_accuracy: 0.9375\n",
      "Epoch 8/30\n",
      "1002/1002 [==============================] - 200s 199ms/step - loss: 0.1589 - accuracy: 0.9563 - val_loss: 0.2019 - val_accuracy: 0.9375\n",
      "Epoch 9/30\n",
      "1002/1002 [==============================] - 200s 199ms/step - loss: 0.1384 - accuracy: 0.9622 - val_loss: 0.0502 - val_accuracy: 1.0000\n",
      "Epoch 10/30\n",
      "1002/1002 [==============================] - 200s 199ms/step - loss: 0.1199 - accuracy: 0.9687 - val_loss: 0.0729 - val_accuracy: 0.9688\n",
      "Epoch 11/30\n",
      "1002/1002 [==============================] - 200s 199ms/step - loss: 0.0956 - accuracy: 0.9756 - val_loss: 0.0265 - val_accuracy: 1.0000\n",
      "Epoch 12/30\n",
      "1002/1002 [==============================] - 200s 199ms/step - loss: 0.0842 - accuracy: 0.9782 - val_loss: 0.0927 - val_accuracy: 0.9688\n",
      "Epoch 13/30\n",
      "1002/1002 [==============================] - 199s 199ms/step - loss: 0.0742 - accuracy: 0.9822 - val_loss: 0.0897 - val_accuracy: 0.9375\n",
      "Epoch 14/30\n",
      "1002/1002 [==============================] - 200s 199ms/step - loss: 0.0609 - accuracy: 0.9858 - val_loss: 0.0489 - val_accuracy: 0.9688\n",
      "Epoch 15/30\n",
      "1002/1002 [==============================] - 200s 199ms/step - loss: 0.0541 - accuracy: 0.9885 - val_loss: 0.0536 - val_accuracy: 0.9688\n",
      "Epoch 16/30\n",
      "1002/1002 [==============================] - 200s 199ms/step - loss: 0.0503 - accuracy: 0.9896 - val_loss: 0.0344 - val_accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "1002/1002 [==============================] - 199s 199ms/step - loss: 0.0417 - accuracy: 0.9915 - val_loss: 0.0993 - val_accuracy: 0.9688\n",
      "Epoch 18/30\n",
      "1002/1002 [==============================] - 206s 206ms/step - loss: 0.0352 - accuracy: 0.9931 - val_loss: 0.0392 - val_accuracy: 0.9688\n",
      "Epoch 19/30\n",
      "1002/1002 [==============================] - 209s 209ms/step - loss: 0.0311 - accuracy: 0.9947 - val_loss: 0.0152 - val_accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "1002/1002 [==============================] - 215s 215ms/step - loss: 0.0273 - accuracy: 0.9952 - val_loss: 0.0198 - val_accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "1002/1002 [==============================] - 218s 217ms/step - loss: 0.0262 - accuracy: 0.9952 - val_loss: 0.0153 - val_accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "1002/1002 [==============================] - 238s 237ms/step - loss: 0.0255 - accuracy: 0.9956 - val_loss: 0.0560 - val_accuracy: 0.9688\n",
      "Epoch 23/30\n",
      "1002/1002 [==============================] - 242s 241ms/step - loss: 0.0236 - accuracy: 0.9959 - val_loss: 0.0419 - val_accuracy: 0.9688\n",
      "Epoch 24/30\n",
      "1002/1002 [==============================] - 239s 239ms/step - loss: 0.0223 - accuracy: 0.9962 - val_loss: 0.0129 - val_accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "1002/1002 [==============================] - 207s 207ms/step - loss: 0.0226 - accuracy: 0.9964 - val_loss: 0.1033 - val_accuracy: 0.9688\n",
      "Epoch 26/30\n",
      "1002/1002 [==============================] - 201s 200ms/step - loss: 0.0229 - accuracy: 0.9960 - val_loss: 0.0574 - val_accuracy: 0.9688\n",
      "Epoch 27/30\n",
      "1002/1002 [==============================] - 200s 200ms/step - loss: 0.0207 - accuracy: 0.9966 - val_loss: 0.0183 - val_accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "1002/1002 [==============================] - 200s 200ms/step - loss: 0.0219 - accuracy: 0.9963 - val_loss: 0.0236 - val_accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "1002/1002 [==============================] - 200s 200ms/step - loss: 0.0186 - accuracy: 0.9968 - val_loss: 0.0897 - val_accuracy: 0.9688\n",
      "Epoch 30/30\n",
      "1002/1002 [==============================] - 201s 200ms/step - loss: 0.0181 - accuracy: 0.9967 - val_loss: 0.0915 - val_accuracy: 0.9688\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_50090_images_True_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.992769\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.75500665 0.74748018 0.75255552 0.74222377]\n",
      "Training resnet for 0.75% of train size (aka 62613 images) with pretrained: False and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 178 trainable: 178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "   6/1253 [..............................] - ETA: 15:09 - loss: 1.3796 - accuracy: 0.3862WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1048s vs `on_train_batch_begin` time: 0.1680s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1048s vs `on_train_batch_end` time: 0.3619s). Check your callbacks.\n",
      "1253/1253 [==============================] - 263s 204ms/step - loss: 1.2393 - accuracy: 0.4461 - val_loss: 1.5383 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "1253/1253 [==============================] - 251s 201ms/step - loss: 1.1085 - accuracy: 0.5453 - val_loss: 1.1618 - val_accuracy: 0.5312\n",
      "Epoch 3/30\n",
      "1253/1253 [==============================] - 250s 200ms/step - loss: 0.6321 - accuracy: 0.7679 - val_loss: 1.7855 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "1253/1253 [==============================] - 250s 200ms/step - loss: 0.4466 - accuracy: 0.8728 - val_loss: 0.7093 - val_accuracy: 0.7500\n",
      "Epoch 5/30\n",
      "1253/1253 [==============================] - 251s 200ms/step - loss: 0.3225 - accuracy: 0.9100 - val_loss: 1.1244 - val_accuracy: 0.7188\n",
      "Epoch 6/30\n",
      "1253/1253 [==============================] - 250s 200ms/step - loss: 0.2555 - accuracy: 0.9299 - val_loss: 0.6448 - val_accuracy: 0.7812\n",
      "Epoch 7/30\n",
      "1253/1253 [==============================] - 250s 199ms/step - loss: 0.2013 - accuracy: 0.9452 - val_loss: 0.2065 - val_accuracy: 0.9375\n",
      "Epoch 8/30\n",
      "1253/1253 [==============================] - 250s 199ms/step - loss: 0.1702 - accuracy: 0.9544 - val_loss: 0.0961 - val_accuracy: 1.0000\n",
      "Epoch 9/30\n",
      "1253/1253 [==============================] - 251s 200ms/step - loss: 0.1524 - accuracy: 0.9590 - val_loss: 0.0835 - val_accuracy: 0.9688\n",
      "Epoch 10/30\n",
      "1253/1253 [==============================] - 257s 205ms/step - loss: 0.1309 - accuracy: 0.9637 - val_loss: 0.0848 - val_accuracy: 0.9688\n",
      "Epoch 11/30\n",
      "1253/1253 [==============================] - 280s 223ms/step - loss: 0.1181 - accuracy: 0.9687 - val_loss: 0.0340 - val_accuracy: 1.0000\n",
      "Epoch 12/30\n",
      "1253/1253 [==============================] - 296s 236ms/step - loss: 0.0997 - accuracy: 0.9741 - val_loss: 0.0828 - val_accuracy: 0.9688\n",
      "Epoch 13/30\n",
      "1253/1253 [==============================] - 301s 240ms/step - loss: 0.0832 - accuracy: 0.9800 - val_loss: 0.0244 - val_accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "1253/1253 [==============================] - 301s 240ms/step - loss: 0.0735 - accuracy: 0.9817 - val_loss: 0.0298 - val_accuracy: 1.0000\n",
      "Epoch 15/30\n",
      "1253/1253 [==============================] - 290s 231ms/step - loss: 0.0657 - accuracy: 0.9839 - val_loss: 0.0223 - val_accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "1253/1253 [==============================] - 288s 230ms/step - loss: 0.0562 - accuracy: 0.9868 - val_loss: 0.1422 - val_accuracy: 0.9688\n",
      "Epoch 17/30\n",
      "1253/1253 [==============================] - 300s 240ms/step - loss: 0.0507 - accuracy: 0.9888 - val_loss: 0.0355 - val_accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "1253/1253 [==============================] - 299s 239ms/step - loss: 0.0462 - accuracy: 0.9904 - val_loss: 0.1472 - val_accuracy: 0.9688\n",
      "Epoch 19/30\n",
      "1253/1253 [==============================] - 299s 239ms/step - loss: 0.0390 - accuracy: 0.9925 - val_loss: 0.2024 - val_accuracy: 0.9688\n",
      "Epoch 20/30\n",
      "1253/1253 [==============================] - 293s 234ms/step - loss: 0.0343 - accuracy: 0.9941 - val_loss: 0.1993 - val_accuracy: 0.9688\n",
      "Epoch 21/30\n",
      "1253/1253 [==============================] - 295s 236ms/step - loss: 0.0382 - accuracy: 0.9915 - val_loss: 0.1868 - val_accuracy: 0.9688\n",
      "Epoch 22/30\n",
      "1253/1253 [==============================] - 303s 242ms/step - loss: 0.0322 - accuracy: 0.9942 - val_loss: 0.1356 - val_accuracy: 0.9688\n",
      "Epoch 23/30\n",
      "1253/1253 [==============================] - 300s 239ms/step - loss: 0.0275 - accuracy: 0.9950 - val_loss: 0.1507 - val_accuracy: 0.9688\n",
      "Epoch 24/30\n",
      "1253/1253 [==============================] - 299s 238ms/step - loss: 0.0242 - accuracy: 0.9958 - val_loss: 0.1802 - val_accuracy: 0.9688\n",
      "Epoch 25/30\n",
      "1253/1253 [==============================] - 280s 223ms/step - loss: 0.0256 - accuracy: 0.9952 - val_loss: 0.1664 - val_accuracy: 0.9688\n",
      "Epoch 26/30\n",
      "1253/1253 [==============================] - 300s 239ms/step - loss: 0.0255 - accuracy: 0.9952 - val_loss: 0.1489 - val_accuracy: 0.9688\n",
      "Epoch 27/30\n",
      "1253/1253 [==============================] - 300s 239ms/step - loss: 0.0226 - accuracy: 0.9960 - val_loss: 0.1870 - val_accuracy: 0.9688\n",
      "Epoch 28/30\n",
      "1253/1253 [==============================] - 299s 239ms/step - loss: 0.0220 - accuracy: 0.9958 - val_loss: 0.1833 - val_accuracy: 0.9688\n",
      "Epoch 29/30\n",
      "1253/1253 [==============================] - 287s 229ms/step - loss: 0.0206 - accuracy: 0.9960 - val_loss: 0.1833 - val_accuracy: 0.9688\n",
      "Epoch 30/30\n",
      "1253/1253 [==============================] - 295s 236ms/step - loss: 0.0200 - accuracy: 0.9962 - val_loss: 0.1819 - val_accuracy: 0.9688\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_62613_images_True_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.991736\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.90378111 0.89694933 0.90192104 0.89902507]\n",
      "Training resnet for 0.9% of train size (aka 75135 images) with pretrained: False and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 178 trainable: 178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "   6/1503 [..............................] - ETA: 24:04 - loss: 1.3800 - accuracy: 0.3806WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1314s vs `on_train_batch_begin` time: 0.2305s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1314s vs `on_train_batch_end` time: 0.4743s). Check your callbacks.\n",
      "1503/1503 [==============================] - 375s 244ms/step - loss: 1.2377 - accuracy: 0.4435 - val_loss: 1.5562 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "1503/1503 [==============================] - 360s 240ms/step - loss: 1.1693 - accuracy: 0.4864 - val_loss: 1.1903 - val_accuracy: 0.5625\n",
      "Epoch 3/30\n",
      "1503/1503 [==============================] - 354s 235ms/step - loss: 0.6021 - accuracy: 0.7986 - val_loss: 1.3531 - val_accuracy: 0.4688\n",
      "Epoch 4/30\n",
      "1503/1503 [==============================] - 353s 235ms/step - loss: 0.4129 - accuracy: 0.8839 - val_loss: 0.2253 - val_accuracy: 0.9688\n",
      "Epoch 5/30\n",
      "1503/1503 [==============================] - 359s 239ms/step - loss: 0.2993 - accuracy: 0.9195 - val_loss: 0.1220 - val_accuracy: 0.9688\n",
      "Epoch 6/30\n",
      "1503/1503 [==============================] - 359s 239ms/step - loss: 0.2325 - accuracy: 0.9367 - val_loss: 0.0687 - val_accuracy: 1.0000\n",
      "Epoch 7/30\n",
      "1503/1503 [==============================] - 346s 230ms/step - loss: 0.1873 - accuracy: 0.9484 - val_loss: 0.0475 - val_accuracy: 1.0000\n",
      "Epoch 8/30\n",
      "1503/1503 [==============================] - 358s 238ms/step - loss: 0.1555 - accuracy: 0.9564 - val_loss: 0.0811 - val_accuracy: 0.9688\n",
      "Epoch 9/30\n",
      "1503/1503 [==============================] - 358s 238ms/step - loss: 0.1314 - accuracy: 0.9643 - val_loss: 0.0974 - val_accuracy: 0.9688\n",
      "Epoch 10/30\n",
      "1503/1503 [==============================] - 360s 239ms/step - loss: 0.1121 - accuracy: 0.9692 - val_loss: 0.1098 - val_accuracy: 0.9688\n",
      "Epoch 11/30\n",
      "1503/1503 [==============================] - 355s 236ms/step - loss: 0.0946 - accuracy: 0.9755 - val_loss: 0.0256 - val_accuracy: 1.0000\n",
      "Epoch 12/30\n",
      "1503/1503 [==============================] - 357s 237ms/step - loss: 0.0809 - accuracy: 0.9793 - val_loss: 0.1106 - val_accuracy: 0.9688\n",
      "Epoch 13/30\n",
      "1503/1503 [==============================] - 358s 238ms/step - loss: 0.0695 - accuracy: 0.9822 - val_loss: 0.0186 - val_accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "1503/1503 [==============================] - 359s 239ms/step - loss: 0.0590 - accuracy: 0.9857 - val_loss: 0.0870 - val_accuracy: 0.9688\n",
      "Epoch 15/30\n",
      "1503/1503 [==============================] - 357s 238ms/step - loss: 0.0513 - accuracy: 0.9880 - val_loss: 0.0326 - val_accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "1503/1503 [==============================] - 355s 236ms/step - loss: 0.0449 - accuracy: 0.9901 - val_loss: 0.0326 - val_accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "1503/1503 [==============================] - 356s 237ms/step - loss: 0.0403 - accuracy: 0.9910 - val_loss: 0.1268 - val_accuracy: 0.9688\n",
      "Epoch 18/30\n",
      "1503/1503 [==============================] - 356s 237ms/step - loss: 0.0367 - accuracy: 0.9919 - val_loss: 0.1318 - val_accuracy: 0.9688\n",
      "Epoch 19/30\n",
      "1503/1503 [==============================] - 356s 237ms/step - loss: 0.0316 - accuracy: 0.9932 - val_loss: 0.0819 - val_accuracy: 0.9688\n",
      "Epoch 20/30\n",
      "1503/1503 [==============================] - 356s 237ms/step - loss: 0.0276 - accuracy: 0.9941 - val_loss: 0.1972 - val_accuracy: 0.9688\n",
      "Epoch 21/30\n",
      "1503/1503 [==============================] - 360s 239ms/step - loss: 0.0260 - accuracy: 0.9949 - val_loss: 0.1949 - val_accuracy: 0.9688\n",
      "Epoch 22/30\n",
      "1503/1503 [==============================] - 359s 239ms/step - loss: 0.0243 - accuracy: 0.9948 - val_loss: 0.1957 - val_accuracy: 0.9688\n",
      "Epoch 23/30\n",
      "1503/1503 [==============================] - 359s 239ms/step - loss: 0.0248 - accuracy: 0.9944 - val_loss: 0.1791 - val_accuracy: 0.9688\n",
      "Epoch 24/30\n",
      "1503/1503 [==============================] - 359s 239ms/step - loss: 0.0202 - accuracy: 0.9954 - val_loss: 0.2042 - val_accuracy: 0.9688\n",
      "Epoch 25/30\n",
      "1503/1503 [==============================] - 358s 238ms/step - loss: 0.0205 - accuracy: 0.9957 - val_loss: 0.2033 - val_accuracy: 0.9688\n",
      "Epoch 26/30\n",
      "1503/1503 [==============================] - 360s 240ms/step - loss: 0.0194 - accuracy: 0.9958 - val_loss: 0.2013 - val_accuracy: 0.9688\n",
      "Epoch 27/30\n",
      "1503/1503 [==============================] - 360s 239ms/step - loss: 0.0182 - accuracy: 0.9957 - val_loss: 0.2045 - val_accuracy: 0.9688\n",
      "Epoch 28/30\n",
      "1503/1503 [==============================] - 360s 240ms/step - loss: 0.0173 - accuracy: 0.9959 - val_loss: 0.2049 - val_accuracy: 0.9688\n",
      "Epoch 29/30\n",
      "1503/1503 [==============================] - 360s 240ms/step - loss: 0.0190 - accuracy: 0.9958 - val_loss: 0.2055 - val_accuracy: 0.9688\n",
      "Epoch 30/30\n",
      "1503/1503 [==============================] - 357s 238ms/step - loss: 0.0175 - accuracy: 0.9960 - val_loss: 0.2047 - val_accuracy: 0.9688\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_75136_images_True_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.997934\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [1. 1. 1. 1.]\n",
      "Training resnet for 1.0% of train size (aka 83484 images) with pretrained: False and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 178 trainable: 178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1670/1670 [==============================] - 424s 249ms/step - loss: 1.0521 - accuracy: 0.5661 - val_loss: 1.6672 - val_accuracy: 0.2812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "1670/1670 [==============================] - 399s 239ms/step - loss: 0.4953 - accuracy: 0.8382 - val_loss: 1.5995 - val_accuracy: 0.5312\n",
      "Epoch 3/30\n",
      "1670/1670 [==============================] - 398s 238ms/step - loss: 0.3297 - accuracy: 0.9104 - val_loss: 0.1643 - val_accuracy: 1.0000\n",
      "Epoch 4/30\n",
      "1670/1670 [==============================] - 393s 235ms/step - loss: 0.2359 - accuracy: 0.9357 - val_loss: 0.1864 - val_accuracy: 0.9688\n",
      "Epoch 5/30\n",
      "1670/1670 [==============================] - 402s 241ms/step - loss: 0.1854 - accuracy: 0.9489 - val_loss: 0.0661 - val_accuracy: 1.0000\n",
      "Epoch 6/30\n",
      "1670/1670 [==============================] - 401s 240ms/step - loss: 0.1552 - accuracy: 0.9571 - val_loss: 0.0553 - val_accuracy: 1.0000\n",
      "Epoch 7/30\n",
      "1670/1670 [==============================] - 394s 236ms/step - loss: 0.1330 - accuracy: 0.9634 - val_loss: 0.0641 - val_accuracy: 1.0000\n",
      "Epoch 8/30\n",
      "1670/1670 [==============================] - 399s 239ms/step - loss: 0.1112 - accuracy: 0.9692 - val_loss: 0.0470 - val_accuracy: 1.0000\n",
      "Epoch 9/30\n",
      "1670/1670 [==============================] - 375s 225ms/step - loss: 0.0974 - accuracy: 0.9741 - val_loss: 0.0609 - val_accuracy: 1.0000\n",
      "Epoch 10/30\n",
      "1670/1670 [==============================] - 338s 203ms/step - loss: 0.0811 - accuracy: 0.9792 - val_loss: 0.0729 - val_accuracy: 1.0000\n",
      "Epoch 11/30\n",
      "1670/1670 [==============================] - 333s 200ms/step - loss: 0.0687 - accuracy: 0.9826 - val_loss: 0.0291 - val_accuracy: 1.0000\n",
      "Epoch 12/30\n",
      "1670/1670 [==============================] - 333s 199ms/step - loss: 0.0597 - accuracy: 0.9856 - val_loss: 0.0252 - val_accuracy: 1.0000\n",
      "Epoch 13/30\n",
      "1670/1670 [==============================] - 332s 199ms/step - loss: 0.0547 - accuracy: 0.9873 - val_loss: 0.1101 - val_accuracy: 0.9062\n",
      "Epoch 14/30\n",
      "1670/1670 [==============================] - 332s 199ms/step - loss: 0.0473 - accuracy: 0.9892 - val_loss: 0.0314 - val_accuracy: 1.0000\n",
      "Epoch 15/30\n",
      "1670/1670 [==============================] - 333s 199ms/step - loss: 0.0398 - accuracy: 0.9920 - val_loss: 0.0233 - val_accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "1670/1670 [==============================] - 333s 199ms/step - loss: 0.0367 - accuracy: 0.9925 - val_loss: 0.0447 - val_accuracy: 0.9688\n",
      "Epoch 17/30\n",
      "1670/1670 [==============================] - 332s 199ms/step - loss: 0.0330 - accuracy: 0.9934 - val_loss: 0.0394 - val_accuracy: 0.9688\n",
      "Epoch 18/30\n",
      "1670/1670 [==============================] - 332s 199ms/step - loss: 0.0279 - accuracy: 0.9948 - val_loss: 0.0362 - val_accuracy: 0.9688\n",
      "Epoch 19/30\n",
      "1670/1670 [==============================] - 333s 199ms/step - loss: 0.0298 - accuracy: 0.9937 - val_loss: 0.0164 - val_accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "1670/1670 [==============================] - 333s 199ms/step - loss: 0.0244 - accuracy: 0.9951 - val_loss: 0.0322 - val_accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "1670/1670 [==============================] - 336s 201ms/step - loss: 0.0225 - accuracy: 0.9951 - val_loss: 0.0232 - val_accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "1670/1670 [==============================] - 337s 202ms/step - loss: 0.0248 - accuracy: 0.9944 - val_loss: 0.0253 - val_accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "1670/1670 [==============================] - 334s 200ms/step - loss: 0.0204 - accuracy: 0.9955 - val_loss: 0.0202 - val_accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "1670/1670 [==============================] - 342s 205ms/step - loss: 0.0202 - accuracy: 0.9954 - val_loss: 0.0289 - val_accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "1670/1670 [==============================] - 335s 201ms/step - loss: 0.0195 - accuracy: 0.9952 - val_loss: 0.0434 - val_accuracy: 0.9688\n",
      "Epoch 26/30\n",
      "1670/1670 [==============================] - 331s 198ms/step - loss: 0.0179 - accuracy: 0.9955 - val_loss: 0.0201 - val_accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "1670/1670 [==============================] - 332s 199ms/step - loss: 0.0185 - accuracy: 0.9952 - val_loss: 0.0231 - val_accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "1670/1670 [==============================] - 332s 199ms/step - loss: 0.0168 - accuracy: 0.9958 - val_loss: 0.0243 - val_accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "1670/1670 [==============================] - 332s 199ms/step - loss: 0.0170 - accuracy: 0.9958 - val_loss: 0.0320 - val_accuracy: 0.9688\n",
      "Epoch 30/30\n",
      "1670/1670 [==============================] - 332s 199ms/step - loss: 0.0159 - accuracy: 0.9961 - val_loss: 0.0251 - val_accuracy: 1.0000\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_83484_images_True_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.995868\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import datetime\n",
    "\n",
    "maxTrain = len(y_train)\n",
    "for newWeights in [True]:\n",
    "    tLayer = [False] if newWeights else [True, False] # do not train only last layer if new weights will be produced \n",
    "    for trainLastLayerOnly in tLayer:\n",
    "        for p in [0.01, 0.025, 0.05, 0.075, 0.09, 0.1, 0.25, 0.4, 0.5, 0.6, 0.75, 0.9, 1.0]:\n",
    "            learning_rate = 0.05\n",
    "            momentum = 0.6\n",
    "            #X_trn, X_tst, y_trn, y_tst\n",
    "            if p < 1:\n",
    "                X_t, _, y_t, _ = train_test_split(images, y_train, test_size=1-p, random_state=56789)\n",
    "            else:\n",
    "                X_t = images; y_t = y_train;\n",
    "            print(f\"Labels fraction: {sum(y_t == 1) / sum(y_train == 1)}\")\n",
    "            for net in [\"resnet\"]:\n",
    "                print(f\"Training {net} for {p}% of train size (aka {len(X_t)} images) with pretrained: {not newWeights} and onlyLastLayersTrained: {trainLastLayerOnly}...\")\n",
    "                model, size, normalization = emptyModelGenerator(net, newWeights=newWeights, lastOnly=trainLastLayerOnly)\n",
    "                printTrainableLayers(model) # see if model is really well trained\n",
    "                X_trn = resizeIms(X_t, size)\n",
    "                #X_trn = normalizeIms(X_trn, normalization=normalization)\n",
    "                X_val = resizeIms(x_val, size)\n",
    "                #X_val = normalizeIms(X_val, normalization=normalization)\n",
    "                log_dir = f\"logs/{net}/fit/{p}trainSet_\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "                tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "                optimizer = SGD(learning_rate=learning_rate, momentum=momentum) # Adam(learning_rate, amsgrad=amsgrad) #create new optimizers\n",
    "                time_callback = TimeHistory()\n",
    "                model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "                hist = model.fit(X_trn, y_t, epochs=epochs, validation_data = (X_val, y_validation), batch_size=batch_size,\n",
    "                            shuffle=True, max_queue_size=20,\n",
    "                            use_multiprocessing=True, workers=5, \n",
    "                            callbacks=[CustomCallback(fraction=0.9, model=net), tensorboard_callback, time_callback])\n",
    "                trainTime = sum(time_callback.times)\n",
    "                model.save(f\"../{net}/{net}_{epochs}epochs_{p*maxTrain:.0f}_images_{newWeights}_newWeights_{trainLastLayerOnly}_lastLayerOnly_{normalization}_normalization\")\n",
    "                tstAcc = testPredict(model, size, name=net) #, normalization=normalization)\n",
    "                results = results.append({\n",
    "                    'model': net, \n",
    "                    'train set images': len(X_t), \n",
    "                    'pretrained': not newWeights, \n",
    "                    'pretrained dataset': None if newWeights or net == \"octnet\" else (\"OCT2017,Srinivasan2014\" if net == \"opticnet\" else \"Imagenet\"),\n",
    "                    'Trained layers': \"Last dense\" if trainLastLayerOnly else \"All\", \n",
    "                    'epochs': epochs, \n",
    "                    'batch size': batch_size, \n",
    "                    'learning rate': f\"{learning_rate}_{momentum}\" if optimizer._name == \"SGD\" else learning_rate, \n",
    "                    'optimizer': \"Amsgrad\" if (optimizer._name == \"Adam\" and amsgrad) else optimizer._name,\n",
    "                    'training time (seconds)': trainTime, \n",
    "                    'train accuracy': hist.history[\"accuracy\"][-1], \n",
    "                    'train loss': hist.history[\"loss\"][-1],\n",
    "                    'validation accuracy': hist.history[\"val_accuracy\"][-1], \n",
    "                    'validation loss': hist.history[\"val_loss\"][-1], \n",
    "                    'test accuracy': tstAcc,\n",
    "                    #'normalization': normalization\n",
    "                }, ignore_index=True)\n",
    "                results.to_csv(\"Results_temp.csv\", index=False)\n",
    "                del model\n",
    "                del X_trn\n",
    "                del X_val\n",
    "                print(\"Done!\\n\" + '-'*50, end='\\n\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
