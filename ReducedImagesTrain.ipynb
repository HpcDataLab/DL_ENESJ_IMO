{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "import os\n",
    "import cv2\n",
    "import pickle\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataPath = \"../../data/OCT/OCT2017/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of Classes Detected : 4\n"
     ]
    }
   ],
   "source": [
    "labels_available = os.listdir(os.path.join(dataPath, \"train\"))\n",
    "print(\"Total Number of Classes Detected :\",len(labels_available))\n",
    "\n",
    "labels_list = ['NORMAL',\"CNV\",\"DME\",\"DRUSEN\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NORMAL CNV DME DRUSEN "
     ]
    }
   ],
   "source": [
    "images=[]\n",
    "y_trn=[]\n",
    "for x in labels_list:\n",
    "    xPath = os.path.join(dataPath, \"train\", x)\n",
    "    myPicList = os.listdir(xPath)\n",
    "    for y in myPicList:\n",
    "        images.append(cv2.imread(os.path.join(xPath, y)))\n",
    "        y_trn.append(labels_list.index(x))\n",
    "    print(x ,end=\" \")\n",
    "\n",
    "y_train = to_categorical(y_trn,len(labels_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NORMAL CNV DME DRUSEN "
     ]
    }
   ],
   "source": [
    "x_val=[]\n",
    "y_val=[]\n",
    "for x in labels_list:\n",
    "    xPath = os.path.join(dataPath, \"val\", x)\n",
    "    myPicList = os.listdir(xPath)\n",
    "    for y in myPicList:\n",
    "        x_val.append(cv2.imread(os.path.join(xPath, y)))\n",
    "        y_val.append(labels_list.index(x))\n",
    "    print(x ,end=\" \")\n",
    "\n",
    "y_validation = to_categorical(y_val,len(labels_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NORMAL CNV DME DRUSEN "
     ]
    }
   ],
   "source": [
    "x_tst=[]\n",
    "y_tst=[]\n",
    "for x in labels_list:\n",
    "    xPath = os.path.join(dataPath, \"test\", x)\n",
    "    myPicList = os.listdir(xPath)\n",
    "    for y in myPicList:\n",
    "        x_tst.append(cv2.imread(os.path.join(xPath, y)))\n",
    "        y_tst.append(labels_list.index(x))\n",
    "    print(x ,end=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resizeIm(im, size):\n",
    "    if im.shape[2] == 1:\n",
    "        im = cv2.cvtColor(im,cv2.COLOR_GRAY2RGB)\n",
    "    return cv2.resize(im, size)\n",
    "\n",
    "def resizeIms(x, size):\n",
    "    return np.array(list(map(lambda im: resizeIm(im, size), x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self,fraction, model):\n",
    "        super(CustomCallback,self).__init__()\n",
    "        self.fraction = fraction\n",
    "        self.train_a = [];\n",
    "        self.val_a =[];\n",
    "        self.logPath = os.path.join(model, \"log.txt\")\n",
    "\n",
    "        if not os.path.isdir(model):\n",
    "            os.mkdir(model)\n",
    "\n",
    "        with open(self.logPath,'w') as f:\n",
    "            f.write('Starting of logging..\\n')\n",
    "\n",
    "        self.fig = plt.figure(figsize=(4,3))\n",
    "        self.ax = plt.subplot(1,1,1)\n",
    "        plt.ion()\n",
    "\n",
    "    def on_train_begin(self,logs=None):\n",
    "        self.fig.show()\n",
    "        self.fig.canvas.draw()\n",
    "\n",
    "    def on_train_end(self,logs=None):\n",
    "        with open(self.logPath,'a') as f:\n",
    "              f.write('End of logging..\\n')\n",
    "    \n",
    "    def on_epoch_begin(self,epoch,logs=None):\n",
    "        lr= tf.keras.backend.get_value(self.model.optimizer.lr)\n",
    "        lr *= self.fraction\n",
    "        tf.keras.backend.set_value(self.model.optimizer.lr,lr)\n",
    "        with open(self.logPath,'a') as f:\n",
    "            f.write('At epoch {:02d}, learning rate changed to {:.4f}\\n'.format(epoch,lr))\n",
    "    \n",
    "    def on_epoch_end(self,epoch,logs=None):\n",
    "        val_acc = logs.get('val_accuracy')\n",
    "        train_acc = logs.get('accuracy')\n",
    "        self.train_a.append(train_acc)\n",
    "        self.val_a.append(val_acc)\n",
    "        with open(self.logPath,'a') as f:\n",
    "            f.write('At epoch {:02d}, training accuracy: {:.3f}, validation accuracy: {:.3f}\\n'.format(epoch,train_acc,val_acc))\n",
    "        self.ax.clear()\n",
    "        self.ax.plot(range(1+epoch),self.train_a,label=\"Training\")\n",
    "        self.ax.plot(range(1+epoch),self.val_a,label=\"Validation\")\n",
    "        self.ax.set_xlabel('Epochs')\n",
    "        self.ax.set_ylabel('Accuracy')\n",
    "        self.ax.legend()\n",
    "        self.fig.canvas.draw()\n",
    "        self.fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xception base model\n",
    "from tensorflow.keras.applications.xception import Xception\n",
    "from tensorflow.keras.applications.xception import preprocess_input, decode_predictions\n",
    "xceptionNetModel = Xception(weights='imagenet')\n",
    "\n",
    "# opticnet base model\n",
    "opticNetModel = tf.keras.models.load_model('../Optic_net-4_classes-Kermany2018.hdf5')\n",
    "\n",
    "# resnet base model\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "\n",
    "resNetModel = ResNet50(weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emptyModelGenerator(model, newWeights=False, lastOnly=False):\n",
    "    model = model.lower()\n",
    "    if model == \"resnet\":\n",
    "        x = resNetModel.output\n",
    "        predictions = Dense(len(labels_list), activation='softmax')(x)\n",
    "        newModel = Model(inputs=resNetModel.input, outputs=predictions)\n",
    "        size = (224, 224)\n",
    "    elif model == \"xception\":\n",
    "        x = xceptionNetModel.output\n",
    "        predictions = Dense(len(labels_list), activation='softmax')(x)\n",
    "        newModel = Model(inputs=xceptionNetModel.input, outputs=predictions)\n",
    "        size = (299, 299)\n",
    "    elif model == \"opticnet\":\n",
    "        newModel = tf.keras.models.load_model('../Optic_net-4_classes-Kermany2018.hdf5')\n",
    "        size = (224, 224)\n",
    "    if newWeights:\n",
    "        newModel = tf.keras.models.clone_model(newModel)\n",
    "    if lastOnly:\n",
    "        newModel = lastDenseTrainable(newModel) # block all layer except the last dense ones\n",
    "    return newModel, size\n",
    "\n",
    "\n",
    "def lastDenseTrainable(model):\n",
    "    model.trainable = False\n",
    "    for i in range(1, len(model.layers)):\n",
    "        if model.layers[-i].__class__.__name__ == \"Dense\":\n",
    "            model.layers[-i].trainable= True\n",
    "        elif model.layers[-i].__class__.__name__ == \"Activation\":\n",
    "            continue\n",
    "        else:\n",
    "            break\n",
    "    return model\n",
    "    \n",
    "\n",
    "def testPredict(model, size, name=None):\n",
    "    X_test = resizeIms(x_tst, size)\n",
    "    X_test = np.array(X_test)\n",
    "    Y_test = np.array(y_tst)\n",
    "    \n",
    "    prediction = model.predict(X_test)\n",
    "    preds = np.argmax(prediction, axis=1)\n",
    "    acc = sum(preds == Y_test) / len(Y_test)\n",
    "    print(f'Test acc for {name if name else \"model\"}: {acc:.6f}')\n",
    "    \n",
    "\n",
    "def computeConfussionMatrix(predictions, labels):\n",
    "    num_labels = len(labels_list)\n",
    "    cMatrix = np.zeros(shape=(num_labels, num_labels))\n",
    "    for i in len(predictions):\n",
    "        p = int(predictions[i])\n",
    "        t = int(predictions[i])\n",
    "        cMatrix[t, p] += 1\n",
    "    print(cMatrix)\n",
    "    ax = sns.heatmap(cMatrix, cmap=\"Blues\", annot=True, fmt=\"d\", xticklabels=labels_list, yticklabels=labels_list)\n",
    "    plt.xlabel(\"Predicted label\")\n",
    "    plt.ylabel(\"True label\")\n",
    "    plt.title(\"Confusion matrix\")\n",
    "    plt.show();\n",
    "    return cMatrix\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "models = [\"xception\", \"resnet\", \"opticnet\"]\n",
    "\n",
    "for mod in models:\n",
    "    print(\"\\n\\n\" + (\"*\"*50) + \"\\nModel: \" + mod + '\\n' + (\"*\"*50))\n",
    "    m = emptyModelGenerator(mod, newWeights=False, lastOnly=True)[0]\n",
    "    #m.trainable = False\n",
    "    a = 0\n",
    "    for l in m.layers:\n",
    "        #l.trainable = True\n",
    "        if l.trainable:\n",
    "            print(l.name, l.trainable)\n",
    "            a += 1\n",
    "            #print(l.trainable_weights)\n",
    "    print(f\"\\nTotal: {len(m.layers)} trainable: {a}\")\n",
    "    print(m.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "optim = Adam(learning_rate=0.001)\n",
    "epochs = 30\n",
    "batch_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels fraction: [0.01037431 0.00938046 0.01092704 0.01021356]\n",
      "Training xception for 0.01% of train size (aka 834 images)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      " 6/17 [=========>....................] - ETA: 5s - loss: 1.3912 - accuracy: 0.1687WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1149s vs `on_train_batch_begin` time: 0.2237s). Check your callbacks.\n",
      "17/17 [==============================] - 20s 382ms/step - loss: 1.3893 - accuracy: 0.1762 - val_loss: 1.3826 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "17/17 [==============================] - 2s 121ms/step - loss: 1.3884 - accuracy: 0.1862 - val_loss: 1.3826 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "17/17 [==============================] - 2s 122ms/step - loss: 1.3901 - accuracy: 0.1748 - val_loss: 1.3826 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "17/17 [==============================] - 2s 121ms/step - loss: 1.3878 - accuracy: 0.1776 - val_loss: 1.3826 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "17/17 [==============================] - 2s 122ms/step - loss: 1.3886 - accuracy: 0.1883 - val_loss: 1.3826 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "17/17 [==============================] - 2s 122ms/step - loss: 1.3864 - accuracy: 0.1869 - val_loss: 1.3826 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "17/17 [==============================] - 2s 122ms/step - loss: 1.3882 - accuracy: 0.1998 - val_loss: 1.3826 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "17/17 [==============================] - 2s 124ms/step - loss: 1.3909 - accuracy: 0.1765 - val_loss: 1.3826 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "17/17 [==============================] - 2s 125ms/step - loss: 1.3877 - accuracy: 0.1868 - val_loss: 1.3826 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "17/17 [==============================] - 2s 123ms/step - loss: 1.3904 - accuracy: 0.1807 - val_loss: 1.3826 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "17/17 [==============================] - 2s 124ms/step - loss: 1.3892 - accuracy: 0.1709 - val_loss: 1.3826 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "17/17 [==============================] - 2s 124ms/step - loss: 1.3881 - accuracy: 0.2023 - val_loss: 1.3826 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "17/17 [==============================] - 2s 124ms/step - loss: 1.3889 - accuracy: 0.1823 - val_loss: 1.3826 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "17/17 [==============================] - 2s 123ms/step - loss: 1.3901 - accuracy: 0.1861 - val_loss: 1.3826 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "17/17 [==============================] - 2s 127ms/step - loss: 1.3879 - accuracy: 0.1891 - val_loss: 1.3826 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "17/17 [==============================] - 2s 125ms/step - loss: 1.3867 - accuracy: 0.1914 - val_loss: 1.3826 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "17/17 [==============================] - 2s 124ms/step - loss: 1.3870 - accuracy: 0.1888 - val_loss: 1.3826 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "17/17 [==============================] - 2s 124ms/step - loss: 1.3874 - accuracy: 0.1864 - val_loss: 1.3826 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "17/17 [==============================] - 2s 124ms/step - loss: 1.3871 - accuracy: 0.1995 - val_loss: 1.3826 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "17/17 [==============================] - 2s 125ms/step - loss: 1.3882 - accuracy: 0.1657 - val_loss: 1.3826 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "17/17 [==============================] - 2s 128ms/step - loss: 1.3889 - accuracy: 0.1763 - val_loss: 1.3826 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "17/17 [==============================] - 2s 125ms/step - loss: 1.3879 - accuracy: 0.1916 - val_loss: 1.3826 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "17/17 [==============================] - 2s 124ms/step - loss: 1.3899 - accuracy: 0.1727 - val_loss: 1.3826 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "17/17 [==============================] - 2s 125ms/step - loss: 1.3893 - accuracy: 0.1771 - val_loss: 1.3826 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "17/17 [==============================] - 2s 125ms/step - loss: 1.3885 - accuracy: 0.1954 - val_loss: 1.3826 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "17/17 [==============================] - 2s 125ms/step - loss: 1.3887 - accuracy: 0.1888 - val_loss: 1.3826 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "17/17 [==============================] - 2s 125ms/step - loss: 1.3893 - accuracy: 0.1836 - val_loss: 1.3826 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "17/17 [==============================] - 2s 125ms/step - loss: 1.3880 - accuracy: 0.1882 - val_loss: 1.3826 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "17/17 [==============================] - 2s 126ms/step - loss: 1.3888 - accuracy: 0.1715 - val_loss: 1.3826 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "17/17 [==============================] - 2s 125ms/step - loss: 1.3899 - accuracy: 0.1681 - val_loss: 1.3826 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../xception/xception_30epochs_834.84_images_False_newWeights_True_lastLayerOnly/assets\n",
      "Test acc for xception: 0.251033\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training resnet for 0.01% of train size (aka 834 images)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      " 6/17 [=========>....................] - ETA: 5s - loss: 1.3889 - accuracy: 0.2242WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0572s vs `on_train_batch_begin` time: 0.2114s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0572s vs `on_train_batch_end` time: 0.1520s). Check your callbacks.\n",
      "17/17 [==============================] - 9s 326ms/step - loss: 1.3875 - accuracy: 0.2376 - val_loss: 1.3850 - val_accuracy: 0.1875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.3864 - accuracy: 0.2337 - val_loss: 1.3850 - val_accuracy: 0.1875\n",
      "Epoch 3/30\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.3868 - accuracy: 0.2448 - val_loss: 1.3850 - val_accuracy: 0.1875\n",
      "Epoch 4/30\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.3867 - accuracy: 0.2308 - val_loss: 1.3850 - val_accuracy: 0.1875\n",
      "Epoch 5/30\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.3863 - accuracy: 0.2466 - val_loss: 1.3850 - val_accuracy: 0.1875\n",
      "Epoch 6/30\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.3871 - accuracy: 0.2380 - val_loss: 1.3850 - val_accuracy: 0.1875\n",
      "Epoch 7/30\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.3873 - accuracy: 0.2267 - val_loss: 1.3850 - val_accuracy: 0.1875\n",
      "Epoch 8/30\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.3869 - accuracy: 0.2320 - val_loss: 1.3850 - val_accuracy: 0.1875\n",
      "Epoch 9/30\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.3865 - accuracy: 0.2485 - val_loss: 1.3850 - val_accuracy: 0.1875\n",
      "Epoch 10/30\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.3864 - accuracy: 0.2379 - val_loss: 1.3850 - val_accuracy: 0.1875\n",
      "Epoch 11/30\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.3866 - accuracy: 0.2483 - val_loss: 1.3850 - val_accuracy: 0.1875\n",
      "Epoch 12/30\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.3868 - accuracy: 0.2387 - val_loss: 1.3850 - val_accuracy: 0.1875\n",
      "Epoch 13/30\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.3866 - accuracy: 0.2480 - val_loss: 1.3850 - val_accuracy: 0.1875\n",
      "Epoch 14/30\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.3873 - accuracy: 0.2217 - val_loss: 1.3850 - val_accuracy: 0.1875\n",
      "Epoch 15/30\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.3866 - accuracy: 0.2418 - val_loss: 1.3850 - val_accuracy: 0.1875\n",
      "Epoch 16/30\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.3869 - accuracy: 0.2221 - val_loss: 1.3850 - val_accuracy: 0.1875\n",
      "Epoch 17/30\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.3867 - accuracy: 0.2542 - val_loss: 1.3850 - val_accuracy: 0.1875\n",
      "Epoch 18/30\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.3861 - accuracy: 0.2554 - val_loss: 1.3850 - val_accuracy: 0.1875\n",
      "Epoch 19/30\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.3875 - accuracy: 0.2182 - val_loss: 1.3850 - val_accuracy: 0.1875\n",
      "Epoch 20/30\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.3868 - accuracy: 0.2367 - val_loss: 1.3850 - val_accuracy: 0.1875\n",
      "Epoch 21/30\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.3872 - accuracy: 0.2344 - val_loss: 1.3850 - val_accuracy: 0.1875\n",
      "Epoch 22/30\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.3873 - accuracy: 0.2058 - val_loss: 1.3850 - val_accuracy: 0.1875\n",
      "Epoch 23/30\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.3859 - accuracy: 0.2701 - val_loss: 1.3850 - val_accuracy: 0.1875\n",
      "Epoch 24/30\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.3869 - accuracy: 0.2313 - val_loss: 1.3850 - val_accuracy: 0.1875\n",
      "Epoch 25/30\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.3870 - accuracy: 0.2232 - val_loss: 1.3850 - val_accuracy: 0.1875\n",
      "Epoch 26/30\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.3866 - accuracy: 0.2377 - val_loss: 1.3850 - val_accuracy: 0.1875\n",
      "Epoch 27/30\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.3867 - accuracy: 0.2389 - val_loss: 1.3850 - val_accuracy: 0.1875\n",
      "Epoch 28/30\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.3860 - accuracy: 0.2601 - val_loss: 1.3850 - val_accuracy: 0.1875\n",
      "Epoch 29/30\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.3870 - accuracy: 0.2279 - val_loss: 1.3850 - val_accuracy: 0.1875\n",
      "Epoch 30/30\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.3875 - accuracy: 0.2125 - val_loss: 1.3850 - val_accuracy: 0.1875\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_834.84_images_False_newWeights_True_lastLayerOnly/assets\n",
      "Test acc for resnet: 0.221074\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training opticnet for 0.01% of train size (aka 834 images)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "17/17 [==============================] - 20s 734ms/step - loss: 284.7919 - accuracy: 0.1530 - val_loss: 217.3077 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "17/17 [==============================] - 5s 294ms/step - loss: 279.5061 - accuracy: 0.1525 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "17/17 [==============================] - 5s 295ms/step - loss: 285.5307 - accuracy: 0.1671 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "17/17 [==============================] - 5s 295ms/step - loss: 290.4244 - accuracy: 0.1400 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "17/17 [==============================] - 5s 295ms/step - loss: 287.1135 - accuracy: 0.1528 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "17/17 [==============================] - 5s 295ms/step - loss: 287.6987 - accuracy: 0.1412 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "17/17 [==============================] - 5s 295ms/step - loss: 283.0473 - accuracy: 0.1615 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "17/17 [==============================] - 5s 296ms/step - loss: 291.0477 - accuracy: 0.1419 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "17/17 [==============================] - 5s 296ms/step - loss: 289.5861 - accuracy: 0.1361 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "17/17 [==============================] - 5s 296ms/step - loss: 286.2549 - accuracy: 0.1355 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "17/17 [==============================] - 5s 297ms/step - loss: 290.3973 - accuracy: 0.1482 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "17/17 [==============================] - 5s 296ms/step - loss: 295.1013 - accuracy: 0.1434 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "17/17 [==============================] - 5s 296ms/step - loss: 288.4462 - accuracy: 0.1392 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "17/17 [==============================] - 5s 296ms/step - loss: 284.7074 - accuracy: 0.1514 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "17/17 [==============================] - 5s 296ms/step - loss: 278.4635 - accuracy: 0.1654 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "17/17 [==============================] - 5s 296ms/step - loss: 290.2042 - accuracy: 0.1463 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "17/17 [==============================] - 5s 296ms/step - loss: 291.4060 - accuracy: 0.1273 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "17/17 [==============================] - 5s 297ms/step - loss: 287.8406 - accuracy: 0.1515 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "17/17 [==============================] - 5s 296ms/step - loss: 288.9457 - accuracy: 0.1475 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "17/17 [==============================] - 5s 296ms/step - loss: 277.6278 - accuracy: 0.1537 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "17/17 [==============================] - 5s 298ms/step - loss: 284.9795 - accuracy: 0.1441 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "17/17 [==============================] - 5s 297ms/step - loss: 282.1701 - accuracy: 0.1628 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "17/17 [==============================] - 5s 297ms/step - loss: 285.6018 - accuracy: 0.1455 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "17/17 [==============================] - 5s 297ms/step - loss: 283.1584 - accuracy: 0.1528 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "17/17 [==============================] - 5s 297ms/step - loss: 295.0348 - accuracy: 0.1440 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "17/17 [==============================] - 5s 296ms/step - loss: 291.8971 - accuracy: 0.1374 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "17/17 [==============================] - 5s 297ms/step - loss: 278.3876 - accuracy: 0.1548 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "17/17 [==============================] - 5s 296ms/step - loss: 291.8558 - accuracy: 0.1436 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "17/17 [==============================] - 5s 296ms/step - loss: 281.4468 - accuracy: 0.1400 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "17/17 [==============================] - 5s 296ms/step - loss: 280.6705 - accuracy: 0.1473 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../opticnet/opticnet_30epochs_834.84_images_False_newWeights_True_lastLayerOnly/assets\n",
      "Test acc for opticnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.02485275 0.02486225 0.02511456 0.02588208]\n",
      "Training xception for 0.025% of train size (aka 2087 images)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      " 6/42 [===>..........................] - ETA: 21s - loss: 1.4067 - accuracy: 0.1938WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1224s vs `on_train_batch_begin` time: 0.2017s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1224s vs `on_train_batch_end` time: 0.2046s). Check your callbacks.\n",
      "42/42 [==============================] - 12s 224ms/step - loss: 1.4091 - accuracy: 0.1604 - val_loss: 1.3917 - val_accuracy: 0.2812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "42/42 [==============================] - 5s 122ms/step - loss: 1.4082 - accuracy: 0.1672 - val_loss: 1.3917 - val_accuracy: 0.2812\n",
      "Epoch 3/30\n",
      "42/42 [==============================] - 5s 122ms/step - loss: 1.4084 - accuracy: 0.1678 - val_loss: 1.3917 - val_accuracy: 0.2812\n",
      "Epoch 4/30\n",
      "42/42 [==============================] - 5s 122ms/step - loss: 1.4074 - accuracy: 0.1662 - val_loss: 1.3917 - val_accuracy: 0.2812\n",
      "Epoch 5/30\n",
      "42/42 [==============================] - 5s 123ms/step - loss: 1.4104 - accuracy: 0.1595 - val_loss: 1.3917 - val_accuracy: 0.2812\n",
      "Epoch 6/30\n",
      "42/42 [==============================] - 5s 124ms/step - loss: 1.4088 - accuracy: 0.1601 - val_loss: 1.3917 - val_accuracy: 0.2812\n",
      "Epoch 7/30\n",
      "42/42 [==============================] - 5s 124ms/step - loss: 1.4082 - accuracy: 0.1637 - val_loss: 1.3917 - val_accuracy: 0.2812\n",
      "Epoch 8/30\n",
      "42/42 [==============================] - 5s 124ms/step - loss: 1.4089 - accuracy: 0.1638 - val_loss: 1.3917 - val_accuracy: 0.2812\n",
      "Epoch 9/30\n",
      "42/42 [==============================] - 5s 124ms/step - loss: 1.4101 - accuracy: 0.1471 - val_loss: 1.3917 - val_accuracy: 0.2812\n",
      "Epoch 10/30\n",
      "42/42 [==============================] - 5s 124ms/step - loss: 1.4074 - accuracy: 0.1704 - val_loss: 1.3917 - val_accuracy: 0.2812\n",
      "Epoch 11/30\n",
      "42/42 [==============================] - 5s 125ms/step - loss: 1.4102 - accuracy: 0.1628 - val_loss: 1.3917 - val_accuracy: 0.2812\n",
      "Epoch 12/30\n",
      "42/42 [==============================] - 5s 124ms/step - loss: 1.4094 - accuracy: 0.1533 - val_loss: 1.3917 - val_accuracy: 0.2812\n",
      "Epoch 13/30\n",
      "42/42 [==============================] - 5s 124ms/step - loss: 1.4106 - accuracy: 0.1542 - val_loss: 1.3917 - val_accuracy: 0.2812\n",
      "Epoch 14/30\n",
      "42/42 [==============================] - 5s 124ms/step - loss: 1.4105 - accuracy: 0.1456 - val_loss: 1.3917 - val_accuracy: 0.2812\n",
      "Epoch 15/30\n",
      "42/42 [==============================] - 5s 124ms/step - loss: 1.4106 - accuracy: 0.1485 - val_loss: 1.3917 - val_accuracy: 0.2812\n",
      "Epoch 16/30\n",
      "42/42 [==============================] - 5s 124ms/step - loss: 1.4092 - accuracy: 0.1662 - val_loss: 1.3917 - val_accuracy: 0.2812\n",
      "Epoch 17/30\n",
      "42/42 [==============================] - 5s 124ms/step - loss: 1.4082 - accuracy: 0.1733 - val_loss: 1.3917 - val_accuracy: 0.2812\n",
      "Epoch 18/30\n",
      "42/42 [==============================] - 5s 124ms/step - loss: 1.4096 - accuracy: 0.1539 - val_loss: 1.3917 - val_accuracy: 0.2812\n",
      "Epoch 19/30\n",
      "42/42 [==============================] - 5s 124ms/step - loss: 1.4088 - accuracy: 0.1691 - val_loss: 1.3917 - val_accuracy: 0.2812\n",
      "Epoch 20/30\n",
      "42/42 [==============================] - 5s 124ms/step - loss: 1.4087 - accuracy: 0.1653 - val_loss: 1.3917 - val_accuracy: 0.2812\n",
      "Epoch 21/30\n",
      "42/42 [==============================] - 5s 125ms/step - loss: 1.4088 - accuracy: 0.1632 - val_loss: 1.3917 - val_accuracy: 0.2812\n",
      "Epoch 22/30\n",
      "42/42 [==============================] - 5s 124ms/step - loss: 1.4092 - accuracy: 0.1623 - val_loss: 1.3917 - val_accuracy: 0.2812\n",
      "Epoch 23/30\n",
      "42/42 [==============================] - 5s 124ms/step - loss: 1.4085 - accuracy: 0.1640 - val_loss: 1.3917 - val_accuracy: 0.2812\n",
      "Epoch 24/30\n",
      "42/42 [==============================] - 5s 124ms/step - loss: 1.4083 - accuracy: 0.1634 - val_loss: 1.3917 - val_accuracy: 0.2812\n",
      "Epoch 25/30\n",
      "42/42 [==============================] - 5s 126ms/step - loss: 1.4093 - accuracy: 0.1622 - val_loss: 1.3917 - val_accuracy: 0.2812\n",
      "Epoch 26/30\n",
      "42/42 [==============================] - 5s 124ms/step - loss: 1.4094 - accuracy: 0.1541 - val_loss: 1.3917 - val_accuracy: 0.2812\n",
      "Epoch 27/30\n",
      "42/42 [==============================] - 5s 124ms/step - loss: 1.4099 - accuracy: 0.1575 - val_loss: 1.3917 - val_accuracy: 0.2812\n",
      "Epoch 28/30\n",
      "42/42 [==============================] - 5s 124ms/step - loss: 1.4098 - accuracy: 0.1595 - val_loss: 1.3917 - val_accuracy: 0.2812\n",
      "Epoch 29/30\n",
      "42/42 [==============================] - 5s 124ms/step - loss: 1.4091 - accuracy: 0.1630 - val_loss: 1.3917 - val_accuracy: 0.2812\n",
      "Epoch 30/30\n",
      "42/42 [==============================] - 5s 124ms/step - loss: 1.4101 - accuracy: 0.1581 - val_loss: 1.3917 - val_accuracy: 0.2812\n",
      "INFO:tensorflow:Assets written to: ../xception/xception_30epochs_2087.1_images_False_newWeights_True_lastLayerOnly/assets\n",
      "Test acc for xception: 0.259298\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training resnet for 0.025% of train size (aka 2087 images)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      " 6/42 [===>..........................] - ETA: 17s - loss: 1.3847 - accuracy: 0.2411WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0599s vs `on_train_batch_begin` time: 0.1975s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0599s vs `on_train_batch_end` time: 0.1593s). Check your callbacks.\n",
      "42/42 [==============================] - 10s 154ms/step - loss: 1.3829 - accuracy: 0.2232 - val_loss: 1.3842 - val_accuracy: 0.2188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "42/42 [==============================] - 2s 58ms/step - loss: 1.3822 - accuracy: 0.2159 - val_loss: 1.3842 - val_accuracy: 0.2188\n",
      "Epoch 3/30\n",
      "42/42 [==============================] - 2s 58ms/step - loss: 1.3827 - accuracy: 0.2029 - val_loss: 1.3842 - val_accuracy: 0.2188\n",
      "Epoch 4/30\n",
      "42/42 [==============================] - 2s 58ms/step - loss: 1.3826 - accuracy: 0.2118 - val_loss: 1.3842 - val_accuracy: 0.2188\n",
      "Epoch 5/30\n",
      "42/42 [==============================] - 2s 58ms/step - loss: 1.3823 - accuracy: 0.2094 - val_loss: 1.3842 - val_accuracy: 0.2188\n",
      "Epoch 6/30\n",
      "42/42 [==============================] - 2s 58ms/step - loss: 1.3834 - accuracy: 0.2071 - val_loss: 1.3842 - val_accuracy: 0.2188\n",
      "Epoch 7/30\n",
      "42/42 [==============================] - 2s 58ms/step - loss: 1.3830 - accuracy: 0.2176 - val_loss: 1.3842 - val_accuracy: 0.2188\n",
      "Epoch 8/30\n",
      "42/42 [==============================] - 2s 59ms/step - loss: 1.3834 - accuracy: 0.2054 - val_loss: 1.3842 - val_accuracy: 0.2188\n",
      "Epoch 9/30\n",
      "42/42 [==============================] - 2s 58ms/step - loss: 1.3827 - accuracy: 0.2176 - val_loss: 1.3842 - val_accuracy: 0.2188\n",
      "Epoch 10/30\n",
      "42/42 [==============================] - 2s 58ms/step - loss: 1.3826 - accuracy: 0.2037 - val_loss: 1.3842 - val_accuracy: 0.2188\n",
      "Epoch 11/30\n",
      "42/42 [==============================] - 2s 58ms/step - loss: 1.3822 - accuracy: 0.2196 - val_loss: 1.3842 - val_accuracy: 0.2188\n",
      "Epoch 12/30\n",
      "42/42 [==============================] - 2s 58ms/step - loss: 1.3821 - accuracy: 0.2164 - val_loss: 1.3842 - val_accuracy: 0.2188\n",
      "Epoch 13/30\n",
      "42/42 [==============================] - 2s 58ms/step - loss: 1.3823 - accuracy: 0.2247 - val_loss: 1.3842 - val_accuracy: 0.2188\n",
      "Epoch 14/30\n",
      "42/42 [==============================] - 2s 58ms/step - loss: 1.3826 - accuracy: 0.1991 - val_loss: 1.3842 - val_accuracy: 0.2188\n",
      "Epoch 15/30\n",
      "42/42 [==============================] - 2s 59ms/step - loss: 1.3828 - accuracy: 0.2098 - val_loss: 1.3842 - val_accuracy: 0.2188\n",
      "Epoch 16/30\n",
      "42/42 [==============================] - 2s 58ms/step - loss: 1.3828 - accuracy: 0.2152 - val_loss: 1.3842 - val_accuracy: 0.2188\n",
      "Epoch 17/30\n",
      "42/42 [==============================] - 2s 58ms/step - loss: 1.3837 - accuracy: 0.2010 - val_loss: 1.3842 - val_accuracy: 0.2188\n",
      "Epoch 18/30\n",
      "42/42 [==============================] - 2s 58ms/step - loss: 1.3834 - accuracy: 0.2082 - val_loss: 1.3842 - val_accuracy: 0.2188\n",
      "Epoch 19/30\n",
      "42/42 [==============================] - 2s 58ms/step - loss: 1.3825 - accuracy: 0.2126 - val_loss: 1.3842 - val_accuracy: 0.2188\n",
      "Epoch 20/30\n",
      "42/42 [==============================] - 2s 58ms/step - loss: 1.3831 - accuracy: 0.2066 - val_loss: 1.3842 - val_accuracy: 0.2188\n",
      "Epoch 21/30\n",
      "42/42 [==============================] - 2s 58ms/step - loss: 1.3827 - accuracy: 0.2155 - val_loss: 1.3842 - val_accuracy: 0.2188\n",
      "Epoch 22/30\n",
      "42/42 [==============================] - 2s 58ms/step - loss: 1.3836 - accuracy: 0.2099 - val_loss: 1.3842 - val_accuracy: 0.2188\n",
      "Epoch 23/30\n",
      "42/42 [==============================] - 2s 58ms/step - loss: 1.3823 - accuracy: 0.2157 - val_loss: 1.3842 - val_accuracy: 0.2188\n",
      "Epoch 24/30\n",
      "42/42 [==============================] - 2s 58ms/step - loss: 1.3830 - accuracy: 0.2129 - val_loss: 1.3842 - val_accuracy: 0.2188\n",
      "Epoch 25/30\n",
      "42/42 [==============================] - 2s 58ms/step - loss: 1.3822 - accuracy: 0.2074 - val_loss: 1.3842 - val_accuracy: 0.2188\n",
      "Epoch 26/30\n",
      "42/42 [==============================] - 2s 58ms/step - loss: 1.3829 - accuracy: 0.2120 - val_loss: 1.3842 - val_accuracy: 0.2188\n",
      "Epoch 27/30\n",
      "42/42 [==============================] - 2s 58ms/step - loss: 1.3824 - accuracy: 0.2223 - val_loss: 1.3842 - val_accuracy: 0.2188\n",
      "Epoch 28/30\n",
      "42/42 [==============================] - 2s 59ms/step - loss: 1.3836 - accuracy: 0.2117 - val_loss: 1.3842 - val_accuracy: 0.2188\n",
      "Epoch 29/30\n",
      "42/42 [==============================] - 2s 58ms/step - loss: 1.3828 - accuracy: 0.2126 - val_loss: 1.3842 - val_accuracy: 0.2188\n",
      "Epoch 30/30\n",
      "42/42 [==============================] - 2s 58ms/step - loss: 1.3822 - accuracy: 0.2204 - val_loss: 1.3842 - val_accuracy: 0.2188\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_2087.1_images_False_newWeights_True_lastLayerOnly/assets\n",
      "Test acc for resnet: 0.239669\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training opticnet for 0.025% of train size (aka 2087 images)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "42/42 [==============================] - 26s 459ms/step - loss: 285.3924 - accuracy: 0.1332 - val_loss: 217.3077 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "42/42 [==============================] - 12s 291ms/step - loss: 297.9843 - accuracy: 0.1178 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "42/42 [==============================] - 12s 291ms/step - loss: 284.5208 - accuracy: 0.1365 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "42/42 [==============================] - 12s 292ms/step - loss: 286.5735 - accuracy: 0.1414 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "42/42 [==============================] - 12s 292ms/step - loss: 285.1623 - accuracy: 0.1435 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "42/42 [==============================] - 12s 292ms/step - loss: 281.0337 - accuracy: 0.1396 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "42/42 [==============================] - 12s 292ms/step - loss: 285.7957 - accuracy: 0.1319 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "42/42 [==============================] - 12s 293ms/step - loss: 289.7751 - accuracy: 0.1302 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "42/42 [==============================] - 12s 293ms/step - loss: 288.3655 - accuracy: 0.1343 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "42/42 [==============================] - 12s 293ms/step - loss: 287.7688 - accuracy: 0.1471 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "42/42 [==============================] - 12s 293ms/step - loss: 285.6597 - accuracy: 0.1374 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "42/42 [==============================] - 12s 293ms/step - loss: 285.1234 - accuracy: 0.1441 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "42/42 [==============================] - 12s 293ms/step - loss: 282.7102 - accuracy: 0.1471 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "42/42 [==============================] - 12s 293ms/step - loss: 287.0097 - accuracy: 0.1424 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "42/42 [==============================] - 12s 293ms/step - loss: 290.7865 - accuracy: 0.1219 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "42/42 [==============================] - 12s 293ms/step - loss: 285.3886 - accuracy: 0.1384 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "42/42 [==============================] - 12s 292ms/step - loss: 288.4110 - accuracy: 0.1226 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "42/42 [==============================] - 12s 293ms/step - loss: 286.2952 - accuracy: 0.1278 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "42/42 [==============================] - 12s 293ms/step - loss: 284.1674 - accuracy: 0.1481 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "42/42 [==============================] - 12s 292ms/step - loss: 283.9156 - accuracy: 0.1445 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "42/42 [==============================] - 12s 292ms/step - loss: 282.7204 - accuracy: 0.1386 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "42/42 [==============================] - 12s 293ms/step - loss: 288.1435 - accuracy: 0.1325 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "42/42 [==============================] - 12s 292ms/step - loss: 281.1030 - accuracy: 0.1465 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "42/42 [==============================] - 12s 292ms/step - loss: 289.4050 - accuracy: 0.1360 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "42/42 [==============================] - 12s 292ms/step - loss: 285.9628 - accuracy: 0.1280 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "42/42 [==============================] - 12s 292ms/step - loss: 283.2423 - accuracy: 0.1429 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "42/42 [==============================] - 12s 292ms/step - loss: 282.5304 - accuracy: 0.1423 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "42/42 [==============================] - 12s 292ms/step - loss: 286.0180 - accuracy: 0.1372 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "42/42 [==============================] - 12s 292ms/step - loss: 287.7100 - accuracy: 0.1307 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "42/42 [==============================] - 12s 292ms/step - loss: 286.7875 - accuracy: 0.1468 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../opticnet/opticnet_30epochs_2087.1_images_False_newWeights_True_lastLayerOnly/assets\n",
      "Test acc for opticnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.04905947 0.05004704 0.05049348 0.05199629]\n",
      "Training xception for 0.05% of train size (aka 4174 images)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      " 6/84 [=>............................] - ETA: 47s - loss: 1.3869 - accuracy: 0.1616WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1208s vs `on_train_batch_begin` time: 0.2167s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1208s vs `on_train_batch_end` time: 0.1920s). Check your callbacks.\n",
      "84/84 [==============================] - 17s 171ms/step - loss: 1.3873 - accuracy: 0.1584 - val_loss: 1.3869 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "84/84 [==============================] - 10s 122ms/step - loss: 1.3876 - accuracy: 0.1421 - val_loss: 1.3869 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "84/84 [==============================] - 10s 123ms/step - loss: 1.3877 - accuracy: 0.1532 - val_loss: 1.3869 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "84/84 [==============================] - 10s 123ms/step - loss: 1.3872 - accuracy: 0.1665 - val_loss: 1.3869 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "84/84 [==============================] - 10s 123ms/step - loss: 1.3868 - accuracy: 0.1619 - val_loss: 1.3869 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "84/84 [==============================] - 10s 123ms/step - loss: 1.3871 - accuracy: 0.1625 - val_loss: 1.3869 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "84/84 [==============================] - 10s 123ms/step - loss: 1.3875 - accuracy: 0.1466 - val_loss: 1.3869 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "84/84 [==============================] - 10s 124ms/step - loss: 1.3873 - accuracy: 0.1484 - val_loss: 1.3869 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "84/84 [==============================] - 10s 123ms/step - loss: 1.3869 - accuracy: 0.1630 - val_loss: 1.3869 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "84/84 [==============================] - 10s 123ms/step - loss: 1.3877 - accuracy: 0.1588 - val_loss: 1.3869 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "84/84 [==============================] - 10s 124ms/step - loss: 1.3873 - accuracy: 0.1637 - val_loss: 1.3869 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "84/84 [==============================] - 10s 124ms/step - loss: 1.3868 - accuracy: 0.1632 - val_loss: 1.3869 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "84/84 [==============================] - 10s 124ms/step - loss: 1.3867 - accuracy: 0.1619 - val_loss: 1.3869 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "84/84 [==============================] - 10s 124ms/step - loss: 1.3869 - accuracy: 0.1678 - val_loss: 1.3869 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "84/84 [==============================] - 10s 124ms/step - loss: 1.3871 - accuracy: 0.1651 - val_loss: 1.3869 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "84/84 [==============================] - 10s 124ms/step - loss: 1.3868 - accuracy: 0.1612 - val_loss: 1.3869 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "84/84 [==============================] - 10s 124ms/step - loss: 1.3875 - accuracy: 0.1458 - val_loss: 1.3869 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "84/84 [==============================] - 10s 124ms/step - loss: 1.3873 - accuracy: 0.1571 - val_loss: 1.3869 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "84/84 [==============================] - 10s 124ms/step - loss: 1.3870 - accuracy: 0.1496 - val_loss: 1.3869 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "84/84 [==============================] - 10s 124ms/step - loss: 1.3872 - accuracy: 0.1546 - val_loss: 1.3869 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "84/84 [==============================] - 10s 124ms/step - loss: 1.3871 - accuracy: 0.1572 - val_loss: 1.3869 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "84/84 [==============================] - 10s 124ms/step - loss: 1.3868 - accuracy: 0.1624 - val_loss: 1.3869 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "84/84 [==============================] - 10s 124ms/step - loss: 1.3872 - accuracy: 0.1601 - val_loss: 1.3869 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "84/84 [==============================] - 10s 124ms/step - loss: 1.3871 - accuracy: 0.1583 - val_loss: 1.3869 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "84/84 [==============================] - 10s 124ms/step - loss: 1.3873 - accuracy: 0.1589 - val_loss: 1.3869 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "84/84 [==============================] - 10s 124ms/step - loss: 1.3874 - accuracy: 0.1532 - val_loss: 1.3869 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "84/84 [==============================] - 10s 124ms/step - loss: 1.3873 - accuracy: 0.1531 - val_loss: 1.3869 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "84/84 [==============================] - 10s 124ms/step - loss: 1.3871 - accuracy: 0.1569 - val_loss: 1.3869 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "84/84 [==============================] - 10s 124ms/step - loss: 1.3874 - accuracy: 0.1520 - val_loss: 1.3869 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "84/84 [==============================] - 10s 124ms/step - loss: 1.3873 - accuracy: 0.1585 - val_loss: 1.3869 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../xception/xception_30epochs_4174.2_images_False_newWeights_True_lastLayerOnly/assets\n",
      "Test acc for xception: 0.253099\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training resnet for 0.05% of train size (aka 4174 images)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      " 6/84 [=>............................] - ETA: 42s - loss: 1.3846 - accuracy: 0.3289WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0612s vs `on_train_batch_begin` time: 0.2438s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0612s vs `on_train_batch_end` time: 0.1619s). Check your callbacks.\n",
      "84/84 [==============================] - 13s 108ms/step - loss: 1.3852 - accuracy: 0.3055 - val_loss: 1.3890 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "84/84 [==============================] - 5s 57ms/step - loss: 1.3850 - accuracy: 0.3049 - val_loss: 1.3890 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "84/84 [==============================] - 5s 58ms/step - loss: 1.3855 - accuracy: 0.2970 - val_loss: 1.3890 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "84/84 [==============================] - 5s 58ms/step - loss: 1.3856 - accuracy: 0.2966 - val_loss: 1.3890 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "84/84 [==============================] - 5s 58ms/step - loss: 1.3857 - accuracy: 0.2983 - val_loss: 1.3890 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "84/84 [==============================] - 5s 58ms/step - loss: 1.3857 - accuracy: 0.3058 - val_loss: 1.3890 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "84/84 [==============================] - 5s 57ms/step - loss: 1.3852 - accuracy: 0.2907 - val_loss: 1.3890 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "84/84 [==============================] - 5s 58ms/step - loss: 1.3853 - accuracy: 0.3009 - val_loss: 1.3890 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "84/84 [==============================] - 5s 58ms/step - loss: 1.3854 - accuracy: 0.3031 - val_loss: 1.3890 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "84/84 [==============================] - 5s 58ms/step - loss: 1.3855 - accuracy: 0.3030 - val_loss: 1.3890 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "84/84 [==============================] - 5s 57ms/step - loss: 1.3853 - accuracy: 0.3001 - val_loss: 1.3890 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "84/84 [==============================] - 5s 58ms/step - loss: 1.3852 - accuracy: 0.3068 - val_loss: 1.3890 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "84/84 [==============================] - 5s 58ms/step - loss: 1.3856 - accuracy: 0.2884 - val_loss: 1.3890 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "84/84 [==============================] - 5s 58ms/step - loss: 1.3854 - accuracy: 0.3043 - val_loss: 1.3890 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "84/84 [==============================] - 5s 58ms/step - loss: 1.3856 - accuracy: 0.2926 - val_loss: 1.3890 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "84/84 [==============================] - 5s 57ms/step - loss: 1.3855 - accuracy: 0.2952 - val_loss: 1.3890 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "84/84 [==============================] - 5s 58ms/step - loss: 1.3854 - accuracy: 0.3046 - val_loss: 1.3890 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "84/84 [==============================] - 5s 58ms/step - loss: 1.3847 - accuracy: 0.3132 - val_loss: 1.3890 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "84/84 [==============================] - 5s 58ms/step - loss: 1.3855 - accuracy: 0.2983 - val_loss: 1.3890 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "84/84 [==============================] - 5s 58ms/step - loss: 1.3853 - accuracy: 0.3049 - val_loss: 1.3890 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "84/84 [==============================] - 5s 58ms/step - loss: 1.3849 - accuracy: 0.3053 - val_loss: 1.3890 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "84/84 [==============================] - 5s 58ms/step - loss: 1.3854 - accuracy: 0.3024 - val_loss: 1.3890 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "84/84 [==============================] - 5s 58ms/step - loss: 1.3852 - accuracy: 0.3030 - val_loss: 1.3890 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "84/84 [==============================] - 5s 58ms/step - loss: 1.3852 - accuracy: 0.3076 - val_loss: 1.3890 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "84/84 [==============================] - 5s 58ms/step - loss: 1.3854 - accuracy: 0.2948 - val_loss: 1.3890 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "84/84 [==============================] - 5s 58ms/step - loss: 1.3855 - accuracy: 0.2949 - val_loss: 1.3890 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "84/84 [==============================] - 5s 58ms/step - loss: 1.3854 - accuracy: 0.2919 - val_loss: 1.3890 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "84/84 [==============================] - 5s 58ms/step - loss: 1.3851 - accuracy: 0.2990 - val_loss: 1.3890 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "84/84 [==============================] - 5s 58ms/step - loss: 1.3855 - accuracy: 0.2992 - val_loss: 1.3890 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "84/84 [==============================] - 5s 58ms/step - loss: 1.3854 - accuracy: 0.3006 - val_loss: 1.3890 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_4174.2_images_False_newWeights_True_lastLayerOnly/assets\n",
      "Test acc for resnet: 0.287190\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training opticnet for 0.05% of train size (aka 4174 images)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "84/84 [==============================] - 37s 357ms/step - loss: 286.6967 - accuracy: 0.1437 - val_loss: 217.3077 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "84/84 [==============================] - 24s 289ms/step - loss: 289.7620 - accuracy: 0.1362 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "84/84 [==============================] - 24s 289ms/step - loss: 289.6078 - accuracy: 0.1358 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "84/84 [==============================] - 24s 289ms/step - loss: 287.7135 - accuracy: 0.1381 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "84/84 [==============================] - 24s 289ms/step - loss: 289.2719 - accuracy: 0.1288 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "84/84 [==============================] - 24s 290ms/step - loss: 288.0476 - accuracy: 0.1393 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "84/84 [==============================] - 24s 290ms/step - loss: 290.4620 - accuracy: 0.1392 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "84/84 [==============================] - 24s 290ms/step - loss: 285.8379 - accuracy: 0.1416 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "84/84 [==============================] - 24s 290ms/step - loss: 284.0973 - accuracy: 0.1444 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "84/84 [==============================] - 24s 290ms/step - loss: 286.9545 - accuracy: 0.1411 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "84/84 [==============================] - 24s 290ms/step - loss: 291.1246 - accuracy: 0.1367 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "84/84 [==============================] - 24s 290ms/step - loss: 288.1909 - accuracy: 0.1381 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "84/84 [==============================] - 24s 290ms/step - loss: 288.2014 - accuracy: 0.1380 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "84/84 [==============================] - 24s 289ms/step - loss: 286.1613 - accuracy: 0.1461 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "84/84 [==============================] - 24s 289ms/step - loss: 289.2019 - accuracy: 0.1366 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "84/84 [==============================] - 24s 289ms/step - loss: 293.2583 - accuracy: 0.1342 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "84/84 [==============================] - 24s 289ms/step - loss: 293.2383 - accuracy: 0.1358 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "84/84 [==============================] - 24s 290ms/step - loss: 291.3679 - accuracy: 0.1361 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "84/84 [==============================] - 24s 290ms/step - loss: 295.6309 - accuracy: 0.1276 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "84/84 [==============================] - 24s 289ms/step - loss: 284.0871 - accuracy: 0.1409 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "84/84 [==============================] - 24s 289ms/step - loss: 289.9121 - accuracy: 0.1335 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "84/84 [==============================] - 24s 290ms/step - loss: 287.1086 - accuracy: 0.1360 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "84/84 [==============================] - 24s 290ms/step - loss: 287.5648 - accuracy: 0.1400 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "84/84 [==============================] - 24s 290ms/step - loss: 289.5041 - accuracy: 0.1294 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "84/84 [==============================] - 24s 290ms/step - loss: 290.5855 - accuracy: 0.1391 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "84/84 [==============================] - 24s 290ms/step - loss: 287.5665 - accuracy: 0.1391 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "84/84 [==============================] - 24s 290ms/step - loss: 291.1292 - accuracy: 0.1324 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "84/84 [==============================] - 24s 290ms/step - loss: 287.2140 - accuracy: 0.1323 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "84/84 [==============================] - 24s 290ms/step - loss: 287.2298 - accuracy: 0.1353 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "84/84 [==============================] - 24s 289ms/step - loss: 291.0256 - accuracy: 0.1417 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../opticnet/opticnet_30epochs_4174.2_images_False_newWeights_True_lastLayerOnly/assets\n",
      "Test acc for opticnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.07474824 0.07533934 0.07472682 0.0746286 ]\n",
      "Training xception for 0.075% of train size (aka 6261 images)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/126 [>.............................] - ETA: 1:06 - loss: 1.3847 - accuracy: 0.2789WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1187s vs `on_train_batch_begin` time: 0.1340s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1187s vs `on_train_batch_end` time: 0.2318s). Check your callbacks.\n",
      "126/126 [==============================] - 22s 150ms/step - loss: 1.3841 - accuracy: 0.3130 - val_loss: 1.3846 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "126/126 [==============================] - 15s 121ms/step - loss: 1.3839 - accuracy: 0.3068 - val_loss: 1.3846 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "126/126 [==============================] - 17s 135ms/step - loss: 1.3835 - accuracy: 0.3227 - val_loss: 1.3846 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "126/126 [==============================] - 15s 123ms/step - loss: 1.3839 - accuracy: 0.3138 - val_loss: 1.3846 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "126/126 [==============================] - 16s 123ms/step - loss: 1.3836 - accuracy: 0.3241 - val_loss: 1.3846 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "126/126 [==============================] - 16s 123ms/step - loss: 1.3836 - accuracy: 0.3202 - val_loss: 1.3846 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "126/126 [==============================] - 16s 123ms/step - loss: 1.3842 - accuracy: 0.3137 - val_loss: 1.3846 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "126/126 [==============================] - 16s 124ms/step - loss: 1.3840 - accuracy: 0.3039 - val_loss: 1.3846 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "126/126 [==============================] - 16s 124ms/step - loss: 1.3843 - accuracy: 0.3113 - val_loss: 1.3846 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "126/126 [==============================] - 16s 124ms/step - loss: 1.3839 - accuracy: 0.3062 - val_loss: 1.3846 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "126/126 [==============================] - 16s 123ms/step - loss: 1.3837 - accuracy: 0.3181 - val_loss: 1.3846 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "126/126 [==============================] - 16s 124ms/step - loss: 1.3841 - accuracy: 0.3133 - val_loss: 1.3846 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "126/126 [==============================] - 16s 124ms/step - loss: 1.3838 - accuracy: 0.3100 - val_loss: 1.3846 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "126/126 [==============================] - 16s 124ms/step - loss: 1.3840 - accuracy: 0.3172 - val_loss: 1.3846 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "126/126 [==============================] - 16s 124ms/step - loss: 1.3835 - accuracy: 0.3289 - val_loss: 1.3846 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "126/126 [==============================] - 16s 124ms/step - loss: 1.3839 - accuracy: 0.3201 - val_loss: 1.3846 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "126/126 [==============================] - 16s 124ms/step - loss: 1.3846 - accuracy: 0.3028 - val_loss: 1.3846 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "126/126 [==============================] - 16s 123ms/step - loss: 1.3841 - accuracy: 0.3123 - val_loss: 1.3846 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "126/126 [==============================] - 16s 123ms/step - loss: 1.3839 - accuracy: 0.3111 - val_loss: 1.3846 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "126/126 [==============================] - 16s 124ms/step - loss: 1.3838 - accuracy: 0.3213 - val_loss: 1.3846 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "126/126 [==============================] - 16s 124ms/step - loss: 1.3839 - accuracy: 0.3177 - val_loss: 1.3846 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "126/126 [==============================] - 16s 123ms/step - loss: 1.3843 - accuracy: 0.3073 - val_loss: 1.3846 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "126/126 [==============================] - 16s 123ms/step - loss: 1.3842 - accuracy: 0.3041 - val_loss: 1.3846 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "126/126 [==============================] - 16s 123ms/step - loss: 1.3839 - accuracy: 0.3202 - val_loss: 1.3846 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "126/126 [==============================] - 16s 124ms/step - loss: 1.3842 - accuracy: 0.3158 - val_loss: 1.3846 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "126/126 [==============================] - 16s 124ms/step - loss: 1.3841 - accuracy: 0.3076 - val_loss: 1.3846 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "126/126 [==============================] - 16s 123ms/step - loss: 1.3842 - accuracy: 0.3057 - val_loss: 1.3846 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "126/126 [==============================] - 16s 123ms/step - loss: 1.3838 - accuracy: 0.3107 - val_loss: 1.3846 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "126/126 [==============================] - 16s 124ms/step - loss: 1.3838 - accuracy: 0.3185 - val_loss: 1.3846 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "126/126 [==============================] - 16s 123ms/step - loss: 1.3839 - accuracy: 0.3141 - val_loss: 1.3846 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../xception/xception_30epochs_6261.3_images_False_newWeights_True_lastLayerOnly/assets\n",
      "Test acc for xception: 0.248967\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training resnet for 0.075% of train size (aka 6261 images)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/126 [>.............................] - ETA: 59s - loss: 1.3922 - accuracy: 0.2259 WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0598s vs `on_train_batch_begin` time: 0.1981s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0598s vs `on_train_batch_end` time: 0.1676s). Check your callbacks.\n",
      "126/126 [==============================] - 15s 89ms/step - loss: 1.3923 - accuracy: 0.1767 - val_loss: 1.3910 - val_accuracy: 0.1562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "126/126 [==============================] - 7s 57ms/step - loss: 1.3920 - accuracy: 0.1752 - val_loss: 1.3910 - val_accuracy: 0.1562\n",
      "Epoch 3/30\n",
      "126/126 [==============================] - 7s 57ms/step - loss: 1.3921 - accuracy: 0.1756 - val_loss: 1.3910 - val_accuracy: 0.1562\n",
      "Epoch 4/30\n",
      "126/126 [==============================] - 7s 57ms/step - loss: 1.3923 - accuracy: 0.1694 - val_loss: 1.3910 - val_accuracy: 0.1562\n",
      "Epoch 5/30\n",
      "126/126 [==============================] - 7s 58ms/step - loss: 1.3921 - accuracy: 0.1741 - val_loss: 1.3910 - val_accuracy: 0.1562\n",
      "Epoch 6/30\n",
      "126/126 [==============================] - 7s 57ms/step - loss: 1.3920 - accuracy: 0.1681 - val_loss: 1.3910 - val_accuracy: 0.1562\n",
      "Epoch 7/30\n",
      "126/126 [==============================] - 7s 58ms/step - loss: 1.3922 - accuracy: 0.1777 - val_loss: 1.3910 - val_accuracy: 0.1562\n",
      "Epoch 8/30\n",
      "126/126 [==============================] - 7s 57ms/step - loss: 1.3923 - accuracy: 0.1706 - val_loss: 1.3910 - val_accuracy: 0.1562\n",
      "Epoch 9/30\n",
      "126/126 [==============================] - 7s 58ms/step - loss: 1.3926 - accuracy: 0.1638 - val_loss: 1.3910 - val_accuracy: 0.1562\n",
      "Epoch 10/30\n",
      "126/126 [==============================] - 7s 58ms/step - loss: 1.3920 - accuracy: 0.1774 - val_loss: 1.3910 - val_accuracy: 0.1562\n",
      "Epoch 11/30\n",
      "126/126 [==============================] - 7s 58ms/step - loss: 1.3921 - accuracy: 0.1771 - val_loss: 1.3910 - val_accuracy: 0.1562\n",
      "Epoch 12/30\n",
      "126/126 [==============================] - 7s 58ms/step - loss: 1.3921 - accuracy: 0.1798 - val_loss: 1.3910 - val_accuracy: 0.1562\n",
      "Epoch 13/30\n",
      "126/126 [==============================] - 7s 58ms/step - loss: 1.3924 - accuracy: 0.1626 - val_loss: 1.3910 - val_accuracy: 0.1562\n",
      "Epoch 14/30\n",
      "126/126 [==============================] - 7s 58ms/step - loss: 1.3923 - accuracy: 0.1732 - val_loss: 1.3910 - val_accuracy: 0.1562\n",
      "Epoch 15/30\n",
      "126/126 [==============================] - 7s 58ms/step - loss: 1.3922 - accuracy: 0.1712 - val_loss: 1.3910 - val_accuracy: 0.1562\n",
      "Epoch 16/30\n",
      "126/126 [==============================] - 7s 58ms/step - loss: 1.3922 - accuracy: 0.1773 - val_loss: 1.3910 - val_accuracy: 0.1562\n",
      "Epoch 17/30\n",
      "126/126 [==============================] - 7s 58ms/step - loss: 1.3923 - accuracy: 0.1690 - val_loss: 1.3910 - val_accuracy: 0.1562\n",
      "Epoch 18/30\n",
      "126/126 [==============================] - 7s 58ms/step - loss: 1.3922 - accuracy: 0.1726 - val_loss: 1.3910 - val_accuracy: 0.1562\n",
      "Epoch 19/30\n",
      "126/126 [==============================] - 7s 58ms/step - loss: 1.3924 - accuracy: 0.1743 - val_loss: 1.3910 - val_accuracy: 0.1562\n",
      "Epoch 20/30\n",
      "126/126 [==============================] - 7s 58ms/step - loss: 1.3923 - accuracy: 0.1722 - val_loss: 1.3910 - val_accuracy: 0.1562\n",
      "Epoch 21/30\n",
      "126/126 [==============================] - 7s 58ms/step - loss: 1.3920 - accuracy: 0.1794 - val_loss: 1.3910 - val_accuracy: 0.1562\n",
      "Epoch 22/30\n",
      "126/126 [==============================] - 7s 58ms/step - loss: 1.3924 - accuracy: 0.1751 - val_loss: 1.3910 - val_accuracy: 0.1562\n",
      "Epoch 23/30\n",
      "126/126 [==============================] - 7s 58ms/step - loss: 1.3920 - accuracy: 0.1762 - val_loss: 1.3910 - val_accuracy: 0.1562\n",
      "Epoch 24/30\n",
      "126/126 [==============================] - 7s 58ms/step - loss: 1.3925 - accuracy: 0.1682 - val_loss: 1.3910 - val_accuracy: 0.1562\n",
      "Epoch 25/30\n",
      "126/126 [==============================] - 7s 58ms/step - loss: 1.3923 - accuracy: 0.1702 - val_loss: 1.3910 - val_accuracy: 0.1562\n",
      "Epoch 26/30\n",
      "126/126 [==============================] - 7s 58ms/step - loss: 1.3925 - accuracy: 0.1716 - val_loss: 1.3910 - val_accuracy: 0.1562\n",
      "Epoch 27/30\n",
      "126/126 [==============================] - 7s 58ms/step - loss: 1.3918 - accuracy: 0.1830 - val_loss: 1.3910 - val_accuracy: 0.1562\n",
      "Epoch 28/30\n",
      "126/126 [==============================] - 7s 58ms/step - loss: 1.3923 - accuracy: 0.1726 - val_loss: 1.3910 - val_accuracy: 0.1562\n",
      "Epoch 29/30\n",
      "126/126 [==============================] - 7s 58ms/step - loss: 1.3925 - accuracy: 0.1661 - val_loss: 1.3910 - val_accuracy: 0.1562\n",
      "Epoch 30/30\n",
      "126/126 [==============================] - 7s 58ms/step - loss: 1.3922 - accuracy: 0.1844 - val_loss: 1.3910 - val_accuracy: 0.1562\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_6261.3_images_False_newWeights_True_lastLayerOnly/assets\n",
      "Test acc for resnet: 0.160124\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training opticnet for 0.075% of train size (aka 6261 images)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "126/126 [==============================] - 48s 332ms/step - loss: 289.0950 - accuracy: 0.1410 - val_loss: 217.3077 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "126/126 [==============================] - 36s 288ms/step - loss: 290.5209 - accuracy: 0.1347 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "126/126 [==============================] - 36s 288ms/step - loss: 292.7171 - accuracy: 0.1343 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "126/126 [==============================] - 36s 289ms/step - loss: 292.3002 - accuracy: 0.1317 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "126/126 [==============================] - 36s 289ms/step - loss: 297.4110 - accuracy: 0.1319 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "126/126 [==============================] - 36s 289ms/step - loss: 295.1907 - accuracy: 0.1322 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "126/126 [==============================] - 36s 289ms/step - loss: 293.5473 - accuracy: 0.1309 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "126/126 [==============================] - 36s 289ms/step - loss: 292.1990 - accuracy: 0.1347 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "126/126 [==============================] - 36s 289ms/step - loss: 288.9411 - accuracy: 0.1370 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "126/126 [==============================] - 36s 289ms/step - loss: 289.4113 - accuracy: 0.1327 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "126/126 [==============================] - 36s 289ms/step - loss: 288.9530 - accuracy: 0.1357 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "126/126 [==============================] - 36s 289ms/step - loss: 295.7741 - accuracy: 0.1241 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "126/126 [==============================] - 36s 289ms/step - loss: 292.3412 - accuracy: 0.1391 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "126/126 [==============================] - 36s 289ms/step - loss: 292.5016 - accuracy: 0.1361 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "126/126 [==============================] - 36s 289ms/step - loss: 291.7391 - accuracy: 0.1354 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "126/126 [==============================] - 36s 289ms/step - loss: 290.0129 - accuracy: 0.1331 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "126/126 [==============================] - 36s 289ms/step - loss: 291.8539 - accuracy: 0.1383 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "126/126 [==============================] - 36s 289ms/step - loss: 289.1201 - accuracy: 0.1334 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "126/126 [==============================] - 36s 289ms/step - loss: 290.3071 - accuracy: 0.1396 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "126/126 [==============================] - 36s 289ms/step - loss: 293.3462 - accuracy: 0.1381 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "126/126 [==============================] - 36s 288ms/step - loss: 291.6317 - accuracy: 0.1338 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "126/126 [==============================] - 36s 289ms/step - loss: 293.7387 - accuracy: 0.1325 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "126/126 [==============================] - 36s 289ms/step - loss: 293.3116 - accuracy: 0.1369 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "126/126 [==============================] - 36s 289ms/step - loss: 289.5492 - accuracy: 0.1367 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "126/126 [==============================] - 36s 289ms/step - loss: 292.1553 - accuracy: 0.1353 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "126/126 [==============================] - 36s 289ms/step - loss: 296.2469 - accuracy: 0.1325 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "126/126 [==============================] - 36s 289ms/step - loss: 286.8725 - accuracy: 0.1423 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "126/126 [==============================] - 36s 289ms/step - loss: 286.5930 - accuracy: 0.1382 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "126/126 [==============================] - 36s 289ms/step - loss: 288.5415 - accuracy: 0.1318 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "126/126 [==============================] - 36s 289ms/step - loss: 292.1636 - accuracy: 0.1349 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../opticnet/opticnet_30epochs_6261.3_images_False_newWeights_True_lastLayerOnly/assets\n",
      "Test acc for opticnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.09029071 0.09041795 0.08909059 0.08844011]\n",
      "Training xception for 0.09% of train size (aka 7513 images)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/151 [>.............................] - ETA: 1:32 - loss: 1.3882 - accuracy: 0.1242WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1194s vs `on_train_batch_begin` time: 0.1953s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1194s vs `on_train_batch_end` time: 0.2372s). Check your callbacks.\n",
      "151/151 [==============================] - 27s 149ms/step - loss: 1.3875 - accuracy: 0.1498 - val_loss: 1.3877 - val_accuracy: 0.2188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "151/151 [==============================] - 18s 122ms/step - loss: 1.3877 - accuracy: 0.1505 - val_loss: 1.3877 - val_accuracy: 0.2188\n",
      "Epoch 3/30\n",
      "151/151 [==============================] - 19s 123ms/step - loss: 1.3873 - accuracy: 0.1552 - val_loss: 1.3877 - val_accuracy: 0.2188\n",
      "Epoch 4/30\n",
      "151/151 [==============================] - 19s 123ms/step - loss: 1.3874 - accuracy: 0.1498 - val_loss: 1.3877 - val_accuracy: 0.2188\n",
      "Epoch 5/30\n",
      "151/151 [==============================] - 19s 124ms/step - loss: 1.3875 - accuracy: 0.1508 - val_loss: 1.3877 - val_accuracy: 0.2188\n",
      "Epoch 6/30\n",
      "151/151 [==============================] - 19s 123ms/step - loss: 1.3879 - accuracy: 0.1462 - val_loss: 1.3877 - val_accuracy: 0.2188\n",
      "Epoch 7/30\n",
      "151/151 [==============================] - 19s 124ms/step - loss: 1.3876 - accuracy: 0.1487 - val_loss: 1.3877 - val_accuracy: 0.2188\n",
      "Epoch 8/30\n",
      "151/151 [==============================] - 19s 124ms/step - loss: 1.3874 - accuracy: 0.1522 - val_loss: 1.3877 - val_accuracy: 0.2188\n",
      "Epoch 9/30\n",
      "151/151 [==============================] - 19s 124ms/step - loss: 1.3876 - accuracy: 0.1481 - val_loss: 1.3877 - val_accuracy: 0.2188\n",
      "Epoch 10/30\n",
      "151/151 [==============================] - 19s 124ms/step - loss: 1.3876 - accuracy: 0.1533 - val_loss: 1.3877 - val_accuracy: 0.2188\n",
      "Epoch 11/30\n",
      "151/151 [==============================] - 19s 124ms/step - loss: 1.3877 - accuracy: 0.1482 - val_loss: 1.3877 - val_accuracy: 0.2188\n",
      "Epoch 12/30\n",
      "151/151 [==============================] - 19s 124ms/step - loss: 1.3873 - accuracy: 0.1546 - val_loss: 1.3877 - val_accuracy: 0.2188\n",
      "Epoch 13/30\n",
      "151/151 [==============================] - 19s 124ms/step - loss: 1.3874 - accuracy: 0.1578 - val_loss: 1.3877 - val_accuracy: 0.2188\n",
      "Epoch 14/30\n",
      "151/151 [==============================] - 19s 124ms/step - loss: 1.3873 - accuracy: 0.1543 - val_loss: 1.3877 - val_accuracy: 0.2188\n",
      "Epoch 15/30\n",
      "151/151 [==============================] - 19s 124ms/step - loss: 1.3875 - accuracy: 0.1459 - val_loss: 1.3877 - val_accuracy: 0.2188\n",
      "Epoch 16/30\n",
      "151/151 [==============================] - 19s 124ms/step - loss: 1.3879 - accuracy: 0.1489 - val_loss: 1.3877 - val_accuracy: 0.2188\n",
      "Epoch 17/30\n",
      "151/151 [==============================] - 19s 124ms/step - loss: 1.3877 - accuracy: 0.1424 - val_loss: 1.3877 - val_accuracy: 0.2188\n",
      "Epoch 18/30\n",
      "151/151 [==============================] - 19s 124ms/step - loss: 1.3876 - accuracy: 0.1435 - val_loss: 1.3877 - val_accuracy: 0.2188\n",
      "Epoch 19/30\n",
      "151/151 [==============================] - 19s 124ms/step - loss: 1.3878 - accuracy: 0.1467 - val_loss: 1.3877 - val_accuracy: 0.2188\n",
      "Epoch 20/30\n",
      "151/151 [==============================] - 19s 123ms/step - loss: 1.3874 - accuracy: 0.1461 - val_loss: 1.3877 - val_accuracy: 0.2188\n",
      "Epoch 21/30\n",
      "151/151 [==============================] - 19s 124ms/step - loss: 1.3870 - accuracy: 0.1557 - val_loss: 1.3877 - val_accuracy: 0.2188\n",
      "Epoch 22/30\n",
      "151/151 [==============================] - 19s 124ms/step - loss: 1.3875 - accuracy: 0.1481 - val_loss: 1.3877 - val_accuracy: 0.2188\n",
      "Epoch 23/30\n",
      "151/151 [==============================] - 19s 124ms/step - loss: 1.3877 - accuracy: 0.1496 - val_loss: 1.3877 - val_accuracy: 0.2188\n",
      "Epoch 24/30\n",
      "151/151 [==============================] - 19s 124ms/step - loss: 1.3871 - accuracy: 0.1527 - val_loss: 1.3877 - val_accuracy: 0.2188\n",
      "Epoch 25/30\n",
      "151/151 [==============================] - 19s 124ms/step - loss: 1.3875 - accuracy: 0.1540 - val_loss: 1.3877 - val_accuracy: 0.2188\n",
      "Epoch 26/30\n",
      "151/151 [==============================] - 19s 124ms/step - loss: 1.3873 - accuracy: 0.1538 - val_loss: 1.3877 - val_accuracy: 0.2188\n",
      "Epoch 27/30\n",
      "151/151 [==============================] - 19s 124ms/step - loss: 1.3879 - accuracy: 0.1504 - val_loss: 1.3877 - val_accuracy: 0.2188\n",
      "Epoch 28/30\n",
      "151/151 [==============================] - 19s 124ms/step - loss: 1.3877 - accuracy: 0.1495 - val_loss: 1.3877 - val_accuracy: 0.2188\n",
      "Epoch 29/30\n",
      "151/151 [==============================] - 19s 124ms/step - loss: 1.3875 - accuracy: 0.1491 - val_loss: 1.3877 - val_accuracy: 0.2188\n",
      "Epoch 30/30\n",
      "151/151 [==============================] - 19s 124ms/step - loss: 1.3877 - accuracy: 0.1456 - val_loss: 1.3877 - val_accuracy: 0.2188\n",
      "INFO:tensorflow:Assets written to: ../xception/xception_30epochs_7513.5599999999995_images_False_newWeights_True_lastLayerOnly/assets\n",
      "Test acc for xception: 0.241736\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training resnet for 0.09% of train size (aka 7513 images)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/151 [>.............................] - ETA: 1:23 - loss: 1.3844 - accuracy: 0.3054WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0609s vs `on_train_batch_begin` time: 0.2240s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0609s vs `on_train_batch_end` time: 0.2079s). Check your callbacks.\n",
      "151/151 [==============================] - 18s 87ms/step - loss: 1.3846 - accuracy: 0.2882 - val_loss: 1.3914 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "151/151 [==============================] - 9s 58ms/step - loss: 1.3848 - accuracy: 0.2789 - val_loss: 1.3914 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "151/151 [==============================] - 9s 58ms/step - loss: 1.3845 - accuracy: 0.2866 - val_loss: 1.3914 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "151/151 [==============================] - 9s 58ms/step - loss: 1.3845 - accuracy: 0.2816 - val_loss: 1.3914 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "151/151 [==============================] - 9s 58ms/step - loss: 1.3846 - accuracy: 0.2738 - val_loss: 1.3914 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "151/151 [==============================] - 9s 58ms/step - loss: 1.3845 - accuracy: 0.2878 - val_loss: 1.3914 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "151/151 [==============================] - 9s 58ms/step - loss: 1.3845 - accuracy: 0.2904 - val_loss: 1.3914 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "151/151 [==============================] - 9s 58ms/step - loss: 1.3844 - accuracy: 0.2904 - val_loss: 1.3914 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "151/151 [==============================] - 9s 58ms/step - loss: 1.3844 - accuracy: 0.2942 - val_loss: 1.3914 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "151/151 [==============================] - 9s 58ms/step - loss: 1.3845 - accuracy: 0.2911 - val_loss: 1.3914 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "151/151 [==============================] - 9s 58ms/step - loss: 1.3846 - accuracy: 0.2924 - val_loss: 1.3914 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "151/151 [==============================] - 9s 58ms/step - loss: 1.3844 - accuracy: 0.2918 - val_loss: 1.3914 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "151/151 [==============================] - 9s 58ms/step - loss: 1.3849 - accuracy: 0.2870 - val_loss: 1.3914 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "151/151 [==============================] - 9s 58ms/step - loss: 1.3845 - accuracy: 0.2941 - val_loss: 1.3914 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "151/151 [==============================] - 9s 58ms/step - loss: 1.3849 - accuracy: 0.2790 - val_loss: 1.3914 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "151/151 [==============================] - 9s 58ms/step - loss: 1.3848 - accuracy: 0.2873 - val_loss: 1.3914 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "151/151 [==============================] - 9s 58ms/step - loss: 1.3846 - accuracy: 0.2890 - val_loss: 1.3914 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "151/151 [==============================] - 9s 58ms/step - loss: 1.3845 - accuracy: 0.2877 - val_loss: 1.3914 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "151/151 [==============================] - 9s 58ms/step - loss: 1.3851 - accuracy: 0.2817 - val_loss: 1.3914 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "151/151 [==============================] - 9s 58ms/step - loss: 1.3844 - accuracy: 0.2885 - val_loss: 1.3914 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "151/151 [==============================] - 9s 58ms/step - loss: 1.3849 - accuracy: 0.2831 - val_loss: 1.3914 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "151/151 [==============================] - 9s 58ms/step - loss: 1.3842 - accuracy: 0.2941 - val_loss: 1.3914 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "151/151 [==============================] - 9s 58ms/step - loss: 1.3843 - accuracy: 0.2922 - val_loss: 1.3914 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "151/151 [==============================] - 9s 58ms/step - loss: 1.3843 - accuracy: 0.2911 - val_loss: 1.3914 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "151/151 [==============================] - 9s 58ms/step - loss: 1.3844 - accuracy: 0.2928 - val_loss: 1.3914 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "151/151 [==============================] - 9s 58ms/step - loss: 1.3847 - accuracy: 0.2893 - val_loss: 1.3914 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "151/151 [==============================] - 9s 58ms/step - loss: 1.3847 - accuracy: 0.2895 - val_loss: 1.3914 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "151/151 [==============================] - 9s 58ms/step - loss: 1.3844 - accuracy: 0.2826 - val_loss: 1.3914 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "151/151 [==============================] - 9s 58ms/step - loss: 1.3842 - accuracy: 0.2930 - val_loss: 1.3914 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "151/151 [==============================] - 9s 58ms/step - loss: 1.3848 - accuracy: 0.2896 - val_loss: 1.3914 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_7513.5599999999995_images_False_newWeights_True_lastLayerOnly/assets\n",
      "Test acc for resnet: 0.232438\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training opticnet for 0.09% of train size (aka 7513 images)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "151/151 [==============================] - 57s 328ms/step - loss: 293.7909 - accuracy: 0.1370 - val_loss: 217.3077 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "151/151 [==============================] - 44s 289ms/step - loss: 292.1991 - accuracy: 0.1379 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "151/151 [==============================] - 44s 289ms/step - loss: 293.8346 - accuracy: 0.1299 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "151/151 [==============================] - 44s 289ms/step - loss: 294.1219 - accuracy: 0.1344 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "151/151 [==============================] - 44s 289ms/step - loss: 293.5089 - accuracy: 0.1351 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "151/151 [==============================] - 44s 289ms/step - loss: 289.9126 - accuracy: 0.1392 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "151/151 [==============================] - 44s 289ms/step - loss: 292.3034 - accuracy: 0.1352 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "151/151 [==============================] - 44s 290ms/step - loss: 290.4237 - accuracy: 0.1310 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "151/151 [==============================] - 44s 289ms/step - loss: 290.7806 - accuracy: 0.1398 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "151/151 [==============================] - 44s 289ms/step - loss: 294.4105 - accuracy: 0.1295 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "151/151 [==============================] - 44s 289ms/step - loss: 293.5157 - accuracy: 0.1331 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "151/151 [==============================] - 44s 289ms/step - loss: 295.7412 - accuracy: 0.1299 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "151/151 [==============================] - 44s 289ms/step - loss: 295.1197 - accuracy: 0.1317 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "151/151 [==============================] - 44s 289ms/step - loss: 291.7769 - accuracy: 0.1307 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "151/151 [==============================] - 44s 290ms/step - loss: 291.5851 - accuracy: 0.1365 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "151/151 [==============================] - 44s 289ms/step - loss: 293.4869 - accuracy: 0.1300 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "151/151 [==============================] - 44s 289ms/step - loss: 292.0911 - accuracy: 0.1385 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "151/151 [==============================] - 44s 289ms/step - loss: 288.4406 - accuracy: 0.1373 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "151/151 [==============================] - 44s 289ms/step - loss: 291.5071 - accuracy: 0.1367 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "151/151 [==============================] - 44s 289ms/step - loss: 291.0987 - accuracy: 0.1383 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "151/151 [==============================] - 44s 289ms/step - loss: 289.4393 - accuracy: 0.1377 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "151/151 [==============================] - 44s 289ms/step - loss: 289.6672 - accuracy: 0.1319 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "151/151 [==============================] - 44s 289ms/step - loss: 293.8080 - accuracy: 0.1298 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "151/151 [==============================] - 44s 289ms/step - loss: 295.4064 - accuracy: 0.1290 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "151/151 [==============================] - 44s 289ms/step - loss: 288.6284 - accuracy: 0.1360 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "151/151 [==============================] - 44s 289ms/step - loss: 293.8517 - accuracy: 0.1388 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "151/151 [==============================] - 44s 289ms/step - loss: 291.9896 - accuracy: 0.1319 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "151/151 [==============================] - 44s 289ms/step - loss: 291.6134 - accuracy: 0.1341 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "151/151 [==============================] - 44s 289ms/step - loss: 292.3112 - accuracy: 0.1382 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "151/151 [==============================] - 44s 289ms/step - loss: 293.3551 - accuracy: 0.1277 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../opticnet/opticnet_30epochs_7513.5599999999995_images_False_newWeights_True_lastLayerOnly/assets\n",
      "Test acc for opticnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.10115903 0.10044349 0.09834332 0.09668059]\n",
      "Training xception for 0.1% of train size (aka 8348 images)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/167 [>.............................] - ETA: 1:37 - loss: 1.3669 - accuracy: 0.4496WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1225s vs `on_train_batch_begin` time: 0.1986s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1225s vs `on_train_batch_end` time: 0.2059s). Check your callbacks.\n",
      "167/167 [==============================] - 28s 148ms/step - loss: 1.3733 - accuracy: 0.4131 - val_loss: 1.3821 - val_accuracy: 0.3125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "167/167 [==============================] - 20s 122ms/step - loss: 1.3741 - accuracy: 0.4105 - val_loss: 1.3821 - val_accuracy: 0.3125\n",
      "Epoch 3/30\n",
      "167/167 [==============================] - 21s 124ms/step - loss: 1.3730 - accuracy: 0.4191 - val_loss: 1.3821 - val_accuracy: 0.3125\n",
      "Epoch 4/30\n",
      "167/167 [==============================] - 21s 124ms/step - loss: 1.3736 - accuracy: 0.4150 - val_loss: 1.3821 - val_accuracy: 0.3125\n",
      "Epoch 5/30\n",
      "167/167 [==============================] - 21s 124ms/step - loss: 1.3734 - accuracy: 0.4128 - val_loss: 1.3821 - val_accuracy: 0.3125\n",
      "Epoch 6/30\n",
      "167/167 [==============================] - 21s 124ms/step - loss: 1.3727 - accuracy: 0.4182 - val_loss: 1.3821 - val_accuracy: 0.3125\n",
      "Epoch 7/30\n",
      "167/167 [==============================] - 21s 124ms/step - loss: 1.3739 - accuracy: 0.4049 - val_loss: 1.3821 - val_accuracy: 0.3125\n",
      "Epoch 8/30\n",
      "167/167 [==============================] - 21s 124ms/step - loss: 1.3737 - accuracy: 0.4126 - val_loss: 1.3821 - val_accuracy: 0.3125\n",
      "Epoch 9/30\n",
      "167/167 [==============================] - 21s 124ms/step - loss: 1.3742 - accuracy: 0.4108 - val_loss: 1.3821 - val_accuracy: 0.3125\n",
      "Epoch 10/30\n",
      "167/167 [==============================] - 21s 124ms/step - loss: 1.3725 - accuracy: 0.4257 - val_loss: 1.3821 - val_accuracy: 0.3125\n",
      "Epoch 11/30\n",
      "167/167 [==============================] - 21s 124ms/step - loss: 1.3733 - accuracy: 0.4130 - val_loss: 1.3821 - val_accuracy: 0.3125\n",
      "Epoch 12/30\n",
      "167/167 [==============================] - 21s 124ms/step - loss: 1.3737 - accuracy: 0.4088 - val_loss: 1.3821 - val_accuracy: 0.3125\n",
      "Epoch 13/30\n",
      "167/167 [==============================] - 21s 124ms/step - loss: 1.3730 - accuracy: 0.4140 - val_loss: 1.3821 - val_accuracy: 0.3125\n",
      "Epoch 14/30\n",
      "167/167 [==============================] - 21s 124ms/step - loss: 1.3739 - accuracy: 0.4129 - val_loss: 1.3821 - val_accuracy: 0.3125\n",
      "Epoch 15/30\n",
      "167/167 [==============================] - 21s 124ms/step - loss: 1.3740 - accuracy: 0.4092 - val_loss: 1.3821 - val_accuracy: 0.3125\n",
      "Epoch 16/30\n",
      "167/167 [==============================] - 21s 124ms/step - loss: 1.3737 - accuracy: 0.4121 - val_loss: 1.3821 - val_accuracy: 0.3125\n",
      "Epoch 17/30\n",
      "167/167 [==============================] - 21s 124ms/step - loss: 1.3741 - accuracy: 0.4095 - val_loss: 1.3821 - val_accuracy: 0.3125\n",
      "Epoch 18/30\n",
      "167/167 [==============================] - 21s 124ms/step - loss: 1.3743 - accuracy: 0.4038 - val_loss: 1.3821 - val_accuracy: 0.3125\n",
      "Epoch 19/30\n",
      "167/167 [==============================] - 21s 124ms/step - loss: 1.3738 - accuracy: 0.4126 - val_loss: 1.3821 - val_accuracy: 0.3125\n",
      "Epoch 20/30\n",
      "167/167 [==============================] - 21s 124ms/step - loss: 1.3735 - accuracy: 0.4115 - val_loss: 1.3821 - val_accuracy: 0.3125\n",
      "Epoch 21/30\n",
      "167/167 [==============================] - 21s 124ms/step - loss: 1.3731 - accuracy: 0.4158 - val_loss: 1.3821 - val_accuracy: 0.3125\n",
      "Epoch 22/30\n",
      "167/167 [==============================] - 21s 124ms/step - loss: 1.3735 - accuracy: 0.4167 - val_loss: 1.3821 - val_accuracy: 0.3125\n",
      "Epoch 23/30\n",
      "167/167 [==============================] - 21s 124ms/step - loss: 1.3733 - accuracy: 0.4141 - val_loss: 1.3821 - val_accuracy: 0.3125\n",
      "Epoch 24/30\n",
      "167/167 [==============================] - 21s 124ms/step - loss: 1.3740 - accuracy: 0.4079 - val_loss: 1.3821 - val_accuracy: 0.3125\n",
      "Epoch 25/30\n",
      "167/167 [==============================] - 21s 124ms/step - loss: 1.3738 - accuracy: 0.4141 - val_loss: 1.3821 - val_accuracy: 0.3125\n",
      "Epoch 26/30\n",
      "167/167 [==============================] - 21s 124ms/step - loss: 1.3732 - accuracy: 0.4152 - val_loss: 1.3821 - val_accuracy: 0.3125\n",
      "Epoch 27/30\n",
      "167/167 [==============================] - 21s 124ms/step - loss: 1.3729 - accuracy: 0.4189 - val_loss: 1.3821 - val_accuracy: 0.3125\n",
      "Epoch 28/30\n",
      "167/167 [==============================] - 21s 124ms/step - loss: 1.3736 - accuracy: 0.4159 - val_loss: 1.3821 - val_accuracy: 0.3125\n",
      "Epoch 29/30\n",
      "167/167 [==============================] - 21s 124ms/step - loss: 1.3740 - accuracy: 0.4072 - val_loss: 1.3821 - val_accuracy: 0.3125\n",
      "Epoch 30/30\n",
      "167/167 [==============================] - 21s 124ms/step - loss: 1.3741 - accuracy: 0.4123 - val_loss: 1.3821 - val_accuracy: 0.3125\n",
      "INFO:tensorflow:Assets written to: ../xception/xception_30epochs_8348.4_images_False_newWeights_True_lastLayerOnly/assets\n",
      "Test acc for xception: 0.247934\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training resnet for 0.1% of train size (aka 8348 images)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/167 [>.............................] - ETA: 1:23 - loss: 1.3794 - accuracy: 0.4132WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0604s vs `on_train_batch_begin` time: 0.1973s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0604s vs `on_train_batch_end` time: 0.1832s). Check your callbacks.\n",
      "167/167 [==============================] - 18s 83ms/step - loss: 1.3822 - accuracy: 0.3121 - val_loss: 1.3881 - val_accuracy: 0.1250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "167/167 [==============================] - 10s 57ms/step - loss: 1.3819 - accuracy: 0.2979 - val_loss: 1.3881 - val_accuracy: 0.1250\n",
      "Epoch 3/30\n",
      "167/167 [==============================] - 10s 58ms/step - loss: 1.3819 - accuracy: 0.3069 - val_loss: 1.3881 - val_accuracy: 0.1250\n",
      "Epoch 4/30\n",
      "167/167 [==============================] - 10s 58ms/step - loss: 1.3824 - accuracy: 0.3034 - val_loss: 1.3881 - val_accuracy: 0.1250\n",
      "Epoch 5/30\n",
      "167/167 [==============================] - 10s 58ms/step - loss: 1.3819 - accuracy: 0.3077 - val_loss: 1.3881 - val_accuracy: 0.1250\n",
      "Epoch 6/30\n",
      "167/167 [==============================] - 10s 58ms/step - loss: 1.3818 - accuracy: 0.3064 - val_loss: 1.3881 - val_accuracy: 0.1250\n",
      "Epoch 7/30\n",
      "167/167 [==============================] - 10s 58ms/step - loss: 1.3823 - accuracy: 0.2959 - val_loss: 1.3881 - val_accuracy: 0.1250\n",
      "Epoch 8/30\n",
      "167/167 [==============================] - 10s 58ms/step - loss: 1.3820 - accuracy: 0.3014 - val_loss: 1.3881 - val_accuracy: 0.1250\n",
      "Epoch 9/30\n",
      "167/167 [==============================] - 10s 58ms/step - loss: 1.3818 - accuracy: 0.3067 - val_loss: 1.3881 - val_accuracy: 0.1250\n",
      "Epoch 10/30\n",
      "167/167 [==============================] - 10s 58ms/step - loss: 1.3817 - accuracy: 0.3112 - val_loss: 1.3881 - val_accuracy: 0.1250\n",
      "Epoch 11/30\n",
      "167/167 [==============================] - 10s 58ms/step - loss: 1.3825 - accuracy: 0.3049 - val_loss: 1.3881 - val_accuracy: 0.1250\n",
      "Epoch 12/30\n",
      "167/167 [==============================] - 10s 58ms/step - loss: 1.3820 - accuracy: 0.3015 - val_loss: 1.3881 - val_accuracy: 0.1250\n",
      "Epoch 13/30\n",
      "167/167 [==============================] - 10s 58ms/step - loss: 1.3819 - accuracy: 0.3131 - val_loss: 1.3881 - val_accuracy: 0.1250\n",
      "Epoch 14/30\n",
      "167/167 [==============================] - 10s 59ms/step - loss: 1.3822 - accuracy: 0.2980 - val_loss: 1.3881 - val_accuracy: 0.1250\n",
      "Epoch 15/30\n",
      "167/167 [==============================] - 10s 58ms/step - loss: 1.3823 - accuracy: 0.3045 - val_loss: 1.3881 - val_accuracy: 0.1250\n",
      "Epoch 16/30\n",
      "167/167 [==============================] - 10s 58ms/step - loss: 1.3824 - accuracy: 0.2969 - val_loss: 1.3881 - val_accuracy: 0.1250\n",
      "Epoch 17/30\n",
      "167/167 [==============================] - 10s 58ms/step - loss: 1.3821 - accuracy: 0.2986 - val_loss: 1.3881 - val_accuracy: 0.1250\n",
      "Epoch 18/30\n",
      "167/167 [==============================] - 10s 58ms/step - loss: 1.3821 - accuracy: 0.3060 - val_loss: 1.3881 - val_accuracy: 0.1250\n",
      "Epoch 19/30\n",
      "167/167 [==============================] - 10s 58ms/step - loss: 1.3823 - accuracy: 0.2990 - val_loss: 1.3881 - val_accuracy: 0.1250\n",
      "Epoch 20/30\n",
      "167/167 [==============================] - 10s 58ms/step - loss: 1.3821 - accuracy: 0.3019 - val_loss: 1.3881 - val_accuracy: 0.1250\n",
      "Epoch 21/30\n",
      "167/167 [==============================] - 10s 58ms/step - loss: 1.3823 - accuracy: 0.2985 - val_loss: 1.3881 - val_accuracy: 0.1250\n",
      "Epoch 22/30\n",
      "167/167 [==============================] - 10s 58ms/step - loss: 1.3817 - accuracy: 0.3043 - val_loss: 1.3881 - val_accuracy: 0.1250\n",
      "Epoch 23/30\n",
      "167/167 [==============================] - 10s 58ms/step - loss: 1.3819 - accuracy: 0.3086 - val_loss: 1.3881 - val_accuracy: 0.1250\n",
      "Epoch 24/30\n",
      "167/167 [==============================] - 10s 58ms/step - loss: 1.3823 - accuracy: 0.3037 - val_loss: 1.3881 - val_accuracy: 0.1250\n",
      "Epoch 25/30\n",
      "167/167 [==============================] - 10s 58ms/step - loss: 1.3819 - accuracy: 0.3055 - val_loss: 1.3881 - val_accuracy: 0.1250\n",
      "Epoch 26/30\n",
      "167/167 [==============================] - 10s 58ms/step - loss: 1.3824 - accuracy: 0.3027 - val_loss: 1.3881 - val_accuracy: 0.1250\n",
      "Epoch 27/30\n",
      "167/167 [==============================] - 10s 58ms/step - loss: 1.3821 - accuracy: 0.3069 - val_loss: 1.3881 - val_accuracy: 0.1250\n",
      "Epoch 28/30\n",
      "167/167 [==============================] - 10s 58ms/step - loss: 1.3821 - accuracy: 0.3021 - val_loss: 1.3881 - val_accuracy: 0.1250\n",
      "Epoch 29/30\n",
      "167/167 [==============================] - 10s 58ms/step - loss: 1.3821 - accuracy: 0.3054 - val_loss: 1.3881 - val_accuracy: 0.1250\n",
      "Epoch 30/30\n",
      "167/167 [==============================] - 10s 58ms/step - loss: 1.3823 - accuracy: 0.3035 - val_loss: 1.3881 - val_accuracy: 0.1250\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_8348.4_images_False_newWeights_True_lastLayerOnly/assets\n",
      "Test acc for resnet: 0.216942\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training opticnet for 0.1% of train size (aka 8348 images)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "167/167 [==============================] - 61s 327ms/step - loss: 294.8919 - accuracy: 0.1289 - val_loss: 217.3077 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "167/167 [==============================] - 48s 290ms/step - loss: 290.2660 - accuracy: 0.1346 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "167/167 [==============================] - 49s 291ms/step - loss: 292.1529 - accuracy: 0.1287 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "167/167 [==============================] - 48s 290ms/step - loss: 291.7221 - accuracy: 0.1388 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "167/167 [==============================] - 49s 290ms/step - loss: 290.1371 - accuracy: 0.1353 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "167/167 [==============================] - 48s 290ms/step - loss: 291.3609 - accuracy: 0.1311 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "167/167 [==============================] - 48s 290ms/step - loss: 293.6403 - accuracy: 0.1337 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "167/167 [==============================] - 48s 290ms/step - loss: 295.6080 - accuracy: 0.1346 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "167/167 [==============================] - 49s 291ms/step - loss: 294.3447 - accuracy: 0.1349 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "167/167 [==============================] - 49s 290ms/step - loss: 292.3734 - accuracy: 0.1315 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "167/167 [==============================] - 48s 290ms/step - loss: 292.1989 - accuracy: 0.1336 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "167/167 [==============================] - 49s 291ms/step - loss: 291.1321 - accuracy: 0.1362 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "167/167 [==============================] - 48s 290ms/step - loss: 292.4515 - accuracy: 0.1331 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "167/167 [==============================] - 48s 290ms/step - loss: 294.8998 - accuracy: 0.1274 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "167/167 [==============================] - 48s 290ms/step - loss: 292.9501 - accuracy: 0.1303 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "167/167 [==============================] - 48s 290ms/step - loss: 293.3903 - accuracy: 0.1291 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "167/167 [==============================] - 48s 290ms/step - loss: 293.9604 - accuracy: 0.1331 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "167/167 [==============================] - 48s 290ms/step - loss: 291.1511 - accuracy: 0.1315 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "167/167 [==============================] - 48s 290ms/step - loss: 290.2930 - accuracy: 0.1355 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "167/167 [==============================] - 48s 290ms/step - loss: 295.6153 - accuracy: 0.1361 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "167/167 [==============================] - 48s 290ms/step - loss: 291.8942 - accuracy: 0.1377 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "167/167 [==============================] - 49s 291ms/step - loss: 292.1817 - accuracy: 0.1338 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "167/167 [==============================] - 48s 290ms/step - loss: 290.9148 - accuracy: 0.1336 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "167/167 [==============================] - 48s 290ms/step - loss: 293.4775 - accuracy: 0.1305 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "167/167 [==============================] - 48s 290ms/step - loss: 290.3569 - accuracy: 0.1365 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "167/167 [==============================] - 48s 290ms/step - loss: 291.1921 - accuracy: 0.1300 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "167/167 [==============================] - 48s 290ms/step - loss: 293.5116 - accuracy: 0.1340 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "167/167 [==============================] - 49s 291ms/step - loss: 291.6033 - accuracy: 0.1377 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "167/167 [==============================] - 48s 290ms/step - loss: 294.4772 - accuracy: 0.1321 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "167/167 [==============================] - 48s 290ms/step - loss: 293.7854 - accuracy: 0.1367 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../opticnet/opticnet_30epochs_8348.4_images_False_newWeights_True_lastLayerOnly/assets\n",
      "Test acc for opticnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.25069352 0.25362183 0.24735636 0.23572423]\n",
      "Training xception for 0.25% of train size (aka 20871 images)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/418 [..............................] - ETA: 4:26 - loss: 1.3567 - accuracy: 0.4324WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1183s vs `on_train_batch_begin` time: 0.1964s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1183s vs `on_train_batch_end` time: 0.2448s). Check your callbacks.\n",
      "418/418 [==============================] - 60s 132ms/step - loss: 1.3610 - accuracy: 0.4243 - val_loss: 1.3816 - val_accuracy: 0.2812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "418/418 [==============================] - 51s 123ms/step - loss: 1.3614 - accuracy: 0.4217 - val_loss: 1.3816 - val_accuracy: 0.2812\n",
      "Epoch 3/30\n",
      "418/418 [==============================] - 52s 124ms/step - loss: 1.3616 - accuracy: 0.4223 - val_loss: 1.3816 - val_accuracy: 0.2812\n",
      "Epoch 4/30\n",
      "418/418 [==============================] - 52s 124ms/step - loss: 1.3611 - accuracy: 0.4258 - val_loss: 1.3816 - val_accuracy: 0.2812\n",
      "Epoch 5/30\n",
      "418/418 [==============================] - 52s 124ms/step - loss: 1.3616 - accuracy: 0.4208 - val_loss: 1.3816 - val_accuracy: 0.2812\n",
      "Epoch 6/30\n",
      "418/418 [==============================] - 52s 124ms/step - loss: 1.3614 - accuracy: 0.4229 - val_loss: 1.3816 - val_accuracy: 0.2812\n",
      "Epoch 7/30\n",
      "418/418 [==============================] - 52s 124ms/step - loss: 1.3614 - accuracy: 0.4225 - val_loss: 1.3816 - val_accuracy: 0.2812\n",
      "Epoch 8/30\n",
      "418/418 [==============================] - 52s 124ms/step - loss: 1.3614 - accuracy: 0.4203 - val_loss: 1.3816 - val_accuracy: 0.2812\n",
      "Epoch 9/30\n",
      "418/418 [==============================] - 52s 124ms/step - loss: 1.3614 - accuracy: 0.4194 - val_loss: 1.3816 - val_accuracy: 0.2812\n",
      "Epoch 10/30\n",
      "418/418 [==============================] - 52s 124ms/step - loss: 1.3615 - accuracy: 0.4206 - val_loss: 1.3816 - val_accuracy: 0.2812\n",
      "Epoch 11/30\n",
      "418/418 [==============================] - 52s 124ms/step - loss: 1.3614 - accuracy: 0.4217 - val_loss: 1.3816 - val_accuracy: 0.2812\n",
      "Epoch 12/30\n",
      "418/418 [==============================] - 52s 124ms/step - loss: 1.3614 - accuracy: 0.4216 - val_loss: 1.3816 - val_accuracy: 0.2812\n",
      "Epoch 13/30\n",
      "418/418 [==============================] - 52s 124ms/step - loss: 1.3614 - accuracy: 0.4212 - val_loss: 1.3816 - val_accuracy: 0.2812\n",
      "Epoch 14/30\n",
      "418/418 [==============================] - 52s 124ms/step - loss: 1.3613 - accuracy: 0.4225 - val_loss: 1.3816 - val_accuracy: 0.2812\n",
      "Epoch 15/30\n",
      "418/418 [==============================] - 52s 124ms/step - loss: 1.3623 - accuracy: 0.4142 - val_loss: 1.3816 - val_accuracy: 0.2812\n",
      "Epoch 16/30\n",
      "418/418 [==============================] - 52s 124ms/step - loss: 1.3613 - accuracy: 0.4220 - val_loss: 1.3816 - val_accuracy: 0.2812\n",
      "Epoch 17/30\n",
      "418/418 [==============================] - 52s 124ms/step - loss: 1.3609 - accuracy: 0.4242 - val_loss: 1.3816 - val_accuracy: 0.2812\n",
      "Epoch 18/30\n",
      "418/418 [==============================] - 52s 124ms/step - loss: 1.3609 - accuracy: 0.4247 - val_loss: 1.3816 - val_accuracy: 0.2812\n",
      "Epoch 19/30\n",
      "418/418 [==============================] - 52s 124ms/step - loss: 1.3619 - accuracy: 0.4179 - val_loss: 1.3816 - val_accuracy: 0.2812\n",
      "Epoch 20/30\n",
      "418/418 [==============================] - 52s 124ms/step - loss: 1.3617 - accuracy: 0.4185 - val_loss: 1.3816 - val_accuracy: 0.2812\n",
      "Epoch 21/30\n",
      "418/418 [==============================] - 52s 124ms/step - loss: 1.3612 - accuracy: 0.4232 - val_loss: 1.3816 - val_accuracy: 0.2812\n",
      "Epoch 22/30\n",
      "418/418 [==============================] - 52s 124ms/step - loss: 1.3614 - accuracy: 0.4217 - val_loss: 1.3816 - val_accuracy: 0.2812\n",
      "Epoch 23/30\n",
      "418/418 [==============================] - 52s 124ms/step - loss: 1.3620 - accuracy: 0.4186 - val_loss: 1.3816 - val_accuracy: 0.2812\n",
      "Epoch 24/30\n",
      "418/418 [==============================] - 52s 124ms/step - loss: 1.3618 - accuracy: 0.4185 - val_loss: 1.3816 - val_accuracy: 0.2812\n",
      "Epoch 25/30\n",
      "418/418 [==============================] - 52s 124ms/step - loss: 1.3609 - accuracy: 0.4270 - val_loss: 1.3816 - val_accuracy: 0.2812\n",
      "Epoch 26/30\n",
      "418/418 [==============================] - 52s 124ms/step - loss: 1.3628 - accuracy: 0.4088 - val_loss: 1.3816 - val_accuracy: 0.2812\n",
      "Epoch 27/30\n",
      "418/418 [==============================] - 52s 124ms/step - loss: 1.3619 - accuracy: 0.4186 - val_loss: 1.3816 - val_accuracy: 0.2812\n",
      "Epoch 28/30\n",
      "418/418 [==============================] - 52s 124ms/step - loss: 1.3607 - accuracy: 0.4274 - val_loss: 1.3816 - val_accuracy: 0.2812\n",
      "Epoch 29/30\n",
      "418/418 [==============================] - 52s 124ms/step - loss: 1.3614 - accuracy: 0.4229 - val_loss: 1.3816 - val_accuracy: 0.2812\n",
      "Epoch 30/30\n",
      "418/418 [==============================] - 52s 124ms/step - loss: 1.3614 - accuracy: 0.4215 - val_loss: 1.3816 - val_accuracy: 0.2812\n",
      "INFO:tensorflow:Assets written to: ../xception/xception_30epochs_20871.0_images_False_newWeights_True_lastLayerOnly/assets\n",
      "Test acc for xception: 0.237603\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training resnet for 0.25% of train size (aka 20871 images)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/418 [..............................] - ETA: 3:24 - loss: 1.3855 - accuracy: 0.2688WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0616s vs `on_train_batch_begin` time: 0.1937s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0616s vs `on_train_batch_end` time: 0.1680s). Check your callbacks.\n",
      "418/418 [==============================] - 33s 69ms/step - loss: 1.3879 - accuracy: 0.2042 - val_loss: 1.3860 - val_accuracy: 0.1562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "418/418 [==============================] - 24s 57ms/step - loss: 1.3881 - accuracy: 0.2023 - val_loss: 1.3860 - val_accuracy: 0.1562\n",
      "Epoch 3/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3879 - accuracy: 0.2036 - val_loss: 1.3860 - val_accuracy: 0.1562\n",
      "Epoch 4/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3881 - accuracy: 0.2003 - val_loss: 1.3860 - val_accuracy: 0.1562\n",
      "Epoch 5/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3880 - accuracy: 0.2020 - val_loss: 1.3860 - val_accuracy: 0.1562\n",
      "Epoch 6/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3882 - accuracy: 0.1980 - val_loss: 1.3860 - val_accuracy: 0.1562\n",
      "Epoch 7/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3882 - accuracy: 0.1988 - val_loss: 1.3860 - val_accuracy: 0.1562\n",
      "Epoch 8/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3881 - accuracy: 0.1993 - val_loss: 1.3860 - val_accuracy: 0.1562\n",
      "Epoch 9/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3880 - accuracy: 0.2020 - val_loss: 1.3860 - val_accuracy: 0.1562\n",
      "Epoch 10/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3880 - accuracy: 0.1968 - val_loss: 1.3860 - val_accuracy: 0.1562\n",
      "Epoch 11/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3882 - accuracy: 0.1985 - val_loss: 1.3860 - val_accuracy: 0.1562\n",
      "Epoch 12/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3880 - accuracy: 0.2028 - val_loss: 1.3860 - val_accuracy: 0.1562\n",
      "Epoch 13/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3880 - accuracy: 0.1989 - val_loss: 1.3860 - val_accuracy: 0.1562\n",
      "Epoch 14/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3882 - accuracy: 0.1997 - val_loss: 1.3860 - val_accuracy: 0.1562\n",
      "Epoch 15/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3883 - accuracy: 0.1960 - val_loss: 1.3860 - val_accuracy: 0.1562\n",
      "Epoch 16/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3881 - accuracy: 0.1984 - val_loss: 1.3860 - val_accuracy: 0.1562\n",
      "Epoch 17/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3881 - accuracy: 0.2025 - val_loss: 1.3860 - val_accuracy: 0.1562\n",
      "Epoch 18/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3880 - accuracy: 0.2003 - val_loss: 1.3860 - val_accuracy: 0.1562\n",
      "Epoch 19/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3879 - accuracy: 0.2004 - val_loss: 1.3860 - val_accuracy: 0.1562\n",
      "Epoch 20/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3882 - accuracy: 0.2020 - val_loss: 1.3860 - val_accuracy: 0.1562\n",
      "Epoch 21/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3879 - accuracy: 0.2041 - val_loss: 1.3860 - val_accuracy: 0.1562\n",
      "Epoch 22/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3879 - accuracy: 0.2033 - val_loss: 1.3860 - val_accuracy: 0.1562\n",
      "Epoch 23/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3878 - accuracy: 0.2056 - val_loss: 1.3860 - val_accuracy: 0.1562\n",
      "Epoch 24/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3880 - accuracy: 0.1975 - val_loss: 1.3860 - val_accuracy: 0.1562\n",
      "Epoch 25/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3880 - accuracy: 0.1993 - val_loss: 1.3860 - val_accuracy: 0.1562\n",
      "Epoch 26/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3880 - accuracy: 0.2027 - val_loss: 1.3860 - val_accuracy: 0.1562\n",
      "Epoch 27/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3881 - accuracy: 0.1983 - val_loss: 1.3860 - val_accuracy: 0.1562\n",
      "Epoch 28/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3879 - accuracy: 0.2028 - val_loss: 1.3860 - val_accuracy: 0.1562\n",
      "Epoch 29/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3881 - accuracy: 0.1959 - val_loss: 1.3860 - val_accuracy: 0.1562\n",
      "Epoch 30/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3880 - accuracy: 0.2012 - val_loss: 1.3860 - val_accuracy: 0.1562\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_20871.0_images_False_newWeights_True_lastLayerOnly/assets\n",
      "Test acc for resnet: 0.202479\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training opticnet for 0.25% of train size (aka 20871 images)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:15: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  self.fig = plt.figure(figsize=(4,3))\n",
      "<ipython-input-8-797fd00c81c1>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "418/418 [==============================] - 132s 302ms/step - loss: 291.9559 - accuracy: 0.1322 - val_loss: 217.3077 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "418/418 [==============================] - 121s 289ms/step - loss: 291.4915 - accuracy: 0.1324 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "418/418 [==============================] - 121s 289ms/step - loss: 290.9319 - accuracy: 0.1353 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "418/418 [==============================] - 121s 289ms/step - loss: 291.7317 - accuracy: 0.1349 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "418/418 [==============================] - 121s 289ms/step - loss: 292.8079 - accuracy: 0.1334 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "418/418 [==============================] - 121s 289ms/step - loss: 293.4589 - accuracy: 0.1315 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "418/418 [==============================] - 121s 289ms/step - loss: 292.1352 - accuracy: 0.1335 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "418/418 [==============================] - 121s 289ms/step - loss: 293.5541 - accuracy: 0.1341 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "418/418 [==============================] - 121s 289ms/step - loss: 289.7769 - accuracy: 0.1359 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "418/418 [==============================] - 121s 289ms/step - loss: 292.2737 - accuracy: 0.1354 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "418/418 [==============================] - 121s 289ms/step - loss: 291.4774 - accuracy: 0.1316 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "418/418 [==============================] - 121s 289ms/step - loss: 291.8528 - accuracy: 0.1354 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "418/418 [==============================] - 121s 289ms/step - loss: 290.3930 - accuracy: 0.1394 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "418/418 [==============================] - 121s 289ms/step - loss: 290.9842 - accuracy: 0.1361 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "418/418 [==============================] - 121s 289ms/step - loss: 290.0166 - accuracy: 0.1370 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "418/418 [==============================] - 121s 289ms/step - loss: 291.9973 - accuracy: 0.1350 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "418/418 [==============================] - 121s 288ms/step - loss: 290.7638 - accuracy: 0.1351 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "418/418 [==============================] - 121s 289ms/step - loss: 291.3676 - accuracy: 0.1297 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "418/418 [==============================] - 121s 289ms/step - loss: 293.3425 - accuracy: 0.1297 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "418/418 [==============================] - 121s 289ms/step - loss: 290.9971 - accuracy: 0.1394 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "418/418 [==============================] - 121s 289ms/step - loss: 290.2384 - accuracy: 0.1351 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "418/418 [==============================] - 121s 289ms/step - loss: 291.9700 - accuracy: 0.1310 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "418/418 [==============================] - 121s 289ms/step - loss: 292.4131 - accuracy: 0.1355 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "418/418 [==============================] - 121s 289ms/step - loss: 291.8193 - accuracy: 0.1325 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "418/418 [==============================] - 121s 289ms/step - loss: 290.1994 - accuracy: 0.1337 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "418/418 [==============================] - 121s 289ms/step - loss: 293.5092 - accuracy: 0.1330 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "418/418 [==============================] - 121s 289ms/step - loss: 292.3803 - accuracy: 0.1293 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "418/418 [==============================] - 121s 289ms/step - loss: 290.9863 - accuracy: 0.1351 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "418/418 [==============================] - 121s 289ms/step - loss: 292.9987 - accuracy: 0.1347 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "418/418 [==============================] - 121s 289ms/step - loss: 293.0984 - accuracy: 0.1324 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../opticnet/opticnet_30epochs_20871.0_images_False_newWeights_True_lastLayerOnly/assets\n",
      "Test acc for opticnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.39840395 0.40263405 0.40033486 0.39298979]\n",
      "Training xception for 0.4% of train size (aka 33393 images)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/668 [..............................] - ETA: 6:34 - loss: 1.3990 - accuracy: 0.1283WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1167s vs `on_train_batch_begin` time: 0.1946s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1167s vs `on_train_batch_end` time: 0.2055s). Check your callbacks.\n",
      "668/668 [==============================] - 90s 131ms/step - loss: 1.3969 - accuracy: 0.1411 - val_loss: 1.3917 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "668/668 [==============================] - 82s 123ms/step - loss: 1.3972 - accuracy: 0.1422 - val_loss: 1.3917 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "668/668 [==============================] - 83s 124ms/step - loss: 1.3969 - accuracy: 0.1434 - val_loss: 1.3917 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "668/668 [==============================] - 83s 124ms/step - loss: 1.3970 - accuracy: 0.1438 - val_loss: 1.3917 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "668/668 [==============================] - 83s 124ms/step - loss: 1.3969 - accuracy: 0.1430 - val_loss: 1.3917 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "668/668 [==============================] - 83s 124ms/step - loss: 1.3971 - accuracy: 0.1423 - val_loss: 1.3917 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "668/668 [==============================] - 83s 124ms/step - loss: 1.3972 - accuracy: 0.1402 - val_loss: 1.3917 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "668/668 [==============================] - 83s 124ms/step - loss: 1.3969 - accuracy: 0.1418 - val_loss: 1.3917 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "668/668 [==============================] - 83s 124ms/step - loss: 1.3971 - accuracy: 0.1445 - val_loss: 1.3917 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "668/668 [==============================] - 83s 124ms/step - loss: 1.3970 - accuracy: 0.1417 - val_loss: 1.3917 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "668/668 [==============================] - 83s 124ms/step - loss: 1.3969 - accuracy: 0.1456 - val_loss: 1.3917 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "668/668 [==============================] - 83s 124ms/step - loss: 1.3966 - accuracy: 0.1462 - val_loss: 1.3917 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "668/668 [==============================] - 83s 124ms/step - loss: 1.3968 - accuracy: 0.1433 - val_loss: 1.3917 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "668/668 [==============================] - 83s 124ms/step - loss: 1.3968 - accuracy: 0.1440 - val_loss: 1.3917 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "668/668 [==============================] - 83s 124ms/step - loss: 1.3970 - accuracy: 0.1432 - val_loss: 1.3917 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "668/668 [==============================] - 83s 124ms/step - loss: 1.3972 - accuracy: 0.1389 - val_loss: 1.3917 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "668/668 [==============================] - 83s 124ms/step - loss: 1.3968 - accuracy: 0.1451 - val_loss: 1.3917 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "668/668 [==============================] - 83s 124ms/step - loss: 1.3966 - accuracy: 0.1447 - val_loss: 1.3917 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "668/668 [==============================] - 83s 124ms/step - loss: 1.3966 - accuracy: 0.1436 - val_loss: 1.3917 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "668/668 [==============================] - 83s 124ms/step - loss: 1.3968 - accuracy: 0.1439 - val_loss: 1.3917 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "668/668 [==============================] - 83s 124ms/step - loss: 1.3968 - accuracy: 0.1437 - val_loss: 1.3917 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "668/668 [==============================] - 83s 124ms/step - loss: 1.3970 - accuracy: 0.1443 - val_loss: 1.3917 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "668/668 [==============================] - 83s 124ms/step - loss: 1.3970 - accuracy: 0.1470 - val_loss: 1.3917 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "668/668 [==============================] - 83s 124ms/step - loss: 1.3970 - accuracy: 0.1424 - val_loss: 1.3917 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "668/668 [==============================] - 83s 124ms/step - loss: 1.3966 - accuracy: 0.1441 - val_loss: 1.3917 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "668/668 [==============================] - 83s 124ms/step - loss: 1.3974 - accuracy: 0.1434 - val_loss: 1.3917 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "668/668 [==============================] - 83s 124ms/step - loss: 1.3968 - accuracy: 0.1442 - val_loss: 1.3917 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "668/668 [==============================] - 83s 124ms/step - loss: 1.3965 - accuracy: 0.1459 - val_loss: 1.3917 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "668/668 [==============================] - 83s 124ms/step - loss: 1.3968 - accuracy: 0.1415 - val_loss: 1.3917 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "668/668 [==============================] - 83s 124ms/step - loss: 1.3968 - accuracy: 0.1452 - val_loss: 1.3917 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../xception/xception_30epochs_33393.6_images_False_newWeights_True_lastLayerOnly/assets\n",
      "Test acc for xception: 0.247934\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training resnet for 0.4% of train size (aka 33393 images)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/668 [..............................] - ETA: 5:26 - loss: 1.3867 - accuracy: 0.2392WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0598s vs `on_train_batch_begin` time: 0.1879s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0598s vs `on_train_batch_end` time: 0.1737s). Check your callbacks.\n",
      "668/668 [==============================] - 45s 63ms/step - loss: 1.3878 - accuracy: 0.1958 - val_loss: 1.3833 - val_accuracy: 0.3438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "668/668 [==============================] - 38s 57ms/step - loss: 1.3877 - accuracy: 0.1944 - val_loss: 1.3833 - val_accuracy: 0.3438\n",
      "Epoch 3/30\n",
      "668/668 [==============================] - 38s 57ms/step - loss: 1.3878 - accuracy: 0.1890 - val_loss: 1.3833 - val_accuracy: 0.3438\n",
      "Epoch 4/30\n",
      "668/668 [==============================] - 38s 58ms/step - loss: 1.3877 - accuracy: 0.1937 - val_loss: 1.3833 - val_accuracy: 0.3438\n",
      "Epoch 5/30\n",
      "668/668 [==============================] - 38s 58ms/step - loss: 1.3878 - accuracy: 0.1922 - val_loss: 1.3833 - val_accuracy: 0.3438\n",
      "Epoch 6/30\n",
      "668/668 [==============================] - 38s 58ms/step - loss: 1.3876 - accuracy: 0.1975 - val_loss: 1.3833 - val_accuracy: 0.3438\n",
      "Epoch 7/30\n",
      "668/668 [==============================] - 38s 58ms/step - loss: 1.3878 - accuracy: 0.1911 - val_loss: 1.3833 - val_accuracy: 0.3438\n",
      "Epoch 8/30\n",
      "668/668 [==============================] - 38s 58ms/step - loss: 1.3877 - accuracy: 0.1952 - val_loss: 1.3833 - val_accuracy: 0.3438\n",
      "Epoch 9/30\n",
      "668/668 [==============================] - 38s 57ms/step - loss: 1.3879 - accuracy: 0.1906 - val_loss: 1.3833 - val_accuracy: 0.3438\n",
      "Epoch 10/30\n",
      "668/668 [==============================] - 38s 58ms/step - loss: 1.3879 - accuracy: 0.1884 - val_loss: 1.3833 - val_accuracy: 0.3438\n",
      "Epoch 11/30\n",
      "668/668 [==============================] - 39s 58ms/step - loss: 1.3877 - accuracy: 0.1925 - val_loss: 1.3833 - val_accuracy: 0.3438\n",
      "Epoch 12/30\n",
      "668/668 [==============================] - 39s 58ms/step - loss: 1.3877 - accuracy: 0.1938 - val_loss: 1.3833 - val_accuracy: 0.3438\n",
      "Epoch 13/30\n",
      "668/668 [==============================] - 39s 58ms/step - loss: 1.3877 - accuracy: 0.1957 - val_loss: 1.3833 - val_accuracy: 0.3438\n",
      "Epoch 14/30\n",
      "668/668 [==============================] - 39s 58ms/step - loss: 1.3878 - accuracy: 0.1915 - val_loss: 1.3833 - val_accuracy: 0.3438\n",
      "Epoch 15/30\n",
      "668/668 [==============================] - 39s 58ms/step - loss: 1.3878 - accuracy: 0.1931 - val_loss: 1.3833 - val_accuracy: 0.3438\n",
      "Epoch 16/30\n",
      "668/668 [==============================] - 38s 58ms/step - loss: 1.3880 - accuracy: 0.1889 - val_loss: 1.3833 - val_accuracy: 0.3438\n",
      "Epoch 17/30\n",
      "668/668 [==============================] - 38s 58ms/step - loss: 1.3877 - accuracy: 0.1930 - val_loss: 1.3833 - val_accuracy: 0.3438\n",
      "Epoch 18/30\n",
      "668/668 [==============================] - 38s 58ms/step - loss: 1.3878 - accuracy: 0.1907 - val_loss: 1.3833 - val_accuracy: 0.3438\n",
      "Epoch 19/30\n",
      "668/668 [==============================] - 38s 58ms/step - loss: 1.3878 - accuracy: 0.1916 - val_loss: 1.3833 - val_accuracy: 0.3438\n",
      "Epoch 20/30\n",
      "668/668 [==============================] - 38s 58ms/step - loss: 1.3878 - accuracy: 0.1915 - val_loss: 1.3833 - val_accuracy: 0.3438\n",
      "Epoch 21/30\n",
      "668/668 [==============================] - 39s 58ms/step - loss: 1.3878 - accuracy: 0.1916 - val_loss: 1.3833 - val_accuracy: 0.3438\n",
      "Epoch 22/30\n",
      "668/668 [==============================] - 39s 58ms/step - loss: 1.3878 - accuracy: 0.1903 - val_loss: 1.3833 - val_accuracy: 0.3438\n",
      "Epoch 23/30\n",
      "668/668 [==============================] - 39s 58ms/step - loss: 1.3877 - accuracy: 0.1964 - val_loss: 1.3833 - val_accuracy: 0.3438\n",
      "Epoch 24/30\n",
      "668/668 [==============================] - 38s 58ms/step - loss: 1.3879 - accuracy: 0.1897 - val_loss: 1.3833 - val_accuracy: 0.3438\n",
      "Epoch 25/30\n",
      "668/668 [==============================] - 38s 58ms/step - loss: 1.3877 - accuracy: 0.1924 - val_loss: 1.3833 - val_accuracy: 0.3438\n",
      "Epoch 26/30\n",
      "668/668 [==============================] - 38s 58ms/step - loss: 1.3879 - accuracy: 0.1910 - val_loss: 1.3833 - val_accuracy: 0.3438\n",
      "Epoch 27/30\n",
      "668/668 [==============================] - 38s 58ms/step - loss: 1.3878 - accuracy: 0.1899 - val_loss: 1.3833 - val_accuracy: 0.3438\n",
      "Epoch 28/30\n",
      "668/668 [==============================] - 38s 58ms/step - loss: 1.3877 - accuracy: 0.1925 - val_loss: 1.3833 - val_accuracy: 0.3438\n",
      "Epoch 29/30\n",
      "668/668 [==============================] - 38s 58ms/step - loss: 1.3878 - accuracy: 0.1911 - val_loss: 1.3833 - val_accuracy: 0.3438\n",
      "Epoch 30/30\n",
      "668/668 [==============================] - 38s 58ms/step - loss: 1.3877 - accuracy: 0.1930 - val_loss: 1.3833 - val_accuracy: 0.3438\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_33393.6_images_False_newWeights_True_lastLayerOnly/assets\n",
      "Test acc for resnet: 0.216942\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training opticnet for 0.4% of train size (aka 33393 images)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "668/668 [==============================] - 206s 299ms/step - loss: 288.9477 - accuracy: 0.1359 - val_loss: 217.3077 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "668/668 [==============================] - 193s 289ms/step - loss: 289.4494 - accuracy: 0.1390 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "668/668 [==============================] - 193s 289ms/step - loss: 290.3990 - accuracy: 0.1335 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "668/668 [==============================] - 193s 289ms/step - loss: 290.2197 - accuracy: 0.1355 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "668/668 [==============================] - 193s 289ms/step - loss: 288.8262 - accuracy: 0.1368 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "668/668 [==============================] - 193s 289ms/step - loss: 287.6663 - accuracy: 0.1371 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "668/668 [==============================] - 194s 290ms/step - loss: 291.5809 - accuracy: 0.1361 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "668/668 [==============================] - 193s 289ms/step - loss: 290.6711 - accuracy: 0.1343 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "668/668 [==============================] - 193s 289ms/step - loss: 289.6758 - accuracy: 0.1325 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "668/668 [==============================] - 193s 289ms/step - loss: 291.4105 - accuracy: 0.1355 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "668/668 [==============================] - 193s 290ms/step - loss: 291.4159 - accuracy: 0.1348 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "668/668 [==============================] - 193s 289ms/step - loss: 289.5759 - accuracy: 0.1352 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "668/668 [==============================] - 193s 289ms/step - loss: 290.6747 - accuracy: 0.1330 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "668/668 [==============================] - 193s 289ms/step - loss: 290.5397 - accuracy: 0.1342 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "668/668 [==============================] - 193s 289ms/step - loss: 288.7698 - accuracy: 0.1380 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "668/668 [==============================] - 193s 289ms/step - loss: 289.9867 - accuracy: 0.1333 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "668/668 [==============================] - 193s 289ms/step - loss: 290.1669 - accuracy: 0.1364 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "668/668 [==============================] - 193s 289ms/step - loss: 289.7088 - accuracy: 0.1364 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "668/668 [==============================] - 193s 289ms/step - loss: 289.7123 - accuracy: 0.1373 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "668/668 [==============================] - 193s 289ms/step - loss: 290.4350 - accuracy: 0.1359 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "668/668 [==============================] - 193s 289ms/step - loss: 290.9436 - accuracy: 0.1351 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "668/668 [==============================] - 193s 289ms/step - loss: 289.6109 - accuracy: 0.1354 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "668/668 [==============================] - 193s 289ms/step - loss: 290.1137 - accuracy: 0.1385 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "668/668 [==============================] - 193s 289ms/step - loss: 290.0198 - accuracy: 0.1356 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "668/668 [==============================] - 193s 289ms/step - loss: 290.9515 - accuracy: 0.1337 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "668/668 [==============================] - 193s 289ms/step - loss: 289.5515 - accuracy: 0.1364 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "668/668 [==============================] - 193s 289ms/step - loss: 288.9623 - accuracy: 0.1386 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "668/668 [==============================] - 193s 289ms/step - loss: 289.1236 - accuracy: 0.1354 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "668/668 [==============================] - 194s 290ms/step - loss: 289.5280 - accuracy: 0.1341 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "668/668 [==============================] - 193s 289ms/step - loss: 288.2246 - accuracy: 0.1360 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../opticnet/opticnet_30epochs_33393.6_images_False_newWeights_True_lastLayerOnly/assets\n",
      "Test acc for opticnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.49747292 0.50272813 0.49973564 0.49628598]\n",
      "Training xception for 0.5% of train size (aka 41742 images)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/835 [..............................] - ETA: 8:36 - loss: 1.3871 - accuracy: 0.1468 WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1204s vs `on_train_batch_begin` time: 0.1926s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1204s vs `on_train_batch_end` time: 0.2262s). Check your callbacks.\n",
      "835/835 [==============================] - 111s 127ms/step - loss: 1.3877 - accuracy: 0.1309 - val_loss: 1.3883 - val_accuracy: 0.1875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "835/835 [==============================] - 103s 124ms/step - loss: 1.3875 - accuracy: 0.1349 - val_loss: 1.3883 - val_accuracy: 0.1875\n",
      "Epoch 3/30\n",
      "835/835 [==============================] - 104s 124ms/step - loss: 1.3875 - accuracy: 0.1346 - val_loss: 1.3883 - val_accuracy: 0.1875\n",
      "Epoch 4/30\n",
      "835/835 [==============================] - 104s 124ms/step - loss: 1.3875 - accuracy: 0.1342 - val_loss: 1.3883 - val_accuracy: 0.1875\n",
      "Epoch 5/30\n",
      "835/835 [==============================] - 104s 124ms/step - loss: 1.3876 - accuracy: 0.1317 - val_loss: 1.3883 - val_accuracy: 0.1875\n",
      "Epoch 6/30\n",
      "835/835 [==============================] - 103s 124ms/step - loss: 1.3876 - accuracy: 0.1299 - val_loss: 1.3883 - val_accuracy: 0.1875\n",
      "Epoch 7/30\n",
      "835/835 [==============================] - 103s 124ms/step - loss: 1.3876 - accuracy: 0.1327 - val_loss: 1.3883 - val_accuracy: 0.1875\n",
      "Epoch 8/30\n",
      "835/835 [==============================] - 103s 124ms/step - loss: 1.3876 - accuracy: 0.1339 - val_loss: 1.3883 - val_accuracy: 0.1875\n",
      "Epoch 9/30\n",
      "835/835 [==============================] - 103s 124ms/step - loss: 1.3875 - accuracy: 0.1335 - val_loss: 1.3883 - val_accuracy: 0.1875\n",
      "Epoch 10/30\n",
      "835/835 [==============================] - 103s 124ms/step - loss: 1.3876 - accuracy: 0.1312 - val_loss: 1.3883 - val_accuracy: 0.1875\n",
      "Epoch 11/30\n",
      "835/835 [==============================] - 103s 124ms/step - loss: 1.3875 - accuracy: 0.1356 - val_loss: 1.3883 - val_accuracy: 0.1875\n",
      "Epoch 12/30\n",
      "835/835 [==============================] - 103s 124ms/step - loss: 1.3876 - accuracy: 0.1325 - val_loss: 1.3883 - val_accuracy: 0.1875\n",
      "Epoch 13/30\n",
      "835/835 [==============================] - 103s 124ms/step - loss: 1.3874 - accuracy: 0.1376 - val_loss: 1.3883 - val_accuracy: 0.1875\n",
      "Epoch 14/30\n",
      "835/835 [==============================] - 103s 124ms/step - loss: 1.3875 - accuracy: 0.1356 - val_loss: 1.3883 - val_accuracy: 0.1875\n",
      "Epoch 15/30\n",
      "835/835 [==============================] - 103s 124ms/step - loss: 1.3878 - accuracy: 0.1309 - val_loss: 1.3883 - val_accuracy: 0.1875\n",
      "Epoch 16/30\n",
      "835/835 [==============================] - 103s 124ms/step - loss: 1.3875 - accuracy: 0.1330 - val_loss: 1.3883 - val_accuracy: 0.1875\n",
      "Epoch 17/30\n",
      "835/835 [==============================] - 103s 124ms/step - loss: 1.3877 - accuracy: 0.1316 - val_loss: 1.3883 - val_accuracy: 0.1875\n",
      "Epoch 18/30\n",
      "835/835 [==============================] - 104s 124ms/step - loss: 1.3875 - accuracy: 0.1329 - val_loss: 1.3883 - val_accuracy: 0.1875\n",
      "Epoch 19/30\n",
      "835/835 [==============================] - 104s 124ms/step - loss: 1.3876 - accuracy: 0.1316 - val_loss: 1.3883 - val_accuracy: 0.1875\n",
      "Epoch 20/30\n",
      "835/835 [==============================] - 103s 124ms/step - loss: 1.3874 - accuracy: 0.1375 - val_loss: 1.3883 - val_accuracy: 0.1875\n",
      "Epoch 21/30\n",
      "835/835 [==============================] - 103s 124ms/step - loss: 1.3876 - accuracy: 0.1312 - val_loss: 1.3883 - val_accuracy: 0.1875\n",
      "Epoch 22/30\n",
      "835/835 [==============================] - 103s 124ms/step - loss: 1.3876 - accuracy: 0.1315 - val_loss: 1.3883 - val_accuracy: 0.1875\n",
      "Epoch 23/30\n",
      "835/835 [==============================] - 103s 124ms/step - loss: 1.3876 - accuracy: 0.1330 - val_loss: 1.3883 - val_accuracy: 0.1875\n",
      "Epoch 24/30\n",
      "835/835 [==============================] - 103s 124ms/step - loss: 1.3876 - accuracy: 0.1297 - val_loss: 1.3883 - val_accuracy: 0.1875\n",
      "Epoch 25/30\n",
      "835/835 [==============================] - 104s 124ms/step - loss: 1.3877 - accuracy: 0.1315 - val_loss: 1.3883 - val_accuracy: 0.1875\n",
      "Epoch 26/30\n",
      "835/835 [==============================] - 103s 124ms/step - loss: 1.3878 - accuracy: 0.1287 - val_loss: 1.3883 - val_accuracy: 0.1875\n",
      "Epoch 27/30\n",
      "581/835 [===================>..........] - ETA: 31s - loss: 1.3873 - accuracy: 0.1370"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-1ee419435413>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0moptim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         hist = model.fit(X_trn, y_t, epochs=epochs, validation_data = (X_val, y_validation), batch_size=batch_size,\n\u001b[0m\u001b[1;32m     26\u001b[0m                     \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                     \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2940\u001b[0m       (graph_function,\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2942\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1916\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1919\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m/anaconda/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    553\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    556\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import datetime\n",
    "\n",
    "newWeights=False; trainLastLayerOnly=True\n",
    "\n",
    "maxTrain = len(y_train)\n",
    "#for p in [1.0]:\n",
    "#for p in [0.1, 0.25, 0.4, 0.5, 0.6, 0.75, 0.9]:\n",
    "for p in [0.01, 0.025, 0.05, 0.075, 0.09, 0.1, 0.25, 0.4, 0.5, 0.6, 0.75, 0.9, 1.0]:\n",
    "    #X_trn, X_tst, y_trn, y_tst\n",
    "    if p < 1:\n",
    "        X_t, _, y_t, _ = train_test_split(images, y_train, test_size=1-p, random_state=123)\n",
    "    else:\n",
    "        X_t = images; y_t = y_train;\n",
    "    print(f\"Labels fraction: {sum(y_t == 1) / sum(y_train == 1)}\")\n",
    "    for net in [\"xception\", \"resnet\", \"opticnet\"]:\n",
    "        print(f\"Training {net} for {p}% of train size (aka {len(X_t)} images)...\")\n",
    "        model, size = emptyModelGenerator(net, newWeights=newWeights, lastOnly=trainLastLayerOnly)\n",
    "        X_trn = resizeIms(X_t, size)\n",
    "        X_val = resizeIms(x_val, size)\n",
    "        log_dir = f\"logs/{net}/fit/{p}trainSet_\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "        tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "        optim = Adam(learning_rate=0.001)\n",
    "        model.compile(optimizer=optim, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "        hist = model.fit(X_trn, y_t, epochs=epochs, validation_data = (X_val, y_validation), batch_size=batch_size,\n",
    "                    shuffle=True, max_queue_size=20,\n",
    "                    use_multiprocessing=True, workers=5, \n",
    "                    callbacks=[CustomCallback(fraction=0.9, model=net), tensorboard_callback])\n",
    "        model.save(f\"../{net}/{net}_{epochs}epochs_{p*maxTrain}_images_{newWeights}_newWeights_{trainLastLayerOnly}_lastLayerOnly\")\n",
    "        testPredict(model, size, name=net)\n",
    "        del model\n",
    "        del X_trn\n",
    "        del X_val\n",
    "        print(\"Done!\\n\" + '-'*50, end='\\n\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
