{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "import os\n",
    "import cv2\n",
    "import pickle\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version is: 2.4.1\n"
     ]
    }
   ],
   "source": [
    "print(f\"Tensorflow version is: {tf.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataPath = \"../../data/OCT/OCT2017/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of Classes Detected : 4\n"
     ]
    }
   ],
   "source": [
    "labels_available = os.listdir(os.path.join(dataPath, \"train\"))\n",
    "print(\"Total Number of Classes Detected :\",len(labels_available))\n",
    "\n",
    "labels_list = ['NORMAL',\"CNV\",\"DME\",\"DRUSEN\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NORMAL CNV DME DRUSEN "
     ]
    }
   ],
   "source": [
    "images=[]\n",
    "y_trn=[]\n",
    "for x in labels_list:\n",
    "    xPath = os.path.join(dataPath, \"train\", x)\n",
    "    myPicList = os.listdir(xPath)\n",
    "    for y in myPicList:\n",
    "        images.append(cv2.imread(os.path.join(xPath, y)))\n",
    "        y_trn.append(labels_list.index(x))\n",
    "    print(x ,end=\" \")\n",
    "\n",
    "y_train = to_categorical(y_trn,len(labels_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NORMAL CNV DME DRUSEN "
     ]
    }
   ],
   "source": [
    "x_val=[]\n",
    "y_val=[]\n",
    "for x in labels_list:\n",
    "    xPath = os.path.join(dataPath, \"val\", x)\n",
    "    myPicList = os.listdir(xPath)\n",
    "    for y in myPicList:\n",
    "        x_val.append(cv2.imread(os.path.join(xPath, y)))\n",
    "        y_val.append(labels_list.index(x))\n",
    "    print(x ,end=\" \")\n",
    "\n",
    "y_validation = to_categorical(y_val,len(labels_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NORMAL CNV DME DRUSEN "
     ]
    }
   ],
   "source": [
    "x_tst=[]\n",
    "y_tst=[]\n",
    "for x in labels_list:\n",
    "    xPath = os.path.join(dataPath, \"test\", x)\n",
    "    myPicList = os.listdir(xPath)\n",
    "    for y in myPicList:\n",
    "        x_tst.append(cv2.imread(os.path.join(xPath, y)))\n",
    "        y_tst.append(labels_list.index(x))\n",
    "    print(x ,end=\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of images per category and set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label\t\tTrain\t\tValidation\t\tTest\n",
      "NORMAL\t\t26315\t\t8\t\t\t242\n",
      "CNV\t\t37205\t\t8\t\t\t242\n",
      "DME\t\t11348\t\t8\t\t\t242\n",
      "DRUSEN\t\t8616\t\t8\t\t\t242\n"
     ]
    }
   ],
   "source": [
    "def getNumberOfItems(labels, itemLabel):\n",
    "    return sum(list(map(lambda x: x == itemLabel, labels))) \n",
    "\n",
    "\n",
    "print(\"Label\\t\\tTrain\\t\\tValidation\\t\\tTest\")\n",
    "for i, label in enumerate(labels_list):\n",
    "    print(f\"{label}\\t\\t{getNumberOfItems(y_trn, i)}\\t\\t{getNumberOfItems(y_val, i)}\\t\\t\\t{getNumberOfItems(y_tst, i)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resizeIm(im, size):\n",
    "    if im.shape[2] == 1:\n",
    "        im = cv2.cvtColor(im,cv2.COLOR_GRAY2RGB)\n",
    "    return cv2.resize(im, size)\n",
    "\n",
    "def resizeIms(x, size):\n",
    "    return np.array(list(map(lambda im: resizeIm(im, size), x)))\n",
    "\n",
    "# Substract the mean specified by Mean (https://www.mathworks.com/help/deeplearning/ref/nnet.cnn.layer.imageinputlayer.html)\n",
    "# Substract mean by channel\n",
    "def zerocenter(x):\n",
    "    return (x - np.mean(x, axis=(0, 1))) / (2*np.std(x, axis=(0, 1)))\n",
    "\n",
    "# Rescale the input to be in the range [-1, 1] using the minimum and maximum values specified by Min and Max, respectively. (https://www.mathworks.com/help/deeplearning/ref/nnet.cnn.layer.imageinputlayer.html)\n",
    "# Compute using the formula: $x\\prime = 2 * \\frac{x - \\min{x}}{\\max{x} - \\min{x}} - 1$ taken from: https://stats.stackexchange.com/a/178629\n",
    "def rescaleSymmetric(x):\n",
    "    x = zerocenter(x)\n",
    "    return 2 * (x - np.min(x, axis=(0, 1)))/np.ptp(x, axis=(0, 1)) - 1\n",
    "\n",
    "def normalizeIms(x, normalization):\n",
    "    if normalization == \"zerocenter\":\n",
    "        func = zerocenter\n",
    "    elif normalization == \"rescale-symmetric\":\n",
    "        func = rescaleSymmetric\n",
    "    else:\n",
    "        return x\n",
    "    return np.array(list(map(lambda im: func(im), x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self,fraction, model):\n",
    "        super(CustomCallback,self).__init__()\n",
    "        self.fraction = fraction\n",
    "        self.train_a = [];\n",
    "        self.val_a =[];\n",
    "        self.logPath = os.path.join(model, \"log.txt\")\n",
    "\n",
    "        if not os.path.isdir(model):\n",
    "            os.mkdir(model)\n",
    "\n",
    "        with open(self.logPath,'w') as f:\n",
    "            f.write('Starting of logging..\\n')\n",
    "\n",
    "        self.fig = plt.figure(figsize=(4,3))\n",
    "        self.ax = plt.subplot(1,1,1)\n",
    "        plt.ion()\n",
    "\n",
    "    def on_train_begin(self,logs=None):\n",
    "        self.fig.show()\n",
    "        self.fig.canvas.draw()\n",
    "\n",
    "    def on_train_end(self,logs=None):\n",
    "        with open(self.logPath,'a') as f:\n",
    "              f.write('End of logging..\\n')\n",
    "    \n",
    "    def on_epoch_begin(self,epoch,logs=None):\n",
    "        lr= tf.keras.backend.get_value(self.model.optimizer.lr)\n",
    "        lr *= self.fraction\n",
    "        tf.keras.backend.set_value(self.model.optimizer.lr,lr)\n",
    "        with open(self.logPath,'a') as f:\n",
    "            f.write('At epoch {:02d}, learning rate changed to {:.4f}\\n'.format(epoch,lr))\n",
    "    \n",
    "    def on_epoch_end(self,epoch,logs=None):\n",
    "        val_acc = logs.get('val_accuracy')\n",
    "        train_acc = logs.get('accuracy')\n",
    "        self.train_a.append(train_acc)\n",
    "        self.val_a.append(val_acc)\n",
    "        with open(self.logPath,'a') as f:\n",
    "            f.write('At epoch {:02d}, training accuracy: {:.3f}, validation accuracy: {:.3f}\\n'.format(epoch,train_acc,val_acc))\n",
    "        self.ax.clear()\n",
    "        self.ax.plot(range(1+epoch),self.train_a,label=\"Training\")\n",
    "        self.ax.plot(range(1+epoch),self.val_a,label=\"Validation\")\n",
    "        self.ax.set_xlabel('Epochs')\n",
    "        self.ax.set_ylabel('Accuracy')\n",
    "        self.ax.legend()\n",
    "        self.fig.canvas.draw()\n",
    "        self.fig.show()\n",
    "        \n",
    "class TimeHistory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.times = []\n",
    "\n",
    "    def on_epoch_begin(self, batch, logs={}):\n",
    "        self.epoch_time_start = time.time()\n",
    "\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.times.append(time.time() - self.epoch_time_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "# xception base model\n",
    "#from tensorflow.keras.applications.xception import Xception\n",
    "#from tensorflow.keras.applications.xception import preprocess_input, decode_predictions\n",
    "#xceptionNetModel = Xception(weights='imagenet')\n",
    "#xceptionNetModel.save(\"../Xception.hdf5\")\n",
    "\n",
    "xceptionNetModel = tf.keras.models.load_model('../Xception.hdf5')\n",
    "\n",
    "# opticnet base model\n",
    "opticNetModel = tf.keras.models.load_model('../Optic_net-4_classes-Kermany2018.hdf5')\n",
    "\n",
    "# resnet base model\n",
    "#from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "#from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "#resNetModel = ResNet50(weights='imagenet')\n",
    "#resNetModel.save(\"../Resnet50.hdf5\")\n",
    "\n",
    "resNetModel = tf.keras.models.load_model('../Resnet50.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 221, 221, 32)      4736      \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 221, 221, 32)      128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 110, 110, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 104, 104, 32)      50208     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 104, 104, 32)      128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 52, 52, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 48, 48, 64)        51264     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 48, 48, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 24, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 20, 20, 128)       204928    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 20, 20, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 10, 10, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 8, 8, 256)         295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d (AveragePo (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               131200    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4)                 132       \n",
      "_________________________________________________________________\n",
      "softmax (Softmax)            (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 743,812\n",
      "Trainable params: 742,788\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "conv_init = tf.keras.initializers.RandomNormal(mean=0., stddev=1.) # convolutional layer with zero mean and 1 sd\n",
    "#batch_init = tf.keras.initializers.RandomNormal(mean=1., stddev=0.02) # non-sense here\n",
    "\n",
    "octnet = keras.models.Sequential() # empty model\n",
    "\n",
    "octnet.add(keras.layers.Conv2D(32, (7, 7), activation=\"relu\", use_bias=True, input_shape=(227, 227, 3), kernel_initializer=conv_init))\n",
    "octnet.add(keras.layers.BatchNormalization())\n",
    "octnet.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "octnet.add(keras.layers.Conv2D(32, (7, 7), activation=\"relu\", use_bias=True, kernel_initializer=conv_init))\n",
    "octnet.add(keras.layers.BatchNormalization())\n",
    "octnet.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "octnet.add(keras.layers.Conv2D(64, (5, 5), activation=\"relu\", use_bias=True, kernel_initializer=conv_init))\n",
    "octnet.add(keras.layers.BatchNormalization())\n",
    "octnet.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "octnet.add(keras.layers.Conv2D(128, (5, 5), activation=\"relu\", use_bias=True, kernel_initializer=conv_init))\n",
    "octnet.add(keras.layers.BatchNormalization())\n",
    "octnet.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "octnet.add(keras.layers.Conv2D(256, (3, 3), activation=\"relu\", use_bias=True, kernel_initializer=conv_init))\n",
    "octnet.add(keras.layers.BatchNormalization())\n",
    "octnet.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "#octnet.add(keras.layers.Conv2D(512, (3, 3), activation=\"relu\", use_bias=True))\n",
    "#octnet.add(keras.layers.BatchNormalization())\n",
    "#octnet.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "octnet.add(keras.layers.AveragePooling2D())\n",
    "octnet.add(keras.layers.Flatten())\n",
    "octnet.add(keras.layers.Dense(128))\n",
    "octnet.add(keras.layers.Dropout(0.5))\n",
    "octnet.add(keras.layers.Dense(32))\n",
    "octnet.add(keras.layers.Dropout(0.5))\n",
    "octnet.add(keras.layers.Dense(4))\n",
    "octnet.add(keras.layers.Softmax())\n",
    "\n",
    "octnet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emptyModelGenerator(model, newWeights=False, lastOnly=False):\n",
    "    model = model.lower() # lower case model name\n",
    "    if model == \"resnet\":\n",
    "        x = resNetModel.output\n",
    "        predictions = Dense(len(labels_list), activation='softmax')(x)\n",
    "        newModel = Model(inputs=resNetModel.input, outputs=predictions)\n",
    "        size = (224, 224)\n",
    "        normalization = \"zerocenter\"\n",
    "    elif model == \"xception\":\n",
    "        x = xceptionNetModel.output\n",
    "        predictions = Dense(len(labels_list), activation='softmax')(x)\n",
    "        newModel = Model(inputs=xceptionNetModel.input, outputs=predictions)\n",
    "        size = (299, 299)\n",
    "        normalization = \"rescale-symmetric\"\n",
    "    elif model == \"opticnet\":\n",
    "        newModel = tf.keras.models.load_model('../Optic_net-4_classes-Kermany2018.hdf5')\n",
    "        size = (224, 224)\n",
    "        normalization = \"rescale-symmetric\"\n",
    "    elif model == \"octnet\":\n",
    "        newModel = tf.keras.models.clone_model(octnet)\n",
    "        size = (227, 227)\n",
    "        normalization = \"zerocenter\"\n",
    "    if newWeights:\n",
    "        newModel = tf.keras.models.clone_model(newModel)\n",
    "    if lastOnly:\n",
    "        newModel = lastDenseTrainable(newModel) # block all layer except the last dense ones\n",
    "    else:\n",
    "        newModel.trainable = True\n",
    "    return newModel, size, normalization\n",
    "\n",
    "\n",
    "def lastDenseTrainable(model):\n",
    "    model.trainable = False\n",
    "    for i in range(1, len(model.layers)):\n",
    "        if model.layers[-i].__class__.__name__ == \"Dense\":\n",
    "            model.layers[-i].trainable= True\n",
    "        elif model.layers[-i].__class__.__name__ == \"Activation\":\n",
    "            continue\n",
    "        else:\n",
    "            break\n",
    "    return model\n",
    "    \n",
    "\n",
    "def testPredict(model, size, name=None, normalization=None):\n",
    "    X_test = resizeIms(x_tst, size)\n",
    "    if normalization:\n",
    "        X_test = normalizeIms(X_test, normalization)\n",
    "    X_test = np.array(X_test)\n",
    "    Y_test = np.array(y_tst)\n",
    "    \n",
    "    prediction = model.predict(X_test)\n",
    "    preds = np.argmax(prediction, axis=1)\n",
    "    acc = sum(preds == Y_test) / len(Y_test)\n",
    "    print(f'Test acc for {name if name else \"model\"}: {acc:.6f}')\n",
    "    return acc\n",
    "    \n",
    "\n",
    "def computeConfussionMatrix(predictions, labels):\n",
    "    num_labels = len(labels_list)\n",
    "    cMatrix = np.zeros(shape=(num_labels, num_labels))\n",
    "    for i in len(predictions):\n",
    "        p = int(predictions[i])\n",
    "        t = int(predictions[i])\n",
    "        cMatrix[t, p] += 1\n",
    "    print(cMatrix)\n",
    "    ax = sns.heatmap(cMatrix, cmap=\"Blues\", annot=True, fmt=\"d\", xticklabels=labels_list, yticklabels=labels_list)\n",
    "    plt.xlabel(\"Predicted label\")\n",
    "    plt.ylabel(\"True label\")\n",
    "    plt.title(\"Confusion matrix\")\n",
    "    plt.show();\n",
    "    return cMatrix\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "**************************************************\n",
      "Model: xception\n",
      "**************************************************\n",
      "\n",
      "Total: 135 trainable: 2\n",
      "\n",
      "\n",
      "**************************************************\n",
      "Model: resnet\n",
      "**************************************************\n",
      "\n",
      "Total: 178 trainable: 2\n",
      "\n",
      "\n",
      "**************************************************\n",
      "Model: opticnet\n",
      "**************************************************\n",
      "\n",
      "Total: 276 trainable: 2\n",
      "\n",
      "\n",
      "**************************************************\n",
      "Model: octnet\n",
      "**************************************************\n",
      "\n",
      "Total: 23 trainable: 0\n"
     ]
    }
   ],
   "source": [
    "models = [\"xception\", \"resnet\", \"opticnet\", \"octnet\"]\n",
    "\n",
    "def printTrainableLayers(m):\n",
    "    a = 0\n",
    "    for l in m.layers:\n",
    "        #l.trainable = True\n",
    "        if l.trainable:\n",
    "            #print(l.name, l.trainable)\n",
    "            a += 1\n",
    "    print(f\"\\nTotal: {len(m.layers)} trainable: {a}\")\n",
    "\n",
    "for mod in models:\n",
    "    print(\"\\n\\n\" + (\"*\"*50) + \"\\nModel: \" + mod + '\\n' + (\"*\"*50))\n",
    "    m = emptyModelGenerator(mod, newWeights=False, lastOnly=True)[0]\n",
    "    printTrainableLayers(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "momentum = 0.9\n",
    "optim = lambda lr: Adam(learning_rate=lr)\n",
    "#optim = lambda lr, momentum: SGD(learning_rate=lr, momentum=momentum)\n",
    "epochs = 30\n",
    "batch_size = 50\n",
    "#batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "results = pd.read_csv(\"Results_temp.csv\")\n",
    "results[\"normalization\"] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "es = pd.read_csv(\"Results_temp.csv\")\n",
    "res.to_csv(\"Results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels fraction: [0.0100323  0.01083188 0.00863588 0.00800836]\n",
      "Training octnet for 0.01% of train size (aka 834 images) with pretrained: True and onlyLastLayersTrained: True...\n",
      "\n",
      "Total: 23 trainable: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      " 3/17 [====>.........................] - ETA: 1s - loss: 1093799061.3333 - accuracy: 0.3233 WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0127s vs `on_train_batch_end` time: 0.0228s). Check your callbacks.\n",
      "17/17 [==============================] - 2s 42ms/step - loss: 1104847306.6667 - accuracy: 0.3093 - val_loss: 418593344.0000 - val_accuracy: 0.4688\n",
      "Epoch 2/30\n",
      " 5/17 [=======>......................] - ETA: 0s - loss: 1150179302.4000 - accuracy: 0.3263"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 16ms/step - loss: 1179385016.8889 - accuracy: 0.3119 - val_loss: 418593344.0000 - val_accuracy: 0.4688\n",
      "Epoch 3/30\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 1141976366.2222 - accuracy: 0.3226 - val_loss: 418593344.0000 - val_accuracy: 0.4688\n",
      "Epoch 4/30\n",
      "17/17 [==============================] - 0s 15ms/step - loss: 1087038823.1111 - accuracy: 0.2957 - val_loss: 418593344.0000 - val_accuracy: 0.4688\n",
      "Epoch 5/30\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 1178790584.8889 - accuracy: 0.2919 - val_loss: 418593344.0000 - val_accuracy: 0.4688\n",
      "Epoch 6/30\n",
      "17/17 [==============================] - 0s 15ms/step - loss: 1160533006.2222 - accuracy: 0.2989 - val_loss: 418593344.0000 - val_accuracy: 0.4688\n",
      "Epoch 7/30\n",
      "17/17 [==============================] - 0s 15ms/step - loss: 1182453667.5556 - accuracy: 0.2885 - val_loss: 418593344.0000 - val_accuracy: 0.4688\n",
      "Epoch 8/30\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 1156325589.3333 - accuracy: 0.2876 - val_loss: 418593344.0000 - val_accuracy: 0.4688\n",
      "Epoch 9/30\n",
      "17/17 [==============================] - 0s 15ms/step - loss: 1220623516.4444 - accuracy: 0.2703 - val_loss: 418593344.0000 - val_accuracy: 0.4688\n",
      "Epoch 10/30\n",
      "17/17 [==============================] - 0s 15ms/step - loss: 1085109525.3333 - accuracy: 0.3126 - val_loss: 418593344.0000 - val_accuracy: 0.4688\n",
      "Epoch 11/30\n",
      "17/17 [==============================] - 0s 15ms/step - loss: 1242374606.2222 - accuracy: 0.2811 - val_loss: 418593344.0000 - val_accuracy: 0.4688\n",
      "Epoch 12/30\n",
      "17/17 [==============================] - 0s 15ms/step - loss: 1176908394.6667 - accuracy: 0.2929 - val_loss: 418593344.0000 - val_accuracy: 0.4688\n",
      "Epoch 13/30\n",
      "17/17 [==============================] - 0s 15ms/step - loss: 1187329244.4444 - accuracy: 0.3065 - val_loss: 418593344.0000 - val_accuracy: 0.4688\n",
      "Epoch 14/30\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 1053475089.7778 - accuracy: 0.3385 - val_loss: 418593344.0000 - val_accuracy: 0.4688\n",
      "Epoch 15/30\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 1085197557.3333 - accuracy: 0.3308 - val_loss: 418593344.0000 - val_accuracy: 0.4688\n",
      "Epoch 16/30\n",
      "17/17 [==============================] - 0s 17ms/step - loss: 1001409742.2222 - accuracy: 0.3245 - val_loss: 418593344.0000 - val_accuracy: 0.4688\n",
      "Epoch 17/30\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 1230053340.4444 - accuracy: 0.2779 - val_loss: 418593344.0000 - val_accuracy: 0.4688\n",
      "Epoch 18/30\n",
      "17/17 [==============================] - 0s 15ms/step - loss: 1098888092.4444 - accuracy: 0.3338 - val_loss: 418593344.0000 - val_accuracy: 0.4688\n",
      "Epoch 19/30\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 1161967594.6667 - accuracy: 0.3185 - val_loss: 418593344.0000 - val_accuracy: 0.4688\n",
      "Epoch 20/30\n",
      "17/17 [==============================] - 0s 15ms/step - loss: 1167756359.1111 - accuracy: 0.2840 - val_loss: 418593344.0000 - val_accuracy: 0.4688\n",
      "Epoch 21/30\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 1139261937.7778 - accuracy: 0.2950 - val_loss: 418593344.0000 - val_accuracy: 0.4688\n",
      "Epoch 22/30\n",
      "17/17 [==============================] - 0s 15ms/step - loss: 1230566456.8889 - accuracy: 0.2760 - val_loss: 418593344.0000 - val_accuracy: 0.4688\n",
      "Epoch 23/30\n",
      "17/17 [==============================] - 0s 15ms/step - loss: 1192064675.5556 - accuracy: 0.2949 - val_loss: 418593344.0000 - val_accuracy: 0.4688\n",
      "Epoch 24/30\n",
      "17/17 [==============================] - 0s 15ms/step - loss: 1250283164.4444 - accuracy: 0.2346 - val_loss: 418593344.0000 - val_accuracy: 0.4688\n",
      "Epoch 25/30\n",
      "17/17 [==============================] - 0s 15ms/step - loss: 1242581752.8889 - accuracy: 0.3009 - val_loss: 418593344.0000 - val_accuracy: 0.4688\n",
      "Epoch 26/30\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 1025779516.4444 - accuracy: 0.3405 - val_loss: 418593344.0000 - val_accuracy: 0.4688\n",
      "Epoch 27/30\n",
      "17/17 [==============================] - 0s 15ms/step - loss: 1191666588.4444 - accuracy: 0.3048 - val_loss: 418593344.0000 - val_accuracy: 0.4688\n",
      "Epoch 28/30\n",
      "17/17 [==============================] - 0s 14ms/step - loss: 1235004330.6667 - accuracy: 0.3030 - val_loss: 418593344.0000 - val_accuracy: 0.4688\n",
      "Epoch 29/30\n",
      "17/17 [==============================] - 0s 15ms/step - loss: 1128620480.0000 - accuracy: 0.2896 - val_loss: 418593344.0000 - val_accuracy: 0.4688\n",
      "Epoch 30/30\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 1146687708.4444 - accuracy: 0.2987 - val_loss: 418593344.0000 - val_accuracy: 0.4688\n",
      "INFO:tensorflow:Assets written to: ../octnet/octnet_30epochs_835_images_False_newWeights_True_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for octnet: 0.324380\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.02420673 0.02577611 0.02634826 0.02228412]\n",
      "Training octnet for 0.025% of train size (aka 2087 images) with pretrained: True and onlyLastLayersTrained: True...\n",
      "\n",
      "Total: 23 trainable: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      " 3/42 [=>............................] - ETA: 3s - loss: 1478092160.0000 - accuracy: 0.3667 WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0146s vs `on_train_batch_end` time: 0.0221s). Check your callbacks.\n",
      "42/42 [==============================] - 2s 26ms/step - loss: 1589831432.9302 - accuracy: 0.3163 - val_loss: 1367525632.0000 - val_accuracy: 0.2500\n",
      "Epoch 2/30\n",
      " 5/42 [==>...........................] - ETA: 0s - loss: 1741104435.2000 - accuracy: 0.2712"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 1s 16ms/step - loss: 1683641332.0930 - accuracy: 0.2864 - val_loss: 1367525632.0000 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 1536352696.5581 - accuracy: 0.3295 - val_loss: 1367525632.0000 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 1607041172.8372 - accuracy: 0.2920 - val_loss: 1367525632.0000 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 1583876250.7907 - accuracy: 0.3001 - val_loss: 1367525632.0000 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 1569583800.5581 - accuracy: 0.3137 - val_loss: 1367525632.0000 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 1601990343.4419 - accuracy: 0.3043 - val_loss: 1367525632.0000 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 1657382248.1860 - accuracy: 0.3174 - val_loss: 1367525632.0000 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 1562645408.7442 - accuracy: 0.3074 - val_loss: 1367525632.0000 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 1605979091.3488 - accuracy: 0.3095 - val_loss: 1367525632.0000 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 1583962760.9302 - accuracy: 0.3167 - val_loss: 1367525632.0000 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 1672393245.7674 - accuracy: 0.3143 - val_loss: 1367525632.0000 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 1638771744.7442 - accuracy: 0.2825 - val_loss: 1367525632.0000 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 1586155412.8372 - accuracy: 0.3081 - val_loss: 1367525632.0000 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 1548317374.5116 - accuracy: 0.3282 - val_loss: 1367525632.0000 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 1617936491.1628 - accuracy: 0.3219 - val_loss: 1367525632.0000 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 1614122749.0233 - accuracy: 0.3108 - val_loss: 1367525632.0000 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 1587999184.3721 - accuracy: 0.3017 - val_loss: 1367525632.0000 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 1636031565.3953 - accuracy: 0.3102 - val_loss: 1367525632.0000 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 1636980593.1163 - accuracy: 0.3011 - val_loss: 1367525632.0000 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 1644061707.9070 - accuracy: 0.2971 - val_loss: 1367525632.0000 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 1601864415.2558 - accuracy: 0.2804 - val_loss: 1367525632.0000 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 1559937887.2558 - accuracy: 0.3243 - val_loss: 1367525632.0000 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 1597473768.1860 - accuracy: 0.3042 - val_loss: 1367525632.0000 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 1555706281.6744 - accuracy: 0.3316 - val_loss: 1367525632.0000 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 1641243103.2558 - accuracy: 0.3049 - val_loss: 1367525632.0000 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 1542390298.7907 - accuracy: 0.3070 - val_loss: 1367525632.0000 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 1564578167.0698 - accuracy: 0.3060 - val_loss: 1367525632.0000 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 1552498688.0000 - accuracy: 0.3189 - val_loss: 1367525632.0000 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 1578783059.3488 - accuracy: 0.3267 - val_loss: 1367525632.0000 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../octnet/octnet_30epochs_2087_images_False_newWeights_True_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for octnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.04902147 0.05096089 0.0489073  0.05025534]\n",
      "Training octnet for 0.05% of train size (aka 4174 images) with pretrained: True and onlyLastLayersTrained: True...\n",
      "\n",
      "Total: 23 trainable: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      " 3/84 [>.............................] - ETA: 6s - loss: 1668716842.6667 - accuracy: 0.2267 WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0136s vs `on_train_batch_end` time: 0.0208s). Check your callbacks.\n",
      "84/84 [==============================] - 2s 19ms/step - loss: 1670507474.8235 - accuracy: 0.2435 - val_loss: 350031616.0000 - val_accuracy: 0.3125\n",
      "Epoch 2/30\n",
      " 6/84 [=>............................] - ETA: 0s - loss: 1966538986.6667 - accuracy: 0.2580"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84/84 [==============================] - 1s 14ms/step - loss: 1731134605.5529 - accuracy: 0.2448 - val_loss: 350031616.0000 - val_accuracy: 0.3125\n",
      "Epoch 3/30\n",
      "84/84 [==============================] - 1s 14ms/step - loss: 1781662498.6353 - accuracy: 0.2368 - val_loss: 350031616.0000 - val_accuracy: 0.3125\n",
      "Epoch 4/30\n",
      "84/84 [==============================] - 1s 14ms/step - loss: 1758830473.0353 - accuracy: 0.2302 - val_loss: 350031616.0000 - val_accuracy: 0.3125\n",
      "Epoch 5/30\n",
      "84/84 [==============================] - 1s 14ms/step - loss: 1735866468.8941 - accuracy: 0.2344 - val_loss: 350031616.0000 - val_accuracy: 0.3125\n",
      "Epoch 6/30\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 1714962951.5294 - accuracy: 0.2511 - val_loss: 350031616.0000 - val_accuracy: 0.3125\n",
      "Epoch 7/30\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 1667009523.9529 - accuracy: 0.2548 - val_loss: 350031616.0000 - val_accuracy: 0.3125\n",
      "Epoch 8/30\n",
      "84/84 [==============================] - 1s 14ms/step - loss: 1711184117.4588 - accuracy: 0.2422 - val_loss: 350031616.0000 - val_accuracy: 0.3125\n",
      "Epoch 9/30\n",
      "84/84 [==============================] - 1s 14ms/step - loss: 1637811350.5882 - accuracy: 0.2458 - val_loss: 350031616.0000 - val_accuracy: 0.3125\n",
      "Epoch 10/30\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 1720057258.1647 - accuracy: 0.2442 - val_loss: 350031616.0000 - val_accuracy: 0.3125\n",
      "Epoch 11/30\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 1747214537.7882 - accuracy: 0.2324 - val_loss: 350031616.0000 - val_accuracy: 0.3125\n",
      "Epoch 12/30\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 1737164869.2706 - accuracy: 0.2195 - val_loss: 350031616.0000 - val_accuracy: 0.3125\n",
      "Epoch 13/30\n",
      "84/84 [==============================] - 1s 14ms/step - loss: 1710152670.8706 - accuracy: 0.2354 - val_loss: 350031616.0000 - val_accuracy: 0.3125\n",
      "Epoch 14/30\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 1727007647.6235 - accuracy: 0.2459 - val_loss: 350031616.0000 - val_accuracy: 0.3125\n",
      "Epoch 15/30\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 1743004902.4000 - accuracy: 0.2360 - val_loss: 350031616.0000 - val_accuracy: 0.3125\n",
      "Epoch 16/30\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 1703148098.2588 - accuracy: 0.2608 - val_loss: 350031616.0000 - val_accuracy: 0.3125\n",
      "Epoch 17/30\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 1732920571.4824 - accuracy: 0.2288 - val_loss: 350031616.0000 - val_accuracy: 0.3125\n",
      "Epoch 18/30\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 1716393216.0000 - accuracy: 0.2371 - val_loss: 350031616.0000 - val_accuracy: 0.3125\n",
      "Epoch 19/30\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 1731417289.7882 - accuracy: 0.2316 - val_loss: 350031616.0000 - val_accuracy: 0.3125\n",
      "Epoch 20/30\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 1694005922.6353 - accuracy: 0.2347 - val_loss: 350031616.0000 - val_accuracy: 0.3125\n",
      "Epoch 21/30\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 1722490071.3412 - accuracy: 0.2368 - val_loss: 350031616.0000 - val_accuracy: 0.3125\n",
      "Epoch 22/30\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 1758400096.3765 - accuracy: 0.2260 - val_loss: 350031616.0000 - val_accuracy: 0.3125\n",
      "Epoch 23/30\n",
      "84/84 [==============================] - 1s 14ms/step - loss: 1761516063.6235 - accuracy: 0.2378 - val_loss: 350031616.0000 - val_accuracy: 0.3125\n",
      "Epoch 24/30\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 1655674839.3412 - accuracy: 0.2373 - val_loss: 350031616.0000 - val_accuracy: 0.3125\n",
      "Epoch 25/30\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 1753163870.8706 - accuracy: 0.2274 - val_loss: 350031616.0000 - val_accuracy: 0.3125\n",
      "Epoch 26/30\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 1727975795.9529 - accuracy: 0.2440 - val_loss: 350031616.0000 - val_accuracy: 0.3125\n",
      "Epoch 27/30\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 1687783392.3765 - accuracy: 0.2367 - val_loss: 350031616.0000 - val_accuracy: 0.3125\n",
      "Epoch 28/30\n",
      "84/84 [==============================] - 1s 13ms/step - loss: 1658154857.4118 - accuracy: 0.2441 - val_loss: 350031616.0000 - val_accuracy: 0.3125\n",
      "Epoch 29/30\n",
      "84/84 [==============================] - 1s 12ms/step - loss: 1705174302.1176 - accuracy: 0.2534 - val_loss: 350031616.0000 - val_accuracy: 0.3125\n",
      "Epoch 30/30\n",
      "84/84 [==============================] - 1s 14ms/step - loss: 1697379088.5647 - accuracy: 0.2332 - val_loss: 350031616.0000 - val_accuracy: 0.3125\n",
      "INFO:tensorflow:Assets written to: ../octnet/octnet_30epochs_4174_images_False_newWeights_True_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for octnet: 0.246901\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.07501425 0.07571563 0.07340501 0.07393222]\n",
      "Training octnet for 0.075% of train size (aka 6261 images) with pretrained: True and onlyLastLayersTrained: True...\n",
      "\n",
      "Total: 23 trainable: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/126 [>.............................] - ETA: 4s - loss: 1863631424.0000 - accuracy: 0.2238 WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0137s vs `on_train_batch_end` time: 0.0221s). Check your callbacks.\n",
      "126/126 [==============================] - 3s 17ms/step - loss: 1943225908.4094 - accuracy: 0.1980 - val_loss: 515259328.0000 - val_accuracy: 0.2188\n",
      "Epoch 2/30\n",
      "  6/126 [>.............................] - ETA: 1s - loss: 2010437418.6667 - accuracy: 0.1471"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126/126 [==============================] - 2s 12ms/step - loss: 1982321454.3622 - accuracy: 0.1850 - val_loss: 515259328.0000 - val_accuracy: 0.2188\n",
      "Epoch 3/30\n",
      "126/126 [==============================] - 2s 13ms/step - loss: 1978635311.3701 - accuracy: 0.1993 - val_loss: 515259328.0000 - val_accuracy: 0.2188\n",
      "Epoch 4/30\n",
      "126/126 [==============================] - 2s 12ms/step - loss: 2039884132.7874 - accuracy: 0.1856 - val_loss: 515259328.0000 - val_accuracy: 0.2188\n",
      "Epoch 5/30\n",
      "126/126 [==============================] - 2s 13ms/step - loss: 1960368149.1654 - accuracy: 0.1861 - val_loss: 515259328.0000 - val_accuracy: 0.2188\n",
      "Epoch 6/30\n",
      "126/126 [==============================] - 2s 12ms/step - loss: 2044289071.3701 - accuracy: 0.1896 - val_loss: 515259328.0000 - val_accuracy: 0.2188\n",
      "Epoch 7/30\n",
      "126/126 [==============================] - 2s 13ms/step - loss: 1912524243.6535 - accuracy: 0.1930 - val_loss: 515259328.0000 - val_accuracy: 0.2188\n",
      "Epoch 8/30\n",
      "126/126 [==============================] - 2s 12ms/step - loss: 1937907933.7323 - accuracy: 0.1967 - val_loss: 515259328.0000 - val_accuracy: 0.2188\n",
      "Epoch 9/30\n",
      "126/126 [==============================] - 2s 13ms/step - loss: 1940512051.4016 - accuracy: 0.1991 - val_loss: 515259328.0000 - val_accuracy: 0.2188\n",
      "Epoch 10/30\n",
      "126/126 [==============================] - 2s 13ms/step - loss: 1939036972.3465 - accuracy: 0.1964 - val_loss: 515259328.0000 - val_accuracy: 0.2188\n",
      "Epoch 11/30\n",
      "126/126 [==============================] - 2s 13ms/step - loss: 1909925606.8031 - accuracy: 0.2066 - val_loss: 515259328.0000 - val_accuracy: 0.2188\n",
      "Epoch 12/30\n",
      "126/126 [==============================] - 2s 13ms/step - loss: 1957700652.3465 - accuracy: 0.1963 - val_loss: 515259328.0000 - val_accuracy: 0.2188\n",
      "Epoch 13/30\n",
      "126/126 [==============================] - 2s 12ms/step - loss: 1999950134.4252 - accuracy: 0.1777 - val_loss: 515259328.0000 - val_accuracy: 0.2188\n",
      "Epoch 14/30\n",
      "126/126 [==============================] - 2s 13ms/step - loss: 1953500844.3465 - accuracy: 0.1898 - val_loss: 515259328.0000 - val_accuracy: 0.2188\n",
      "Epoch 15/30\n",
      "126/126 [==============================] - 2s 12ms/step - loss: 2000001100.5984 - accuracy: 0.1843 - val_loss: 515259328.0000 - val_accuracy: 0.2188\n",
      "Epoch 16/30\n",
      "126/126 [==============================] - 2s 13ms/step - loss: 2058807814.0472 - accuracy: 0.1860 - val_loss: 515259328.0000 - val_accuracy: 0.2188\n",
      "Epoch 17/30\n",
      "126/126 [==============================] - 2s 13ms/step - loss: 1944413626.4567 - accuracy: 0.2002 - val_loss: 515259328.0000 - val_accuracy: 0.2188\n",
      "Epoch 18/30\n",
      "126/126 [==============================] - 2s 13ms/step - loss: 1940047259.2126 - accuracy: 0.1963 - val_loss: 515259328.0000 - val_accuracy: 0.2188\n",
      "Epoch 19/30\n",
      "126/126 [==============================] - 2s 12ms/step - loss: 1966409414.5512 - accuracy: 0.1869 - val_loss: 515259328.0000 - val_accuracy: 0.2188\n",
      "Epoch 20/30\n",
      "126/126 [==============================] - 2s 13ms/step - loss: 1984921356.0945 - accuracy: 0.1874 - val_loss: 515259328.0000 - val_accuracy: 0.2188\n",
      "Epoch 21/30\n",
      "126/126 [==============================] - 2s 13ms/step - loss: 1932338637.6063 - accuracy: 0.2001 - val_loss: 515259328.0000 - val_accuracy: 0.2188\n",
      "Epoch 22/30\n",
      "126/126 [==============================] - 2s 12ms/step - loss: 1952906272.2520 - accuracy: 0.1964 - val_loss: 515259328.0000 - val_accuracy: 0.2188\n",
      "Epoch 23/30\n",
      "126/126 [==============================] - 2s 12ms/step - loss: 1960256051.4016 - accuracy: 0.1959 - val_loss: 515259328.0000 - val_accuracy: 0.2188\n",
      "Epoch 24/30\n",
      "126/126 [==============================] - 2s 12ms/step - loss: 1972422172.2205 - accuracy: 0.1940 - val_loss: 515259328.0000 - val_accuracy: 0.2188\n",
      "Epoch 25/30\n",
      "126/126 [==============================] - 2s 12ms/step - loss: 1888259318.9291 - accuracy: 0.1995 - val_loss: 515259328.0000 - val_accuracy: 0.2188\n",
      "Epoch 26/30\n",
      "126/126 [==============================] - 2s 12ms/step - loss: 1912037852.7244 - accuracy: 0.1946 - val_loss: 515259328.0000 - val_accuracy: 0.2188\n",
      "Epoch 27/30\n",
      "126/126 [==============================] - 2s 12ms/step - loss: 2000366465.0079 - accuracy: 0.1919 - val_loss: 515259328.0000 - val_accuracy: 0.2188\n",
      "Epoch 28/30\n",
      "126/126 [==============================] - 2s 12ms/step - loss: 1963855604.9134 - accuracy: 0.1869 - val_loss: 515259328.0000 - val_accuracy: 0.2188\n",
      "Epoch 29/30\n",
      "126/126 [==============================] - 2s 12ms/step - loss: 1920930125.6063 - accuracy: 0.2221 - val_loss: 515259328.0000 - val_accuracy: 0.2188\n",
      "Epoch 30/30\n",
      "126/126 [==============================] - 2s 13ms/step - loss: 1917105636.7874 - accuracy: 0.1984 - val_loss: 515259328.0000 - val_accuracy: 0.2188\n",
      "INFO:tensorflow:Assets written to: ../octnet/octnet_30epochs_6261_images_False_newWeights_True_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for octnet: 0.229339\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.08956869 0.0906061  0.09067677 0.08774373]\n",
      "Training octnet for 0.09% of train size (aka 7513 images) with pretrained: True and onlyLastLayersTrained: True...\n",
      "\n",
      "Total: 23 trainable: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  3/151 [..............................] - ETA: 11s - loss: 2781579690.6667 - accuracy: 0.2278 WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0126s vs `on_train_batch_end` time: 0.0210s). Check your callbacks.\n",
      "151/151 [==============================] - 3s 15ms/step - loss: 2723168591.1579 - accuracy: 0.2924 - val_loss: 1967168256.0000 - val_accuracy: 0.2500\n",
      "Epoch 2/30\n",
      "  6/151 [>.............................] - ETA: 1s - loss: 2568954026.6667 - accuracy: 0.3015"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151/151 [==============================] - 2s 12ms/step - loss: 2701425744.8421 - accuracy: 0.2849 - val_loss: 1967168256.0000 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "151/151 [==============================] - 2s 12ms/step - loss: 2781928030.3158 - accuracy: 0.2743 - val_loss: 1967168256.0000 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "151/151 [==============================] - 2s 13ms/step - loss: 2720687567.1579 - accuracy: 0.2994 - val_loss: 1967168256.0000 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "151/151 [==============================] - 2s 13ms/step - loss: 2716213249.6842 - accuracy: 0.2930 - val_loss: 1967168256.0000 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "151/151 [==============================] - 2s 12ms/step - loss: 2833365061.0526 - accuracy: 0.2851 - val_loss: 1967168256.0000 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "151/151 [==============================] - 2s 12ms/step - loss: 2680749588.2105 - accuracy: 0.2934 - val_loss: 1967168256.0000 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "151/151 [==============================] - 2s 12ms/step - loss: 2655371636.2105 - accuracy: 0.2896 - val_loss: 1967168256.0000 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "151/151 [==============================] - 2s 12ms/step - loss: 2706499499.7895 - accuracy: 0.2967 - val_loss: 1967168256.0000 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "151/151 [==============================] - 2s 12ms/step - loss: 2700155678.3158 - accuracy: 0.2935 - val_loss: 1967168256.0000 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "151/151 [==============================] - 2s 12ms/step - loss: 2716955334.7368 - accuracy: 0.2988 - val_loss: 1967168256.0000 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "151/151 [==============================] - 2s 12ms/step - loss: 2653981130.1053 - accuracy: 0.2957 - val_loss: 1967168256.0000 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "151/151 [==============================] - 2s 12ms/step - loss: 2752719609.2632 - accuracy: 0.2957 - val_loss: 1967168256.0000 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "151/151 [==============================] - 2s 12ms/step - loss: 2688109507.3684 - accuracy: 0.3002 - val_loss: 1967168256.0000 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "151/151 [==============================] - 2s 12ms/step - loss: 2724825254.7368 - accuracy: 0.2909 - val_loss: 1967168256.0000 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "151/151 [==============================] - 2s 12ms/step - loss: 2707486681.2632 - accuracy: 0.2954 - val_loss: 1967168256.0000 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "151/151 [==============================] - 2s 12ms/step - loss: 2687985562.9474 - accuracy: 0.2941 - val_loss: 1967168256.0000 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "151/151 [==============================] - 2s 12ms/step - loss: 2775468035.3684 - accuracy: 0.2901 - val_loss: 1967168256.0000 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "151/151 [==============================] - 2s 13ms/step - loss: 2753250266.9474 - accuracy: 0.2828 - val_loss: 1967168256.0000 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "151/151 [==============================] - 2s 12ms/step - loss: 2747190666.1053 - accuracy: 0.2857 - val_loss: 1967168256.0000 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "151/151 [==============================] - 2s 12ms/step - loss: 2724048469.8947 - accuracy: 0.2849 - val_loss: 1967168256.0000 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "151/151 [==============================] - 2s 13ms/step - loss: 2633971880.4211 - accuracy: 0.3038 - val_loss: 1967168256.0000 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "151/151 [==============================] - 2s 13ms/step - loss: 2718550458.1053 - accuracy: 0.2964 - val_loss: 1967168256.0000 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "151/151 [==============================] - 2s 13ms/step - loss: 2723781037.4737 - accuracy: 0.2941 - val_loss: 1967168256.0000 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "151/151 [==============================] - 2s 12ms/step - loss: 2709847877.0526 - accuracy: 0.2881 - val_loss: 1967168256.0000 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "151/151 [==============================] - 2s 13ms/step - loss: 2707127785.2632 - accuracy: 0.2917 - val_loss: 1967168256.0000 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "151/151 [==============================] - 2s 13ms/step - loss: 2737818883.3684 - accuracy: 0.2923 - val_loss: 1967168256.0000 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "151/151 [==============================] - 2s 13ms/step - loss: 2680607270.7368 - accuracy: 0.2881 - val_loss: 1967168256.0000 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "151/151 [==============================] - 2s 13ms/step - loss: 2732811919.1579 - accuracy: 0.2951 - val_loss: 1967168256.0000 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "151/151 [==============================] - 2s 12ms/step - loss: 2631609498.9474 - accuracy: 0.2981 - val_loss: 1967168256.0000 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../octnet/octnet_30epochs_7514_images_False_newWeights_True_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for octnet: 0.245868\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.09804294 0.10108856 0.10213253 0.09842154]\n",
      "Training octnet for 0.1% of train size (aka 8348 images) with pretrained: True and onlyLastLayersTrained: True...\n",
      "\n",
      "Total: 23 trainable: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  3/167 [..............................] - ETA: 11s - loss: 1344275712.0000 - accuracy: 0.2833 WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0125s vs `on_train_batch_end` time: 0.0197s). Check your callbacks.\n",
      "167/167 [==============================] - 3s 15ms/step - loss: 1048090481.9048 - accuracy: 0.3227 - val_loss: 726021376.0000 - val_accuracy: 0.2500\n",
      "Epoch 2/30\n",
      "  6/167 [>.............................] - ETA: 1s - loss: 1182249258.6667 - accuracy: 0.2923"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "167/167 [==============================] - 2s 12ms/step - loss: 1072286839.2381 - accuracy: 0.3121 - val_loss: 726021376.0000 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "167/167 [==============================] - 2s 12ms/step - loss: 1060430872.3810 - accuracy: 0.3234 - val_loss: 726021376.0000 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "167/167 [==============================] - 2s 12ms/step - loss: 1064150750.0952 - accuracy: 0.3183 - val_loss: 726021376.0000 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "167/167 [==============================] - 2s 12ms/step - loss: 1095292506.6667 - accuracy: 0.3153 - val_loss: 726021376.0000 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "167/167 [==============================] - 2s 12ms/step - loss: 1063890088.7619 - accuracy: 0.3274 - val_loss: 726021376.0000 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "167/167 [==============================] - 2s 12ms/step - loss: 1090554282.2857 - accuracy: 0.3113 - val_loss: 726021376.0000 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "167/167 [==============================] - 2s 12ms/step - loss: 1065955014.8571 - accuracy: 0.3241 - val_loss: 726021376.0000 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "167/167 [==============================] - 2s 12ms/step - loss: 1085410354.2857 - accuracy: 0.3166 - val_loss: 726021376.0000 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "167/167 [==============================] - 2s 12ms/step - loss: 1121924422.8571 - accuracy: 0.3010 - val_loss: 726021376.0000 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "167/167 [==============================] - 2s 12ms/step - loss: 1073351884.5714 - accuracy: 0.3193 - val_loss: 726021376.0000 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "167/167 [==============================] - 2s 12ms/step - loss: 1078617011.8095 - accuracy: 0.3160 - val_loss: 726021376.0000 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "167/167 [==============================] - 2s 13ms/step - loss: 1091746798.4762 - accuracy: 0.3177 - val_loss: 726021376.0000 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "167/167 [==============================] - 2s 13ms/step - loss: 1076499484.1905 - accuracy: 0.3094 - val_loss: 726021376.0000 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "167/167 [==============================] - 2s 13ms/step - loss: 1113793460.5714 - accuracy: 0.3028 - val_loss: 726021376.0000 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "167/167 [==============================] - 2s 12ms/step - loss: 1063873855.2381 - accuracy: 0.3345 - val_loss: 726021376.0000 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "167/167 [==============================] - 2s 13ms/step - loss: 1057160208.7619 - accuracy: 0.3129 - val_loss: 726021376.0000 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "167/167 [==============================] - 2s 13ms/step - loss: 1073697739.4286 - accuracy: 0.3191 - val_loss: 726021376.0000 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "167/167 [==============================] - 2s 12ms/step - loss: 1072908934.4762 - accuracy: 0.3210 - val_loss: 726021376.0000 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "167/167 [==============================] - 2s 13ms/step - loss: 1108269664.0000 - accuracy: 0.3113 - val_loss: 726021376.0000 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "167/167 [==============================] - 2s 13ms/step - loss: 1086314500.5714 - accuracy: 0.3262 - val_loss: 726021376.0000 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "167/167 [==============================] - 2s 12ms/step - loss: 1084305971.4286 - accuracy: 0.3148 - val_loss: 726021376.0000 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "167/167 [==============================] - 2s 13ms/step - loss: 1081574890.6667 - accuracy: 0.3119 - val_loss: 726021376.0000 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "167/167 [==============================] - 2s 13ms/step - loss: 1086709688.0000 - accuracy: 0.3197 - val_loss: 726021376.0000 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "167/167 [==============================] - 2s 12ms/step - loss: 1075986073.9048 - accuracy: 0.3255 - val_loss: 726021376.0000 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "167/167 [==============================] - 2s 13ms/step - loss: 1066551247.2381 - accuracy: 0.3186 - val_loss: 726021376.0000 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "167/167 [==============================] - 2s 13ms/step - loss: 1103033371.8095 - accuracy: 0.3115 - val_loss: 726021376.0000 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "167/167 [==============================] - 2s 12ms/step - loss: 1063467057.9048 - accuracy: 0.3310 - val_loss: 726021376.0000 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "167/167 [==============================] - 2s 13ms/step - loss: 1091723121.9048 - accuracy: 0.3094 - val_loss: 726021376.0000 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "167/167 [==============================] - 2s 13ms/step - loss: 1074389821.3333 - accuracy: 0.3276 - val_loss: 726021376.0000 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../octnet/octnet_30epochs_8348_images_False_newWeights_True_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for octnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.25061752 0.25077275 0.247092   0.24860724]\n",
      "Training octnet for 0.25% of train size (aka 20871 images) with pretrained: True and onlyLastLayersTrained: True...\n",
      "\n",
      "Total: 23 trainable: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  3/418 [..............................] - ETA: 30s - loss: 1175368490.6667 - accuracy: 0.1811 WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0131s vs `on_train_batch_end` time: 0.0199s). Check your callbacks.\n",
      "418/418 [==============================] - 6s 13ms/step - loss: 1246816557.2124 - accuracy: 0.2129 - val_loss: 468025120.0000 - val_accuracy: 0.2500\n",
      "Epoch 2/30\n",
      "  6/418 [..............................] - ETA: 5s - loss: 1228837504.0000 - accuracy: 0.2177"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "418/418 [==============================] - 5s 12ms/step - loss: 1250976479.6181 - accuracy: 0.2151 - val_loss: 468025120.0000 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "418/418 [==============================] - 5s 12ms/step - loss: 1279343875.9714 - accuracy: 0.2074 - val_loss: 468025120.0000 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "418/418 [==============================] - 5s 12ms/step - loss: 1270313074.5585 - accuracy: 0.2127 - val_loss: 468025120.0000 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "418/418 [==============================] - 5s 12ms/step - loss: 1260529590.9881 - accuracy: 0.2085 - val_loss: 468025120.0000 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "418/418 [==============================] - 5s 12ms/step - loss: 1264885169.1838 - accuracy: 0.2140 - val_loss: 468025120.0000 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "418/418 [==============================] - 5s 12ms/step - loss: 1272890675.0167 - accuracy: 0.2136 - val_loss: 468025120.0000 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "418/418 [==============================] - 5s 12ms/step - loss: 1263451471.4272 - accuracy: 0.2088 - val_loss: 468025120.0000 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "418/418 [==============================] - 5s 12ms/step - loss: 1272248053.3079 - accuracy: 0.2128 - val_loss: 468025120.0000 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "418/418 [==============================] - 5s 12ms/step - loss: 1264668950.9117 - accuracy: 0.2112 - val_loss: 468025120.0000 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "418/418 [==============================] - 5s 12ms/step - loss: 1276419369.2411 - accuracy: 0.2127 - val_loss: 468025120.0000 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "418/418 [==============================] - 5s 12ms/step - loss: 1256495618.1384 - accuracy: 0.2160 - val_loss: 468025120.0000 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "418/418 [==============================] - 5s 12ms/step - loss: 1277522556.7924 - accuracy: 0.2109 - val_loss: 468025120.0000 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "418/418 [==============================] - 5s 12ms/step - loss: 1268448860.2578 - accuracy: 0.2060 - val_loss: 468025120.0000 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "418/418 [==============================] - 5s 12ms/step - loss: 1260245957.9570 - accuracy: 0.2147 - val_loss: 468025120.0000 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "418/418 [==============================] - 5s 12ms/step - loss: 1252971753.0883 - accuracy: 0.2122 - val_loss: 468025120.0000 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "418/418 [==============================] - 5s 12ms/step - loss: 1260303643.7995 - accuracy: 0.2110 - val_loss: 468025120.0000 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "418/418 [==============================] - 5s 12ms/step - loss: 1246270017.0692 - accuracy: 0.2189 - val_loss: 468025120.0000 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "418/418 [==============================] - 5s 12ms/step - loss: 1267359529.2411 - accuracy: 0.2156 - val_loss: 468025120.0000 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "418/418 [==============================] - 5s 12ms/step - loss: 1254662645.4606 - accuracy: 0.2165 - val_loss: 468025120.0000 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "418/418 [==============================] - 5s 12ms/step - loss: 1279615668.5442 - accuracy: 0.2085 - val_loss: 468025120.0000 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "418/418 [==============================] - 5s 12ms/step - loss: 1249570322.9403 - accuracy: 0.2138 - val_loss: 468025120.0000 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "418/418 [==============================] - 5s 12ms/step - loss: 1256045663.6181 - accuracy: 0.2148 - val_loss: 468025120.0000 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "418/418 [==============================] - 5s 12ms/step - loss: 1258504076.5251 - accuracy: 0.2138 - val_loss: 468025120.0000 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "418/418 [==============================] - 5s 12ms/step - loss: 1261391492.5823 - accuracy: 0.2147 - val_loss: 468025120.0000 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "418/418 [==============================] - 5s 12ms/step - loss: 1290398181.4224 - accuracy: 0.2052 - val_loss: 468025120.0000 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "418/418 [==============================] - 5s 12ms/step - loss: 1267364633.0501 - accuracy: 0.2089 - val_loss: 468025120.0000 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "418/418 [==============================] - 5s 12ms/step - loss: 1274112029.0215 - accuracy: 0.2158 - val_loss: 468025120.0000 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "418/418 [==============================] - 5s 12ms/step - loss: 1259801982.1671 - accuracy: 0.2208 - val_loss: 468025120.0000 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "418/418 [==============================] - 5s 12ms/step - loss: 1275789040.4200 - accuracy: 0.2072 - val_loss: 468025120.0000 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../octnet/octnet_30epochs_20871_images_False_newWeights_True_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for octnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.39931598 0.39956995 0.40236165 0.40076602]\n",
      "Training octnet for 0.4% of train size (aka 33393 images) with pretrained: True and onlyLastLayersTrained: True...\n",
      "\n",
      "Total: 23 trainable: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:15: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  self.fig = plt.figure(figsize=(4,3))\n",
      "<ipython-input-11-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  3/668 [..............................] - ETA: 47s - loss: 1568552448.0000 - accuracy: 0.2356 WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0125s vs `on_train_batch_end` time: 0.0199s). Check your callbacks.\n",
      "668/668 [==============================] - 9s 13ms/step - loss: 1763511185.0284 - accuracy: 0.2524 - val_loss: 572746368.0000 - val_accuracy: 0.2500\n",
      "Epoch 2/30\n",
      "  6/668 [..............................] - ETA: 8s - loss: 1777138986.6667 - accuracy: 0.2567"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "668/668 [==============================] - 8s 12ms/step - loss: 1779415654.9357 - accuracy: 0.2469 - val_loss: 572746368.0000 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "668/668 [==============================] - 8s 12ms/step - loss: 1777728317.2257 - accuracy: 0.2517 - val_loss: 572746368.0000 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "668/668 [==============================] - 8s 12ms/step - loss: 1764018685.5127 - accuracy: 0.2518 - val_loss: 572746368.0000 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "668/668 [==============================] - 8s 12ms/step - loss: 1774268438.1943 - accuracy: 0.2500 - val_loss: 572746368.0000 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "668/668 [==============================] - 8s 12ms/step - loss: 1767181388.9148 - accuracy: 0.2561 - val_loss: 572746368.0000 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "668/668 [==============================] - 8s 12ms/step - loss: 1786922313.0882 - accuracy: 0.2501 - val_loss: 572746368.0000 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "668/668 [==============================] - 8s 12ms/step - loss: 1770564016.0239 - accuracy: 0.2543 - val_loss: 572746368.0000 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "668/668 [==============================] - 8s 12ms/step - loss: 1796209674.5232 - accuracy: 0.2448 - val_loss: 572746368.0000 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "668/668 [==============================] - 8s 12ms/step - loss: 1781588640.9088 - accuracy: 0.2527 - val_loss: 572746368.0000 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "668/668 [==============================] - 8s 12ms/step - loss: 1776541528.9686 - accuracy: 0.2508 - val_loss: 572746368.0000 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "668/668 [==============================] - 8s 12ms/step - loss: 1757990949.8834 - accuracy: 0.2549 - val_loss: 572746368.0000 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "668/668 [==============================] - 8s 12ms/step - loss: 1771413782.5770 - accuracy: 0.2477 - val_loss: 572746368.0000 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "668/668 [==============================] - 8s 12ms/step - loss: 1792679232.6697 - accuracy: 0.2484 - val_loss: 572746368.0000 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "668/668 [==============================] - 8s 12ms/step - loss: 1798051941.5964 - accuracy: 0.2479 - val_loss: 572746368.0000 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "668/668 [==============================] - 8s 12ms/step - loss: 1778146885.0703 - accuracy: 0.2455 - val_loss: 572746368.0000 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "668/668 [==============================] - 8s 12ms/step - loss: 1802877994.4753 - accuracy: 0.2518 - val_loss: 572746368.0000 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "668/668 [==============================] - 8s 12ms/step - loss: 1788643831.0075 - accuracy: 0.2535 - val_loss: 572746368.0000 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "668/668 [==============================] - 8s 12ms/step - loss: 1757072200.8969 - accuracy: 0.2522 - val_loss: 572746368.0000 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "668/668 [==============================] - 8s 12ms/step - loss: 1761102992.6457 - accuracy: 0.2575 - val_loss: 572746368.0000 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "668/668 [==============================] - 8s 12ms/step - loss: 1790488781.4888 - accuracy: 0.2467 - val_loss: 572746368.0000 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "668/668 [==============================] - 8s 12ms/step - loss: 1791905195.2407 - accuracy: 0.2465 - val_loss: 572746368.0000 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "668/668 [==============================] - 8s 12ms/step - loss: 1807933498.1644 - accuracy: 0.2406 - val_loss: 572746368.0000 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "668/668 [==============================] - 8s 12ms/step - loss: 1791895909.5964 - accuracy: 0.2483 - val_loss: 572746368.0000 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "668/668 [==============================] - 8s 12ms/step - loss: 1769507172.8311 - accuracy: 0.2523 - val_loss: 572746368.0000 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "668/668 [==============================] - 8s 12ms/step - loss: 1774821859.3004 - accuracy: 0.2517 - val_loss: 572746368.0000 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "668/668 [==============================] - 8s 12ms/step - loss: 1776414132.6158 - accuracy: 0.2521 - val_loss: 572746368.0000 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "668/668 [==============================] - 8s 12ms/step - loss: 1785174028.0538 - accuracy: 0.2483 - val_loss: 572746368.0000 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "668/668 [==============================] - 8s 12ms/step - loss: 1773291054.3019 - accuracy: 0.2548 - val_loss: 572746368.0000 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "668/668 [==============================] - 8s 12ms/step - loss: 1773934049.1958 - accuracy: 0.2536 - val_loss: 572746368.0000 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../octnet/octnet_30epochs_33394_images_False_newWeights_True_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for octnet: 0.268595\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.50279308 0.49955651 0.50035249 0.49292015]\n",
      "Training octnet for 0.5% of train size (aka 41742 images) with pretrained: True and onlyLastLayersTrained: True...\n",
      "\n",
      "Total: 23 trainable: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  3/835 [..............................] - ETA: 1:01 - loss: 1527616896.0000 - accuracy: 0.2556WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0128s vs `on_train_batch_end` time: 0.0207s). Check your callbacks.\n",
      "835/835 [==============================] - 11s 13ms/step - loss: 1660689324.8612 - accuracy: 0.2622 - val_loss: 665585920.0000 - val_accuracy: 0.2188\n",
      "Epoch 2/30\n",
      "  6/835 [..............................] - ETA: 10s - loss: 1715868928.0000 - accuracy: 0.2798"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "835/835 [==============================] - 10s 12ms/step - loss: 1685963809.5311 - accuracy: 0.2619 - val_loss: 665585920.0000 - val_accuracy: 0.2188\n",
      "Epoch 3/30\n",
      "835/835 [==============================] - 10s 12ms/step - loss: 1668076112.0766 - accuracy: 0.2613 - val_loss: 665585920.0000 - val_accuracy: 0.2188\n",
      "Epoch 4/30\n",
      "835/835 [==============================] - 10s 12ms/step - loss: 1643872413.0909 - accuracy: 0.2627 - val_loss: 665585920.0000 - val_accuracy: 0.2188\n",
      "Epoch 5/30\n",
      "835/835 [==============================] - 10s 12ms/step - loss: 1660045523.2919 - accuracy: 0.2593 - val_loss: 665585920.0000 - val_accuracy: 0.2188\n",
      "Epoch 6/30\n",
      "835/835 [==============================] - 10s 12ms/step - loss: 1670055058.0670 - accuracy: 0.2611 - val_loss: 665585920.0000 - val_accuracy: 0.2188\n",
      "Epoch 7/30\n",
      "835/835 [==============================] - 10s 12ms/step - loss: 1662980588.8612 - accuracy: 0.2607 - val_loss: 665585920.0000 - val_accuracy: 0.2188\n",
      "Epoch 8/30\n",
      "835/835 [==============================] - 10s 12ms/step - loss: 1668831120.2297 - accuracy: 0.2586 - val_loss: 665585920.0000 - val_accuracy: 0.2188\n",
      "Epoch 9/30\n",
      "835/835 [==============================] - 10s 12ms/step - loss: 1658454743.4258 - accuracy: 0.2630 - val_loss: 665585920.0000 - val_accuracy: 0.2188\n",
      "Epoch 10/30\n",
      "835/835 [==============================] - 10s 12ms/step - loss: 1681322083.5215 - accuracy: 0.2561 - val_loss: 665585920.0000 - val_accuracy: 0.2188\n",
      "Epoch 11/30\n",
      "835/835 [==============================] - 10s 12ms/step - loss: 1669650698.8708 - accuracy: 0.2602 - val_loss: 665585920.0000 - val_accuracy: 0.2188\n",
      "Epoch 12/30\n",
      "835/835 [==============================] - 10s 12ms/step - loss: 1682849883.1005 - accuracy: 0.2621 - val_loss: 665585920.0000 - val_accuracy: 0.2188\n",
      "Epoch 13/30\n",
      "835/835 [==============================] - 10s 12ms/step - loss: 1657918003.5981 - accuracy: 0.2589 - val_loss: 665585920.0000 - val_accuracy: 0.2188\n",
      "Epoch 14/30\n",
      "835/835 [==============================] - 10s 12ms/step - loss: 1666954079.2344 - accuracy: 0.2597 - val_loss: 665585920.0000 - val_accuracy: 0.2188\n",
      "Epoch 15/30\n",
      "835/835 [==============================] - 10s 12ms/step - loss: 1661380509.0909 - accuracy: 0.2582 - val_loss: 665585920.0000 - val_accuracy: 0.2188\n",
      "Epoch 16/30\n",
      "835/835 [==============================] - 10s 12ms/step - loss: 1650232537.1100 - accuracy: 0.2581 - val_loss: 665585920.0000 - val_accuracy: 0.2188\n",
      "Epoch 17/30\n",
      "835/835 [==============================] - 10s 12ms/step - loss: 1669885497.1100 - accuracy: 0.2640 - val_loss: 665585920.0000 - val_accuracy: 0.2188\n",
      "Epoch 18/30\n",
      "835/835 [==============================] - 10s 12ms/step - loss: 1652774626.4498 - accuracy: 0.2620 - val_loss: 665585920.0000 - val_accuracy: 0.2188\n",
      "Epoch 19/30\n",
      "835/835 [==============================] - 10s 12ms/step - loss: 1671224310.0478 - accuracy: 0.2609 - val_loss: 665585920.0000 - val_accuracy: 0.2188\n",
      "Epoch 20/30\n",
      "835/835 [==============================] - 10s 12ms/step - loss: 1666120776.5742 - accuracy: 0.2580 - val_loss: 665585920.0000 - val_accuracy: 0.2188\n",
      "Epoch 21/30\n",
      "835/835 [==============================] - 10s 12ms/step - loss: 1679209821.2440 - accuracy: 0.2605 - val_loss: 665585920.0000 - val_accuracy: 0.2188\n",
      "Epoch 22/30\n",
      "835/835 [==============================] - 10s 12ms/step - loss: 1674299400.2679 - accuracy: 0.2647 - val_loss: 665585920.0000 - val_accuracy: 0.2188\n",
      "Epoch 23/30\n",
      "835/835 [==============================] - 10s 12ms/step - loss: 1677394919.6555 - accuracy: 0.2578 - val_loss: 665585920.0000 - val_accuracy: 0.2188\n",
      "Epoch 24/30\n",
      "835/835 [==============================] - 10s 12ms/step - loss: 1644739821.9330 - accuracy: 0.2640 - val_loss: 665585920.0000 - val_accuracy: 0.2188\n",
      "Epoch 25/30\n",
      "835/835 [==============================] - 10s 12ms/step - loss: 1658133058.1435 - accuracy: 0.2603 - val_loss: 665585920.0000 - val_accuracy: 0.2188\n",
      "Epoch 26/30\n",
      "835/835 [==============================] - 10s 12ms/step - loss: 1680584341.4354 - accuracy: 0.2606 - val_loss: 665585920.0000 - val_accuracy: 0.2188\n",
      "Epoch 27/30\n",
      "835/835 [==============================] - 10s 12ms/step - loss: 1659396512.9187 - accuracy: 0.2674 - val_loss: 665585920.0000 - val_accuracy: 0.2188\n",
      "Epoch 28/30\n",
      "835/835 [==============================] - 10s 12ms/step - loss: 1652865047.2727 - accuracy: 0.2627 - val_loss: 665585920.0000 - val_accuracy: 0.2188\n",
      "Epoch 29/30\n",
      "835/835 [==============================] - 10s 12ms/step - loss: 1664423703.5789 - accuracy: 0.2634 - val_loss: 665585920.0000 - val_accuracy: 0.2188\n",
      "Epoch 30/30\n",
      "835/835 [==============================] - 10s 12ms/step - loss: 1672395347.4450 - accuracy: 0.2580 - val_loss: 665585920.0000 - val_accuracy: 0.2188\n",
      "INFO:tensorflow:Assets written to: ../octnet/octnet_30epochs_41742_images_False_newWeights_True_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for octnet: 0.260331\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.60167205 0.60102137 0.59878393 0.59203807]\n",
      "Training octnet for 0.6% of train size (aka 50090 images) with pretrained: True and onlyLastLayersTrained: True...\n",
      "\n",
      "Total: 23 trainable: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "   3/1002 [..............................] - ETA: 1:17 - loss: 2535037696.0000 - accuracy: 0.2000 WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0125s vs `on_train_batch_end` time: 0.0221s). Check your callbacks.\n",
      "1002/1002 [==============================] - 14s 13ms/step - loss: 2725043688.7737 - accuracy: 0.1698 - val_loss: 1584663552.0000 - val_accuracy: 0.2500\n",
      "Epoch 2/30\n",
      "   6/1002 [..............................] - ETA: 12s - loss: 2769934122.6667 - accuracy: 0.1516"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1002/1002 [==============================] - 12s 12ms/step - loss: 2710056677.2004 - accuracy: 0.1643 - val_loss: 1584663552.0000 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "1002/1002 [==============================] - 12s 12ms/step - loss: 2737574724.1476 - accuracy: 0.1703 - val_loss: 1584663552.0000 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "1002/1002 [==============================] - 12s 12ms/step - loss: 2739325184.0000 - accuracy: 0.1662 - val_loss: 1584663552.0000 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "1002/1002 [==============================] - 12s 12ms/step - loss: 2715714193.9940 - accuracy: 0.1683 - val_loss: 1584663552.0000 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "1002/1002 [==============================] - 12s 12ms/step - loss: 2731632360.2632 - accuracy: 0.1647 - val_loss: 1584663552.0000 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "1002/1002 [==============================] - 12s 12ms/step - loss: 2739294556.3948 - accuracy: 0.1681 - val_loss: 1584663552.0000 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "1002/1002 [==============================] - 12s 12ms/step - loss: 2714369410.4247 - accuracy: 0.1712 - val_loss: 1584663552.0000 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "1002/1002 [==============================] - 12s 12ms/step - loss: 2742515510.8754 - accuracy: 0.1613 - val_loss: 1584663552.0000 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "1002/1002 [==============================] - 12s 12ms/step - loss: 2729928536.5663 - accuracy: 0.1653 - val_loss: 1584663552.0000 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "1002/1002 [==============================] - 12s 12ms/step - loss: 2713858891.2941 - accuracy: 0.1699 - val_loss: 1584663552.0000 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "1002/1002 [==============================] - 12s 12ms/step - loss: 2739684252.7139 - accuracy: 0.1686 - val_loss: 1584663552.0000 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "1002/1002 [==============================] - 12s 12ms/step - loss: 2725647298.7438 - accuracy: 0.1682 - val_loss: 1584663552.0000 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "1002/1002 [==============================] - 12s 12ms/step - loss: 2746454736.1436 - accuracy: 0.1658 - val_loss: 1584663552.0000 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "1002/1002 [==============================] - 12s 12ms/step - loss: 2713056522.7198 - accuracy: 0.1652 - val_loss: 1584663552.0000 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "1002/1002 [==============================] - 12s 12ms/step - loss: 2723215705.5872 - accuracy: 0.1684 - val_loss: 1584663552.0000 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "1002/1002 [==============================] - 12s 12ms/step - loss: 2726255724.7298 - accuracy: 0.1677 - val_loss: 1584663552.0000 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "1002/1002 [==============================] - 12s 12ms/step - loss: 2737323545.2682 - accuracy: 0.1656 - val_loss: 1584663552.0000 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "1002/1002 [==============================] - 12s 12ms/step - loss: 2736336521.5713 - accuracy: 0.1657 - val_loss: 1584663552.0000 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "1002/1002 [==============================] - 12s 12ms/step - loss: 2723041518.2612 - accuracy: 0.1700 - val_loss: 1584663552.0000 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "1002/1002 [==============================] - 12s 12ms/step - loss: 2723184739.0309 - accuracy: 0.1657 - val_loss: 1584663552.0000 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "1002/1002 [==============================] - 12s 12ms/step - loss: 2705466726.8594 - accuracy: 0.1679 - val_loss: 1584663552.0000 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "1002/1002 [==============================] - 12s 12ms/step - loss: 2727152009.5713 - accuracy: 0.1664 - val_loss: 1584663552.0000 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "1002/1002 [==============================] - 12s 12ms/step - loss: 2725842938.1296 - accuracy: 0.1658 - val_loss: 1584663552.0000 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "1002/1002 [==============================] - 12s 12ms/step - loss: 2758268781.7507 - accuracy: 0.1646 - val_loss: 1584663552.0000 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "1002/1002 [==============================] - 12s 12ms/step - loss: 2738178742.7478 - accuracy: 0.1681 - val_loss: 1584663552.0000 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "1002/1002 [==============================] - 12s 12ms/step - loss: 2755186959.3141 - accuracy: 0.1650 - val_loss: 1584663552.0000 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "1002/1002 [==============================] - 12s 12ms/step - loss: 2726963916.6979 - accuracy: 0.1685 - val_loss: 1584663552.0000 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "1002/1002 [==============================] - 12s 12ms/step - loss: 2728490030.7079 - accuracy: 0.1625 - val_loss: 1584663552.0000 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "1002/1002 [==============================] - 12s 12ms/step - loss: 2751576508.1077 - accuracy: 0.1643 - val_loss: 1584663552.0000 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../octnet/octnet_30epochs_50090_images_False_newWeights_True_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for octnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.75265058 0.74871657 0.74929503 0.74837512]\n",
      "Training octnet for 0.75% of train size (aka 62613 images) with pretrained: True and onlyLastLayersTrained: True...\n",
      "\n",
      "Total: 23 trainable: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "   3/1253 [..............................] - ETA: 1:30 - loss: 1896643072.0000 - accuracy: 0.1833 WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0127s vs `on_train_batch_end` time: 0.0201s). Check your callbacks.\n",
      "1253/1253 [==============================] - 16s 13ms/step - loss: 1692614071.4258 - accuracy: 0.2038 - val_loss: 418186240.0000 - val_accuracy: 0.2500\n",
      "Epoch 2/30\n",
      "   6/1253 [..............................] - ETA: 14s - loss: 1745507840.0000 - accuracy: 0.1702"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1253/1253 [==============================] - 15s 12ms/step - loss: 1700320690.1180 - accuracy: 0.2050 - val_loss: 418186240.0000 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "1253/1253 [==============================] - 15s 12ms/step - loss: 1700049255.5024 - accuracy: 0.2063 - val_loss: 418186240.0000 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "1253/1253 [==============================] - 15s 12ms/step - loss: 1699779731.5981 - accuracy: 0.2040 - val_loss: 418186240.0000 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "1253/1253 [==============================] - 15s 12ms/step - loss: 1711796934.3285 - accuracy: 0.2032 - val_loss: 418186240.0000 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "1253/1253 [==============================] - 15s 12ms/step - loss: 1689254771.8533 - accuracy: 0.2079 - val_loss: 418186240.0000 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "1253/1253 [==============================] - 15s 12ms/step - loss: 1690995228.0702 - accuracy: 0.2036 - val_loss: 418186240.0000 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "1253/1253 [==============================] - 15s 12ms/step - loss: 1701116528.9952 - accuracy: 0.2033 - val_loss: 418186240.0000 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "1253/1253 [==============================] - 15s 12ms/step - loss: 1699429056.0000 - accuracy: 0.2044 - val_loss: 418186240.0000 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "1253/1253 [==============================] - 15s 12ms/step - loss: 1693457698.2967 - accuracy: 0.2049 - val_loss: 418186240.0000 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "1253/1253 [==============================] - 15s 12ms/step - loss: 1706856664.7018 - accuracy: 0.2024 - val_loss: 418186240.0000 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "1253/1253 [==============================] - 15s 12ms/step - loss: 1709231620.3892 - accuracy: 0.2041 - val_loss: 418186240.0000 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "1253/1253 [==============================] - 15s 12ms/step - loss: 1698786919.7065 - accuracy: 0.2045 - val_loss: 418186240.0000 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "1253/1253 [==============================] - 15s 12ms/step - loss: 1709109844.6188 - accuracy: 0.2034 - val_loss: 418186240.0000 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "1253/1253 [==============================] - 15s 12ms/step - loss: 1699021331.0877 - accuracy: 0.2021 - val_loss: 418186240.0000 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "1253/1253 [==============================] - 15s 12ms/step - loss: 1689470602.4115 - accuracy: 0.2042 - val_loss: 418186240.0000 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "1253/1253 [==============================] - 15s 12ms/step - loss: 1692622400.8166 - accuracy: 0.2075 - val_loss: 418186240.0000 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "1253/1253 [==============================] - 16s 12ms/step - loss: 1690001937.5566 - accuracy: 0.2007 - val_loss: 418186240.0000 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "1253/1253 [==============================] - 15s 12ms/step - loss: 1690278451.5470 - accuracy: 0.2064 - val_loss: 418186240.0000 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "1253/1253 [==============================] - 15s 12ms/step - loss: 1702398244.0319 - accuracy: 0.2033 - val_loss: 418186240.0000 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "1253/1253 [==============================] - 16s 12ms/step - loss: 1697935269.4609 - accuracy: 0.2013 - val_loss: 418186240.0000 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "1253/1253 [==============================] - 15s 12ms/step - loss: 1692517828.0829 - accuracy: 0.2051 - val_loss: 418186240.0000 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "1253/1253 [==============================] - 16s 12ms/step - loss: 1710839496.1659 - accuracy: 0.2034 - val_loss: 418186240.0000 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "1253/1253 [==============================] - 15s 12ms/step - loss: 1694617343.1834 - accuracy: 0.2055 - val_loss: 418186240.0000 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "1253/1253 [==============================] - 15s 12ms/step - loss: 1692225967.3620 - accuracy: 0.2057 - val_loss: 418186240.0000 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "1253/1253 [==============================] - 15s 12ms/step - loss: 1686048533.8437 - accuracy: 0.2021 - val_loss: 418186240.0000 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "1253/1253 [==============================] - 16s 12ms/step - loss: 1678459906.6539 - accuracy: 0.2059 - val_loss: 418186240.0000 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "1253/1253 [==============================] - 16s 12ms/step - loss: 1702227221.7416 - accuracy: 0.2040 - val_loss: 418186240.0000 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "1253/1253 [==============================] - 16s 12ms/step - loss: 1696967266.6029 - accuracy: 0.2039 - val_loss: 418186240.0000 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "1253/1253 [==============================] - 16s 12ms/step - loss: 1707920377.1611 - accuracy: 0.1992 - val_loss: 418186240.0000 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../octnet/octnet_30epochs_62613_images_False_newWeights_True_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for octnet: 0.224174\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.89895497 0.90022846 0.90306662 0.89809656]\n",
      "Training octnet for 0.9% of train size (aka 75135 images) with pretrained: True and onlyLastLayersTrained: True...\n",
      "\n",
      "Total: 23 trainable: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "   3/1503 [..............................] - ETA: 1:52 - loss: 2157519914.6667 - accuracy: 0.2833 WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0125s vs `on_train_batch_end` time: 0.0211s). Check your callbacks.\n",
      "1503/1503 [==============================] - 20s 13ms/step - loss: 2286801525.1915 - accuracy: 0.2765 - val_loss: 612906816.0000 - val_accuracy: 0.3438\n",
      "Epoch 2/30\n",
      "   5/1503 [..............................] - ETA: 19s - loss: 2200062771.2000 - accuracy: 0.3164"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1503/1503 [==============================] - 18s 12ms/step - loss: 2279078984.8511 - accuracy: 0.2811 - val_loss: 612906816.0000 - val_accuracy: 0.3438\n",
      "Epoch 3/30\n",
      "1503/1503 [==============================] - 18s 12ms/step - loss: 2291444983.8298 - accuracy: 0.2749 - val_loss: 612906816.0000 - val_accuracy: 0.3438\n",
      "Epoch 4/30\n",
      "1503/1503 [==============================] - 19s 12ms/step - loss: 2286133769.7021 - accuracy: 0.2798 - val_loss: 612906816.0000 - val_accuracy: 0.3438\n",
      "Epoch 5/30\n",
      "1503/1503 [==============================] - 19s 12ms/step - loss: 2284473674.2128 - accuracy: 0.2789 - val_loss: 612906816.0000 - val_accuracy: 0.3438\n",
      "Epoch 6/30\n",
      "1503/1503 [==============================] - 18s 12ms/step - loss: 2265096953.0213 - accuracy: 0.2852 - val_loss: 612906816.0000 - val_accuracy: 0.3438\n",
      "Epoch 7/30\n",
      "1503/1503 [==============================] - 19s 12ms/step - loss: 2289795997.6170 - accuracy: 0.2784 - val_loss: 612906816.0000 - val_accuracy: 0.3438\n",
      "Epoch 8/30\n",
      "1503/1503 [==============================] - 19s 12ms/step - loss: 2288849732.9362 - accuracy: 0.2796 - val_loss: 612906816.0000 - val_accuracy: 0.3438\n",
      "Epoch 9/30\n",
      "1503/1503 [==============================] - 19s 12ms/step - loss: 2276018545.7872 - accuracy: 0.2792 - val_loss: 612906816.0000 - val_accuracy: 0.3438\n",
      "Epoch 10/30\n",
      "1503/1503 [==============================] - 18s 12ms/step - loss: 2308349479.8298 - accuracy: 0.2760 - val_loss: 612906816.0000 - val_accuracy: 0.3438\n",
      "Epoch 11/30\n",
      "1503/1503 [==============================] - 19s 12ms/step - loss: 2298501116.4255 - accuracy: 0.2793 - val_loss: 612906816.0000 - val_accuracy: 0.3438\n",
      "Epoch 12/30\n",
      "1503/1503 [==============================] - 19s 12ms/step - loss: 2289686300.3404 - accuracy: 0.2812 - val_loss: 612906816.0000 - val_accuracy: 0.3438\n",
      "Epoch 13/30\n",
      "1503/1503 [==============================] - 19s 12ms/step - loss: 2300700350.2979 - accuracy: 0.2761 - val_loss: 612906816.0000 - val_accuracy: 0.3438\n",
      "Epoch 14/30\n",
      "1503/1503 [==============================] - 19s 12ms/step - loss: 2288425264.9362 - accuracy: 0.2779 - val_loss: 612906816.0000 - val_accuracy: 0.3438\n",
      "Epoch 15/30\n",
      "1503/1503 [==============================] - 19s 12ms/step - loss: 2289850903.6596 - accuracy: 0.2770 - val_loss: 612906816.0000 - val_accuracy: 0.3438\n",
      "Epoch 16/30\n",
      "1503/1503 [==============================] - 19s 12ms/step - loss: 2300632714.8936 - accuracy: 0.2772 - val_loss: 612906816.0000 - val_accuracy: 0.3438\n",
      "Epoch 17/30\n",
      "1503/1503 [==============================] - 19s 12ms/step - loss: 2288477796.5957 - accuracy: 0.2756 - val_loss: 612906816.0000 - val_accuracy: 0.3438\n",
      "Epoch 18/30\n",
      "1503/1503 [==============================] - 18s 12ms/step - loss: 2277570575.2340 - accuracy: 0.2784 - val_loss: 612906816.0000 - val_accuracy: 0.3438\n",
      "Epoch 19/30\n",
      "1503/1503 [==============================] - 19s 12ms/step - loss: 2274425550.4681 - accuracy: 0.2812 - val_loss: 612906816.0000 - val_accuracy: 0.3438\n",
      "Epoch 20/30\n",
      "1503/1503 [==============================] - 19s 12ms/step - loss: 2291312418.5532 - accuracy: 0.2775 - val_loss: 612906816.0000 - val_accuracy: 0.3438\n",
      "Epoch 21/30\n",
      "1503/1503 [==============================] - 18s 12ms/step - loss: 2306240257.7872 - accuracy: 0.2772 - val_loss: 612906816.0000 - val_accuracy: 0.3438\n",
      "Epoch 22/30\n",
      "1503/1503 [==============================] - 18s 12ms/step - loss: 2299838997.6170 - accuracy: 0.2761 - val_loss: 612906816.0000 - val_accuracy: 0.3438\n",
      "Epoch 23/30\n",
      "1503/1503 [==============================] - 19s 12ms/step - loss: 2294963807.6596 - accuracy: 0.2777 - val_loss: 612906816.0000 - val_accuracy: 0.3438\n",
      "Epoch 24/30\n",
      "1503/1503 [==============================] - 19s 12ms/step - loss: 2274019329.0213 - accuracy: 0.2813 - val_loss: 612906816.0000 - val_accuracy: 0.3438\n",
      "Epoch 25/30\n",
      "1503/1503 [==============================] - 19s 12ms/step - loss: 2283627204.2553 - accuracy: 0.2814 - val_loss: 612906816.0000 - val_accuracy: 0.3438\n",
      "Epoch 26/30\n",
      "1503/1503 [==============================] - 18s 12ms/step - loss: 2289606694.4681 - accuracy: 0.2822 - val_loss: 612906816.0000 - val_accuracy: 0.3438\n",
      "Epoch 27/30\n",
      "1503/1503 [==============================] - 19s 12ms/step - loss: 2291800673.8723 - accuracy: 0.2732 - val_loss: 612906816.0000 - val_accuracy: 0.3438\n",
      "Epoch 28/30\n",
      "1503/1503 [==============================] - 19s 12ms/step - loss: 2274336883.7447 - accuracy: 0.2804 - val_loss: 612906816.0000 - val_accuracy: 0.3438\n",
      "Epoch 29/30\n",
      "1503/1503 [==============================] - 18s 12ms/step - loss: 2270694715.4043 - accuracy: 0.2840 - val_loss: 612906816.0000 - val_accuracy: 0.3438\n",
      "Epoch 30/30\n",
      "1503/1503 [==============================] - 19s 12ms/step - loss: 2306330930.3830 - accuracy: 0.2739 - val_loss: 612906816.0000 - val_accuracy: 0.3438\n",
      "INFO:tensorflow:Assets written to: ../octnet/octnet_30epochs_75136_images_False_newWeights_True_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for octnet: 0.283058\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [1. 1. 1. 1.]\n",
      "Training octnet for 1.0% of train size (aka 83484 images) with pretrained: True and onlyLastLayersTrained: True...\n",
      "\n",
      "Total: 23 trainable: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "   3/1670 [..............................] - ETA: 2:02 - loss: 2223182890.6667 - accuracy: 0.2411 WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0126s vs `on_train_batch_end` time: 0.0206s). Check your callbacks.\n",
      "1670/1670 [==============================] - 21s 12ms/step - loss: 2670527411.9354 - accuracy: 0.1838 - val_loss: 1478757632.0000 - val_accuracy: 0.2500\n",
      "Epoch 2/30\n",
      "   6/1670 [..............................] - ETA: 20s - loss: 2671657557.3333 - accuracy: 0.1859"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1670/1670 [==============================] - 20s 12ms/step - loss: 2664021592.3974 - accuracy: 0.1856 - val_loss: 1478757632.0000 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "1670/1670 [==============================] - 20s 12ms/step - loss: 2674452532.8546 - accuracy: 0.1826 - val_loss: 1478757632.0000 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "1670/1670 [==============================] - 20s 12ms/step - loss: 2690271539.3992 - accuracy: 0.1837 - val_loss: 1478757632.0000 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "1670/1670 [==============================] - 21s 12ms/step - loss: 2658751485.0892 - accuracy: 0.1844 - val_loss: 1478757632.0000 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "1670/1670 [==============================] - 20s 12ms/step - loss: 2687391177.1538 - accuracy: 0.1830 - val_loss: 1478757632.0000 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "1670/1670 [==============================] - 20s 12ms/step - loss: 2686812370.6523 - accuracy: 0.1845 - val_loss: 1478757632.0000 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "1670/1670 [==============================] - 21s 12ms/step - loss: 2675530541.3477 - accuracy: 0.1845 - val_loss: 1478757632.0000 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "1670/1670 [==============================] - 21s 12ms/step - loss: 2688999051.1071 - accuracy: 0.1854 - val_loss: 1478757632.0000 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "1670/1670 [==============================] - 21s 12ms/step - loss: 2678258529.8959 - accuracy: 0.1857 - val_loss: 1478757632.0000 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "1670/1670 [==============================] - 21s 12ms/step - loss: 2698608946.5566 - accuracy: 0.1823 - val_loss: 1478757632.0000 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "1670/1670 [==============================] - 21s 12ms/step - loss: 2693367643.6146 - accuracy: 0.1804 - val_loss: 1478757632.0000 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "1670/1670 [==============================] - 21s 12ms/step - loss: 2671662915.8683 - accuracy: 0.1835 - val_loss: 1478757632.0000 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "1670/1670 [==============================] - 20s 12ms/step - loss: 2674023147.0114 - accuracy: 0.1848 - val_loss: 1478757632.0000 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "1670/1670 [==============================] - 21s 12ms/step - loss: 2675818066.8821 - accuracy: 0.1829 - val_loss: 1478757632.0000 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "1670/1670 [==============================] - 21s 12ms/step - loss: 2689250786.2789 - accuracy: 0.1842 - val_loss: 1478757632.0000 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "1670/1670 [==============================] - 21s 12ms/step - loss: 2683337350.6643 - accuracy: 0.1838 - val_loss: 1478757632.0000 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "1670/1670 [==============================] - 21s 12ms/step - loss: 2664845970.2310 - accuracy: 0.1850 - val_loss: 1478757632.0000 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "1670/1670 [==============================] - 21s 12ms/step - loss: 2704894794.1496 - accuracy: 0.1786 - val_loss: 1478757632.0000 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "1670/1670 [==============================] - 21s 12ms/step - loss: 2667756087.4590 - accuracy: 0.1832 - val_loss: 1478757632.0000 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "1670/1670 [==============================] - 21s 12ms/step - loss: 2696408428.1604 - accuracy: 0.1828 - val_loss: 1478757632.0000 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "1670/1670 [==============================] - 21s 12ms/step - loss: 2696436743.5835 - accuracy: 0.1811 - val_loss: 1478757632.0000 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "1670/1670 [==============================] - 21s 12ms/step - loss: 2669868780.3902 - accuracy: 0.1829 - val_loss: 1478757632.0000 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "1670/1670 [==============================] - 20s 12ms/step - loss: 2686910063.2244 - accuracy: 0.1843 - val_loss: 1478757632.0000 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "1670/1670 [==============================] - 20s 12ms/step - loss: 2676030306.6619 - accuracy: 0.1818 - val_loss: 1478757632.0000 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "1670/1670 [==============================] - 21s 12ms/step - loss: 2669051975.0856 - accuracy: 0.1820 - val_loss: 1478757632.0000 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "1670/1670 [==============================] - 20s 12ms/step - loss: 2685976042.8582 - accuracy: 0.1811 - val_loss: 1478757632.0000 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "1670/1670 [==============================] - 20s 12ms/step - loss: 2669823483.8636 - accuracy: 0.1903 - val_loss: 1478757632.0000 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "1670/1670 [==============================] - 20s 12ms/step - loss: 2686289166.7074 - accuracy: 0.1847 - val_loss: 1478757632.0000 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "1670/1670 [==============================] - 20s 12ms/step - loss: 2681270698.0539 - accuracy: 0.1839 - val_loss: 1478757632.0000 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../octnet/octnet_30epochs_83484_images_False_newWeights_True_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for octnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.0100323  0.01083188 0.00863588 0.00800836]\n",
      "Training octnet for 0.01% of train size (aka 834 images) with pretrained: True and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 23 trainable: 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      " 5/17 [=======>......................] - ETA: 1s - loss: 4.9219 - accuracy: 0.3384WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0180s vs `on_train_batch_end` time: 0.0536s). Check your callbacks.\n",
      "17/17 [==============================] - 2s 73ms/step - loss: 4.5548 - accuracy: 0.3718 - val_loss: 527.7617 - val_accuracy: 0.4375\n",
      "Epoch 2/30\n",
      " 1/17 [>.............................] - ETA: 0s - loss: 2.5958 - accuracy: 0.5800"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 1s 42ms/step - loss: 2.6957 - accuracy: 0.5233 - val_loss: 79.4119 - val_accuracy: 0.5000\n",
      "Epoch 3/30\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 2.2466 - accuracy: 0.5432 - val_loss: 43.5615 - val_accuracy: 0.4062\n",
      "Epoch 4/30\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 1.7571 - accuracy: 0.5921 - val_loss: 18.9835 - val_accuracy: 0.5000\n",
      "Epoch 5/30\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 1.3953 - accuracy: 0.6347 - val_loss: 13.8315 - val_accuracy: 0.5000\n",
      "Epoch 6/30\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 1.4255 - accuracy: 0.6311 - val_loss: 9.1417 - val_accuracy: 0.5000\n",
      "Epoch 7/30\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 1.3467 - accuracy: 0.6621 - val_loss: 6.6616 - val_accuracy: 0.5000\n",
      "Epoch 8/30\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 1.1655 - accuracy: 0.6783 - val_loss: 4.5020 - val_accuracy: 0.4688\n",
      "Epoch 9/30\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.9956 - accuracy: 0.7249 - val_loss: 4.3071 - val_accuracy: 0.5000\n",
      "Epoch 10/30\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.9436 - accuracy: 0.7270 - val_loss: 2.9773 - val_accuracy: 0.5000\n",
      "Epoch 11/30\n",
      "17/17 [==============================] - 1s 44ms/step - loss: 0.8930 - accuracy: 0.7234 - val_loss: 1.3690 - val_accuracy: 0.6250\n",
      "Epoch 12/30\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.8742 - accuracy: 0.7050 - val_loss: 1.8099 - val_accuracy: 0.5312\n",
      "Epoch 13/30\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.7214 - accuracy: 0.7447 - val_loss: 2.1722 - val_accuracy: 0.4688\n",
      "Epoch 14/30\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.6475 - accuracy: 0.7854 - val_loss: 1.9452 - val_accuracy: 0.5000\n",
      "Epoch 15/30\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.7353 - accuracy: 0.7680 - val_loss: 1.3610 - val_accuracy: 0.5938\n",
      "Epoch 16/30\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.6337 - accuracy: 0.7917 - val_loss: 1.2820 - val_accuracy: 0.5938\n",
      "Epoch 17/30\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.6254 - accuracy: 0.7724 - val_loss: 1.4517 - val_accuracy: 0.5625\n",
      "Epoch 18/30\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.5291 - accuracy: 0.7943 - val_loss: 1.2260 - val_accuracy: 0.6250\n",
      "Epoch 19/30\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.6397 - accuracy: 0.7810 - val_loss: 1.4553 - val_accuracy: 0.5938\n",
      "Epoch 20/30\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.4471 - accuracy: 0.8533 - val_loss: 1.3001 - val_accuracy: 0.6250\n",
      "Epoch 21/30\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.5616 - accuracy: 0.7836 - val_loss: 1.3233 - val_accuracy: 0.6250\n",
      "Epoch 22/30\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.5434 - accuracy: 0.8025 - val_loss: 1.2484 - val_accuracy: 0.6250\n",
      "Epoch 23/30\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.6147 - accuracy: 0.7948 - val_loss: 1.1478 - val_accuracy: 0.6562\n",
      "Epoch 24/30\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.5102 - accuracy: 0.8083 - val_loss: 1.2068 - val_accuracy: 0.6250\n",
      "Epoch 25/30\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.4446 - accuracy: 0.8251 - val_loss: 1.2313 - val_accuracy: 0.6250\n",
      "Epoch 26/30\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.4733 - accuracy: 0.8372 - val_loss: 1.0730 - val_accuracy: 0.6562\n",
      "Epoch 27/30\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.4925 - accuracy: 0.8218 - val_loss: 1.0768 - val_accuracy: 0.6875\n",
      "Epoch 28/30\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.5275 - accuracy: 0.8253 - val_loss: 1.2100 - val_accuracy: 0.6250\n",
      "Epoch 29/30\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.4451 - accuracy: 0.8394 - val_loss: 1.1945 - val_accuracy: 0.6250\n",
      "Epoch 30/30\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.4965 - accuracy: 0.8373 - val_loss: 1.1991 - val_accuracy: 0.6250\n",
      "INFO:tensorflow:Assets written to: ../octnet/octnet_30epochs_835_images_False_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for octnet: 0.561983\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.02420673 0.02577611 0.02634826 0.02228412]\n",
      "Training octnet for 0.025% of train size (aka 2087 images) with pretrained: True and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 23 trainable: 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      " 5/42 [==>...........................] - ETA: 3s - loss: 5.0660 - accuracy: 0.3306WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0182s vs `on_train_batch_end` time: 0.0545s). Check your callbacks.\n",
      "42/42 [==============================] - 3s 53ms/step - loss: 3.9361 - accuracy: 0.3867 - val_loss: 35.7743 - val_accuracy: 0.4688\n",
      "Epoch 2/30\n",
      " 1/42 [..............................] - ETA: 1s - loss: 1.9628 - accuracy: 0.5200"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 2s 41ms/step - loss: 2.1105 - accuracy: 0.5254 - val_loss: 9.0132 - val_accuracy: 0.5000\n",
      "Epoch 3/30\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 1.5931 - accuracy: 0.5809 - val_loss: 3.7764 - val_accuracy: 0.5000\n",
      "Epoch 4/30\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 1.5473 - accuracy: 0.6020 - val_loss: 2.0260 - val_accuracy: 0.5000\n",
      "Epoch 5/30\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 1.2414 - accuracy: 0.6375 - val_loss: 1.1531 - val_accuracy: 0.5312\n",
      "Epoch 6/30\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 1.2144 - accuracy: 0.6386 - val_loss: 1.2719 - val_accuracy: 0.5312\n",
      "Epoch 7/30\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 1.1270 - accuracy: 0.6618 - val_loss: 0.7884 - val_accuracy: 0.6250\n",
      "Epoch 8/30\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 1.0632 - accuracy: 0.6572 - val_loss: 0.8107 - val_accuracy: 0.6562\n",
      "Epoch 9/30\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.9479 - accuracy: 0.6999 - val_loss: 0.8665 - val_accuracy: 0.5625\n",
      "Epoch 10/30\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.8255 - accuracy: 0.7178 - val_loss: 1.0695 - val_accuracy: 0.5312\n",
      "Epoch 11/30\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.8924 - accuracy: 0.7208 - val_loss: 0.8640 - val_accuracy: 0.5938\n",
      "Epoch 12/30\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.7503 - accuracy: 0.7533 - val_loss: 0.7864 - val_accuracy: 0.6250\n",
      "Epoch 13/30\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.8024 - accuracy: 0.7350 - val_loss: 0.8494 - val_accuracy: 0.6562\n",
      "Epoch 14/30\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.6516 - accuracy: 0.7675 - val_loss: 0.8857 - val_accuracy: 0.5625\n",
      "Epoch 15/30\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.6877 - accuracy: 0.7567 - val_loss: 0.8239 - val_accuracy: 0.6562\n",
      "Epoch 16/30\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.6554 - accuracy: 0.7642 - val_loss: 0.8020 - val_accuracy: 0.5938\n",
      "Epoch 17/30\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.6796 - accuracy: 0.7671 - val_loss: 0.7744 - val_accuracy: 0.5625\n",
      "Epoch 18/30\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.6064 - accuracy: 0.8082 - val_loss: 0.6917 - val_accuracy: 0.6250\n",
      "Epoch 19/30\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.5485 - accuracy: 0.7956 - val_loss: 0.7649 - val_accuracy: 0.6562\n",
      "Epoch 20/30\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.5001 - accuracy: 0.8127 - val_loss: 0.7645 - val_accuracy: 0.6562\n",
      "Epoch 21/30\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.5467 - accuracy: 0.8014 - val_loss: 0.7561 - val_accuracy: 0.7188\n",
      "Epoch 22/30\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.5468 - accuracy: 0.7972 - val_loss: 0.7449 - val_accuracy: 0.7500\n",
      "Epoch 23/30\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.5605 - accuracy: 0.7857 - val_loss: 0.7225 - val_accuracy: 0.7500\n",
      "Epoch 24/30\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.5084 - accuracy: 0.8306 - val_loss: 0.7923 - val_accuracy: 0.6562\n",
      "Epoch 25/30\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.5310 - accuracy: 0.8056 - val_loss: 0.7347 - val_accuracy: 0.7500\n",
      "Epoch 26/30\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.4889 - accuracy: 0.8252 - val_loss: 0.6681 - val_accuracy: 0.7500\n",
      "Epoch 27/30\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.4976 - accuracy: 0.8239 - val_loss: 0.7868 - val_accuracy: 0.6562\n",
      "Epoch 28/30\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.5045 - accuracy: 0.8319 - val_loss: 0.6742 - val_accuracy: 0.7500\n",
      "Epoch 29/30\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.4762 - accuracy: 0.8240 - val_loss: 0.7532 - val_accuracy: 0.6562\n",
      "Epoch 30/30\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.4959 - accuracy: 0.8279 - val_loss: 0.7107 - val_accuracy: 0.7188\n",
      "INFO:tensorflow:Assets written to: ../octnet/octnet_30epochs_2087_images_False_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for octnet: 0.675620\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.04902147 0.05096089 0.0489073  0.05025534]\n",
      "Training octnet for 0.05% of train size (aka 4174 images) with pretrained: True and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 23 trainable: 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      " 5/84 [>.............................] - ETA: 7s - loss: 5.3352 - accuracy: 0.2760 WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0186s vs `on_train_batch_end` time: 0.0543s). Check your callbacks.\n",
      "84/84 [==============================] - 5s 46ms/step - loss: 4.0112 - accuracy: 0.4032 - val_loss: 6.4860 - val_accuracy: 0.5000\n",
      "Epoch 2/30\n",
      " 1/84 [..............................] - ETA: 3s - loss: 1.9597 - accuracy: 0.4400"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84/84 [==============================] - 3s 40ms/step - loss: 1.9532 - accuracy: 0.5325 - val_loss: 1.4520 - val_accuracy: 0.5312\n",
      "Epoch 3/30\n",
      "84/84 [==============================] - 3s 40ms/step - loss: 1.4798 - accuracy: 0.5815 - val_loss: 1.0496 - val_accuracy: 0.5938\n",
      "Epoch 4/30\n",
      "84/84 [==============================] - 3s 40ms/step - loss: 1.2064 - accuracy: 0.6424 - val_loss: 1.2335 - val_accuracy: 0.4688\n",
      "Epoch 5/30\n",
      "84/84 [==============================] - 3s 40ms/step - loss: 1.0675 - accuracy: 0.6805 - val_loss: 0.8847 - val_accuracy: 0.6250\n",
      "Epoch 6/30\n",
      "84/84 [==============================] - 3s 41ms/step - loss: 0.9195 - accuracy: 0.6895 - val_loss: 0.9136 - val_accuracy: 0.6250\n",
      "Epoch 7/30\n",
      "84/84 [==============================] - 3s 41ms/step - loss: 0.8830 - accuracy: 0.7008 - val_loss: 0.9300 - val_accuracy: 0.6562\n",
      "Epoch 8/30\n",
      "84/84 [==============================] - 3s 41ms/step - loss: 0.8271 - accuracy: 0.7147 - val_loss: 0.8606 - val_accuracy: 0.6875\n",
      "Epoch 9/30\n",
      "84/84 [==============================] - 3s 41ms/step - loss: 0.7342 - accuracy: 0.7487 - val_loss: 0.7243 - val_accuracy: 0.7188\n",
      "Epoch 10/30\n",
      "84/84 [==============================] - 3s 41ms/step - loss: 0.6817 - accuracy: 0.7575 - val_loss: 0.6569 - val_accuracy: 0.7188\n",
      "Epoch 11/30\n",
      "84/84 [==============================] - 3s 41ms/step - loss: 0.6492 - accuracy: 0.7585 - val_loss: 0.7661 - val_accuracy: 0.7188\n",
      "Epoch 12/30\n",
      "84/84 [==============================] - 3s 41ms/step - loss: 0.6158 - accuracy: 0.7679 - val_loss: 0.7734 - val_accuracy: 0.7188\n",
      "Epoch 13/30\n",
      "84/84 [==============================] - 3s 41ms/step - loss: 0.5557 - accuracy: 0.7922 - val_loss: 0.6630 - val_accuracy: 0.7500\n",
      "Epoch 14/30\n",
      "84/84 [==============================] - 3s 41ms/step - loss: 0.5679 - accuracy: 0.7900 - val_loss: 0.7026 - val_accuracy: 0.6875\n",
      "Epoch 15/30\n",
      "84/84 [==============================] - 3s 41ms/step - loss: 0.5394 - accuracy: 0.8004 - val_loss: 0.7181 - val_accuracy: 0.7500\n",
      "Epoch 16/30\n",
      "84/84 [==============================] - 3s 41ms/step - loss: 0.5007 - accuracy: 0.8156 - val_loss: 0.6940 - val_accuracy: 0.6875\n",
      "Epoch 17/30\n",
      "84/84 [==============================] - 3s 41ms/step - loss: 0.5178 - accuracy: 0.8149 - val_loss: 0.7369 - val_accuracy: 0.6875\n",
      "Epoch 18/30\n",
      "84/84 [==============================] - 3s 41ms/step - loss: 0.4632 - accuracy: 0.8329 - val_loss: 0.6670 - val_accuracy: 0.7812\n",
      "Epoch 19/30\n",
      "84/84 [==============================] - 3s 41ms/step - loss: 0.4529 - accuracy: 0.8301 - val_loss: 0.6734 - val_accuracy: 0.7812\n",
      "Epoch 20/30\n",
      "84/84 [==============================] - 3s 41ms/step - loss: 0.4368 - accuracy: 0.8381 - val_loss: 0.7262 - val_accuracy: 0.7500\n",
      "Epoch 21/30\n",
      "84/84 [==============================] - 3s 41ms/step - loss: 0.4464 - accuracy: 0.8388 - val_loss: 0.6965 - val_accuracy: 0.7188\n",
      "Epoch 22/30\n",
      "84/84 [==============================] - 3s 41ms/step - loss: 0.4347 - accuracy: 0.8458 - val_loss: 0.7241 - val_accuracy: 0.6562\n",
      "Epoch 23/30\n",
      "84/84 [==============================] - 3s 41ms/step - loss: 0.4261 - accuracy: 0.8434 - val_loss: 0.7549 - val_accuracy: 0.7188\n",
      "Epoch 24/30\n",
      "84/84 [==============================] - 3s 41ms/step - loss: 0.4172 - accuracy: 0.8530 - val_loss: 0.7066 - val_accuracy: 0.7188\n",
      "Epoch 25/30\n",
      "84/84 [==============================] - 3s 41ms/step - loss: 0.3869 - accuracy: 0.8547 - val_loss: 0.7517 - val_accuracy: 0.7812\n",
      "Epoch 26/30\n",
      "84/84 [==============================] - 3s 41ms/step - loss: 0.4062 - accuracy: 0.8481 - val_loss: 0.7046 - val_accuracy: 0.7500\n",
      "Epoch 27/30\n",
      "84/84 [==============================] - 3s 41ms/step - loss: 0.3658 - accuracy: 0.8659 - val_loss: 0.6860 - val_accuracy: 0.7500\n",
      "Epoch 28/30\n",
      "84/84 [==============================] - 3s 41ms/step - loss: 0.3657 - accuracy: 0.8701 - val_loss: 0.7229 - val_accuracy: 0.7188\n",
      "Epoch 29/30\n",
      "84/84 [==============================] - 3s 41ms/step - loss: 0.3477 - accuracy: 0.8756 - val_loss: 0.7127 - val_accuracy: 0.7500\n",
      "Epoch 30/30\n",
      "84/84 [==============================] - 3s 41ms/step - loss: 0.3642 - accuracy: 0.8645 - val_loss: 0.7109 - val_accuracy: 0.7812\n",
      "INFO:tensorflow:Assets written to: ../octnet/octnet_30epochs_4174_images_False_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for octnet: 0.750000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.07501425 0.07571563 0.07340501 0.07393222]\n",
      "Training octnet for 0.075% of train size (aka 6261 images) with pretrained: True and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 23 trainable: 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  5/126 [>.............................] - ETA: 10s - loss: 4.2712 - accuracy: 0.3336WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0188s vs `on_train_batch_end` time: 0.0519s). Check your callbacks.\n",
      "126/126 [==============================] - 7s 49ms/step - loss: 3.4897 - accuracy: 0.4284 - val_loss: 2.2020 - val_accuracy: 0.5312\n",
      "Epoch 2/30\n",
      "  1/126 [..............................] - ETA: 5s - loss: 1.4838 - accuracy: 0.6000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126/126 [==============================] - 5s 41ms/step - loss: 1.5526 - accuracy: 0.5933 - val_loss: 0.7184 - val_accuracy: 0.6562\n",
      "Epoch 3/30\n",
      "126/126 [==============================] - 5s 41ms/step - loss: 1.1262 - accuracy: 0.6615 - val_loss: 1.4135 - val_accuracy: 0.5312\n",
      "Epoch 4/30\n",
      "126/126 [==============================] - 5s 41ms/step - loss: 0.8932 - accuracy: 0.7001 - val_loss: 0.9319 - val_accuracy: 0.5938\n",
      "Epoch 5/30\n",
      "126/126 [==============================] - 5s 41ms/step - loss: 0.8534 - accuracy: 0.7263 - val_loss: 0.8622 - val_accuracy: 0.6562\n",
      "Epoch 6/30\n",
      "126/126 [==============================] - 5s 41ms/step - loss: 0.7128 - accuracy: 0.7535 - val_loss: 0.7290 - val_accuracy: 0.6250\n",
      "Epoch 7/30\n",
      "126/126 [==============================] - 5s 41ms/step - loss: 0.6322 - accuracy: 0.7720 - val_loss: 0.8874 - val_accuracy: 0.6875\n",
      "Epoch 8/30\n",
      "126/126 [==============================] - 5s 41ms/step - loss: 0.5747 - accuracy: 0.7936 - val_loss: 1.0030 - val_accuracy: 0.6562\n",
      "Epoch 9/30\n",
      "126/126 [==============================] - 5s 41ms/step - loss: 0.5720 - accuracy: 0.7986 - val_loss: 0.8050 - val_accuracy: 0.6562\n",
      "Epoch 10/30\n",
      "126/126 [==============================] - 5s 41ms/step - loss: 0.4956 - accuracy: 0.8215 - val_loss: 0.7089 - val_accuracy: 0.7188\n",
      "Epoch 11/30\n",
      "126/126 [==============================] - 5s 41ms/step - loss: 0.4863 - accuracy: 0.8261 - val_loss: 0.6610 - val_accuracy: 0.6875\n",
      "Epoch 12/30\n",
      "126/126 [==============================] - 5s 41ms/step - loss: 0.4399 - accuracy: 0.8354 - val_loss: 0.6862 - val_accuracy: 0.6562\n",
      "Epoch 13/30\n",
      "126/126 [==============================] - 5s 41ms/step - loss: 0.4515 - accuracy: 0.8443 - val_loss: 0.6673 - val_accuracy: 0.6875\n",
      "Epoch 14/30\n",
      "126/126 [==============================] - 5s 41ms/step - loss: 0.4275 - accuracy: 0.8460 - val_loss: 0.7482 - val_accuracy: 0.6875\n",
      "Epoch 15/30\n",
      "126/126 [==============================] - 5s 41ms/step - loss: 0.3868 - accuracy: 0.8587 - val_loss: 1.0195 - val_accuracy: 0.6562\n",
      "Epoch 16/30\n",
      "126/126 [==============================] - 5s 41ms/step - loss: 0.3774 - accuracy: 0.8669 - val_loss: 0.8913 - val_accuracy: 0.7188\n",
      "Epoch 17/30\n",
      "126/126 [==============================] - 5s 41ms/step - loss: 0.3441 - accuracy: 0.8755 - val_loss: 0.7547 - val_accuracy: 0.7188\n",
      "Epoch 18/30\n",
      "126/126 [==============================] - 5s 41ms/step - loss: 0.3478 - accuracy: 0.8742 - val_loss: 0.6830 - val_accuracy: 0.6875\n",
      "Epoch 19/30\n",
      "126/126 [==============================] - 5s 41ms/step - loss: 0.3259 - accuracy: 0.8799 - val_loss: 0.7596 - val_accuracy: 0.6875\n",
      "Epoch 20/30\n",
      "126/126 [==============================] - 5s 41ms/step - loss: 0.3164 - accuracy: 0.8859 - val_loss: 0.9103 - val_accuracy: 0.7188\n",
      "Epoch 21/30\n",
      "126/126 [==============================] - 5s 41ms/step - loss: 0.3119 - accuracy: 0.8892 - val_loss: 0.8066 - val_accuracy: 0.6875\n",
      "Epoch 22/30\n",
      "126/126 [==============================] - 5s 41ms/step - loss: 0.2982 - accuracy: 0.8930 - val_loss: 0.8980 - val_accuracy: 0.6875\n",
      "Epoch 23/30\n",
      "126/126 [==============================] - 5s 41ms/step - loss: 0.2984 - accuracy: 0.8957 - val_loss: 0.7360 - val_accuracy: 0.6875\n",
      "Epoch 24/30\n",
      "126/126 [==============================] - 5s 41ms/step - loss: 0.2902 - accuracy: 0.8988 - val_loss: 0.9805 - val_accuracy: 0.6875\n",
      "Epoch 25/30\n",
      "126/126 [==============================] - 5s 41ms/step - loss: 0.2764 - accuracy: 0.8982 - val_loss: 0.8258 - val_accuracy: 0.6875\n",
      "Epoch 26/30\n",
      "126/126 [==============================] - 5s 41ms/step - loss: 0.2610 - accuracy: 0.9069 - val_loss: 0.6873 - val_accuracy: 0.6875\n",
      "Epoch 27/30\n",
      "126/126 [==============================] - 5s 41ms/step - loss: 0.2583 - accuracy: 0.9134 - val_loss: 0.8064 - val_accuracy: 0.7188\n",
      "Epoch 28/30\n",
      "126/126 [==============================] - 5s 41ms/step - loss: 0.2590 - accuracy: 0.9086 - val_loss: 0.7184 - val_accuracy: 0.6875\n",
      "Epoch 29/30\n",
      "126/126 [==============================] - 5s 41ms/step - loss: 0.2455 - accuracy: 0.9098 - val_loss: 0.7483 - val_accuracy: 0.6875\n",
      "Epoch 30/30\n",
      "126/126 [==============================] - 5s 41ms/step - loss: 0.2636 - accuracy: 0.9064 - val_loss: 0.7783 - val_accuracy: 0.6875\n",
      "INFO:tensorflow:Assets written to: ../octnet/octnet_30epochs_6261_images_False_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for octnet: 0.816116\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.08956869 0.0906061  0.09067677 0.08774373]\n",
      "Training octnet for 0.09% of train size (aka 7513 images) with pretrained: True and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 23 trainable: 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  5/151 [..............................] - ETA: 13s - loss: 4.9223 - accuracy: 0.3263WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0184s vs `on_train_batch_end` time: 0.0547s). Check your callbacks.\n",
      "151/151 [==============================] - 8s 44ms/step - loss: 3.3382 - accuracy: 0.4436 - val_loss: 1.5704 - val_accuracy: 0.5000\n",
      "Epoch 2/30\n",
      "  1/151 [..............................] - ETA: 6s - loss: 1.5476 - accuracy: 0.6800"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151/151 [==============================] - 6s 40ms/step - loss: 1.4471 - accuracy: 0.6135 - val_loss: 1.0491 - val_accuracy: 0.5625\n",
      "Epoch 3/30\n",
      "151/151 [==============================] - 6s 40ms/step - loss: 1.0159 - accuracy: 0.6791 - val_loss: 0.7491 - val_accuracy: 0.7188\n",
      "Epoch 4/30\n",
      "151/151 [==============================] - 6s 40ms/step - loss: 0.8695 - accuracy: 0.7030 - val_loss: 0.7145 - val_accuracy: 0.6875\n",
      "Epoch 5/30\n",
      "151/151 [==============================] - 6s 41ms/step - loss: 0.7539 - accuracy: 0.7374 - val_loss: 0.8516 - val_accuracy: 0.6562\n",
      "Epoch 6/30\n",
      "151/151 [==============================] - 6s 41ms/step - loss: 0.6838 - accuracy: 0.7657 - val_loss: 0.6816 - val_accuracy: 0.7188\n",
      "Epoch 7/30\n",
      "151/151 [==============================] - 6s 41ms/step - loss: 0.6258 - accuracy: 0.7760 - val_loss: 0.6494 - val_accuracy: 0.7188\n",
      "Epoch 8/30\n",
      "151/151 [==============================] - 6s 41ms/step - loss: 0.5619 - accuracy: 0.8019 - val_loss: 0.8386 - val_accuracy: 0.7500\n",
      "Epoch 9/30\n",
      "151/151 [==============================] - 6s 41ms/step - loss: 0.5576 - accuracy: 0.8003 - val_loss: 0.6675 - val_accuracy: 0.6875\n",
      "Epoch 10/30\n",
      "151/151 [==============================] - 6s 41ms/step - loss: 0.4745 - accuracy: 0.8329 - val_loss: 0.6121 - val_accuracy: 0.7500\n",
      "Epoch 11/30\n",
      "151/151 [==============================] - 6s 41ms/step - loss: 0.4785 - accuracy: 0.8194 - val_loss: 0.7782 - val_accuracy: 0.7500\n",
      "Epoch 12/30\n",
      "151/151 [==============================] - 6s 41ms/step - loss: 0.4378 - accuracy: 0.8327 - val_loss: 0.5211 - val_accuracy: 0.7500\n",
      "Epoch 13/30\n",
      "151/151 [==============================] - 6s 41ms/step - loss: 0.4346 - accuracy: 0.8459 - val_loss: 0.6528 - val_accuracy: 0.7500\n",
      "Epoch 14/30\n",
      "151/151 [==============================] - 6s 41ms/step - loss: 0.3989 - accuracy: 0.8543 - val_loss: 0.6975 - val_accuracy: 0.7500\n",
      "Epoch 15/30\n",
      "151/151 [==============================] - 6s 41ms/step - loss: 0.3715 - accuracy: 0.8675 - val_loss: 0.8154 - val_accuracy: 0.7500\n",
      "Epoch 16/30\n",
      "151/151 [==============================] - 6s 41ms/step - loss: 0.3546 - accuracy: 0.8697 - val_loss: 0.8677 - val_accuracy: 0.7188\n",
      "Epoch 17/30\n",
      "151/151 [==============================] - 6s 41ms/step - loss: 0.3331 - accuracy: 0.8870 - val_loss: 0.7824 - val_accuracy: 0.7812\n",
      "Epoch 18/30\n",
      "151/151 [==============================] - 6s 41ms/step - loss: 0.3240 - accuracy: 0.8857 - val_loss: 0.7355 - val_accuracy: 0.7500\n",
      "Epoch 19/30\n",
      "151/151 [==============================] - 6s 41ms/step - loss: 0.3211 - accuracy: 0.8833 - val_loss: 0.6378 - val_accuracy: 0.7812\n",
      "Epoch 20/30\n",
      "151/151 [==============================] - 6s 41ms/step - loss: 0.2813 - accuracy: 0.9025 - val_loss: 0.7975 - val_accuracy: 0.7500\n",
      "Epoch 21/30\n",
      "151/151 [==============================] - 6s 41ms/step - loss: 0.2736 - accuracy: 0.9057 - val_loss: 0.7771 - val_accuracy: 0.7812\n",
      "Epoch 22/30\n",
      "151/151 [==============================] - 6s 41ms/step - loss: 0.2653 - accuracy: 0.9053 - val_loss: 0.6681 - val_accuracy: 0.7812\n",
      "Epoch 23/30\n",
      "151/151 [==============================] - 6s 41ms/step - loss: 0.2505 - accuracy: 0.9144 - val_loss: 0.6911 - val_accuracy: 0.8125\n",
      "Epoch 24/30\n",
      "151/151 [==============================] - 6s 41ms/step - loss: 0.2644 - accuracy: 0.9080 - val_loss: 0.7726 - val_accuracy: 0.7500\n",
      "Epoch 25/30\n",
      "151/151 [==============================] - 6s 41ms/step - loss: 0.2343 - accuracy: 0.9169 - val_loss: 0.6476 - val_accuracy: 0.7812\n",
      "Epoch 26/30\n",
      "151/151 [==============================] - 6s 41ms/step - loss: 0.2406 - accuracy: 0.9157 - val_loss: 0.7536 - val_accuracy: 0.7812\n",
      "Epoch 27/30\n",
      "151/151 [==============================] - 6s 41ms/step - loss: 0.2524 - accuracy: 0.9082 - val_loss: 0.7432 - val_accuracy: 0.7500\n",
      "Epoch 28/30\n",
      "151/151 [==============================] - 6s 41ms/step - loss: 0.2338 - accuracy: 0.9216 - val_loss: 0.6731 - val_accuracy: 0.7812\n",
      "Epoch 29/30\n",
      "151/151 [==============================] - 6s 41ms/step - loss: 0.2338 - accuracy: 0.9190 - val_loss: 0.7832 - val_accuracy: 0.7812\n",
      "Epoch 30/30\n",
      "151/151 [==============================] - 6s 41ms/step - loss: 0.2269 - accuracy: 0.9195 - val_loss: 0.7546 - val_accuracy: 0.7812\n",
      "INFO:tensorflow:Assets written to: ../octnet/octnet_30epochs_7514_images_False_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for octnet: 0.859504\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.09804294 0.10108856 0.10213253 0.09842154]\n",
      "Training octnet for 0.1% of train size (aka 8348 images) with pretrained: True and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 23 trainable: 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  5/167 [..............................] - ETA: 14s - loss: 4.4943 - accuracy: 0.3519WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0188s vs `on_train_batch_end` time: 0.0534s). Check your callbacks.\n",
      "167/167 [==============================] - 8s 44ms/step - loss: 2.9739 - accuracy: 0.4347 - val_loss: 2.8153 - val_accuracy: 0.5000\n",
      "Epoch 2/30\n",
      "  1/167 [..............................] - ETA: 6s - loss: 1.5753 - accuracy: 0.6200"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "167/167 [==============================] - 7s 41ms/step - loss: 1.3735 - accuracy: 0.6001 - val_loss: 0.8420 - val_accuracy: 0.5625\n",
      "Epoch 3/30\n",
      "167/167 [==============================] - 7s 40ms/step - loss: 1.0293 - accuracy: 0.6578 - val_loss: 0.6032 - val_accuracy: 0.7188\n",
      "Epoch 4/30\n",
      "167/167 [==============================] - 7s 41ms/step - loss: 0.8025 - accuracy: 0.7157 - val_loss: 0.7146 - val_accuracy: 0.7188\n",
      "Epoch 5/30\n",
      "167/167 [==============================] - 7s 41ms/step - loss: 0.7133 - accuracy: 0.7412 - val_loss: 0.6561 - val_accuracy: 0.6875\n",
      "Epoch 6/30\n",
      "167/167 [==============================] - 7s 41ms/step - loss: 0.6417 - accuracy: 0.7763 - val_loss: 0.5276 - val_accuracy: 0.8125\n",
      "Epoch 7/30\n",
      "167/167 [==============================] - 7s 41ms/step - loss: 0.5976 - accuracy: 0.7876 - val_loss: 0.6162 - val_accuracy: 0.7188\n",
      "Epoch 8/30\n",
      "167/167 [==============================] - 7s 41ms/step - loss: 0.5364 - accuracy: 0.8156 - val_loss: 0.6633 - val_accuracy: 0.7500\n",
      "Epoch 9/30\n",
      "167/167 [==============================] - 7s 41ms/step - loss: 0.4924 - accuracy: 0.8233 - val_loss: 0.5838 - val_accuracy: 0.7500\n",
      "Epoch 10/30\n",
      "167/167 [==============================] - 7s 41ms/step - loss: 0.4636 - accuracy: 0.8316 - val_loss: 0.4330 - val_accuracy: 0.7812\n",
      "Epoch 11/30\n",
      "167/167 [==============================] - 7s 41ms/step - loss: 0.4371 - accuracy: 0.8408 - val_loss: 0.4923 - val_accuracy: 0.8125\n",
      "Epoch 12/30\n",
      "167/167 [==============================] - 7s 41ms/step - loss: 0.4193 - accuracy: 0.8469 - val_loss: 0.5007 - val_accuracy: 0.7812\n",
      "Epoch 13/30\n",
      "167/167 [==============================] - 7s 41ms/step - loss: 0.3760 - accuracy: 0.8667 - val_loss: 0.5187 - val_accuracy: 0.7500\n",
      "Epoch 14/30\n",
      "167/167 [==============================] - 7s 41ms/step - loss: 0.3645 - accuracy: 0.8710 - val_loss: 0.4577 - val_accuracy: 0.7812\n",
      "Epoch 15/30\n",
      "167/167 [==============================] - 7s 41ms/step - loss: 0.3480 - accuracy: 0.8757 - val_loss: 0.3987 - val_accuracy: 0.8125\n",
      "Epoch 16/30\n",
      "167/167 [==============================] - 7s 41ms/step - loss: 0.3392 - accuracy: 0.8752 - val_loss: 0.5058 - val_accuracy: 0.8125\n",
      "Epoch 17/30\n",
      "167/167 [==============================] - 7s 41ms/step - loss: 0.3355 - accuracy: 0.8814 - val_loss: 0.4430 - val_accuracy: 0.8125\n",
      "Epoch 18/30\n",
      "167/167 [==============================] - 7s 41ms/step - loss: 0.3031 - accuracy: 0.8866 - val_loss: 0.4969 - val_accuracy: 0.8438\n",
      "Epoch 19/30\n",
      "167/167 [==============================] - 7s 41ms/step - loss: 0.2898 - accuracy: 0.8938 - val_loss: 0.3538 - val_accuracy: 0.8438\n",
      "Epoch 20/30\n",
      "167/167 [==============================] - 7s 41ms/step - loss: 0.2798 - accuracy: 0.8957 - val_loss: 0.4732 - val_accuracy: 0.8438\n",
      "Epoch 21/30\n",
      "167/167 [==============================] - 7s 41ms/step - loss: 0.2886 - accuracy: 0.8980 - val_loss: 0.3940 - val_accuracy: 0.8438\n",
      "Epoch 22/30\n",
      "167/167 [==============================] - 7s 41ms/step - loss: 0.2473 - accuracy: 0.9143 - val_loss: 0.3751 - val_accuracy: 0.8125\n",
      "Epoch 23/30\n",
      "167/167 [==============================] - 7s 41ms/step - loss: 0.2472 - accuracy: 0.9103 - val_loss: 0.3943 - val_accuracy: 0.8438\n",
      "Epoch 24/30\n",
      "167/167 [==============================] - 7s 41ms/step - loss: 0.2469 - accuracy: 0.9149 - val_loss: 0.3967 - val_accuracy: 0.8438\n",
      "Epoch 25/30\n",
      "167/167 [==============================] - 7s 41ms/step - loss: 0.2460 - accuracy: 0.9149 - val_loss: 0.3452 - val_accuracy: 0.8438\n",
      "Epoch 26/30\n",
      "167/167 [==============================] - 7s 41ms/step - loss: 0.2260 - accuracy: 0.9229 - val_loss: 0.3732 - val_accuracy: 0.8438\n",
      "Epoch 27/30\n",
      "167/167 [==============================] - 7s 41ms/step - loss: 0.2200 - accuracy: 0.9212 - val_loss: 0.3885 - val_accuracy: 0.8438\n",
      "Epoch 28/30\n",
      "167/167 [==============================] - 7s 41ms/step - loss: 0.2056 - accuracy: 0.9310 - val_loss: 0.3944 - val_accuracy: 0.8750\n",
      "Epoch 29/30\n",
      "167/167 [==============================] - 7s 41ms/step - loss: 0.2118 - accuracy: 0.9244 - val_loss: 0.4046 - val_accuracy: 0.8438\n",
      "Epoch 30/30\n",
      "167/167 [==============================] - 7s 41ms/step - loss: 0.2107 - accuracy: 0.9242 - val_loss: 0.3904 - val_accuracy: 0.8438\n",
      "INFO:tensorflow:Assets written to: ../octnet/octnet_30epochs_8348_images_False_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for octnet: 0.862603\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.25061752 0.25077275 0.247092   0.24860724]\n",
      "Training octnet for 0.25% of train size (aka 20871 images) with pretrained: True and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 23 trainable: 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  5/418 [..............................] - ETA: 37s - loss: 4.8452 - accuracy: 0.3763WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0186s vs `on_train_batch_end` time: 0.0545s). Check your callbacks.\n",
      "418/418 [==============================] - 18s 41ms/step - loss: 2.2952 - accuracy: 0.5481 - val_loss: 0.7210 - val_accuracy: 0.6875\n",
      "Epoch 2/30\n",
      "  1/418 [..............................] - ETA: 17s - loss: 0.7765 - accuracy: 0.8200"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "418/418 [==============================] - 17s 40ms/step - loss: 0.7748 - accuracy: 0.7430 - val_loss: 0.5982 - val_accuracy: 0.6875\n",
      "Epoch 3/30\n",
      "418/418 [==============================] - 17s 41ms/step - loss: 0.6117 - accuracy: 0.7870 - val_loss: 0.5919 - val_accuracy: 0.7188\n",
      "Epoch 4/30\n",
      "418/418 [==============================] - 17s 41ms/step - loss: 0.5231 - accuracy: 0.8178 - val_loss: 0.5208 - val_accuracy: 0.7188\n",
      "Epoch 5/30\n",
      "418/418 [==============================] - 17s 41ms/step - loss: 0.4702 - accuracy: 0.8344 - val_loss: 0.4587 - val_accuracy: 0.8125\n",
      "Epoch 6/30\n",
      "418/418 [==============================] - 17s 41ms/step - loss: 0.4301 - accuracy: 0.8490 - val_loss: 0.3444 - val_accuracy: 0.9062\n",
      "Epoch 7/30\n",
      "418/418 [==============================] - 17s 41ms/step - loss: 0.3837 - accuracy: 0.8632 - val_loss: 0.2602 - val_accuracy: 0.8750\n",
      "Epoch 8/30\n",
      "418/418 [==============================] - 17s 41ms/step - loss: 0.3463 - accuracy: 0.8783 - val_loss: 0.2434 - val_accuracy: 0.9375\n",
      "Epoch 9/30\n",
      "418/418 [==============================] - 17s 41ms/step - loss: 0.3238 - accuracy: 0.8835 - val_loss: 0.1643 - val_accuracy: 0.9375\n",
      "Epoch 10/30\n",
      "418/418 [==============================] - 17s 41ms/step - loss: 0.2903 - accuracy: 0.9004 - val_loss: 0.1437 - val_accuracy: 0.9688\n",
      "Epoch 11/30\n",
      "418/418 [==============================] - 17s 41ms/step - loss: 0.2630 - accuracy: 0.9108 - val_loss: 0.2445 - val_accuracy: 0.9375\n",
      "Epoch 12/30\n",
      "418/418 [==============================] - 17s 41ms/step - loss: 0.2411 - accuracy: 0.9150 - val_loss: 0.1033 - val_accuracy: 0.9688\n",
      "Epoch 13/30\n",
      "418/418 [==============================] - 17s 41ms/step - loss: 0.2212 - accuracy: 0.9231 - val_loss: 0.1534 - val_accuracy: 0.9375\n",
      "Epoch 14/30\n",
      "418/418 [==============================] - 17s 41ms/step - loss: 0.1987 - accuracy: 0.9298 - val_loss: 0.1732 - val_accuracy: 0.9375\n",
      "Epoch 15/30\n",
      "418/418 [==============================] - 17s 41ms/step - loss: 0.1877 - accuracy: 0.9340 - val_loss: 0.1351 - val_accuracy: 0.9688\n",
      "Epoch 16/30\n",
      "418/418 [==============================] - 17s 41ms/step - loss: 0.1713 - accuracy: 0.9411 - val_loss: 0.1485 - val_accuracy: 0.9688\n",
      "Epoch 17/30\n",
      "418/418 [==============================] - 17s 41ms/step - loss: 0.1497 - accuracy: 0.9473 - val_loss: 0.0917 - val_accuracy: 0.9688\n",
      "Epoch 18/30\n",
      "418/418 [==============================] - 17s 41ms/step - loss: 0.1406 - accuracy: 0.9528 - val_loss: 0.0975 - val_accuracy: 0.9375\n",
      "Epoch 19/30\n",
      "418/418 [==============================] - 17s 41ms/step - loss: 0.1312 - accuracy: 0.9541 - val_loss: 0.0474 - val_accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "418/418 [==============================] - 17s 41ms/step - loss: 0.1120 - accuracy: 0.9616 - val_loss: 0.0743 - val_accuracy: 0.9688\n",
      "Epoch 21/30\n",
      "418/418 [==============================] - 17s 41ms/step - loss: 0.1085 - accuracy: 0.9631 - val_loss: 0.0754 - val_accuracy: 0.9688\n",
      "Epoch 22/30\n",
      "418/418 [==============================] - 17s 41ms/step - loss: 0.1008 - accuracy: 0.9656 - val_loss: 0.1162 - val_accuracy: 0.9062\n",
      "Epoch 23/30\n",
      "418/418 [==============================] - 17s 41ms/step - loss: 0.0951 - accuracy: 0.9675 - val_loss: 0.1206 - val_accuracy: 0.9688\n",
      "Epoch 24/30\n",
      "418/418 [==============================] - 17s 41ms/step - loss: 0.0910 - accuracy: 0.9693 - val_loss: 0.1166 - val_accuracy: 0.9688\n",
      "Epoch 25/30\n",
      "418/418 [==============================] - 17s 41ms/step - loss: 0.0807 - accuracy: 0.9714 - val_loss: 0.0938 - val_accuracy: 0.9375\n",
      "Epoch 26/30\n",
      "418/418 [==============================] - 17s 41ms/step - loss: 0.0842 - accuracy: 0.9716 - val_loss: 0.1631 - val_accuracy: 0.9375\n",
      "Epoch 27/30\n",
      "418/418 [==============================] - 17s 40ms/step - loss: 0.0825 - accuracy: 0.9725 - val_loss: 0.0515 - val_accuracy: 0.9688\n",
      "Epoch 28/30\n",
      "418/418 [==============================] - 17s 41ms/step - loss: 0.0703 - accuracy: 0.9769 - val_loss: 0.1167 - val_accuracy: 0.9375\n",
      "Epoch 29/30\n",
      "418/418 [==============================] - 17s 40ms/step - loss: 0.0669 - accuracy: 0.9776 - val_loss: 0.1052 - val_accuracy: 0.9688\n",
      "Epoch 30/30\n",
      "418/418 [==============================] - 17s 40ms/step - loss: 0.0654 - accuracy: 0.9774 - val_loss: 0.1334 - val_accuracy: 0.9688\n",
      "INFO:tensorflow:Assets written to: ../octnet/octnet_30epochs_20871_images_False_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for octnet: 0.939050\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.39931598 0.39956995 0.40236165 0.40076602]\n",
      "Training octnet for 0.4% of train size (aka 33393 images) with pretrained: True and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 23 trainable: 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  5/668 [..............................] - ETA: 58s - loss: 5.3750 - accuracy: 0.3017 WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0184s vs `on_train_batch_end` time: 0.0535s). Check your callbacks.\n",
      "668/668 [==============================] - 28s 41ms/step - loss: 2.1166 - accuracy: 0.5429 - val_loss: 0.7872 - val_accuracy: 0.6250\n",
      "Epoch 2/30\n",
      "  1/668 [..............................] - ETA: 27s - loss: 1.2946 - accuracy: 0.6600"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "668/668 [==============================] - 27s 40ms/step - loss: 0.6782 - accuracy: 0.7643 - val_loss: 0.5274 - val_accuracy: 0.7812\n",
      "Epoch 3/30\n",
      "668/668 [==============================] - 27s 41ms/step - loss: 0.5147 - accuracy: 0.8180 - val_loss: 0.4338 - val_accuracy: 0.8125\n",
      "Epoch 4/30\n",
      "668/668 [==============================] - 27s 41ms/step - loss: 0.4312 - accuracy: 0.8507 - val_loss: 0.2326 - val_accuracy: 0.9375\n",
      "Epoch 5/30\n",
      "668/668 [==============================] - 27s 41ms/step - loss: 0.3599 - accuracy: 0.8790 - val_loss: 0.2055 - val_accuracy: 0.9375\n",
      "Epoch 6/30\n",
      "668/668 [==============================] - 27s 41ms/step - loss: 0.3156 - accuracy: 0.8903 - val_loss: 0.1827 - val_accuracy: 0.9375\n",
      "Epoch 7/30\n",
      "668/668 [==============================] - 27s 41ms/step - loss: 0.2858 - accuracy: 0.9046 - val_loss: 0.1788 - val_accuracy: 0.9375\n",
      "Epoch 8/30\n",
      "668/668 [==============================] - 27s 41ms/step - loss: 0.2518 - accuracy: 0.9156 - val_loss: 0.0816 - val_accuracy: 0.9688\n",
      "Epoch 9/30\n",
      "668/668 [==============================] - 27s 41ms/step - loss: 0.2237 - accuracy: 0.9229 - val_loss: 0.0388 - val_accuracy: 1.0000\n",
      "Epoch 10/30\n",
      "668/668 [==============================] - 27s 41ms/step - loss: 0.2013 - accuracy: 0.9331 - val_loss: 0.0971 - val_accuracy: 0.9375\n",
      "Epoch 11/30\n",
      "668/668 [==============================] - 27s 41ms/step - loss: 0.1926 - accuracy: 0.9349 - val_loss: 0.0130 - val_accuracy: 1.0000\n",
      "Epoch 12/30\n",
      "668/668 [==============================] - 27s 41ms/step - loss: 0.1723 - accuracy: 0.9428 - val_loss: 0.0168 - val_accuracy: 1.0000\n",
      "Epoch 13/30\n",
      "668/668 [==============================] - 27s 40ms/step - loss: 0.1538 - accuracy: 0.9500 - val_loss: 0.0125 - val_accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "668/668 [==============================] - 27s 41ms/step - loss: 0.1364 - accuracy: 0.9543 - val_loss: 0.0142 - val_accuracy: 1.0000\n",
      "Epoch 15/30\n",
      "668/668 [==============================] - 27s 41ms/step - loss: 0.1201 - accuracy: 0.9581 - val_loss: 0.0099 - val_accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "668/668 [==============================] - 27s 41ms/step - loss: 0.1044 - accuracy: 0.9648 - val_loss: 0.0138 - val_accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "668/668 [==============================] - 27s 40ms/step - loss: 0.1035 - accuracy: 0.9649 - val_loss: 0.0327 - val_accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "668/668 [==============================] - 27s 40ms/step - loss: 0.0972 - accuracy: 0.9671 - val_loss: 0.0084 - val_accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "668/668 [==============================] - 27s 40ms/step - loss: 0.0841 - accuracy: 0.9705 - val_loss: 0.0216 - val_accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "668/668 [==============================] - 27s 41ms/step - loss: 0.0791 - accuracy: 0.9728 - val_loss: 0.0194 - val_accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "668/668 [==============================] - 27s 40ms/step - loss: 0.0705 - accuracy: 0.9760 - val_loss: 0.0064 - val_accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "668/668 [==============================] - 27s 40ms/step - loss: 0.0648 - accuracy: 0.9778 - val_loss: 0.0043 - val_accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "668/668 [==============================] - 27s 40ms/step - loss: 0.0617 - accuracy: 0.9791 - val_loss: 0.0054 - val_accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "668/668 [==============================] - 27s 40ms/step - loss: 0.0553 - accuracy: 0.9818 - val_loss: 0.0071 - val_accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "668/668 [==============================] - 27s 40ms/step - loss: 0.0533 - accuracy: 0.9818 - val_loss: 0.0072 - val_accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "668/668 [==============================] - 27s 41ms/step - loss: 0.0506 - accuracy: 0.9821 - val_loss: 0.0036 - val_accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "668/668 [==============================] - 27s 40ms/step - loss: 0.0519 - accuracy: 0.9819 - val_loss: 0.0044 - val_accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "668/668 [==============================] - 27s 40ms/step - loss: 0.0430 - accuracy: 0.9860 - val_loss: 0.0047 - val_accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "668/668 [==============================] - 27s 40ms/step - loss: 0.0459 - accuracy: 0.9854 - val_loss: 0.0053 - val_accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "668/668 [==============================] - 27s 40ms/step - loss: 0.0465 - accuracy: 0.9849 - val_loss: 0.0046 - val_accuracy: 1.0000\n",
      "INFO:tensorflow:Assets written to: ../octnet/octnet_30epochs_33394_images_False_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for octnet: 0.978306\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.50279308 0.49955651 0.50035249 0.49292015]\n",
      "Training octnet for 0.5% of train size (aka 41742 images) with pretrained: True and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 23 trainable: 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  5/835 [..............................] - ETA: 1:16 - loss: 4.7105 - accuracy: 0.2653WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0184s vs `on_train_batch_end` time: 0.0560s). Check your callbacks.\n",
      "835/835 [==============================] - 35s 41ms/step - loss: 1.8654 - accuracy: 0.5696 - val_loss: 0.5641 - val_accuracy: 0.7500\n",
      "Epoch 2/30\n",
      "  1/835 [..............................] - ETA: 34s - loss: 0.8420 - accuracy: 0.7200"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "835/835 [==============================] - 34s 40ms/step - loss: 0.5996 - accuracy: 0.7915 - val_loss: 0.4590 - val_accuracy: 0.7500\n",
      "Epoch 3/30\n",
      "835/835 [==============================] - 34s 41ms/step - loss: 0.4624 - accuracy: 0.8396 - val_loss: 0.2500 - val_accuracy: 0.9062\n",
      "Epoch 4/30\n",
      "835/835 [==============================] - 34s 41ms/step - loss: 0.3780 - accuracy: 0.8715 - val_loss: 0.2640 - val_accuracy: 0.9062\n",
      "Epoch 5/30\n",
      "835/835 [==============================] - 34s 41ms/step - loss: 0.3185 - accuracy: 0.8905 - val_loss: 0.0530 - val_accuracy: 1.0000\n",
      "Epoch 6/30\n",
      "835/835 [==============================] - 34s 41ms/step - loss: 0.2786 - accuracy: 0.9077 - val_loss: 0.0375 - val_accuracy: 1.0000\n",
      "Epoch 7/30\n",
      "835/835 [==============================] - 34s 41ms/step - loss: 0.2442 - accuracy: 0.9183 - val_loss: 0.0209 - val_accuracy: 1.0000\n",
      "Epoch 8/30\n",
      "835/835 [==============================] - 34s 41ms/step - loss: 0.2241 - accuracy: 0.9244 - val_loss: 0.0328 - val_accuracy: 1.0000\n",
      "Epoch 9/30\n",
      "835/835 [==============================] - 34s 41ms/step - loss: 0.2004 - accuracy: 0.9327 - val_loss: 0.0268 - val_accuracy: 1.0000\n",
      "Epoch 10/30\n",
      "835/835 [==============================] - 34s 41ms/step - loss: 0.1837 - accuracy: 0.9385 - val_loss: 0.0463 - val_accuracy: 1.0000\n",
      "Epoch 11/30\n",
      "835/835 [==============================] - 34s 41ms/step - loss: 0.1618 - accuracy: 0.9468 - val_loss: 0.0514 - val_accuracy: 0.9688\n",
      "Epoch 12/30\n",
      "835/835 [==============================] - 34s 41ms/step - loss: 0.1468 - accuracy: 0.9511 - val_loss: 0.0351 - val_accuracy: 1.0000\n",
      "Epoch 13/30\n",
      "835/835 [==============================] - 34s 41ms/step - loss: 0.1310 - accuracy: 0.9565 - val_loss: 0.0194 - val_accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "835/835 [==============================] - 34s 41ms/step - loss: 0.1209 - accuracy: 0.9585 - val_loss: 0.0164 - val_accuracy: 1.0000\n",
      "Epoch 15/30\n",
      "835/835 [==============================] - 34s 41ms/step - loss: 0.1018 - accuracy: 0.9661 - val_loss: 0.0144 - val_accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "835/835 [==============================] - 34s 40ms/step - loss: 0.0941 - accuracy: 0.9674 - val_loss: 0.0273 - val_accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "835/835 [==============================] - 34s 40ms/step - loss: 0.0862 - accuracy: 0.9699 - val_loss: 0.0135 - val_accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "835/835 [==============================] - 34s 40ms/step - loss: 0.0809 - accuracy: 0.9725 - val_loss: 0.0059 - val_accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "835/835 [==============================] - 34s 41ms/step - loss: 0.0738 - accuracy: 0.9760 - val_loss: 0.0080 - val_accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "835/835 [==============================] - 34s 41ms/step - loss: 0.0641 - accuracy: 0.9784 - val_loss: 0.0661 - val_accuracy: 0.9688\n",
      "Epoch 21/30\n",
      "835/835 [==============================] - 34s 40ms/step - loss: 0.0650 - accuracy: 0.9782 - val_loss: 0.0035 - val_accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "835/835 [==============================] - 34s 40ms/step - loss: 0.0541 - accuracy: 0.9811 - val_loss: 0.0283 - val_accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "835/835 [==============================] - 34s 41ms/step - loss: 0.0508 - accuracy: 0.9836 - val_loss: 0.0050 - val_accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "835/835 [==============================] - 34s 40ms/step - loss: 0.0511 - accuracy: 0.9829 - val_loss: 0.0150 - val_accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "835/835 [==============================] - 34s 40ms/step - loss: 0.0476 - accuracy: 0.9843 - val_loss: 0.0122 - val_accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "835/835 [==============================] - 34s 40ms/step - loss: 0.0424 - accuracy: 0.9853 - val_loss: 0.0218 - val_accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "835/835 [==============================] - 34s 40ms/step - loss: 0.0404 - accuracy: 0.9865 - val_loss: 0.0243 - val_accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "835/835 [==============================] - 34s 40ms/step - loss: 0.0383 - accuracy: 0.9870 - val_loss: 0.0134 - val_accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "835/835 [==============================] - 34s 40ms/step - loss: 0.0367 - accuracy: 0.9879 - val_loss: 0.0135 - val_accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "835/835 [==============================] - 34s 40ms/step - loss: 0.0375 - accuracy: 0.9874 - val_loss: 0.0285 - val_accuracy: 0.9688\n",
      "INFO:tensorflow:Assets written to: ../octnet/octnet_30epochs_41742_images_False_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for octnet: 0.979339\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.60167205 0.60102137 0.59878393 0.59203807]\n",
      "Training octnet for 0.6% of train size (aka 50090 images) with pretrained: True and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 23 trainable: 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "   5/1002 [..............................] - ETA: 1:27 - loss: 5.2930 - accuracy: 0.3355WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0187s vs `on_train_batch_end` time: 0.0529s). Check your callbacks.\n",
      "1002/1002 [==============================] - 43s 41ms/step - loss: 2.0227 - accuracy: 0.5731 - val_loss: 0.7046 - val_accuracy: 0.6875\n",
      "Epoch 2/30\n",
      "   1/1002 [..............................] - ETA: 40s - loss: 0.5407 - accuracy: 0.7600"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1002/1002 [==============================] - 41s 41ms/step - loss: 0.5887 - accuracy: 0.7958 - val_loss: 0.4988 - val_accuracy: 0.8125\n",
      "Epoch 3/30\n",
      "1002/1002 [==============================] - 41s 41ms/step - loss: 0.4624 - accuracy: 0.8405 - val_loss: 0.1733 - val_accuracy: 0.9375\n",
      "Epoch 4/30\n",
      "1002/1002 [==============================] - 41s 41ms/step - loss: 0.3703 - accuracy: 0.8727 - val_loss: 0.1078 - val_accuracy: 0.9375\n",
      "Epoch 5/30\n",
      "1002/1002 [==============================] - 41s 41ms/step - loss: 0.3123 - accuracy: 0.8937 - val_loss: 0.1368 - val_accuracy: 0.9688\n",
      "Epoch 6/30\n",
      "1002/1002 [==============================] - 41s 41ms/step - loss: 0.2727 - accuracy: 0.9073 - val_loss: 0.0724 - val_accuracy: 1.0000\n",
      "Epoch 7/30\n",
      "1002/1002 [==============================] - 41s 41ms/step - loss: 0.2387 - accuracy: 0.9211 - val_loss: 0.0929 - val_accuracy: 0.9688\n",
      "Epoch 8/30\n",
      "1002/1002 [==============================] - 41s 41ms/step - loss: 0.2182 - accuracy: 0.9286 - val_loss: 0.0282 - val_accuracy: 1.0000\n",
      "Epoch 9/30\n",
      "1002/1002 [==============================] - 41s 40ms/step - loss: 0.1977 - accuracy: 0.9345 - val_loss: 0.0472 - val_accuracy: 1.0000\n",
      "Epoch 10/30\n",
      "1002/1002 [==============================] - 40s 40ms/step - loss: 0.1725 - accuracy: 0.9421 - val_loss: 0.0297 - val_accuracy: 1.0000\n",
      "Epoch 11/30\n",
      "1002/1002 [==============================] - 41s 40ms/step - loss: 0.1585 - accuracy: 0.9484 - val_loss: 0.0279 - val_accuracy: 1.0000\n",
      "Epoch 12/30\n",
      "1002/1002 [==============================] - 40s 40ms/step - loss: 0.1384 - accuracy: 0.9538 - val_loss: 0.0170 - val_accuracy: 1.0000\n",
      "Epoch 13/30\n",
      "1002/1002 [==============================] - 41s 41ms/step - loss: 0.1217 - accuracy: 0.9583 - val_loss: 0.0471 - val_accuracy: 0.9688\n",
      "Epoch 14/30\n",
      "1002/1002 [==============================] - 40s 40ms/step - loss: 0.1149 - accuracy: 0.9619 - val_loss: 0.0119 - val_accuracy: 1.0000\n",
      "Epoch 15/30\n",
      "1002/1002 [==============================] - 41s 40ms/step - loss: 0.1008 - accuracy: 0.9665 - val_loss: 0.0128 - val_accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "1002/1002 [==============================] - 40s 40ms/step - loss: 0.0857 - accuracy: 0.9712 - val_loss: 0.0542 - val_accuracy: 0.9688\n",
      "Epoch 17/30\n",
      "1002/1002 [==============================] - 41s 40ms/step - loss: 0.0810 - accuracy: 0.9726 - val_loss: 0.0169 - val_accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "1002/1002 [==============================] - 41s 40ms/step - loss: 0.0756 - accuracy: 0.9743 - val_loss: 0.0173 - val_accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "1002/1002 [==============================] - 40s 40ms/step - loss: 0.0636 - accuracy: 0.9786 - val_loss: 0.0063 - val_accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "1002/1002 [==============================] - 41s 40ms/step - loss: 0.0637 - accuracy: 0.9790 - val_loss: 0.0042 - val_accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "1002/1002 [==============================] - 40s 40ms/step - loss: 0.0566 - accuracy: 0.9808 - val_loss: 0.0068 - val_accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "1002/1002 [==============================] - 41s 40ms/step - loss: 0.0532 - accuracy: 0.9814 - val_loss: 0.0045 - val_accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "1002/1002 [==============================] - 40s 40ms/step - loss: 0.0515 - accuracy: 0.9826 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "1002/1002 [==============================] - 40s 40ms/step - loss: 0.0441 - accuracy: 0.9848 - val_loss: 0.0113 - val_accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "1002/1002 [==============================] - 40s 40ms/step - loss: 0.0463 - accuracy: 0.9830 - val_loss: 0.0044 - val_accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "1002/1002 [==============================] - 41s 40ms/step - loss: 0.0400 - accuracy: 0.9860 - val_loss: 0.0214 - val_accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "1002/1002 [==============================] - 41s 41ms/step - loss: 0.0416 - accuracy: 0.9860 - val_loss: 0.0104 - val_accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "1002/1002 [==============================] - 41s 40ms/step - loss: 0.0372 - accuracy: 0.9875 - val_loss: 0.0056 - val_accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "1002/1002 [==============================] - 41s 40ms/step - loss: 0.0387 - accuracy: 0.9881 - val_loss: 0.0114 - val_accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "1002/1002 [==============================] - 40s 40ms/step - loss: 0.0371 - accuracy: 0.9876 - val_loss: 0.0126 - val_accuracy: 1.0000\n",
      "INFO:tensorflow:Assets written to: ../octnet/octnet_30epochs_50090_images_False_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for octnet: 0.979339\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.75265058 0.74871657 0.74929503 0.74837512]\n",
      "Training octnet for 0.75% of train size (aka 62613 images) with pretrained: True and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 23 trainable: 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "   5/1253 [..............................] - ETA: 1:53 - loss: 3.8071 - accuracy: 0.2923WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0185s vs `on_train_batch_end` time: 0.0550s). Check your callbacks.\n",
      "1253/1253 [==============================] - 52s 41ms/step - loss: 1.5949 - accuracy: 0.6126 - val_loss: 0.5491 - val_accuracy: 0.7500\n",
      "Epoch 2/30\n",
      "   1/1253 [..............................] - ETA: 50s - loss: 0.3778 - accuracy: 0.8800"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1253/1253 [==============================] - 51s 41ms/step - loss: 0.5115 - accuracy: 0.8218 - val_loss: 0.4830 - val_accuracy: 0.7812\n",
      "Epoch 3/30\n",
      "1253/1253 [==============================] - 51s 41ms/step - loss: 0.3733 - accuracy: 0.8738 - val_loss: 0.0951 - val_accuracy: 0.9688\n",
      "Epoch 4/30\n",
      "1253/1253 [==============================] - 51s 41ms/step - loss: 0.3036 - accuracy: 0.8995 - val_loss: 0.0390 - val_accuracy: 1.0000\n",
      "Epoch 5/30\n",
      "1253/1253 [==============================] - 51s 41ms/step - loss: 0.2643 - accuracy: 0.9129 - val_loss: 0.0953 - val_accuracy: 0.9688\n",
      "Epoch 6/30\n",
      "1253/1253 [==============================] - 51s 41ms/step - loss: 0.2290 - accuracy: 0.9256 - val_loss: 0.0655 - val_accuracy: 1.0000\n",
      "Epoch 7/30\n",
      "1253/1253 [==============================] - 51s 41ms/step - loss: 0.2109 - accuracy: 0.9317 - val_loss: 0.0140 - val_accuracy: 1.0000\n",
      "Epoch 8/30\n",
      "1253/1253 [==============================] - 51s 41ms/step - loss: 0.1851 - accuracy: 0.9398 - val_loss: 0.0119 - val_accuracy: 1.0000\n",
      "Epoch 9/30\n",
      "1253/1253 [==============================] - 51s 41ms/step - loss: 0.1667 - accuracy: 0.9434 - val_loss: 0.0138 - val_accuracy: 1.0000\n",
      "Epoch 10/30\n",
      "1253/1253 [==============================] - 51s 41ms/step - loss: 0.1479 - accuracy: 0.9515 - val_loss: 0.0073 - val_accuracy: 1.0000\n",
      "Epoch 11/30\n",
      "1253/1253 [==============================] - 51s 41ms/step - loss: 0.1368 - accuracy: 0.9546 - val_loss: 0.0069 - val_accuracy: 1.0000\n",
      "Epoch 12/30\n",
      "1253/1253 [==============================] - 51s 41ms/step - loss: 0.1170 - accuracy: 0.9614 - val_loss: 0.0053 - val_accuracy: 1.0000\n",
      "Epoch 13/30\n",
      "1253/1253 [==============================] - 51s 40ms/step - loss: 0.1043 - accuracy: 0.9661 - val_loss: 0.0158 - val_accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "1253/1253 [==============================] - 51s 40ms/step - loss: 0.0924 - accuracy: 0.9687 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 15/30\n",
      "1253/1253 [==============================] - 51s 40ms/step - loss: 0.0849 - accuracy: 0.9729 - val_loss: 0.0129 - val_accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "1253/1253 [==============================] - 52s 41ms/step - loss: 0.0807 - accuracy: 0.9736 - val_loss: 0.0193 - val_accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "1253/1253 [==============================] - 51s 40ms/step - loss: 0.0717 - accuracy: 0.9756 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "1253/1253 [==============================] - 51s 41ms/step - loss: 0.0675 - accuracy: 0.9779 - val_loss: 0.0070 - val_accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "1253/1253 [==============================] - 51s 41ms/step - loss: 0.0632 - accuracy: 0.9790 - val_loss: 0.0207 - val_accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "1253/1253 [==============================] - 51s 40ms/step - loss: 0.0530 - accuracy: 0.9820 - val_loss: 0.0067 - val_accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "1253/1253 [==============================] - 51s 41ms/step - loss: 0.0513 - accuracy: 0.9824 - val_loss: 0.0061 - val_accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "1253/1253 [==============================] - 51s 40ms/step - loss: 0.0447 - accuracy: 0.9847 - val_loss: 0.0095 - val_accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "1253/1253 [==============================] - 51s 40ms/step - loss: 0.0441 - accuracy: 0.9852 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "1253/1253 [==============================] - 51s 40ms/step - loss: 0.0396 - accuracy: 0.9868 - val_loss: 0.0187 - val_accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "1253/1253 [==============================] - 51s 41ms/step - loss: 0.0386 - accuracy: 0.9864 - val_loss: 0.0170 - val_accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "1253/1253 [==============================] - 51s 40ms/step - loss: 0.0371 - accuracy: 0.9887 - val_loss: 0.0050 - val_accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "1253/1253 [==============================] - 51s 40ms/step - loss: 0.0325 - accuracy: 0.9892 - val_loss: 0.0112 - val_accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "1253/1253 [==============================] - 51s 41ms/step - loss: 0.0332 - accuracy: 0.9884 - val_loss: 0.0192 - val_accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "1253/1253 [==============================] - 51s 40ms/step - loss: 0.0323 - accuracy: 0.9889 - val_loss: 0.0089 - val_accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "1253/1253 [==============================] - 51s 41ms/step - loss: 0.0317 - accuracy: 0.9896 - val_loss: 0.0439 - val_accuracy: 0.9688\n",
      "INFO:tensorflow:Assets written to: ../octnet/octnet_30epochs_62613_images_False_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for octnet: 0.989669\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.89895497 0.90022846 0.90306662 0.89809656]\n",
      "Training octnet for 0.9% of train size (aka 75135 images) with pretrained: True and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 23 trainable: 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "   5/1503 [..............................] - ETA: 2:13 - loss: 4.2515 - accuracy: 0.3844WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0182s vs `on_train_batch_end` time: 0.0541s). Check your callbacks.\n",
      "1503/1503 [==============================] - 62s 40ms/step - loss: 1.6632 - accuracy: 0.6235 - val_loss: 0.5646 - val_accuracy: 0.7812\n",
      "Epoch 2/30\n",
      "   1/1503 [..............................] - ETA: 1:00 - loss: 0.6076 - accuracy: 0.8000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1503/1503 [==============================] - 61s 41ms/step - loss: 0.4860 - accuracy: 0.8283 - val_loss: 0.2446 - val_accuracy: 0.9062\n",
      "Epoch 3/30\n",
      "1503/1503 [==============================] - 62s 41ms/step - loss: 0.3599 - accuracy: 0.8747 - val_loss: 0.1155 - val_accuracy: 0.9375\n",
      "Epoch 4/30\n",
      "1503/1503 [==============================] - 62s 41ms/step - loss: 0.2918 - accuracy: 0.9025 - val_loss: 0.0583 - val_accuracy: 0.9688\n",
      "Epoch 5/30\n",
      "1503/1503 [==============================] - 62s 41ms/step - loss: 0.2515 - accuracy: 0.9175 - val_loss: 0.0689 - val_accuracy: 1.0000\n",
      "Epoch 6/30\n",
      "1503/1503 [==============================] - 61s 41ms/step - loss: 0.2172 - accuracy: 0.9279 - val_loss: 0.0460 - val_accuracy: 1.0000\n",
      "Epoch 7/30\n",
      "1503/1503 [==============================] - 61s 41ms/step - loss: 0.1905 - accuracy: 0.9378 - val_loss: 0.0265 - val_accuracy: 1.0000\n",
      "Epoch 8/30\n",
      "1503/1503 [==============================] - 61s 41ms/step - loss: 0.1621 - accuracy: 0.9463 - val_loss: 0.0408 - val_accuracy: 1.0000\n",
      "Epoch 9/30\n",
      "1503/1503 [==============================] - 61s 41ms/step - loss: 0.1467 - accuracy: 0.9503 - val_loss: 0.0150 - val_accuracy: 1.0000\n",
      "Epoch 10/30\n",
      "1503/1503 [==============================] - 61s 41ms/step - loss: 0.1275 - accuracy: 0.9580 - val_loss: 0.0349 - val_accuracy: 1.0000\n",
      "Epoch 11/30\n",
      "1503/1503 [==============================] - 61s 41ms/step - loss: 0.1157 - accuracy: 0.9618 - val_loss: 0.0181 - val_accuracy: 1.0000\n",
      "Epoch 12/30\n",
      "1503/1503 [==============================] - 61s 41ms/step - loss: 0.0991 - accuracy: 0.9670 - val_loss: 0.0121 - val_accuracy: 1.0000\n",
      "Epoch 13/30\n",
      "1503/1503 [==============================] - 61s 41ms/step - loss: 0.0901 - accuracy: 0.9707 - val_loss: 0.0419 - val_accuracy: 0.9688\n",
      "Epoch 14/30\n",
      "1503/1503 [==============================] - 61s 41ms/step - loss: 0.0732 - accuracy: 0.9748 - val_loss: 0.0181 - val_accuracy: 1.0000\n",
      "Epoch 15/30\n",
      "1503/1503 [==============================] - 61s 41ms/step - loss: 0.0682 - accuracy: 0.9774 - val_loss: 0.0115 - val_accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "1503/1503 [==============================] - 61s 40ms/step - loss: 0.0602 - accuracy: 0.9787 - val_loss: 0.0102 - val_accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "1503/1503 [==============================] - 61s 41ms/step - loss: 0.0507 - accuracy: 0.9831 - val_loss: 0.0120 - val_accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "1503/1503 [==============================] - 61s 41ms/step - loss: 0.0465 - accuracy: 0.9842 - val_loss: 0.0062 - val_accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "1503/1503 [==============================] - 61s 41ms/step - loss: 0.0446 - accuracy: 0.9845 - val_loss: 0.0240 - val_accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "1503/1503 [==============================] - 61s 41ms/step - loss: 0.0386 - accuracy: 0.9867 - val_loss: 0.0562 - val_accuracy: 0.9688\n",
      "Epoch 21/30\n",
      "1503/1503 [==============================] - 61s 41ms/step - loss: 0.0354 - accuracy: 0.9881 - val_loss: 0.0123 - val_accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "1503/1503 [==============================] - 61s 41ms/step - loss: 0.0328 - accuracy: 0.9886 - val_loss: 0.0384 - val_accuracy: 0.9688\n",
      "Epoch 23/30\n",
      "1503/1503 [==============================] - 61s 41ms/step - loss: 0.0318 - accuracy: 0.9896 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "1503/1503 [==============================] - 61s 41ms/step - loss: 0.0298 - accuracy: 0.9895 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "1503/1503 [==============================] - 61s 41ms/step - loss: 0.0303 - accuracy: 0.9910 - val_loss: 0.0184 - val_accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "1503/1503 [==============================] - 61s 40ms/step - loss: 0.0268 - accuracy: 0.9905 - val_loss: 0.0610 - val_accuracy: 0.9688\n",
      "Epoch 27/30\n",
      "1503/1503 [==============================] - 61s 41ms/step - loss: 0.0249 - accuracy: 0.9918 - val_loss: 0.0547 - val_accuracy: 0.9688\n",
      "Epoch 28/30\n",
      "1503/1503 [==============================] - 61s 41ms/step - loss: 0.0225 - accuracy: 0.9925 - val_loss: 0.0213 - val_accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "1503/1503 [==============================] - 61s 41ms/step - loss: 0.0223 - accuracy: 0.9924 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "1503/1503 [==============================] - 61s 41ms/step - loss: 0.0237 - accuracy: 0.9920 - val_loss: 0.0157 - val_accuracy: 1.0000\n",
      "INFO:tensorflow:Assets written to: ../octnet/octnet_30epochs_75136_images_False_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for octnet: 0.985537\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [1. 1. 1. 1.]\n",
      "Training octnet for 1.0% of train size (aka 83484 images) with pretrained: True and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 23 trainable: 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "   5/1670 [..............................] - ETA: 2:24 - loss: 4.6479 - accuracy: 0.2979WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0182s vs `on_train_batch_end` time: 0.0527s). Check your callbacks.\n",
      "1670/1670 [==============================] - 69s 41ms/step - loss: 1.4302 - accuracy: 0.6413 - val_loss: 0.8148 - val_accuracy: 0.7188\n",
      "Epoch 2/30\n",
      "   1/1670 [..............................] - ETA: 1:08 - loss: 0.2970 - accuracy: 0.9000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1670/1670 [==============================] - 68s 41ms/step - loss: 0.4269 - accuracy: 0.8530 - val_loss: 0.3370 - val_accuracy: 0.8750\n",
      "Epoch 3/30\n",
      "1670/1670 [==============================] - 68s 41ms/step - loss: 0.3148 - accuracy: 0.8932 - val_loss: 0.2142 - val_accuracy: 0.9062\n",
      "Epoch 4/30\n",
      "1670/1670 [==============================] - 68s 41ms/step - loss: 0.2650 - accuracy: 0.9121 - val_loss: 0.2261 - val_accuracy: 0.8750\n",
      "Epoch 5/30\n",
      "1670/1670 [==============================] - 69s 41ms/step - loss: 0.2348 - accuracy: 0.9226 - val_loss: 0.0880 - val_accuracy: 0.9688\n",
      "Epoch 6/30\n",
      "1670/1670 [==============================] - 68s 41ms/step - loss: 0.2032 - accuracy: 0.9325 - val_loss: 0.0563 - val_accuracy: 1.0000\n",
      "Epoch 7/30\n",
      "1670/1670 [==============================] - 68s 41ms/step - loss: 0.1809 - accuracy: 0.9399 - val_loss: 0.0549 - val_accuracy: 0.9688\n",
      "Epoch 8/30\n",
      "1670/1670 [==============================] - 68s 41ms/step - loss: 0.1571 - accuracy: 0.9482 - val_loss: 0.0590 - val_accuracy: 0.9688\n",
      "Epoch 9/30\n",
      "1670/1670 [==============================] - 68s 41ms/step - loss: 0.1393 - accuracy: 0.9531 - val_loss: 0.1523 - val_accuracy: 0.9375\n",
      "Epoch 10/30\n",
      "1670/1670 [==============================] - 68s 41ms/step - loss: 0.1265 - accuracy: 0.9572 - val_loss: 0.0396 - val_accuracy: 1.0000\n",
      "Epoch 11/30\n",
      "1670/1670 [==============================] - 68s 41ms/step - loss: 0.1158 - accuracy: 0.9608 - val_loss: 0.0270 - val_accuracy: 1.0000\n",
      "Epoch 12/30\n",
      "1670/1670 [==============================] - 68s 41ms/step - loss: 0.1016 - accuracy: 0.9661 - val_loss: 0.0510 - val_accuracy: 0.9688\n",
      "Epoch 13/30\n",
      "1670/1670 [==============================] - 68s 41ms/step - loss: 0.0867 - accuracy: 0.9703 - val_loss: 0.0553 - val_accuracy: 0.9688\n",
      "Epoch 14/30\n",
      "1670/1670 [==============================] - 67s 40ms/step - loss: 0.0776 - accuracy: 0.9727 - val_loss: 0.0094 - val_accuracy: 1.0000\n",
      "Epoch 15/30\n",
      "1670/1670 [==============================] - 67s 40ms/step - loss: 0.0749 - accuracy: 0.9746 - val_loss: 0.0183 - val_accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "1670/1670 [==============================] - 68s 40ms/step - loss: 0.0638 - accuracy: 0.9788 - val_loss: 0.0148 - val_accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "1670/1670 [==============================] - 68s 41ms/step - loss: 0.0589 - accuracy: 0.9801 - val_loss: 0.0271 - val_accuracy: 0.9688\n",
      "Epoch 18/30\n",
      "1670/1670 [==============================] - 68s 41ms/step - loss: 0.0540 - accuracy: 0.9815 - val_loss: 0.0145 - val_accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "1670/1670 [==============================] - 68s 41ms/step - loss: 0.0485 - accuracy: 0.9835 - val_loss: 0.0330 - val_accuracy: 0.9688\n",
      "Epoch 20/30\n",
      "1670/1670 [==============================] - 68s 40ms/step - loss: 0.0464 - accuracy: 0.9838 - val_loss: 0.0559 - val_accuracy: 0.9688\n",
      "Epoch 21/30\n",
      "1670/1670 [==============================] - 68s 41ms/step - loss: 0.0430 - accuracy: 0.9856 - val_loss: 0.0410 - val_accuracy: 0.9688\n",
      "Epoch 22/30\n",
      "1670/1670 [==============================] - 68s 41ms/step - loss: 0.0394 - accuracy: 0.9857 - val_loss: 0.0243 - val_accuracy: 0.9688\n",
      "Epoch 23/30\n",
      "1670/1670 [==============================] - 68s 40ms/step - loss: 0.0380 - accuracy: 0.9872 - val_loss: 0.0581 - val_accuracy: 0.9688\n",
      "Epoch 24/30\n",
      "1670/1670 [==============================] - 68s 41ms/step - loss: 0.0353 - accuracy: 0.9879 - val_loss: 0.0120 - val_accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "1670/1670 [==============================] - 68s 41ms/step - loss: 0.0357 - accuracy: 0.9873 - val_loss: 0.0477 - val_accuracy: 0.9688\n",
      "Epoch 26/30\n",
      "1670/1670 [==============================] - 68s 41ms/step - loss: 0.0332 - accuracy: 0.9889 - val_loss: 0.0699 - val_accuracy: 0.9688\n",
      "Epoch 27/30\n",
      "1670/1670 [==============================] - 68s 41ms/step - loss: 0.0308 - accuracy: 0.9895 - val_loss: 0.0181 - val_accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "1670/1670 [==============================] - 68s 41ms/step - loss: 0.0298 - accuracy: 0.9900 - val_loss: 0.0602 - val_accuracy: 0.9688\n",
      "Epoch 29/30\n",
      "1670/1670 [==============================] - 68s 40ms/step - loss: 0.0270 - accuracy: 0.9904 - val_loss: 0.0779 - val_accuracy: 0.9688\n",
      "Epoch 30/30\n",
      "1670/1670 [==============================] - 68s 41ms/step - loss: 0.0268 - accuracy: 0.9904 - val_loss: 0.0355 - val_accuracy: 0.9688\n",
      "INFO:tensorflow:Assets written to: ../octnet/octnet_30epochs_83484_images_False_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for octnet: 0.991736\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import datetime\n",
    "\n",
    "maxTrain = len(y_train)\n",
    "for newWeights in [False]:\n",
    "    tLayer = [False] if newWeights else [True, False] # do not train only last layer if new weights will be produced \n",
    "    for trainLastLayerOnly in tLayer:\n",
    "        for p in [0.01, 0.025, 0.05, 0.075, 0.09, 0.1, 0.25, 0.4, 0.5, 0.6, 0.75, 0.9, 1.0]:\n",
    "            for r_state in [45687864]:\n",
    "                #X_trn, X_tst, y_trn, y_tst\n",
    "                if p < 1:\n",
    "                    X_t, _, y_t, _ = train_test_split(images, y_train, test_size=1-p, random_state=r_state)\n",
    "                else:\n",
    "                    X_t = images; y_t = y_train;\n",
    "                print(f\"Labels fraction: {sum(y_t == 1) / sum(y_train == 1)}\")\n",
    "                for net in [\"octnet\"]:\n",
    "                    print(f\"Training {net} for {p}% of train size (aka {len(X_t)} images) with pretrained: {not newWeights} and onlyLastLayersTrained: {trainLastLayerOnly}...\")\n",
    "                    model, size, normalization = emptyModelGenerator(net, newWeights=newWeights, lastOnly=trainLastLayerOnly)\n",
    "                    printTrainableLayers(model) # see if model is really well trained\n",
    "                    X_trn = resizeIms(X_t, size)\n",
    "                    #X_trn = normalizeIms(X_trn, normalization=normalization)\n",
    "                    X_val = resizeIms(x_val, size)\n",
    "                    #X_val = normalizeIms(X_val, normalization=normalization)\n",
    "                    log_dir = f\"logs/{net}/fit/{p}trainSet_\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "                    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "                    optimizer = Adam(learning_rate) # amsgrad=amsgrad) #SGD(learning_rate=learning_rate, momentum=momentum) #create new optimizers\n",
    "                    time_callback = TimeHistory()\n",
    "                    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "                    hist = model.fit(X_trn, y_t, epochs=epochs, validation_data = (X_val, y_validation), batch_size=batch_size,\n",
    "                                shuffle=True, max_queue_size=20,\n",
    "                                use_multiprocessing=True, workers=5, \n",
    "                                callbacks=[CustomCallback(fraction=0.9, model=net), tensorboard_callback, time_callback])\n",
    "                    trainTime = sum(time_callback.times)\n",
    "                    model.save(f\"../{net}/{net}_{epochs}epochs_{p*maxTrain:.0f}_images_{newWeights}_newWeights_{trainLastLayerOnly}_lastLayerOnly_{normalization}_normalization\")\n",
    "                    tstAcc = testPredict(model, size, name=net) #, normalization=normalization)\n",
    "                    results = results.append({\n",
    "                        'model': net, \n",
    "                        'train set images': len(X_t), \n",
    "                        'pretrained': not newWeights, \n",
    "                        'pretrained dataset': None if newWeights or net == \"octnet\" else (\"OCT2017,Srinivasan2014\" if net == \"opticnet\" else \"Imagenet\"),\n",
    "                        'Trained layers': \"Last dense\" if trainLastLayerOnly else \"All\", \n",
    "                        'epochs': epochs, \n",
    "                        'batch size': batch_size, \n",
    "                        'learning rate': f\"{learning_rate}_{momentum}\" if optimizer._name == \"SGD\" else learning_rate, \n",
    "                        'optimizer': optimizer._name,\n",
    "                        'training time (seconds)': trainTime, \n",
    "                        'train accuracy': hist.history[\"accuracy\"][-1], \n",
    "                        'train loss': hist.history[\"loss\"][-1],\n",
    "                        'validation accuracy': hist.history[\"val_accuracy\"][-1], \n",
    "                        'validation loss': hist.history[\"val_loss\"][-1], \n",
    "                        'test accuracy': tstAcc,\n",
    "                        #'normalization': normalization\n",
    "                    }, ignore_index=True)\n",
    "                    results.to_csv(\"Results_temp.csv\", index=False)\n",
    "                    del model\n",
    "                    del X_trn\n",
    "                    del X_val\n",
    "                    print(\"Done!\\n\" + '-'*50, end='\\n\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
