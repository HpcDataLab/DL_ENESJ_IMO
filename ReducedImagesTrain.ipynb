{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "import os\n",
    "import cv2\n",
    "import pickle\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version is: 2.4.1\n"
     ]
    }
   ],
   "source": [
    "print(f\"Tensorflow version is: {tf.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataPath = \"../../data/OCT/OCT2017/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of Classes Detected : 4\n"
     ]
    }
   ],
   "source": [
    "labels_available = os.listdir(os.path.join(dataPath, \"train\"))\n",
    "print(\"Total Number of Classes Detected :\",len(labels_available))\n",
    "\n",
    "labels_list = ['NORMAL',\"CNV\",\"DME\",\"DRUSEN\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NORMAL CNV DME DRUSEN "
     ]
    }
   ],
   "source": [
    "images=[]\n",
    "y_trn=[]\n",
    "for x in labels_list:\n",
    "    xPath = os.path.join(dataPath, \"train\", x)\n",
    "    myPicList = os.listdir(xPath)\n",
    "    for y in myPicList:\n",
    "        images.append(cv2.imread(os.path.join(xPath, y)))\n",
    "        y_trn.append(labels_list.index(x))\n",
    "    print(x ,end=\" \")\n",
    "\n",
    "y_train = to_categorical(y_trn,len(labels_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NORMAL CNV DME DRUSEN "
     ]
    }
   ],
   "source": [
    "x_val=[]\n",
    "y_val=[]\n",
    "for x in labels_list:\n",
    "    xPath = os.path.join(dataPath, \"val\", x)\n",
    "    myPicList = os.listdir(xPath)\n",
    "    for y in myPicList:\n",
    "        x_val.append(cv2.imread(os.path.join(xPath, y)))\n",
    "        y_val.append(labels_list.index(x))\n",
    "    print(x ,end=\" \")\n",
    "\n",
    "y_validation = to_categorical(y_val,len(labels_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NORMAL CNV DME DRUSEN "
     ]
    }
   ],
   "source": [
    "x_tst=[]\n",
    "y_tst=[]\n",
    "for x in labels_list:\n",
    "    xPath = os.path.join(dataPath, \"test\", x)\n",
    "    myPicList = os.listdir(xPath)\n",
    "    for y in myPicList:\n",
    "        x_tst.append(cv2.imread(os.path.join(xPath, y)))\n",
    "        y_tst.append(labels_list.index(x))\n",
    "    print(x ,end=\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of images per category and set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label\t\tTrain\t\tValidation\t\tTest\n",
      "NORMAL\t\t26315\t\t8\t\t\t242\n",
      "CNV\t\t37205\t\t8\t\t\t242\n",
      "DME\t\t11348\t\t8\t\t\t242\n",
      "DRUSEN\t\t8616\t\t8\t\t\t242\n"
     ]
    }
   ],
   "source": [
    "def getNumberOfItems(labels, itemLabel):\n",
    "    return sum(list(map(lambda x: x == itemLabel, labels))) \n",
    "\n",
    "\n",
    "print(\"Label\\t\\tTrain\\t\\tValidation\\t\\tTest\")\n",
    "for i, label in enumerate(labels_list):\n",
    "    print(f\"{label}\\t\\t{getNumberOfItems(y_trn, i)}\\t\\t{getNumberOfItems(y_val, i)}\\t\\t\\t{getNumberOfItems(y_tst, i)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resizeIm(im, size):\n",
    "    if im.shape[2] == 1:\n",
    "        im = cv2.cvtColor(im,cv2.COLOR_GRAY2RGB)\n",
    "    return cv2.resize(im, size)\n",
    "\n",
    "def resizeIms(x, size):\n",
    "    return np.array(list(map(lambda im: resizeIm(im, size), x)))\n",
    "\n",
    "# Substract the mean specified by Mean (https://www.mathworks.com/help/deeplearning/ref/nnet.cnn.layer.imageinputlayer.html)\n",
    "# Substract mean by channel\n",
    "def zerocenter(x):\n",
    "    return (x - np.mean(x, axis=(0, 1))) / (2*np.std(x, axis=(0, 1)))\n",
    "\n",
    "# Rescale the input to be in the range [-1, 1] using the minimum and maximum values specified by Min and Max, respectively. (https://www.mathworks.com/help/deeplearning/ref/nnet.cnn.layer.imageinputlayer.html)\n",
    "# Compute using the formula: $x\\prime = 2 * \\frac{x - \\min{x}}{\\max{x} - \\min{x}} - 1$ taken from: https://stats.stackexchange.com/a/178629\n",
    "def rescaleSymmetric(x):\n",
    "    x = zerocenter(x)\n",
    "    return 2 * (x - np.min(x, axis=(0, 1)))/np.ptp(x, axis=(0, 1)) - 1\n",
    "\n",
    "def normalizeIms(x, normalization):\n",
    "    if normalization == \"zerocenter\":\n",
    "        func = zerocenter\n",
    "    elif normalization == \"rescale-symmetric\":\n",
    "        func = rescaleSymmetric\n",
    "    else:\n",
    "        return x\n",
    "    return np.array(list(map(lambda im: func(im), x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self,fraction, model):\n",
    "        super(CustomCallback,self).__init__()\n",
    "        self.fraction = fraction\n",
    "        self.train_a = [];\n",
    "        self.val_a =[];\n",
    "        self.logPath = os.path.join(model, \"log.txt\")\n",
    "\n",
    "        if not os.path.isdir(model):\n",
    "            os.mkdir(model)\n",
    "\n",
    "        with open(self.logPath,'w') as f:\n",
    "            f.write('Starting of logging..\\n')\n",
    "\n",
    "        self.fig = plt.figure(figsize=(4,3))\n",
    "        self.ax = plt.subplot(1,1,1)\n",
    "        plt.ion()\n",
    "\n",
    "    def on_train_begin(self,logs=None):\n",
    "        self.fig.show()\n",
    "        self.fig.canvas.draw()\n",
    "\n",
    "    def on_train_end(self,logs=None):\n",
    "        with open(self.logPath,'a') as f:\n",
    "              f.write('End of logging..\\n')\n",
    "    \n",
    "    def on_epoch_begin(self,epoch,logs=None):\n",
    "        lr= tf.keras.backend.get_value(self.model.optimizer.lr)\n",
    "        lr *= self.fraction\n",
    "        tf.keras.backend.set_value(self.model.optimizer.lr,lr)\n",
    "        with open(self.logPath,'a') as f:\n",
    "            f.write('At epoch {:02d}, learning rate changed to {:.4f}\\n'.format(epoch,lr))\n",
    "    \n",
    "    def on_epoch_end(self,epoch,logs=None):\n",
    "        val_acc = logs.get('val_accuracy')\n",
    "        train_acc = logs.get('accuracy')\n",
    "        self.train_a.append(train_acc)\n",
    "        self.val_a.append(val_acc)\n",
    "        with open(self.logPath,'a') as f:\n",
    "            f.write('At epoch {:02d}, training accuracy: {:.3f}, validation accuracy: {:.3f}\\n'.format(epoch,train_acc,val_acc))\n",
    "        self.ax.clear()\n",
    "        self.ax.plot(range(1+epoch),self.train_a,label=\"Training\")\n",
    "        self.ax.plot(range(1+epoch),self.val_a,label=\"Validation\")\n",
    "        self.ax.set_xlabel('Epochs')\n",
    "        self.ax.set_ylabel('Accuracy')\n",
    "        self.ax.legend()\n",
    "        self.fig.canvas.draw()\n",
    "        self.fig.show()\n",
    "        \n",
    "class TimeHistory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.times = []\n",
    "\n",
    "    def on_epoch_begin(self, batch, logs={}):\n",
    "        self.epoch_time_start = time.time()\n",
    "\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.times.append(time.time() - self.epoch_time_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "# xception base model\n",
    "#from tensorflow.keras.applications.xception import Xception\n",
    "#from tensorflow.keras.applications.xception import preprocess_input, decode_predictions\n",
    "#xceptionNetModel = Xception(weights='imagenet')\n",
    "#xceptionNetModel.save(\"../Xception.hdf5\")\n",
    "\n",
    "xceptionNetModel = tf.keras.models.load_model('../Xception.hdf5')\n",
    "\n",
    "# opticnet base model\n",
    "opticNetModel = tf.keras.models.load_model('../Optic_net-4_classes-Kermany2018.hdf5')\n",
    "\n",
    "# resnet base model\n",
    "#from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "#from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "#resNetModel = ResNet50(weights='imagenet')\n",
    "#resNetModel.save(\"../Resnet50.hdf5\")\n",
    "\n",
    "resNetModel = tf.keras.models.load_model('../Resnet50.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 221, 221, 32)      4736      \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 221, 221, 32)      128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 110, 110, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 104, 104, 32)      50208     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 104, 104, 32)      128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 52, 52, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 48, 48, 64)        51264     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 48, 48, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 24, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 20, 20, 128)       204928    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 20, 20, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 10, 10, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 8, 8, 256)         295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d (AveragePo (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               131200    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4)                 132       \n",
      "_________________________________________________________________\n",
      "softmax (Softmax)            (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 743,812\n",
      "Trainable params: 742,788\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "conv_init = tf.keras.initializers.RandomNormal(mean=0., stddev=1.) # convolutional layer with zero mean and 1 sd\n",
    "#batch_init = tf.keras.initializers.RandomNormal(mean=1., stddev=0.02) # non-sense here\n",
    "\n",
    "octnet = keras.models.Sequential() # empty model\n",
    "\n",
    "octnet.add(keras.layers.Conv2D(32, (7, 7), activation=\"relu\", use_bias=True, input_shape=(227, 227, 3), kernel_initializer=conv_init))\n",
    "octnet.add(keras.layers.BatchNormalization())\n",
    "octnet.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "octnet.add(keras.layers.Conv2D(32, (7, 7), activation=\"relu\", use_bias=True, kernel_initializer=conv_init))\n",
    "octnet.add(keras.layers.BatchNormalization())\n",
    "octnet.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "octnet.add(keras.layers.Conv2D(64, (5, 5), activation=\"relu\", use_bias=True, kernel_initializer=conv_init))\n",
    "octnet.add(keras.layers.BatchNormalization())\n",
    "octnet.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "octnet.add(keras.layers.Conv2D(128, (5, 5), activation=\"relu\", use_bias=True, kernel_initializer=conv_init))\n",
    "octnet.add(keras.layers.BatchNormalization())\n",
    "octnet.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "octnet.add(keras.layers.Conv2D(256, (3, 3), activation=\"relu\", use_bias=True, kernel_initializer=conv_init))\n",
    "octnet.add(keras.layers.BatchNormalization())\n",
    "octnet.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "#octnet.add(keras.layers.Conv2D(512, (3, 3), activation=\"relu\", use_bias=True))\n",
    "#octnet.add(keras.layers.BatchNormalization())\n",
    "#octnet.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "octnet.add(keras.layers.AveragePooling2D())\n",
    "octnet.add(keras.layers.Flatten())\n",
    "octnet.add(keras.layers.Dense(128))\n",
    "octnet.add(keras.layers.Dropout(0.5))\n",
    "octnet.add(keras.layers.Dense(32))\n",
    "octnet.add(keras.layers.Dropout(0.5))\n",
    "octnet.add(keras.layers.Dense(4))\n",
    "octnet.add(keras.layers.Softmax())\n",
    "\n",
    "octnet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emptyModelGenerator(model, newWeights=False, lastOnly=False):\n",
    "    model = model.lower() # lower case model name\n",
    "    if model == \"resnet\":\n",
    "        x = resNetModel.output\n",
    "        predictions = Dense(len(labels_list), activation='softmax')(x)\n",
    "        newModel = Model(inputs=resNetModel.input, outputs=predictions)\n",
    "        size = (224, 224)\n",
    "        normalization = \"zerocenter\"\n",
    "    elif model == \"xception\":\n",
    "        x = xceptionNetModel.output\n",
    "        predictions = Dense(len(labels_list), activation='softmax')(x)\n",
    "        newModel = Model(inputs=xceptionNetModel.input, outputs=predictions)\n",
    "        size = (299, 299)\n",
    "        normalization = \"rescale-symmetric\"\n",
    "    elif model == \"opticnet\":\n",
    "        newModel = tf.keras.models.load_model('../Optic_net-4_classes-Kermany2018.hdf5')\n",
    "        size = (224, 224)\n",
    "        normalization = \"rescale-symmetric\"\n",
    "    elif model == \"octnet\":\n",
    "        newModel = tf.keras.models.clone_model(octnet)\n",
    "        size = (227, 227)\n",
    "        normalization = \"zerocenter\"\n",
    "    if newWeights:\n",
    "        newModel = tf.keras.models.clone_model(newModel)\n",
    "    if lastOnly:\n",
    "        newModel = lastDenseTrainable(newModel) # block all layer except the last dense ones\n",
    "    else:\n",
    "        newModel.trainable = True\n",
    "    return newModel, size, normalization\n",
    "\n",
    "\n",
    "def lastDenseTrainable(model):\n",
    "    model.trainable = False\n",
    "    for i in range(1, len(model.layers)):\n",
    "        if model.layers[-i].__class__.__name__ == \"Dense\":\n",
    "            model.layers[-i].trainable= True\n",
    "        elif model.layers[-i].__class__.__name__ == \"Activation\":\n",
    "            continue\n",
    "        else:\n",
    "            break\n",
    "    return model\n",
    "    \n",
    "\n",
    "def testPredict(model, size, name=None, normalization=None):\n",
    "    X_test = resizeIms(x_tst, size)\n",
    "    if normalization:\n",
    "        X_test = normalizeIms(X_test, normalization)\n",
    "    X_test = np.array(X_test)\n",
    "    Y_test = np.array(y_tst)\n",
    "    \n",
    "    prediction = model.predict(X_test)\n",
    "    preds = np.argmax(prediction, axis=1)\n",
    "    acc = sum(preds == Y_test) / len(Y_test)\n",
    "    print(f'Test acc for {name if name else \"model\"}: {acc:.6f}')\n",
    "    return acc\n",
    "    \n",
    "\n",
    "def computeConfussionMatrix(predictions, labels):\n",
    "    num_labels = len(labels_list)\n",
    "    cMatrix = np.zeros(shape=(num_labels, num_labels))\n",
    "    for i in len(predictions):\n",
    "        p = int(predictions[i])\n",
    "        t = int(predictions[i])\n",
    "        cMatrix[t, p] += 1\n",
    "    print(cMatrix)\n",
    "    ax = sns.heatmap(cMatrix, cmap=\"Blues\", annot=True, fmt=\"d\", xticklabels=labels_list, yticklabels=labels_list)\n",
    "    plt.xlabel(\"Predicted label\")\n",
    "    plt.ylabel(\"True label\")\n",
    "    plt.title(\"Confusion matrix\")\n",
    "    plt.show();\n",
    "    return cMatrix\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "**************************************************\n",
      "Model: xception\n",
      "**************************************************\n",
      "\n",
      "Total: 135 trainable: 2\n",
      "\n",
      "\n",
      "**************************************************\n",
      "Model: resnet\n",
      "**************************************************\n",
      "\n",
      "Total: 178 trainable: 2\n",
      "\n",
      "\n",
      "**************************************************\n",
      "Model: opticnet\n",
      "**************************************************\n",
      "\n",
      "Total: 276 trainable: 2\n",
      "\n",
      "\n",
      "**************************************************\n",
      "Model: octnet\n",
      "**************************************************\n",
      "\n",
      "Total: 23 trainable: 0\n"
     ]
    }
   ],
   "source": [
    "models = [\"xception\", \"resnet\", \"opticnet\", \"octnet\"]\n",
    "\n",
    "def printTrainableLayers(m):\n",
    "    a = 0\n",
    "    for l in m.layers:\n",
    "        #l.trainable = True\n",
    "        if l.trainable:\n",
    "            #print(l.name, l.trainable)\n",
    "            a += 1\n",
    "    print(f\"\\nTotal: {len(m.layers)} trainable: {a}\")\n",
    "\n",
    "for mod in models:\n",
    "    print(\"\\n\\n\" + (\"*\"*50) + \"\\nModel: \" + mod + '\\n' + (\"*\"*50))\n",
    "    m = emptyModelGenerator(mod, newWeights=False, lastOnly=True)[0]\n",
    "    printTrainableLayers(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "momentum = 0.9\n",
    "optim = lambda lr: Adam(learning_rate=lr)\n",
    "#optim = lambda lr, momentum: SGD(learning_rate=lr, momentum=momentum)\n",
    "epochs = 30\n",
    "batch_size = 50\n",
    "#batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "results = pd.read_csv(\"Results_temp.csv\")\n",
    "results[\"normalization\"] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pandas as pd\n",
    "#res = pd.read_csv(\"Results_temp.csv\")\n",
    "#res.to_csv(\"Results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels fraction: [0.10070302 0.09832012 0.10248502 0.10178737]\n",
      "Training resnet for 0.1% of train size (aka 8348 images) with pretrained: False and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 178 trainable: 178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/167 [>.............................] - ETA: 2:16 - loss: 1.3801 - accuracy: 0.3402WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1779s vs `on_train_batch_end` time: 0.4600s). Check your callbacks.\n",
      "167/167 [==============================] - 77s 429ms/step - loss: 1.2877 - accuracy: 0.4280 - val_loss: 1.5396 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "167/167 [==============================] - 69s 411ms/step - loss: 1.2337 - accuracy: 0.4411 - val_loss: 1.5485 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "167/167 [==============================] - 69s 412ms/step - loss: 1.2351 - accuracy: 0.4422 - val_loss: 1.5576 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "167/167 [==============================] - 69s 412ms/step - loss: 1.2299 - accuracy: 0.4376 - val_loss: 1.5433 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "167/167 [==============================] - 69s 412ms/step - loss: 1.1932 - accuracy: 0.4778 - val_loss: 1.7497 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "167/167 [==============================] - 69s 412ms/step - loss: 0.9079 - accuracy: 0.7051 - val_loss: 1.2681 - val_accuracy: 0.5000\n",
      "Epoch 7/30\n",
      "167/167 [==============================] - 69s 412ms/step - loss: 0.8315 - accuracy: 0.7221 - val_loss: 1.1757 - val_accuracy: 0.5000\n",
      "Epoch 8/30\n",
      "167/167 [==============================] - 69s 412ms/step - loss: 0.7424 - accuracy: 0.7409 - val_loss: 1.2919 - val_accuracy: 0.5000\n",
      "Epoch 9/30\n",
      "167/167 [==============================] - 69s 412ms/step - loss: 0.7220 - accuracy: 0.7353 - val_loss: 1.2876 - val_accuracy: 0.5000\n",
      "Epoch 10/30\n",
      "167/167 [==============================] - 69s 412ms/step - loss: 0.6879 - accuracy: 0.7401 - val_loss: 1.1880 - val_accuracy: 0.5000\n",
      "Epoch 11/30\n",
      "167/167 [==============================] - 69s 412ms/step - loss: 0.6385 - accuracy: 0.7494 - val_loss: 1.3192 - val_accuracy: 0.5000\n",
      "Epoch 12/30\n",
      "167/167 [==============================] - 69s 412ms/step - loss: 0.6178 - accuracy: 0.7427 - val_loss: 1.2318 - val_accuracy: 0.5000\n",
      "Epoch 13/30\n",
      "167/167 [==============================] - 69s 413ms/step - loss: 0.5754 - accuracy: 0.7777 - val_loss: 1.2876 - val_accuracy: 0.4375\n",
      "Epoch 14/30\n",
      "167/167 [==============================] - 69s 412ms/step - loss: 0.5502 - accuracy: 0.8257 - val_loss: 1.7693 - val_accuracy: 0.3125\n",
      "Epoch 15/30\n",
      "167/167 [==============================] - 69s 412ms/step - loss: 0.5323 - accuracy: 0.8297 - val_loss: 0.8813 - val_accuracy: 0.6250\n",
      "Epoch 16/30\n",
      "167/167 [==============================] - 69s 412ms/step - loss: 0.4874 - accuracy: 0.8493 - val_loss: 0.8792 - val_accuracy: 0.6875\n",
      "Epoch 17/30\n",
      "167/167 [==============================] - 69s 412ms/step - loss: 0.4834 - accuracy: 0.8458 - val_loss: 1.2463 - val_accuracy: 0.5625\n",
      "Epoch 18/30\n",
      "167/167 [==============================] - 34s 204ms/step - loss: 0.4428 - accuracy: 0.8611 - val_loss: 0.9872 - val_accuracy: 0.6875\n",
      "Epoch 19/30\n",
      "167/167 [==============================] - 33s 200ms/step - loss: 0.4350 - accuracy: 0.8605 - val_loss: 0.8277 - val_accuracy: 0.5938TA: 9s - loss: 0.4360 - acc\n",
      "Epoch 20/30\n",
      "167/167 [==============================] - 33s 200ms/step - loss: 0.4013 - accuracy: 0.8648 - val_loss: 0.7210 - val_accuracy: 0.7188\n",
      "Epoch 21/30\n",
      "167/167 [==============================] - 41s 243ms/step - loss: 0.4015 - accuracy: 0.8594 - val_loss: 0.6980 - val_accuracy: 0.7188\n",
      "Epoch 22/30\n",
      "167/167 [==============================] - 57s 339ms/step - loss: 0.3815 - accuracy: 0.8695 - val_loss: 0.7144 - val_accuracy: 0.7188\n",
      "Epoch 23/30\n",
      "167/167 [==============================] - 69s 412ms/step - loss: 0.3633 - accuracy: 0.8687 - val_loss: 1.3242 - val_accuracy: 0.5000\n",
      "Epoch 24/30\n",
      "167/167 [==============================] - 69s 411ms/step - loss: 0.3355 - accuracy: 0.8798 - val_loss: 0.7762 - val_accuracy: 0.6250\n",
      "Epoch 25/30\n",
      "167/167 [==============================] - 69s 411ms/step - loss: 0.3206 - accuracy: 0.8845 - val_loss: 0.5921 - val_accuracy: 0.7500\n",
      "Epoch 26/30\n",
      "167/167 [==============================] - 69s 412ms/step - loss: 0.3139 - accuracy: 0.8833 - val_loss: 0.9117 - val_accuracy: 0.6562\n",
      "Epoch 27/30\n",
      "167/167 [==============================] - 69s 412ms/step - loss: 0.2997 - accuracy: 0.8883 - val_loss: 0.7356 - val_accuracy: 0.7188\n",
      "Epoch 28/30\n",
      "167/167 [==============================] - 69s 412ms/step - loss: 0.2972 - accuracy: 0.8852 - val_loss: 0.7163 - val_accuracy: 0.7188\n",
      "Epoch 29/30\n",
      "167/167 [==============================] - 69s 411ms/step - loss: 0.2813 - accuracy: 0.8940 - val_loss: 0.4976 - val_accuracy: 0.7500\n",
      "Epoch 30/30\n",
      "167/167 [==============================] - 69s 412ms/step - loss: 0.2835 - accuracy: 0.8828 - val_loss: 0.5973 - val_accuracy: 0.6875\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_8348_images_True_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.720041\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.09861296 0.09904583 0.10345435 0.10376045]\n",
      "Training resnet for 0.1% of train size (aka 8348 images) with pretrained: False and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 178 trainable: 178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/167 [>.............................] - ETA: 2:23 - loss: 1.3809 - accuracy: 0.2509WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1820s vs `on_train_batch_end` time: 0.4839s). Check your callbacks.\n",
      "167/167 [==============================] - 78s 431ms/step - loss: 1.2814 - accuracy: 0.4241 - val_loss: 1.4855 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "167/167 [==============================] - 69s 412ms/step - loss: 1.2342 - accuracy: 0.4427 - val_loss: 1.5316 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "167/167 [==============================] - 69s 412ms/step - loss: 1.2448 - accuracy: 0.4369 - val_loss: 1.5418 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "167/167 [==============================] - 69s 412ms/step - loss: 1.2360 - accuracy: 0.4494 - val_loss: 1.5473 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "167/167 [==============================] - 69s 412ms/step - loss: 1.2404 - accuracy: 0.4451 - val_loss: 1.5512 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "167/167 [==============================] - 69s 412ms/step - loss: 1.2447 - accuracy: 0.4342 - val_loss: 1.5523 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "167/167 [==============================] - 69s 412ms/step - loss: 1.2313 - accuracy: 0.4477 - val_loss: 1.5426 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "167/167 [==============================] - 69s 413ms/step - loss: 1.2272 - accuracy: 0.4532 - val_loss: 1.5391 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "167/167 [==============================] - 69s 413ms/step - loss: 1.2417 - accuracy: 0.4430 - val_loss: 1.5467 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "167/167 [==============================] - 69s 412ms/step - loss: 1.2411 - accuracy: 0.4483 - val_loss: 1.5439 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "167/167 [==============================] - 69s 411ms/step - loss: 1.2475 - accuracy: 0.4367 - val_loss: 1.5527 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "167/167 [==============================] - 69s 412ms/step - loss: 1.2460 - accuracy: 0.4405 - val_loss: 1.5457 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "167/167 [==============================] - 69s 411ms/step - loss: 1.2406 - accuracy: 0.4417 - val_loss: 1.5430 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "167/167 [==============================] - 69s 411ms/step - loss: 1.2227 - accuracy: 0.4578 - val_loss: 1.5345 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "167/167 [==============================] - 69s 411ms/step - loss: 1.2364 - accuracy: 0.4406 - val_loss: 1.5441 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "167/167 [==============================] - 69s 411ms/step - loss: 1.2430 - accuracy: 0.4427 - val_loss: 1.5438 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "167/167 [==============================] - 69s 411ms/step - loss: 1.2362 - accuracy: 0.4449 - val_loss: 1.5436 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "167/167 [==============================] - 69s 411ms/step - loss: 1.2353 - accuracy: 0.4407 - val_loss: 1.5453 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "167/167 [==============================] - 69s 411ms/step - loss: 1.2346 - accuracy: 0.4566 - val_loss: 1.5423 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "167/167 [==============================] - 69s 411ms/step - loss: 1.2376 - accuracy: 0.4432 - val_loss: 1.5432 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "167/167 [==============================] - 69s 411ms/step - loss: 1.2461 - accuracy: 0.4385 - val_loss: 1.5458 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "167/167 [==============================] - 69s 411ms/step - loss: 1.2335 - accuracy: 0.4484 - val_loss: 1.5445 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "167/167 [==============================] - 69s 411ms/step - loss: 1.2390 - accuracy: 0.4408 - val_loss: 1.5456 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "167/167 [==============================] - 69s 411ms/step - loss: 1.2526 - accuracy: 0.4280 - val_loss: 1.5474 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "167/167 [==============================] - 69s 411ms/step - loss: 1.2405 - accuracy: 0.4447 - val_loss: 1.5461 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "167/167 [==============================] - 69s 411ms/step - loss: 1.2381 - accuracy: 0.4453 - val_loss: 1.5454 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "167/167 [==============================] - 69s 411ms/step - loss: 1.2431 - accuracy: 0.4359 - val_loss: 1.5459 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "167/167 [==============================] - 69s 411ms/step - loss: 1.2390 - accuracy: 0.4419 - val_loss: 1.5453 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "167/167 [==============================] - 69s 411ms/step - loss: 1.2365 - accuracy: 0.4440 - val_loss: 1.5453 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "167/167 [==============================] - 69s 411ms/step - loss: 1.2483 - accuracy: 0.4344 - val_loss: 1.5461 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_8348_images_True_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.09963899 0.1007929  0.10010575 0.09749304]\n",
      "Training resnet for 0.1% of train size (aka 8348 images) with pretrained: False and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 178 trainable: 178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/167 [>.............................] - ETA: 2:28 - loss: 1.3769 - accuracy: 0.3404WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2223s vs `on_train_batch_end` time: 0.4727s). Check your callbacks.\n",
      "167/167 [==============================] - 79s 430ms/step - loss: 1.2759 - accuracy: 0.4435 - val_loss: 1.5072 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "167/167 [==============================] - 69s 412ms/step - loss: 1.2307 - accuracy: 0.4469 - val_loss: 1.5613 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "167/167 [==============================] - 69s 411ms/step - loss: 1.2171 - accuracy: 0.4568 - val_loss: 1.5526 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "167/167 [==============================] - 69s 411ms/step - loss: 1.2220 - accuracy: 0.4537 - val_loss: 1.5537 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "167/167 [==============================] - 69s 410ms/step - loss: 1.2307 - accuracy: 0.4470 - val_loss: 1.5669 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "167/167 [==============================] - 69s 411ms/step - loss: 1.2293 - accuracy: 0.4436 - val_loss: 1.5690 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "167/167 [==============================] - 69s 410ms/step - loss: 1.2279 - accuracy: 0.4521 - val_loss: 1.5706 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "167/167 [==============================] - 68s 410ms/step - loss: 1.2317 - accuracy: 0.4426 - val_loss: 1.5705 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "167/167 [==============================] - 68s 410ms/step - loss: 1.2253 - accuracy: 0.4475 - val_loss: 1.5613 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "167/167 [==============================] - 68s 410ms/step - loss: 1.2340 - accuracy: 0.4395 - val_loss: 1.5658 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "167/167 [==============================] - 69s 411ms/step - loss: 1.2252 - accuracy: 0.4558 - val_loss: 1.5615 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "167/167 [==============================] - 68s 409ms/step - loss: 1.2236 - accuracy: 0.4496 - val_loss: 1.5653 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "167/167 [==============================] - 68s 409ms/step - loss: 1.2174 - accuracy: 0.4638 - val_loss: 1.5567 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "167/167 [==============================] - 68s 410ms/step - loss: 1.2255 - accuracy: 0.4505 - val_loss: 1.5611 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "167/167 [==============================] - 68s 410ms/step - loss: 1.2219 - accuracy: 0.4556 - val_loss: 1.5588 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "167/167 [==============================] - 68s 410ms/step - loss: 1.2289 - accuracy: 0.4450 - val_loss: 1.5709 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "167/167 [==============================] - 68s 409ms/step - loss: 1.2256 - accuracy: 0.4521 - val_loss: 1.5702 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "167/167 [==============================] - 68s 410ms/step - loss: 1.2258 - accuracy: 0.4466 - val_loss: 1.5590 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "167/167 [==============================] - 68s 410ms/step - loss: 1.2207 - accuracy: 0.4553 - val_loss: 1.5792 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "167/167 [==============================] - 68s 410ms/step - loss: 1.2163 - accuracy: 0.4493 - val_loss: 1.5375 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "167/167 [==============================] - 68s 410ms/step - loss: 1.1678 - accuracy: 0.4557 - val_loss: 1.6140 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "167/167 [==============================] - 68s 410ms/step - loss: 1.0998 - accuracy: 0.4448 - val_loss: 1.4813 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "167/167 [==============================] - 68s 410ms/step - loss: 1.0346 - accuracy: 0.5573 - val_loss: 1.4140 - val_accuracy: 0.5000\n",
      "Epoch 24/30\n",
      "167/167 [==============================] - 68s 409ms/step - loss: 0.9947 - accuracy: 0.7257 - val_loss: 1.8342 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "167/167 [==============================] - 68s 409ms/step - loss: 0.9605 - accuracy: 0.7279 - val_loss: 1.6790 - val_accuracy: 0.3750\n",
      "Epoch 26/30\n",
      "167/167 [==============================] - 68s 409ms/step - loss: 0.9306 - accuracy: 0.7345 - val_loss: 1.5349 - val_accuracy: 0.5000\n",
      "Epoch 27/30\n",
      "167/167 [==============================] - 68s 409ms/step - loss: 0.9237 - accuracy: 0.7242 - val_loss: 1.5129 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "167/167 [==============================] - 68s 410ms/step - loss: 0.8807 - accuracy: 0.7350 - val_loss: 1.7439 - val_accuracy: 0.4062\n",
      "Epoch 29/30\n",
      "167/167 [==============================] - 68s 409ms/step - loss: 0.8595 - accuracy: 0.7322 - val_loss: 1.6160 - val_accuracy: 0.4062\n",
      "Epoch 30/30\n",
      "167/167 [==============================] - 68s 410ms/step - loss: 0.8470 - accuracy: 0.7340 - val_loss: 2.0518 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_8348_images_True_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.253099\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.09944898 0.09891144 0.1011632  0.10480501]\n",
      "Training resnet for 0.1% of train size (aka 8348 images) with pretrained: False and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 178 trainable: 178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:15: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  self.fig = plt.figure(figsize=(4,3))\n",
      "<ipython-input-11-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/167 [>.............................] - ETA: 2:23 - loss: 1.3819 - accuracy: 0.2740WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1786s vs `on_train_batch_end` time: 0.4724s). Check your callbacks.\n",
      "167/167 [==============================] - 78s 428ms/step - loss: 1.2874 - accuracy: 0.4225 - val_loss: 1.5397 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "167/167 [==============================] - 68s 410ms/step - loss: 1.2309 - accuracy: 0.4485 - val_loss: 1.5491 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "167/167 [==============================] - 68s 410ms/step - loss: 1.2328 - accuracy: 0.4474 - val_loss: 1.5569 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "167/167 [==============================] - 68s 410ms/step - loss: 1.2296 - accuracy: 0.4446 - val_loss: 1.5538 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "167/167 [==============================] - 68s 410ms/step - loss: 1.2216 - accuracy: 0.4536 - val_loss: 1.5358 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "167/167 [==============================] - 73s 434ms/step - loss: 1.2365 - accuracy: 0.4507 - val_loss: 1.5505 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "167/167 [==============================] - 68s 410ms/step - loss: 1.2305 - accuracy: 0.4471 - val_loss: 1.5382 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "167/167 [==============================] - 68s 409ms/step - loss: 1.2357 - accuracy: 0.4364 - val_loss: 1.5495 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "167/167 [==============================] - 68s 409ms/step - loss: 1.2331 - accuracy: 0.4447 - val_loss: 1.5428 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "167/167 [==============================] - 68s 409ms/step - loss: 1.2167 - accuracy: 0.4393 - val_loss: 1.5043 - val_accuracy: 0.2812\n",
      "Epoch 11/30\n",
      "167/167 [==============================] - 68s 410ms/step - loss: 1.0064 - accuracy: 0.6894 - val_loss: 1.8677 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "167/167 [==============================] - 68s 409ms/step - loss: 0.8770 - accuracy: 0.7258 - val_loss: 1.9890 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "167/167 [==============================] - 68s 409ms/step - loss: 0.8452 - accuracy: 0.7235 - val_loss: 1.7001 - val_accuracy: 0.3438\n",
      "Epoch 14/30\n",
      "167/167 [==============================] - 69s 410ms/step - loss: 0.7966 - accuracy: 0.7348 - val_loss: 1.2803 - val_accuracy: 0.5000\n",
      "Epoch 15/30\n",
      "167/167 [==============================] - 68s 409ms/step - loss: 0.7812 - accuracy: 0.7325 - val_loss: 1.7409 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "167/167 [==============================] - 68s 409ms/step - loss: 0.7450 - accuracy: 0.7420 - val_loss: 1.3690 - val_accuracy: 0.5000\n",
      "Epoch 17/30\n",
      "167/167 [==============================] - 68s 409ms/step - loss: 0.7046 - accuracy: 0.7551 - val_loss: 1.3771 - val_accuracy: 0.3438\n",
      "Epoch 18/30\n",
      "167/167 [==============================] - 68s 409ms/step - loss: 0.7169 - accuracy: 0.7395 - val_loss: 1.1738 - val_accuracy: 0.5000\n",
      "Epoch 19/30\n",
      "167/167 [==============================] - 68s 409ms/step - loss: 0.7072 - accuracy: 0.7396 - val_loss: 1.1115 - val_accuracy: 0.4688\n",
      "Epoch 20/30\n",
      "167/167 [==============================] - 68s 409ms/step - loss: 0.6837 - accuracy: 0.7433 - val_loss: 1.1072 - val_accuracy: 0.5000\n",
      "Epoch 21/30\n",
      "167/167 [==============================] - 68s 409ms/step - loss: 0.6314 - accuracy: 0.7588 - val_loss: 1.1357 - val_accuracy: 0.5000\n",
      "Epoch 22/30\n",
      "167/167 [==============================] - 68s 409ms/step - loss: 0.6341 - accuracy: 0.7528 - val_loss: 1.2395 - val_accuracy: 0.5000\n",
      "Epoch 23/30\n",
      "167/167 [==============================] - 68s 409ms/step - loss: 0.6343 - accuracy: 0.7495 - val_loss: 1.1610 - val_accuracy: 0.5000\n",
      "Epoch 24/30\n",
      "167/167 [==============================] - 68s 409ms/step - loss: 0.6115 - accuracy: 0.7555 - val_loss: 1.0085 - val_accuracy: 0.5000\n",
      "Epoch 25/30\n",
      "167/167 [==============================] - 68s 408ms/step - loss: 0.6092 - accuracy: 0.7501 - val_loss: 1.0018 - val_accuracy: 0.5000\n",
      "Epoch 26/30\n",
      "167/167 [==============================] - 68s 408ms/step - loss: 0.5983 - accuracy: 0.7531 - val_loss: 0.9680 - val_accuracy: 0.5000\n",
      "Epoch 27/30\n",
      "167/167 [==============================] - 68s 408ms/step - loss: 0.5879 - accuracy: 0.7516 - val_loss: 1.0536 - val_accuracy: 0.5000\n",
      "Epoch 28/30\n",
      "167/167 [==============================] - 68s 408ms/step - loss: 0.5849 - accuracy: 0.7476 - val_loss: 1.0355 - val_accuracy: 0.5000\n",
      "Epoch 29/30\n",
      "167/167 [==============================] - 68s 408ms/step - loss: 0.5778 - accuracy: 0.7487 - val_loss: 1.0842 - val_accuracy: 0.5000\n",
      "Epoch 30/30\n",
      "167/167 [==============================] - 68s 407ms/step - loss: 0.5595 - accuracy: 0.7580 - val_loss: 1.1142 - val_accuracy: 0.5000\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_8348_images_True_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.500000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import datetime\n",
    "\n",
    "maxTrain = len(y_train)\n",
    "for newWeights in [True]:\n",
    "    tLayer = [False] if newWeights else [True, False] # do not train only last layer if new weights will be produced \n",
    "    for trainLastLayerOnly in tLayer:\n",
    "        for p in [0.1]:\n",
    "            learning_rate = 0.05\n",
    "            momentum = 0.6\n",
    "            for r_state in [1234567, 927123, 1273262, 836344]:\n",
    "                #X_trn, X_tst, y_trn, y_tst\n",
    "                if p < 1:\n",
    "                    X_t, _, y_t, _ = train_test_split(images, y_train, test_size=1-p, random_state=r_state)\n",
    "                else:\n",
    "                    X_t = images; y_t = y_train;\n",
    "                print(f\"Labels fraction: {sum(y_t == 1) / sum(y_train == 1)}\")\n",
    "                for net in [\"resnet\"]:\n",
    "                    print(f\"Training {net} for {p}% of train size (aka {len(X_t)} images) with pretrained: {not newWeights} and onlyLastLayersTrained: {trainLastLayerOnly}...\")\n",
    "                    model, size, normalization = emptyModelGenerator(net, newWeights=newWeights, lastOnly=trainLastLayerOnly)\n",
    "                    printTrainableLayers(model) # see if model is really well trained\n",
    "                    X_trn = resizeIms(X_t, size)\n",
    "                    #X_trn = normalizeIms(X_trn, normalization=normalization)\n",
    "                    X_val = resizeIms(x_val, size)\n",
    "                    #X_val = normalizeIms(X_val, normalization=normalization)\n",
    "                    log_dir = f\"logs/{net}/fit/{p}trainSet_\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "                    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "                    optimizer = SGD(learning_rate=learning_rate, momentum=momentum) # Adam(learning_rate, amsgrad=amsgrad) #create new optimizers\n",
    "                    time_callback = TimeHistory()\n",
    "                    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "                    hist = model.fit(X_trn, y_t, epochs=epochs, validation_data = (X_val, y_validation), batch_size=batch_size,\n",
    "                                shuffle=True, max_queue_size=20,\n",
    "                                use_multiprocessing=True, workers=5, \n",
    "                                callbacks=[CustomCallback(fraction=0.9, model=net), tensorboard_callback, time_callback])\n",
    "                    trainTime = sum(time_callback.times)\n",
    "                    model.save(f\"../{net}/{net}_{epochs}epochs_{p*maxTrain:.0f}_images_{newWeights}_newWeights_{trainLastLayerOnly}_lastLayerOnly_{normalization}_normalization\")\n",
    "                    tstAcc = testPredict(model, size, name=net) #, normalization=normalization)\n",
    "                    results = results.append({\n",
    "                        'model': net, \n",
    "                        'train set images': len(X_t), \n",
    "                        'pretrained': not newWeights, \n",
    "                        'pretrained dataset': None if newWeights or net == \"octnet\" else (\"OCT2017,Srinivasan2014\" if net == \"opticnet\" else \"Imagenet\"),\n",
    "                        'Trained layers': \"Last dense\" if trainLastLayerOnly else \"All\", \n",
    "                        'epochs': epochs, \n",
    "                        'batch size': batch_size, \n",
    "                        'learning rate': f\"{learning_rate}_{momentum}\" if optimizer._name == \"SGD\" else learning_rate, \n",
    "                        'optimizer': \"Amsgrad\" if (optimizer._name == \"Adam\" and amsgrad) else optimizer._name,\n",
    "                        'training time (seconds)': trainTime, \n",
    "                        'train accuracy': hist.history[\"accuracy\"][-1], \n",
    "                        'train loss': hist.history[\"loss\"][-1],\n",
    "                        'validation accuracy': hist.history[\"val_accuracy\"][-1], \n",
    "                        'validation loss': hist.history[\"val_loss\"][-1], \n",
    "                        'test accuracy': tstAcc,\n",
    "                        #'normalization': normalization\n",
    "                    }, ignore_index=True)\n",
    "                    results.to_csv(\"Results_temp.csv\", index=False)\n",
    "                    del model\n",
    "                    del X_trn\n",
    "                    del X_val\n",
    "                    print(\"Done!\\n\" + '-'*50, end='\\n\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
