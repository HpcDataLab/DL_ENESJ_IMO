{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "import os\n",
    "import cv2\n",
    "import pickle\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version is: 2.4.1\n"
     ]
    }
   ],
   "source": [
    "print(f\"Tensorflow version is: {tf.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataPath = \"../../data/OCT/OCT2017/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of Classes Detected : 4\n"
     ]
    }
   ],
   "source": [
    "labels_available = os.listdir(os.path.join(dataPath, \"train\"))\n",
    "print(\"Total Number of Classes Detected :\",len(labels_available))\n",
    "\n",
    "labels_list = ['NORMAL',\"CNV\",\"DME\",\"DRUSEN\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NORMAL CNV DME DRUSEN "
     ]
    }
   ],
   "source": [
    "images=[]\n",
    "y_trn=[]\n",
    "for x in labels_list:\n",
    "    xPath = os.path.join(dataPath, \"train\", x)\n",
    "    myPicList = os.listdir(xPath)\n",
    "    for y in myPicList:\n",
    "        images.append(cv2.imread(os.path.join(xPath, y)))\n",
    "        y_trn.append(labels_list.index(x))\n",
    "    print(x ,end=\" \")\n",
    "\n",
    "y_train = to_categorical(y_trn,len(labels_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NORMAL CNV DME DRUSEN "
     ]
    }
   ],
   "source": [
    "x_val=[]\n",
    "y_val=[]\n",
    "for x in labels_list:\n",
    "    xPath = os.path.join(dataPath, \"val\", x)\n",
    "    myPicList = os.listdir(xPath)\n",
    "    for y in myPicList:\n",
    "        x_val.append(cv2.imread(os.path.join(xPath, y)))\n",
    "        y_val.append(labels_list.index(x))\n",
    "    print(x ,end=\" \")\n",
    "\n",
    "y_validation = to_categorical(y_val,len(labels_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NORMAL CNV DME DRUSEN "
     ]
    }
   ],
   "source": [
    "x_tst=[]\n",
    "y_tst=[]\n",
    "for x in labels_list:\n",
    "    xPath = os.path.join(dataPath, \"test\", x)\n",
    "    myPicList = os.listdir(xPath)\n",
    "    for y in myPicList:\n",
    "        x_tst.append(cv2.imread(os.path.join(xPath, y)))\n",
    "        y_tst.append(labels_list.index(x))\n",
    "    print(x ,end=\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of images per category and set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label\t\tTrain\t\tValidation\t\tTest\n",
      "NORMAL\t\t26315\t\t8\t\t\t242\n",
      "CNV\t\t37205\t\t8\t\t\t242\n",
      "DME\t\t11348\t\t8\t\t\t242\n",
      "DRUSEN\t\t8616\t\t8\t\t\t242\n"
     ]
    }
   ],
   "source": [
    "def getNumberOfItems(labels, itemLabel):\n",
    "    return sum(list(map(lambda x: x == itemLabel, labels))) \n",
    "\n",
    "\n",
    "print(\"Label\\t\\tTrain\\t\\tValidation\\t\\tTest\")\n",
    "for i, label in enumerate(labels_list):\n",
    "    print(f\"{label}\\t\\t{getNumberOfItems(y_trn, i)}\\t\\t{getNumberOfItems(y_val, i)}\\t\\t\\t{getNumberOfItems(y_tst, i)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resizeIm(im, size):\n",
    "    if im.shape[2] == 1:\n",
    "        im = cv2.cvtColor(im,cv2.COLOR_GRAY2RGB)\n",
    "    return cv2.resize(im, size)\n",
    "\n",
    "def resizeIms(x, size):\n",
    "    return np.array(list(map(lambda im: resizeIm(im, size), x)))\n",
    "\n",
    "# Substract the mean specified by Mean (https://www.mathworks.com/help/deeplearning/ref/nnet.cnn.layer.imageinputlayer.html)\n",
    "# Substract mean by channel\n",
    "def zerocenter(x):\n",
    "    return (x - np.mean(x, axis=(0, 1))) / (2*np.std(x, axis=(0, 1)))\n",
    "\n",
    "# Rescale the input to be in the range [-1, 1] using the minimum and maximum values specified by Min and Max, respectively. (https://www.mathworks.com/help/deeplearning/ref/nnet.cnn.layer.imageinputlayer.html)\n",
    "# Compute using the formula: $x\\prime = 2 * \\frac{x - \\min{x}}{\\max{x} - \\min{x}} - 1$ taken from: https://stats.stackexchange.com/a/178629\n",
    "def rescaleSymmetric(x):\n",
    "    x = zerocenter(x)\n",
    "    return 2 * (x - np.min(x, axis=(0, 1)))/np.ptp(x, axis=(0, 1)) - 1\n",
    "\n",
    "def normalizeIms(x, normalization):\n",
    "    if normalization == \"zerocenter\":\n",
    "        func = zerocenter\n",
    "    elif normalization == \"rescale-symmetric\":\n",
    "        func = rescaleSymmetric\n",
    "    else:\n",
    "        return x\n",
    "    return np.array(list(map(lambda im: func(im), x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self,fraction, model):\n",
    "        super(CustomCallback,self).__init__()\n",
    "        self.fraction = fraction\n",
    "        self.train_a = [];\n",
    "        self.val_a =[];\n",
    "        self.logPath = os.path.join(model, \"log.txt\")\n",
    "\n",
    "        if not os.path.isdir(model):\n",
    "            os.mkdir(model)\n",
    "\n",
    "        with open(self.logPath,'w') as f:\n",
    "            f.write('Starting of logging..\\n')\n",
    "\n",
    "        self.fig = plt.figure(figsize=(4,3))\n",
    "        self.ax = plt.subplot(1,1,1)\n",
    "        plt.ion()\n",
    "\n",
    "    def on_train_begin(self,logs=None):\n",
    "        self.fig.show()\n",
    "        self.fig.canvas.draw()\n",
    "\n",
    "    def on_train_end(self,logs=None):\n",
    "        with open(self.logPath,'a') as f:\n",
    "              f.write('End of logging..\\n')\n",
    "    \n",
    "    def on_epoch_begin(self,epoch,logs=None):\n",
    "        lr= tf.keras.backend.get_value(self.model.optimizer.lr)\n",
    "        lr *= self.fraction\n",
    "        tf.keras.backend.set_value(self.model.optimizer.lr,lr)\n",
    "        with open(self.logPath,'a') as f:\n",
    "            f.write('At epoch {:02d}, learning rate changed to {:.4f}\\n'.format(epoch,lr))\n",
    "    \n",
    "    def on_epoch_end(self,epoch,logs=None):\n",
    "        val_acc = logs.get('val_accuracy')\n",
    "        train_acc = logs.get('accuracy')\n",
    "        self.train_a.append(train_acc)\n",
    "        self.val_a.append(val_acc)\n",
    "        with open(self.logPath,'a') as f:\n",
    "            f.write('At epoch {:02d}, training accuracy: {:.3f}, validation accuracy: {:.3f}\\n'.format(epoch,train_acc,val_acc))\n",
    "        self.ax.clear()\n",
    "        self.ax.plot(range(1+epoch),self.train_a,label=\"Training\")\n",
    "        self.ax.plot(range(1+epoch),self.val_a,label=\"Validation\")\n",
    "        self.ax.set_xlabel('Epochs')\n",
    "        self.ax.set_ylabel('Accuracy')\n",
    "        self.ax.legend()\n",
    "        self.fig.canvas.draw()\n",
    "        self.fig.show()\n",
    "        \n",
    "class TimeHistory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.times = []\n",
    "\n",
    "    def on_epoch_begin(self, batch, logs={}):\n",
    "        self.epoch_time_start = time.time()\n",
    "\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.times.append(time.time() - self.epoch_time_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "# xception base model\n",
    "#from tensorflow.keras.applications.xception import Xception\n",
    "#from tensorflow.keras.applications.xception import preprocess_input, decode_predictions\n",
    "#xceptionNetModel = Xception(weights='imagenet')\n",
    "#xceptionNetModel.save(\"../Xception.hdf5\")\n",
    "\n",
    "xceptionNetModel = tf.keras.models.load_model('../Xception.hdf5')\n",
    "\n",
    "# opticnet base model\n",
    "opticNetModel = tf.keras.models.load_model('../Optic_net-4_classes-Kermany2018.hdf5')\n",
    "\n",
    "# resnet base model\n",
    "#from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "#from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "#resNetModel = ResNet50(weights='imagenet')\n",
    "#resNetModel.save(\"../Resnet50.hdf5\")\n",
    "\n",
    "resNetModel = tf.keras.models.load_model('../Resnet50.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 221, 221, 32)      4736      \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 221, 221, 32)      128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 110, 110, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 104, 104, 32)      50208     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 104, 104, 32)      128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 52, 52, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 48, 48, 64)        51264     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 48, 48, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 24, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 20, 20, 128)       204928    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 20, 20, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 10, 10, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 8, 8, 256)         295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d (AveragePo (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               131200    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4)                 132       \n",
      "_________________________________________________________________\n",
      "softmax (Softmax)            (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 743,812\n",
      "Trainable params: 742,788\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "conv_init = tf.keras.initializers.RandomNormal(mean=0., stddev=1.) # convolutional layer with zero mean and 1 sd\n",
    "#batch_init = tf.keras.initializers.RandomNormal(mean=1., stddev=0.02) # non-sense here\n",
    "\n",
    "octnet = keras.models.Sequential() # empty model\n",
    "\n",
    "octnet.add(keras.layers.Conv2D(32, (7, 7), activation=\"relu\", use_bias=True, input_shape=(227, 227, 3), kernel_initializer=conv_init))\n",
    "octnet.add(keras.layers.BatchNormalization())\n",
    "octnet.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "octnet.add(keras.layers.Conv2D(32, (7, 7), activation=\"relu\", use_bias=True, kernel_initializer=conv_init))\n",
    "octnet.add(keras.layers.BatchNormalization())\n",
    "octnet.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "octnet.add(keras.layers.Conv2D(64, (5, 5), activation=\"relu\", use_bias=True, kernel_initializer=conv_init))\n",
    "octnet.add(keras.layers.BatchNormalization())\n",
    "octnet.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "octnet.add(keras.layers.Conv2D(128, (5, 5), activation=\"relu\", use_bias=True, kernel_initializer=conv_init))\n",
    "octnet.add(keras.layers.BatchNormalization())\n",
    "octnet.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "octnet.add(keras.layers.Conv2D(256, (3, 3), activation=\"relu\", use_bias=True, kernel_initializer=conv_init))\n",
    "octnet.add(keras.layers.BatchNormalization())\n",
    "octnet.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "#octnet.add(keras.layers.Conv2D(512, (3, 3), activation=\"relu\", use_bias=True))\n",
    "#octnet.add(keras.layers.BatchNormalization())\n",
    "#octnet.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "octnet.add(keras.layers.AveragePooling2D())\n",
    "octnet.add(keras.layers.Flatten())\n",
    "octnet.add(keras.layers.Dense(128))\n",
    "octnet.add(keras.layers.Dropout(0.5))\n",
    "octnet.add(keras.layers.Dense(32))\n",
    "octnet.add(keras.layers.Dropout(0.5))\n",
    "octnet.add(keras.layers.Dense(4))\n",
    "octnet.add(keras.layers.Softmax())\n",
    "\n",
    "octnet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emptyModelGenerator(model, newWeights=False, lastOnly=False):\n",
    "    model = model.lower() # lower case model name\n",
    "    if model == \"resnet\":\n",
    "        x = resNetModel.output\n",
    "        predictions = Dense(len(labels_list), activation='softmax')(x)\n",
    "        newModel = Model(inputs=resNetModel.input, outputs=predictions)\n",
    "        size = (224, 224)\n",
    "        normalization = \"zerocenter\"\n",
    "    elif model == \"xception\":\n",
    "        x = xceptionNetModel.output\n",
    "        predictions = Dense(len(labels_list), activation='softmax')(x)\n",
    "        newModel = Model(inputs=xceptionNetModel.input, outputs=predictions)\n",
    "        size = (299, 299)\n",
    "        normalization = \"rescale-symmetric\"\n",
    "    elif model == \"opticnet\":\n",
    "        newModel = tf.keras.models.load_model('../Optic_net-4_classes-Kermany2018.hdf5')\n",
    "        size = (224, 224)\n",
    "        normalization = \"rescale-symmetric\"\n",
    "    elif model == \"octnet\":\n",
    "        newModel = tf.keras.models.clone_model(octnet)\n",
    "        size = (227, 227)\n",
    "        normalization = \"zerocenter\"\n",
    "    if newWeights:\n",
    "        newModel = tf.keras.models.clone_model(newModel)\n",
    "    if lastOnly:\n",
    "        newModel = lastDenseTrainable(newModel) # block all layer except the last dense ones\n",
    "    else:\n",
    "        newModel.trainable = True\n",
    "    return newModel, size, normalization\n",
    "\n",
    "\n",
    "def lastDenseTrainable(model):\n",
    "    model.trainable = False\n",
    "    for i in range(1, len(model.layers)):\n",
    "        if model.layers[-i].__class__.__name__ == \"Dense\":\n",
    "            model.layers[-i].trainable= True\n",
    "        elif model.layers[-i].__class__.__name__ == \"Activation\":\n",
    "            continue\n",
    "        else:\n",
    "            break\n",
    "    return model\n",
    "    \n",
    "\n",
    "def testPredict(model, size, name=None, normalization=None):\n",
    "    X_test = resizeIms(x_tst, size)\n",
    "    if normalization:\n",
    "        X_test = normalizeIms(X_test, normalization)\n",
    "    X_test = np.array(X_test)\n",
    "    Y_test = np.array(y_tst)\n",
    "    \n",
    "    prediction = model.predict(X_test)\n",
    "    preds = np.argmax(prediction, axis=1)\n",
    "    acc = sum(preds == Y_test) / len(Y_test)\n",
    "    print(f'Test acc for {name if name else \"model\"}: {acc:.6f}')\n",
    "    return acc\n",
    "    \n",
    "\n",
    "def computeConfussionMatrix(predictions, labels):\n",
    "    num_labels = len(labels_list)\n",
    "    cMatrix = np.zeros(shape=(num_labels, num_labels))\n",
    "    for i in len(predictions):\n",
    "        p = int(predictions[i])\n",
    "        t = int(predictions[i])\n",
    "        cMatrix[t, p] += 1\n",
    "    print(cMatrix)\n",
    "    ax = sns.heatmap(cMatrix, cmap=\"Blues\", annot=True, fmt=\"d\", xticklabels=labels_list, yticklabels=labels_list)\n",
    "    plt.xlabel(\"Predicted label\")\n",
    "    plt.ylabel(\"True label\")\n",
    "    plt.title(\"Confusion matrix\")\n",
    "    plt.show();\n",
    "    return cMatrix\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "**************************************************\n",
      "Model: xception\n",
      "**************************************************\n",
      "\n",
      "Total: 135 trainable: 2\n",
      "\n",
      "\n",
      "**************************************************\n",
      "Model: resnet\n",
      "**************************************************\n",
      "\n",
      "Total: 178 trainable: 2\n",
      "\n",
      "\n",
      "**************************************************\n",
      "Model: opticnet\n",
      "**************************************************\n",
      "\n",
      "Total: 276 trainable: 2\n",
      "\n",
      "\n",
      "**************************************************\n",
      "Model: octnet\n",
      "**************************************************\n",
      "\n",
      "Total: 23 trainable: 0\n"
     ]
    }
   ],
   "source": [
    "models = [\"xception\", \"resnet\", \"opticnet\", \"octnet\"]\n",
    "\n",
    "def printTrainableLayers(m):\n",
    "    a = 0\n",
    "    for l in m.layers:\n",
    "        #l.trainable = True\n",
    "        if l.trainable:\n",
    "            #print(l.name, l.trainable)\n",
    "            a += 1\n",
    "    print(f\"\\nTotal: {len(m.layers)} trainable: {a}\")\n",
    "\n",
    "for mod in models:\n",
    "    print(\"\\n\\n\" + (\"*\"*50) + \"\\nModel: \" + mod + '\\n' + (\"*\"*50))\n",
    "    m = emptyModelGenerator(mod, newWeights=False, lastOnly=True)[0]\n",
    "    printTrainableLayers(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "momentum = 0.9\n",
    "optim = lambda lr: Adam(learning_rate=lr)\n",
    "#optim = lambda lr, momentum: SGD(learning_rate=lr, momentum=momentum)\n",
    "epochs = 30\n",
    "#batch_size = 50\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "results = pd.read_csv(\"Results.csv\")\n",
    "results[\"normalization\"] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pandas as pd\n",
    "#res = pd.read_csv(\"Results_temp.csv\")\n",
    "#res.to_csv(\"Results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels fraction: [0.0100703  0.01042871 0.00845964 0.00986537]\n",
      "Training resnet for 0.01% of train size (aka 834 images) with pretrained: False and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 178 trainable: 178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "6/7 [========================>.....] - ETA: 0s - loss: 1.3854 - accuracy: 0.3210WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2015s vs `on_train_batch_end` time: 0.5219s). Check your callbacks.\n",
      "7/7 [==============================] - 13s 1s/step - loss: 1.3854 - accuracy: 0.3397 - val_loss: 1.3863 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "7/7 [==============================] - 3s 440ms/step - loss: 1.3844 - accuracy: 0.4656 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "7/7 [==============================] - 3s 437ms/step - loss: 1.3833 - accuracy: 0.4644 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "7/7 [==============================] - 3s 440ms/step - loss: 1.3825 - accuracy: 0.4577 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "7/7 [==============================] - 3s 438ms/step - loss: 1.3815 - accuracy: 0.4610 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "7/7 [==============================] - 3s 439ms/step - loss: 1.3807 - accuracy: 0.4697 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "7/7 [==============================] - 3s 440ms/step - loss: 1.3798 - accuracy: 0.4785 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "7/7 [==============================] - 3s 440ms/step - loss: 1.3795 - accuracy: 0.4743 - val_loss: 1.3864 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "7/7 [==============================] - 3s 443ms/step - loss: 1.3790 - accuracy: 0.4635 - val_loss: 1.3864 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "7/7 [==============================] - 3s 443ms/step - loss: 1.3789 - accuracy: 0.4577 - val_loss: 1.3864 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "7/7 [==============================] - 3s 445ms/step - loss: 1.3778 - accuracy: 0.4752 - val_loss: 1.3864 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "7/7 [==============================] - 3s 444ms/step - loss: 1.3782 - accuracy: 0.4527 - val_loss: 1.3864 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "7/7 [==============================] - 3s 445ms/step - loss: 1.3773 - accuracy: 0.4677 - val_loss: 1.3864 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "7/7 [==============================] - 3s 445ms/step - loss: 1.3767 - accuracy: 0.4777 - val_loss: 1.3864 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "7/7 [==============================] - 3s 444ms/step - loss: 1.3766 - accuracy: 0.4718 - val_loss: 1.3864 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "7/7 [==============================] - 3s 446ms/step - loss: 1.3765 - accuracy: 0.4582 - val_loss: 1.3864 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "7/7 [==============================] - 3s 447ms/step - loss: 1.3768 - accuracy: 0.4560 - val_loss: 1.3864 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "7/7 [==============================] - 3s 446ms/step - loss: 1.3759 - accuracy: 0.4713 - val_loss: 1.3864 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "7/7 [==============================] - 3s 447ms/step - loss: 1.3765 - accuracy: 0.4566 - val_loss: 1.3864 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "7/7 [==============================] - 3s 447ms/step - loss: 1.3754 - accuracy: 0.4822 - val_loss: 1.3864 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "7/7 [==============================] - 3s 447ms/step - loss: 1.3754 - accuracy: 0.4716 - val_loss: 1.3864 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "7/7 [==============================] - 3s 448ms/step - loss: 1.3758 - accuracy: 0.4541 - val_loss: 1.3864 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "7/7 [==============================] - 3s 448ms/step - loss: 1.3758 - accuracy: 0.4576 - val_loss: 1.3864 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "7/7 [==============================] - 3s 449ms/step - loss: 1.3759 - accuracy: 0.4507 - val_loss: 1.3864 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "7/7 [==============================] - 3s 449ms/step - loss: 1.3750 - accuracy: 0.4666 - val_loss: 1.3864 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "7/7 [==============================] - 3s 448ms/step - loss: 1.3746 - accuracy: 0.4862 - val_loss: 1.3864 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "7/7 [==============================] - 3s 451ms/step - loss: 1.3752 - accuracy: 0.4585 - val_loss: 1.3864 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "7/7 [==============================] - 3s 449ms/step - loss: 1.3752 - accuracy: 0.4580 - val_loss: 1.3864 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "7/7 [==============================] - 3s 449ms/step - loss: 1.3752 - accuracy: 0.4586 - val_loss: 1.3864 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "7/7 [==============================] - 3s 449ms/step - loss: 1.3752 - accuracy: 0.4606 - val_loss: 1.3864 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_835_images_True_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.02496675 0.02607176 0.02264716 0.02356082]\n",
      "Training resnet for 0.025% of train size (aka 2087 images) with pretrained: False and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 178 trainable: 178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      " 6/17 [=========>....................] - ETA: 10s - loss: 1.3858 - accuracy: 0.3367WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2024s vs `on_train_batch_end` time: 0.5036s). Check your callbacks.\n",
      "17/17 [==============================] - 18s 708ms/step - loss: 1.3854 - accuracy: 0.3930 - val_loss: 1.3863 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "17/17 [==============================] - 8s 454ms/step - loss: 1.3830 - accuracy: 0.4479 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "17/17 [==============================] - 8s 456ms/step - loss: 1.3803 - accuracy: 0.4719 - val_loss: 1.3864 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "17/17 [==============================] - 8s 458ms/step - loss: 1.3780 - accuracy: 0.4680 - val_loss: 1.3864 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "17/17 [==============================] - 8s 459ms/step - loss: 1.3764 - accuracy: 0.4633 - val_loss: 1.3864 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "17/17 [==============================] - 8s 459ms/step - loss: 1.3746 - accuracy: 0.4730 - val_loss: 1.3865 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "17/17 [==============================] - 8s 460ms/step - loss: 1.3727 - accuracy: 0.4752 - val_loss: 1.3866 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "17/17 [==============================] - 8s 461ms/step - loss: 1.3717 - accuracy: 0.4637 - val_loss: 1.3866 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "17/17 [==============================] - 8s 461ms/step - loss: 1.3711 - accuracy: 0.4477 - val_loss: 1.3867 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "17/17 [==============================] - 8s 461ms/step - loss: 1.3692 - accuracy: 0.4702 - val_loss: 1.3867 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "17/17 [==============================] - 8s 461ms/step - loss: 1.3680 - accuracy: 0.4801 - val_loss: 1.3868 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "17/17 [==============================] - 8s 461ms/step - loss: 1.3669 - accuracy: 0.4730 - val_loss: 1.3868 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "17/17 [==============================] - 8s 462ms/step - loss: 1.3659 - accuracy: 0.4814 - val_loss: 1.3868 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "17/17 [==============================] - 8s 462ms/step - loss: 1.3666 - accuracy: 0.4617 - val_loss: 1.3869 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "17/17 [==============================] - 8s 464ms/step - loss: 1.3647 - accuracy: 0.4839 - val_loss: 1.3869 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "17/17 [==============================] - 8s 462ms/step - loss: 1.3649 - accuracy: 0.4609 - val_loss: 1.3869 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "17/17 [==============================] - 8s 462ms/step - loss: 1.3647 - accuracy: 0.4590 - val_loss: 1.3870 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "17/17 [==============================] - 8s 462ms/step - loss: 1.3638 - accuracy: 0.4712 - val_loss: 1.3870 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "17/17 [==============================] - 8s 462ms/step - loss: 1.3640 - accuracy: 0.4594 - val_loss: 1.3871 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "17/17 [==============================] - 8s 463ms/step - loss: 1.3626 - accuracy: 0.4645 - val_loss: 1.3871 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "17/17 [==============================] - 8s 462ms/step - loss: 1.3646 - accuracy: 0.4564 - val_loss: 1.3871 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "17/17 [==============================] - 8s 462ms/step - loss: 1.3620 - accuracy: 0.4652 - val_loss: 1.3871 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "17/17 [==============================] - 8s 461ms/step - loss: 1.3627 - accuracy: 0.4569 - val_loss: 1.3871 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "17/17 [==============================] - 8s 461ms/step - loss: 1.3614 - accuracy: 0.4669 - val_loss: 1.3871 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "17/17 [==============================] - 8s 462ms/step - loss: 1.3619 - accuracy: 0.4662 - val_loss: 1.3872 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "17/17 [==============================] - 8s 462ms/step - loss: 1.3629 - accuracy: 0.4568 - val_loss: 1.3872 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "17/17 [==============================] - 8s 463ms/step - loss: 1.3619 - accuracy: 0.4572 - val_loss: 1.3872 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "17/17 [==============================] - 8s 461ms/step - loss: 1.3620 - accuracy: 0.4629 - val_loss: 1.3872 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "17/17 [==============================] - 8s 461ms/step - loss: 1.3606 - accuracy: 0.4770 - val_loss: 1.3872 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "17/17 [==============================] - 8s 461ms/step - loss: 1.3616 - accuracy: 0.4652 - val_loss: 1.3872 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_2087_images_True_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.05050352 0.04929445 0.05137469 0.04967502]\n",
      "Training resnet for 0.05% of train size (aka 4174 images) with pretrained: False and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 178 trainable: 178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      " 6/33 [====>.........................] - ETA: 27s - loss: 1.3857 - accuracy: 0.2539WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2053s vs `on_train_batch_end` time: 0.5336s). Check your callbacks.\n",
      "33/33 [==============================] - 27s 598ms/step - loss: 1.3848 - accuracy: 0.3711 - val_loss: 1.3863 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "33/33 [==============================] - 16s 471ms/step - loss: 1.3804 - accuracy: 0.4412 - val_loss: 1.3864 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "33/33 [==============================] - 16s 473ms/step - loss: 1.3770 - accuracy: 0.4249 - val_loss: 1.3865 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "33/33 [==============================] - 16s 474ms/step - loss: 1.3735 - accuracy: 0.4337 - val_loss: 1.3867 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "33/33 [==============================] - 16s 475ms/step - loss: 1.3700 - accuracy: 0.4419 - val_loss: 1.3868 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "33/33 [==============================] - 16s 475ms/step - loss: 1.3678 - accuracy: 0.4376 - val_loss: 1.3869 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "33/33 [==============================] - 16s 475ms/step - loss: 1.3654 - accuracy: 0.4436 - val_loss: 1.3871 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "33/33 [==============================] - 16s 476ms/step - loss: 1.3633 - accuracy: 0.4379 - val_loss: 1.3873 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "33/33 [==============================] - 16s 476ms/step - loss: 1.3615 - accuracy: 0.4370 - val_loss: 1.3874 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "33/33 [==============================] - 16s 476ms/step - loss: 1.3602 - accuracy: 0.4281 - val_loss: 1.3876 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "33/33 [==============================] - 16s 476ms/step - loss: 1.3594 - accuracy: 0.4291 - val_loss: 1.3877 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "33/33 [==============================] - 16s 476ms/step - loss: 1.3552 - accuracy: 0.4546 - val_loss: 1.3880 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "33/33 [==============================] - 16s 476ms/step - loss: 1.3560 - accuracy: 0.4382 - val_loss: 1.3881 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "33/33 [==============================] - 16s 476ms/step - loss: 1.3536 - accuracy: 0.4525 - val_loss: 1.3883 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "33/33 [==============================] - 16s 477ms/step - loss: 1.3563 - accuracy: 0.4267 - val_loss: 1.3885 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "33/33 [==============================] - 16s 476ms/step - loss: 1.3536 - accuracy: 0.4401 - val_loss: 1.3887 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "33/33 [==============================] - 16s 477ms/step - loss: 1.3519 - accuracy: 0.4448 - val_loss: 1.3887 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "33/33 [==============================] - 16s 477ms/step - loss: 1.3520 - accuracy: 0.4446 - val_loss: 1.3889 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "33/33 [==============================] - 16s 476ms/step - loss: 1.3502 - accuracy: 0.4395 - val_loss: 1.3890 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "33/33 [==============================] - 16s 477ms/step - loss: 1.3482 - accuracy: 0.4553 - val_loss: 1.3891 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "33/33 [==============================] - 16s 477ms/step - loss: 1.3502 - accuracy: 0.4351 - val_loss: 1.3892 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "33/33 [==============================] - 16s 476ms/step - loss: 1.3494 - accuracy: 0.4411 - val_loss: 1.3894 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "33/33 [==============================] - 16s 476ms/step - loss: 1.3482 - accuracy: 0.4430 - val_loss: 1.3894 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "33/33 [==============================] - 16s 476ms/step - loss: 1.3458 - accuracy: 0.4523 - val_loss: 1.3895 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "33/33 [==============================] - 16s 477ms/step - loss: 1.3485 - accuracy: 0.4381 - val_loss: 1.3895 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "33/33 [==============================] - 16s 478ms/step - loss: 1.3459 - accuracy: 0.4613 - val_loss: 1.3896 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "33/33 [==============================] - 16s 476ms/step - loss: 1.3480 - accuracy: 0.4406 - val_loss: 1.3896 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "33/33 [==============================] - 16s 477ms/step - loss: 1.3510 - accuracy: 0.4145 - val_loss: 1.3896 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "33/33 [==============================] - 16s 476ms/step - loss: 1.3476 - accuracy: 0.4403 - val_loss: 1.3896 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "33/33 [==============================] - 16s 475ms/step - loss: 1.3477 - accuracy: 0.4388 - val_loss: 1.3896 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_4174_images_True_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.07573627 0.07464051 0.07543179 0.07370009]\n",
      "Training resnet for 0.075% of train size (aka 6261 images) with pretrained: False and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 178 trainable: 178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      " 6/49 [==>...........................] - ETA: 42s - loss: 1.3864 - accuracy: 0.2038WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2023s vs `on_train_batch_end` time: 0.5423s). Check your callbacks.\n",
      "49/49 [==============================] - 35s 557ms/step - loss: 1.3849 - accuracy: 0.3662 - val_loss: 1.3864 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "49/49 [==============================] - 23s 477ms/step - loss: 1.3786 - accuracy: 0.4359 - val_loss: 1.3865 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "49/49 [==============================] - 23s 478ms/step - loss: 1.3725 - accuracy: 0.4498 - val_loss: 1.3868 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "49/49 [==============================] - 23s 479ms/step - loss: 1.3682 - accuracy: 0.4456 - val_loss: 1.3871 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "49/49 [==============================] - 24s 480ms/step - loss: 1.3633 - accuracy: 0.4488 - val_loss: 1.3875 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "49/49 [==============================] - 24s 481ms/step - loss: 1.3600 - accuracy: 0.4451 - val_loss: 1.3878 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "49/49 [==============================] - 24s 480ms/step - loss: 1.3564 - accuracy: 0.4449 - val_loss: 1.3881 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "49/49 [==============================] - 24s 481ms/step - loss: 1.3525 - accuracy: 0.4568 - val_loss: 1.3885 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "49/49 [==============================] - 24s 481ms/step - loss: 1.3502 - accuracy: 0.4541 - val_loss: 1.3888 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "49/49 [==============================] - 24s 481ms/step - loss: 1.3490 - accuracy: 0.4451 - val_loss: 1.3891 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "49/49 [==============================] - 24s 481ms/step - loss: 1.3455 - accuracy: 0.4563 - val_loss: 1.3894 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "49/49 [==============================] - 24s 480ms/step - loss: 1.3438 - accuracy: 0.4542 - val_loss: 1.3896 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "49/49 [==============================] - 24s 481ms/step - loss: 1.3434 - accuracy: 0.4418 - val_loss: 1.3898 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "49/49 [==============================] - 24s 481ms/step - loss: 1.3420 - accuracy: 0.4495 - val_loss: 1.3900 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "49/49 [==============================] - 24s 481ms/step - loss: 1.3418 - accuracy: 0.4422 - val_loss: 1.3903 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "49/49 [==============================] - 24s 481ms/step - loss: 1.3412 - accuracy: 0.4354 - val_loss: 1.3905 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "49/49 [==============================] - 24s 481ms/step - loss: 1.3389 - accuracy: 0.4415 - val_loss: 1.3906 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "49/49 [==============================] - 24s 481ms/step - loss: 1.3384 - accuracy: 0.4373 - val_loss: 1.3908 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "49/49 [==============================] - 24s 481ms/step - loss: 1.3388 - accuracy: 0.4348 - val_loss: 1.3910 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "49/49 [==============================] - 24s 481ms/step - loss: 1.3365 - accuracy: 0.4479 - val_loss: 1.3911 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "49/49 [==============================] - 24s 481ms/step - loss: 1.3346 - accuracy: 0.4498 - val_loss: 1.3912 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "49/49 [==============================] - 24s 481ms/step - loss: 1.3357 - accuracy: 0.4482 - val_loss: 1.3913 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "49/49 [==============================] - 24s 481ms/step - loss: 1.3358 - accuracy: 0.4442 - val_loss: 1.3915 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "49/49 [==============================] - 24s 481ms/step - loss: 1.3333 - accuracy: 0.4474 - val_loss: 1.3915 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "49/49 [==============================] - 24s 481ms/step - loss: 1.3355 - accuracy: 0.4425 - val_loss: 1.3916 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "49/49 [==============================] - 24s 481ms/step - loss: 1.3322 - accuracy: 0.4528 - val_loss: 1.3917 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "49/49 [==============================] - 24s 482ms/step - loss: 1.3348 - accuracy: 0.4323 - val_loss: 1.3917 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "49/49 [==============================] - 24s 481ms/step - loss: 1.3322 - accuracy: 0.4502 - val_loss: 1.3918 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "49/49 [==============================] - 24s 481ms/step - loss: 1.3346 - accuracy: 0.4399 - val_loss: 1.3919 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "49/49 [==============================] - 24s 480ms/step - loss: 1.3319 - accuracy: 0.4434 - val_loss: 1.3919 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_6261_images_True_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.09158275 0.08899341 0.08970744 0.08983287]\n",
      "Training resnet for 0.09% of train size (aka 7513 images) with pretrained: False and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 178 trainable: 178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      " 6/59 [==>...........................] - ETA: 52s - loss: 1.3861 - accuracy: 0.2534 WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2037s vs `on_train_batch_end` time: 0.5117s). Check your callbacks.\n",
      "59/59 [==============================] - 38s 542ms/step - loss: 1.3843 - accuracy: 0.3391 - val_loss: 1.3864 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "59/59 [==============================] - 28s 476ms/step - loss: 1.3766 - accuracy: 0.4371 - val_loss: 1.3867 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "59/59 [==============================] - 28s 478ms/step - loss: 1.3700 - accuracy: 0.4403 - val_loss: 1.3871 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "59/59 [==============================] - 28s 478ms/step - loss: 1.3641 - accuracy: 0.4399 - val_loss: 1.3875 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "59/59 [==============================] - 28s 479ms/step - loss: 1.3591 - accuracy: 0.4391 - val_loss: 1.3880 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "59/59 [==============================] - 28s 479ms/step - loss: 1.3552 - accuracy: 0.4475 - val_loss: 1.3884 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "59/59 [==============================] - 28s 479ms/step - loss: 1.3513 - accuracy: 0.4479 - val_loss: 1.3889 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "59/59 [==============================] - 28s 479ms/step - loss: 1.3483 - accuracy: 0.4362 - val_loss: 1.3893 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "59/59 [==============================] - 28s 479ms/step - loss: 1.3461 - accuracy: 0.4329 - val_loss: 1.3897 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "59/59 [==============================] - 28s 479ms/step - loss: 1.3437 - accuracy: 0.4336 - val_loss: 1.3901 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "59/59 [==============================] - 28s 479ms/step - loss: 1.3396 - accuracy: 0.4416 - val_loss: 1.3905 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "59/59 [==============================] - 28s 479ms/step - loss: 1.3373 - accuracy: 0.4494 - val_loss: 1.3909 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "59/59 [==============================] - 28s 479ms/step - loss: 1.3383 - accuracy: 0.4318 - val_loss: 1.3913 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "59/59 [==============================] - 28s 479ms/step - loss: 1.3372 - accuracy: 0.4370 - val_loss: 1.3916 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "59/59 [==============================] - 28s 479ms/step - loss: 1.3336 - accuracy: 0.4371 - val_loss: 1.3918 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "59/59 [==============================] - 28s 479ms/step - loss: 1.3339 - accuracy: 0.4400 - val_loss: 1.3921 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "59/59 [==============================] - 28s 479ms/step - loss: 1.3306 - accuracy: 0.4456 - val_loss: 1.3923 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "59/59 [==============================] - 28s 480ms/step - loss: 1.3299 - accuracy: 0.4449 - val_loss: 1.3925 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "59/59 [==============================] - 28s 479ms/step - loss: 1.3300 - accuracy: 0.4408 - val_loss: 1.3928 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "59/59 [==============================] - 28s 479ms/step - loss: 1.3283 - accuracy: 0.4429 - val_loss: 1.3930 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "59/59 [==============================] - 28s 479ms/step - loss: 1.3286 - accuracy: 0.4394 - val_loss: 1.3931 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "59/59 [==============================] - 28s 479ms/step - loss: 1.3295 - accuracy: 0.4379 - val_loss: 1.3933 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "59/59 [==============================] - 28s 480ms/step - loss: 1.3275 - accuracy: 0.4424 - val_loss: 1.3934 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "59/59 [==============================] - 28s 480ms/step - loss: 1.3275 - accuracy: 0.4353 - val_loss: 1.3936 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "59/59 [==============================] - 28s 479ms/step - loss: 1.3277 - accuracy: 0.4386 - val_loss: 1.3937 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "59/59 [==============================] - 28s 479ms/step - loss: 1.3247 - accuracy: 0.4472 - val_loss: 1.3938 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "59/59 [==============================] - 28s 479ms/step - loss: 1.3265 - accuracy: 0.4384 - val_loss: 1.3939 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "59/59 [==============================] - 28s 479ms/step - loss: 1.3247 - accuracy: 0.4517 - val_loss: 1.3939 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "59/59 [==============================] - 28s 479ms/step - loss: 1.3264 - accuracy: 0.4375 - val_loss: 1.3940 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "59/59 [==============================] - 28s 479ms/step - loss: 1.3269 - accuracy: 0.4356 - val_loss: 1.3941 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_7514_images_True_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.10089303 0.09931461 0.10028199 0.0998143 ]\n",
      "Training resnet for 0.1% of train size (aka 8348 images) with pretrained: False and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 178 trainable: 178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      " 6/66 [=>............................] - ETA: 59s - loss: 1.3851 - accuracy: 0.4603 WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2015s vs `on_train_batch_end` time: 0.5218s). Check your callbacks.\n",
      "66/66 [==============================] - 41s 531ms/step - loss: 1.3829 - accuracy: 0.4459 - val_loss: 1.3864 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "66/66 [==============================] - 31s 472ms/step - loss: 1.3743 - accuracy: 0.4471 - val_loss: 1.3868 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "66/66 [==============================] - 31s 475ms/step - loss: 1.3674 - accuracy: 0.4374 - val_loss: 1.3873 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "66/66 [==============================] - 31s 476ms/step - loss: 1.3613 - accuracy: 0.4376 - val_loss: 1.3878 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "66/66 [==============================] - 31s 475ms/step - loss: 1.3560 - accuracy: 0.4373 - val_loss: 1.3884 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "66/66 [==============================] - 31s 476ms/step - loss: 1.3504 - accuracy: 0.4433 - val_loss: 1.3890 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "66/66 [==============================] - 31s 476ms/step - loss: 1.3455 - accuracy: 0.4472 - val_loss: 1.3897 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "66/66 [==============================] - 31s 476ms/step - loss: 1.3434 - accuracy: 0.4372 - val_loss: 1.3903 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "66/66 [==============================] - 31s 476ms/step - loss: 1.3397 - accuracy: 0.4407 - val_loss: 1.3909 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "66/66 [==============================] - 31s 476ms/step - loss: 1.3359 - accuracy: 0.4433 - val_loss: 1.3918 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "66/66 [==============================] - 31s 476ms/step - loss: 1.3324 - accuracy: 0.4470 - val_loss: 1.3922 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "66/66 [==============================] - 31s 476ms/step - loss: 1.3306 - accuracy: 0.4411 - val_loss: 1.3927 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "66/66 [==============================] - 31s 476ms/step - loss: 1.3281 - accuracy: 0.4474 - val_loss: 1.3930 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "66/66 [==============================] - 31s 476ms/step - loss: 1.3267 - accuracy: 0.4451 - val_loss: 1.3934 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "66/66 [==============================] - 31s 476ms/step - loss: 1.3253 - accuracy: 0.4450 - val_loss: 1.3939 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "66/66 [==============================] - 31s 476ms/step - loss: 1.3246 - accuracy: 0.4411 - val_loss: 1.3942 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "66/66 [==============================] - 31s 476ms/step - loss: 1.3224 - accuracy: 0.4443 - val_loss: 1.3946 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "66/66 [==============================] - 32s 477ms/step - loss: 1.3201 - accuracy: 0.4478 - val_loss: 1.3948 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "66/66 [==============================] - 31s 476ms/step - loss: 1.3220 - accuracy: 0.4355 - val_loss: 1.3950 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "66/66 [==============================] - 31s 476ms/step - loss: 1.3215 - accuracy: 0.4365 - val_loss: 1.3953 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "66/66 [==============================] - 31s 476ms/step - loss: 1.3217 - accuracy: 0.4342 - val_loss: 1.3955 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "66/66 [==============================] - 31s 476ms/step - loss: 1.3187 - accuracy: 0.4407 - val_loss: 1.3958 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "66/66 [==============================] - 31s 476ms/step - loss: 1.3180 - accuracy: 0.4414 - val_loss: 1.3959 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "66/66 [==============================] - 31s 476ms/step - loss: 1.3169 - accuracy: 0.4399 - val_loss: 1.3961 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "66/66 [==============================] - 31s 477ms/step - loss: 1.3184 - accuracy: 0.4388 - val_loss: 1.3962 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "66/66 [==============================] - 31s 476ms/step - loss: 1.3170 - accuracy: 0.4377 - val_loss: 1.3962 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "66/66 [==============================] - 31s 476ms/step - loss: 1.3191 - accuracy: 0.4328 - val_loss: 1.3964 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "66/66 [==============================] - 31s 476ms/step - loss: 1.3164 - accuracy: 0.4400 - val_loss: 1.3966 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "66/66 [==============================] - 31s 477ms/step - loss: 1.3157 - accuracy: 0.4433 - val_loss: 1.3969 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "66/66 [==============================] - 31s 476ms/step - loss: 1.3154 - accuracy: 0.4381 - val_loss: 1.3972 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_8348_images_True_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.25251758 0.24784303 0.25484667 0.24524141]\n",
      "Training resnet for 0.25% of train size (aka 20871 images) with pretrained: False and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 178 trainable: 178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/164 [>.............................] - ETA: 2:36 - loss: 1.3867 - accuracy: 0.1895WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1989s vs `on_train_batch_end` time: 0.5164s). Check your callbacks.\n",
      "164/164 [==============================] - 88s 498ms/step - loss: 1.3814 - accuracy: 0.3865 - val_loss: 1.3871 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "164/164 [==============================] - 79s 479ms/step - loss: 1.3608 - accuracy: 0.4437 - val_loss: 1.3889 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "164/164 [==============================] - 79s 480ms/step - loss: 1.3450 - accuracy: 0.4403 - val_loss: 1.3914 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "164/164 [==============================] - 79s 479ms/step - loss: 1.3334 - accuracy: 0.4372 - val_loss: 1.3942 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "164/164 [==============================] - 79s 479ms/step - loss: 1.3214 - accuracy: 0.4449 - val_loss: 1.3970 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "164/164 [==============================] - 79s 479ms/step - loss: 1.3148 - accuracy: 0.4403 - val_loss: 1.3997 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "164/164 [==============================] - 79s 479ms/step - loss: 1.3105 - accuracy: 0.4301 - val_loss: 1.4026 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "164/164 [==============================] - 78s 478ms/step - loss: 1.3033 - accuracy: 0.4390 - val_loss: 1.4053 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "164/164 [==============================] - 78s 478ms/step - loss: 1.2955 - accuracy: 0.4477 - val_loss: 1.4074 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "164/164 [==============================] - 79s 479ms/step - loss: 1.2940 - accuracy: 0.4393 - val_loss: 1.4097 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "164/164 [==============================] - 78s 478ms/step - loss: 1.2899 - accuracy: 0.4433 - val_loss: 1.4116 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "164/164 [==============================] - 78s 478ms/step - loss: 1.2863 - accuracy: 0.4421 - val_loss: 1.4136 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "164/164 [==============================] - 79s 479ms/step - loss: 1.2814 - accuracy: 0.4483 - val_loss: 1.4156 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "164/164 [==============================] - 78s 478ms/step - loss: 1.2835 - accuracy: 0.4392 - val_loss: 1.4172 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "164/164 [==============================] - 79s 479ms/step - loss: 1.2825 - accuracy: 0.4376 - val_loss: 1.4186 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "164/164 [==============================] - 79s 479ms/step - loss: 1.2791 - accuracy: 0.4417 - val_loss: 1.4198 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "164/164 [==============================] - 79s 479ms/step - loss: 1.2754 - accuracy: 0.4425 - val_loss: 1.4211 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "164/164 [==============================] - 79s 479ms/step - loss: 1.2755 - accuracy: 0.4402 - val_loss: 1.4222 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "164/164 [==============================] - 78s 479ms/step - loss: 1.2723 - accuracy: 0.4466 - val_loss: 1.4233 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "164/164 [==============================] - 79s 479ms/step - loss: 1.2758 - accuracy: 0.4396 - val_loss: 1.4239 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "164/164 [==============================] - 79s 479ms/step - loss: 1.2718 - accuracy: 0.4425 - val_loss: 1.4251 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "164/164 [==============================] - 79s 479ms/step - loss: 1.2715 - accuracy: 0.4413 - val_loss: 1.4256 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "164/164 [==============================] - 79s 479ms/step - loss: 1.2715 - accuracy: 0.4450 - val_loss: 1.4264 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "164/164 [==============================] - 78s 479ms/step - loss: 1.2694 - accuracy: 0.4448 - val_loss: 1.4270 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "164/164 [==============================] - 79s 479ms/step - loss: 1.2730 - accuracy: 0.4378 - val_loss: 1.4280 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "164/164 [==============================] - 79s 479ms/step - loss: 1.2703 - accuracy: 0.4379 - val_loss: 1.4284 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "164/164 [==============================] - 79s 479ms/step - loss: 1.2696 - accuracy: 0.4363 - val_loss: 1.4287 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "164/164 [==============================] - 79s 479ms/step - loss: 1.2687 - accuracy: 0.4414 - val_loss: 1.4292 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "164/164 [==============================] - 79s 479ms/step - loss: 1.2691 - accuracy: 0.4415 - val_loss: 1.4297 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "164/164 [==============================] - 79s 479ms/step - loss: 1.2709 - accuracy: 0.4364 - val_loss: 1.4301 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_20871_images_True_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.40547216 0.3980379  0.40183292 0.38927577]\n",
      "Training resnet for 0.4% of train size (aka 33393 images) with pretrained: False and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 178 trainable: 178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/261 [..............................] - ETA: 4:11 - loss: 1.3860 - accuracy: 0.3227WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1986s vs `on_train_batch_end` time: 0.5124s). Check your callbacks.\n",
      "261/261 [==============================] - 135s 494ms/step - loss: 1.3775 - accuracy: 0.4185 - val_loss: 1.3883 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "261/261 [==============================] - 126s 482ms/step - loss: 1.3470 - accuracy: 0.4438 - val_loss: 1.3926 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "261/261 [==============================] - 126s 482ms/step - loss: 1.3254 - accuracy: 0.4432 - val_loss: 1.3982 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "261/261 [==============================] - 126s 481ms/step - loss: 1.3095 - accuracy: 0.4425 - val_loss: 1.4039 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "261/261 [==============================] - 126s 481ms/step - loss: 1.2976 - accuracy: 0.4438 - val_loss: 1.4094 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "261/261 [==============================] - 126s 481ms/step - loss: 1.2858 - accuracy: 0.4491 - val_loss: 1.4147 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "261/261 [==============================] - 126s 481ms/step - loss: 1.2837 - accuracy: 0.4377 - val_loss: 1.4195 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "261/261 [==============================] - 126s 481ms/step - loss: 1.2760 - accuracy: 0.4428 - val_loss: 1.4238 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "261/261 [==============================] - 126s 481ms/step - loss: 1.2709 - accuracy: 0.4428 - val_loss: 1.4278 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "261/261 [==============================] - 126s 481ms/step - loss: 1.2654 - accuracy: 0.4457 - val_loss: 1.4315 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "261/261 [==============================] - 126s 482ms/step - loss: 1.2637 - accuracy: 0.4427 - val_loss: 1.4346 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "261/261 [==============================] - 126s 482ms/step - loss: 1.2637 - accuracy: 0.4404 - val_loss: 1.4374 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "261/261 [==============================] - 126s 481ms/step - loss: 1.2554 - accuracy: 0.4501 - val_loss: 1.4399 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "261/261 [==============================] - 126s 481ms/step - loss: 1.2565 - accuracy: 0.4418 - val_loss: 1.4422 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "261/261 [==============================] - 126s 481ms/step - loss: 1.2562 - accuracy: 0.4434 - val_loss: 1.4442 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "261/261 [==============================] - 126s 482ms/step - loss: 1.2505 - accuracy: 0.4464 - val_loss: 1.4461 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "261/261 [==============================] - 126s 482ms/step - loss: 1.2520 - accuracy: 0.4448 - val_loss: 1.4477 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "261/261 [==============================] - 126s 481ms/step - loss: 1.2532 - accuracy: 0.4438 - val_loss: 1.4493 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "261/261 [==============================] - 126s 482ms/step - loss: 1.2519 - accuracy: 0.4435 - val_loss: 1.4505 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "261/261 [==============================] - 126s 482ms/step - loss: 1.2521 - accuracy: 0.4417 - val_loss: 1.4516 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "261/261 [==============================] - 126s 481ms/step - loss: 1.2486 - accuracy: 0.4441 - val_loss: 1.4528 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "261/261 [==============================] - 126s 481ms/step - loss: 1.2482 - accuracy: 0.4450 - val_loss: 1.4536 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "261/261 [==============================] - 126s 481ms/step - loss: 1.2479 - accuracy: 0.4452 - val_loss: 1.4544 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "261/261 [==============================] - 126s 481ms/step - loss: 1.2467 - accuracy: 0.4446 - val_loss: 1.4553 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "261/261 [==============================] - 126s 481ms/step - loss: 1.2495 - accuracy: 0.4420 - val_loss: 1.4559 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "261/261 [==============================] - 126s 481ms/step - loss: 1.2492 - accuracy: 0.4426 - val_loss: 1.4567 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "261/261 [==============================] - 126s 481ms/step - loss: 1.2495 - accuracy: 0.4404 - val_loss: 1.4572 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "261/261 [==============================] - 126s 481ms/step - loss: 1.2499 - accuracy: 0.4394 - val_loss: 1.4576 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "261/261 [==============================] - 126s 482ms/step - loss: 1.2441 - accuracy: 0.4462 - val_loss: 1.4579 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "261/261 [==============================] - 126s 481ms/step - loss: 1.2494 - accuracy: 0.4434 - val_loss: 1.4585 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_33394_images_True_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.5065552  0.49565919 0.50361297 0.49396472]\n",
      "Training resnet for 0.5% of train size (aka 41742 images) with pretrained: False and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 178 trainable: 178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/327 [..............................] - ETA: 5:16 - loss: 1.3858 - accuracy: 0.3242WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2002s vs `on_train_batch_end` time: 0.5147s). Check your callbacks.\n",
      "327/327 [==============================] - 166s 490ms/step - loss: 1.3754 - accuracy: 0.4272 - val_loss: 1.3892 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "327/327 [==============================] - 158s 482ms/step - loss: 1.3400 - accuracy: 0.4394 - val_loss: 1.3957 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "327/327 [==============================] - 157s 480ms/step - loss: 1.3152 - accuracy: 0.4420 - val_loss: 1.4033 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "327/327 [==============================] - 157s 480ms/step - loss: 1.2983 - accuracy: 0.4424 - val_loss: 1.4111 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "327/327 [==============================] - 157s 480ms/step - loss: 1.2852 - accuracy: 0.4430 - val_loss: 1.4186 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "327/327 [==============================] - 157s 480ms/step - loss: 1.2769 - accuracy: 0.4409 - val_loss: 1.4255 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "327/327 [==============================] - 157s 480ms/step - loss: 1.2712 - accuracy: 0.4393 - val_loss: 1.4318 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "327/327 [==============================] - 157s 480ms/step - loss: 1.2647 - accuracy: 0.4438 - val_loss: 1.4375 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "327/327 [==============================] - 157s 480ms/step - loss: 1.2597 - accuracy: 0.4399 - val_loss: 1.4429 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "327/327 [==============================] - 157s 480ms/step - loss: 1.2578 - accuracy: 0.4392 - val_loss: 1.4479 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "327/327 [==============================] - 157s 480ms/step - loss: 1.2560 - accuracy: 0.4383 - val_loss: 1.4530 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "327/327 [==============================] - 157s 480ms/step - loss: 1.2479 - accuracy: 0.4441 - val_loss: 1.4562 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "327/327 [==============================] - 157s 480ms/step - loss: 1.2508 - accuracy: 0.4405 - val_loss: 1.4601 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "327/327 [==============================] - 157s 480ms/step - loss: 1.2453 - accuracy: 0.4424 - val_loss: 1.4635 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "327/327 [==============================] - 157s 480ms/step - loss: 1.2472 - accuracy: 0.4410 - val_loss: 1.4666 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "327/327 [==============================] - 157s 480ms/step - loss: 1.2469 - accuracy: 0.4421 - val_loss: 1.4695 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "327/327 [==============================] - 157s 480ms/step - loss: 1.2468 - accuracy: 0.4409 - val_loss: 1.4716 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "327/327 [==============================] - 157s 480ms/step - loss: 1.2496 - accuracy: 0.4348 - val_loss: 1.4743 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "327/327 [==============================] - 157s 480ms/step - loss: 1.2431 - accuracy: 0.4412 - val_loss: 1.4765 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "327/327 [==============================] - 157s 480ms/step - loss: 1.2415 - accuracy: 0.4426 - val_loss: 1.4780 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "327/327 [==============================] - 157s 480ms/step - loss: 1.2424 - accuracy: 0.4421 - val_loss: 1.4798 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "327/327 [==============================] - 157s 480ms/step - loss: 1.2418 - accuracy: 0.4405 - val_loss: 1.4815 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "327/327 [==============================] - 157s 480ms/step - loss: 1.2418 - accuracy: 0.4414 - val_loss: 1.4829 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "327/327 [==============================] - 157s 481ms/step - loss: 1.2406 - accuracy: 0.4406 - val_loss: 1.4846 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "327/327 [==============================] - 157s 480ms/step - loss: 1.2473 - accuracy: 0.4347 - val_loss: 1.4853 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "327/327 [==============================] - 157s 481ms/step - loss: 1.2395 - accuracy: 0.4434 - val_loss: 1.4866 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "327/327 [==============================] - 157s 481ms/step - loss: 1.2355 - accuracy: 0.4454 - val_loss: 1.4872 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "327/327 [==============================] - 157s 480ms/step - loss: 1.2392 - accuracy: 0.4405 - val_loss: 1.4883 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "327/327 [==============================] - 157s 480ms/step - loss: 1.2386 - accuracy: 0.4454 - val_loss: 1.4894 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "327/327 [==============================] - 157s 481ms/step - loss: 1.2406 - accuracy: 0.4424 - val_loss: 1.4900 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_41742_images_True_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.60516816 0.59567262 0.60327811 0.5985376 ]\n",
      "Training resnet for 0.6% of train size (aka 50090 images) with pretrained: False and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 178 trainable: 178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/392 [..............................] - ETA: 6:14 - loss: 1.3850 - accuracy: 0.3685WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1984s vs `on_train_batch_end` time: 0.5024s). Check your callbacks.\n",
      "392/392 [==============================] - 199s 493ms/step - loss: 1.3726 - accuracy: 0.4317 - val_loss: 1.3905 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "392/392 [==============================] - 189s 483ms/step - loss: 1.3307 - accuracy: 0.4475 - val_loss: 1.3997 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "392/392 [==============================] - 188s 481ms/step - loss: 1.3055 - accuracy: 0.4431 - val_loss: 1.4098 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "392/392 [==============================] - 189s 481ms/step - loss: 1.2861 - accuracy: 0.4429 - val_loss: 1.4209 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "392/392 [==============================] - 188s 481ms/step - loss: 1.2725 - accuracy: 0.4463 - val_loss: 1.4325 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "392/392 [==============================] - 188s 481ms/step - loss: 1.2653 - accuracy: 0.4383 - val_loss: 1.4477 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "392/392 [==============================] - 188s 480ms/step - loss: 1.2523 - accuracy: 0.4485 - val_loss: 1.4597 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "392/392 [==============================] - 188s 481ms/step - loss: 1.2471 - accuracy: 0.4429 - val_loss: 1.4721 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "392/392 [==============================] - 189s 481ms/step - loss: 1.2474 - accuracy: 0.4361 - val_loss: 1.4805 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "392/392 [==============================] - 188s 481ms/step - loss: 1.2402 - accuracy: 0.4420 - val_loss: 1.4873 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "392/392 [==============================] - 188s 481ms/step - loss: 1.2410 - accuracy: 0.4403 - val_loss: 1.4937 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "392/392 [==============================] - 188s 481ms/step - loss: 1.2414 - accuracy: 0.4393 - val_loss: 1.4983 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "392/392 [==============================] - 188s 481ms/step - loss: 1.2357 - accuracy: 0.4432 - val_loss: 1.5026 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "392/392 [==============================] - 189s 481ms/step - loss: 1.2337 - accuracy: 0.4422 - val_loss: 1.5062 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "392/392 [==============================] - 189s 481ms/step - loss: 1.2360 - accuracy: 0.4436 - val_loss: 1.5087 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "392/392 [==============================] - 189s 481ms/step - loss: 1.2356 - accuracy: 0.4407 - val_loss: 1.5107 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "392/392 [==============================] - 188s 481ms/step - loss: 1.2355 - accuracy: 0.4415 - val_loss: 1.5128 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "392/392 [==============================] - 189s 481ms/step - loss: 1.2361 - accuracy: 0.4411 - val_loss: 1.5147 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "392/392 [==============================] - 189s 481ms/step - loss: 1.2309 - accuracy: 0.4485 - val_loss: 1.5163 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "392/392 [==============================] - 189s 482ms/step - loss: 1.2354 - accuracy: 0.4403 - val_loss: 1.5177 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "392/392 [==============================] - 189s 481ms/step - loss: 1.2342 - accuracy: 0.4415 - val_loss: 1.5186 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "392/392 [==============================] - 189s 481ms/step - loss: 1.2356 - accuracy: 0.4417 - val_loss: 1.5198 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "392/392 [==============================] - 189s 481ms/step - loss: 1.2342 - accuracy: 0.4413 - val_loss: 1.5205 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "392/392 [==============================] - 189s 481ms/step - loss: 1.2338 - accuracy: 0.4396 - val_loss: 1.5210 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "392/392 [==============================] - 189s 481ms/step - loss: 1.2339 - accuracy: 0.4409 - val_loss: 1.5220 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "392/392 [==============================] - 189s 481ms/step - loss: 1.2336 - accuracy: 0.4401 - val_loss: 1.5226 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "392/392 [==============================] - 189s 481ms/step - loss: 1.2302 - accuracy: 0.4427 - val_loss: 1.5230 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "392/392 [==============================] - 189s 481ms/step - loss: 1.2301 - accuracy: 0.4439 - val_loss: 1.5235 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "392/392 [==============================] - 189s 481ms/step - loss: 1.2344 - accuracy: 0.4391 - val_loss: 1.5240 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "392/392 [==============================] - 189s 481ms/step - loss: 1.2324 - accuracy: 0.4423 - val_loss: 1.5244 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_50090_images_True_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.75500665 0.74748018 0.75255552 0.74222377]\n",
      "Training resnet for 0.75% of train size (aka 62613 images) with pretrained: False and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 178 trainable: 178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/490 [..............................] - ETA: 7:57 - loss: 1.3847 - accuracy: 0.4538WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1990s vs `on_train_batch_end` time: 0.5123s). Check your callbacks.\n",
      "490/490 [==============================] - 247s 492ms/step - loss: 1.3682 - accuracy: 0.4435 - val_loss: 1.3938 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "490/490 [==============================] - 236s 482ms/step - loss: 1.3071 - accuracy: 0.4439 - val_loss: 1.4259 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "490/490 [==============================] - 236s 481ms/step - loss: 1.2672 - accuracy: 0.4419 - val_loss: 1.4529 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "490/490 [==============================] - 236s 481ms/step - loss: 1.2495 - accuracy: 0.4412 - val_loss: 1.4736 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "490/490 [==============================] - 236s 481ms/step - loss: 1.2431 - accuracy: 0.4428 - val_loss: 1.4890 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "490/490 [==============================] - 236s 481ms/step - loss: 1.2378 - accuracy: 0.4444 - val_loss: 1.5004 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "490/490 [==============================] - 236s 481ms/step - loss: 1.2340 - accuracy: 0.4441 - val_loss: 1.5088 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "490/490 [==============================] - 236s 481ms/step - loss: 1.2336 - accuracy: 0.4424 - val_loss: 1.5154 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "490/490 [==============================] - 236s 481ms/step - loss: 1.2299 - accuracy: 0.4457 - val_loss: 1.5206 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "490/490 [==============================] - 236s 481ms/step - loss: 1.2324 - accuracy: 0.4412 - val_loss: 1.5247 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "490/490 [==============================] - 236s 481ms/step - loss: 1.2320 - accuracy: 0.4443 - val_loss: 1.5279 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "490/490 [==============================] - 236s 481ms/step - loss: 1.2306 - accuracy: 0.4453 - val_loss: 1.5306 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "490/490 [==============================] - 236s 481ms/step - loss: 1.2319 - accuracy: 0.4433 - val_loss: 1.5327 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "490/490 [==============================] - 236s 481ms/step - loss: 1.2355 - accuracy: 0.4401 - val_loss: 1.5344 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "490/490 [==============================] - 236s 481ms/step - loss: 1.2315 - accuracy: 0.4420 - val_loss: 1.5360 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "490/490 [==============================] - 236s 481ms/step - loss: 1.2299 - accuracy: 0.4438 - val_loss: 1.5374 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "490/490 [==============================] - 236s 481ms/step - loss: 1.2305 - accuracy: 0.4412 - val_loss: 1.5385 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "490/490 [==============================] - 236s 481ms/step - loss: 1.2300 - accuracy: 0.4431 - val_loss: 1.5395 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "490/490 [==============================] - 236s 481ms/step - loss: 1.2293 - accuracy: 0.4460 - val_loss: 1.5403 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "490/490 [==============================] - 236s 481ms/step - loss: 1.2295 - accuracy: 0.4463 - val_loss: 1.5408 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "490/490 [==============================] - 236s 481ms/step - loss: 1.2242 - accuracy: 0.4494 - val_loss: 1.5416 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "490/490 [==============================] - 236s 481ms/step - loss: 1.2271 - accuracy: 0.4459 - val_loss: 1.5421 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "490/490 [==============================] - 236s 481ms/step - loss: 1.2289 - accuracy: 0.4454 - val_loss: 1.5424 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "490/490 [==============================] - 235s 481ms/step - loss: 1.2299 - accuracy: 0.4421 - val_loss: 1.5428 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "490/490 [==============================] - 236s 481ms/step - loss: 1.2313 - accuracy: 0.4446 - val_loss: 1.5431 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "490/490 [==============================] - 236s 481ms/step - loss: 1.2308 - accuracy: 0.4429 - val_loss: 1.5434 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "490/490 [==============================] - 236s 481ms/step - loss: 1.2337 - accuracy: 0.4413 - val_loss: 1.5435 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "490/490 [==============================] - 235s 481ms/step - loss: 1.2276 - accuracy: 0.4465 - val_loss: 1.5440 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "490/490 [==============================] - 235s 480ms/step - loss: 1.2278 - accuracy: 0.4481 - val_loss: 1.5442 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "490/490 [==============================] - 235s 480ms/step - loss: 1.2261 - accuracy: 0.4483 - val_loss: 1.5444 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_62613_images_True_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.90378111 0.89694933 0.90192104 0.89902507]\n",
      "Training resnet for 0.9% of train size (aka 75135 images) with pretrained: False and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 178 trainable: 178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/587 [..............................] - ETA: 9:33 - loss: 1.3856 - accuracy: 0.3526 WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2017s vs `on_train_batch_end` time: 0.5099s). Check your callbacks.\n",
      "587/587 [==============================] - 293s 488ms/step - loss: 1.3676 - accuracy: 0.4277 - val_loss: 1.3953 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "587/587 [==============================] - 283s 482ms/step - loss: 1.3099 - accuracy: 0.4442 - val_loss: 1.4174 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "587/587 [==============================] - 283s 481ms/step - loss: 1.2695 - accuracy: 0.4447 - val_loss: 1.4565 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "587/587 [==============================] - 283s 482ms/step - loss: 1.2455 - accuracy: 0.4440 - val_loss: 1.4801 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "587/587 [==============================] - 283s 481ms/step - loss: 1.2395 - accuracy: 0.4446 - val_loss: 1.4969 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "587/587 [==============================] - 282s 481ms/step - loss: 1.2355 - accuracy: 0.4439 - val_loss: 1.5088 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "587/587 [==============================] - 283s 481ms/step - loss: 1.2341 - accuracy: 0.4431 - val_loss: 1.5170 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "587/587 [==============================] - 282s 481ms/step - loss: 1.2271 - accuracy: 0.4500 - val_loss: 1.5231 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "587/587 [==============================] - 283s 481ms/step - loss: 1.2318 - accuracy: 0.4419 - val_loss: 1.5281 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "587/587 [==============================] - 283s 481ms/step - loss: 1.2330 - accuracy: 0.4444 - val_loss: 1.5317 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "587/587 [==============================] - 283s 481ms/step - loss: 1.2304 - accuracy: 0.4449 - val_loss: 1.5344 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "587/587 [==============================] - 282s 481ms/step - loss: 1.2319 - accuracy: 0.4453 - val_loss: 1.5369 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "587/587 [==============================] - 283s 481ms/step - loss: 1.2309 - accuracy: 0.4417 - val_loss: 1.5389 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "587/587 [==============================] - 283s 481ms/step - loss: 1.2308 - accuracy: 0.4432 - val_loss: 1.5400 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "587/587 [==============================] - 282s 481ms/step - loss: 1.2319 - accuracy: 0.4443 - val_loss: 1.5416 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "587/587 [==============================] - 282s 481ms/step - loss: 1.2302 - accuracy: 0.4452 - val_loss: 1.5415 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "587/587 [==============================] - 282s 481ms/step - loss: 1.2312 - accuracy: 0.4429 - val_loss: 1.5434 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "587/587 [==============================] - 283s 481ms/step - loss: 1.2342 - accuracy: 0.4406 - val_loss: 1.5431 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "587/587 [==============================] - 282s 481ms/step - loss: 1.2306 - accuracy: 0.4426 - val_loss: 1.5440 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "587/587 [==============================] - 282s 481ms/step - loss: 1.2288 - accuracy: 0.4441 - val_loss: 1.5442 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "587/587 [==============================] - 282s 481ms/step - loss: 1.2299 - accuracy: 0.4439 - val_loss: 1.5447 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "587/587 [==============================] - 283s 481ms/step - loss: 1.2313 - accuracy: 0.4434 - val_loss: 1.5447 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "587/587 [==============================] - 282s 481ms/step - loss: 1.2301 - accuracy: 0.4415 - val_loss: 1.5459 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "587/587 [==============================] - 282s 481ms/step - loss: 1.2299 - accuracy: 0.4430 - val_loss: 1.5455 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "587/587 [==============================] - 283s 481ms/step - loss: 1.2304 - accuracy: 0.4446 - val_loss: 1.5457 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "587/587 [==============================] - 282s 481ms/step - loss: 1.2277 - accuracy: 0.4471 - val_loss: 1.5450 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "587/587 [==============================] - 282s 481ms/step - loss: 1.2300 - accuracy: 0.4451 - val_loss: 1.5449 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "587/587 [==============================] - 282s 481ms/step - loss: 1.2285 - accuracy: 0.4456 - val_loss: 1.5456 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "587/587 [==============================] - 282s 481ms/step - loss: 1.2273 - accuracy: 0.4450 - val_loss: 1.5445 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "587/587 [==============================] - 282s 481ms/step - loss: 1.2295 - accuracy: 0.4441 - val_loss: 1.5451 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_75136_images_True_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [1. 1. 1. 1.]\n",
      "Training resnet for 1.0% of train size (aka 83484 images) with pretrained: False and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 178 trainable: 178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/653 [..............................] - ETA: 10:58 - loss: 1.3856 - accuracy: 0.3320WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2027s vs `on_train_batch_end` time: 0.5324s). Check your callbacks.\n",
      "653/653 [==============================] - 324s 485ms/step - loss: 1.3652 - accuracy: 0.4402 - val_loss: 1.3972 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "653/653 [==============================] - 314s 480ms/step - loss: 1.2983 - accuracy: 0.4468 - val_loss: 1.4348 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "653/653 [==============================] - 314s 481ms/step - loss: 1.2550 - accuracy: 0.4478 - val_loss: 1.4689 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "653/653 [==============================] - 314s 480ms/step - loss: 1.2417 - accuracy: 0.4454 - val_loss: 1.4915 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "653/653 [==============================] - 314s 480ms/step - loss: 1.2363 - accuracy: 0.4453 - val_loss: 1.5067 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "653/653 [==============================] - 314s 480ms/step - loss: 1.2330 - accuracy: 0.4460 - val_loss: 1.5175 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "653/653 [==============================] - 314s 480ms/step - loss: 1.2313 - accuracy: 0.4457 - val_loss: 1.5252 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "653/653 [==============================] - 314s 480ms/step - loss: 1.2304 - accuracy: 0.4471 - val_loss: 1.5303 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "653/653 [==============================] - 314s 480ms/step - loss: 1.2321 - accuracy: 0.4437 - val_loss: 1.5344 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "653/653 [==============================] - 314s 480ms/step - loss: 1.2306 - accuracy: 0.4459 - val_loss: 1.5377 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "653/653 [==============================] - 314s 480ms/step - loss: 1.2296 - accuracy: 0.4463 - val_loss: 1.5399 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "653/653 [==============================] - 314s 480ms/step - loss: 1.2285 - accuracy: 0.4478 - val_loss: 1.5418 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "653/653 [==============================] - 314s 480ms/step - loss: 1.2315 - accuracy: 0.4439 - val_loss: 1.5431 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "653/653 [==============================] - 314s 480ms/step - loss: 1.2296 - accuracy: 0.4442 - val_loss: 1.5440 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "653/653 [==============================] - 314s 480ms/step - loss: 1.2312 - accuracy: 0.4445 - val_loss: 1.5442 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "653/653 [==============================] - 314s 480ms/step - loss: 1.2298 - accuracy: 0.4457 - val_loss: 1.5444 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "653/653 [==============================] - 314s 481ms/step - loss: 1.2287 - accuracy: 0.4468 - val_loss: 1.5444 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "653/653 [==============================] - 314s 480ms/step - loss: 1.2305 - accuracy: 0.4433 - val_loss: 1.5437 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "653/653 [==============================] - 314s 481ms/step - loss: 1.2313 - accuracy: 0.4441 - val_loss: 1.5431 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "653/653 [==============================] - 314s 481ms/step - loss: 1.2292 - accuracy: 0.4451 - val_loss: 1.5413 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "653/653 [==============================] - 314s 480ms/step - loss: 1.2274 - accuracy: 0.4473 - val_loss: 1.5389 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "653/653 [==============================] - 314s 480ms/step - loss: 1.2283 - accuracy: 0.4440 - val_loss: 1.5378 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "653/653 [==============================] - 314s 480ms/step - loss: 1.2263 - accuracy: 0.4458 - val_loss: 1.5397 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "653/653 [==============================] - 314s 480ms/step - loss: 1.2274 - accuracy: 0.4474 - val_loss: 1.5391 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "653/653 [==============================] - 314s 480ms/step - loss: 1.2296 - accuracy: 0.4434 - val_loss: 1.5367 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "653/653 [==============================] - 314s 480ms/step - loss: 1.2277 - accuracy: 0.4440 - val_loss: 1.5394 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "653/653 [==============================] - 314s 480ms/step - loss: 1.2248 - accuracy: 0.4453 - val_loss: 1.5385 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "653/653 [==============================] - 314s 480ms/step - loss: 1.2271 - accuracy: 0.4438 - val_loss: 1.5349 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "653/653 [==============================] - 314s 480ms/step - loss: 1.2266 - accuracy: 0.4461 - val_loss: 1.5368 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "653/653 [==============================] - 313s 480ms/step - loss: 1.2248 - accuracy: 0.4478 - val_loss: 1.5361 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_83484_images_True_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.0100703  0.01042871 0.00845964 0.00986537]\n",
      "Training resnet for 0.01% of train size (aka 834 images) with pretrained: True and onlyLastLayersTrained: True...\n",
      "\n",
      "Total: 178 trainable: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "6/7 [========================>.....] - ETA: 0s - loss: 1.4323 - accuracy: 0.0076WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1354s vs `on_train_batch_begin` time: 0.2022s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1354s vs `on_train_batch_end` time: 0.1900s). Check your callbacks.\n",
      "7/7 [==============================] - 10s 767ms/step - loss: 1.4324 - accuracy: 0.0066 - val_loss: 1.4278 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "7/7 [==============================] - 1s 137ms/step - loss: 1.4326 - accuracy: 0.0016 - val_loss: 1.4278 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/30\n",
      "7/7 [==============================] - 1s 139ms/step - loss: 1.4327 - accuracy: 0.0027 - val_loss: 1.4278 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/30\n",
      "7/7 [==============================] - 1s 139ms/step - loss: 1.4331 - accuracy: 0.0031 - val_loss: 1.4278 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/30\n",
      "7/7 [==============================] - 1s 137ms/step - loss: 1.4332 - accuracy: 0.0012 - val_loss: 1.4278 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/30\n",
      "7/7 [==============================] - 1s 137ms/step - loss: 1.4330 - accuracy: 0.0035 - val_loss: 1.4278 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/30\n",
      "7/7 [==============================] - 1s 136ms/step - loss: 1.4327 - accuracy: 0.0042 - val_loss: 1.4278 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/30\n",
      "7/7 [==============================] - 1s 137ms/step - loss: 1.4328 - accuracy: 0.0025 - val_loss: 1.4278 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/30\n",
      "7/7 [==============================] - 1s 138ms/step - loss: 1.4328 - accuracy: 0.0018 - val_loss: 1.4278 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/30\n",
      "7/7 [==============================] - 1s 136ms/step - loss: 1.4327 - accuracy: 0.0038 - val_loss: 1.4278 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/30\n",
      "7/7 [==============================] - 1s 137ms/step - loss: 1.4330 - accuracy: 0.0023 - val_loss: 1.4278 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/30\n",
      "7/7 [==============================] - 1s 137ms/step - loss: 1.4326 - accuracy: 0.0042 - val_loss: 1.4278 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/30\n",
      "7/7 [==============================] - 1s 137ms/step - loss: 1.4330 - accuracy: 0.0056 - val_loss: 1.4278 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/30\n",
      "7/7 [==============================] - 1s 138ms/step - loss: 1.4333 - accuracy: 0.0023 - val_loss: 1.4278 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/30\n",
      "7/7 [==============================] - 1s 136ms/step - loss: 1.4330 - accuracy: 0.0028 - val_loss: 1.4278 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/30\n",
      "7/7 [==============================] - 1s 137ms/step - loss: 1.4330 - accuracy: 0.0016 - val_loss: 1.4278 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/30\n",
      "7/7 [==============================] - 1s 137ms/step - loss: 1.4325 - accuracy: 0.0040 - val_loss: 1.4278 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/30\n",
      "7/7 [==============================] - 1s 139ms/step - loss: 1.4333 - accuracy: 0.0033 - val_loss: 1.4278 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/30\n",
      "7/7 [==============================] - 1s 136ms/step - loss: 1.4325 - accuracy: 0.0038 - val_loss: 1.4278 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/30\n",
      "7/7 [==============================] - 1s 139ms/step - loss: 1.4328 - accuracy: 0.0038 - val_loss: 1.4278 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/30\n",
      "7/7 [==============================] - 1s 136ms/step - loss: 1.4324 - accuracy: 0.0038 - val_loss: 1.4278 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/30\n",
      "7/7 [==============================] - 1s 136ms/step - loss: 1.4329 - accuracy: 0.0031 - val_loss: 1.4278 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/30\n",
      "7/7 [==============================] - 1s 137ms/step - loss: 1.4329 - accuracy: 0.0022 - val_loss: 1.4278 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/30\n",
      "7/7 [==============================] - 1s 136ms/step - loss: 1.4323 - accuracy: 0.0045 - val_loss: 1.4278 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/30\n",
      "7/7 [==============================] - 1s 136ms/step - loss: 1.4324 - accuracy: 0.0061 - val_loss: 1.4278 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/30\n",
      "7/7 [==============================] - 1s 138ms/step - loss: 1.4330 - accuracy: 0.0022 - val_loss: 1.4278 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/30\n",
      "7/7 [==============================] - 1s 135ms/step - loss: 1.4330 - accuracy: 0.0048 - val_loss: 1.4278 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/30\n",
      "7/7 [==============================] - 1s 136ms/step - loss: 1.4324 - accuracy: 0.0043 - val_loss: 1.4278 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/30\n",
      "7/7 [==============================] - 1s 135ms/step - loss: 1.4328 - accuracy: 0.0051 - val_loss: 1.4278 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/30\n",
      "7/7 [==============================] - 1s 137ms/step - loss: 1.4332 - accuracy: 0.0023 - val_loss: 1.4278 - val_accuracy: 0.0000e+00\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_835_images_False_newWeights_True_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.000000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.02496675 0.02607176 0.02264716 0.02356082]\n",
      "Training resnet for 0.025% of train size (aka 2087 images) with pretrained: True and onlyLastLayersTrained: True...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total: 178 trainable: 2\n",
      "Epoch 1/30\n",
      " 6/17 [=========>....................] - ETA: 5s - loss: 1.3903 - accuracy: 0.2036WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1336s vs `on_train_batch_end` time: 0.1722s). Check your callbacks.\n",
      "17/17 [==============================] - 9s 340ms/step - loss: 1.3899 - accuracy: 0.2085 - val_loss: 1.3805 - val_accuracy: 0.4688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "17/17 [==============================] - 2s 133ms/step - loss: 1.3887 - accuracy: 0.2132 - val_loss: 1.3805 - val_accuracy: 0.4688\n",
      "Epoch 3/30\n",
      "17/17 [==============================] - 2s 132ms/step - loss: 1.3890 - accuracy: 0.2241 - val_loss: 1.3805 - val_accuracy: 0.4688\n",
      "Epoch 4/30\n",
      "17/17 [==============================] - 2s 132ms/step - loss: 1.3891 - accuracy: 0.2191 - val_loss: 1.3805 - val_accuracy: 0.4688\n",
      "Epoch 5/30\n",
      "17/17 [==============================] - 2s 133ms/step - loss: 1.3894 - accuracy: 0.2138 - val_loss: 1.3805 - val_accuracy: 0.4688\n",
      "Epoch 6/30\n",
      "17/17 [==============================] - 2s 134ms/step - loss: 1.3889 - accuracy: 0.2219 - val_loss: 1.3805 - val_accuracy: 0.4688\n",
      "Epoch 7/30\n",
      "17/17 [==============================] - 2s 133ms/step - loss: 1.3895 - accuracy: 0.2179 - val_loss: 1.3805 - val_accuracy: 0.4688\n",
      "Epoch 8/30\n",
      "17/17 [==============================] - 2s 133ms/step - loss: 1.3891 - accuracy: 0.2025 - val_loss: 1.3805 - val_accuracy: 0.4688\n",
      "Epoch 9/30\n",
      "17/17 [==============================] - 2s 133ms/step - loss: 1.3891 - accuracy: 0.2235 - val_loss: 1.3805 - val_accuracy: 0.4688\n",
      "Epoch 10/30\n",
      "17/17 [==============================] - 2s 132ms/step - loss: 1.3901 - accuracy: 0.1978 - val_loss: 1.3805 - val_accuracy: 0.4688\n",
      "Epoch 11/30\n",
      "17/17 [==============================] - 2s 134ms/step - loss: 1.3889 - accuracy: 0.2085 - val_loss: 1.3805 - val_accuracy: 0.4688\n",
      "Epoch 12/30\n",
      "17/17 [==============================] - 2s 134ms/step - loss: 1.3894 - accuracy: 0.2138 - val_loss: 1.3805 - val_accuracy: 0.4688\n",
      "Epoch 13/30\n",
      "17/17 [==============================] - 2s 133ms/step - loss: 1.3890 - accuracy: 0.2138 - val_loss: 1.3805 - val_accuracy: 0.4688\n",
      "Epoch 14/30\n",
      "17/17 [==============================] - 2s 134ms/step - loss: 1.3888 - accuracy: 0.2182 - val_loss: 1.3805 - val_accuracy: 0.4688\n",
      "Epoch 15/30\n",
      "17/17 [==============================] - 2s 134ms/step - loss: 1.3896 - accuracy: 0.2087 - val_loss: 1.3805 - val_accuracy: 0.4688\n",
      "Epoch 16/30\n",
      "17/17 [==============================] - 2s 134ms/step - loss: 1.3897 - accuracy: 0.2191 - val_loss: 1.3805 - val_accuracy: 0.4688\n",
      "Epoch 17/30\n",
      "17/17 [==============================] - 2s 134ms/step - loss: 1.3890 - accuracy: 0.2201 - val_loss: 1.3805 - val_accuracy: 0.4688\n",
      "Epoch 18/30\n",
      "17/17 [==============================] - 2s 134ms/step - loss: 1.3888 - accuracy: 0.2286 - val_loss: 1.3805 - val_accuracy: 0.4688\n",
      "Epoch 19/30\n",
      "17/17 [==============================] - 2s 134ms/step - loss: 1.3889 - accuracy: 0.2304 - val_loss: 1.3805 - val_accuracy: 0.4688\n",
      "Epoch 20/30\n",
      "17/17 [==============================] - 2s 134ms/step - loss: 1.3894 - accuracy: 0.2270 - val_loss: 1.3805 - val_accuracy: 0.4688\n",
      "Epoch 21/30\n",
      "17/17 [==============================] - 2s 134ms/step - loss: 1.3891 - accuracy: 0.2193 - val_loss: 1.3805 - val_accuracy: 0.4688\n",
      "Epoch 22/30\n",
      "17/17 [==============================] - 2s 134ms/step - loss: 1.3893 - accuracy: 0.2082 - val_loss: 1.3805 - val_accuracy: 0.4688\n",
      "Epoch 23/30\n",
      "17/17 [==============================] - 2s 134ms/step - loss: 1.3891 - accuracy: 0.2076 - val_loss: 1.3805 - val_accuracy: 0.4688\n",
      "Epoch 24/30\n",
      "17/17 [==============================] - 2s 133ms/step - loss: 1.3893 - accuracy: 0.2155 - val_loss: 1.3805 - val_accuracy: 0.4688\n",
      "Epoch 25/30\n",
      "17/17 [==============================] - 2s 134ms/step - loss: 1.3891 - accuracy: 0.2062 - val_loss: 1.3805 - val_accuracy: 0.4688\n",
      "Epoch 26/30\n",
      "17/17 [==============================] - 2s 134ms/step - loss: 1.3894 - accuracy: 0.2118 - val_loss: 1.3805 - val_accuracy: 0.4688\n",
      "Epoch 27/30\n",
      "17/17 [==============================] - 2s 135ms/step - loss: 1.3895 - accuracy: 0.2123 - val_loss: 1.3805 - val_accuracy: 0.4688\n",
      "Epoch 28/30\n",
      "17/17 [==============================] - 2s 133ms/step - loss: 1.3898 - accuracy: 0.2198 - val_loss: 1.3805 - val_accuracy: 0.4688\n",
      "Epoch 29/30\n",
      "17/17 [==============================] - 2s 135ms/step - loss: 1.3893 - accuracy: 0.2187 - val_loss: 1.3805 - val_accuracy: 0.4688\n",
      "Epoch 30/30\n",
      "17/17 [==============================] - 2s 133ms/step - loss: 1.3891 - accuracy: 0.2119 - val_loss: 1.3805 - val_accuracy: 0.4688\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_2087_images_False_newWeights_True_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.493802\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.05050352 0.04929445 0.05137469 0.04967502]\n",
      "Training resnet for 0.05% of train size (aka 4174 images) with pretrained: True and onlyLastLayersTrained: True...\n",
      "\n",
      "Total: 178 trainable: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      " 6/33 [====>.........................] - ETA: 14s - loss: 1.3872 - accuracy: 0.3072WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1339s vs `on_train_batch_begin` time: 0.1810s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1339s vs `on_train_batch_end` time: 0.1553s). Check your callbacks.\n",
      "33/33 [==============================] - 11s 244ms/step - loss: 1.3866 - accuracy: 0.3176 - val_loss: 1.3936 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "33/33 [==============================] - 4s 135ms/step - loss: 1.3865 - accuracy: 0.3214 - val_loss: 1.3936 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "33/33 [==============================] - 4s 135ms/step - loss: 1.3865 - accuracy: 0.3181 - val_loss: 1.3936 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "33/33 [==============================] - 4s 134ms/step - loss: 1.3868 - accuracy: 0.3134 - val_loss: 1.3936 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "33/33 [==============================] - 4s 136ms/step - loss: 1.3873 - accuracy: 0.3026 - val_loss: 1.3936 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "33/33 [==============================] - 4s 135ms/step - loss: 1.3866 - accuracy: 0.3210 - val_loss: 1.3936 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "33/33 [==============================] - 4s 136ms/step - loss: 1.3868 - accuracy: 0.3162 - val_loss: 1.3936 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "33/33 [==============================] - 4s 136ms/step - loss: 1.3870 - accuracy: 0.3090 - val_loss: 1.3936 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "33/33 [==============================] - 4s 136ms/step - loss: 1.3861 - accuracy: 0.3284 - val_loss: 1.3936 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "33/33 [==============================] - 4s 135ms/step - loss: 1.3871 - accuracy: 0.3056 - val_loss: 1.3936 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "33/33 [==============================] - 4s 136ms/step - loss: 1.3869 - accuracy: 0.3086 - val_loss: 1.3936 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "33/33 [==============================] - 5s 136ms/step - loss: 1.3868 - accuracy: 0.3171 - val_loss: 1.3936 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "33/33 [==============================] - 4s 135ms/step - loss: 1.3868 - accuracy: 0.3124 - val_loss: 1.3936 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "33/33 [==============================] - 4s 136ms/step - loss: 1.3866 - accuracy: 0.3198 - val_loss: 1.3936 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "33/33 [==============================] - 4s 136ms/step - loss: 1.3869 - accuracy: 0.3079 - val_loss: 1.3936 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "33/33 [==============================] - 5s 136ms/step - loss: 1.3866 - accuracy: 0.3184 - val_loss: 1.3936 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "33/33 [==============================] - 4s 136ms/step - loss: 1.3863 - accuracy: 0.3263 - val_loss: 1.3936 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "33/33 [==============================] - 4s 135ms/step - loss: 1.3861 - accuracy: 0.3310 - val_loss: 1.3936 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "33/33 [==============================] - 4s 136ms/step - loss: 1.3868 - accuracy: 0.3160 - val_loss: 1.3936 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "33/33 [==============================] - 4s 135ms/step - loss: 1.3863 - accuracy: 0.3238 - val_loss: 1.3936 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "33/33 [==============================] - 4s 136ms/step - loss: 1.3865 - accuracy: 0.3198 - val_loss: 1.3936 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "33/33 [==============================] - 4s 136ms/step - loss: 1.3870 - accuracy: 0.3098 - val_loss: 1.3936 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "33/33 [==============================] - 4s 136ms/step - loss: 1.3861 - accuracy: 0.3256 - val_loss: 1.3936 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "33/33 [==============================] - 4s 136ms/step - loss: 1.3859 - accuracy: 0.3380 - val_loss: 1.3936 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "33/33 [==============================] - 4s 135ms/step - loss: 1.3865 - accuracy: 0.3179 - val_loss: 1.3936 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "33/33 [==============================] - 4s 136ms/step - loss: 1.3862 - accuracy: 0.3255 - val_loss: 1.3936 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "33/33 [==============================] - 5s 137ms/step - loss: 1.3864 - accuracy: 0.3228 - val_loss: 1.3936 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "33/33 [==============================] - 4s 136ms/step - loss: 1.3865 - accuracy: 0.3188 - val_loss: 1.3936 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "33/33 [==============================] - 4s 136ms/step - loss: 1.3860 - accuracy: 0.3279 - val_loss: 1.3936 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "33/33 [==============================] - 4s 136ms/step - loss: 1.3863 - accuracy: 0.3236 - val_loss: 1.3936 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_4174_images_False_newWeights_True_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.07573627 0.07464051 0.07543179 0.07370009]\n",
      "Training resnet for 0.075% of train size (aka 6261 images) with pretrained: True and onlyLastLayersTrained: True...\n",
      "\n",
      "Total: 178 trainable: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      " 6/49 [==>...........................] - ETA: 23s - loss: 1.3665 - accuracy: 0.4587WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1332s vs `on_train_batch_begin` time: 0.1817s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1332s vs `on_train_batch_end` time: 0.1650s). Check your callbacks.\n",
      "49/49 [==============================] - 13s 207ms/step - loss: 1.3668 - accuracy: 0.4445 - val_loss: 1.3713 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "49/49 [==============================] - 7s 136ms/step - loss: 1.3668 - accuracy: 0.4407 - val_loss: 1.3713 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "49/49 [==============================] - 7s 136ms/step - loss: 1.3670 - accuracy: 0.4379 - val_loss: 1.3713 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "49/49 [==============================] - 7s 136ms/step - loss: 1.3668 - accuracy: 0.4410 - val_loss: 1.3713 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "49/49 [==============================] - 7s 136ms/step - loss: 1.3668 - accuracy: 0.4389 - val_loss: 1.3713 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "49/49 [==============================] - 7s 136ms/step - loss: 1.3666 - accuracy: 0.4474 - val_loss: 1.3713 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "49/49 [==============================] - 7s 137ms/step - loss: 1.3667 - accuracy: 0.4480 - val_loss: 1.3713 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "49/49 [==============================] - 7s 137ms/step - loss: 1.3672 - accuracy: 0.4353 - val_loss: 1.3713 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "49/49 [==============================] - 7s 136ms/step - loss: 1.3668 - accuracy: 0.4463 - val_loss: 1.3713 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "49/49 [==============================] - 7s 137ms/step - loss: 1.3671 - accuracy: 0.4327 - val_loss: 1.3713 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "49/49 [==============================] - 7s 136ms/step - loss: 1.3663 - accuracy: 0.4586 - val_loss: 1.3713 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "49/49 [==============================] - 7s 137ms/step - loss: 1.3664 - accuracy: 0.4474 - val_loss: 1.3713 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "49/49 [==============================] - 7s 137ms/step - loss: 1.3667 - accuracy: 0.4457 - val_loss: 1.3713 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "49/49 [==============================] - 7s 137ms/step - loss: 1.3667 - accuracy: 0.4498 - val_loss: 1.3713 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "49/49 [==============================] - 7s 137ms/step - loss: 1.3671 - accuracy: 0.4390 - val_loss: 1.3713 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "49/49 [==============================] - 7s 137ms/step - loss: 1.3671 - accuracy: 0.4342 - val_loss: 1.3713 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "49/49 [==============================] - 7s 136ms/step - loss: 1.3666 - accuracy: 0.4558 - val_loss: 1.3713 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "49/49 [==============================] - 7s 137ms/step - loss: 1.3671 - accuracy: 0.4399 - val_loss: 1.3713 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "49/49 [==============================] - 7s 137ms/step - loss: 1.3672 - accuracy: 0.4329 - val_loss: 1.3713 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "49/49 [==============================] - 7s 137ms/step - loss: 1.3668 - accuracy: 0.4431 - val_loss: 1.3713 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "49/49 [==============================] - 7s 137ms/step - loss: 1.3669 - accuracy: 0.4389 - val_loss: 1.3713 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "49/49 [==============================] - 7s 137ms/step - loss: 1.3669 - accuracy: 0.4393 - val_loss: 1.3713 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "49/49 [==============================] - 7s 137ms/step - loss: 1.3669 - accuracy: 0.4404 - val_loss: 1.3713 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "49/49 [==============================] - 7s 137ms/step - loss: 1.3671 - accuracy: 0.4341 - val_loss: 1.3713 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "49/49 [==============================] - 7s 138ms/step - loss: 1.3668 - accuracy: 0.4459 - val_loss: 1.3713 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "49/49 [==============================] - 7s 137ms/step - loss: 1.3669 - accuracy: 0.4450 - val_loss: 1.3713 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "49/49 [==============================] - 7s 137ms/step - loss: 1.3666 - accuracy: 0.4451 - val_loss: 1.3713 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "49/49 [==============================] - 7s 137ms/step - loss: 1.3672 - accuracy: 0.4300 - val_loss: 1.3713 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "49/49 [==============================] - 7s 137ms/step - loss: 1.3671 - accuracy: 0.4362 - val_loss: 1.3713 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "49/49 [==============================] - 7s 137ms/step - loss: 1.3667 - accuracy: 0.4497 - val_loss: 1.3713 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_6261_images_False_newWeights_True_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.09158275 0.08899341 0.08970744 0.08983287]\n",
      "Training resnet for 0.09% of train size (aka 7513 images) with pretrained: True and onlyLastLayersTrained: True...\n",
      "\n",
      "Total: 178 trainable: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      " 6/59 [==>...........................] - ETA: 29s - loss: 1.3901 - accuracy: 0.1315WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1332s vs `on_train_batch_begin` time: 0.1857s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1332s vs `on_train_batch_end` time: 0.1658s). Check your callbacks.\n",
      "59/59 [==============================] - 15s 195ms/step - loss: 1.3900 - accuracy: 0.1343 - val_loss: 1.3884 - val_accuracy: 0.2812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "59/59 [==============================] - 8s 135ms/step - loss: 1.3900 - accuracy: 0.1383 - val_loss: 1.3884 - val_accuracy: 0.2812\n",
      "Epoch 3/30\n",
      "59/59 [==============================] - 8s 136ms/step - loss: 1.3901 - accuracy: 0.1372 - val_loss: 1.3884 - val_accuracy: 0.2812\n",
      "Epoch 4/30\n",
      "59/59 [==============================] - 8s 136ms/step - loss: 1.3900 - accuracy: 0.1352 - val_loss: 1.3884 - val_accuracy: 0.2812\n",
      "Epoch 5/30\n",
      "59/59 [==============================] - 8s 136ms/step - loss: 1.3895 - accuracy: 0.1375 - val_loss: 1.3884 - val_accuracy: 0.2812\n",
      "Epoch 6/30\n",
      "59/59 [==============================] - 8s 137ms/step - loss: 1.3905 - accuracy: 0.1310 - val_loss: 1.3884 - val_accuracy: 0.2812\n",
      "Epoch 7/30\n",
      "59/59 [==============================] - 8s 137ms/step - loss: 1.3903 - accuracy: 0.1348 - val_loss: 1.3884 - val_accuracy: 0.2812\n",
      "Epoch 8/30\n",
      "59/59 [==============================] - 8s 137ms/step - loss: 1.3902 - accuracy: 0.1369 - val_loss: 1.3884 - val_accuracy: 0.2812\n",
      "Epoch 9/30\n",
      "59/59 [==============================] - 8s 137ms/step - loss: 1.3907 - accuracy: 0.1349 - val_loss: 1.3884 - val_accuracy: 0.2812\n",
      "Epoch 10/30\n",
      "59/59 [==============================] - 8s 137ms/step - loss: 1.3904 - accuracy: 0.1460 - val_loss: 1.3884 - val_accuracy: 0.2812\n",
      "Epoch 11/30\n",
      "59/59 [==============================] - 8s 137ms/step - loss: 1.3904 - accuracy: 0.1336 - val_loss: 1.3884 - val_accuracy: 0.2812\n",
      "Epoch 12/30\n",
      "59/59 [==============================] - 8s 137ms/step - loss: 1.3907 - accuracy: 0.1292 - val_loss: 1.3884 - val_accuracy: 0.2812\n",
      "Epoch 13/30\n",
      "59/59 [==============================] - 8s 137ms/step - loss: 1.3909 - accuracy: 0.1330 - val_loss: 1.3884 - val_accuracy: 0.2812\n",
      "Epoch 14/30\n",
      "59/59 [==============================] - 8s 137ms/step - loss: 1.3901 - accuracy: 0.1379 - val_loss: 1.3884 - val_accuracy: 0.2812\n",
      "Epoch 15/30\n",
      "59/59 [==============================] - 8s 137ms/step - loss: 1.3900 - accuracy: 0.1389 - val_loss: 1.3884 - val_accuracy: 0.2812\n",
      "Epoch 16/30\n",
      "59/59 [==============================] - 8s 137ms/step - loss: 1.3902 - accuracy: 0.1375 - val_loss: 1.3884 - val_accuracy: 0.2812\n",
      "Epoch 17/30\n",
      "59/59 [==============================] - 8s 136ms/step - loss: 1.3904 - accuracy: 0.1347 - val_loss: 1.3884 - val_accuracy: 0.2812\n",
      "Epoch 18/30\n",
      "59/59 [==============================] - 8s 137ms/step - loss: 1.3899 - accuracy: 0.1409 - val_loss: 1.3884 - val_accuracy: 0.2812\n",
      "Epoch 19/30\n",
      "59/59 [==============================] - 8s 137ms/step - loss: 1.3905 - accuracy: 0.1311 - val_loss: 1.3884 - val_accuracy: 0.2812\n",
      "Epoch 20/30\n",
      "59/59 [==============================] - 8s 137ms/step - loss: 1.3902 - accuracy: 0.1353 - val_loss: 1.3884 - val_accuracy: 0.2812\n",
      "Epoch 21/30\n",
      "59/59 [==============================] - 8s 137ms/step - loss: 1.3905 - accuracy: 0.1344 - val_loss: 1.3884 - val_accuracy: 0.2812\n",
      "Epoch 22/30\n",
      "59/59 [==============================] - 8s 137ms/step - loss: 1.3904 - accuracy: 0.1301 - val_loss: 1.3884 - val_accuracy: 0.2812\n",
      "Epoch 23/30\n",
      "59/59 [==============================] - 8s 137ms/step - loss: 1.3896 - accuracy: 0.1366 - val_loss: 1.3884 - val_accuracy: 0.2812\n",
      "Epoch 24/30\n",
      "59/59 [==============================] - 8s 137ms/step - loss: 1.3899 - accuracy: 0.1414 - val_loss: 1.3884 - val_accuracy: 0.2812\n",
      "Epoch 25/30\n",
      "59/59 [==============================] - 8s 137ms/step - loss: 1.3898 - accuracy: 0.1348 - val_loss: 1.3884 - val_accuracy: 0.2812\n",
      "Epoch 26/30\n",
      "59/59 [==============================] - 8s 137ms/step - loss: 1.3899 - accuracy: 0.1415 - val_loss: 1.3884 - val_accuracy: 0.2812\n",
      "Epoch 27/30\n",
      "59/59 [==============================] - 8s 137ms/step - loss: 1.3902 - accuracy: 0.1415 - val_loss: 1.3884 - val_accuracy: 0.2812\n",
      "Epoch 28/30\n",
      "59/59 [==============================] - 8s 137ms/step - loss: 1.3900 - accuracy: 0.1405 - val_loss: 1.3884 - val_accuracy: 0.2812\n",
      "Epoch 29/30\n",
      "59/59 [==============================] - 8s 137ms/step - loss: 1.3903 - accuracy: 0.1382 - val_loss: 1.3884 - val_accuracy: 0.2812\n",
      "Epoch 30/30\n",
      "59/59 [==============================] - 8s 137ms/step - loss: 1.3897 - accuracy: 0.1401 - val_loss: 1.3884 - val_accuracy: 0.2812\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_7514_images_False_newWeights_True_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.256198\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.10089303 0.09931461 0.10028199 0.0998143 ]\n",
      "Training resnet for 0.1% of train size (aka 8348 images) with pretrained: True and onlyLastLayersTrained: True...\n",
      "\n",
      "Total: 178 trainable: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      " 6/66 [=>............................] - ETA: 30s - loss: 1.4090 - accuracy: 0.1279WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1339s vs `on_train_batch_end` time: 0.1744s). Check your callbacks.\n",
      "66/66 [==============================] - 16s 184ms/step - loss: 1.4086 - accuracy: 0.1389 - val_loss: 1.3955 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "66/66 [==============================] - 9s 135ms/step - loss: 1.4089 - accuracy: 0.1404 - val_loss: 1.3955 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "66/66 [==============================] - 9s 135ms/step - loss: 1.4090 - accuracy: 0.1308 - val_loss: 1.3955 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "66/66 [==============================] - 9s 135ms/step - loss: 1.4079 - accuracy: 0.1427 - val_loss: 1.3955 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "66/66 [==============================] - 9s 136ms/step - loss: 1.4091 - accuracy: 0.1372 - val_loss: 1.3955 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "66/66 [==============================] - 9s 136ms/step - loss: 1.4081 - accuracy: 0.1382 - val_loss: 1.3955 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "66/66 [==============================] - 9s 135ms/step - loss: 1.4087 - accuracy: 0.1408 - val_loss: 1.3955 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "66/66 [==============================] - 9s 135ms/step - loss: 1.4088 - accuracy: 0.1368 - val_loss: 1.3955 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "66/66 [==============================] - 9s 135ms/step - loss: 1.4082 - accuracy: 0.1356 - val_loss: 1.3955 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "66/66 [==============================] - 9s 136ms/step - loss: 1.4093 - accuracy: 0.1345 - val_loss: 1.3955 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "66/66 [==============================] - 9s 136ms/step - loss: 1.4085 - accuracy: 0.1362 - val_loss: 1.3955 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "66/66 [==============================] - 9s 135ms/step - loss: 1.4083 - accuracy: 0.1437 - val_loss: 1.3955 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "66/66 [==============================] - 9s 136ms/step - loss: 1.4091 - accuracy: 0.1386 - val_loss: 1.3955 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "66/66 [==============================] - 9s 136ms/step - loss: 1.4087 - accuracy: 0.1364 - val_loss: 1.3955 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "66/66 [==============================] - 9s 136ms/step - loss: 1.4089 - accuracy: 0.1323 - val_loss: 1.3955 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "66/66 [==============================] - 9s 136ms/step - loss: 1.4086 - accuracy: 0.1397 - val_loss: 1.3955 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "66/66 [==============================] - 9s 136ms/step - loss: 1.4088 - accuracy: 0.1358 - val_loss: 1.3955 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "66/66 [==============================] - 9s 136ms/step - loss: 1.4089 - accuracy: 0.1384 - val_loss: 1.3955 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "66/66 [==============================] - 9s 135ms/step - loss: 1.4090 - accuracy: 0.1338 - val_loss: 1.3955 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "66/66 [==============================] - 9s 135ms/step - loss: 1.4094 - accuracy: 0.1375 - val_loss: 1.3955 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "66/66 [==============================] - 9s 136ms/step - loss: 1.4087 - accuracy: 0.1395 - val_loss: 1.3955 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "66/66 [==============================] - 9s 136ms/step - loss: 1.4090 - accuracy: 0.1378 - val_loss: 1.3955 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "66/66 [==============================] - 9s 136ms/step - loss: 1.4090 - accuracy: 0.1375 - val_loss: 1.3955 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "66/66 [==============================] - 9s 136ms/step - loss: 1.4090 - accuracy: 0.1360 - val_loss: 1.3955 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "66/66 [==============================] - 9s 136ms/step - loss: 1.4091 - accuracy: 0.1364 - val_loss: 1.3955 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "66/66 [==============================] - 9s 135ms/step - loss: 1.4087 - accuracy: 0.1376 - val_loss: 1.3955 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "66/66 [==============================] - 9s 136ms/step - loss: 1.4088 - accuracy: 0.1427 - val_loss: 1.3955 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "66/66 [==============================] - 9s 136ms/step - loss: 1.4089 - accuracy: 0.1361 - val_loss: 1.3955 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "66/66 [==============================] - 9s 136ms/step - loss: 1.4089 - accuracy: 0.1363 - val_loss: 1.3955 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "66/66 [==============================] - 9s 136ms/step - loss: 1.4088 - accuracy: 0.1376 - val_loss: 1.3955 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_8348_images_False_newWeights_True_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.25251758 0.24784303 0.25484667 0.24524141]\n",
      "Training resnet for 0.25% of train size (aka 20871 images) with pretrained: True and onlyLastLayersTrained: True...\n",
      "\n",
      "Total: 178 trainable: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/164 [>.............................] - ETA: 1:27 - loss: 1.3906 - accuracy: 0.4159WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1330s vs `on_train_batch_begin` time: 0.1854s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1330s vs `on_train_batch_end` time: 0.1636s). Check your callbacks.\n",
      "164/164 [==============================] - 29s 155ms/step - loss: 1.3886 - accuracy: 0.4372 - val_loss: 1.4045 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "164/164 [==============================] - 22s 135ms/step - loss: 1.3880 - accuracy: 0.4467 - val_loss: 1.4045 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "164/164 [==============================] - 22s 136ms/step - loss: 1.3884 - accuracy: 0.4403 - val_loss: 1.4045 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "164/164 [==============================] - 22s 136ms/step - loss: 1.3882 - accuracy: 0.4428 - val_loss: 1.4045 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "164/164 [==============================] - 22s 136ms/step - loss: 1.3886 - accuracy: 0.4362 - val_loss: 1.4045 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "164/164 [==============================] - 22s 136ms/step - loss: 1.3884 - accuracy: 0.4375 - val_loss: 1.4045 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "164/164 [==============================] - 22s 136ms/step - loss: 1.3880 - accuracy: 0.4477 - val_loss: 1.4045 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "164/164 [==============================] - 22s 136ms/step - loss: 1.3884 - accuracy: 0.4403 - val_loss: 1.4045 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "164/164 [==============================] - 22s 136ms/step - loss: 1.3881 - accuracy: 0.4455 - val_loss: 1.4045 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "164/164 [==============================] - 22s 136ms/step - loss: 1.3883 - accuracy: 0.4402 - val_loss: 1.4045 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "164/164 [==============================] - 22s 136ms/step - loss: 1.3886 - accuracy: 0.4382 - val_loss: 1.4045 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "164/164 [==============================] - 22s 136ms/step - loss: 1.3884 - accuracy: 0.4424 - val_loss: 1.4045 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "164/164 [==============================] - 22s 136ms/step - loss: 1.3885 - accuracy: 0.4386 - val_loss: 1.4045 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "164/164 [==============================] - 22s 136ms/step - loss: 1.3883 - accuracy: 0.4388 - val_loss: 1.4045 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "164/164 [==============================] - 22s 136ms/step - loss: 1.3887 - accuracy: 0.4336 - val_loss: 1.4045 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "164/164 [==============================] - 22s 136ms/step - loss: 1.3884 - accuracy: 0.4405 - val_loss: 1.4045 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "164/164 [==============================] - 22s 136ms/step - loss: 1.3886 - accuracy: 0.4389 - val_loss: 1.4045 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "164/164 [==============================] - 22s 137ms/step - loss: 1.3883 - accuracy: 0.4410 - val_loss: 1.4045 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "164/164 [==============================] - 22s 136ms/step - loss: 1.3886 - accuracy: 0.4375 - val_loss: 1.4045 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "164/164 [==============================] - 22s 136ms/step - loss: 1.3881 - accuracy: 0.4438 - val_loss: 1.4045 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "164/164 [==============================] - 22s 136ms/step - loss: 1.3883 - accuracy: 0.4409 - val_loss: 1.4045 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "164/164 [==============================] - 22s 136ms/step - loss: 1.3883 - accuracy: 0.4413 - val_loss: 1.4045 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "164/164 [==============================] - 22s 136ms/step - loss: 1.3887 - accuracy: 0.4364 - val_loss: 1.4045 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "164/164 [==============================] - 22s 136ms/step - loss: 1.3884 - accuracy: 0.4398 - val_loss: 1.4045 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "164/164 [==============================] - 22s 136ms/step - loss: 1.3885 - accuracy: 0.4389 - val_loss: 1.4045 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "164/164 [==============================] - 22s 136ms/step - loss: 1.3882 - accuracy: 0.4459 - val_loss: 1.4045 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "164/164 [==============================] - 22s 136ms/step - loss: 1.3881 - accuracy: 0.4481 - val_loss: 1.4045 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "164/164 [==============================] - 22s 136ms/step - loss: 1.3885 - accuracy: 0.4386 - val_loss: 1.4045 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "164/164 [==============================] - 22s 136ms/step - loss: 1.3884 - accuracy: 0.4422 - val_loss: 1.4045 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "164/164 [==============================] - 22s 136ms/step - loss: 1.3881 - accuracy: 0.4424 - val_loss: 1.4045 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_20871_images_False_newWeights_True_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.40547216 0.3980379  0.40183292 0.38927577]\n",
      "Training resnet for 0.4% of train size (aka 33393 images) with pretrained: True and onlyLastLayersTrained: True...\n",
      "\n",
      "Total: 178 trainable: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/261 [..............................] - ETA: 2:07 - loss: 1.3777 - accuracy: 0.4183WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1341s vs `on_train_batch_end` time: 0.1719s). Check your callbacks.\n",
      "261/261 [==============================] - 42s 147ms/step - loss: 1.3776 - accuracy: 0.4211 - val_loss: 1.3702 - val_accuracy: 0.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "261/261 [==============================] - 35s 136ms/step - loss: 1.3775 - accuracy: 0.4219 - val_loss: 1.3702 - val_accuracy: 0.5000\n",
      "Epoch 3/30\n",
      "261/261 [==============================] - 36s 136ms/step - loss: 1.3781 - accuracy: 0.4161 - val_loss: 1.3702 - val_accuracy: 0.5000\n",
      "Epoch 4/30\n",
      "261/261 [==============================] - 36s 137ms/step - loss: 1.3777 - accuracy: 0.4196 - val_loss: 1.3702 - val_accuracy: 0.5000\n",
      "Epoch 5/30\n",
      "261/261 [==============================] - 36s 137ms/step - loss: 1.3781 - accuracy: 0.4155 - val_loss: 1.3702 - val_accuracy: 0.5000\n",
      "Epoch 6/30\n",
      "261/261 [==============================] - 36s 137ms/step - loss: 1.3780 - accuracy: 0.4167 - val_loss: 1.3702 - val_accuracy: 0.5000\n",
      "Epoch 7/30\n",
      "261/261 [==============================] - 36s 137ms/step - loss: 1.3777 - accuracy: 0.4205 - val_loss: 1.3702 - val_accuracy: 0.5000\n",
      "Epoch 8/30\n",
      "261/261 [==============================] - 36s 137ms/step - loss: 1.3781 - accuracy: 0.4152 - val_loss: 1.3702 - val_accuracy: 0.5000\n",
      "Epoch 9/30\n",
      "261/261 [==============================] - 36s 137ms/step - loss: 1.3778 - accuracy: 0.4192 - val_loss: 1.3702 - val_accuracy: 0.5000\n",
      "Epoch 10/30\n",
      "261/261 [==============================] - 36s 137ms/step - loss: 1.3778 - accuracy: 0.4190 - val_loss: 1.3702 - val_accuracy: 0.5000\n",
      "Epoch 11/30\n",
      "261/261 [==============================] - 36s 137ms/step - loss: 1.3782 - accuracy: 0.4140 - val_loss: 1.3702 - val_accuracy: 0.5000\n",
      "Epoch 12/30\n",
      "261/261 [==============================] - 36s 137ms/step - loss: 1.3783 - accuracy: 0.4138 - val_loss: 1.3702 - val_accuracy: 0.5000\n",
      "Epoch 13/30\n",
      "261/261 [==============================] - 36s 136ms/step - loss: 1.3775 - accuracy: 0.4220 - val_loss: 1.3702 - val_accuracy: 0.5000\n",
      "Epoch 14/30\n",
      "261/261 [==============================] - 36s 137ms/step - loss: 1.3780 - accuracy: 0.4166 - val_loss: 1.3702 - val_accuracy: 0.5000\n",
      "Epoch 15/30\n",
      "261/261 [==============================] - 36s 137ms/step - loss: 1.3782 - accuracy: 0.4146 - val_loss: 1.3702 - val_accuracy: 0.5000\n",
      "Epoch 16/30\n",
      "261/261 [==============================] - 36s 137ms/step - loss: 1.3778 - accuracy: 0.4184 - val_loss: 1.3702 - val_accuracy: 0.5000\n",
      "Epoch 17/30\n",
      "261/261 [==============================] - 36s 137ms/step - loss: 1.3781 - accuracy: 0.4157 - val_loss: 1.3702 - val_accuracy: 0.5000\n",
      "Epoch 18/30\n",
      "261/261 [==============================] - 36s 136ms/step - loss: 1.3780 - accuracy: 0.4174 - val_loss: 1.3702 - val_accuracy: 0.5000\n",
      "Epoch 19/30\n",
      "261/261 [==============================] - 36s 137ms/step - loss: 1.3776 - accuracy: 0.4207 - val_loss: 1.3702 - val_accuracy: 0.5000\n",
      "Epoch 20/30\n",
      "261/261 [==============================] - 36s 137ms/step - loss: 1.3776 - accuracy: 0.4206 - val_loss: 1.3702 - val_accuracy: 0.5000\n",
      "Epoch 21/30\n",
      "261/261 [==============================] - 36s 137ms/step - loss: 1.3770 - accuracy: 0.4269 - val_loss: 1.3702 - val_accuracy: 0.5000\n",
      "Epoch 22/30\n",
      "261/261 [==============================] - 36s 137ms/step - loss: 1.3777 - accuracy: 0.4198 - val_loss: 1.3702 - val_accuracy: 0.5000\n",
      "Epoch 23/30\n",
      "261/261 [==============================] - 36s 137ms/step - loss: 1.3777 - accuracy: 0.4196 - val_loss: 1.3702 - val_accuracy: 0.5000\n",
      "Epoch 24/30\n",
      "261/261 [==============================] - 36s 136ms/step - loss: 1.3778 - accuracy: 0.4191 - val_loss: 1.3702 - val_accuracy: 0.5000\n",
      "Epoch 25/30\n",
      "261/261 [==============================] - 36s 137ms/step - loss: 1.3776 - accuracy: 0.4201 - val_loss: 1.3702 - val_accuracy: 0.5000\n",
      "Epoch 26/30\n",
      "261/261 [==============================] - 36s 137ms/step - loss: 1.3776 - accuracy: 0.4219 - val_loss: 1.3702 - val_accuracy: 0.5000\n",
      "Epoch 27/30\n",
      "261/261 [==============================] - 36s 137ms/step - loss: 1.3780 - accuracy: 0.4166 - val_loss: 1.3702 - val_accuracy: 0.5000\n",
      "Epoch 28/30\n",
      "261/261 [==============================] - 36s 137ms/step - loss: 1.3776 - accuracy: 0.4211 - val_loss: 1.3702 - val_accuracy: 0.5000\n",
      "Epoch 29/30\n",
      "261/261 [==============================] - 36s 136ms/step - loss: 1.3781 - accuracy: 0.4154 - val_loss: 1.3702 - val_accuracy: 0.5000\n",
      "Epoch 30/30\n",
      "261/261 [==============================] - 36s 136ms/step - loss: 1.3778 - accuracy: 0.4183 - val_loss: 1.3702 - val_accuracy: 0.5000\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_33394_images_False_newWeights_True_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.498967\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.5065552  0.49565919 0.50361297 0.49396472]\n",
      "Training resnet for 0.5% of train size (aka 41742 images) with pretrained: True and onlyLastLayersTrained: True...\n",
      "\n",
      "Total: 178 trainable: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/327 [..............................] - ETA: 2:56 - loss: 1.4272 - accuracy: 0.0019WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1328s vs `on_train_batch_begin` time: 0.1849s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1328s vs `on_train_batch_end` time: 0.1637s). Check your callbacks.\n",
      "327/327 [==============================] - 51s 145ms/step - loss: 1.4287 - accuracy: 0.0018 - val_loss: 1.4130 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "327/327 [==============================] - 44s 136ms/step - loss: 1.4288 - accuracy: 0.0017 - val_loss: 1.4130 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/30\n",
      "327/327 [==============================] - 44s 136ms/step - loss: 1.4289 - accuracy: 0.0018 - val_loss: 1.4130 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/30\n",
      "327/327 [==============================] - 45s 136ms/step - loss: 1.4286 - accuracy: 0.0014 - val_loss: 1.4130 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/30\n",
      "327/327 [==============================] - 45s 136ms/step - loss: 1.4286 - accuracy: 0.0016 - val_loss: 1.4130 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/30\n",
      "327/327 [==============================] - 45s 136ms/step - loss: 1.4290 - accuracy: 0.0018 - val_loss: 1.4130 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/30\n",
      "327/327 [==============================] - 45s 136ms/step - loss: 1.4289 - accuracy: 0.0018 - val_loss: 1.4130 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/30\n",
      "327/327 [==============================] - 45s 136ms/step - loss: 1.4289 - accuracy: 0.0016 - val_loss: 1.4130 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/30\n",
      "327/327 [==============================] - 45s 136ms/step - loss: 1.4288 - accuracy: 0.0018 - val_loss: 1.4130 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/30\n",
      "327/327 [==============================] - 45s 136ms/step - loss: 1.4287 - accuracy: 0.0021 - val_loss: 1.4130 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/30\n",
      "327/327 [==============================] - 45s 137ms/step - loss: 1.4288 - accuracy: 0.0020 - val_loss: 1.4130 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/30\n",
      "327/327 [==============================] - 45s 136ms/step - loss: 1.4286 - accuracy: 0.0018 - val_loss: 1.4130 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/30\n",
      "327/327 [==============================] - 45s 136ms/step - loss: 1.4286 - accuracy: 0.0019 - val_loss: 1.4130 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/30\n",
      "327/327 [==============================] - 45s 136ms/step - loss: 1.4286 - accuracy: 0.0013 - val_loss: 1.4130 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/30\n",
      "327/327 [==============================] - 45s 136ms/step - loss: 1.4287 - accuracy: 0.0017 - val_loss: 1.4130 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/30\n",
      "327/327 [==============================] - 45s 136ms/step - loss: 1.4290 - accuracy: 0.0020 - val_loss: 1.4130 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/30\n",
      "327/327 [==============================] - 45s 136ms/step - loss: 1.4289 - accuracy: 0.0018 - val_loss: 1.4130 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/30\n",
      "327/327 [==============================] - 45s 136ms/step - loss: 1.4288 - accuracy: 0.0016 - val_loss: 1.4130 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/30\n",
      "327/327 [==============================] - 45s 136ms/step - loss: 1.4287 - accuracy: 0.0018 - val_loss: 1.4130 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/30\n",
      "327/327 [==============================] - 45s 136ms/step - loss: 1.4286 - accuracy: 0.0019 - val_loss: 1.4130 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/30\n",
      "327/327 [==============================] - 45s 136ms/step - loss: 1.4289 - accuracy: 0.0017 - val_loss: 1.4130 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/30\n",
      "327/327 [==============================] - 45s 136ms/step - loss: 1.4290 - accuracy: 0.0015 - val_loss: 1.4130 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/30\n",
      "327/327 [==============================] - 45s 136ms/step - loss: 1.4288 - accuracy: 0.0016 - val_loss: 1.4130 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/30\n",
      "327/327 [==============================] - 45s 136ms/step - loss: 1.4287 - accuracy: 0.0018 - val_loss: 1.4130 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/30\n",
      "327/327 [==============================] - 44s 136ms/step - loss: 1.4288 - accuracy: 0.0018 - val_loss: 1.4130 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/30\n",
      "327/327 [==============================] - 44s 136ms/step - loss: 1.4288 - accuracy: 0.0023 - val_loss: 1.4130 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/30\n",
      "327/327 [==============================] - 45s 136ms/step - loss: 1.4286 - accuracy: 0.0018 - val_loss: 1.4130 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/30\n",
      "327/327 [==============================] - 45s 137ms/step - loss: 1.4287 - accuracy: 0.0019 - val_loss: 1.4130 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/30\n",
      "327/327 [==============================] - 45s 136ms/step - loss: 1.4290 - accuracy: 0.0018 - val_loss: 1.4130 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/30\n",
      "327/327 [==============================] - 45s 137ms/step - loss: 1.4285 - accuracy: 0.0016 - val_loss: 1.4130 - val_accuracy: 0.0000e+00\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_41742_images_False_newWeights_True_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.000000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.60516816 0.59567262 0.60327811 0.5985376 ]\n",
      "Training resnet for 0.6% of train size (aka 50090 images) with pretrained: True and onlyLastLayersTrained: True...\n",
      "\n",
      "Total: 178 trainable: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/392 [..............................] - ETA: 3:28 - loss: 1.4222 - accuracy: 0.0000e+00WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1330s vs `on_train_batch_begin` time: 0.1800s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1330s vs `on_train_batch_end` time: 0.1596s). Check your callbacks.\n",
      "392/392 [==============================] - 60s 144ms/step - loss: 1.4229 - accuracy: 6.9907e-04 - val_loss: 1.4231 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "392/392 [==============================] - 53s 136ms/step - loss: 1.4230 - accuracy: 7.8307e-04 - val_loss: 1.4231 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/30\n",
      "392/392 [==============================] - 54s 137ms/step - loss: 1.4229 - accuracy: 9.0160e-04 - val_loss: 1.4231 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/30\n",
      "392/392 [==============================] - 54s 136ms/step - loss: 1.4229 - accuracy: 9.2487e-04 - val_loss: 1.4231 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/30\n",
      "392/392 [==============================] - 53s 136ms/step - loss: 1.4231 - accuracy: 9.3110e-04 - val_loss: 1.4231 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/30\n",
      "392/392 [==============================] - 54s 137ms/step - loss: 1.4230 - accuracy: 8.2005e-04 - val_loss: 1.4231 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/30\n",
      "392/392 [==============================] - 53s 136ms/step - loss: 1.4231 - accuracy: 6.8655e-04 - val_loss: 1.4231 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/30\n",
      "392/392 [==============================] - 54s 137ms/step - loss: 1.4229 - accuracy: 0.0010 - val_loss: 1.4231 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/30\n",
      "392/392 [==============================] - 54s 137ms/step - loss: 1.4229 - accuracy: 8.8144e-04 - val_loss: 1.4231 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/30\n",
      "392/392 [==============================] - 54s 137ms/step - loss: 1.4229 - accuracy: 0.0010 - val_loss: 1.4231 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/30\n",
      "392/392 [==============================] - 54s 137ms/step - loss: 1.4229 - accuracy: 7.6438e-04 - val_loss: 1.4231 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/30\n",
      "392/392 [==============================] - 54s 137ms/step - loss: 1.4229 - accuracy: 9.0913e-04 - val_loss: 1.4231 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/30\n",
      "392/392 [==============================] - 53s 136ms/step - loss: 1.4229 - accuracy: 9.5000e-04 - val_loss: 1.4231 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/30\n",
      "392/392 [==============================] - 54s 137ms/step - loss: 1.4230 - accuracy: 9.5946e-04 - val_loss: 1.4231 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/30\n",
      "392/392 [==============================] - 54s 137ms/step - loss: 1.4230 - accuracy: 5.9953e-04 - val_loss: 1.4231 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/30\n",
      "392/392 [==============================] - 53s 136ms/step - loss: 1.4229 - accuracy: 7.9490e-04 - val_loss: 1.4231 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/30\n",
      "392/392 [==============================] - 53s 136ms/step - loss: 1.4229 - accuracy: 8.3648e-04 - val_loss: 1.4231 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/30\n",
      "392/392 [==============================] - 53s 136ms/step - loss: 1.4230 - accuracy: 7.9560e-04 - val_loss: 1.4231 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/30\n",
      "392/392 [==============================] - 53s 136ms/step - loss: 1.4229 - accuracy: 8.9908e-04 - val_loss: 1.4231 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/30\n",
      "392/392 [==============================] - 53s 136ms/step - loss: 1.4229 - accuracy: 0.0011 - val_loss: 1.4231 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/30\n",
      "392/392 [==============================] - 54s 137ms/step - loss: 1.4230 - accuracy: 0.0011 - val_loss: 1.4231 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/30\n",
      "392/392 [==============================] - 54s 137ms/step - loss: 1.4229 - accuracy: 9.3907e-04 - val_loss: 1.4231 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/30\n",
      "392/392 [==============================] - 54s 137ms/step - loss: 1.4230 - accuracy: 6.5287e-04 - val_loss: 1.4231 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/30\n",
      "392/392 [==============================] - 54s 137ms/step - loss: 1.4229 - accuracy: 7.7141e-04 - val_loss: 1.4231 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/30\n",
      "392/392 [==============================] - 54s 137ms/step - loss: 1.4230 - accuracy: 7.6690e-04 - val_loss: 1.4231 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/30\n",
      "392/392 [==============================] - 54s 136ms/step - loss: 1.4230 - accuracy: 0.0010 - val_loss: 1.4231 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/30\n",
      "392/392 [==============================] - 54s 137ms/step - loss: 1.4228 - accuracy: 9.9366e-04 - val_loss: 1.4231 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/30\n",
      "392/392 [==============================] - 54s 137ms/step - loss: 1.4229 - accuracy: 6.2713e-04 - val_loss: 1.4231 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/30\n",
      "392/392 [==============================] - 54s 137ms/step - loss: 1.4228 - accuracy: 7.8595e-04 - val_loss: 1.4231 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/30\n",
      "392/392 [==============================] - 54s 137ms/step - loss: 1.4230 - accuracy: 8.2047e-04 - val_loss: 1.4231 - val_accuracy: 0.0000e+00\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_50090_images_False_newWeights_True_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.000000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.75500665 0.74748018 0.75255552 0.74222377]\n",
      "Training resnet for 0.75% of train size (aka 62613 images) with pretrained: True and onlyLastLayersTrained: True...\n",
      "\n",
      "Total: 178 trainable: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/490 [..............................] - ETA: 4:26 - loss: 1.3573 - accuracy: 0.4785WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1331s vs `on_train_batch_begin` time: 0.1826s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1331s vs `on_train_batch_end` time: 0.1654s). Check your callbacks.\n",
      "490/490 [==============================] - 73s 142ms/step - loss: 1.3589 - accuracy: 0.4546 - val_loss: 1.3558 - val_accuracy: 0.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "490/490 [==============================] - 67s 136ms/step - loss: 1.3592 - accuracy: 0.4499 - val_loss: 1.3558 - val_accuracy: 0.5000\n",
      "Epoch 3/30\n",
      "490/490 [==============================] - 67s 136ms/step - loss: 1.3591 - accuracy: 0.4520 - val_loss: 1.3558 - val_accuracy: 0.5000\n",
      "Epoch 4/30\n",
      "490/490 [==============================] - 67s 137ms/step - loss: 1.3590 - accuracy: 0.4532 - val_loss: 1.3558 - val_accuracy: 0.5000\n",
      "Epoch 5/30\n",
      "490/490 [==============================] - 67s 136ms/step - loss: 1.3591 - accuracy: 0.4510 - val_loss: 1.3558 - val_accuracy: 0.5000\n",
      "Epoch 6/30\n",
      "490/490 [==============================] - 67s 136ms/step - loss: 1.3593 - accuracy: 0.4484 - val_loss: 1.3558 - val_accuracy: 0.5000\n",
      "Epoch 7/30\n",
      "490/490 [==============================] - 67s 136ms/step - loss: 1.3590 - accuracy: 0.4535 - val_loss: 1.3558 - val_accuracy: 0.5000\n",
      "Epoch 8/30\n",
      "490/490 [==============================] - 67s 136ms/step - loss: 1.3590 - accuracy: 0.4527 - val_loss: 1.3558 - val_accuracy: 0.5000\n",
      "Epoch 9/30\n",
      "490/490 [==============================] - 67s 136ms/step - loss: 1.3591 - accuracy: 0.4508 - val_loss: 1.3558 - val_accuracy: 0.5000\n",
      "Epoch 10/30\n",
      "490/490 [==============================] - 67s 136ms/step - loss: 1.3590 - accuracy: 0.4538 - val_loss: 1.3558 - val_accuracy: 0.5000\n",
      "Epoch 11/30\n",
      "490/490 [==============================] - 67s 136ms/step - loss: 1.3589 - accuracy: 0.4533 - val_loss: 1.3558 - val_accuracy: 0.5000\n",
      "Epoch 12/30\n",
      "490/490 [==============================] - 67s 136ms/step - loss: 1.3592 - accuracy: 0.4494 - val_loss: 1.3558 - val_accuracy: 0.5000\n",
      "Epoch 13/30\n",
      "490/490 [==============================] - 67s 136ms/step - loss: 1.3590 - accuracy: 0.4535 - val_loss: 1.3558 - val_accuracy: 0.5000\n",
      "Epoch 14/30\n",
      "490/490 [==============================] - 67s 137ms/step - loss: 1.3590 - accuracy: 0.4529 - val_loss: 1.3558 - val_accuracy: 0.5000\n",
      "Epoch 15/30\n",
      "490/490 [==============================] - 67s 137ms/step - loss: 1.3591 - accuracy: 0.4510 - val_loss: 1.3558 - val_accuracy: 0.5000\n",
      "Epoch 16/30\n",
      "490/490 [==============================] - 67s 136ms/step - loss: 1.3592 - accuracy: 0.4498 - val_loss: 1.3558 - val_accuracy: 0.5000\n",
      "Epoch 17/30\n",
      "490/490 [==============================] - 67s 136ms/step - loss: 1.3588 - accuracy: 0.4561 - val_loss: 1.3558 - val_accuracy: 0.5000\n",
      "Epoch 18/30\n",
      "490/490 [==============================] - 67s 136ms/step - loss: 1.3590 - accuracy: 0.4525 - val_loss: 1.3558 - val_accuracy: 0.5000\n",
      "Epoch 19/30\n",
      "490/490 [==============================] - 67s 136ms/step - loss: 1.3590 - accuracy: 0.4533 - val_loss: 1.3558 - val_accuracy: 0.5000\n",
      "Epoch 20/30\n",
      "490/490 [==============================] - 67s 136ms/step - loss: 1.3590 - accuracy: 0.4526 - val_loss: 1.3558 - val_accuracy: 0.5000\n",
      "Epoch 21/30\n",
      "490/490 [==============================] - 67s 136ms/step - loss: 1.3590 - accuracy: 0.4536 - val_loss: 1.3558 - val_accuracy: 0.5000\n",
      "Epoch 22/30\n",
      "490/490 [==============================] - 67s 136ms/step - loss: 1.3588 - accuracy: 0.4554 - val_loss: 1.3558 - val_accuracy: 0.5000\n",
      "Epoch 23/30\n",
      "490/490 [==============================] - 67s 136ms/step - loss: 1.3590 - accuracy: 0.4532 - val_loss: 1.3558 - val_accuracy: 0.5000\n",
      "Epoch 24/30\n",
      "490/490 [==============================] - 67s 137ms/step - loss: 1.3589 - accuracy: 0.4540 - val_loss: 1.3558 - val_accuracy: 0.5000\n",
      "Epoch 25/30\n",
      "490/490 [==============================] - 67s 136ms/step - loss: 1.3589 - accuracy: 0.4539 - val_loss: 1.3558 - val_accuracy: 0.5000\n",
      "Epoch 26/30\n",
      "490/490 [==============================] - 67s 137ms/step - loss: 1.3590 - accuracy: 0.4525 - val_loss: 1.3558 - val_accuracy: 0.5000\n",
      "Epoch 27/30\n",
      "490/490 [==============================] - 67s 136ms/step - loss: 1.3591 - accuracy: 0.4520 - val_loss: 1.3558 - val_accuracy: 0.5000\n",
      "Epoch 28/30\n",
      "490/490 [==============================] - 67s 137ms/step - loss: 1.3589 - accuracy: 0.4540 - val_loss: 1.3558 - val_accuracy: 0.5000\n",
      "Epoch 29/30\n",
      "490/490 [==============================] - 67s 136ms/step - loss: 1.3587 - accuracy: 0.4577 - val_loss: 1.3558 - val_accuracy: 0.5000\n",
      "Epoch 30/30\n",
      "490/490 [==============================] - 67s 136ms/step - loss: 1.3593 - accuracy: 0.4479 - val_loss: 1.3558 - val_accuracy: 0.5000\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_62613_images_False_newWeights_True_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.500000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.90378111 0.89694933 0.90192104 0.89902507]\n",
      "Training resnet for 0.9% of train size (aka 75135 images) with pretrained: True and onlyLastLayersTrained: True...\n",
      "\n",
      "Total: 178 trainable: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/587 [..............................] - ETA: 5:15 - loss: 1.3579 - accuracy: 0.3245WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1329s vs `on_train_batch_begin` time: 0.1503s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1329s vs `on_train_batch_end` time: 0.1924s). Check your callbacks.\n",
      "587/587 [==============================] - 88s 141ms/step - loss: 1.3582 - accuracy: 0.3169 - val_loss: 1.3617 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "587/587 [==============================] - 80s 137ms/step - loss: 1.3583 - accuracy: 0.3165 - val_loss: 1.3617 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "587/587 [==============================] - 80s 137ms/step - loss: 1.3582 - accuracy: 0.3188 - val_loss: 1.3617 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "587/587 [==============================] - 80s 137ms/step - loss: 1.3583 - accuracy: 0.3153 - val_loss: 1.3617 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "587/587 [==============================] - 80s 137ms/step - loss: 1.3583 - accuracy: 0.3164 - val_loss: 1.3617 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "587/587 [==============================] - 81s 137ms/step - loss: 1.3582 - accuracy: 0.3168 - val_loss: 1.3617 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "587/587 [==============================] - 80s 137ms/step - loss: 1.3582 - accuracy: 0.3206 - val_loss: 1.3617 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "587/587 [==============================] - 80s 137ms/step - loss: 1.3582 - accuracy: 0.3192 - val_loss: 1.3617 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "587/587 [==============================] - 80s 137ms/step - loss: 1.3582 - accuracy: 0.3210 - val_loss: 1.3617 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "587/587 [==============================] - 80s 137ms/step - loss: 1.3582 - accuracy: 0.3171 - val_loss: 1.3617 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "587/587 [==============================] - 80s 137ms/step - loss: 1.3582 - accuracy: 0.3191 - val_loss: 1.3617 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "587/587 [==============================] - 80s 137ms/step - loss: 1.3582 - accuracy: 0.3186 - val_loss: 1.3617 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "587/587 [==============================] - 80s 137ms/step - loss: 1.3582 - accuracy: 0.3171 - val_loss: 1.3617 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "587/587 [==============================] - 80s 137ms/step - loss: 1.3583 - accuracy: 0.3167 - val_loss: 1.3617 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "587/587 [==============================] - 81s 137ms/step - loss: 1.3583 - accuracy: 0.3161 - val_loss: 1.3617 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "587/587 [==============================] - 80s 137ms/step - loss: 1.3582 - accuracy: 0.3187 - val_loss: 1.3617 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "587/587 [==============================] - 80s 137ms/step - loss: 1.3583 - accuracy: 0.3156 - val_loss: 1.3617 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "587/587 [==============================] - 80s 137ms/step - loss: 1.3583 - accuracy: 0.3158 - val_loss: 1.3617 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "587/587 [==============================] - 80s 137ms/step - loss: 1.3582 - accuracy: 0.3200 - val_loss: 1.3617 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "587/587 [==============================] - 80s 137ms/step - loss: 1.3583 - accuracy: 0.3154 - val_loss: 1.3617 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "587/587 [==============================] - 80s 137ms/step - loss: 1.3583 - accuracy: 0.3153 - val_loss: 1.3617 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "587/587 [==============================] - 80s 137ms/step - loss: 1.3582 - accuracy: 0.3177 - val_loss: 1.3617 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "587/587 [==============================] - 80s 137ms/step - loss: 1.3583 - accuracy: 0.3165 - val_loss: 1.3617 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "587/587 [==============================] - 80s 137ms/step - loss: 1.3582 - accuracy: 0.3188 - val_loss: 1.3617 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "587/587 [==============================] - 80s 137ms/step - loss: 1.3583 - accuracy: 0.3158 - val_loss: 1.3617 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "587/587 [==============================] - 80s 137ms/step - loss: 1.3583 - accuracy: 0.3160 - val_loss: 1.3617 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "587/587 [==============================] - 80s 137ms/step - loss: 1.3584 - accuracy: 0.3113 - val_loss: 1.3617 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "587/587 [==============================] - 80s 137ms/step - loss: 1.3583 - accuracy: 0.3163 - val_loss: 1.3617 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "587/587 [==============================] - 80s 137ms/step - loss: 1.3582 - accuracy: 0.3172 - val_loss: 1.3617 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "587/587 [==============================] - 80s 137ms/step - loss: 1.3583 - accuracy: 0.3149 - val_loss: 1.3617 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_75136_images_False_newWeights_True_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [1. 1. 1. 1.]\n",
      "Training resnet for 1.0% of train size (aka 83484 images) with pretrained: True and onlyLastLayersTrained: True...\n",
      "\n",
      "Total: 178 trainable: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/653 [..............................] - ETA: 5:53 - loss: 1.4166 - accuracy: 0.1146WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1321s vs `on_train_batch_begin` time: 0.1787s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1321s vs `on_train_batch_end` time: 0.1670s). Check your callbacks.\n",
      "653/653 [==============================] - 96s 141ms/step - loss: 1.4153 - accuracy: 0.1051 - val_loss: 1.3972 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "653/653 [==============================] - 89s 137ms/step - loss: 1.4157 - accuracy: 0.1029 - val_loss: 1.3972 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "653/653 [==============================] - 89s 137ms/step - loss: 1.4154 - accuracy: 0.1037 - val_loss: 1.3972 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "653/653 [==============================] - 89s 137ms/step - loss: 1.4155 - accuracy: 0.1028 - val_loss: 1.3972 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "653/653 [==============================] - 89s 137ms/step - loss: 1.4148 - accuracy: 0.1053 - val_loss: 1.3972 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "653/653 [==============================] - 89s 137ms/step - loss: 1.4154 - accuracy: 0.1028 - val_loss: 1.3972 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "653/653 [==============================] - 89s 137ms/step - loss: 1.4155 - accuracy: 0.1023 - val_loss: 1.3972 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "653/653 [==============================] - 89s 137ms/step - loss: 1.4153 - accuracy: 0.1048 - val_loss: 1.3972 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "653/653 [==============================] - 89s 137ms/step - loss: 1.4153 - accuracy: 0.1041 - val_loss: 1.3972 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "653/653 [==============================] - 89s 137ms/step - loss: 1.4154 - accuracy: 0.1033 - val_loss: 1.3972 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "653/653 [==============================] - 89s 137ms/step - loss: 1.4157 - accuracy: 0.1029 - val_loss: 1.3972 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "653/653 [==============================] - 89s 137ms/step - loss: 1.4151 - accuracy: 0.1025 - val_loss: 1.3972 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "653/653 [==============================] - 89s 137ms/step - loss: 1.4154 - accuracy: 0.1049 - val_loss: 1.3972 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "653/653 [==============================] - 89s 137ms/step - loss: 1.4153 - accuracy: 0.1056 - val_loss: 1.3972 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "653/653 [==============================] - 89s 137ms/step - loss: 1.4151 - accuracy: 0.1039 - val_loss: 1.3972 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "653/653 [==============================] - 89s 137ms/step - loss: 1.4153 - accuracy: 0.1046 - val_loss: 1.3972 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "653/653 [==============================] - 89s 137ms/step - loss: 1.4154 - accuracy: 0.1041 - val_loss: 1.3972 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "653/653 [==============================] - 89s 137ms/step - loss: 1.4154 - accuracy: 0.1028 - val_loss: 1.3972 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "653/653 [==============================] - 90s 137ms/step - loss: 1.4153 - accuracy: 0.1036 - val_loss: 1.3972 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "653/653 [==============================] - 89s 137ms/step - loss: 1.4155 - accuracy: 0.1040 - val_loss: 1.3972 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "653/653 [==============================] - 89s 137ms/step - loss: 1.4154 - accuracy: 0.1030 - val_loss: 1.3972 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "653/653 [==============================] - 89s 137ms/step - loss: 1.4152 - accuracy: 0.1046 - val_loss: 1.3972 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "653/653 [==============================] - 89s 137ms/step - loss: 1.4157 - accuracy: 0.1027 - val_loss: 1.3972 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "653/653 [==============================] - 89s 137ms/step - loss: 1.4156 - accuracy: 0.1035 - val_loss: 1.3972 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "653/653 [==============================] - 89s 137ms/step - loss: 1.4150 - accuracy: 0.1062 - val_loss: 1.3972 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "653/653 [==============================] - 89s 137ms/step - loss: 1.4154 - accuracy: 0.1042 - val_loss: 1.3972 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "653/653 [==============================] - 89s 137ms/step - loss: 1.4152 - accuracy: 0.1036 - val_loss: 1.3972 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "653/653 [==============================] - 89s 137ms/step - loss: 1.4153 - accuracy: 0.1042 - val_loss: 1.3972 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "653/653 [==============================] - 89s 137ms/step - loss: 1.4153 - accuracy: 0.1026 - val_loss: 1.3972 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "653/653 [==============================] - 89s 137ms/step - loss: 1.4155 - accuracy: 0.1027 - val_loss: 1.3972 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_83484_images_False_newWeights_True_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.0100703  0.01042871 0.00845964 0.00986537]\n",
      "Training resnet for 0.01% of train size (aka 834 images) with pretrained: True and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 178 trainable: 178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "6/7 [========================>.....] - ETA: 0s - loss: 1.4323 - accuracy: 0.0959WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1995s vs `on_train_batch_end` time: 0.5176s). Check your callbacks.\n",
      "7/7 [==============================] - 14s 1s/step - loss: 1.4317 - accuracy: 0.0974 - val_loss: 1.4005 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "7/7 [==============================] - 3s 443ms/step - loss: 1.4256 - accuracy: 0.1047 - val_loss: 1.3984 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "7/7 [==============================] - 3s 444ms/step - loss: 1.4235 - accuracy: 0.0972 - val_loss: 1.3964 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "7/7 [==============================] - 3s 444ms/step - loss: 1.4189 - accuracy: 0.1017 - val_loss: 1.3947 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "7/7 [==============================] - 3s 446ms/step - loss: 1.4146 - accuracy: 0.1004 - val_loss: 1.3931 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "7/7 [==============================] - 3s 446ms/step - loss: 1.4118 - accuracy: 0.1114 - val_loss: 1.3917 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "7/7 [==============================] - 3s 445ms/step - loss: 1.4094 - accuracy: 0.1085 - val_loss: 1.3904 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "7/7 [==============================] - 3s 445ms/step - loss: 1.4079 - accuracy: 0.0936 - val_loss: 1.3893 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "7/7 [==============================] - 3s 446ms/step - loss: 1.4054 - accuracy: 0.1043 - val_loss: 1.3883 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "7/7 [==============================] - 3s 446ms/step - loss: 1.4033 - accuracy: 0.1076 - val_loss: 1.3874 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "7/7 [==============================] - 3s 447ms/step - loss: 1.4018 - accuracy: 0.1012 - val_loss: 1.3866 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "7/7 [==============================] - 3s 446ms/step - loss: 1.4018 - accuracy: 0.0849 - val_loss: 1.3858 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "7/7 [==============================] - 3s 447ms/step - loss: 1.3990 - accuracy: 0.0986 - val_loss: 1.3852 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "7/7 [==============================] - 3s 446ms/step - loss: 1.3979 - accuracy: 0.1016 - val_loss: 1.3846 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "7/7 [==============================] - 3s 448ms/step - loss: 1.3965 - accuracy: 0.1059 - val_loss: 1.3840 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "7/7 [==============================] - 3s 448ms/step - loss: 1.3952 - accuracy: 0.1050 - val_loss: 1.3836 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "7/7 [==============================] - 3s 448ms/step - loss: 1.3948 - accuracy: 0.1055 - val_loss: 1.3831 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "7/7 [==============================] - 3s 449ms/step - loss: 1.3939 - accuracy: 0.1107 - val_loss: 1.3827 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "7/7 [==============================] - 3s 448ms/step - loss: 1.3929 - accuracy: 0.1111 - val_loss: 1.3824 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "7/7 [==============================] - 3s 447ms/step - loss: 1.3922 - accuracy: 0.1068 - val_loss: 1.3821 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "7/7 [==============================] - 3s 447ms/step - loss: 1.3919 - accuracy: 0.1026 - val_loss: 1.3818 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "7/7 [==============================] - 3s 447ms/step - loss: 1.3918 - accuracy: 0.0996 - val_loss: 1.3815 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "7/7 [==============================] - 3s 448ms/step - loss: 1.3916 - accuracy: 0.0919 - val_loss: 1.3813 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "7/7 [==============================] - 3s 447ms/step - loss: 1.3911 - accuracy: 0.0950 - val_loss: 1.3811 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "7/7 [==============================] - 3s 447ms/step - loss: 1.3908 - accuracy: 0.1008 - val_loss: 1.3809 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "7/7 [==============================] - 3s 449ms/step - loss: 1.3904 - accuracy: 0.0941 - val_loss: 1.3808 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "7/7 [==============================] - 3s 451ms/step - loss: 1.3898 - accuracy: 0.1024 - val_loss: 1.3806 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "7/7 [==============================] - 3s 449ms/step - loss: 1.3901 - accuracy: 0.0871 - val_loss: 1.3805 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "7/7 [==============================] - 3s 448ms/step - loss: 1.3888 - accuracy: 0.1081 - val_loss: 1.3804 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "7/7 [==============================] - 3s 456ms/step - loss: 1.3895 - accuracy: 0.0910 - val_loss: 1.3802 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_835_images_False_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.02496675 0.02607176 0.02264716 0.02356082]\n",
      "Training resnet for 0.025% of train size (aka 2087 images) with pretrained: True and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 178 trainable: 178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      " 6/17 [=========>....................] - ETA: 10s - loss: 1.4306 - accuracy: 0.0000e+00WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1995s vs `on_train_batch_end` time: 0.5192s). Check your callbacks.\n",
      "17/17 [==============================] - 18s 705ms/step - loss: 1.4301 - accuracy: 4.8125e-04 - val_loss: 1.4158 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "17/17 [==============================] - 8s 453ms/step - loss: 1.4210 - accuracy: 0.0020 - val_loss: 1.4106 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/30\n",
      "17/17 [==============================] - 8s 455ms/step - loss: 1.4114 - accuracy: 2.5406e-04 - val_loss: 1.4060 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/30\n",
      "17/17 [==============================] - 8s 456ms/step - loss: 1.4021 - accuracy: 0.0010 - val_loss: 1.4018 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/30\n",
      "17/17 [==============================] - 8s 457ms/step - loss: 1.3962 - accuracy: 0.0015 - val_loss: 1.3981 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/30\n",
      "17/17 [==============================] - 8s 458ms/step - loss: 1.3890 - accuracy: 0.2086 - val_loss: 1.3948 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "17/17 [==============================] - 8s 458ms/step - loss: 1.3823 - accuracy: 0.4721 - val_loss: 1.3919 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "17/17 [==============================] - 8s 458ms/step - loss: 1.3772 - accuracy: 0.4686 - val_loss: 1.3892 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "17/17 [==============================] - 8s 458ms/step - loss: 1.3726 - accuracy: 0.4656 - val_loss: 1.3869 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "17/17 [==============================] - 8s 458ms/step - loss: 1.3687 - accuracy: 0.4614 - val_loss: 1.3847 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "17/17 [==============================] - 8s 459ms/step - loss: 1.3645 - accuracy: 0.4652 - val_loss: 1.3828 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "17/17 [==============================] - 8s 458ms/step - loss: 1.3603 - accuracy: 0.4747 - val_loss: 1.3811 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "17/17 [==============================] - 8s 459ms/step - loss: 1.3585 - accuracy: 0.4614 - val_loss: 1.3796 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "17/17 [==============================] - 8s 460ms/step - loss: 1.3562 - accuracy: 0.4580 - val_loss: 1.3782 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "17/17 [==============================] - 8s 460ms/step - loss: 1.3539 - accuracy: 0.4581 - val_loss: 1.3770 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "17/17 [==============================] - 8s 460ms/step - loss: 1.3517 - accuracy: 0.4562 - val_loss: 1.3759 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "17/17 [==============================] - 8s 459ms/step - loss: 1.3501 - accuracy: 0.4545 - val_loss: 1.3749 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "17/17 [==============================] - 8s 459ms/step - loss: 1.3455 - accuracy: 0.4798 - val_loss: 1.3740 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "17/17 [==============================] - 8s 460ms/step - loss: 1.3456 - accuracy: 0.4603 - val_loss: 1.3732 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "17/17 [==============================] - 8s 461ms/step - loss: 1.3446 - accuracy: 0.4615 - val_loss: 1.3725 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "17/17 [==============================] - 8s 460ms/step - loss: 1.3439 - accuracy: 0.4566 - val_loss: 1.3719 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "17/17 [==============================] - 8s 459ms/step - loss: 1.3410 - accuracy: 0.4721 - val_loss: 1.3713 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "17/17 [==============================] - 8s 460ms/step - loss: 1.3403 - accuracy: 0.4676 - val_loss: 1.3708 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "17/17 [==============================] - 8s 460ms/step - loss: 1.3412 - accuracy: 0.4511 - val_loss: 1.3703 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "17/17 [==============================] - 8s 460ms/step - loss: 1.3403 - accuracy: 0.4509 - val_loss: 1.3699 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "17/17 [==============================] - 8s 460ms/step - loss: 1.3378 - accuracy: 0.4673 - val_loss: 1.3695 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "17/17 [==============================] - 8s 459ms/step - loss: 1.3377 - accuracy: 0.4618 - val_loss: 1.3691 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "17/17 [==============================] - 8s 460ms/step - loss: 1.3373 - accuracy: 0.4630 - val_loss: 1.3688 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "17/17 [==============================] - 8s 459ms/step - loss: 1.3382 - accuracy: 0.4561 - val_loss: 1.3686 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "17/17 [==============================] - 8s 460ms/step - loss: 1.3346 - accuracy: 0.4728 - val_loss: 1.3683 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_2087_images_False_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.05050352 0.04929445 0.05137469 0.04967502]\n",
      "Training resnet for 0.05% of train size (aka 4174 images) with pretrained: True and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 178 trainable: 178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      " 6/33 [====>.........................] - ETA: 27s - loss: 1.3796 - accuracy: 0.0000e+00WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2014s vs `on_train_batch_end` time: 0.5421s). Check your callbacks.\n",
      "33/33 [==============================] - 27s 596ms/step - loss: 1.3759 - accuracy: 0.1589 - val_loss: 1.3780 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "33/33 [==============================] - 15s 469ms/step - loss: 1.3581 - accuracy: 0.4449 - val_loss: 1.3686 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "33/33 [==============================] - 16s 470ms/step - loss: 1.3425 - accuracy: 0.4401 - val_loss: 1.3602 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "33/33 [==============================] - 16s 472ms/step - loss: 1.3292 - accuracy: 0.5306 - val_loss: 1.3527 - val_accuracy: 0.5000\n",
      "Epoch 5/30\n",
      "33/33 [==============================] - 16s 472ms/step - loss: 1.3157 - accuracy: 0.7646 - val_loss: 1.3462 - val_accuracy: 0.5000\n",
      "Epoch 6/30\n",
      "33/33 [==============================] - 16s 473ms/step - loss: 1.3052 - accuracy: 0.7624 - val_loss: 1.3403 - val_accuracy: 0.5000\n",
      "Epoch 7/30\n",
      "33/33 [==============================] - 16s 473ms/step - loss: 1.2974 - accuracy: 0.7482 - val_loss: 1.3351 - val_accuracy: 0.5000\n",
      "Epoch 8/30\n",
      "33/33 [==============================] - 16s 473ms/step - loss: 1.2879 - accuracy: 0.7494 - val_loss: 1.3304 - val_accuracy: 0.5000\n",
      "Epoch 9/30\n",
      "33/33 [==============================] - 16s 474ms/step - loss: 1.2804 - accuracy: 0.7991 - val_loss: 1.3263 - val_accuracy: 0.7500\n",
      "Epoch 10/30\n",
      "33/33 [==============================] - 16s 474ms/step - loss: 1.2712 - accuracy: 0.8972 - val_loss: 1.3226 - val_accuracy: 0.7500\n",
      "Epoch 11/30\n",
      "33/33 [==============================] - 16s 474ms/step - loss: 1.2682 - accuracy: 0.8904 - val_loss: 1.3193 - val_accuracy: 0.7500\n",
      "Epoch 12/30\n",
      "33/33 [==============================] - 16s 474ms/step - loss: 1.2620 - accuracy: 0.8977 - val_loss: 1.3163 - val_accuracy: 0.7500\n",
      "Epoch 13/30\n",
      "33/33 [==============================] - 16s 473ms/step - loss: 1.2566 - accuracy: 0.8931 - val_loss: 1.3137 - val_accuracy: 0.7500\n",
      "Epoch 14/30\n",
      "33/33 [==============================] - 16s 473ms/step - loss: 1.2506 - accuracy: 0.8973 - val_loss: 1.3113 - val_accuracy: 0.7500\n",
      "Epoch 15/30\n",
      "33/33 [==============================] - 16s 474ms/step - loss: 1.2514 - accuracy: 0.8849 - val_loss: 1.3092 - val_accuracy: 0.7500\n",
      "Epoch 16/30\n",
      "33/33 [==============================] - 16s 474ms/step - loss: 1.2461 - accuracy: 0.8933 - val_loss: 1.3073 - val_accuracy: 0.7500\n",
      "Epoch 17/30\n",
      "33/33 [==============================] - 16s 473ms/step - loss: 1.2411 - accuracy: 0.8933 - val_loss: 1.3056 - val_accuracy: 0.7500\n",
      "Epoch 18/30\n",
      "33/33 [==============================] - 16s 474ms/step - loss: 1.2395 - accuracy: 0.8931 - val_loss: 1.3041 - val_accuracy: 0.7500\n",
      "Epoch 19/30\n",
      "33/33 [==============================] - 16s 474ms/step - loss: 1.2356 - accuracy: 0.8931 - val_loss: 1.3027 - val_accuracy: 0.7500\n",
      "Epoch 20/30\n",
      "33/33 [==============================] - 16s 473ms/step - loss: 1.2362 - accuracy: 0.8869 - val_loss: 1.3015 - val_accuracy: 0.7500\n",
      "Epoch 21/30\n",
      "33/33 [==============================] - 16s 474ms/step - loss: 1.2340 - accuracy: 0.8925 - val_loss: 1.3004 - val_accuracy: 0.7500\n",
      "Epoch 22/30\n",
      "33/33 [==============================] - 16s 473ms/step - loss: 1.2315 - accuracy: 0.8918 - val_loss: 1.2994 - val_accuracy: 0.7500\n",
      "Epoch 23/30\n",
      "33/33 [==============================] - 16s 474ms/step - loss: 1.2282 - accuracy: 0.8901 - val_loss: 1.2985 - val_accuracy: 0.7500\n",
      "Epoch 24/30\n",
      "33/33 [==============================] - 16s 473ms/step - loss: 1.2267 - accuracy: 0.8910 - val_loss: 1.2977 - val_accuracy: 0.7500\n",
      "Epoch 25/30\n",
      "33/33 [==============================] - 16s 473ms/step - loss: 1.2269 - accuracy: 0.8813 - val_loss: 1.2969 - val_accuracy: 0.7500\n",
      "Epoch 26/30\n",
      "33/33 [==============================] - 16s 473ms/step - loss: 1.2262 - accuracy: 0.8842 - val_loss: 1.2963 - val_accuracy: 0.7500\n",
      "Epoch 27/30\n",
      "33/33 [==============================] - 16s 473ms/step - loss: 1.2239 - accuracy: 0.8845 - val_loss: 1.2957 - val_accuracy: 0.7500\n",
      "Epoch 28/30\n",
      "33/33 [==============================] - 16s 473ms/step - loss: 1.2229 - accuracy: 0.8901 - val_loss: 1.2952 - val_accuracy: 0.7500\n",
      "Epoch 29/30\n",
      "33/33 [==============================] - 16s 474ms/step - loss: 1.2216 - accuracy: 0.8867 - val_loss: 1.2947 - val_accuracy: 0.7500\n",
      "Epoch 30/30\n",
      "33/33 [==============================] - 16s 474ms/step - loss: 1.2228 - accuracy: 0.8815 - val_loss: 1.2943 - val_accuracy: 0.7500\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_4174_images_False_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.743802\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.07573627 0.07464051 0.07543179 0.07370009]\n",
      "Training resnet for 0.075% of train size (aka 6261 images) with pretrained: True and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 178 trainable: 178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      " 6/49 [==>...........................] - ETA: 42s - loss: 1.3929 - accuracy: 0.1224WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2017s vs `on_train_batch_end` time: 0.5219s). Check your callbacks.\n",
      "49/49 [==============================] - 33s 555ms/step - loss: 1.3872 - accuracy: 0.1352 - val_loss: 1.3811 - val_accuracy: 0.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "49/49 [==============================] - 23s 474ms/step - loss: 1.3613 - accuracy: 0.4795 - val_loss: 1.3674 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "49/49 [==============================] - 23s 477ms/step - loss: 1.3379 - accuracy: 0.4357 - val_loss: 1.3553 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "49/49 [==============================] - 23s 477ms/step - loss: 1.3175 - accuracy: 0.4439 - val_loss: 1.3447 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "49/49 [==============================] - 23s 478ms/step - loss: 1.2989 - accuracy: 0.4557 - val_loss: 1.3353 - val_accuracy: 0.5000\n",
      "Epoch 6/30\n",
      "49/49 [==============================] - 23s 479ms/step - loss: 1.2829 - accuracy: 0.7665 - val_loss: 1.3270 - val_accuracy: 0.5000\n",
      "Epoch 7/30\n",
      "49/49 [==============================] - 23s 477ms/step - loss: 1.2712 - accuracy: 0.7569 - val_loss: 1.3197 - val_accuracy: 0.5000\n",
      "Epoch 8/30\n",
      "49/49 [==============================] - 23s 478ms/step - loss: 1.2584 - accuracy: 0.7625 - val_loss: 1.3132 - val_accuracy: 0.5000\n",
      "Epoch 9/30\n",
      "49/49 [==============================] - 23s 478ms/step - loss: 1.2474 - accuracy: 0.7591 - val_loss: 1.3074 - val_accuracy: 0.5000\n",
      "Epoch 10/30\n",
      "49/49 [==============================] - 23s 478ms/step - loss: 1.2370 - accuracy: 0.7667 - val_loss: 1.3022 - val_accuracy: 0.5000\n",
      "Epoch 11/30\n",
      "49/49 [==============================] - 23s 478ms/step - loss: 1.2305 - accuracy: 0.7624 - val_loss: 1.2976 - val_accuracy: 0.5000\n",
      "Epoch 12/30\n",
      "49/49 [==============================] - 23s 478ms/step - loss: 1.2235 - accuracy: 0.7556 - val_loss: 1.2935 - val_accuracy: 0.5000\n",
      "Epoch 13/30\n",
      "49/49 [==============================] - 23s 478ms/step - loss: 1.2142 - accuracy: 0.7618 - val_loss: 1.2898 - val_accuracy: 0.5000\n",
      "Epoch 14/30\n",
      "49/49 [==============================] - 23s 478ms/step - loss: 1.2098 - accuracy: 0.7573 - val_loss: 1.2866 - val_accuracy: 0.5000\n",
      "Epoch 15/30\n",
      "49/49 [==============================] - 23s 478ms/step - loss: 1.2045 - accuracy: 0.7579 - val_loss: 1.2836 - val_accuracy: 0.5000\n",
      "Epoch 16/30\n",
      "49/49 [==============================] - 23s 478ms/step - loss: 1.2006 - accuracy: 0.7617 - val_loss: 1.2810 - val_accuracy: 0.5000\n",
      "Epoch 17/30\n",
      "49/49 [==============================] - 23s 478ms/step - loss: 1.1979 - accuracy: 0.7509 - val_loss: 1.2787 - val_accuracy: 0.5000\n",
      "Epoch 18/30\n",
      "49/49 [==============================] - 23s 478ms/step - loss: 1.1899 - accuracy: 0.7643 - val_loss: 1.2766 - val_accuracy: 0.5000\n",
      "Epoch 19/30\n",
      "49/49 [==============================] - 23s 478ms/step - loss: 1.1876 - accuracy: 0.7632 - val_loss: 1.2747 - val_accuracy: 0.5000\n",
      "Epoch 20/30\n",
      "49/49 [==============================] - 23s 479ms/step - loss: 1.1863 - accuracy: 0.7587 - val_loss: 1.2730 - val_accuracy: 0.5000\n",
      "Epoch 21/30\n",
      "49/49 [==============================] - 23s 478ms/step - loss: 1.1836 - accuracy: 0.7612 - val_loss: 1.2715 - val_accuracy: 0.5000\n",
      "Epoch 22/30\n",
      "49/49 [==============================] - 23s 478ms/step - loss: 1.1819 - accuracy: 0.7593 - val_loss: 1.2701 - val_accuracy: 0.5000\n",
      "Epoch 23/30\n",
      "49/49 [==============================] - 23s 478ms/step - loss: 1.1774 - accuracy: 0.7619 - val_loss: 1.2689 - val_accuracy: 0.5000\n",
      "Epoch 24/30\n",
      "49/49 [==============================] - 23s 478ms/step - loss: 1.1768 - accuracy: 0.7560 - val_loss: 1.2678 - val_accuracy: 0.5000\n",
      "Epoch 25/30\n",
      "49/49 [==============================] - 23s 478ms/step - loss: 1.1725 - accuracy: 0.7654 - val_loss: 1.2668 - val_accuracy: 0.5000\n",
      "Epoch 26/30\n",
      "49/49 [==============================] - 23s 478ms/step - loss: 1.1742 - accuracy: 0.7541 - val_loss: 1.2660 - val_accuracy: 0.5000\n",
      "Epoch 27/30\n",
      "49/49 [==============================] - 23s 478ms/step - loss: 1.1721 - accuracy: 0.7574 - val_loss: 1.2652 - val_accuracy: 0.5000\n",
      "Epoch 28/30\n",
      "49/49 [==============================] - 23s 478ms/step - loss: 1.1704 - accuracy: 0.7634 - val_loss: 1.2644 - val_accuracy: 0.5000\n",
      "Epoch 29/30\n",
      "49/49 [==============================] - 23s 478ms/step - loss: 1.1675 - accuracy: 0.7647 - val_loss: 1.2638 - val_accuracy: 0.5000\n",
      "Epoch 30/30\n",
      "49/49 [==============================] - 23s 478ms/step - loss: 1.1734 - accuracy: 0.7460 - val_loss: 1.2632 - val_accuracy: 0.5000\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_6261_images_False_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.500000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.09158275 0.08899341 0.08970744 0.08983287]\n",
      "Training resnet for 0.09% of train size (aka 7513 images) with pretrained: True and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 178 trainable: 178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      " 6/59 [==>...........................] - ETA: 53s - loss: 1.3767 - accuracy: 0.4505 WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2005s vs `on_train_batch_end` time: 0.5232s). Check your callbacks.\n",
      "59/59 [==============================] - 38s 542ms/step - loss: 1.3687 - accuracy: 0.5329 - val_loss: 1.3502 - val_accuracy: 0.9688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "59/59 [==============================] - 28s 474ms/step - loss: 1.3364 - accuracy: 0.9570 - val_loss: 1.3336 - val_accuracy: 0.7500\n",
      "Epoch 3/30\n",
      "59/59 [==============================] - 28s 476ms/step - loss: 1.3093 - accuracy: 0.8936 - val_loss: 1.3191 - val_accuracy: 0.7500\n",
      "Epoch 4/30\n",
      "59/59 [==============================] - 28s 476ms/step - loss: 1.2852 - accuracy: 0.8919 - val_loss: 1.3064 - val_accuracy: 0.7500\n",
      "Epoch 5/30\n",
      "59/59 [==============================] - 28s 477ms/step - loss: 1.2635 - accuracy: 0.8939 - val_loss: 1.2953 - val_accuracy: 0.7500\n",
      "Epoch 6/30\n",
      "59/59 [==============================] - 28s 477ms/step - loss: 1.2446 - accuracy: 0.8925 - val_loss: 1.2855 - val_accuracy: 0.7500\n",
      "Epoch 7/30\n",
      "59/59 [==============================] - 28s 476ms/step - loss: 1.2289 - accuracy: 0.8904 - val_loss: 1.2769 - val_accuracy: 0.7500\n",
      "Epoch 8/30\n",
      "59/59 [==============================] - 28s 476ms/step - loss: 1.2138 - accuracy: 0.8930 - val_loss: 1.2692 - val_accuracy: 0.5000\n",
      "Epoch 9/30\n",
      "59/59 [==============================] - 28s 476ms/step - loss: 1.2030 - accuracy: 0.7593 - val_loss: 1.2625 - val_accuracy: 0.5000\n",
      "Epoch 10/30\n",
      "59/59 [==============================] - 28s 477ms/step - loss: 1.1910 - accuracy: 0.7611 - val_loss: 1.2565 - val_accuracy: 0.5000\n",
      "Epoch 11/30\n",
      "59/59 [==============================] - 28s 476ms/step - loss: 1.1819 - accuracy: 0.7593 - val_loss: 1.2511 - val_accuracy: 0.5000\n",
      "Epoch 12/30\n",
      "59/59 [==============================] - 28s 476ms/step - loss: 1.1736 - accuracy: 0.7574 - val_loss: 1.2464 - val_accuracy: 0.5000\n",
      "Epoch 13/30\n",
      "59/59 [==============================] - 28s 477ms/step - loss: 1.1665 - accuracy: 0.7595 - val_loss: 1.2422 - val_accuracy: 0.5000\n",
      "Epoch 14/30\n",
      "59/59 [==============================] - 28s 477ms/step - loss: 1.1595 - accuracy: 0.7564 - val_loss: 1.2384 - val_accuracy: 0.5000\n",
      "Epoch 15/30\n",
      "59/59 [==============================] - 28s 478ms/step - loss: 1.1525 - accuracy: 0.7594 - val_loss: 1.2350 - val_accuracy: 0.5000\n",
      "Epoch 16/30\n",
      "59/59 [==============================] - 28s 476ms/step - loss: 1.1458 - accuracy: 0.7628 - val_loss: 1.2320 - val_accuracy: 0.5000\n",
      "Epoch 17/30\n",
      "59/59 [==============================] - 28s 476ms/step - loss: 1.1418 - accuracy: 0.7627 - val_loss: 1.2293 - val_accuracy: 0.5000\n",
      "Epoch 18/30\n",
      "59/59 [==============================] - 28s 476ms/step - loss: 1.1395 - accuracy: 0.7555 - val_loss: 1.2269 - val_accuracy: 0.5000\n",
      "Epoch 19/30\n",
      "59/59 [==============================] - 28s 476ms/step - loss: 1.1308 - accuracy: 0.7684 - val_loss: 1.2248 - val_accuracy: 0.5000\n",
      "Epoch 20/30\n",
      "59/59 [==============================] - 28s 476ms/step - loss: 1.1282 - accuracy: 0.7700 - val_loss: 1.2229 - val_accuracy: 0.5000\n",
      "Epoch 21/30\n",
      "59/59 [==============================] - 28s 476ms/step - loss: 1.1259 - accuracy: 0.7628 - val_loss: 1.2211 - val_accuracy: 0.5000\n",
      "Epoch 22/30\n",
      "59/59 [==============================] - 28s 476ms/step - loss: 1.1240 - accuracy: 0.7639 - val_loss: 1.2196 - val_accuracy: 0.5000\n",
      "Epoch 23/30\n",
      "59/59 [==============================] - 28s 476ms/step - loss: 1.1231 - accuracy: 0.7606 - val_loss: 1.2182 - val_accuracy: 0.5000\n",
      "Epoch 24/30\n",
      "59/59 [==============================] - 28s 476ms/step - loss: 1.1205 - accuracy: 0.7607 - val_loss: 1.2169 - val_accuracy: 0.5000\n",
      "Epoch 25/30\n",
      "59/59 [==============================] - 28s 476ms/step - loss: 1.1176 - accuracy: 0.7616 - val_loss: 1.2158 - val_accuracy: 0.5000\n",
      "Epoch 26/30\n",
      "59/59 [==============================] - 28s 476ms/step - loss: 1.1171 - accuracy: 0.7561 - val_loss: 1.2148 - val_accuracy: 0.5000\n",
      "Epoch 27/30\n",
      "59/59 [==============================] - 28s 476ms/step - loss: 1.1141 - accuracy: 0.7584 - val_loss: 1.2139 - val_accuracy: 0.5000\n",
      "Epoch 28/30\n",
      "59/59 [==============================] - 28s 476ms/step - loss: 1.1122 - accuracy: 0.7629 - val_loss: 1.2131 - val_accuracy: 0.5000\n",
      "Epoch 29/30\n",
      "59/59 [==============================] - 28s 476ms/step - loss: 1.1094 - accuracy: 0.7661 - val_loss: 1.2123 - val_accuracy: 0.5000\n",
      "Epoch 30/30\n",
      "59/59 [==============================] - 28s 477ms/step - loss: 1.1108 - accuracy: 0.7609 - val_loss: 1.2117 - val_accuracy: 0.5000\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_7514_images_False_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.500000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.10089303 0.09931461 0.10028199 0.0998143 ]\n",
      "Training resnet for 0.1% of train size (aka 8348 images) with pretrained: True and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 178 trainable: 178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      " 6/66 [=>............................] - ETA: 1:00 - loss: 1.3469 - accuracy: 0.7589WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1992s vs `on_train_batch_end` time: 0.5203s). Check your callbacks.\n",
      "66/66 [==============================] - 41s 529ms/step - loss: 1.3387 - accuracy: 0.7607 - val_loss: 1.3531 - val_accuracy: 0.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "66/66 [==============================] - 31s 470ms/step - loss: 1.3059 - accuracy: 0.7568 - val_loss: 1.3356 - val_accuracy: 0.5000\n",
      "Epoch 3/30\n",
      "66/66 [==============================] - 31s 472ms/step - loss: 1.2767 - accuracy: 0.7613 - val_loss: 1.3204 - val_accuracy: 0.5000\n",
      "Epoch 4/30\n",
      "66/66 [==============================] - 31s 472ms/step - loss: 1.2509 - accuracy: 0.7615 - val_loss: 1.3070 - val_accuracy: 0.5000\n",
      "Epoch 5/30\n",
      "66/66 [==============================] - 31s 473ms/step - loss: 1.2316 - accuracy: 0.7532 - val_loss: 1.2954 - val_accuracy: 0.5000\n",
      "Epoch 6/30\n",
      "66/66 [==============================] - 31s 473ms/step - loss: 1.2128 - accuracy: 0.7543 - val_loss: 1.2851 - val_accuracy: 0.5000\n",
      "Epoch 7/30\n",
      "66/66 [==============================] - 31s 473ms/step - loss: 1.1916 - accuracy: 0.7692 - val_loss: 1.2760 - val_accuracy: 0.5000\n",
      "Epoch 8/30\n",
      "66/66 [==============================] - 31s 473ms/step - loss: 1.1777 - accuracy: 0.7646 - val_loss: 1.2680 - val_accuracy: 0.5000\n",
      "Epoch 9/30\n",
      "66/66 [==============================] - 31s 473ms/step - loss: 1.1693 - accuracy: 0.7516 - val_loss: 1.2609 - val_accuracy: 0.5000\n",
      "Epoch 10/30\n",
      "66/66 [==============================] - 31s 473ms/step - loss: 1.1576 - accuracy: 0.7553 - val_loss: 1.2546 - val_accuracy: 0.5000\n",
      "Epoch 11/30\n",
      "66/66 [==============================] - 31s 473ms/step - loss: 1.1443 - accuracy: 0.7634 - val_loss: 1.2491 - val_accuracy: 0.5000\n",
      "Epoch 12/30\n",
      "66/66 [==============================] - 31s 473ms/step - loss: 1.1385 - accuracy: 0.7565 - val_loss: 1.2441 - val_accuracy: 0.5000\n",
      "Epoch 13/30\n",
      "66/66 [==============================] - 31s 473ms/step - loss: 1.1294 - accuracy: 0.7608 - val_loss: 1.2397 - val_accuracy: 0.5000\n",
      "Epoch 14/30\n",
      "66/66 [==============================] - 31s 473ms/step - loss: 1.1192 - accuracy: 0.7665 - val_loss: 1.2358 - val_accuracy: 0.5000\n",
      "Epoch 15/30\n",
      "66/66 [==============================] - 31s 473ms/step - loss: 1.1123 - accuracy: 0.7676 - val_loss: 1.2322 - val_accuracy: 0.5000\n",
      "Epoch 16/30\n",
      "66/66 [==============================] - 31s 473ms/step - loss: 1.1089 - accuracy: 0.7664 - val_loss: 1.2291 - val_accuracy: 0.5000\n",
      "Epoch 17/30\n",
      "66/66 [==============================] - 31s 473ms/step - loss: 1.1043 - accuracy: 0.7639 - val_loss: 1.2263 - val_accuracy: 0.5000\n",
      "Epoch 18/30\n",
      "66/66 [==============================] - 31s 473ms/step - loss: 1.0992 - accuracy: 0.7636 - val_loss: 1.2238 - val_accuracy: 0.5000\n",
      "Epoch 19/30\n",
      "66/66 [==============================] - 31s 473ms/step - loss: 1.0987 - accuracy: 0.7557 - val_loss: 1.2215 - val_accuracy: 0.5000\n",
      "Epoch 20/30\n",
      "66/66 [==============================] - 31s 473ms/step - loss: 1.0942 - accuracy: 0.7569 - val_loss: 1.2195 - val_accuracy: 0.5000\n",
      "Epoch 21/30\n",
      "66/66 [==============================] - 31s 474ms/step - loss: 1.0921 - accuracy: 0.7582 - val_loss: 1.2176 - val_accuracy: 0.5000\n",
      "Epoch 22/30\n",
      "66/66 [==============================] - 31s 473ms/step - loss: 1.0913 - accuracy: 0.7546 - val_loss: 1.2160 - val_accuracy: 0.5000\n",
      "Epoch 23/30\n",
      "66/66 [==============================] - 31s 473ms/step - loss: 1.0839 - accuracy: 0.7599 - val_loss: 1.2146 - val_accuracy: 0.5000\n",
      "Epoch 24/30\n",
      "66/66 [==============================] - 31s 473ms/step - loss: 1.0821 - accuracy: 0.7601 - val_loss: 1.2132 - val_accuracy: 0.5000\n",
      "Epoch 25/30\n",
      "66/66 [==============================] - 31s 473ms/step - loss: 1.0803 - accuracy: 0.7619 - val_loss: 1.2121 - val_accuracy: 0.5000\n",
      "Epoch 26/30\n",
      "66/66 [==============================] - 31s 473ms/step - loss: 1.0769 - accuracy: 0.7649 - val_loss: 1.2110 - val_accuracy: 0.5000\n",
      "Epoch 27/30\n",
      "66/66 [==============================] - 31s 473ms/step - loss: 1.0763 - accuracy: 0.7630 - val_loss: 1.2101 - val_accuracy: 0.5000\n",
      "Epoch 28/30\n",
      "66/66 [==============================] - 31s 473ms/step - loss: 1.0799 - accuracy: 0.7544 - val_loss: 1.2092 - val_accuracy: 0.5000\n",
      "Epoch 29/30\n",
      "66/66 [==============================] - 31s 473ms/step - loss: 1.0803 - accuracy: 0.7500 - val_loss: 1.2085 - val_accuracy: 0.5000\n",
      "Epoch 30/30\n",
      "66/66 [==============================] - 31s 473ms/step - loss: 1.0743 - accuracy: 0.7605 - val_loss: 1.2078 - val_accuracy: 0.5000\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_8348_images_False_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.500000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.25251758 0.24784303 0.25484667 0.24524141]\n",
      "Training resnet for 0.25% of train size (aka 20871 images) with pretrained: True and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 178 trainable: 178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/164 [>.............................] - ETA: 2:36 - loss: 1.3983 - accuracy: 0.0058WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2001s vs `on_train_batch_end` time: 0.5166s). Check your callbacks.\n",
      "164/164 [==============================] - 87s 496ms/step - loss: 1.3766 - accuracy: 0.3408 - val_loss: 1.3440 - val_accuracy: 0.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "164/164 [==============================] - 78s 475ms/step - loss: 1.2914 - accuracy: 0.7604 - val_loss: 1.3015 - val_accuracy: 0.5000\n",
      "Epoch 3/30\n",
      "164/164 [==============================] - 78s 476ms/step - loss: 1.2218 - accuracy: 0.7610 - val_loss: 1.2662 - val_accuracy: 0.5000\n",
      "Epoch 4/30\n",
      "164/164 [==============================] - 78s 476ms/step - loss: 1.1663 - accuracy: 0.7589 - val_loss: 1.2366 - val_accuracy: 0.5000\n",
      "Epoch 5/30\n",
      "164/164 [==============================] - 78s 476ms/step - loss: 1.1200 - accuracy: 0.7591 - val_loss: 1.2115 - val_accuracy: 0.5000\n",
      "Epoch 6/30\n",
      "164/164 [==============================] - 78s 476ms/step - loss: 1.0810 - accuracy: 0.7594 - val_loss: 1.1899 - val_accuracy: 0.5000\n",
      "Epoch 7/30\n",
      "164/164 [==============================] - 78s 476ms/step - loss: 1.0486 - accuracy: 0.7589 - val_loss: 1.1715 - val_accuracy: 0.5000\n",
      "Epoch 8/30\n",
      "164/164 [==============================] - 78s 475ms/step - loss: 1.0204 - accuracy: 0.7602 - val_loss: 1.1555 - val_accuracy: 0.5000\n",
      "Epoch 9/30\n",
      "164/164 [==============================] - 78s 476ms/step - loss: 0.9965 - accuracy: 0.7592 - val_loss: 1.1415 - val_accuracy: 0.5000\n",
      "Epoch 10/30\n",
      "164/164 [==============================] - 78s 476ms/step - loss: 0.9770 - accuracy: 0.7592 - val_loss: 1.1291 - val_accuracy: 0.5000\n",
      "Epoch 11/30\n",
      "164/164 [==============================] - 78s 476ms/step - loss: 0.9580 - accuracy: 0.7617 - val_loss: 1.1184 - val_accuracy: 0.5000\n",
      "Epoch 12/30\n",
      "164/164 [==============================] - 78s 476ms/step - loss: 0.9431 - accuracy: 0.7619 - val_loss: 1.1089 - val_accuracy: 0.5000\n",
      "Epoch 13/30\n",
      "164/164 [==============================] - 78s 476ms/step - loss: 0.9294 - accuracy: 0.7613 - val_loss: 1.1004 - val_accuracy: 0.5000\n",
      "Epoch 14/30\n",
      "164/164 [==============================] - 78s 476ms/step - loss: 0.9172 - accuracy: 0.7624 - val_loss: 1.0931 - val_accuracy: 0.5000\n",
      "Epoch 15/30\n",
      "164/164 [==============================] - 78s 476ms/step - loss: 0.9074 - accuracy: 0.7610 - val_loss: 1.0865 - val_accuracy: 0.5000\n",
      "Epoch 16/30\n",
      "164/164 [==============================] - 78s 476ms/step - loss: 0.8982 - accuracy: 0.7617 - val_loss: 1.0807 - val_accuracy: 0.5000\n",
      "Epoch 17/30\n",
      "164/164 [==============================] - 78s 476ms/step - loss: 0.8915 - accuracy: 0.7611 - val_loss: 1.0754 - val_accuracy: 0.5000\n",
      "Epoch 18/30\n",
      "164/164 [==============================] - 78s 476ms/step - loss: 0.8837 - accuracy: 0.7603 - val_loss: 1.0709 - val_accuracy: 0.5000\n",
      "Epoch 19/30\n",
      "164/164 [==============================] - 78s 476ms/step - loss: 0.8762 - accuracy: 0.7617 - val_loss: 1.0666 - val_accuracy: 0.5000\n",
      "Epoch 20/30\n",
      "164/164 [==============================] - 78s 476ms/step - loss: 0.8720 - accuracy: 0.7607 - val_loss: 1.0629 - val_accuracy: 0.5000\n",
      "Epoch 21/30\n",
      "164/164 [==============================] - 78s 476ms/step - loss: 0.8647 - accuracy: 0.7664 - val_loss: 1.0596 - val_accuracy: 0.5000\n",
      "Epoch 22/30\n",
      "164/164 [==============================] - 78s 476ms/step - loss: 0.8662 - accuracy: 0.7574 - val_loss: 1.0566 - val_accuracy: 0.5000\n",
      "Epoch 23/30\n",
      "164/164 [==============================] - 78s 476ms/step - loss: 0.8592 - accuracy: 0.7592 - val_loss: 1.0538 - val_accuracy: 0.5000\n",
      "Epoch 24/30\n",
      "164/164 [==============================] - 78s 476ms/step - loss: 0.8573 - accuracy: 0.7592 - val_loss: 1.0516 - val_accuracy: 0.5000\n",
      "Epoch 25/30\n",
      "164/164 [==============================] - 78s 476ms/step - loss: 0.8530 - accuracy: 0.7593 - val_loss: 1.0497 - val_accuracy: 0.5000\n",
      "Epoch 26/30\n",
      "164/164 [==============================] - 78s 476ms/step - loss: 0.8528 - accuracy: 0.7558 - val_loss: 1.0476 - val_accuracy: 0.5000\n",
      "Epoch 27/30\n",
      "164/164 [==============================] - 78s 476ms/step - loss: 0.8480 - accuracy: 0.7599 - val_loss: 1.0458 - val_accuracy: 0.5000\n",
      "Epoch 28/30\n",
      "164/164 [==============================] - 78s 476ms/step - loss: 0.8461 - accuracy: 0.7583 - val_loss: 1.0444 - val_accuracy: 0.5000\n",
      "Epoch 29/30\n",
      "164/164 [==============================] - 78s 476ms/step - loss: 0.8403 - accuracy: 0.7656 - val_loss: 1.0430 - val_accuracy: 0.5000\n",
      "Epoch 30/30\n",
      "164/164 [==============================] - 78s 476ms/step - loss: 0.8429 - accuracy: 0.7607 - val_loss: 1.0418 - val_accuracy: 0.5000\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_20871_images_False_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.500000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.40547216 0.3980379  0.40183292 0.38927577]\n",
      "Training resnet for 0.4% of train size (aka 33393 images) with pretrained: True and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 178 trainable: 178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/261 [..............................] - ETA: 4:12 - loss: 1.3905 - accuracy: 0.4322WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1983s vs `on_train_batch_end` time: 0.5164s). Check your callbacks.\n",
      "261/261 [==============================] - 134s 491ms/step - loss: 1.3531 - accuracy: 0.6081 - val_loss: 1.2927 - val_accuracy: 0.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "261/261 [==============================] - 125s 478ms/step - loss: 1.2238 - accuracy: 0.7605 - val_loss: 1.2307 - val_accuracy: 0.5000\n",
      "Epoch 3/30\n",
      "261/261 [==============================] - 125s 478ms/step - loss: 1.1243 - accuracy: 0.7649 - val_loss: 1.1814 - val_accuracy: 0.5000\n",
      "Epoch 4/30\n",
      "261/261 [==============================] - 125s 478ms/step - loss: 1.0501 - accuracy: 0.7608 - val_loss: 1.1412 - val_accuracy: 0.5000\n",
      "Epoch 5/30\n",
      "261/261 [==============================] - 125s 478ms/step - loss: 0.9898 - accuracy: 0.7608 - val_loss: 1.1077 - val_accuracy: 0.5000\n",
      "Epoch 6/30\n",
      "261/261 [==============================] - 125s 478ms/step - loss: 0.9386 - accuracy: 0.7656 - val_loss: 1.0795 - val_accuracy: 0.5000\n",
      "Epoch 7/30\n",
      "261/261 [==============================] - 125s 478ms/step - loss: 0.9042 - accuracy: 0.7583 - val_loss: 1.0554 - val_accuracy: 0.5000\n",
      "Epoch 8/30\n",
      "261/261 [==============================] - 125s 478ms/step - loss: 0.8692 - accuracy: 0.7608 - val_loss: 1.0345 - val_accuracy: 0.5000\n",
      "Epoch 9/30\n",
      "261/261 [==============================] - 125s 478ms/step - loss: 0.8408 - accuracy: 0.7632 - val_loss: 1.0168 - val_accuracy: 0.5000\n",
      "Epoch 10/30\n",
      "261/261 [==============================] - 125s 478ms/step - loss: 0.8167 - accuracy: 0.7649 - val_loss: 1.0010 - val_accuracy: 0.5000\n",
      "Epoch 11/30\n",
      "261/261 [==============================] - 125s 478ms/step - loss: 0.7963 - accuracy: 0.7650 - val_loss: 0.9874 - val_accuracy: 0.5000\n",
      "Epoch 12/30\n",
      "261/261 [==============================] - 125s 478ms/step - loss: 0.7795 - accuracy: 0.7638 - val_loss: 0.9752 - val_accuracy: 0.5000\n",
      "Epoch 13/30\n",
      "261/261 [==============================] - 125s 478ms/step - loss: 0.7683 - accuracy: 0.7603 - val_loss: 0.9648 - val_accuracy: 0.5000\n",
      "Epoch 14/30\n",
      "261/261 [==============================] - 125s 478ms/step - loss: 0.7554 - accuracy: 0.8079 - val_loss: 0.9553 - val_accuracy: 0.7500\n",
      "Epoch 15/30\n",
      "261/261 [==============================] - 125s 478ms/step - loss: 0.7420 - accuracy: 0.8906 - val_loss: 0.9472 - val_accuracy: 0.7500\n",
      "Epoch 16/30\n",
      "261/261 [==============================] - 125s 478ms/step - loss: 0.7347 - accuracy: 0.8916 - val_loss: 0.9399 - val_accuracy: 0.7500\n",
      "Epoch 17/30\n",
      "261/261 [==============================] - 125s 478ms/step - loss: 0.7243 - accuracy: 0.8957 - val_loss: 0.9332 - val_accuracy: 0.7500\n",
      "Epoch 18/30\n",
      "261/261 [==============================] - 125s 478ms/step - loss: 0.7180 - accuracy: 0.8936 - val_loss: 0.9272 - val_accuracy: 0.7500\n",
      "Epoch 19/30\n",
      "261/261 [==============================] - 125s 478ms/step - loss: 0.7110 - accuracy: 0.8947 - val_loss: 0.9222 - val_accuracy: 0.7500\n",
      "Epoch 20/30\n",
      "261/261 [==============================] - 125s 478ms/step - loss: 0.7053 - accuracy: 0.8962 - val_loss: 0.9177 - val_accuracy: 0.7500\n",
      "Epoch 21/30\n",
      "261/261 [==============================] - 125s 478ms/step - loss: 0.7007 - accuracy: 0.8969 - val_loss: 0.9134 - val_accuracy: 0.7500\n",
      "Epoch 22/30\n",
      "261/261 [==============================] - 125s 478ms/step - loss: 0.6933 - accuracy: 0.8978 - val_loss: 0.9098 - val_accuracy: 0.7500\n",
      "Epoch 23/30\n",
      "261/261 [==============================] - 125s 478ms/step - loss: 0.6920 - accuracy: 0.8945 - val_loss: 0.9064 - val_accuracy: 0.7500\n",
      "Epoch 24/30\n",
      "261/261 [==============================] - 125s 478ms/step - loss: 0.6879 - accuracy: 0.8976 - val_loss: 0.9036 - val_accuracy: 0.7500\n",
      "Epoch 25/30\n",
      "261/261 [==============================] - 125s 478ms/step - loss: 0.6867 - accuracy: 0.8951 - val_loss: 0.9009 - val_accuracy: 0.7500\n",
      "Epoch 26/30\n",
      "261/261 [==============================] - 125s 478ms/step - loss: 0.6832 - accuracy: 0.8955 - val_loss: 0.8985 - val_accuracy: 0.7500\n",
      "Epoch 27/30\n",
      "261/261 [==============================] - 125s 478ms/step - loss: 0.6770 - accuracy: 0.8967 - val_loss: 0.8963 - val_accuracy: 0.7500\n",
      "Epoch 28/30\n",
      "261/261 [==============================] - 125s 478ms/step - loss: 0.6772 - accuracy: 0.8955 - val_loss: 0.8946 - val_accuracy: 0.7500\n",
      "Epoch 29/30\n",
      "261/261 [==============================] - 125s 478ms/step - loss: 0.6766 - accuracy: 0.8943 - val_loss: 0.8927 - val_accuracy: 0.7500\n",
      "Epoch 30/30\n",
      "261/261 [==============================] - 125s 478ms/step - loss: 0.6716 - accuracy: 0.8961 - val_loss: 0.8910 - val_accuracy: 0.7500\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_33394_images_False_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.748967\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.5065552  0.49565919 0.50361297 0.49396472]\n",
      "Training resnet for 0.5% of train size (aka 41742 images) with pretrained: True and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 178 trainable: 178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/327 [..............................] - ETA: 5:24 - loss: 1.3821 - accuracy: 0.0032WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2010s vs `on_train_batch_end` time: 0.5360s). Check your callbacks.\n",
      "327/327 [==============================] - 167s 487ms/step - loss: 1.3386 - accuracy: 0.4033 - val_loss: 1.2821 - val_accuracy: 0.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "327/327 [==============================] - 156s 476ms/step - loss: 1.1852 - accuracy: 0.7586 - val_loss: 1.2090 - val_accuracy: 0.5000\n",
      "Epoch 3/30\n",
      "327/327 [==============================] - 156s 477ms/step - loss: 1.0722 - accuracy: 0.7617 - val_loss: 1.1516 - val_accuracy: 0.5000\n",
      "Epoch 4/30\n",
      "327/327 [==============================] - 156s 477ms/step - loss: 0.9883 - accuracy: 0.7603 - val_loss: 1.1054 - val_accuracy: 0.5000\n",
      "Epoch 5/30\n",
      "327/327 [==============================] - 156s 477ms/step - loss: 0.9252 - accuracy: 0.7575 - val_loss: 1.0671 - val_accuracy: 0.5000\n",
      "Epoch 6/30\n",
      "327/327 [==============================] - 156s 477ms/step - loss: 0.8714 - accuracy: 0.7621 - val_loss: 1.0350 - val_accuracy: 0.5000\n",
      "Epoch 7/30\n",
      "327/327 [==============================] - 156s 477ms/step - loss: 0.8320 - accuracy: 0.7600 - val_loss: 1.0079 - val_accuracy: 0.5000\n",
      "Epoch 8/30\n",
      "327/327 [==============================] - 156s 477ms/step - loss: 0.7993 - accuracy: 0.7589 - val_loss: 0.9845 - val_accuracy: 0.5000\n",
      "Epoch 9/30\n",
      "327/327 [==============================] - 156s 477ms/step - loss: 0.7708 - accuracy: 0.7599 - val_loss: 0.9638 - val_accuracy: 0.5000\n",
      "Epoch 10/30\n",
      "327/327 [==============================] - 156s 477ms/step - loss: 0.7461 - accuracy: 0.7716 - val_loss: 0.9464 - val_accuracy: 0.7500\n",
      "Epoch 11/30\n",
      "327/327 [==============================] - 156s 477ms/step - loss: 0.7247 - accuracy: 0.8916 - val_loss: 0.9308 - val_accuracy: 0.7500\n",
      "Epoch 12/30\n",
      "327/327 [==============================] - 156s 477ms/step - loss: 0.7074 - accuracy: 0.8927 - val_loss: 0.9169 - val_accuracy: 0.7500\n",
      "Epoch 13/30\n",
      "327/327 [==============================] - 156s 477ms/step - loss: 0.6941 - accuracy: 0.8944 - val_loss: 0.9049 - val_accuracy: 0.7500\n",
      "Epoch 14/30\n",
      "327/327 [==============================] - 156s 477ms/step - loss: 0.6823 - accuracy: 0.8944 - val_loss: 0.8946 - val_accuracy: 0.7500\n",
      "Epoch 15/30\n",
      "327/327 [==============================] - 156s 477ms/step - loss: 0.6690 - accuracy: 0.8963 - val_loss: 0.8853 - val_accuracy: 0.7500\n",
      "Epoch 16/30\n",
      "327/327 [==============================] - 156s 477ms/step - loss: 0.6626 - accuracy: 0.8945 - val_loss: 0.8768 - val_accuracy: 0.7500\n",
      "Epoch 17/30\n",
      "327/327 [==============================] - 156s 477ms/step - loss: 0.6544 - accuracy: 0.8937 - val_loss: 0.8692 - val_accuracy: 0.7500\n",
      "Epoch 18/30\n",
      "327/327 [==============================] - 156s 477ms/step - loss: 0.6433 - accuracy: 0.8959 - val_loss: 0.8631 - val_accuracy: 0.7500\n",
      "Epoch 19/30\n",
      "327/327 [==============================] - 156s 477ms/step - loss: 0.6387 - accuracy: 0.8946 - val_loss: 0.8566 - val_accuracy: 0.7500\n",
      "Epoch 20/30\n",
      "327/327 [==============================] - 156s 477ms/step - loss: 0.6312 - accuracy: 0.8972 - val_loss: 0.8519 - val_accuracy: 0.7500\n",
      "Epoch 21/30\n",
      "327/327 [==============================] - 156s 477ms/step - loss: 0.6304 - accuracy: 0.8928 - val_loss: 0.8472 - val_accuracy: 0.7500\n",
      "Epoch 22/30\n",
      "327/327 [==============================] - 156s 477ms/step - loss: 0.6249 - accuracy: 0.8930 - val_loss: 0.8427 - val_accuracy: 0.7500\n",
      "Epoch 23/30\n",
      "327/327 [==============================] - 156s 477ms/step - loss: 0.6202 - accuracy: 0.8928 - val_loss: 0.8390 - val_accuracy: 0.7500\n",
      "Epoch 24/30\n",
      "327/327 [==============================] - 156s 477ms/step - loss: 0.6159 - accuracy: 0.8933 - val_loss: 0.8357 - val_accuracy: 0.7500\n",
      "Epoch 25/30\n",
      "327/327 [==============================] - 156s 477ms/step - loss: 0.6143 - accuracy: 0.8943 - val_loss: 0.8327 - val_accuracy: 0.7500\n",
      "Epoch 26/30\n",
      "327/327 [==============================] - 156s 477ms/step - loss: 0.6091 - accuracy: 0.8951 - val_loss: 0.8301 - val_accuracy: 0.7500\n",
      "Epoch 27/30\n",
      "327/327 [==============================] - 156s 477ms/step - loss: 0.6081 - accuracy: 0.8932 - val_loss: 0.8278 - val_accuracy: 0.7500\n",
      "Epoch 28/30\n",
      "327/327 [==============================] - 156s 477ms/step - loss: 0.6037 - accuracy: 0.8961 - val_loss: 0.8262 - val_accuracy: 0.7500\n",
      "Epoch 29/30\n",
      "327/327 [==============================] - 156s 477ms/step - loss: 0.6012 - accuracy: 0.8969 - val_loss: 0.8237 - val_accuracy: 0.7500\n",
      "Epoch 30/30\n",
      "327/327 [==============================] - 156s 476ms/step - loss: 0.6007 - accuracy: 0.8942 - val_loss: 0.8222 - val_accuracy: 0.7500\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_41742_images_False_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.750000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.60516816 0.59567262 0.60327811 0.5985376 ]\n",
      "Training resnet for 0.6% of train size (aka 50090 images) with pretrained: True and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 178 trainable: 178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/392 [..............................] - ETA: 6:19 - loss: 1.4145 - accuracy: 0.0032WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1998s vs `on_train_batch_end` time: 0.5096s). Check your callbacks.\n",
      "392/392 [==============================] - 196s 485ms/step - loss: 1.3623 - accuracy: 0.3308 - val_loss: 1.2942 - val_accuracy: 0.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "392/392 [==============================] - 187s 477ms/step - loss: 1.1814 - accuracy: 0.7577 - val_loss: 1.2080 - val_accuracy: 0.5000\n",
      "Epoch 3/30\n",
      "392/392 [==============================] - 187s 477ms/step - loss: 1.0548 - accuracy: 0.7573 - val_loss: 1.1415 - val_accuracy: 0.5000\n",
      "Epoch 4/30\n",
      "392/392 [==============================] - 187s 477ms/step - loss: 0.9596 - accuracy: 0.7618 - val_loss: 1.0882 - val_accuracy: 0.5000\n",
      "Epoch 5/30\n",
      "392/392 [==============================] - 187s 477ms/step - loss: 0.8901 - accuracy: 0.7586 - val_loss: 1.0439 - val_accuracy: 0.5000\n",
      "Epoch 6/30\n",
      "392/392 [==============================] - 187s 477ms/step - loss: 0.8358 - accuracy: 0.7588 - val_loss: 1.0071 - val_accuracy: 0.5000\n",
      "Epoch 7/30\n",
      "392/392 [==============================] - 187s 478ms/step - loss: 0.7908 - accuracy: 0.7602 - val_loss: 0.9762 - val_accuracy: 0.5000\n",
      "Epoch 8/30\n",
      "392/392 [==============================] - 187s 477ms/step - loss: 0.7568 - accuracy: 0.7589 - val_loss: 0.9493 - val_accuracy: 0.5000\n",
      "Epoch 9/30\n",
      "392/392 [==============================] - 187s 477ms/step - loss: 0.7265 - accuracy: 0.7584 - val_loss: 0.9260 - val_accuracy: 0.5000\n",
      "Epoch 10/30\n",
      "392/392 [==============================] - 187s 477ms/step - loss: 0.7006 - accuracy: 0.7593 - val_loss: 0.9059 - val_accuracy: 0.5000\n",
      "Epoch 11/30\n",
      "392/392 [==============================] - 187s 478ms/step - loss: 0.6765 - accuracy: 0.7652 - val_loss: 0.8884 - val_accuracy: 0.7500\n",
      "Epoch 12/30\n",
      "392/392 [==============================] - 187s 478ms/step - loss: 0.6673 - accuracy: 0.8850 - val_loss: 0.8725 - val_accuracy: 0.7500\n",
      "Epoch 13/30\n",
      "392/392 [==============================] - 187s 477ms/step - loss: 0.6465 - accuracy: 0.8922 - val_loss: 0.8591 - val_accuracy: 0.7500\n",
      "Epoch 14/30\n",
      "392/392 [==============================] - 187s 477ms/step - loss: 0.6332 - accuracy: 0.8952 - val_loss: 0.8474 - val_accuracy: 0.7500\n",
      "Epoch 15/30\n",
      "392/392 [==============================] - 187s 478ms/step - loss: 0.6224 - accuracy: 0.8927 - val_loss: 0.8369 - val_accuracy: 0.7500\n",
      "Epoch 16/30\n",
      "392/392 [==============================] - 187s 477ms/step - loss: 0.6130 - accuracy: 0.8938 - val_loss: 0.8270 - val_accuracy: 0.7500\n",
      "Epoch 17/30\n",
      "392/392 [==============================] - 187s 477ms/step - loss: 0.6049 - accuracy: 0.8949 - val_loss: 0.8192 - val_accuracy: 0.8750\n",
      "Epoch 18/30\n",
      "392/392 [==============================] - 187s 478ms/step - loss: 0.5957 - accuracy: 0.9447 - val_loss: 0.8120 - val_accuracy: 0.9375\n",
      "Epoch 19/30\n",
      "392/392 [==============================] - 187s 478ms/step - loss: 0.5905 - accuracy: 0.9596 - val_loss: 0.8049 - val_accuracy: 0.9688\n",
      "Epoch 20/30\n",
      "392/392 [==============================] - 187s 478ms/step - loss: 0.5833 - accuracy: 0.9670 - val_loss: 0.7997 - val_accuracy: 0.9688\n",
      "Epoch 21/30\n",
      "392/392 [==============================] - 187s 477ms/step - loss: 0.5796 - accuracy: 0.9710 - val_loss: 0.7945 - val_accuracy: 0.9688\n",
      "Epoch 22/30\n",
      "392/392 [==============================] - 187s 477ms/step - loss: 0.5717 - accuracy: 0.9739 - val_loss: 0.7900 - val_accuracy: 0.9688\n",
      "Epoch 23/30\n",
      "392/392 [==============================] - 187s 478ms/step - loss: 0.5699 - accuracy: 0.9760 - val_loss: 0.7856 - val_accuracy: 0.9688\n",
      "Epoch 24/30\n",
      "392/392 [==============================] - 187s 477ms/step - loss: 0.5657 - accuracy: 0.9784 - val_loss: 0.7817 - val_accuracy: 0.9688\n",
      "Epoch 25/30\n",
      "392/392 [==============================] - 187s 478ms/step - loss: 0.5606 - accuracy: 0.9801 - val_loss: 0.7786 - val_accuracy: 0.9688\n",
      "Epoch 26/30\n",
      "392/392 [==============================] - 187s 478ms/step - loss: 0.5599 - accuracy: 0.9799 - val_loss: 0.7756 - val_accuracy: 0.9688\n",
      "Epoch 27/30\n",
      "392/392 [==============================] - 187s 478ms/step - loss: 0.5572 - accuracy: 0.9812 - val_loss: 0.7729 - val_accuracy: 0.9688\n",
      "Epoch 28/30\n",
      "392/392 [==============================] - 187s 478ms/step - loss: 0.5562 - accuracy: 0.9809 - val_loss: 0.7703 - val_accuracy: 0.9688\n",
      "Epoch 29/30\n",
      "392/392 [==============================] - 187s 478ms/step - loss: 0.5543 - accuracy: 0.9813 - val_loss: 0.7682 - val_accuracy: 0.9688\n",
      "Epoch 30/30\n",
      "392/392 [==============================] - 187s 478ms/step - loss: 0.5510 - accuracy: 0.9829 - val_loss: 0.7668 - val_accuracy: 0.9688\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_50090_images_False_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.972107\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.75500665 0.74748018 0.75255552 0.74222377]\n",
      "Training resnet for 0.75% of train size (aka 62613 images) with pretrained: True and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 178 trainable: 178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/490 [..............................] - ETA: 7:58 - loss: 1.3872 - accuracy: 0.0019WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2008s vs `on_train_batch_end` time: 0.5126s). Check your callbacks.\n",
      "490/490 [==============================] - 243s 484ms/step - loss: 1.3227 - accuracy: 0.5968 - val_loss: 1.2471 - val_accuracy: 0.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "490/490 [==============================] - 234s 478ms/step - loss: 1.1073 - accuracy: 0.7629 - val_loss: 1.1488 - val_accuracy: 0.5000\n",
      "Epoch 3/30\n",
      "490/490 [==============================] - 234s 478ms/step - loss: 0.9664 - accuracy: 0.7619 - val_loss: 1.0750 - val_accuracy: 0.5000\n",
      "Epoch 4/30\n",
      "490/490 [==============================] - 234s 478ms/step - loss: 0.8692 - accuracy: 0.7599 - val_loss: 1.0163 - val_accuracy: 0.5000\n",
      "Epoch 5/30\n",
      "490/490 [==============================] - 234s 478ms/step - loss: 0.7969 - accuracy: 0.7603 - val_loss: 0.9688 - val_accuracy: 0.5000\n",
      "Epoch 6/30\n",
      "490/490 [==============================] - 234s 478ms/step - loss: 0.7423 - accuracy: 0.8288 - val_loss: 0.9288 - val_accuracy: 0.7500\n",
      "Epoch 7/30\n",
      "490/490 [==============================] - 234s 478ms/step - loss: 0.6983 - accuracy: 0.8906 - val_loss: 0.8951 - val_accuracy: 0.7500\n",
      "Epoch 8/30\n",
      "490/490 [==============================] - 234s 478ms/step - loss: 0.6621 - accuracy: 0.8933 - val_loss: 0.8663 - val_accuracy: 0.7500\n",
      "Epoch 9/30\n",
      "490/490 [==============================] - 234s 478ms/step - loss: 0.6337 - accuracy: 0.8941 - val_loss: 0.8419 - val_accuracy: 0.7500\n",
      "Epoch 10/30\n",
      "490/490 [==============================] - 234s 478ms/step - loss: 0.6118 - accuracy: 0.8945 - val_loss: 0.8205 - val_accuracy: 0.7500\n",
      "Epoch 11/30\n",
      "490/490 [==============================] - 234s 478ms/step - loss: 0.5897 - accuracy: 0.8960 - val_loss: 0.8017 - val_accuracy: 0.7500\n",
      "Epoch 12/30\n",
      "490/490 [==============================] - 234s 478ms/step - loss: 0.5733 - accuracy: 0.8971 - val_loss: 0.7857 - val_accuracy: 0.7500\n",
      "Epoch 13/30\n",
      "490/490 [==============================] - 234s 478ms/step - loss: 0.5615 - accuracy: 0.8948 - val_loss: 0.7712 - val_accuracy: 0.7500\n",
      "Epoch 14/30\n",
      "490/490 [==============================] - 234s 478ms/step - loss: 0.5467 - accuracy: 0.8953 - val_loss: 0.7588 - val_accuracy: 0.7500\n",
      "Epoch 15/30\n",
      "490/490 [==============================] - 234s 478ms/step - loss: 0.5337 - accuracy: 0.8964 - val_loss: 0.7477 - val_accuracy: 0.7500\n",
      "Epoch 16/30\n",
      "490/490 [==============================] - 234s 478ms/step - loss: 0.5270 - accuracy: 0.8947 - val_loss: 0.7378 - val_accuracy: 0.7500\n",
      "Epoch 17/30\n",
      "490/490 [==============================] - 234s 478ms/step - loss: 0.5158 - accuracy: 0.9173 - val_loss: 0.7293 - val_accuracy: 0.9375\n",
      "Epoch 18/30\n",
      "490/490 [==============================] - 234s 478ms/step - loss: 0.5108 - accuracy: 0.9639 - val_loss: 0.7217 - val_accuracy: 0.9688\n",
      "Epoch 19/30\n",
      "490/490 [==============================] - 234s 478ms/step - loss: 0.5036 - accuracy: 0.9720 - val_loss: 0.7148 - val_accuracy: 0.9688\n",
      "Epoch 20/30\n",
      "490/490 [==============================] - 234s 478ms/step - loss: 0.5008 - accuracy: 0.9757 - val_loss: 0.7083 - val_accuracy: 0.9688\n",
      "Epoch 21/30\n",
      "490/490 [==============================] - 234s 478ms/step - loss: 0.4923 - accuracy: 0.9799 - val_loss: 0.7034 - val_accuracy: 0.9688\n",
      "Epoch 22/30\n",
      "490/490 [==============================] - 234s 478ms/step - loss: 0.4912 - accuracy: 0.9815 - val_loss: 0.6981 - val_accuracy: 0.9688\n",
      "Epoch 23/30\n",
      "490/490 [==============================] - 234s 478ms/step - loss: 0.4846 - accuracy: 0.9836 - val_loss: 0.6944 - val_accuracy: 0.9688\n",
      "Epoch 24/30\n",
      "490/490 [==============================] - 234s 478ms/step - loss: 0.4809 - accuracy: 0.9854 - val_loss: 0.6905 - val_accuracy: 0.9688\n",
      "Epoch 25/30\n",
      "490/490 [==============================] - 234s 478ms/step - loss: 0.4797 - accuracy: 0.9846 - val_loss: 0.6868 - val_accuracy: 0.9688\n",
      "Epoch 26/30\n",
      "490/490 [==============================] - 234s 478ms/step - loss: 0.4749 - accuracy: 0.9871 - val_loss: 0.6842 - val_accuracy: 0.9688\n",
      "Epoch 27/30\n",
      "490/490 [==============================] - 234s 478ms/step - loss: 0.4684 - accuracy: 0.9879 - val_loss: 0.6819 - val_accuracy: 0.9688\n",
      "Epoch 28/30\n",
      "490/490 [==============================] - 234s 478ms/step - loss: 0.4724 - accuracy: 0.9869 - val_loss: 0.6780 - val_accuracy: 0.9688\n",
      "Epoch 29/30\n",
      "490/490 [==============================] - 234s 478ms/step - loss: 0.4713 - accuracy: 0.9879 - val_loss: 0.6765 - val_accuracy: 0.9688\n",
      "Epoch 30/30\n",
      "490/490 [==============================] - 234s 478ms/step - loss: 0.4669 - accuracy: 0.9880 - val_loss: 0.6738 - val_accuracy: 0.9688\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_62613_images_False_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.985537\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.90378111 0.89694933 0.90192104 0.89902507]\n",
      "Training resnet for 0.9% of train size (aka 75135 images) with pretrained: True and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 178 trainable: 178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/587 [..............................] - ETA: 9:36 - loss: 1.3850 - accuracy: 0.2238 WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2005s vs `on_train_batch_end` time: 0.5169s). Check your callbacks.\n",
      "587/587 [==============================] - 292s 486ms/step - loss: 1.3090 - accuracy: 0.5387 - val_loss: 1.2002 - val_accuracy: 0.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "587/587 [==============================] - 282s 480ms/step - loss: 1.0623 - accuracy: 0.7620 - val_loss: 1.0892 - val_accuracy: 0.5000\n",
      "Epoch 3/30\n",
      "587/587 [==============================] - 281s 479ms/step - loss: 0.9085 - accuracy: 0.7613 - val_loss: 1.0074 - val_accuracy: 0.5000\n",
      "Epoch 4/30\n",
      "587/587 [==============================] - 281s 479ms/step - loss: 0.8055 - accuracy: 0.7993 - val_loss: 0.9425 - val_accuracy: 0.7500\n",
      "Epoch 5/30\n",
      "587/587 [==============================] - 282s 480ms/step - loss: 0.7277 - accuracy: 0.8950 - val_loss: 0.8907 - val_accuracy: 0.7500\n",
      "Epoch 6/30\n",
      "587/587 [==============================] - 281s 479ms/step - loss: 0.6741 - accuracy: 0.8928 - val_loss: 0.8474 - val_accuracy: 0.7500\n",
      "Epoch 7/30\n",
      "587/587 [==============================] - 281s 480ms/step - loss: 0.6304 - accuracy: 0.8931 - val_loss: 0.8108 - val_accuracy: 0.7500\n",
      "Epoch 8/30\n",
      "587/587 [==============================] - 281s 479ms/step - loss: 0.5946 - accuracy: 0.8941 - val_loss: 0.7805 - val_accuracy: 0.7500\n",
      "Epoch 9/30\n",
      "587/587 [==============================] - 282s 480ms/step - loss: 0.5660 - accuracy: 0.8950 - val_loss: 0.7537 - val_accuracy: 0.9062\n",
      "Epoch 10/30\n",
      "587/587 [==============================] - 282s 480ms/step - loss: 0.5423 - accuracy: 0.9603 - val_loss: 0.7312 - val_accuracy: 0.9688\n",
      "Epoch 11/30\n",
      "587/587 [==============================] - 281s 479ms/step - loss: 0.5228 - accuracy: 0.9813 - val_loss: 0.7112 - val_accuracy: 0.9688\n",
      "Epoch 12/30\n",
      "587/587 [==============================] - 282s 480ms/step - loss: 0.5051 - accuracy: 0.9868 - val_loss: 0.6947 - val_accuracy: 0.9688\n",
      "Epoch 13/30\n",
      "587/587 [==============================] - 282s 480ms/step - loss: 0.4920 - accuracy: 0.9884 - val_loss: 0.6792 - val_accuracy: 0.9688\n",
      "Epoch 14/30\n",
      "587/587 [==============================] - 282s 480ms/step - loss: 0.4834 - accuracy: 0.9900 - val_loss: 0.6660 - val_accuracy: 0.9688\n",
      "Epoch 15/30\n",
      "587/587 [==============================] - 282s 480ms/step - loss: 0.4695 - accuracy: 0.9912 - val_loss: 0.6553 - val_accuracy: 0.9688\n",
      "Epoch 16/30\n",
      "587/587 [==============================] - 282s 480ms/step - loss: 0.4609 - accuracy: 0.9911 - val_loss: 0.6447 - val_accuracy: 0.9688\n",
      "Epoch 17/30\n",
      "587/587 [==============================] - 282s 480ms/step - loss: 0.4508 - accuracy: 0.9924 - val_loss: 0.6359 - val_accuracy: 0.9688\n",
      "Epoch 18/30\n",
      "587/587 [==============================] - 282s 480ms/step - loss: 0.4457 - accuracy: 0.9920 - val_loss: 0.6275 - val_accuracy: 0.9688\n",
      "Epoch 19/30\n",
      "587/587 [==============================] - 282s 480ms/step - loss: 0.4373 - accuracy: 0.9930 - val_loss: 0.6216 - val_accuracy: 0.9688\n",
      "Epoch 20/30\n",
      "587/587 [==============================] - 282s 480ms/step - loss: 0.4341 - accuracy: 0.9933 - val_loss: 0.6149 - val_accuracy: 0.9688\n",
      "Epoch 21/30\n",
      "587/587 [==============================] - 282s 480ms/step - loss: 0.4307 - accuracy: 0.9925 - val_loss: 0.6093 - val_accuracy: 0.9688\n",
      "Epoch 22/30\n",
      "587/587 [==============================] - 282s 480ms/step - loss: 0.4242 - accuracy: 0.9933 - val_loss: 0.6044 - val_accuracy: 0.9688\n",
      "Epoch 23/30\n",
      "587/587 [==============================] - 282s 480ms/step - loss: 0.4230 - accuracy: 0.9931 - val_loss: 0.6003 - val_accuracy: 0.9688\n",
      "Epoch 24/30\n",
      "587/587 [==============================] - 282s 480ms/step - loss: 0.4167 - accuracy: 0.9935 - val_loss: 0.5967 - val_accuracy: 0.9688\n",
      "Epoch 25/30\n",
      "587/587 [==============================] - 282s 480ms/step - loss: 0.4143 - accuracy: 0.9931 - val_loss: 0.5931 - val_accuracy: 0.9688\n",
      "Epoch 26/30\n",
      "587/587 [==============================] - 282s 480ms/step - loss: 0.4135 - accuracy: 0.9939 - val_loss: 0.5894 - val_accuracy: 0.9688\n",
      "Epoch 27/30\n",
      "587/587 [==============================] - 282s 480ms/step - loss: 0.4086 - accuracy: 0.9937 - val_loss: 0.5869 - val_accuracy: 0.9688\n",
      "Epoch 28/30\n",
      "587/587 [==============================] - 282s 480ms/step - loss: 0.4101 - accuracy: 0.9930 - val_loss: 0.5845 - val_accuracy: 0.9688\n",
      "Epoch 29/30\n",
      "587/587 [==============================] - 282s 480ms/step - loss: 0.4072 - accuracy: 0.9931 - val_loss: 0.5823 - val_accuracy: 0.9688\n",
      "Epoch 30/30\n",
      "587/587 [==============================] - 282s 480ms/step - loss: 0.4057 - accuracy: 0.9935 - val_loss: 0.5805 - val_accuracy: 0.9688\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_75136_images_False_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.993802\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [1. 1. 1. 1.]\n",
      "Training resnet for 1.0% of train size (aka 83484 images) with pretrained: True and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 178 trainable: 178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/653 [..............................] - ETA: 11:16 - loss: 1.4099 - accuracy: 0.0000e+00WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2046s vs `on_train_batch_end` time: 0.5500s). Check your callbacks.\n",
      "653/653 [==============================] - 327s 488ms/step - loss: 1.3238 - accuracy: 0.5400 - val_loss: 1.2213 - val_accuracy: 0.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "653/653 [==============================] - 313s 480ms/step - loss: 1.0537 - accuracy: 0.7584 - val_loss: 1.1012 - val_accuracy: 0.5000\n",
      "Epoch 3/30\n",
      "653/653 [==============================] - 313s 479ms/step - loss: 0.8896 - accuracy: 0.7597 - val_loss: 1.0129 - val_accuracy: 0.5000\n",
      "Epoch 4/30\n",
      "653/653 [==============================] - 313s 480ms/step - loss: 0.7837 - accuracy: 0.7642 - val_loss: 0.9439 - val_accuracy: 0.7500\n",
      "Epoch 5/30\n",
      "653/653 [==============================] - 313s 480ms/step - loss: 0.7084 - accuracy: 0.8912 - val_loss: 0.8882 - val_accuracy: 0.7500\n",
      "Epoch 6/30\n",
      "653/653 [==============================] - 313s 480ms/step - loss: 0.6519 - accuracy: 0.8924 - val_loss: 0.8420 - val_accuracy: 0.7500\n",
      "Epoch 7/30\n",
      "653/653 [==============================] - 313s 480ms/step - loss: 0.6071 - accuracy: 0.8932 - val_loss: 0.8030 - val_accuracy: 0.7500\n",
      "Epoch 8/30\n",
      "653/653 [==============================] - 313s 480ms/step - loss: 0.5720 - accuracy: 0.8945 - val_loss: 0.7706 - val_accuracy: 0.7500\n",
      "Epoch 9/30\n",
      "653/653 [==============================] - 313s 480ms/step - loss: 0.5438 - accuracy: 0.8939 - val_loss: 0.7418 - val_accuracy: 0.7500\n",
      "Epoch 10/30\n",
      "653/653 [==============================] - 313s 480ms/step - loss: 0.5184 - accuracy: 0.9059 - val_loss: 0.7182 - val_accuracy: 0.9688\n",
      "Epoch 11/30\n",
      "653/653 [==============================] - 313s 480ms/step - loss: 0.5010 - accuracy: 0.9760 - val_loss: 0.6974 - val_accuracy: 0.9688\n",
      "Epoch 12/30\n",
      "653/653 [==============================] - 313s 480ms/step - loss: 0.4845 - accuracy: 0.9848 - val_loss: 0.6791 - val_accuracy: 0.9688\n",
      "Epoch 13/30\n",
      "653/653 [==============================] - 313s 480ms/step - loss: 0.4693 - accuracy: 0.9883 - val_loss: 0.6623 - val_accuracy: 0.9688\n",
      "Epoch 14/30\n",
      "653/653 [==============================] - 313s 480ms/step - loss: 0.4551 - accuracy: 0.9900 - val_loss: 0.6496 - val_accuracy: 0.9688\n",
      "Epoch 15/30\n",
      "653/653 [==============================] - 314s 480ms/step - loss: 0.4461 - accuracy: 0.9910 - val_loss: 0.6371 - val_accuracy: 0.9688\n",
      "Epoch 16/30\n",
      "653/653 [==============================] - 313s 480ms/step - loss: 0.4399 - accuracy: 0.9914 - val_loss: 0.6267 - val_accuracy: 0.9688\n",
      "Epoch 17/30\n",
      "653/653 [==============================] - 314s 480ms/step - loss: 0.4301 - accuracy: 0.9921 - val_loss: 0.6176 - val_accuracy: 0.9688\n",
      "Epoch 18/30\n",
      "653/653 [==============================] - 313s 480ms/step - loss: 0.4233 - accuracy: 0.9925 - val_loss: 0.6094 - val_accuracy: 0.9688\n",
      "Epoch 19/30\n",
      "653/653 [==============================] - 313s 480ms/step - loss: 0.4172 - accuracy: 0.9925 - val_loss: 0.6020 - val_accuracy: 0.9688\n",
      "Epoch 20/30\n",
      "653/653 [==============================] - 313s 480ms/step - loss: 0.4115 - accuracy: 0.9934 - val_loss: 0.5955 - val_accuracy: 0.9688\n",
      "Epoch 21/30\n",
      "653/653 [==============================] - 314s 480ms/step - loss: 0.4065 - accuracy: 0.9932 - val_loss: 0.5900 - val_accuracy: 0.9688\n",
      "Epoch 22/30\n",
      "653/653 [==============================] - 313s 480ms/step - loss: 0.4034 - accuracy: 0.9929 - val_loss: 0.5853 - val_accuracy: 0.9688\n",
      "Epoch 23/30\n",
      "653/653 [==============================] - 314s 480ms/step - loss: 0.3988 - accuracy: 0.9936 - val_loss: 0.5803 - val_accuracy: 0.9688\n",
      "Epoch 24/30\n",
      "653/653 [==============================] - 313s 480ms/step - loss: 0.3966 - accuracy: 0.9928 - val_loss: 0.5760 - val_accuracy: 0.9688\n",
      "Epoch 25/30\n",
      "653/653 [==============================] - 313s 480ms/step - loss: 0.3942 - accuracy: 0.9934 - val_loss: 0.5725 - val_accuracy: 0.9688\n",
      "Epoch 26/30\n",
      "653/653 [==============================] - 314s 480ms/step - loss: 0.3915 - accuracy: 0.9932 - val_loss: 0.5695 - val_accuracy: 0.9688\n",
      "Epoch 27/30\n",
      "653/653 [==============================] - 314s 480ms/step - loss: 0.3911 - accuracy: 0.9933 - val_loss: 0.5666 - val_accuracy: 0.9688\n",
      "Epoch 28/30\n",
      "653/653 [==============================] - 314s 480ms/step - loss: 0.3870 - accuracy: 0.9934 - val_loss: 0.5637 - val_accuracy: 0.9688\n",
      "Epoch 29/30\n",
      "653/653 [==============================] - 314s 480ms/step - loss: 0.3842 - accuracy: 0.9928 - val_loss: 0.5616 - val_accuracy: 0.9688\n",
      "Epoch 30/30\n",
      "653/653 [==============================] - 313s 480ms/step - loss: 0.3838 - accuracy: 0.9930 - val_loss: 0.5594 - val_accuracy: 0.9688\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_83484_images_False_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.993802\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import datetime\n",
    "\n",
    "maxTrain = len(y_train)\n",
    "for newWeights in [True, False]:\n",
    "    tLayer = [False] if newWeights else [True, False] # do not train only last layer if new weights will be produced \n",
    "    for trainLastLayerOnly in tLayer:\n",
    "        for p in [0.01, 0.025, 0.05, 0.075, 0.09, 0.1, 0.25, 0.4, 0.5, 0.6, 0.75, 0.9, 1.0]:\n",
    "            #X_trn, X_tst, y_trn, y_tst\n",
    "            if p < 1:\n",
    "                X_t, _, y_t, _ = train_test_split(images, y_train, test_size=1-p, random_state=56789)\n",
    "            else:\n",
    "                X_t = images; y_t = y_train;\n",
    "            print(f\"Labels fraction: {sum(y_t == 1) / sum(y_train == 1)}\")\n",
    "            for net in [\"resnet\"]:\n",
    "                print(f\"Training {net} for {p}% of train size (aka {len(X_t)} images) with pretrained: {not newWeights} and onlyLastLayersTrained: {trainLastLayerOnly}...\")\n",
    "                model, size, normalization = emptyModelGenerator(net, newWeights=newWeights, lastOnly=trainLastLayerOnly)\n",
    "                printTrainableLayers(model) # see if model is really well trained\n",
    "                X_trn = resizeIms(X_t, size)\n",
    "                #X_trn = normalizeIms(X_trn, normalization=normalization)\n",
    "                X_val = resizeIms(x_val, size)\n",
    "                #X_val = normalizeIms(X_val, normalization=normalization)\n",
    "                log_dir = f\"logs/{net}/fit/{p}trainSet_\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "                tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "                optimizer = SGD(learning_rate=learning_rate, momentum=momentum) #Adam(learning_rate) # create new optimizers\n",
    "                time_callback = TimeHistory()\n",
    "                model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "                hist = model.fit(X_trn, y_t, epochs=epochs, validation_data = (X_val, y_validation), batch_size=batch_size,\n",
    "                            shuffle=True, max_queue_size=20,\n",
    "                            use_multiprocessing=True, workers=5, \n",
    "                            callbacks=[CustomCallback(fraction=0.9, model=net), tensorboard_callback, time_callback])\n",
    "                trainTime = sum(time_callback.times)\n",
    "                model.save(f\"../{net}/{net}_{epochs}epochs_{p*maxTrain:.0f}_images_{newWeights}_newWeights_{trainLastLayerOnly}_lastLayerOnly_{normalization}_normalization\")\n",
    "                tstAcc = testPredict(model, size, name=net) #, normalization=normalization)\n",
    "                results = results.append({\n",
    "                    'model': net, \n",
    "                    'train set images': len(X_t), \n",
    "                    'pretrained': not newWeights, \n",
    "                    'pretrained dataset': None if newWeights or net == \"octnet\" else (\"OCT2017,Srinivasan2014\" if net == \"opticnet\" else \"Imagenet\"),\n",
    "                    'Trained layers': \"Last dense\" if trainLastLayerOnly else \"All\", \n",
    "                    'epochs': epochs, \n",
    "                    'batch size': batch_size, \n",
    "                    'learning rate': learning_rate, \n",
    "                    'optimizer': optimizer._name,\n",
    "                    'training time (seconds)': trainTime, \n",
    "                    'train accuracy': hist.history[\"accuracy\"][-1], \n",
    "                    'train loss': hist.history[\"loss\"][-1],\n",
    "                    'validation accuracy': hist.history[\"val_accuracy\"][-1], \n",
    "                    'validation loss': hist.history[\"val_loss\"][-1], \n",
    "                    'test accuracy': tstAcc,\n",
    "                    #'normalization': normalization\n",
    "                }, ignore_index=True)\n",
    "                results.to_csv(\"Results_temp.csv\", index=False)\n",
    "                del model\n",
    "                del X_trn\n",
    "                del X_val\n",
    "                print(\"Done!\\n\" + '-'*50, end='\\n\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
