{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "import os\n",
    "import cv2\n",
    "import pickle\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataPath = \"../../data/OCT/OCT2017/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of Classes Detected : 4\n"
     ]
    }
   ],
   "source": [
    "labels_available = os.listdir(os.path.join(dataPath, \"train\"))\n",
    "print(\"Total Number of Classes Detected :\",len(labels_available))\n",
    "\n",
    "labels_list = ['NORMAL',\"CNV\",\"DME\",\"DRUSEN\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NORMAL CNV DME DRUSEN "
     ]
    }
   ],
   "source": [
    "images=[]\n",
    "y_trn=[]\n",
    "for x in labels_list:\n",
    "    xPath = os.path.join(dataPath, \"train\", x)\n",
    "    myPicList = os.listdir(xPath)\n",
    "    for y in myPicList:\n",
    "        images.append(cv2.imread(os.path.join(xPath, y)))\n",
    "        y_trn.append(labels_list.index(x))\n",
    "    print(x ,end=\" \")\n",
    "\n",
    "y_train = to_categorical(y_trn,len(labels_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NORMAL CNV DME DRUSEN "
     ]
    }
   ],
   "source": [
    "x_val=[]\n",
    "y_val=[]\n",
    "for x in labels_list:\n",
    "    xPath = os.path.join(dataPath, \"val\", x)\n",
    "    myPicList = os.listdir(xPath)\n",
    "    for y in myPicList:\n",
    "        x_val.append(cv2.imread(os.path.join(xPath, y)))\n",
    "        y_val.append(labels_list.index(x))\n",
    "    print(x ,end=\" \")\n",
    "\n",
    "y_validation = to_categorical(y_val,len(labels_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NORMAL CNV DME DRUSEN "
     ]
    }
   ],
   "source": [
    "x_tst=[]\n",
    "y_tst=[]\n",
    "for x in labels_list:\n",
    "    xPath = os.path.join(dataPath, \"test\", x)\n",
    "    myPicList = os.listdir(xPath)\n",
    "    for y in myPicList:\n",
    "        x_tst.append(cv2.imread(os.path.join(xPath, y)))\n",
    "        y_tst.append(labels_list.index(x))\n",
    "    print(x ,end=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resizeIm(im, size):\n",
    "    if im.shape[2] == 1:\n",
    "        im = cv2.cvtColor(im,cv2.COLOR_GRAY2RGB)\n",
    "    return cv2.resize(im, size)\n",
    "\n",
    "def resizeIms(x, size):\n",
    "    return np.array(list(map(lambda im: resizeIm(im, size), x)))\n",
    "\n",
    "# Substract the mean specified by Mean (https://www.mathworks.com/help/deeplearning/ref/nnet.cnn.layer.imageinputlayer.html)\n",
    "# Substract mean by channel\n",
    "def zerocenter(x):\n",
    "    return (x - np.mean(x, axis=(0, 1))) / (2*np.std(x, axis=(0, 1)))\n",
    "\n",
    "# Rescale the input to be in the range [-1, 1] using the minimum and maximum values specified by Min and Max, respectively. (https://www.mathworks.com/help/deeplearning/ref/nnet.cnn.layer.imageinputlayer.html)\n",
    "# Compute using the formula: $x\\prime = 2 * \\frac{x - \\min{x}}{\\max{x} - \\min{x}} - 1$ taken from: https://stats.stackexchange.com/a/178629\n",
    "def rescaleSymmetric(x):\n",
    "    x = zerocenter(x)\n",
    "    return 2 * (x - np.min(x, axis=(0, 1)))/np.ptp(x, axis=(0, 1)) - 1\n",
    "\n",
    "def normalizeIms(x, normalization):\n",
    "    if normalization == \"zerocenter\":\n",
    "        func = zerocenter\n",
    "    elif normalization == \"rescale-symmetric\":\n",
    "        func = rescaleSymmetric\n",
    "    else:\n",
    "        return x\n",
    "    return np.array(list(map(lambda im: func(im), x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self,fraction, model):\n",
    "        super(CustomCallback,self).__init__()\n",
    "        self.fraction = fraction\n",
    "        self.train_a = [];\n",
    "        self.val_a =[];\n",
    "        self.logPath = os.path.join(model, \"log.txt\")\n",
    "\n",
    "        if not os.path.isdir(model):\n",
    "            os.mkdir(model)\n",
    "\n",
    "        with open(self.logPath,'w') as f:\n",
    "            f.write('Starting of logging..\\n')\n",
    "\n",
    "        self.fig = plt.figure(figsize=(4,3))\n",
    "        self.ax = plt.subplot(1,1,1)\n",
    "        plt.ion()\n",
    "\n",
    "    def on_train_begin(self,logs=None):\n",
    "        self.fig.show()\n",
    "        self.fig.canvas.draw()\n",
    "\n",
    "    def on_train_end(self,logs=None):\n",
    "        with open(self.logPath,'a') as f:\n",
    "              f.write('End of logging..\\n')\n",
    "    \n",
    "    def on_epoch_begin(self,epoch,logs=None):\n",
    "        lr= tf.keras.backend.get_value(self.model.optimizer.lr)\n",
    "        lr *= self.fraction\n",
    "        tf.keras.backend.set_value(self.model.optimizer.lr,lr)\n",
    "        with open(self.logPath,'a') as f:\n",
    "            f.write('At epoch {:02d}, learning rate changed to {:.4f}\\n'.format(epoch,lr))\n",
    "    \n",
    "    def on_epoch_end(self,epoch,logs=None):\n",
    "        val_acc = logs.get('val_accuracy')\n",
    "        train_acc = logs.get('accuracy')\n",
    "        self.train_a.append(train_acc)\n",
    "        self.val_a.append(val_acc)\n",
    "        with open(self.logPath,'a') as f:\n",
    "            f.write('At epoch {:02d}, training accuracy: {:.3f}, validation accuracy: {:.3f}\\n'.format(epoch,train_acc,val_acc))\n",
    "        self.ax.clear()\n",
    "        self.ax.plot(range(1+epoch),self.train_a,label=\"Training\")\n",
    "        self.ax.plot(range(1+epoch),self.val_a,label=\"Validation\")\n",
    "        self.ax.set_xlabel('Epochs')\n",
    "        self.ax.set_ylabel('Accuracy')\n",
    "        self.ax.legend()\n",
    "        self.fig.canvas.draw()\n",
    "        self.fig.show()\n",
    "        \n",
    "class TimeHistory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.times = []\n",
    "\n",
    "    def on_epoch_begin(self, batch, logs={}):\n",
    "        self.epoch_time_start = time.time()\n",
    "\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.times.append(time.time() - self.epoch_time_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "# xception base model\n",
    "#from tensorflow.keras.applications.xception import Xception\n",
    "#from tensorflow.keras.applications.xception import preprocess_input, decode_predictions\n",
    "#xceptionNetModel = Xception(weights='imagenet')\n",
    "#xceptionNetModel.save(\"../Xception.hdf5\")\n",
    "\n",
    "xceptionNetModel = tf.keras.models.load_model('../Xception.hdf5')\n",
    "\n",
    "# opticnet base model\n",
    "opticNetModel = tf.keras.models.load_model('../Optic_net-4_classes-Kermany2018.hdf5')\n",
    "\n",
    "# resnet base model\n",
    "#from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "#from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "#resNetModel = ResNet50(weights='imagenet')\n",
    "#resNetModel.save(\"../Resnet50.hdf5\")\n",
    "\n",
    "resNetModel = tf.keras.models.load_model('../Resnet50.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emptyModelGenerator(model, newWeights=False, lastOnly=False):\n",
    "    model = model.lower() # lower case model name\n",
    "    if model == \"resnet\":\n",
    "        x = resNetModel.output\n",
    "        predictions = Dense(len(labels_list), activation='softmax')(x)\n",
    "        newModel = Model(inputs=resNetModel.input, outputs=predictions)\n",
    "        size = (224, 224)\n",
    "        normalization = \"zerocenter\"\n",
    "    elif model == \"xception\":\n",
    "        x = xceptionNetModel.output\n",
    "        predictions = Dense(len(labels_list), activation='softmax')(x)\n",
    "        newModel = Model(inputs=xceptionNetModel.input, outputs=predictions)\n",
    "        size = (299, 299)\n",
    "        normalization = \"rescale-symmetric\"\n",
    "    elif model == \"opticnet\":\n",
    "        newModel = tf.keras.models.load_model('../Optic_net-4_classes-Kermany2018.hdf5')\n",
    "        size = (224, 224)\n",
    "        normalization = \"rescale-symmetric\"\n",
    "    if newWeights:\n",
    "        newModel = tf.keras.models.clone_model(newModel)\n",
    "    if lastOnly:\n",
    "        newModel = lastDenseTrainable(newModel) # block all layer except the last dense ones\n",
    "    else:\n",
    "        newModel.trainable = True\n",
    "    return newModel, size, normalization\n",
    "\n",
    "\n",
    "def lastDenseTrainable(model):\n",
    "    model.trainable = False\n",
    "    for i in range(1, len(model.layers)):\n",
    "        if model.layers[-i].__class__.__name__ == \"Dense\":\n",
    "            model.layers[-i].trainable= True\n",
    "        elif model.layers[-i].__class__.__name__ == \"Activation\":\n",
    "            continue\n",
    "        else:\n",
    "            break\n",
    "    return model\n",
    "    \n",
    "\n",
    "def testPredict(model, size, name=None, normalization=None):\n",
    "    X_test = resizeIms(x_tst, size)\n",
    "    if normalization:\n",
    "        X_test = normalizeIms(X_test, normalization)\n",
    "    X_test = np.array(X_test)\n",
    "    Y_test = np.array(y_tst)\n",
    "    \n",
    "    prediction = model.predict(X_test)\n",
    "    preds = np.argmax(prediction, axis=1)\n",
    "    acc = sum(preds == Y_test) / len(Y_test)\n",
    "    print(f'Test acc for {name if name else \"model\"}: {acc:.6f}')\n",
    "    return acc\n",
    "    \n",
    "\n",
    "def computeConfussionMatrix(predictions, labels):\n",
    "    num_labels = len(labels_list)\n",
    "    cMatrix = np.zeros(shape=(num_labels, num_labels))\n",
    "    for i in len(predictions):\n",
    "        p = int(predictions[i])\n",
    "        t = int(predictions[i])\n",
    "        cMatrix[t, p] += 1\n",
    "    print(cMatrix)\n",
    "    ax = sns.heatmap(cMatrix, cmap=\"Blues\", annot=True, fmt=\"d\", xticklabels=labels_list, yticklabels=labels_list)\n",
    "    plt.xlabel(\"Predicted label\")\n",
    "    plt.ylabel(\"True label\")\n",
    "    plt.title(\"Confusion matrix\")\n",
    "    plt.show();\n",
    "    return cMatrix\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "**************************************************\n",
      "Model: xception\n",
      "**************************************************\n",
      "\n",
      "Total: 135 trainable: 2\n",
      "\n",
      "\n",
      "**************************************************\n",
      "Model: resnet\n",
      "**************************************************\n",
      "\n",
      "Total: 178 trainable: 2\n",
      "\n",
      "\n",
      "**************************************************\n",
      "Model: opticnet\n",
      "**************************************************\n",
      "\n",
      "Total: 276 trainable: 2\n"
     ]
    }
   ],
   "source": [
    "models = [\"xception\", \"resnet\", \"opticnet\"]\n",
    "\n",
    "def printTrainableLayers(m):\n",
    "    a = 0\n",
    "    for l in m.layers:\n",
    "        #l.trainable = True\n",
    "        if l.trainable:\n",
    "            #print(l.name, l.trainable)\n",
    "            a += 1\n",
    "    print(f\"\\nTotal: {len(m.layers)} trainable: {a}\")\n",
    "\n",
    "for mod in models:\n",
    "    print(\"\\n\\n\" + (\"*\"*50) + \"\\nModel: \" + mod + '\\n' + (\"*\"*50))\n",
    "    m = emptyModelGenerator(mod, newWeights=False, lastOnly=True)[0]\n",
    "    printTrainableLayers(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "momentum = 0.5\n",
    "optim = lambda lr: Adam(learning_rate=lr)\n",
    "#optim = SGD(learning_rate=lr, momentum=momentum)\n",
    "epochs = 30\n",
    "batch_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "results = pd.read_csv(\"Results.csv\")\n",
    "results[\"normalization\"] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pandas as pd\n",
    "#res = pd.read_csv(\"Results_temp.csv\")\n",
    "#res.to_csv(\"Results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels fraction: [0.0101463  0.00983739 0.01039831 0.00963324]\n",
      "Training xception for 0.01% of train size (aka 834 images) with pretrained: False and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 135 trainable: 135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      " 6/17 [=========>....................] - ETA: 11s - loss: 1.3826 - accuracy: 0.3193WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1617s vs `on_train_batch_begin` time: 0.1936s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1617s vs `on_train_batch_end` time: 0.5478s). Check your callbacks.\n",
      "17/17 [==============================] - 32s 1s/step - loss: 1.3735 - accuracy: 0.4018 - val_loss: 1.3866 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "17/17 [==============================] - 12s 732ms/step - loss: 1.3274 - accuracy: 0.6778 - val_loss: 1.3871 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "17/17 [==============================] - 13s 738ms/step - loss: 1.3108 - accuracy: 0.6651 - val_loss: 1.3877 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "17/17 [==============================] - 13s 740ms/step - loss: 1.2871 - accuracy: 0.6923 - val_loss: 1.3884 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "17/17 [==============================] - 13s 737ms/step - loss: 1.2738 - accuracy: 0.6888 - val_loss: 1.3891 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "17/17 [==============================] - 13s 745ms/step - loss: 1.2502 - accuracy: 0.7170 - val_loss: 1.3899 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "17/17 [==============================] - 13s 752ms/step - loss: 1.2562 - accuracy: 0.6893 - val_loss: 1.3906 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "17/17 [==============================] - 13s 751ms/step - loss: 1.2323 - accuracy: 0.7339 - val_loss: 1.3915 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "17/17 [==============================] - 13s 745ms/step - loss: 1.2284 - accuracy: 0.7262 - val_loss: 1.3922 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "17/17 [==============================] - 13s 754ms/step - loss: 1.2205 - accuracy: 0.7292 - val_loss: 1.3931 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "17/17 [==============================] - 13s 749ms/step - loss: 1.2088 - accuracy: 0.7449 - val_loss: 1.3940 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "17/17 [==============================] - 13s 751ms/step - loss: 1.2194 - accuracy: 0.7071 - val_loss: 1.3953 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "17/17 [==============================] - 13s 752ms/step - loss: 1.1917 - accuracy: 0.7588 - val_loss: 1.3968 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "17/17 [==============================] - 13s 757ms/step - loss: 1.1972 - accuracy: 0.7386 - val_loss: 1.3979 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "17/17 [==============================] - 13s 767ms/step - loss: 1.1943 - accuracy: 0.7346 - val_loss: 1.3992 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "17/17 [==============================] - 13s 763ms/step - loss: 1.1783 - accuracy: 0.7592 - val_loss: 1.4016 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "17/17 [==============================] - 13s 764ms/step - loss: 1.1817 - accuracy: 0.7457 - val_loss: 1.4040 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "17/17 [==============================] - 13s 753ms/step - loss: 1.1822 - accuracy: 0.7426 - val_loss: 1.4064 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "17/17 [==============================] - 13s 760ms/step - loss: 1.1753 - accuracy: 0.7466 - val_loss: 1.4080 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "17/17 [==============================] - 13s 760ms/step - loss: 1.1655 - accuracy: 0.7626 - val_loss: 1.4097 - val_accuracy: 0.2188\n",
      "Epoch 21/30\n",
      "17/17 [==============================] - 13s 751ms/step - loss: 1.1634 - accuracy: 0.7590 - val_loss: 1.4108 - val_accuracy: 0.2188\n",
      "Epoch 22/30\n",
      "17/17 [==============================] - 13s 775ms/step - loss: 1.1766 - accuracy: 0.7345 - val_loss: 1.4111 - val_accuracy: 0.2188\n",
      "Epoch 23/30\n",
      "17/17 [==============================] - 13s 757ms/step - loss: 1.1700 - accuracy: 0.7430 - val_loss: 1.4131 - val_accuracy: 0.1250\n",
      "Epoch 24/30\n",
      "17/17 [==============================] - 13s 756ms/step - loss: 1.1665 - accuracy: 0.7469 - val_loss: 1.4130 - val_accuracy: 0.1250\n",
      "Epoch 25/30\n",
      "17/17 [==============================] - 13s 766ms/step - loss: 1.1370 - accuracy: 0.7925 - val_loss: 1.4128 - val_accuracy: 0.2188\n",
      "Epoch 26/30\n",
      "17/17 [==============================] - 13s 756ms/step - loss: 1.1633 - accuracy: 0.7441 - val_loss: 1.4133 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "17/17 [==============================] - 13s 758ms/step - loss: 1.1543 - accuracy: 0.7565 - val_loss: 1.4117 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "17/17 [==============================] - 13s 766ms/step - loss: 1.1481 - accuracy: 0.7656 - val_loss: 1.4122 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "17/17 [==============================] - 13s 759ms/step - loss: 1.1562 - accuracy: 0.7549 - val_loss: 1.4134 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "17/17 [==============================] - 13s 761ms/step - loss: 1.1443 - accuracy: 0.7717 - val_loss: 1.4083 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../xception/xception_30epochs_834.84_images_True_newWeights_False_lastLayerOnly_rescale-symmetric_normalization/assets\n",
      "Test acc for xception: 0.264463\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training resnet for 0.01% of train size (aka 834 images) with pretrained: False and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 178 trainable: 178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      " 6/17 [=========>....................] - ETA: 7s - loss: 1.3811 - accuracy: 0.2342WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1009s vs `on_train_batch_begin` time: 0.1672s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1009s vs `on_train_batch_end` time: 0.3125s). Check your callbacks.\n",
      "17/17 [==============================] - 16s 513ms/step - loss: 1.3691 - accuracy: 0.2756 - val_loss: 1.3889 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "17/17 [==============================] - 3s 196ms/step - loss: 1.3459 - accuracy: 0.3008 - val_loss: 1.3901 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "17/17 [==============================] - 3s 196ms/step - loss: 1.3315 - accuracy: 0.4240 - val_loss: 1.3957 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "17/17 [==============================] - 3s 197ms/step - loss: 1.3194 - accuracy: 0.4532 - val_loss: 1.3967 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "17/17 [==============================] - 3s 197ms/step - loss: 1.3176 - accuracy: 0.4347 - val_loss: 1.3999 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "17/17 [==============================] - 3s 197ms/step - loss: 1.3148 - accuracy: 0.4305 - val_loss: 1.4027 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "17/17 [==============================] - 3s 197ms/step - loss: 1.3018 - accuracy: 0.4509 - val_loss: 1.4053 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "17/17 [==============================] - 3s 197ms/step - loss: 1.3066 - accuracy: 0.4203 - val_loss: 1.4075 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "17/17 [==============================] - 3s 197ms/step - loss: 1.3006 - accuracy: 0.4385 - val_loss: 1.4096 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "17/17 [==============================] - 3s 198ms/step - loss: 1.2965 - accuracy: 0.4401 - val_loss: 1.4114 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "17/17 [==============================] - 3s 197ms/step - loss: 1.2864 - accuracy: 0.4553 - val_loss: 1.4131 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "17/17 [==============================] - 3s 197ms/step - loss: 1.2906 - accuracy: 0.4513 - val_loss: 1.4145 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "17/17 [==============================] - 3s 200ms/step - loss: 1.2844 - accuracy: 0.4480 - val_loss: 1.4159 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "17/17 [==============================] - 3s 197ms/step - loss: 1.2835 - accuracy: 0.4347 - val_loss: 1.4171 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "17/17 [==============================] - 3s 198ms/step - loss: 1.2840 - accuracy: 0.4420 - val_loss: 1.4182 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "17/17 [==============================] - 3s 198ms/step - loss: 1.2766 - accuracy: 0.4276 - val_loss: 1.4193 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "17/17 [==============================] - 3s 197ms/step - loss: 1.2867 - accuracy: 0.4312 - val_loss: 1.4201 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "17/17 [==============================] - 3s 197ms/step - loss: 1.2775 - accuracy: 0.4484 - val_loss: 1.4210 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "17/17 [==============================] - 3s 199ms/step - loss: 1.2785 - accuracy: 0.4302 - val_loss: 1.4218 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "17/17 [==============================] - 3s 197ms/step - loss: 1.2774 - accuracy: 0.4409 - val_loss: 1.4224 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "17/17 [==============================] - 3s 198ms/step - loss: 1.2696 - accuracy: 0.4597 - val_loss: 1.4231 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "17/17 [==============================] - 3s 197ms/step - loss: 1.2705 - accuracy: 0.4300 - val_loss: 1.4236 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "17/17 [==============================] - 3s 198ms/step - loss: 1.2779 - accuracy: 0.4356 - val_loss: 1.4241 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "17/17 [==============================] - 3s 199ms/step - loss: 1.2715 - accuracy: 0.4307 - val_loss: 1.4246 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "17/17 [==============================] - 3s 197ms/step - loss: 1.2805 - accuracy: 0.4307 - val_loss: 1.4250 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "17/17 [==============================] - 3s 197ms/step - loss: 1.2797 - accuracy: 0.4318 - val_loss: 1.4253 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "17/17 [==============================] - 3s 198ms/step - loss: 1.2695 - accuracy: 0.4493 - val_loss: 1.4257 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "17/17 [==============================] - 3s 198ms/step - loss: 1.2637 - accuracy: 0.4405 - val_loss: 1.4260 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "17/17 [==============================] - 3s 198ms/step - loss: 1.2866 - accuracy: 0.4185 - val_loss: 1.4263 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "17/17 [==============================] - 3s 197ms/step - loss: 1.2866 - accuracy: 0.4081 - val_loss: 1.4265 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_834.84_images_True_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training opticnet for 0.01% of train size (aka 834 images) with pretrained: False and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 276 trainable: 276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      " 6/17 [=========>....................] - ETA: 20s - loss: 20.9519 - accuracy: 0.2453WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.4648s vs `on_train_batch_end` time: 0.9808s). Check your callbacks.\n",
      "17/17 [==============================] - 48s 2s/step - loss: 19.1608 - accuracy: 0.2992 - val_loss: 84.3053 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "17/17 [==============================] - 20s 1s/step - loss: 3.1693 - accuracy: 0.3416 - val_loss: 4.9285 - val_accuracy: 0.2812\n",
      "Epoch 3/30\n",
      "17/17 [==============================] - 20s 1s/step - loss: 1.8072 - accuracy: 0.3235 - val_loss: 3.1466 - val_accuracy: 0.3125\n",
      "Epoch 4/30\n",
      "17/17 [==============================] - 20s 1s/step - loss: 1.4709 - accuracy: 0.3709 - val_loss: 1.5989 - val_accuracy: 0.2188\n",
      "Epoch 5/30\n",
      "17/17 [==============================] - 20s 1s/step - loss: 1.2390 - accuracy: 0.4805 - val_loss: 1.6322 - val_accuracy: 0.2188\n",
      "Epoch 6/30\n",
      "17/17 [==============================] - 20s 1s/step - loss: 1.1638 - accuracy: 0.5096 - val_loss: 1.5875 - val_accuracy: 0.2812\n",
      "Epoch 7/30\n",
      "17/17 [==============================] - 20s 1s/step - loss: 1.1444 - accuracy: 0.5418 - val_loss: 1.4786 - val_accuracy: 0.4375\n",
      "Epoch 8/30\n",
      "17/17 [==============================] - 20s 1s/step - loss: 1.0352 - accuracy: 0.5948 - val_loss: 1.2951 - val_accuracy: 0.5938\n",
      "Epoch 9/30\n",
      "17/17 [==============================] - 20s 1s/step - loss: 1.0761 - accuracy: 0.5889 - val_loss: 1.3357 - val_accuracy: 0.3125\n",
      "Epoch 10/30\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.9061 - accuracy: 0.6695 - val_loss: 1.5469 - val_accuracy: 0.3125\n",
      "Epoch 11/30\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.8248 - accuracy: 0.7085 - val_loss: 1.4507 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.6996 - accuracy: 0.7396 - val_loss: 1.5949 - val_accuracy: 0.3125\n",
      "Epoch 13/30\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.5814 - accuracy: 0.7780 - val_loss: 1.6165 - val_accuracy: 0.3125\n",
      "Epoch 14/30\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.6181 - accuracy: 0.7756 - val_loss: 1.1751 - val_accuracy: 0.4375\n",
      "Epoch 15/30\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.4924 - accuracy: 0.7927 - val_loss: 1.6421 - val_accuracy: 0.4062\n",
      "Epoch 16/30\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.4062 - accuracy: 0.8463 - val_loss: 1.8589 - val_accuracy: 0.2812\n",
      "Epoch 17/30\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.3411 - accuracy: 0.8698 - val_loss: 1.0688 - val_accuracy: 0.6250\n",
      "Epoch 18/30\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2816 - accuracy: 0.8897 - val_loss: 2.0462 - val_accuracy: 0.4375\n",
      "Epoch 19/30\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2677 - accuracy: 0.8905 - val_loss: 1.3880 - val_accuracy: 0.4375\n",
      "Epoch 20/30\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.1857 - accuracy: 0.9211 - val_loss: 1.7920 - val_accuracy: 0.5000\n",
      "Epoch 21/30\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.1460 - accuracy: 0.9512 - val_loss: 1.5184 - val_accuracy: 0.5625\n",
      "Epoch 22/30\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.1236 - accuracy: 0.9491 - val_loss: 3.6293 - val_accuracy: 0.3125\n",
      "Epoch 23/30\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.1029 - accuracy: 0.9580 - val_loss: 2.2743 - val_accuracy: 0.3438\n",
      "Epoch 24/30\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.0864 - accuracy: 0.9760 - val_loss: 1.0715 - val_accuracy: 0.7188\n",
      "Epoch 25/30\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.0684 - accuracy: 0.9870 - val_loss: 1.5847 - val_accuracy: 0.6250\n",
      "Epoch 26/30\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.0443 - accuracy: 0.9914 - val_loss: 1.7862 - val_accuracy: 0.5312\n",
      "Epoch 27/30\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.0307 - accuracy: 0.9950 - val_loss: 1.9269 - val_accuracy: 0.5625\n",
      "Epoch 28/30\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.0246 - accuracy: 0.9982 - val_loss: 1.9856 - val_accuracy: 0.5312\n",
      "Epoch 29/30\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.0156 - accuracy: 1.0000 - val_loss: 2.0190 - val_accuracy: 0.5625\n",
      "Epoch 30/30\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.0177 - accuracy: 0.9978 - val_loss: 2.0534 - val_accuracy: 0.5938\n",
      "INFO:tensorflow:Assets written to: ../opticnet/opticnet_30epochs_834.84_images_True_newWeights_False_lastLayerOnly_rescale-symmetric_normalization/assets\n",
      "Test acc for opticnet: 0.564050\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.02451074 0.02513103 0.02467395 0.02634633]\n",
      "Training xception for 0.025% of train size (aka 2087 images) with pretrained: False and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 135 trainable: 135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      " 6/42 [===>..........................] - ETA: 47s - loss: 1.3839 - accuracy: 0.2980WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1603s vs `on_train_batch_begin` time: 0.2069s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1603s vs `on_train_batch_end` time: 0.8412s). Check your callbacks.\n",
      "42/42 [==============================] - 43s 899ms/step - loss: 1.3563 - accuracy: 0.4932 - val_loss: 1.3875 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "42/42 [==============================] - 32s 766ms/step - loss: 1.2854 - accuracy: 0.6873 - val_loss: 1.3896 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "42/42 [==============================] - 33s 780ms/step - loss: 1.2441 - accuracy: 0.7059 - val_loss: 1.3930 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "42/42 [==============================] - 32s 755ms/step - loss: 1.2099 - accuracy: 0.7111 - val_loss: 1.4016 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "42/42 [==============================] - 32s 755ms/step - loss: 1.1755 - accuracy: 0.7292 - val_loss: 1.4136 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "42/42 [==============================] - 32s 759ms/step - loss: 1.1568 - accuracy: 0.7290 - val_loss: 1.4147 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "42/42 [==============================] - 32s 762ms/step - loss: 1.1305 - accuracy: 0.7388 - val_loss: 1.4076 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "42/42 [==============================] - 32s 765ms/step - loss: 1.0999 - accuracy: 0.7551 - val_loss: 1.4043 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "42/42 [==============================] - 32s 767ms/step - loss: 1.1075 - accuracy: 0.7193 - val_loss: 1.4050 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "42/42 [==============================] - 32s 762ms/step - loss: 1.0788 - accuracy: 0.7223 - val_loss: 1.3639 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "42/42 [==============================] - 32s 767ms/step - loss: 1.0506 - accuracy: 0.7493 - val_loss: 1.2250 - val_accuracy: 0.5000\n",
      "Epoch 12/30\n",
      "42/42 [==============================] - 32s 765ms/step - loss: 1.0360 - accuracy: 0.7452 - val_loss: 1.2900 - val_accuracy: 0.5000\n",
      "Epoch 13/30\n",
      "42/42 [==============================] - 32s 766ms/step - loss: 1.0377 - accuracy: 0.7143 - val_loss: 1.2752 - val_accuracy: 0.4375\n",
      "Epoch 14/30\n",
      "42/42 [==============================] - 32s 764ms/step - loss: 1.0087 - accuracy: 0.7486 - val_loss: 1.2263 - val_accuracy: 0.4688\n",
      "Epoch 15/30\n",
      "42/42 [==============================] - 32s 762ms/step - loss: 1.0068 - accuracy: 0.7329 - val_loss: 1.2936 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "42/42 [==============================] - 32s 763ms/step - loss: 0.9772 - accuracy: 0.7556 - val_loss: 1.3842 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "42/42 [==============================] - 32s 758ms/step - loss: 0.9765 - accuracy: 0.7321 - val_loss: 1.3003 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "42/42 [==============================] - 33s 779ms/step - loss: 0.9733 - accuracy: 0.7391 - val_loss: 1.2497 - val_accuracy: 0.3438\n",
      "Epoch 19/30\n",
      "42/42 [==============================] - 33s 783ms/step - loss: 0.9621 - accuracy: 0.7401 - val_loss: 1.1579 - val_accuracy: 0.5000\n",
      "Epoch 20/30\n",
      "42/42 [==============================] - 32s 764ms/step - loss: 0.9567 - accuracy: 0.7388 - val_loss: 1.3474 - val_accuracy: 0.4062\n",
      "Epoch 21/30\n",
      "42/42 [==============================] - 32s 766ms/step - loss: 0.9610 - accuracy: 0.8249 - val_loss: 1.1355 - val_accuracy: 0.7500\n",
      "Epoch 22/30\n",
      "42/42 [==============================] - 32s 758ms/step - loss: 0.9341 - accuracy: 0.8553 - val_loss: 1.1813 - val_accuracy: 0.6875\n",
      "Epoch 23/30\n",
      "42/42 [==============================] - 32s 764ms/step - loss: 0.9200 - accuracy: 0.8682 - val_loss: 1.1530 - val_accuracy: 0.7188\n",
      "Epoch 24/30\n",
      "42/42 [==============================] - 32s 756ms/step - loss: 0.9305 - accuracy: 0.8630 - val_loss: 1.1279 - val_accuracy: 0.7500\n",
      "Epoch 25/30\n",
      "42/42 [==============================] - 33s 776ms/step - loss: 0.9213 - accuracy: 0.8625 - val_loss: 1.1257 - val_accuracy: 0.7500\n",
      "Epoch 26/30\n",
      "42/42 [==============================] - 32s 770ms/step - loss: 0.9130 - accuracy: 0.8702 - val_loss: 1.1297 - val_accuracy: 0.7500\n",
      "Epoch 27/30\n",
      "42/42 [==============================] - 32s 767ms/step - loss: 0.9162 - accuracy: 0.8614 - val_loss: 1.1344 - val_accuracy: 0.7188\n",
      "Epoch 28/30\n",
      "42/42 [==============================] - 32s 767ms/step - loss: 0.9043 - accuracy: 0.8756 - val_loss: 1.1457 - val_accuracy: 0.7188\n",
      "Epoch 29/30\n",
      "42/42 [==============================] - 32s 768ms/step - loss: 0.9113 - accuracy: 0.8683 - val_loss: 1.1193 - val_accuracy: 0.7500\n",
      "Epoch 30/30\n",
      "42/42 [==============================] - 32s 765ms/step - loss: 0.8965 - accuracy: 0.8807 - val_loss: 1.1154 - val_accuracy: 0.7500\n",
      "INFO:tensorflow:Assets written to: ../xception/xception_30epochs_2087.1_images_True_newWeights_False_lastLayerOnly_rescale-symmetric_normalization/assets\n",
      "Test acc for xception: 0.728306\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training resnet for 0.025% of train size (aka 2087 images) with pretrained: False and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 178 trainable: 178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      " 6/42 [===>..........................] - ETA: 28s - loss: 1.3782 - accuracy: 0.3372WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1072s vs `on_train_batch_begin` time: 0.2003s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1072s vs `on_train_batch_end` time: 0.3715s). Check your callbacks.\n",
      "42/42 [==============================] - 22s 329ms/step - loss: 1.3565 - accuracy: 0.4501 - val_loss: 1.3888 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "42/42 [==============================] - 8s 196ms/step - loss: 1.3076 - accuracy: 0.6323 - val_loss: 1.3999 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "42/42 [==============================] - 8s 197ms/step - loss: 1.2663 - accuracy: 0.6734 - val_loss: 1.4011 - val_accuracy: 0.2812\n",
      "Epoch 4/30\n",
      "42/42 [==============================] - 8s 197ms/step - loss: 1.2409 - accuracy: 0.6556 - val_loss: 1.4137 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "42/42 [==============================] - 8s 199ms/step - loss: 1.2077 - accuracy: 0.6845 - val_loss: 1.3642 - val_accuracy: 0.4375\n",
      "Epoch 6/30\n",
      "42/42 [==============================] - 8s 199ms/step - loss: 1.1900 - accuracy: 0.6918 - val_loss: 1.4257 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "42/42 [==============================] - 8s 200ms/step - loss: 1.1877 - accuracy: 0.6613 - val_loss: 1.4066 - val_accuracy: 0.3438\n",
      "Epoch 8/30\n",
      "42/42 [==============================] - 8s 198ms/step - loss: 1.1594 - accuracy: 0.6880 - val_loss: 1.3376 - val_accuracy: 0.5000\n",
      "Epoch 9/30\n",
      "42/42 [==============================] - 8s 199ms/step - loss: 1.1430 - accuracy: 0.7001 - val_loss: 1.3386 - val_accuracy: 0.5000\n",
      "Epoch 10/30\n",
      "42/42 [==============================] - 8s 200ms/step - loss: 1.1225 - accuracy: 0.7183 - val_loss: 1.4436 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "42/42 [==============================] - 8s 199ms/step - loss: 1.1113 - accuracy: 0.7037 - val_loss: 1.4096 - val_accuracy: 0.3125\n",
      "Epoch 12/30\n",
      "42/42 [==============================] - 8s 199ms/step - loss: 1.1084 - accuracy: 0.6890 - val_loss: 1.3550 - val_accuracy: 0.4375\n",
      "Epoch 13/30\n",
      "42/42 [==============================] - 8s 199ms/step - loss: 1.0988 - accuracy: 0.7173 - val_loss: 1.3486 - val_accuracy: 0.4688\n",
      "Epoch 14/30\n",
      "42/42 [==============================] - 8s 199ms/step - loss: 1.1011 - accuracy: 0.7117 - val_loss: 1.3401 - val_accuracy: 0.5000\n",
      "Epoch 15/30\n",
      "42/42 [==============================] - 8s 199ms/step - loss: 1.0812 - accuracy: 0.7180 - val_loss: 1.3706 - val_accuracy: 0.4062\n",
      "Epoch 16/30\n",
      "42/42 [==============================] - 8s 199ms/step - loss: 1.0884 - accuracy: 0.7089 - val_loss: 1.3324 - val_accuracy: 0.5000\n",
      "Epoch 17/30\n",
      "42/42 [==============================] - 8s 199ms/step - loss: 1.0776 - accuracy: 0.7151 - val_loss: 1.3339 - val_accuracy: 0.5000\n",
      "Epoch 18/30\n",
      "42/42 [==============================] - 8s 199ms/step - loss: 1.0777 - accuracy: 0.7187 - val_loss: 1.3125 - val_accuracy: 0.5000\n",
      "Epoch 19/30\n",
      "42/42 [==============================] - 8s 200ms/step - loss: 1.0489 - accuracy: 0.7419 - val_loss: 1.3051 - val_accuracy: 0.5000\n",
      "Epoch 20/30\n",
      "42/42 [==============================] - 8s 199ms/step - loss: 1.0653 - accuracy: 0.7058 - val_loss: 1.3528 - val_accuracy: 0.5000\n",
      "Epoch 21/30\n",
      "42/42 [==============================] - 8s 199ms/step - loss: 1.0400 - accuracy: 0.7376 - val_loss: 1.2940 - val_accuracy: 0.5000\n",
      "Epoch 22/30\n",
      "42/42 [==============================] - 8s 199ms/step - loss: 1.0493 - accuracy: 0.7240 - val_loss: 1.2822 - val_accuracy: 0.5000\n",
      "Epoch 23/30\n",
      "42/42 [==============================] - 8s 199ms/step - loss: 1.0458 - accuracy: 0.7238 - val_loss: 1.3239 - val_accuracy: 0.4688\n",
      "Epoch 24/30\n",
      "42/42 [==============================] - 8s 199ms/step - loss: 1.0365 - accuracy: 0.7298 - val_loss: 1.2723 - val_accuracy: 0.5000\n",
      "Epoch 25/30\n",
      "42/42 [==============================] - 8s 198ms/step - loss: 1.0298 - accuracy: 0.7426 - val_loss: 1.2836 - val_accuracy: 0.5000\n",
      "Epoch 26/30\n",
      "42/42 [==============================] - 8s 199ms/step - loss: 1.0352 - accuracy: 0.7317 - val_loss: 1.2530 - val_accuracy: 0.5000\n",
      "Epoch 27/30\n",
      "42/42 [==============================] - 8s 199ms/step - loss: 1.0394 - accuracy: 0.7159 - val_loss: 1.2601 - val_accuracy: 0.5000\n",
      "Epoch 28/30\n",
      "42/42 [==============================] - 8s 199ms/step - loss: 1.0390 - accuracy: 0.7213 - val_loss: 1.2674 - val_accuracy: 0.5000\n",
      "Epoch 29/30\n",
      "42/42 [==============================] - 8s 199ms/step - loss: 1.0079 - accuracy: 0.7528 - val_loss: 1.3746 - val_accuracy: 0.3750\n",
      "Epoch 30/30\n",
      "42/42 [==============================] - 8s 199ms/step - loss: 1.0143 - accuracy: 0.7401 - val_loss: 1.2746 - val_accuracy: 0.5000\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_2087.1_images_True_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.475207\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training opticnet for 0.025% of train size (aka 2087 images) with pretrained: False and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 276 trainable: 276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      " 6/42 [===>..........................] - ETA: 1:07 - loss: 22.7343 - accuracy: 0.2801WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.4661s vs `on_train_batch_end` time: 1.0695s). Check your callbacks.\n",
      "42/42 [==============================] - 71s 1s/step - loss: 10.1193 - accuracy: 0.3304 - val_loss: 2.9342 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "42/42 [==============================] - 49s 1s/step - loss: 1.5860 - accuracy: 0.4260 - val_loss: 2.2044 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "42/42 [==============================] - 49s 1s/step - loss: 1.1873 - accuracy: 0.5649 - val_loss: 1.8681 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "42/42 [==============================] - 49s 1s/step - loss: 1.0203 - accuracy: 0.6512 - val_loss: 1.3459 - val_accuracy: 0.3438\n",
      "Epoch 5/30\n",
      "42/42 [==============================] - 49s 1s/step - loss: 0.8671 - accuracy: 0.6842 - val_loss: 1.0535 - val_accuracy: 0.4688\n",
      "Epoch 6/30\n",
      "42/42 [==============================] - 49s 1s/step - loss: 0.8118 - accuracy: 0.7047 - val_loss: 2.3825 - val_accuracy: 0.2812\n",
      "Epoch 7/30\n",
      "42/42 [==============================] - 49s 1s/step - loss: 0.7389 - accuracy: 0.7258 - val_loss: 1.0124 - val_accuracy: 0.5312\n",
      "Epoch 8/30\n",
      "42/42 [==============================] - 49s 1s/step - loss: 0.7066 - accuracy: 0.7360 - val_loss: 0.9152 - val_accuracy: 0.5938\n",
      "Epoch 9/30\n",
      "42/42 [==============================] - 49s 1s/step - loss: 0.6066 - accuracy: 0.7782 - val_loss: 2.5752 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "42/42 [==============================] - 49s 1s/step - loss: 0.5255 - accuracy: 0.7988 - val_loss: 2.8086 - val_accuracy: 0.3750\n",
      "Epoch 11/30\n",
      "42/42 [==============================] - 49s 1s/step - loss: 0.4064 - accuracy: 0.8496 - val_loss: 6.8424 - val_accuracy: 0.3125\n",
      "Epoch 12/30\n",
      "42/42 [==============================] - 49s 1s/step - loss: 0.3512 - accuracy: 0.8795 - val_loss: 1.1206 - val_accuracy: 0.7500\n",
      "Epoch 13/30\n",
      "42/42 [==============================] - 49s 1s/step - loss: 0.2344 - accuracy: 0.9156 - val_loss: 1.4110 - val_accuracy: 0.5312\n",
      "Epoch 14/30\n",
      "42/42 [==============================] - 49s 1s/step - loss: 0.2202 - accuracy: 0.9123 - val_loss: 2.0189 - val_accuracy: 0.5312\n",
      "Epoch 15/30\n",
      "42/42 [==============================] - 49s 1s/step - loss: 0.1970 - accuracy: 0.9297 - val_loss: 1.2181 - val_accuracy: 0.6562\n",
      "Epoch 16/30\n",
      "42/42 [==============================] - 49s 1s/step - loss: 0.1087 - accuracy: 0.9603 - val_loss: 0.5534 - val_accuracy: 0.8125\n",
      "Epoch 17/30\n",
      "42/42 [==============================] - 49s 1s/step - loss: 0.0610 - accuracy: 0.9871 - val_loss: 1.0968 - val_accuracy: 0.7188\n",
      "Epoch 18/30\n",
      "42/42 [==============================] - 49s 1s/step - loss: 0.0317 - accuracy: 0.9927 - val_loss: 1.5563 - val_accuracy: 0.6875\n",
      "Epoch 19/30\n",
      "42/42 [==============================] - 49s 1s/step - loss: 0.0287 - accuracy: 0.9943 - val_loss: 0.7893 - val_accuracy: 0.8750\n",
      "Epoch 20/30\n",
      "42/42 [==============================] - 49s 1s/step - loss: 0.0124 - accuracy: 0.9977 - val_loss: 0.5161 - val_accuracy: 0.8750\n",
      "Epoch 21/30\n",
      "42/42 [==============================] - 49s 1s/step - loss: 0.0300 - accuracy: 0.9881 - val_loss: 0.4955 - val_accuracy: 0.8750\n",
      "Epoch 22/30\n",
      "42/42 [==============================] - 49s 1s/step - loss: 0.0314 - accuracy: 0.9892 - val_loss: 1.1113 - val_accuracy: 0.7812\n",
      "Epoch 23/30\n",
      "42/42 [==============================] - 49s 1s/step - loss: 0.0123 - accuracy: 0.9958 - val_loss: 0.7139 - val_accuracy: 0.8125\n",
      "Epoch 24/30\n",
      "42/42 [==============================] - 49s 1s/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.6433 - val_accuracy: 0.8438\n",
      "Epoch 25/30\n",
      "42/42 [==============================] - 49s 1s/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.6442 - val_accuracy: 0.8750\n",
      "Epoch 26/30\n",
      "42/42 [==============================] - 49s 1s/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.5437 - val_accuracy: 0.9062\n",
      "Epoch 27/30\n",
      "42/42 [==============================] - 49s 1s/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.5583 - val_accuracy: 0.8750\n",
      "Epoch 28/30\n",
      "42/42 [==============================] - 49s 1s/step - loss: 0.0045 - accuracy: 0.9993 - val_loss: 0.5235 - val_accuracy: 0.9062\n",
      "Epoch 29/30\n",
      "42/42 [==============================] - 49s 1s/step - loss: 0.0048 - accuracy: 0.9991 - val_loss: 0.4579 - val_accuracy: 0.9375\n",
      "Epoch 30/30\n",
      "42/42 [==============================] - 49s 1s/step - loss: 0.0040 - accuracy: 0.9983 - val_loss: 0.4908 - val_accuracy: 0.8750\n",
      "INFO:tensorflow:Assets written to: ../opticnet/opticnet_30epochs_2087.1_images_True_newWeights_False_lastLayerOnly_rescale-symmetric_normalization/assets\n",
      "Test acc for opticnet: 0.825413\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.0498575  0.04993952 0.05172718 0.04839833]\n",
      "Training xception for 0.05% of train size (aka 4174 images) with pretrained: False and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 135 trainable: 135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      " 6/84 [=>............................] - ETA: 1:43 - loss: 1.3824 - accuracy: 0.4576WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1634s vs `on_train_batch_begin` time: 0.2074s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1634s vs `on_train_batch_end` time: 0.8614s). Check your callbacks.\n",
      "84/84 [==============================] - 74s 817ms/step - loss: 1.3310 - accuracy: 0.5981 - val_loss: 1.3902 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "84/84 [==============================] - 65s 768ms/step - loss: 1.2294 - accuracy: 0.7073 - val_loss: 1.4140 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "84/84 [==============================] - 65s 769ms/step - loss: 1.1670 - accuracy: 0.7162 - val_loss: 1.4104 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "84/84 [==============================] - 65s 772ms/step - loss: 1.1007 - accuracy: 0.7438 - val_loss: 1.4443 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "84/84 [==============================] - 65s 769ms/step - loss: 1.0592 - accuracy: 0.7439 - val_loss: 1.5057 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "84/84 [==============================] - 65s 772ms/step - loss: 1.0043 - accuracy: 0.7694 - val_loss: 1.3338 - val_accuracy: 0.4375\n",
      "Epoch 7/30\n",
      "84/84 [==============================] - 64s 762ms/step - loss: 0.9666 - accuracy: 0.8094 - val_loss: 1.1831 - val_accuracy: 0.6562\n",
      "Epoch 8/30\n",
      "84/84 [==============================] - 65s 770ms/step - loss: 0.9350 - accuracy: 0.8255 - val_loss: 1.2435 - val_accuracy: 0.5625\n",
      "Epoch 9/30\n",
      "84/84 [==============================] - 65s 769ms/step - loss: 0.8905 - accuracy: 0.8465 - val_loss: 1.1152 - val_accuracy: 0.7188\n",
      "Epoch 10/30\n",
      "84/84 [==============================] - 64s 764ms/step - loss: 0.8601 - accuracy: 0.8463 - val_loss: 1.1266 - val_accuracy: 0.6875\n",
      "Epoch 11/30\n",
      "84/84 [==============================] - 64s 766ms/step - loss: 0.8425 - accuracy: 0.8540 - val_loss: 1.1050 - val_accuracy: 0.6875\n",
      "Epoch 12/30\n",
      "84/84 [==============================] - 64s 763ms/step - loss: 0.8154 - accuracy: 0.8624 - val_loss: 1.0758 - val_accuracy: 0.7188\n",
      "Epoch 13/30\n",
      "84/84 [==============================] - 64s 766ms/step - loss: 0.8247 - accuracy: 0.8472 - val_loss: 1.1646 - val_accuracy: 0.5938\n",
      "Epoch 14/30\n",
      "84/84 [==============================] - 64s 761ms/step - loss: 0.7911 - accuracy: 0.8643 - val_loss: 1.0415 - val_accuracy: 0.7500\n",
      "Epoch 15/30\n",
      "84/84 [==============================] - 64s 763ms/step - loss: 0.7794 - accuracy: 0.8659 - val_loss: 1.0167 - val_accuracy: 0.7500\n",
      "Epoch 16/30\n",
      "84/84 [==============================] - 64s 765ms/step - loss: 0.7749 - accuracy: 0.8642 - val_loss: 1.0497 - val_accuracy: 0.7188\n",
      "Epoch 17/30\n",
      "84/84 [==============================] - 64s 763ms/step - loss: 0.7567 - accuracy: 0.8656 - val_loss: 1.1005 - val_accuracy: 0.6875\n",
      "Epoch 18/30\n",
      "84/84 [==============================] - 65s 770ms/step - loss: 0.7528 - accuracy: 0.8690 - val_loss: 1.0367 - val_accuracy: 0.7188\n",
      "Epoch 19/30\n",
      "84/84 [==============================] - 64s 764ms/step - loss: 0.7299 - accuracy: 0.8794 - val_loss: 0.9980 - val_accuracy: 0.7500\n",
      "Epoch 20/30\n",
      "84/84 [==============================] - 64s 764ms/step - loss: 0.7269 - accuracy: 0.8808 - val_loss: 1.0289 - val_accuracy: 0.7188\n",
      "Epoch 21/30\n",
      "84/84 [==============================] - 65s 770ms/step - loss: 0.7182 - accuracy: 0.8809 - val_loss: 0.9859 - val_accuracy: 0.7500\n",
      "Epoch 22/30\n",
      "84/84 [==============================] - 64s 765ms/step - loss: 0.7226 - accuracy: 0.8746 - val_loss: 1.0103 - val_accuracy: 0.7188\n",
      "Epoch 23/30\n",
      "84/84 [==============================] - 65s 769ms/step - loss: 0.7021 - accuracy: 0.8866 - val_loss: 1.0190 - val_accuracy: 0.7188\n",
      "Epoch 24/30\n",
      "84/84 [==============================] - 65s 774ms/step - loss: 0.6872 - accuracy: 0.8932 - val_loss: 1.0064 - val_accuracy: 0.7188\n",
      "Epoch 25/30\n",
      "84/84 [==============================] - 64s 767ms/step - loss: 0.6970 - accuracy: 0.8877 - val_loss: 0.9747 - val_accuracy: 0.7500\n",
      "Epoch 26/30\n",
      "84/84 [==============================] - 65s 769ms/step - loss: 0.7045 - accuracy: 0.8777 - val_loss: 0.9727 - val_accuracy: 0.7500\n",
      "Epoch 27/30\n",
      "84/84 [==============================] - 65s 770ms/step - loss: 0.6866 - accuracy: 0.8849 - val_loss: 0.9711 - val_accuracy: 0.7500\n",
      "Epoch 28/30\n",
      "84/84 [==============================] - 64s 765ms/step - loss: 0.6805 - accuracy: 0.8902 - val_loss: 0.9628 - val_accuracy: 0.7500\n",
      "Epoch 29/30\n",
      "84/84 [==============================] - 64s 764ms/step - loss: 0.6660 - accuracy: 0.8964 - val_loss: 0.9612 - val_accuracy: 0.7500\n",
      "Epoch 30/30\n",
      "84/84 [==============================] - 64s 767ms/step - loss: 0.6825 - accuracy: 0.8859 - val_loss: 0.9598 - val_accuracy: 0.7500\n",
      "INFO:tensorflow:Assets written to: ../xception/xception_30epochs_4174.2_images_True_newWeights_False_lastLayerOnly_rescale-symmetric_normalization/assets\n",
      "Test acc for xception: 0.741736\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training resnet for 0.05% of train size (aka 4174 images) with pretrained: False and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 178 trainable: 178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      " 6/84 [=>............................] - ETA: 57s - loss: 1.3796 - accuracy: 0.3820 WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1062s vs `on_train_batch_begin` time: 0.2031s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1062s vs `on_train_batch_end` time: 0.3347s). Check your callbacks.\n",
      "84/84 [==============================] - 28s 255ms/step - loss: 1.3428 - accuracy: 0.5384 - val_loss: 1.3989 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "84/84 [==============================] - 17s 196ms/step - loss: 1.2619 - accuracy: 0.6451 - val_loss: 1.4134 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "84/84 [==============================] - 17s 197ms/step - loss: 1.1945 - accuracy: 0.6785 - val_loss: 1.3686 - val_accuracy: 0.4375\n",
      "Epoch 4/30\n",
      "84/84 [==============================] - 17s 197ms/step - loss: 1.1501 - accuracy: 0.6897 - val_loss: 1.4895 - val_accuracy: 0.2188\n",
      "Epoch 5/30\n",
      "84/84 [==============================] - 17s 198ms/step - loss: 1.1096 - accuracy: 0.7045 - val_loss: 1.4239 - val_accuracy: 0.3125\n",
      "Epoch 6/30\n",
      "84/84 [==============================] - 17s 198ms/step - loss: 1.0882 - accuracy: 0.6959 - val_loss: 1.4756 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "84/84 [==============================] - 17s 198ms/step - loss: 1.0430 - accuracy: 0.7219 - val_loss: 1.5016 - val_accuracy: 0.2812\n",
      "Epoch 8/30\n",
      "84/84 [==============================] - 17s 198ms/step - loss: 1.0146 - accuracy: 0.7245 - val_loss: 1.3396 - val_accuracy: 0.5000\n",
      "Epoch 9/30\n",
      "84/84 [==============================] - 17s 198ms/step - loss: 1.0189 - accuracy: 0.7045 - val_loss: 1.3332 - val_accuracy: 0.4375\n",
      "Epoch 10/30\n",
      "84/84 [==============================] - 17s 198ms/step - loss: 0.9822 - accuracy: 0.7257 - val_loss: 1.2775 - val_accuracy: 0.5000\n",
      "Epoch 11/30\n",
      "84/84 [==============================] - 17s 198ms/step - loss: 0.9615 - accuracy: 0.7361 - val_loss: 1.2899 - val_accuracy: 0.5000\n",
      "Epoch 12/30\n",
      "84/84 [==============================] - 17s 198ms/step - loss: 0.9497 - accuracy: 0.7316 - val_loss: 1.3027 - val_accuracy: 0.5000\n",
      "Epoch 13/30\n",
      "84/84 [==============================] - 17s 198ms/step - loss: 0.9463 - accuracy: 0.7219 - val_loss: 1.3033 - val_accuracy: 0.5000\n",
      "Epoch 14/30\n",
      "84/84 [==============================] - 17s 198ms/step - loss: 0.9239 - accuracy: 0.7281 - val_loss: 1.2998 - val_accuracy: 0.5000\n",
      "Epoch 15/30\n",
      "84/84 [==============================] - 17s 198ms/step - loss: 0.9079 - accuracy: 0.7403 - val_loss: 1.2689 - val_accuracy: 0.5000\n",
      "Epoch 16/30\n",
      "84/84 [==============================] - 17s 198ms/step - loss: 0.9048 - accuracy: 0.7235 - val_loss: 1.2215 - val_accuracy: 0.5000\n",
      "Epoch 17/30\n",
      "84/84 [==============================] - 17s 198ms/step - loss: 0.8988 - accuracy: 0.7295 - val_loss: 1.1578 - val_accuracy: 0.5000\n",
      "Epoch 18/30\n",
      "84/84 [==============================] - 17s 198ms/step - loss: 0.8828 - accuracy: 0.7252 - val_loss: 1.2041 - val_accuracy: 0.5000\n",
      "Epoch 19/30\n",
      "84/84 [==============================] - 17s 198ms/step - loss: 0.8720 - accuracy: 0.7341 - val_loss: 1.1601 - val_accuracy: 0.5000\n",
      "Epoch 20/30\n",
      "84/84 [==============================] - 17s 198ms/step - loss: 0.8721 - accuracy: 0.7245 - val_loss: 1.1593 - val_accuracy: 0.5000\n",
      "Epoch 21/30\n",
      "84/84 [==============================] - 17s 198ms/step - loss: 0.8638 - accuracy: 0.7213 - val_loss: 1.1978 - val_accuracy: 0.5000\n",
      "Epoch 22/30\n",
      "84/84 [==============================] - 17s 198ms/step - loss: 0.8523 - accuracy: 0.7352 - val_loss: 1.3848 - val_accuracy: 0.3438\n",
      "Epoch 23/30\n",
      "84/84 [==============================] - 17s 198ms/step - loss: 0.8542 - accuracy: 0.7247 - val_loss: 1.1477 - val_accuracy: 0.5000\n",
      "Epoch 24/30\n",
      "84/84 [==============================] - 17s 198ms/step - loss: 0.8440 - accuracy: 0.7315 - val_loss: 1.1317 - val_accuracy: 0.5000\n",
      "Epoch 25/30\n",
      "84/84 [==============================] - 17s 199ms/step - loss: 0.8287 - accuracy: 0.7448 - val_loss: 1.1250 - val_accuracy: 0.5000\n",
      "Epoch 26/30\n",
      "84/84 [==============================] - 17s 198ms/step - loss: 0.8481 - accuracy: 0.7185 - val_loss: 1.0970 - val_accuracy: 0.5000\n",
      "Epoch 27/30\n",
      "84/84 [==============================] - 17s 198ms/step - loss: 0.8275 - accuracy: 0.7350 - val_loss: 1.0845 - val_accuracy: 0.5000\n",
      "Epoch 28/30\n",
      "84/84 [==============================] - 17s 198ms/step - loss: 0.8372 - accuracy: 0.7248 - val_loss: 1.0993 - val_accuracy: 0.5000\n",
      "Epoch 29/30\n",
      "84/84 [==============================] - 17s 198ms/step - loss: 0.8221 - accuracy: 0.7294 - val_loss: 1.1288 - val_accuracy: 0.5000\n",
      "Epoch 30/30\n",
      "84/84 [==============================] - 17s 199ms/step - loss: 0.8182 - accuracy: 0.7316 - val_loss: 1.0996 - val_accuracy: 0.5000\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_4174.2_images_True_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.493802\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training opticnet for 0.05% of train size (aka 4174 images) with pretrained: False and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 276 trainable: 276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      " 6/84 [=>............................] - ETA: 2:26 - loss: 32.9266 - accuracy: 0.2863WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.4687s vs `on_train_batch_end` time: 1.0790s). Check your callbacks.\n",
      "84/84 [==============================] - 120s 1s/step - loss: 10.2900 - accuracy: 0.3610 - val_loss: 3.8275 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "84/84 [==============================] - 98s 1s/step - loss: 1.1302 - accuracy: 0.5902 - val_loss: 1.4888 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "84/84 [==============================] - 99s 1s/step - loss: 0.8223 - accuracy: 0.7087 - val_loss: 2.2661 - val_accuracy: 0.3125\n",
      "Epoch 4/30\n",
      "84/84 [==============================] - 99s 1s/step - loss: 0.6603 - accuracy: 0.7583 - val_loss: 1.3642 - val_accuracy: 0.4375\n",
      "Epoch 5/30\n",
      "84/84 [==============================] - 99s 1s/step - loss: 0.5237 - accuracy: 0.8215 - val_loss: 3.5475 - val_accuracy: 0.3125\n",
      "Epoch 6/30\n",
      "84/84 [==============================] - 99s 1s/step - loss: 0.4704 - accuracy: 0.8362 - val_loss: 1.4377 - val_accuracy: 0.5938\n",
      "Epoch 7/30\n",
      "84/84 [==============================] - 99s 1s/step - loss: 0.3848 - accuracy: 0.8662 - val_loss: 0.8981 - val_accuracy: 0.6875\n",
      "Epoch 8/30\n",
      "84/84 [==============================] - 99s 1s/step - loss: 0.3769 - accuracy: 0.8659 - val_loss: 0.5026 - val_accuracy: 0.7812\n",
      "Epoch 9/30\n",
      "84/84 [==============================] - 99s 1s/step - loss: 0.3089 - accuracy: 0.8858 - val_loss: 0.6134 - val_accuracy: 0.8125\n",
      "Epoch 10/30\n",
      "84/84 [==============================] - 99s 1s/step - loss: 0.2891 - accuracy: 0.8942 - val_loss: 3.3051 - val_accuracy: 0.4062\n",
      "Epoch 11/30\n",
      "84/84 [==============================] - 99s 1s/step - loss: 0.2354 - accuracy: 0.9169 - val_loss: 0.4480 - val_accuracy: 0.8438\n",
      "Epoch 12/30\n",
      "84/84 [==============================] - 99s 1s/step - loss: 0.1432 - accuracy: 0.9474 - val_loss: 0.6075 - val_accuracy: 0.7812\n",
      "Epoch 13/30\n",
      "84/84 [==============================] - 99s 1s/step - loss: 0.1117 - accuracy: 0.9621 - val_loss: 0.4166 - val_accuracy: 0.9062\n",
      "Epoch 14/30\n",
      "84/84 [==============================] - 99s 1s/step - loss: 0.0878 - accuracy: 0.9715 - val_loss: 0.8796 - val_accuracy: 0.8750\n",
      "Epoch 15/30\n",
      "84/84 [==============================] - 99s 1s/step - loss: 0.0641 - accuracy: 0.9753 - val_loss: 0.3631 - val_accuracy: 0.8438\n",
      "Epoch 16/30\n",
      "84/84 [==============================] - 99s 1s/step - loss: 0.0754 - accuracy: 0.9743 - val_loss: 0.2548 - val_accuracy: 0.8750\n",
      "Epoch 17/30\n",
      "84/84 [==============================] - 99s 1s/step - loss: 0.0232 - accuracy: 0.9919 - val_loss: 0.7235 - val_accuracy: 0.8750\n",
      "Epoch 18/30\n",
      "84/84 [==============================] - 99s 1s/step - loss: 0.0157 - accuracy: 0.9954 - val_loss: 0.5129 - val_accuracy: 0.9062\n",
      "Epoch 19/30\n",
      "84/84 [==============================] - 98s 1s/step - loss: 0.0107 - accuracy: 0.9975 - val_loss: 0.6290 - val_accuracy: 0.8750\n",
      "Epoch 20/30\n",
      "84/84 [==============================] - 98s 1s/step - loss: 0.0070 - accuracy: 0.9982 - val_loss: 0.6642 - val_accuracy: 0.9062\n",
      "Epoch 21/30\n",
      "84/84 [==============================] - 99s 1s/step - loss: 0.0127 - accuracy: 0.9954 - val_loss: 0.9355 - val_accuracy: 0.8750\n",
      "Epoch 22/30\n",
      "84/84 [==============================] - 99s 1s/step - loss: 0.0063 - accuracy: 0.9986 - val_loss: 0.5073 - val_accuracy: 0.9062\n",
      "Epoch 23/30\n",
      "84/84 [==============================] - 98s 1s/step - loss: 0.0031 - accuracy: 0.9998 - val_loss: 0.6023 - val_accuracy: 0.9062\n",
      "Epoch 24/30\n",
      "84/84 [==============================] - 98s 1s/step - loss: 0.0036 - accuracy: 0.9991 - val_loss: 0.5328 - val_accuracy: 0.9375\n",
      "Epoch 25/30\n",
      "84/84 [==============================] - 98s 1s/step - loss: 0.0021 - accuracy: 0.9999 - val_loss: 0.3641 - val_accuracy: 0.9375\n",
      "Epoch 26/30\n",
      "84/84 [==============================] - 98s 1s/step - loss: 0.0036 - accuracy: 0.9988 - val_loss: 0.5294 - val_accuracy: 0.9062\n",
      "Epoch 27/30\n",
      "84/84 [==============================] - 98s 1s/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4976 - val_accuracy: 0.9062\n",
      "Epoch 28/30\n",
      "84/84 [==============================] - 99s 1s/step - loss: 0.0014 - accuracy: 0.9995 - val_loss: 0.3992 - val_accuracy: 0.9062\n",
      "Epoch 29/30\n",
      "84/84 [==============================] - 98s 1s/step - loss: 0.0036 - accuracy: 0.9990 - val_loss: 0.4728 - val_accuracy: 0.9375\n",
      "Epoch 30/30\n",
      "84/84 [==============================] - 99s 1s/step - loss: 6.7845e-04 - accuracy: 1.0000 - val_loss: 0.5589 - val_accuracy: 0.9062\n",
      "INFO:tensorflow:Assets written to: ../opticnet/opticnet_30epochs_4174.2_images_True_newWeights_False_lastLayerOnly_rescale-symmetric_normalization/assets\n",
      "Test acc for opticnet: 0.909091\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.07376021 0.07496304 0.07701798 0.07625348]\n",
      "Training xception for 0.075% of train size (aka 6261 images) with pretrained: False and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 135 trainable: 135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/126 [>.............................] - ETA: 2:40 - loss: 1.3834 - accuracy: 0.3400WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1633s vs `on_train_batch_begin` time: 0.1964s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1633s vs `on_train_batch_end` time: 0.8766s). Check your callbacks.\n",
      "126/126 [==============================] - 107s 806ms/step - loss: 1.3220 - accuracy: 0.5788 - val_loss: 1.3964 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "126/126 [==============================] - 98s 774ms/step - loss: 1.1836 - accuracy: 0.7109 - val_loss: 1.4490 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "126/126 [==============================] - 97s 768ms/step - loss: 1.0936 - accuracy: 0.7384 - val_loss: 1.3420 - val_accuracy: 0.2812\n",
      "Epoch 4/30\n",
      "126/126 [==============================] - 97s 767ms/step - loss: 1.0268 - accuracy: 0.7336 - val_loss: 1.5019 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "126/126 [==============================] - 98s 780ms/step - loss: 0.9708 - accuracy: 0.7348 - val_loss: 1.3851 - val_accuracy: 0.4375\n",
      "Epoch 6/30\n",
      "126/126 [==============================] - 97s 770ms/step - loss: 0.9109 - accuracy: 0.7769 - val_loss: 1.3503 - val_accuracy: 0.4375\n",
      "Epoch 7/30\n",
      "126/126 [==============================] - 97s 771ms/step - loss: 0.8693 - accuracy: 0.8168 - val_loss: 1.0864 - val_accuracy: 0.6875\n",
      "Epoch 8/30\n",
      "126/126 [==============================] - 97s 768ms/step - loss: 0.8161 - accuracy: 0.8379 - val_loss: 1.2902 - val_accuracy: 0.5312\n",
      "Epoch 9/30\n",
      "126/126 [==============================] - 97s 773ms/step - loss: 0.7989 - accuracy: 0.8308 - val_loss: 1.0314 - val_accuracy: 0.7188\n",
      "Epoch 10/30\n",
      "126/126 [==============================] - 98s 776ms/step - loss: 0.7617 - accuracy: 0.8462 - val_loss: 1.1141 - val_accuracy: 0.6250\n",
      "Epoch 11/30\n",
      "126/126 [==============================] - 97s 767ms/step - loss: 0.7506 - accuracy: 0.8392 - val_loss: 1.0137 - val_accuracy: 0.7188\n",
      "Epoch 12/30\n",
      "126/126 [==============================] - 96s 765ms/step - loss: 0.7148 - accuracy: 0.8537 - val_loss: 0.9768 - val_accuracy: 0.7188\n",
      "Epoch 13/30\n",
      "126/126 [==============================] - 97s 769ms/step - loss: 0.7074 - accuracy: 0.8528 - val_loss: 0.9624 - val_accuracy: 0.7188\n",
      "Epoch 14/30\n",
      "126/126 [==============================] - 96s 763ms/step - loss: 0.6759 - accuracy: 0.8629 - val_loss: 0.9078 - val_accuracy: 0.7500\n",
      "Epoch 15/30\n",
      "126/126 [==============================] - 97s 769ms/step - loss: 0.6659 - accuracy: 0.8669 - val_loss: 0.9084 - val_accuracy: 0.7500\n",
      "Epoch 16/30\n",
      "126/126 [==============================] - 97s 772ms/step - loss: 0.6468 - accuracy: 0.8718 - val_loss: 0.8918 - val_accuracy: 0.7500\n",
      "Epoch 17/30\n",
      "126/126 [==============================] - 97s 769ms/step - loss: 0.6310 - accuracy: 0.8718 - val_loss: 0.9333 - val_accuracy: 0.7188\n",
      "Epoch 18/30\n",
      "126/126 [==============================] - 97s 766ms/step - loss: 0.6265 - accuracy: 0.8722 - val_loss: 0.9964 - val_accuracy: 0.6875\n",
      "Epoch 19/30\n",
      "126/126 [==============================] - 97s 768ms/step - loss: 0.6090 - accuracy: 0.8803 - val_loss: 0.8707 - val_accuracy: 0.7500\n",
      "Epoch 20/30\n",
      "126/126 [==============================] - 97s 773ms/step - loss: 0.6235 - accuracy: 0.8682 - val_loss: 0.9056 - val_accuracy: 0.7188\n",
      "Epoch 21/30\n",
      "126/126 [==============================] - 96s 764ms/step - loss: 0.5861 - accuracy: 0.8863 - val_loss: 0.8829 - val_accuracy: 0.7188\n",
      "Epoch 22/30\n",
      "126/126 [==============================] - 97s 767ms/step - loss: 0.5851 - accuracy: 0.8821 - val_loss: 0.9241 - val_accuracy: 0.7188\n",
      "Epoch 23/30\n",
      "126/126 [==============================] - 97s 774ms/step - loss: 0.5831 - accuracy: 0.8818 - val_loss: 0.8699 - val_accuracy: 0.7188\n",
      "Epoch 24/30\n",
      "126/126 [==============================] - 98s 774ms/step - loss: 0.5698 - accuracy: 0.8845 - val_loss: 0.8537 - val_accuracy: 0.7500\n",
      "Epoch 25/30\n",
      "126/126 [==============================] - 97s 773ms/step - loss: 0.5666 - accuracy: 0.8855 - val_loss: 0.8383 - val_accuracy: 0.7500\n",
      "Epoch 26/30\n",
      "126/126 [==============================] - 97s 769ms/step - loss: 0.5534 - accuracy: 0.8881 - val_loss: 0.8359 - val_accuracy: 0.7500\n",
      "Epoch 27/30\n",
      "126/126 [==============================] - 97s 771ms/step - loss: 0.5533 - accuracy: 0.8866 - val_loss: 0.8165 - val_accuracy: 0.7500\n",
      "Epoch 28/30\n",
      "126/126 [==============================] - 97s 769ms/step - loss: 0.5597 - accuracy: 0.8807 - val_loss: 0.8525 - val_accuracy: 0.7188\n",
      "Epoch 29/30\n",
      "126/126 [==============================] - 97s 770ms/step - loss: 0.5429 - accuracy: 0.8888 - val_loss: 0.8205 - val_accuracy: 0.7188\n",
      "Epoch 30/30\n",
      "126/126 [==============================] - 97s 766ms/step - loss: 0.5464 - accuracy: 0.8863 - val_loss: 0.8806 - val_accuracy: 0.7188\n",
      "INFO:tensorflow:Assets written to: ../xception/xception_30epochs_6261.3_images_True_newWeights_False_lastLayerOnly_rescale-symmetric_normalization/assets\n",
      "Test acc for xception: 0.736570\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training resnet for 0.075% of train size (aka 6261 images) with pretrained: False and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 178 trainable: 178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/126 [>.............................] - ETA: 1:29 - loss: 1.3755 - accuracy: 0.3434WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1058s vs `on_train_batch_begin` time: 0.1871s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1058s vs `on_train_batch_end` time: 0.3529s). Check your callbacks.\n",
      "126/126 [==============================] - 37s 234ms/step - loss: 1.3369 - accuracy: 0.4405 - val_loss: 1.4167 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "126/126 [==============================] - 25s 197ms/step - loss: 1.2746 - accuracy: 0.4410 - val_loss: 1.4513 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "126/126 [==============================] - 25s 198ms/step - loss: 1.2568 - accuracy: 0.4372 - val_loss: 1.4805 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "126/126 [==============================] - 25s 198ms/step - loss: 1.2421 - accuracy: 0.4480 - val_loss: 1.5021 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "126/126 [==============================] - 25s 198ms/step - loss: 1.2385 - accuracy: 0.4460 - val_loss: 1.5164 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "126/126 [==============================] - 25s 199ms/step - loss: 1.2356 - accuracy: 0.4511 - val_loss: 1.5260 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "126/126 [==============================] - 25s 198ms/step - loss: 1.2282 - accuracy: 0.4536 - val_loss: 1.5321 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "126/126 [==============================] - 25s 198ms/step - loss: 1.2392 - accuracy: 0.4387 - val_loss: 1.5372 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "126/126 [==============================] - 25s 198ms/step - loss: 1.2283 - accuracy: 0.4493 - val_loss: 1.5406 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "126/126 [==============================] - 25s 198ms/step - loss: 1.2288 - accuracy: 0.4532 - val_loss: 1.5418 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "126/126 [==============================] - 25s 199ms/step - loss: 1.2251 - accuracy: 0.4527 - val_loss: 1.5432 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "126/126 [==============================] - 25s 199ms/step - loss: 1.2465 - accuracy: 0.4405 - val_loss: 1.5442 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "126/126 [==============================] - 25s 199ms/step - loss: 1.2283 - accuracy: 0.4557 - val_loss: 1.5454 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "126/126 [==============================] - 25s 198ms/step - loss: 1.2340 - accuracy: 0.4482 - val_loss: 1.5459 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "126/126 [==============================] - 25s 199ms/step - loss: 1.2302 - accuracy: 0.4510 - val_loss: 1.5468 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "126/126 [==============================] - 25s 199ms/step - loss: 1.2342 - accuracy: 0.4511 - val_loss: 1.5470 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "126/126 [==============================] - 25s 198ms/step - loss: 1.2332 - accuracy: 0.4477 - val_loss: 1.5476 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "126/126 [==============================] - 25s 198ms/step - loss: 1.2464 - accuracy: 0.4366 - val_loss: 1.5479 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "126/126 [==============================] - 25s 198ms/step - loss: 1.2341 - accuracy: 0.4512 - val_loss: 1.5482 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "126/126 [==============================] - 25s 198ms/step - loss: 1.2366 - accuracy: 0.4449 - val_loss: 1.5483 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "126/126 [==============================] - 25s 198ms/step - loss: 1.2331 - accuracy: 0.4420 - val_loss: 1.5484 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "126/126 [==============================] - 25s 199ms/step - loss: 1.2401 - accuracy: 0.4408 - val_loss: 1.5484 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "126/126 [==============================] - 25s 199ms/step - loss: 1.2383 - accuracy: 0.4470 - val_loss: 1.5486 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "126/126 [==============================] - 25s 198ms/step - loss: 1.2295 - accuracy: 0.4512 - val_loss: 1.5487 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "126/126 [==============================] - 25s 198ms/step - loss: 1.2349 - accuracy: 0.4428 - val_loss: 1.5487 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "126/126 [==============================] - 25s 199ms/step - loss: 1.2390 - accuracy: 0.4420 - val_loss: 1.5489 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "126/126 [==============================] - 25s 198ms/step - loss: 1.2302 - accuracy: 0.4435 - val_loss: 1.5490 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "126/126 [==============================] - 25s 198ms/step - loss: 1.2396 - accuracy: 0.4437 - val_loss: 1.5490 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "126/126 [==============================] - 25s 198ms/step - loss: 1.2353 - accuracy: 0.4434 - val_loss: 1.5491 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "126/126 [==============================] - 25s 198ms/step - loss: 1.2255 - accuracy: 0.4472 - val_loss: 1.5492 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_6261.3_images_True_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training opticnet for 0.075% of train size (aka 6261 images) with pretrained: False and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 276 trainable: 276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/126 [>.............................] - ETA: 3:39 - loss: 33.3884 - accuracy: 0.2931WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.4679s vs `on_train_batch_end` time: 1.0544s). Check your callbacks.\n",
      "126/126 [==============================] - 168s 1s/step - loss: 8.7659 - accuracy: 0.3679 - val_loss: 2.3569 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "126/126 [==============================] - 147s 1s/step - loss: 0.9464 - accuracy: 0.6578 - val_loss: 0.9377 - val_accuracy: 0.5938\n",
      "Epoch 3/30\n",
      "126/126 [==============================] - 147s 1s/step - loss: 0.7389 - accuracy: 0.7276 - val_loss: 0.9729 - val_accuracy: 0.5312\n",
      "Epoch 4/30\n",
      "126/126 [==============================] - 147s 1s/step - loss: 0.6080 - accuracy: 0.7924 - val_loss: 0.6105 - val_accuracy: 0.7500\n",
      "Epoch 5/30\n",
      "126/126 [==============================] - 148s 1s/step - loss: 0.5404 - accuracy: 0.8041 - val_loss: 0.5757 - val_accuracy: 0.8438\n",
      "Epoch 6/30\n",
      "126/126 [==============================] - 147s 1s/step - loss: 0.4074 - accuracy: 0.8562 - val_loss: 0.5363 - val_accuracy: 0.7812\n",
      "Epoch 7/30\n",
      "126/126 [==============================] - 146s 1s/step - loss: 0.3336 - accuracy: 0.8797 - val_loss: 2.3400 - val_accuracy: 0.5312\n",
      "Epoch 8/30\n",
      "126/126 [==============================] - 146s 1s/step - loss: 0.2312 - accuracy: 0.9184 - val_loss: 0.1778 - val_accuracy: 0.9062\n",
      "Epoch 9/30\n",
      "126/126 [==============================] - 147s 1s/step - loss: 0.1998 - accuracy: 0.9293 - val_loss: 0.2185 - val_accuracy: 0.9688\n",
      "Epoch 10/30\n",
      "126/126 [==============================] - 147s 1s/step - loss: 0.1747 - accuracy: 0.9388 - val_loss: 0.0767 - val_accuracy: 0.9688\n",
      "Epoch 11/30\n",
      "126/126 [==============================] - 147s 1s/step - loss: 0.1413 - accuracy: 0.9471 - val_loss: 0.1173 - val_accuracy: 1.0000\n",
      "Epoch 12/30\n",
      "126/126 [==============================] - 147s 1s/step - loss: 0.1013 - accuracy: 0.9672 - val_loss: 0.0341 - val_accuracy: 1.0000\n",
      "Epoch 13/30\n",
      "126/126 [==============================] - 147s 1s/step - loss: 0.0612 - accuracy: 0.9786 - val_loss: 0.0665 - val_accuracy: 0.9375\n",
      "Epoch 14/30\n",
      "126/126 [==============================] - 147s 1s/step - loss: 0.0560 - accuracy: 0.9825 - val_loss: 0.0449 - val_accuracy: 1.0000\n",
      "Epoch 15/30\n",
      "126/126 [==============================] - 147s 1s/step - loss: 0.0580 - accuracy: 0.9795 - val_loss: 0.0718 - val_accuracy: 0.9688\n",
      "Epoch 16/30\n",
      "126/126 [==============================] - 147s 1s/step - loss: 0.0688 - accuracy: 0.9783 - val_loss: 0.5469 - val_accuracy: 0.9375\n",
      "Epoch 17/30\n",
      "126/126 [==============================] - 147s 1s/step - loss: 0.0204 - accuracy: 0.9932 - val_loss: 0.0401 - val_accuracy: 0.9688\n",
      "Epoch 18/30\n",
      "126/126 [==============================] - 147s 1s/step - loss: 0.0092 - accuracy: 0.9971 - val_loss: 0.0617 - val_accuracy: 0.9688\n",
      "Epoch 19/30\n",
      "126/126 [==============================] - 147s 1s/step - loss: 0.0085 - accuracy: 0.9980 - val_loss: 0.4220 - val_accuracy: 0.9375\n",
      "Epoch 20/30\n",
      "126/126 [==============================] - 147s 1s/step - loss: 0.0906 - accuracy: 0.9734 - val_loss: 0.1066 - val_accuracy: 0.9375\n",
      "Epoch 21/30\n",
      "126/126 [==============================] - 147s 1s/step - loss: 0.0156 - accuracy: 0.9958 - val_loss: 0.0075 - val_accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "126/126 [==============================] - 147s 1s/step - loss: 0.0140 - accuracy: 0.9954 - val_loss: 0.0036 - val_accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "126/126 [==============================] - 147s 1s/step - loss: 0.0073 - accuracy: 0.9980 - val_loss: 0.0235 - val_accuracy: 0.9688\n",
      "Epoch 24/30\n",
      "126/126 [==============================] - 147s 1s/step - loss: 0.0040 - accuracy: 0.9991 - val_loss: 0.1350 - val_accuracy: 0.9375\n",
      "Epoch 25/30\n",
      "126/126 [==============================] - 147s 1s/step - loss: 0.0211 - accuracy: 0.9925 - val_loss: 0.0121 - val_accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "126/126 [==============================] - 147s 1s/step - loss: 0.0074 - accuracy: 0.9983 - val_loss: 0.0359 - val_accuracy: 0.9688\n",
      "Epoch 27/30\n",
      "126/126 [==============================] - 147s 1s/step - loss: 0.0062 - accuracy: 0.9984 - val_loss: 0.0035 - val_accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "126/126 [==============================] - 147s 1s/step - loss: 0.0029 - accuracy: 0.9989 - val_loss: 0.0114 - val_accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "126/126 [==============================] - 147s 1s/step - loss: 0.0027 - accuracy: 0.9993 - val_loss: 0.0132 - val_accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "126/126 [==============================] - 147s 1s/step - loss: 0.0041 - accuracy: 0.9989 - val_loss: 0.0089 - val_accuracy: 1.0000\n",
      "INFO:tensorflow:Assets written to: ../opticnet/opticnet_30epochs_6261.3_images_True_newWeights_False_lastLayerOnly_rescale-symmetric_normalization/assets\n",
      "Test acc for opticnet: 0.961777\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.08835265 0.09025669 0.09111738 0.09238626]\n",
      "Training xception for 0.09% of train size (aka 7513 images) with pretrained: False and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 135 trainable: 135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/151 [>.............................] - ETA: 3:13 - loss: 1.3822 - accuracy: 0.4485WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1611s vs `on_train_batch_begin` time: 0.2187s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1611s vs `on_train_batch_end` time: 0.8503s). Check your callbacks.\n",
      "151/151 [==============================] - 124s 784ms/step - loss: 1.3071 - accuracy: 0.6444 - val_loss: 1.3951 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "151/151 [==============================] - 114s 757ms/step - loss: 1.1546 - accuracy: 0.7192 - val_loss: 1.4005 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "151/151 [==============================] - 115s 759ms/step - loss: 1.0480 - accuracy: 0.7268 - val_loss: 1.3411 - val_accuracy: 0.4688\n",
      "Epoch 4/30\n",
      "151/151 [==============================] - 114s 756ms/step - loss: 0.9711 - accuracy: 0.7727 - val_loss: 1.3326 - val_accuracy: 0.4688\n",
      "Epoch 5/30\n",
      "151/151 [==============================] - 115s 761ms/step - loss: 0.8927 - accuracy: 0.7996 - val_loss: 1.0836 - val_accuracy: 0.7188\n",
      "Epoch 6/30\n",
      "151/151 [==============================] - 115s 759ms/step - loss: 0.8295 - accuracy: 0.8264 - val_loss: 1.0462 - val_accuracy: 0.7188\n",
      "Epoch 7/30\n",
      "151/151 [==============================] - 114s 757ms/step - loss: 0.7941 - accuracy: 0.8267 - val_loss: 1.3037 - val_accuracy: 0.4688\n",
      "Epoch 8/30\n",
      "151/151 [==============================] - 115s 762ms/step - loss: 0.7391 - accuracy: 0.8390 - val_loss: 1.3043 - val_accuracy: 0.4688\n",
      "Epoch 9/30\n",
      "151/151 [==============================] - 114s 757ms/step - loss: 0.7033 - accuracy: 0.8504 - val_loss: 0.9283 - val_accuracy: 0.6875\n",
      "Epoch 10/30\n",
      "151/151 [==============================] - 115s 760ms/step - loss: 0.6638 - accuracy: 0.8519 - val_loss: 1.1456 - val_accuracy: 0.5938\n",
      "Epoch 11/30\n",
      "151/151 [==============================] - 115s 762ms/step - loss: 0.6296 - accuracy: 0.8814 - val_loss: 0.7434 - val_accuracy: 0.9688\n",
      "Epoch 12/30\n",
      "151/151 [==============================] - 115s 763ms/step - loss: 0.5911 - accuracy: 0.9081 - val_loss: 0.6437 - val_accuracy: 0.9688\n",
      "Epoch 13/30\n",
      "151/151 [==============================] - 115s 763ms/step - loss: 0.5492 - accuracy: 0.9231 - val_loss: 0.7600 - val_accuracy: 0.8125\n",
      "Epoch 14/30\n",
      "151/151 [==============================] - 115s 763ms/step - loss: 0.5187 - accuracy: 0.9262 - val_loss: 0.6558 - val_accuracy: 0.9062\n",
      "Epoch 15/30\n",
      "151/151 [==============================] - 115s 762ms/step - loss: 0.4904 - accuracy: 0.9365 - val_loss: 0.7069 - val_accuracy: 0.8750\n",
      "Epoch 16/30\n",
      "151/151 [==============================] - 115s 761ms/step - loss: 0.4750 - accuracy: 0.9430 - val_loss: 0.5172 - val_accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "151/151 [==============================] - 115s 761ms/step - loss: 0.4522 - accuracy: 0.9452 - val_loss: 0.5146 - val_accuracy: 0.9688\n",
      "Epoch 18/30\n",
      "151/151 [==============================] - 115s 761ms/step - loss: 0.4460 - accuracy: 0.9481 - val_loss: 0.4698 - val_accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "151/151 [==============================] - 115s 759ms/step - loss: 0.4351 - accuracy: 0.9516 - val_loss: 0.5633 - val_accuracy: 0.9375\n",
      "Epoch 20/30\n",
      "151/151 [==============================] - 114s 757ms/step - loss: 0.4100 - accuracy: 0.9582 - val_loss: 0.4854 - val_accuracy: 0.9688\n",
      "Epoch 21/30\n",
      "151/151 [==============================] - 114s 758ms/step - loss: 0.3997 - accuracy: 0.9601 - val_loss: 0.4379 - val_accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "151/151 [==============================] - 116s 767ms/step - loss: 0.4085 - accuracy: 0.9517 - val_loss: 0.4299 - val_accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "151/151 [==============================] - 115s 759ms/step - loss: 0.3784 - accuracy: 0.9655 - val_loss: 0.4652 - val_accuracy: 0.9688\n",
      "Epoch 24/30\n",
      "151/151 [==============================] - 115s 760ms/step - loss: 0.3677 - accuracy: 0.9701 - val_loss: 0.4509 - val_accuracy: 0.9688\n",
      "Epoch 25/30\n",
      "151/151 [==============================] - 115s 762ms/step - loss: 0.3632 - accuracy: 0.9706 - val_loss: 0.4108 - val_accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "151/151 [==============================] - 115s 762ms/step - loss: 0.3492 - accuracy: 0.9756 - val_loss: 0.4090 - val_accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "151/151 [==============================] - 115s 762ms/step - loss: 0.3463 - accuracy: 0.9761 - val_loss: 0.4123 - val_accuracy: 0.9688\n",
      "Epoch 28/30\n",
      "151/151 [==============================] - 115s 762ms/step - loss: 0.3461 - accuracy: 0.9717 - val_loss: 0.3971 - val_accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "151/151 [==============================] - 116s 765ms/step - loss: 0.3340 - accuracy: 0.9783 - val_loss: 0.3958 - val_accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "151/151 [==============================] - 115s 762ms/step - loss: 0.3366 - accuracy: 0.9765 - val_loss: 0.3927 - val_accuracy: 1.0000\n",
      "INFO:tensorflow:Assets written to: ../xception/xception_30epochs_7513.5599999999995_images_True_newWeights_False_lastLayerOnly_rescale-symmetric_normalization/assets\n",
      "Test acc for xception: 0.971074\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training resnet for 0.09% of train size (aka 7513 images) with pretrained: False and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 178 trainable: 178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/151 [>.............................] - ETA: 1:46 - loss: 1.3814 - accuracy: 0.2604WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1008s vs `on_train_batch_begin` time: 0.2032s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1008s vs `on_train_batch_end` time: 0.3361s). Check your callbacks.\n",
      "151/151 [==============================] - 41s 227ms/step - loss: 1.3342 - accuracy: 0.4251 - val_loss: 1.4292 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "151/151 [==============================] - 30s 196ms/step - loss: 1.2568 - accuracy: 0.4815 - val_loss: 1.4652 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "151/151 [==============================] - 30s 197ms/step - loss: 1.2480 - accuracy: 0.4467 - val_loss: 1.4966 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "151/151 [==============================] - 30s 197ms/step - loss: 1.2404 - accuracy: 0.4416 - val_loss: 1.5169 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "151/151 [==============================] - 30s 198ms/step - loss: 1.2402 - accuracy: 0.4418 - val_loss: 1.5296 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "151/151 [==============================] - 30s 197ms/step - loss: 1.2323 - accuracy: 0.4492 - val_loss: 1.5361 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "151/151 [==============================] - 30s 198ms/step - loss: 1.2339 - accuracy: 0.4449 - val_loss: 1.5407 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "151/151 [==============================] - 30s 198ms/step - loss: 1.2408 - accuracy: 0.4450 - val_loss: 1.5442 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "151/151 [==============================] - 30s 197ms/step - loss: 1.2392 - accuracy: 0.4440 - val_loss: 1.5467 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "151/151 [==============================] - 30s 197ms/step - loss: 1.2353 - accuracy: 0.4468 - val_loss: 1.5478 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "151/151 [==============================] - 30s 198ms/step - loss: 1.2394 - accuracy: 0.4391 - val_loss: 1.5494 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "151/151 [==============================] - 30s 198ms/step - loss: 1.2397 - accuracy: 0.4442 - val_loss: 1.5494 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "151/151 [==============================] - 30s 197ms/step - loss: 1.2189 - accuracy: 0.4591 - val_loss: 1.5501 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "151/151 [==============================] - 30s 197ms/step - loss: 1.2304 - accuracy: 0.4471 - val_loss: 1.5498 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "151/151 [==============================] - 30s 197ms/step - loss: 1.2396 - accuracy: 0.4404 - val_loss: 1.5502 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "151/151 [==============================] - 30s 198ms/step - loss: 1.2343 - accuracy: 0.4482 - val_loss: 1.5502 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "151/151 [==============================] - 30s 198ms/step - loss: 1.2371 - accuracy: 0.4467 - val_loss: 1.5506 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "151/151 [==============================] - 30s 198ms/step - loss: 1.2305 - accuracy: 0.4546 - val_loss: 1.5508 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "151/151 [==============================] - 30s 197ms/step - loss: 1.2398 - accuracy: 0.4468 - val_loss: 1.5509 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "151/151 [==============================] - 30s 197ms/step - loss: 1.2371 - accuracy: 0.4401 - val_loss: 1.5510 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "151/151 [==============================] - 30s 198ms/step - loss: 1.2381 - accuracy: 0.4475 - val_loss: 1.5512 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "151/151 [==============================] - 30s 198ms/step - loss: 1.2368 - accuracy: 0.4421 - val_loss: 1.5507 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "151/151 [==============================] - 30s 198ms/step - loss: 1.2276 - accuracy: 0.4517 - val_loss: 1.5511 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "151/151 [==============================] - 30s 197ms/step - loss: 1.2320 - accuracy: 0.4467 - val_loss: 1.5508 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "151/151 [==============================] - 30s 197ms/step - loss: 1.2338 - accuracy: 0.4503 - val_loss: 1.5507 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "151/151 [==============================] - 30s 198ms/step - loss: 1.2360 - accuracy: 0.4435 - val_loss: 1.5507 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "151/151 [==============================] - 30s 197ms/step - loss: 1.2373 - accuracy: 0.4473 - val_loss: 1.5508 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "151/151 [==============================] - 30s 197ms/step - loss: 1.2369 - accuracy: 0.4420 - val_loss: 1.5508 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "151/151 [==============================] - 30s 197ms/step - loss: 1.2464 - accuracy: 0.4338 - val_loss: 1.5508 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "151/151 [==============================] - 30s 198ms/step - loss: 1.2317 - accuracy: 0.4493 - val_loss: 1.5509 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_7513.5599999999995_images_True_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training opticnet for 0.09% of train size (aka 7513 images) with pretrained: False and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 276 trainable: 276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/151 [>.............................] - ETA: 4:30 - loss: 16.1934 - accuracy: 0.2994WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.4670s vs `on_train_batch_end` time: 1.0542s). Check your callbacks.\n",
      "151/151 [==============================] - 195s 1s/step - loss: 6.4870 - accuracy: 0.3768 - val_loss: 3.1379 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "151/151 [==============================] - 177s 1s/step - loss: 1.0954 - accuracy: 0.6190 - val_loss: 1.0147 - val_accuracy: 0.4375\n",
      "Epoch 3/30\n",
      "151/151 [==============================] - 176s 1s/step - loss: 0.8219 - accuracy: 0.7113 - val_loss: 0.7824 - val_accuracy: 0.5938\n",
      "Epoch 4/30\n",
      "151/151 [==============================] - 176s 1s/step - loss: 0.6800 - accuracy: 0.7487 - val_loss: 0.7989 - val_accuracy: 0.6875\n",
      "Epoch 5/30\n",
      "151/151 [==============================] - 177s 1s/step - loss: 0.6045 - accuracy: 0.7907 - val_loss: 0.3298 - val_accuracy: 0.9062\n",
      "Epoch 6/30\n",
      "151/151 [==============================] - 176s 1s/step - loss: 0.4369 - accuracy: 0.8441 - val_loss: 0.7594 - val_accuracy: 0.7188\n",
      "Epoch 7/30\n",
      "151/151 [==============================] - 176s 1s/step - loss: 0.3277 - accuracy: 0.8843 - val_loss: 1.5504 - val_accuracy: 0.5938\n",
      "Epoch 8/30\n",
      "151/151 [==============================] - 176s 1s/step - loss: 0.2825 - accuracy: 0.9032 - val_loss: 0.1375 - val_accuracy: 0.9375\n",
      "Epoch 9/30\n",
      "151/151 [==============================] - 176s 1s/step - loss: 0.2462 - accuracy: 0.9134 - val_loss: 0.3279 - val_accuracy: 0.8125\n",
      "Epoch 10/30\n",
      "151/151 [==============================] - 177s 1s/step - loss: 0.1918 - accuracy: 0.9346 - val_loss: 0.5602 - val_accuracy: 0.7812\n",
      "Epoch 11/30\n",
      "151/151 [==============================] - 177s 1s/step - loss: 0.1856 - accuracy: 0.9379 - val_loss: 0.2325 - val_accuracy: 0.9062\n",
      "Epoch 12/30\n",
      "151/151 [==============================] - 177s 1s/step - loss: 0.1395 - accuracy: 0.9533 - val_loss: 0.1002 - val_accuracy: 0.9688\n",
      "Epoch 13/30\n",
      "151/151 [==============================] - 177s 1s/step - loss: 0.1087 - accuracy: 0.9631 - val_loss: 0.0321 - val_accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "151/151 [==============================] - 177s 1s/step - loss: 0.0652 - accuracy: 0.9777 - val_loss: 0.2676 - val_accuracy: 0.9062\n",
      "Epoch 15/30\n",
      "151/151 [==============================] - 176s 1s/step - loss: 0.0696 - accuracy: 0.9756 - val_loss: 0.4178 - val_accuracy: 0.8750\n",
      "Epoch 16/30\n",
      "151/151 [==============================] - 176s 1s/step - loss: 0.0343 - accuracy: 0.9902 - val_loss: 0.8352 - val_accuracy: 0.8125\n",
      "Epoch 17/30\n",
      "151/151 [==============================] - 175s 1s/step - loss: 0.0455 - accuracy: 0.9842 - val_loss: 0.0089 - val_accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "151/151 [==============================] - 177s 1s/step - loss: 0.0177 - accuracy: 0.9952 - val_loss: 0.0111 - val_accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "151/151 [==============================] - 176s 1s/step - loss: 0.0177 - accuracy: 0.9959 - val_loss: 0.5730 - val_accuracy: 0.9062\n",
      "Epoch 20/30\n",
      "151/151 [==============================] - 176s 1s/step - loss: 0.0304 - accuracy: 0.9891 - val_loss: 0.1371 - val_accuracy: 0.9688\n",
      "Epoch 21/30\n",
      "151/151 [==============================] - 176s 1s/step - loss: 0.0108 - accuracy: 0.9968 - val_loss: 0.0554 - val_accuracy: 0.9688\n",
      "Epoch 22/30\n",
      "151/151 [==============================] - 176s 1s/step - loss: 0.0049 - accuracy: 0.9989 - val_loss: 0.0154 - val_accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "151/151 [==============================] - 176s 1s/step - loss: 0.0105 - accuracy: 0.9966 - val_loss: 0.0049 - val_accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "151/151 [==============================] - 176s 1s/step - loss: 0.0036 - accuracy: 0.9992 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "151/151 [==============================] - 176s 1s/step - loss: 0.0085 - accuracy: 0.9980 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "151/151 [==============================] - 176s 1s/step - loss: 0.0044 - accuracy: 0.9989 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "151/151 [==============================] - 176s 1s/step - loss: 0.0075 - accuracy: 0.9977 - val_loss: 0.0063 - val_accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "151/151 [==============================] - 176s 1s/step - loss: 0.0049 - accuracy: 0.9982 - val_loss: 0.0071 - val_accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "151/151 [==============================] - 175s 1s/step - loss: 0.0030 - accuracy: 0.9991 - val_loss: 0.0055 - val_accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "151/151 [==============================] - 176s 1s/step - loss: 0.0032 - accuracy: 0.9988 - val_loss: 0.0094 - val_accuracy: 1.0000\n",
      "INFO:tensorflow:Assets written to: ../opticnet/opticnet_30epochs_7513.5599999999995_images_True_newWeights_False_lastLayerOnly_rescale-symmetric_normalization/assets\n",
      "Test acc for opticnet: 0.971074\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.09777693 0.10020159 0.10133944 0.10410864]\n",
      "Training xception for 0.1% of train size (aka 8348 images) with pretrained: False and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 135 trainable: 135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/167 [>.............................] - ETA: 3:31 - loss: 1.3823 - accuracy: 0.3359WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1633s vs `on_train_batch_begin` time: 0.2056s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1633s vs `on_train_batch_end` time: 0.8609s). Check your callbacks.\n",
      "167/167 [==============================] - 145s 834ms/step - loss: 1.3049 - accuracy: 0.6223 - val_loss: 1.3972 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "167/167 [==============================] - 136s 817ms/step - loss: 1.1342 - accuracy: 0.7325 - val_loss: 1.4626 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "167/167 [==============================] - 138s 827ms/step - loss: 1.0322 - accuracy: 0.7305 - val_loss: 1.3205 - val_accuracy: 0.3125\n",
      "Epoch 4/30\n",
      "167/167 [==============================] - 139s 833ms/step - loss: 0.9268 - accuracy: 0.7999 - val_loss: 1.2150 - val_accuracy: 0.5625\n",
      "Epoch 5/30\n",
      "167/167 [==============================] - 140s 839ms/step - loss: 0.8599 - accuracy: 0.8135 - val_loss: 1.3378 - val_accuracy: 0.3750\n",
      "Epoch 6/30\n",
      "167/167 [==============================] - 139s 833ms/step - loss: 0.8029 - accuracy: 0.8268 - val_loss: 1.0521 - val_accuracy: 0.6875\n",
      "Epoch 7/30\n",
      "167/167 [==============================] - 140s 839ms/step - loss: 0.7393 - accuracy: 0.8466 - val_loss: 1.0449 - val_accuracy: 0.6875\n",
      "Epoch 8/30\n",
      "167/167 [==============================] - 140s 840ms/step - loss: 0.7047 - accuracy: 0.8426 - val_loss: 1.0373 - val_accuracy: 0.6562\n",
      "Epoch 9/30\n",
      "167/167 [==============================] - 137s 823ms/step - loss: 0.6538 - accuracy: 0.8550 - val_loss: 0.6920 - val_accuracy: 0.7500\n",
      "Epoch 10/30\n",
      "167/167 [==============================] - 140s 836ms/step - loss: 0.6009 - accuracy: 0.8541 - val_loss: 0.7984 - val_accuracy: 0.6875\n",
      "Epoch 11/30\n",
      "167/167 [==============================] - 137s 821ms/step - loss: 0.5601 - accuracy: 0.8728 - val_loss: 0.6972 - val_accuracy: 0.9062\n",
      "Epoch 12/30\n",
      "167/167 [==============================] - 138s 827ms/step - loss: 0.5443 - accuracy: 0.9138 - val_loss: 0.6341 - val_accuracy: 0.9375\n",
      "Epoch 13/30\n",
      "167/167 [==============================] - 138s 824ms/step - loss: 0.5076 - accuracy: 0.9274 - val_loss: 0.5101 - val_accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "167/167 [==============================] - 140s 841ms/step - loss: 0.4813 - accuracy: 0.9325 - val_loss: 0.5180 - val_accuracy: 0.9688\n",
      "Epoch 15/30\n",
      "167/167 [==============================] - 139s 830ms/step - loss: 0.4485 - accuracy: 0.9444 - val_loss: 0.4673 - val_accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "167/167 [==============================] - 142s 851ms/step - loss: 0.4288 - accuracy: 0.9492 - val_loss: 0.4816 - val_accuracy: 0.9688\n",
      "Epoch 17/30\n",
      "167/167 [==============================] - 141s 844ms/step - loss: 0.4146 - accuracy: 0.9527 - val_loss: 0.4383 - val_accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "167/167 [==============================] - 138s 827ms/step - loss: 0.3962 - accuracy: 0.9554 - val_loss: 0.4214 - val_accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "167/167 [==============================] - 139s 832ms/step - loss: 0.3779 - accuracy: 0.9620 - val_loss: 0.4180 - val_accuracy: 0.9688\n",
      "Epoch 20/30\n",
      "167/167 [==============================] - 137s 820ms/step - loss: 0.3742 - accuracy: 0.9597 - val_loss: 0.3992 - val_accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "167/167 [==============================] - 140s 837ms/step - loss: 0.3498 - accuracy: 0.9695 - val_loss: 0.4064 - val_accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "167/167 [==============================] - 138s 825ms/step - loss: 0.3403 - accuracy: 0.9709 - val_loss: 0.3823 - val_accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "167/167 [==============================] - 135s 810ms/step - loss: 0.3360 - accuracy: 0.9749 - val_loss: 0.3747 - val_accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "167/167 [==============================] - 139s 832ms/step - loss: 0.3308 - accuracy: 0.9730 - val_loss: 0.3959 - val_accuracy: 0.9688\n",
      "Epoch 25/30\n",
      "167/167 [==============================] - 141s 844ms/step - loss: 0.3209 - accuracy: 0.9743 - val_loss: 0.3626 - val_accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "167/167 [==============================] - 141s 845ms/step - loss: 0.3183 - accuracy: 0.9752 - val_loss: 0.3561 - val_accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "167/167 [==============================] - 134s 805ms/step - loss: 0.3110 - accuracy: 0.9769 - val_loss: 0.3525 - val_accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "167/167 [==============================] - 136s 814ms/step - loss: 0.3036 - accuracy: 0.9776 - val_loss: 0.3468 - val_accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "167/167 [==============================] - 137s 823ms/step - loss: 0.3040 - accuracy: 0.9762 - val_loss: 0.3543 - val_accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "167/167 [==============================] - 136s 812ms/step - loss: 0.2926 - accuracy: 0.9811 - val_loss: 0.3400 - val_accuracy: 1.0000\n",
      "INFO:tensorflow:Assets written to: ../xception/xception_30epochs_8348.4_images_True_newWeights_False_lastLayerOnly_rescale-symmetric_normalization/assets\n",
      "Test acc for xception: 0.977273\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training resnet for 0.1% of train size (aka 8348 images) with pretrained: False and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 178 trainable: 178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/167 [>.............................] - ETA: 1:58 - loss: 1.3761 - accuracy: 0.3230WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1038s vs `on_train_batch_begin` time: 0.2056s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1038s vs `on_train_batch_end` time: 0.3303s). Check your callbacks.\n",
      "167/167 [==============================] - 45s 228ms/step - loss: 1.3375 - accuracy: 0.4158 - val_loss: 1.4245 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "167/167 [==============================] - 33s 198ms/step - loss: 1.2691 - accuracy: 0.4370 - val_loss: 1.4674 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "167/167 [==============================] - 33s 198ms/step - loss: 1.2437 - accuracy: 0.4468 - val_loss: 1.4981 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "167/167 [==============================] - 33s 199ms/step - loss: 1.2336 - accuracy: 0.4481 - val_loss: 1.5171 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "167/167 [==============================] - 33s 199ms/step - loss: 1.2423 - accuracy: 0.4414 - val_loss: 1.5298 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "167/167 [==============================] - 33s 199ms/step - loss: 1.2367 - accuracy: 0.4467 - val_loss: 1.5366 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "167/167 [==============================] - 33s 199ms/step - loss: 1.2402 - accuracy: 0.4456 - val_loss: 1.5405 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "167/167 [==============================] - 33s 199ms/step - loss: 1.2264 - accuracy: 0.4507 - val_loss: 1.5439 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "167/167 [==============================] - 33s 199ms/step - loss: 1.2363 - accuracy: 0.4460 - val_loss: 1.5454 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "167/167 [==============================] - 33s 199ms/step - loss: 1.2399 - accuracy: 0.4443 - val_loss: 1.5461 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "167/167 [==============================] - 33s 199ms/step - loss: 1.2315 - accuracy: 0.4510 - val_loss: 1.5466 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "167/167 [==============================] - 33s 199ms/step - loss: 1.2379 - accuracy: 0.4399 - val_loss: 1.5476 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "167/167 [==============================] - 33s 199ms/step - loss: 1.2310 - accuracy: 0.4515 - val_loss: 1.5482 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "167/167 [==============================] - 33s 199ms/step - loss: 1.2528 - accuracy: 0.4347 - val_loss: 1.5478 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "167/167 [==============================] - 33s 199ms/step - loss: 1.2360 - accuracy: 0.4482 - val_loss: 1.5484 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "167/167 [==============================] - 33s 199ms/step - loss: 1.2466 - accuracy: 0.4383 - val_loss: 1.5484 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "167/167 [==============================] - 33s 199ms/step - loss: 1.2315 - accuracy: 0.4488 - val_loss: 1.5485 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "167/167 [==============================] - 33s 199ms/step - loss: 1.2376 - accuracy: 0.4420 - val_loss: 1.5481 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "167/167 [==============================] - 33s 199ms/step - loss: 1.2369 - accuracy: 0.4423 - val_loss: 1.5484 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "167/167 [==============================] - 33s 199ms/step - loss: 1.2456 - accuracy: 0.4414 - val_loss: 1.5486 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "167/167 [==============================] - 33s 199ms/step - loss: 1.2430 - accuracy: 0.4437 - val_loss: 1.5487 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "167/167 [==============================] - 33s 199ms/step - loss: 1.2323 - accuracy: 0.4550 - val_loss: 1.5487 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "167/167 [==============================] - 33s 199ms/step - loss: 1.2276 - accuracy: 0.4568 - val_loss: 1.5488 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "167/167 [==============================] - 33s 199ms/step - loss: 1.2397 - accuracy: 0.4520 - val_loss: 1.5487 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "167/167 [==============================] - 33s 199ms/step - loss: 1.2350 - accuracy: 0.4498 - val_loss: 1.5487 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "167/167 [==============================] - 33s 199ms/step - loss: 1.2338 - accuracy: 0.4460 - val_loss: 1.5488 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "167/167 [==============================] - 33s 199ms/step - loss: 1.2344 - accuracy: 0.4445 - val_loss: 1.5487 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "167/167 [==============================] - 33s 199ms/step - loss: 1.2357 - accuracy: 0.4485 - val_loss: 1.5488 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "167/167 [==============================] - 33s 199ms/step - loss: 1.2280 - accuracy: 0.4568 - val_loss: 1.5405 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "167/167 [==============================] - 33s 199ms/step - loss: 1.2111 - accuracy: 0.4478 - val_loss: 1.4060 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_8348.4_images_True_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training opticnet for 0.1% of train size (aka 8348 images) with pretrained: False and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 276 trainable: 276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/167 [>.............................] - ETA: 4:58 - loss: 23.7477 - accuracy: 0.2303WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.4663s vs `on_train_batch_end` time: 1.0484s). Check your callbacks.\n",
      "167/167 [==============================] - 217s 1s/step - loss: 7.2669 - accuracy: 0.3548 - val_loss: 3.9168 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "167/167 [==============================] - 195s 1s/step - loss: 0.9570 - accuracy: 0.6669 - val_loss: 0.9019 - val_accuracy: 0.6250\n",
      "Epoch 3/30\n",
      "167/167 [==============================] - 194s 1s/step - loss: 0.6285 - accuracy: 0.7741 - val_loss: 2.7144 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "167/167 [==============================] - 195s 1s/step - loss: 0.5299 - accuracy: 0.8138 - val_loss: 2.6089 - val_accuracy: 0.3750\n",
      "Epoch 5/30\n",
      "167/167 [==============================] - 195s 1s/step - loss: 0.4270 - accuracy: 0.8493 - val_loss: 0.3899 - val_accuracy: 0.8125\n",
      "Epoch 6/30\n",
      "167/167 [==============================] - 195s 1s/step - loss: 0.3290 - accuracy: 0.8843 - val_loss: 0.2027 - val_accuracy: 0.9062\n",
      "Epoch 7/30\n",
      "167/167 [==============================] - 194s 1s/step - loss: 0.2693 - accuracy: 0.9044 - val_loss: 0.2758 - val_accuracy: 0.9062\n",
      "Epoch 8/30\n",
      "167/167 [==============================] - 195s 1s/step - loss: 0.2148 - accuracy: 0.9301 - val_loss: 0.2972 - val_accuracy: 0.8750\n",
      "Epoch 9/30\n",
      "167/167 [==============================] - 195s 1s/step - loss: 0.1908 - accuracy: 0.9327 - val_loss: 0.1149 - val_accuracy: 0.9062\n",
      "Epoch 10/30\n",
      "167/167 [==============================] - 195s 1s/step - loss: 0.1735 - accuracy: 0.9419 - val_loss: 0.5092 - val_accuracy: 0.8125\n",
      "Epoch 11/30\n",
      "167/167 [==============================] - 195s 1s/step - loss: 0.1342 - accuracy: 0.9535 - val_loss: 0.0739 - val_accuracy: 0.9688\n",
      "Epoch 12/30\n",
      "167/167 [==============================] - 195s 1s/step - loss: 0.1031 - accuracy: 0.9654 - val_loss: 0.3241 - val_accuracy: 0.9062\n",
      "Epoch 13/30\n",
      "167/167 [==============================] - 196s 1s/step - loss: 0.1137 - accuracy: 0.9602 - val_loss: 0.3913 - val_accuracy: 0.8438\n",
      "Epoch 14/30\n",
      "167/167 [==============================] - 195s 1s/step - loss: 0.0692 - accuracy: 0.9769 - val_loss: 0.1357 - val_accuracy: 0.9688\n",
      "Epoch 15/30\n",
      "167/167 [==============================] - 195s 1s/step - loss: 0.0499 - accuracy: 0.9846 - val_loss: 0.1409 - val_accuracy: 0.9688\n",
      "Epoch 16/30\n",
      "167/167 [==============================] - 195s 1s/step - loss: 0.0388 - accuracy: 0.9869 - val_loss: 0.2926 - val_accuracy: 0.8750\n",
      "Epoch 17/30\n",
      "167/167 [==============================] - 196s 1s/step - loss: 0.0357 - accuracy: 0.9894 - val_loss: 0.1146 - val_accuracy: 0.9688\n",
      "Epoch 18/30\n",
      "167/167 [==============================] - 195s 1s/step - loss: 0.0300 - accuracy: 0.9908 - val_loss: 1.2192 - val_accuracy: 0.6875\n",
      "Epoch 19/30\n",
      "167/167 [==============================] - 195s 1s/step - loss: 0.0211 - accuracy: 0.9934 - val_loss: 0.0077 - val_accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "167/167 [==============================] - 195s 1s/step - loss: 0.0090 - accuracy: 0.9972 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "167/167 [==============================] - 195s 1s/step - loss: 0.0127 - accuracy: 0.9954 - val_loss: 0.0799 - val_accuracy: 0.9688\n",
      "Epoch 22/30\n",
      "167/167 [==============================] - 195s 1s/step - loss: 0.0072 - accuracy: 0.9982 - val_loss: 0.0397 - val_accuracy: 0.9688\n",
      "Epoch 23/30\n",
      "167/167 [==============================] - 195s 1s/step - loss: 0.0076 - accuracy: 0.9978 - val_loss: 0.0698 - val_accuracy: 0.9688\n",
      "Epoch 24/30\n",
      "167/167 [==============================] - 195s 1s/step - loss: 0.0055 - accuracy: 0.9979 - val_loss: 0.0465 - val_accuracy: 0.9688\n",
      "Epoch 25/30\n",
      "167/167 [==============================] - 195s 1s/step - loss: 0.0031 - accuracy: 0.9991 - val_loss: 0.2728 - val_accuracy: 0.9688\n",
      "Epoch 26/30\n",
      "167/167 [==============================] - 196s 1s/step - loss: 0.0089 - accuracy: 0.9977 - val_loss: 0.1971 - val_accuracy: 0.9688\n",
      "Epoch 27/30\n",
      "167/167 [==============================] - 195s 1s/step - loss: 0.0065 - accuracy: 0.9979 - val_loss: 0.2650 - val_accuracy: 0.9375\n",
      "Epoch 28/30\n",
      "167/167 [==============================] - 195s 1s/step - loss: 0.0058 - accuracy: 0.9982 - val_loss: 0.0637 - val_accuracy: 0.9688\n",
      "Epoch 29/30\n",
      "167/167 [==============================] - 195s 1s/step - loss: 0.0093 - accuracy: 0.9973 - val_loss: 0.0411 - val_accuracy: 0.9688\n",
      "Epoch 30/30\n",
      "167/167 [==============================] - 195s 1s/step - loss: 0.0036 - accuracy: 0.9986 - val_loss: 0.0958 - val_accuracy: 0.9688\n",
      "INFO:tensorflow:Assets written to: ../opticnet/opticnet_30epochs_8348.4_images_True_newWeights_False_lastLayerOnly_rescale-symmetric_normalization/assets\n",
      "Test acc for opticnet: 0.972107\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.24943948 0.24918694 0.24735636 0.25870474]\n",
      "Training xception for 0.25% of train size (aka 20871 images) with pretrained: False and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 135 trainable: 135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/418 [..............................] - ETA: 8:55 - loss: 1.3827 - accuracy: 0.3624WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1608s vs `on_train_batch_begin` time: 0.2050s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1608s vs `on_train_batch_end` time: 0.8325s). Check your callbacks.\n",
      "418/418 [==============================] - 330s 776ms/step - loss: 1.2443 - accuracy: 0.6454 - val_loss: 1.4116 - val_accuracy: 0.4062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "418/418 [==============================] - 320s 766ms/step - loss: 0.9557 - accuracy: 0.7422 - val_loss: 1.2721 - val_accuracy: 0.5312\n",
      "Epoch 3/30\n",
      "418/418 [==============================] - 321s 769ms/step - loss: 0.8133 - accuracy: 0.7853 - val_loss: 1.4271 - val_accuracy: 0.4062\n",
      "Epoch 4/30\n",
      "418/418 [==============================] - 321s 768ms/step - loss: 0.6907 - accuracy: 0.8224 - val_loss: 0.9773 - val_accuracy: 0.6562\n",
      "Epoch 5/30\n",
      "418/418 [==============================] - 319s 762ms/step - loss: 0.6031 - accuracy: 0.8344 - val_loss: 0.9261 - val_accuracy: 0.6875\n",
      "Epoch 6/30\n",
      "418/418 [==============================] - 321s 768ms/step - loss: 0.5345 - accuracy: 0.8465 - val_loss: 0.6085 - val_accuracy: 0.7500\n",
      "Epoch 7/30\n",
      "418/418 [==============================] - 320s 766ms/step - loss: 0.4882 - accuracy: 0.8501 - val_loss: 0.5672 - val_accuracy: 0.7500\n",
      "Epoch 8/30\n",
      "418/418 [==============================] - 322s 770ms/step - loss: 0.4425 - accuracy: 0.8575 - val_loss: 0.5433 - val_accuracy: 0.7500\n",
      "Epoch 9/30\n",
      "418/418 [==============================] - 321s 767ms/step - loss: 0.4054 - accuracy: 0.8650 - val_loss: 0.5060 - val_accuracy: 0.7500\n",
      "Epoch 10/30\n",
      "418/418 [==============================] - 321s 768ms/step - loss: 0.3867 - accuracy: 0.8646 - val_loss: 0.4817 - val_accuracy: 0.7500\n",
      "Epoch 11/30\n",
      "418/418 [==============================] - 321s 767ms/step - loss: 0.3402 - accuracy: 0.8745 - val_loss: 0.5053 - val_accuracy: 0.7500\n",
      "Epoch 12/30\n",
      "418/418 [==============================] - 321s 769ms/step - loss: 0.3281 - accuracy: 0.8755 - val_loss: 0.5361 - val_accuracy: 0.7500\n",
      "Epoch 13/30\n",
      "418/418 [==============================] - 322s 770ms/step - loss: 0.3198 - accuracy: 0.8764 - val_loss: 0.4446 - val_accuracy: 0.7500\n",
      "Epoch 14/30\n",
      "418/418 [==============================] - 320s 766ms/step - loss: 0.2941 - accuracy: 0.8832 - val_loss: 0.4309 - val_accuracy: 0.7500\n",
      "Epoch 15/30\n",
      "418/418 [==============================] - 322s 771ms/step - loss: 0.2813 - accuracy: 0.8860 - val_loss: 0.4274 - val_accuracy: 0.8125\n",
      "Epoch 16/30\n",
      "418/418 [==============================] - 321s 768ms/step - loss: 0.2644 - accuracy: 0.8902 - val_loss: 0.4131 - val_accuracy: 0.7500\n",
      "Epoch 17/30\n",
      "418/418 [==============================] - 321s 768ms/step - loss: 0.2594 - accuracy: 0.8910 - val_loss: 0.4065 - val_accuracy: 0.7812\n",
      "Epoch 18/30\n",
      "418/418 [==============================] - 321s 769ms/step - loss: 0.2498 - accuracy: 0.8936 - val_loss: 0.3981 - val_accuracy: 0.7812\n",
      "Epoch 19/30\n",
      "418/418 [==============================] - 322s 769ms/step - loss: 0.2442 - accuracy: 0.8984 - val_loss: 0.3949 - val_accuracy: 0.7812\n",
      "Epoch 20/30\n",
      "418/418 [==============================] - 321s 768ms/step - loss: 0.2280 - accuracy: 0.9515 - val_loss: 0.3378 - val_accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "418/418 [==============================] - 321s 769ms/step - loss: 0.2170 - accuracy: 0.9810 - val_loss: 0.3151 - val_accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "418/418 [==============================] - 321s 769ms/step - loss: 0.1981 - accuracy: 0.9856 - val_loss: 0.2977 - val_accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "418/418 [==============================] - 321s 768ms/step - loss: 0.1847 - accuracy: 0.9882 - val_loss: 0.2837 - val_accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "418/418 [==============================] - 321s 768ms/step - loss: 0.1849 - accuracy: 0.9873 - val_loss: 0.2718 - val_accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "418/418 [==============================] - 320s 766ms/step - loss: 0.1766 - accuracy: 0.9873 - val_loss: 0.2596 - val_accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "418/418 [==============================] - 321s 769ms/step - loss: 0.1704 - accuracy: 0.9886 - val_loss: 0.2502 - val_accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "418/418 [==============================] - 321s 769ms/step - loss: 0.1648 - accuracy: 0.9893 - val_loss: 0.2412 - val_accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "418/418 [==============================] - 321s 767ms/step - loss: 0.1594 - accuracy: 0.9893 - val_loss: 0.2334 - val_accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "418/418 [==============================] - 322s 769ms/step - loss: 0.1538 - accuracy: 0.9906 - val_loss: 0.2264 - val_accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "418/418 [==============================] - 320s 767ms/step - loss: 0.1529 - accuracy: 0.9901 - val_loss: 0.2203 - val_accuracy: 1.0000\n",
      "INFO:tensorflow:Assets written to: ../xception/xception_30epochs_20871.0_images_True_newWeights_False_lastLayerOnly_rescale-symmetric_normalization/assets\n",
      "Test acc for xception: 0.993802\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training resnet for 0.25% of train size (aka 20871 images) with pretrained: False and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 178 trainable: 178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/418 [..............................] - ETA: 5:01 - loss: 1.3760 - accuracy: 0.2921WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1023s vs `on_train_batch_begin` time: 0.2048s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1023s vs `on_train_batch_end` time: 0.3303s). Check your callbacks.\n",
      "418/418 [==============================] - 94s 208ms/step - loss: 1.3045 - accuracy: 0.4389 - val_loss: 1.5002 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "418/418 [==============================] - 83s 198ms/step - loss: 1.2420 - accuracy: 0.4403 - val_loss: 1.5448 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "418/418 [==============================] - 83s 198ms/step - loss: 1.2394 - accuracy: 0.4385 - val_loss: 1.5544 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "418/418 [==============================] - 83s 198ms/step - loss: 1.2341 - accuracy: 0.4457 - val_loss: 1.5533 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "418/418 [==============================] - 83s 198ms/step - loss: 1.2317 - accuracy: 0.4425 - val_loss: 1.5534 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "418/418 [==============================] - 83s 198ms/step - loss: 1.2285 - accuracy: 0.4463 - val_loss: 1.5515 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "418/418 [==============================] - 83s 198ms/step - loss: 1.2331 - accuracy: 0.4485 - val_loss: 1.5520 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "418/418 [==============================] - 83s 198ms/step - loss: 1.2361 - accuracy: 0.4411 - val_loss: 1.5541 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "418/418 [==============================] - 83s 198ms/step - loss: 1.2390 - accuracy: 0.4418 - val_loss: 1.5541 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "418/418 [==============================] - 83s 198ms/step - loss: 1.2364 - accuracy: 0.4397 - val_loss: 1.5547 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "418/418 [==============================] - 83s 198ms/step - loss: 1.2324 - accuracy: 0.4484 - val_loss: 1.5538 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "418/418 [==============================] - 83s 198ms/step - loss: 1.2350 - accuracy: 0.4384 - val_loss: 1.5533 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "418/418 [==============================] - 83s 198ms/step - loss: 1.2303 - accuracy: 0.4456 - val_loss: 1.5529 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "418/418 [==============================] - 83s 198ms/step - loss: 1.2301 - accuracy: 0.4483 - val_loss: 1.5531 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "418/418 [==============================] - 83s 198ms/step - loss: 1.2296 - accuracy: 0.4493 - val_loss: 1.5528 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "418/418 [==============================] - 83s 198ms/step - loss: 1.2365 - accuracy: 0.4398 - val_loss: 1.5533 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "418/418 [==============================] - 83s 198ms/step - loss: 1.2333 - accuracy: 0.4439 - val_loss: 1.5530 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "418/418 [==============================] - 83s 198ms/step - loss: 1.2318 - accuracy: 0.4445 - val_loss: 1.5529 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "418/418 [==============================] - 83s 198ms/step - loss: 1.2269 - accuracy: 0.4476 - val_loss: 1.5527 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "418/418 [==============================] - 83s 198ms/step - loss: 1.2285 - accuracy: 0.4463 - val_loss: 1.5526 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "418/418 [==============================] - 83s 198ms/step - loss: 1.2324 - accuracy: 0.4478 - val_loss: 1.5527 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "418/418 [==============================] - 83s 198ms/step - loss: 1.2325 - accuracy: 0.4465 - val_loss: 1.5526 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "418/418 [==============================] - 83s 198ms/step - loss: 1.2369 - accuracy: 0.4387 - val_loss: 1.5528 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "418/418 [==============================] - 83s 198ms/step - loss: 1.2337 - accuracy: 0.4445 - val_loss: 1.5527 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "418/418 [==============================] - 83s 198ms/step - loss: 1.2352 - accuracy: 0.4392 - val_loss: 1.5529 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "418/418 [==============================] - 83s 198ms/step - loss: 1.2370 - accuracy: 0.4441 - val_loss: 1.5529 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "418/418 [==============================] - 83s 198ms/step - loss: 1.2340 - accuracy: 0.4449 - val_loss: 1.5529 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "418/418 [==============================] - 83s 198ms/step - loss: 1.2343 - accuracy: 0.4466 - val_loss: 1.5530 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "418/418 [==============================] - 83s 198ms/step - loss: 1.2220 - accuracy: 0.4543 - val_loss: 1.5527 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "418/418 [==============================] - 83s 198ms/step - loss: 1.2397 - accuracy: 0.4406 - val_loss: 1.5527 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_20871.0_images_True_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training opticnet for 0.25% of train size (aka 20871 images) with pretrained: False and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 276 trainable: 276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:15: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  self.fig = plt.figure(figsize=(4,3))\n",
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/418 [..............................] - ETA: 12:38 - loss: 24.6609 - accuracy: 0.2269WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.4639s vs `on_train_batch_end` time: 1.0497s). Check your callbacks.\n",
      "418/418 [==============================] - 510s 1s/step - loss: 3.9084 - accuracy: 0.5150 - val_loss: 1.0737 - val_accuracy: 0.5625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "418/418 [==============================] - 490s 1s/step - loss: 0.5181 - accuracy: 0.8076 - val_loss: 0.4349 - val_accuracy: 0.8125\n",
      "Epoch 3/30\n",
      "418/418 [==============================] - 490s 1s/step - loss: 0.3218 - accuracy: 0.8925 - val_loss: 1.0020 - val_accuracy: 0.6250\n",
      "Epoch 4/30\n",
      "418/418 [==============================] - 491s 1s/step - loss: 0.2635 - accuracy: 0.9162 - val_loss: 1.4119 - val_accuracy: 0.6562\n",
      "Epoch 5/30\n",
      "418/418 [==============================] - 491s 1s/step - loss: 0.2372 - accuracy: 0.9239 - val_loss: 0.7637 - val_accuracy: 0.7812\n",
      "Epoch 6/30\n",
      "418/418 [==============================] - 491s 1s/step - loss: 0.2064 - accuracy: 0.9310 - val_loss: 0.2024 - val_accuracy: 0.9375\n",
      "Epoch 7/30\n",
      "418/418 [==============================] - 491s 1s/step - loss: 0.1842 - accuracy: 0.9378 - val_loss: 0.2857 - val_accuracy: 0.8750\n",
      "Epoch 8/30\n",
      "418/418 [==============================] - 491s 1s/step - loss: 0.1558 - accuracy: 0.9460 - val_loss: 0.2280 - val_accuracy: 0.9375\n",
      "Epoch 9/30\n",
      "418/418 [==============================] - 491s 1s/step - loss: 0.1369 - accuracy: 0.9530 - val_loss: 0.2729 - val_accuracy: 0.8750\n",
      "Epoch 10/30\n",
      "418/418 [==============================] - 491s 1s/step - loss: 0.1082 - accuracy: 0.9622 - val_loss: 0.5326 - val_accuracy: 0.8750\n",
      "Epoch 11/30\n",
      "418/418 [==============================] - 490s 1s/step - loss: 0.0969 - accuracy: 0.9681 - val_loss: 0.0923 - val_accuracy: 0.9688\n",
      "Epoch 12/30\n",
      "418/418 [==============================] - 491s 1s/step - loss: 0.0679 - accuracy: 0.9770 - val_loss: 0.0994 - val_accuracy: 0.9688\n",
      "Epoch 13/30\n",
      "418/418 [==============================] - 491s 1s/step - loss: 0.0624 - accuracy: 0.9778 - val_loss: 0.0183 - val_accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "418/418 [==============================] - 491s 1s/step - loss: 0.0461 - accuracy: 0.9843 - val_loss: 0.0715 - val_accuracy: 0.9688\n",
      "Epoch 15/30\n",
      "418/418 [==============================] - 491s 1s/step - loss: 0.0361 - accuracy: 0.9882 - val_loss: 0.0321 - val_accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "418/418 [==============================] - 491s 1s/step - loss: 0.0259 - accuracy: 0.9920 - val_loss: 0.0097 - val_accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "418/418 [==============================] - 491s 1s/step - loss: 0.0238 - accuracy: 0.9910 - val_loss: 0.0169 - val_accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "418/418 [==============================] - 491s 1s/step - loss: 0.0189 - accuracy: 0.9941 - val_loss: 0.1457 - val_accuracy: 0.9688\n",
      "Epoch 19/30\n",
      "418/418 [==============================] - 491s 1s/step - loss: 0.0083 - accuracy: 0.9969 - val_loss: 0.0093 - val_accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "418/418 [==============================] - 491s 1s/step - loss: 0.0142 - accuracy: 0.9965 - val_loss: 0.0102 - val_accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "418/418 [==============================] - 491s 1s/step - loss: 0.0089 - accuracy: 0.9981 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "418/418 [==============================] - 492s 1s/step - loss: 0.0096 - accuracy: 0.9975 - val_loss: 0.0087 - val_accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "418/418 [==============================] - 492s 1s/step - loss: 0.0068 - accuracy: 0.9979 - val_loss: 6.7301e-04 - val_accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "418/418 [==============================] - 492s 1s/step - loss: 0.0061 - accuracy: 0.9982 - val_loss: 0.0091 - val_accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "418/418 [==============================] - 492s 1s/step - loss: 0.0065 - accuracy: 0.9980 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "418/418 [==============================] - 492s 1s/step - loss: 0.0047 - accuracy: 0.9982 - val_loss: 0.0195 - val_accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "418/418 [==============================] - 492s 1s/step - loss: 0.0045 - accuracy: 0.9985 - val_loss: 8.3250e-04 - val_accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "418/418 [==============================] - 492s 1s/step - loss: 0.0036 - accuracy: 0.9989 - val_loss: 8.7886e-04 - val_accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "418/418 [==============================] - 492s 1s/step - loss: 0.0035 - accuracy: 0.9991 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "418/418 [==============================] - 493s 1s/step - loss: 0.0024 - accuracy: 0.9993 - val_loss: 7.4949e-04 - val_accuracy: 1.0000\n",
      "INFO:tensorflow:Assets written to: ../opticnet/opticnet_30epochs_20871.0_images_True_newWeights_False_lastLayerOnly_rescale-symmetric_normalization/assets\n",
      "Test acc for opticnet: 0.978306\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.40068402 0.39922053 0.39813183 0.4036676 ]\n",
      "Training xception for 0.4% of train size (aka 33393 images) with pretrained: False and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 135 trainable: 135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/668 [..............................] - ETA: 14:11 - loss: 1.3840 - accuracy: 0.2848WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1603s vs `on_train_batch_begin` time: 0.1991s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1603s vs `on_train_batch_end` time: 0.8280s). Check your callbacks.\n",
      "668/668 [==============================] - 523s 775ms/step - loss: 1.1909 - accuracy: 0.6821 - val_loss: 1.2091 - val_accuracy: 0.6250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "668/668 [==============================] - 515s 772ms/step - loss: 0.7991 - accuracy: 0.8071 - val_loss: 1.0676 - val_accuracy: 0.5938\n",
      "Epoch 3/30\n",
      "668/668 [==============================] - 515s 770ms/step - loss: 0.6158 - accuracy: 0.8463 - val_loss: 0.6880 - val_accuracy: 0.8438\n",
      "Epoch 4/30\n",
      "668/668 [==============================] - 515s 770ms/step - loss: 0.4720 - accuracy: 0.8927 - val_loss: 0.3612 - val_accuracy: 0.9688\n",
      "Epoch 5/30\n",
      "668/668 [==============================] - 514s 769ms/step - loss: 0.3633 - accuracy: 0.9196 - val_loss: 0.3506 - val_accuracy: 0.9062\n",
      "Epoch 6/30\n",
      "668/668 [==============================] - 515s 772ms/step - loss: 0.2982 - accuracy: 0.9337 - val_loss: 0.2607 - val_accuracy: 0.9688\n",
      "Epoch 7/30\n",
      "668/668 [==============================] - 516s 773ms/step - loss: 0.2571 - accuracy: 0.9411 - val_loss: 0.4403 - val_accuracy: 0.9062\n",
      "Epoch 8/30\n",
      "668/668 [==============================] - 516s 772ms/step - loss: 0.2228 - accuracy: 0.9483 - val_loss: 0.1135 - val_accuracy: 1.0000\n",
      "Epoch 9/30\n",
      "668/668 [==============================] - 517s 774ms/step - loss: 0.2007 - accuracy: 0.9531 - val_loss: 0.0992 - val_accuracy: 1.0000\n",
      "Epoch 10/30\n",
      "668/668 [==============================] - 515s 771ms/step - loss: 0.1786 - accuracy: 0.9584 - val_loss: 0.0806 - val_accuracy: 1.0000\n",
      "Epoch 11/30\n",
      "668/668 [==============================] - 515s 771ms/step - loss: 0.1535 - accuracy: 0.9654 - val_loss: 0.0696 - val_accuracy: 1.0000\n",
      "Epoch 12/30\n",
      "668/668 [==============================] - 515s 772ms/step - loss: 0.1360 - accuracy: 0.9682 - val_loss: 0.0615 - val_accuracy: 1.0000\n",
      "Epoch 13/30\n",
      "668/668 [==============================] - 517s 774ms/step - loss: 0.1282 - accuracy: 0.9717 - val_loss: 0.0546 - val_accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "668/668 [==============================] - 517s 773ms/step - loss: 0.1161 - accuracy: 0.9748 - val_loss: 0.0494 - val_accuracy: 1.0000\n",
      "Epoch 15/30\n",
      "668/668 [==============================] - 516s 773ms/step - loss: 0.1022 - accuracy: 0.9783 - val_loss: 0.0607 - val_accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "668/668 [==============================] - 517s 774ms/step - loss: 0.0943 - accuracy: 0.9798 - val_loss: 0.0406 - val_accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "668/668 [==============================] - 518s 775ms/step - loss: 0.0860 - accuracy: 0.9829 - val_loss: 0.0378 - val_accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "668/668 [==============================] - 517s 775ms/step - loss: 0.0721 - accuracy: 0.9857 - val_loss: 0.0348 - val_accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "668/668 [==============================] - 518s 776ms/step - loss: 0.0654 - accuracy: 0.9887 - val_loss: 0.0334 - val_accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "668/668 [==============================] - 518s 776ms/step - loss: 0.0619 - accuracy: 0.9890 - val_loss: 0.0311 - val_accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "668/668 [==============================] - 517s 774ms/step - loss: 0.0586 - accuracy: 0.9895 - val_loss: 0.0296 - val_accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "668/668 [==============================] - 517s 774ms/step - loss: 0.0561 - accuracy: 0.9901 - val_loss: 0.0299 - val_accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "668/668 [==============================] - 518s 776ms/step - loss: 0.0466 - accuracy: 0.9925 - val_loss: 0.0272 - val_accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "668/668 [==============================] - 516s 773ms/step - loss: 0.0487 - accuracy: 0.9920 - val_loss: 0.0327 - val_accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "668/668 [==============================] - 516s 773ms/step - loss: 0.0473 - accuracy: 0.9923 - val_loss: 0.0251 - val_accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "668/668 [==============================] - 519s 778ms/step - loss: 0.0475 - accuracy: 0.9922 - val_loss: 0.0245 - val_accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "668/668 [==============================] - 516s 773ms/step - loss: 0.0450 - accuracy: 0.9924 - val_loss: 0.0243 - val_accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "668/668 [==============================] - 518s 775ms/step - loss: 0.0473 - accuracy: 0.9924 - val_loss: 0.0231 - val_accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "668/668 [==============================] - 517s 773ms/step - loss: 0.0446 - accuracy: 0.9930 - val_loss: 0.0593 - val_accuracy: 0.9688\n",
      "Epoch 30/30\n",
      "668/668 [==============================] - 518s 775ms/step - loss: 0.0424 - accuracy: 0.9938 - val_loss: 0.0286 - val_accuracy: 1.0000\n",
      "INFO:tensorflow:Assets written to: ../xception/xception_30epochs_33393.6_images_True_newWeights_False_lastLayerOnly_rescale-symmetric_normalization/assets\n",
      "Test acc for xception: 0.988636\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training resnet for 0.4% of train size (aka 33393 images) with pretrained: False and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 178 trainable: 178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/668 [..............................] - ETA: 7:56 - loss: 1.3786 - accuracy: 0.3816WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1030s vs `on_train_batch_begin` time: 0.1968s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1030s vs `on_train_batch_end` time: 0.3271s). Check your callbacks.\n",
      "668/668 [==============================] - 144s 205ms/step - loss: 1.2288 - accuracy: 0.6150 - val_loss: 1.4504 - val_accuracy: 0.3438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "668/668 [==============================] - 133s 199ms/step - loss: 0.9264 - accuracy: 0.7037 - val_loss: 1.3504 - val_accuracy: 0.4688\n",
      "Epoch 3/30\n",
      "668/668 [==============================] - 133s 199ms/step - loss: 0.7892 - accuracy: 0.7482 - val_loss: 0.9820 - val_accuracy: 0.6562\n",
      "Epoch 4/30\n",
      "668/668 [==============================] - 133s 199ms/step - loss: 0.6795 - accuracy: 0.7988 - val_loss: 1.0210 - val_accuracy: 0.6875\n",
      "Epoch 5/30\n",
      "668/668 [==============================] - 133s 199ms/step - loss: 0.6012 - accuracy: 0.8151 - val_loss: 1.0629 - val_accuracy: 0.6562\n",
      "Epoch 6/30\n",
      "668/668 [==============================] - 133s 199ms/step - loss: 0.5401 - accuracy: 0.8312 - val_loss: 1.2931 - val_accuracy: 0.3750\n",
      "Epoch 7/30\n",
      "668/668 [==============================] - 133s 199ms/step - loss: 0.4892 - accuracy: 0.8398 - val_loss: 0.5269 - val_accuracy: 0.8125\n",
      "Epoch 8/30\n",
      "668/668 [==============================] - 133s 199ms/step - loss: 0.4151 - accuracy: 0.8957 - val_loss: 0.5609 - val_accuracy: 0.8750\n",
      "Epoch 9/30\n",
      "668/668 [==============================] - 133s 199ms/step - loss: 0.3470 - accuracy: 0.9170 - val_loss: 0.2633 - val_accuracy: 0.9688\n",
      "Epoch 10/30\n",
      "668/668 [==============================] - 133s 199ms/step - loss: 0.3019 - accuracy: 0.9262 - val_loss: 0.2067 - val_accuracy: 1.0000\n",
      "Epoch 11/30\n",
      "668/668 [==============================] - 133s 199ms/step - loss: 0.2739 - accuracy: 0.9312 - val_loss: 0.2487 - val_accuracy: 0.9688\n",
      "Epoch 12/30\n",
      "668/668 [==============================] - 133s 199ms/step - loss: 0.2518 - accuracy: 0.9364 - val_loss: 0.1404 - val_accuracy: 1.0000\n",
      "Epoch 13/30\n",
      "668/668 [==============================] - 133s 199ms/step - loss: 0.2207 - accuracy: 0.9438 - val_loss: 0.1255 - val_accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "668/668 [==============================] - 133s 199ms/step - loss: 0.2068 - accuracy: 0.9475 - val_loss: 0.1019 - val_accuracy: 1.0000\n",
      "Epoch 15/30\n",
      "668/668 [==============================] - 133s 199ms/step - loss: 0.1928 - accuracy: 0.9513 - val_loss: 0.1016 - val_accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "668/668 [==============================] - 133s 199ms/step - loss: 0.1804 - accuracy: 0.9537 - val_loss: 0.0851 - val_accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "668/668 [==============================] - 133s 199ms/step - loss: 0.1695 - accuracy: 0.9569 - val_loss: 0.0950 - val_accuracy: 0.9688\n",
      "Epoch 18/30\n",
      "668/668 [==============================] - 133s 199ms/step - loss: 0.1583 - accuracy: 0.9610 - val_loss: 0.0796 - val_accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "668/668 [==============================] - 133s 199ms/step - loss: 0.1527 - accuracy: 0.9621 - val_loss: 0.0933 - val_accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "668/668 [==============================] - 133s 199ms/step - loss: 0.1442 - accuracy: 0.9632 - val_loss: 0.0819 - val_accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "668/668 [==============================] - 133s 199ms/step - loss: 0.1357 - accuracy: 0.9657 - val_loss: 0.0578 - val_accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "668/668 [==============================] - 133s 199ms/step - loss: 0.1322 - accuracy: 0.9677 - val_loss: 0.0594 - val_accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "668/668 [==============================] - 133s 199ms/step - loss: 0.1216 - accuracy: 0.9708 - val_loss: 0.0512 - val_accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "668/668 [==============================] - 133s 199ms/step - loss: 0.1174 - accuracy: 0.9727 - val_loss: 0.0612 - val_accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "668/668 [==============================] - 133s 199ms/step - loss: 0.1078 - accuracy: 0.9743 - val_loss: 0.0481 - val_accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "668/668 [==============================] - 133s 199ms/step - loss: 0.1016 - accuracy: 0.9771 - val_loss: 0.0560 - val_accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "668/668 [==============================] - 133s 199ms/step - loss: 0.1045 - accuracy: 0.9768 - val_loss: 0.0440 - val_accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "668/668 [==============================] - 133s 199ms/step - loss: 0.0999 - accuracy: 0.9781 - val_loss: 0.0436 - val_accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "668/668 [==============================] - 133s 199ms/step - loss: 0.0972 - accuracy: 0.9788 - val_loss: 0.0463 - val_accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "668/668 [==============================] - 133s 199ms/step - loss: 0.0950 - accuracy: 0.9800 - val_loss: 0.0428 - val_accuracy: 1.0000\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_33393.6_images_True_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.988636\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training opticnet for 0.4% of train size (aka 33393 images) with pretrained: False and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 276 trainable: 276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/668 [..............................] - ETA: 20:08 - loss: 35.3095 - accuracy: 0.3121WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.4632s vs `on_train_batch_end` time: 1.0397s). Check your callbacks.\n",
      "668/668 [==============================] - 807s 1s/step - loss: 3.5401 - accuracy: 0.5125 - val_loss: 0.8260 - val_accuracy: 0.6250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "668/668 [==============================] - 787s 1s/step - loss: 0.5077 - accuracy: 0.8170 - val_loss: 3.4807 - val_accuracy: 0.3125\n",
      "Epoch 3/30\n",
      "668/668 [==============================] - 789s 1s/step - loss: 0.3125 - accuracy: 0.8961 - val_loss: 0.6558 - val_accuracy: 0.7188\n",
      "Epoch 4/30\n",
      "668/668 [==============================] - 786s 1s/step - loss: 0.2403 - accuracy: 0.9219 - val_loss: 0.0841 - val_accuracy: 1.0000\n",
      "Epoch 5/30\n",
      "668/668 [==============================] - 787s 1s/step - loss: 0.1944 - accuracy: 0.9359 - val_loss: 0.1642 - val_accuracy: 0.9375\n",
      "Epoch 6/30\n",
      "668/668 [==============================] - 785s 1s/step - loss: 0.1829 - accuracy: 0.9381 - val_loss: 0.0185 - val_accuracy: 1.0000\n",
      "Epoch 7/30\n",
      "668/668 [==============================] - 786s 1s/step - loss: 0.1455 - accuracy: 0.9497 - val_loss: 0.1821 - val_accuracy: 0.9688\n",
      "Epoch 8/30\n",
      "668/668 [==============================] - 783s 1s/step - loss: 0.1403 - accuracy: 0.9528 - val_loss: 0.0169 - val_accuracy: 1.0000\n",
      "Epoch 9/30\n",
      "668/668 [==============================] - 783s 1s/step - loss: 0.1203 - accuracy: 0.9583 - val_loss: 0.1657 - val_accuracy: 0.9375\n",
      "Epoch 10/30\n",
      "668/668 [==============================] - 782s 1s/step - loss: 0.1010 - accuracy: 0.9652 - val_loss: 0.0750 - val_accuracy: 0.9375\n",
      "Epoch 11/30\n",
      "668/668 [==============================] - 783s 1s/step - loss: 0.0906 - accuracy: 0.9697 - val_loss: 0.1042 - val_accuracy: 1.0000\n",
      "Epoch 12/30\n",
      "668/668 [==============================] - 787s 1s/step - loss: 0.0684 - accuracy: 0.9772 - val_loss: 0.0372 - val_accuracy: 0.9688\n",
      "Epoch 13/30\n",
      "668/668 [==============================] - 785s 1s/step - loss: 0.0591 - accuracy: 0.9806 - val_loss: 0.0055 - val_accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "668/668 [==============================] - 786s 1s/step - loss: 0.0447 - accuracy: 0.9850 - val_loss: 0.0349 - val_accuracy: 0.9688\n",
      "Epoch 15/30\n",
      "668/668 [==============================] - 785s 1s/step - loss: 0.0334 - accuracy: 0.9898 - val_loss: 7.4243e-04 - val_accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "668/668 [==============================] - 786s 1s/step - loss: 0.0259 - accuracy: 0.9916 - val_loss: 6.1529e-04 - val_accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "668/668 [==============================] - 786s 1s/step - loss: 0.0199 - accuracy: 0.9936 - val_loss: 5.3821e-04 - val_accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "668/668 [==============================] - 786s 1s/step - loss: 0.0151 - accuracy: 0.9956 - val_loss: 6.2171e-04 - val_accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "668/668 [==============================] - 786s 1s/step - loss: 0.0118 - accuracy: 0.9967 - val_loss: 1.2531e-04 - val_accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "668/668 [==============================] - 786s 1s/step - loss: 0.0124 - accuracy: 0.9962 - val_loss: 7.2268e-04 - val_accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "668/668 [==============================] - 786s 1s/step - loss: 0.0080 - accuracy: 0.9976 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "668/668 [==============================] - 782s 1s/step - loss: 0.0091 - accuracy: 0.9969 - val_loss: 7.4478e-04 - val_accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "668/668 [==============================] - 782s 1s/step - loss: 0.0101 - accuracy: 0.9967 - val_loss: 1.8218e-04 - val_accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "668/668 [==============================] - 782s 1s/step - loss: 0.0060 - accuracy: 0.9983 - val_loss: 4.1305e-04 - val_accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "668/668 [==============================] - 782s 1s/step - loss: 0.0062 - accuracy: 0.9984 - val_loss: 8.3627e-05 - val_accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "668/668 [==============================] - 783s 1s/step - loss: 0.0047 - accuracy: 0.9983 - val_loss: 2.4275e-04 - val_accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "668/668 [==============================] - 787s 1s/step - loss: 0.0055 - accuracy: 0.9983 - val_loss: 6.7816e-05 - val_accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "668/668 [==============================] - 787s 1s/step - loss: 0.0077 - accuracy: 0.9971 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "668/668 [==============================] - 784s 1s/step - loss: 0.0035 - accuracy: 0.9986 - val_loss: 6.4236e-04 - val_accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "668/668 [==============================] - 785s 1s/step - loss: 0.0033 - accuracy: 0.9986 - val_loss: 1.5042e-04 - val_accuracy: 1.0000\n",
      "INFO:tensorflow:Assets written to: ../opticnet/opticnet_30epochs_33393.6_images_True_newWeights_False_lastLayerOnly_rescale-symmetric_normalization/assets\n",
      "Test acc for opticnet: 0.989669\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.49766293 0.4985889  0.50608037 0.50522284]\n",
      "Training xception for 0.5% of train size (aka 41742 images) with pretrained: False and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 135 trainable: 135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/835 [..............................] - ETA: 18:17 - loss: 1.3835 - accuracy: 0.3736WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1610s vs `on_train_batch_begin` time: 0.1959s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1610s vs `on_train_batch_end` time: 0.8630s). Check your callbacks.\n",
      "835/835 [==============================] - 650s 770ms/step - loss: 1.1761 - accuracy: 0.6822 - val_loss: 1.6360 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "835/835 [==============================] - 642s 769ms/step - loss: 0.7878 - accuracy: 0.7696 - val_loss: 1.0826 - val_accuracy: 0.5625\n",
      "Epoch 3/30\n",
      "835/835 [==============================] - 641s 768ms/step - loss: 0.6019 - accuracy: 0.8207 - val_loss: 0.6707 - val_accuracy: 0.8125\n",
      "Epoch 4/30\n",
      "835/835 [==============================] - 642s 769ms/step - loss: 0.4450 - accuracy: 0.8876 - val_loss: 0.3819 - val_accuracy: 0.9375\n",
      "Epoch 5/30\n",
      "835/835 [==============================] - 642s 769ms/step - loss: 0.3366 - accuracy: 0.9178 - val_loss: 0.1878 - val_accuracy: 1.0000\n",
      "Epoch 6/30\n",
      "835/835 [==============================] - 643s 770ms/step - loss: 0.2651 - accuracy: 0.9340 - val_loss: 0.4383 - val_accuracy: 0.9062\n",
      "Epoch 7/30\n",
      "835/835 [==============================] - 639s 765ms/step - loss: 0.2130 - accuracy: 0.9481 - val_loss: 0.1196 - val_accuracy: 1.0000\n",
      "Epoch 8/30\n",
      "835/835 [==============================] - 646s 773ms/step - loss: 0.1742 - accuracy: 0.9581 - val_loss: 0.1175 - val_accuracy: 0.9688\n",
      "Epoch 9/30\n",
      "835/835 [==============================] - 642s 768ms/step - loss: 0.1514 - accuracy: 0.9622 - val_loss: 0.0680 - val_accuracy: 1.0000\n",
      "Epoch 10/30\n",
      "835/835 [==============================] - 642s 769ms/step - loss: 0.1384 - accuracy: 0.9663 - val_loss: 0.1173 - val_accuracy: 0.9688\n",
      "Epoch 11/30\n",
      "835/835 [==============================] - 639s 765ms/step - loss: 0.1227 - accuracy: 0.9704 - val_loss: 0.0473 - val_accuracy: 1.0000\n",
      "Epoch 12/30\n",
      "835/835 [==============================] - 639s 766ms/step - loss: 0.1037 - accuracy: 0.9755 - val_loss: 0.0407 - val_accuracy: 1.0000\n",
      "Epoch 13/30\n",
      "835/835 [==============================] - 642s 769ms/step - loss: 0.0858 - accuracy: 0.9810 - val_loss: 0.0657 - val_accuracy: 0.9688\n",
      "Epoch 14/30\n",
      "835/835 [==============================] - 641s 767ms/step - loss: 0.0707 - accuracy: 0.9846 - val_loss: 0.0381 - val_accuracy: 1.0000\n",
      "Epoch 15/30\n",
      "835/835 [==============================] - 641s 768ms/step - loss: 0.0609 - accuracy: 0.9879 - val_loss: 0.0263 - val_accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "835/835 [==============================] - 642s 768ms/step - loss: 0.0549 - accuracy: 0.9887 - val_loss: 0.0293 - val_accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "835/835 [==============================] - 640s 767ms/step - loss: 0.0488 - accuracy: 0.9903 - val_loss: 0.0818 - val_accuracy: 0.9688\n",
      "Epoch 18/30\n",
      "835/835 [==============================] - 643s 770ms/step - loss: 0.0446 - accuracy: 0.9914 - val_loss: 0.0198 - val_accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "835/835 [==============================] - 640s 767ms/step - loss: 0.0413 - accuracy: 0.9926 - val_loss: 0.0736 - val_accuracy: 0.9688\n",
      "Epoch 20/30\n",
      "835/835 [==============================] - 642s 769ms/step - loss: 0.0405 - accuracy: 0.9928 - val_loss: 0.0231 - val_accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "835/835 [==============================] - 643s 770ms/step - loss: 0.0368 - accuracy: 0.9934 - val_loss: 0.0311 - val_accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "835/835 [==============================] - 644s 771ms/step - loss: 0.0347 - accuracy: 0.9943 - val_loss: 0.0497 - val_accuracy: 0.9688\n",
      "Epoch 23/30\n",
      "835/835 [==============================] - 639s 765ms/step - loss: 0.0321 - accuracy: 0.9948 - val_loss: 0.0671 - val_accuracy: 0.9688\n",
      "Epoch 24/30\n",
      "835/835 [==============================] - 641s 768ms/step - loss: 0.0314 - accuracy: 0.9948 - val_loss: 0.0331 - val_accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "835/835 [==============================] - 643s 770ms/step - loss: 0.0306 - accuracy: 0.9951 - val_loss: 0.0164 - val_accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "835/835 [==============================] - 641s 767ms/step - loss: 0.0281 - accuracy: 0.9956 - val_loss: 0.0697 - val_accuracy: 0.9688\n",
      "Epoch 27/30\n",
      "835/835 [==============================] - 640s 767ms/step - loss: 0.0273 - accuracy: 0.9958 - val_loss: 0.0343 - val_accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "835/835 [==============================] - 641s 768ms/step - loss: 0.0279 - accuracy: 0.9955 - val_loss: 0.0195 - val_accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "835/835 [==============================] - 641s 768ms/step - loss: 0.0267 - accuracy: 0.9957 - val_loss: 0.0294 - val_accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "835/835 [==============================] - 638s 764ms/step - loss: 0.0274 - accuracy: 0.9956 - val_loss: 0.0194 - val_accuracy: 1.0000\n",
      "INFO:tensorflow:Assets written to: ../xception/xception_30epochs_41742.0_images_True_newWeights_False_lastLayerOnly_rescale-symmetric_normalization/assets\n",
      "Test acc for xception: 0.993802\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training resnet for 0.5% of train size (aka 41742 images) with pretrained: False and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 178 trainable: 178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/835 [..............................] - ETA: 9:52 - loss: 1.3773 - accuracy: 0.2854 WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1014s vs `on_train_batch_begin` time: 0.1812s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1014s vs `on_train_batch_end` time: 0.3382s). Check your callbacks.\n",
      "835/835 [==============================] - 177s 203ms/step - loss: 1.2861 - accuracy: 0.4421 - val_loss: 1.5436 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "835/835 [==============================] - 165s 198ms/step - loss: 1.2306 - accuracy: 0.4469 - val_loss: 1.5486 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "835/835 [==============================] - 165s 198ms/step - loss: 1.2320 - accuracy: 0.4449 - val_loss: 1.5513 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "835/835 [==============================] - 166s 198ms/step - loss: 1.2304 - accuracy: 0.4487 - val_loss: 1.5523 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "835/835 [==============================] - 166s 198ms/step - loss: 1.2331 - accuracy: 0.4420 - val_loss: 1.5543 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "835/835 [==============================] - 166s 199ms/step - loss: 1.2279 - accuracy: 0.4508 - val_loss: 1.5501 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "835/835 [==============================] - 165s 198ms/step - loss: 1.2302 - accuracy: 0.4431 - val_loss: 1.5550 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "835/835 [==============================] - 165s 198ms/step - loss: 1.2341 - accuracy: 0.4400 - val_loss: 1.5556 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "835/835 [==============================] - 165s 198ms/step - loss: 1.2295 - accuracy: 0.4476 - val_loss: 1.5542 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "835/835 [==============================] - 166s 198ms/step - loss: 1.2287 - accuracy: 0.4447 - val_loss: 1.5519 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "835/835 [==============================] - 166s 198ms/step - loss: 1.2292 - accuracy: 0.4449 - val_loss: 1.5508 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "835/835 [==============================] - 165s 198ms/step - loss: 1.2338 - accuracy: 0.4424 - val_loss: 1.5529 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "835/835 [==============================] - 166s 199ms/step - loss: 1.2320 - accuracy: 0.4450 - val_loss: 1.5533 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "835/835 [==============================] - 166s 198ms/step - loss: 1.2327 - accuracy: 0.4441 - val_loss: 1.5532 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "835/835 [==============================] - 166s 199ms/step - loss: 1.2314 - accuracy: 0.4469 - val_loss: 1.5532 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "835/835 [==============================] - 166s 199ms/step - loss: 1.2289 - accuracy: 0.4469 - val_loss: 1.5527 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "835/835 [==============================] - 166s 198ms/step - loss: 1.2318 - accuracy: 0.4488 - val_loss: 1.5533 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "835/835 [==============================] - 165s 198ms/step - loss: 1.2331 - accuracy: 0.4456 - val_loss: 1.5530 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "835/835 [==============================] - 166s 199ms/step - loss: 1.2315 - accuracy: 0.4433 - val_loss: 1.5538 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "835/835 [==============================] - 166s 199ms/step - loss: 1.2316 - accuracy: 0.4418 - val_loss: 1.5537 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "835/835 [==============================] - 166s 199ms/step - loss: 1.2328 - accuracy: 0.4453 - val_loss: 1.5533 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "835/835 [==============================] - 166s 198ms/step - loss: 1.2361 - accuracy: 0.4416 - val_loss: 1.5537 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "835/835 [==============================] - 166s 198ms/step - loss: 1.2294 - accuracy: 0.4466 - val_loss: 1.5536 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "835/835 [==============================] - 166s 198ms/step - loss: 1.2373 - accuracy: 0.4385 - val_loss: 1.5537 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "835/835 [==============================] - 166s 198ms/step - loss: 1.2316 - accuracy: 0.4460 - val_loss: 1.5536 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "835/835 [==============================] - 166s 198ms/step - loss: 1.2326 - accuracy: 0.4477 - val_loss: 1.5534 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "835/835 [==============================] - 166s 198ms/step - loss: 1.2316 - accuracy: 0.4429 - val_loss: 1.5534 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "835/835 [==============================] - 165s 198ms/step - loss: 1.2334 - accuracy: 0.4435 - val_loss: 1.5536 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "835/835 [==============================] - 165s 198ms/step - loss: 1.2316 - accuracy: 0.4451 - val_loss: 1.5536 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "835/835 [==============================] - 165s 198ms/step - loss: 1.2325 - accuracy: 0.4427 - val_loss: 1.5536 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_41742.0_images_True_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training opticnet for 0.5% of train size (aka 41742 images) with pretrained: False and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 276 trainable: 276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/835 [..............................] - ETA: 25:38 - loss: 21.9329 - accuracy: 0.3115WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.4663s vs `on_train_batch_end` time: 1.0593s). Check your callbacks.\n",
      "835/835 [==============================] - 1002s 1s/step - loss: 2.1571 - accuracy: 0.6244 - val_loss: 0.2544 - val_accuracy: 0.8750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "835/835 [==============================] - 979s 1s/step - loss: 0.3214 - accuracy: 0.8912 - val_loss: 0.2362 - val_accuracy: 0.8750\n",
      "Epoch 3/30\n",
      "835/835 [==============================] - 978s 1s/step - loss: 0.2263 - accuracy: 0.9248 - val_loss: 0.5144 - val_accuracy: 0.7188\n",
      "Epoch 4/30\n",
      "835/835 [==============================] - 981s 1s/step - loss: 0.1965 - accuracy: 0.9349 - val_loss: 0.0841 - val_accuracy: 1.0000\n",
      "Epoch 5/30\n",
      "835/835 [==============================] - 981s 1s/step - loss: 0.1657 - accuracy: 0.9458 - val_loss: 0.1842 - val_accuracy: 0.9062\n",
      "Epoch 6/30\n",
      "835/835 [==============================] - 981s 1s/step - loss: 0.1551 - accuracy: 0.9484 - val_loss: 0.1043 - val_accuracy: 1.0000\n",
      "Epoch 7/30\n",
      "835/835 [==============================] - 982s 1s/step - loss: 0.1328 - accuracy: 0.9541 - val_loss: 0.0438 - val_accuracy: 1.0000\n",
      "Epoch 8/30\n",
      "835/835 [==============================] - 980s 1s/step - loss: 0.1152 - accuracy: 0.9602 - val_loss: 0.0213 - val_accuracy: 1.0000\n",
      "Epoch 9/30\n",
      "835/835 [==============================] - 981s 1s/step - loss: 0.0967 - accuracy: 0.9659 - val_loss: 0.0531 - val_accuracy: 0.9688\n",
      "Epoch 10/30\n",
      "835/835 [==============================] - 981s 1s/step - loss: 0.0763 - accuracy: 0.9737 - val_loss: 0.0356 - val_accuracy: 1.0000\n",
      "Epoch 11/30\n",
      "835/835 [==============================] - 982s 1s/step - loss: 0.0698 - accuracy: 0.9756 - val_loss: 0.2889 - val_accuracy: 0.9688\n",
      "Epoch 12/30\n",
      "835/835 [==============================] - 981s 1s/step - loss: 0.0545 - accuracy: 0.9815 - val_loss: 0.1243 - val_accuracy: 0.9688\n",
      "Epoch 13/30\n",
      "835/835 [==============================] - 981s 1s/step - loss: 0.0410 - accuracy: 0.9854 - val_loss: 0.0571 - val_accuracy: 0.9688\n",
      "Epoch 14/30\n",
      "835/835 [==============================] - 982s 1s/step - loss: 0.0316 - accuracy: 0.9894 - val_loss: 0.0848 - val_accuracy: 0.9375\n",
      "Epoch 15/30\n",
      "835/835 [==============================] - 983s 1s/step - loss: 0.0256 - accuracy: 0.9914 - val_loss: 0.0076 - val_accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "835/835 [==============================] - 983s 1s/step - loss: 0.0221 - accuracy: 0.9930 - val_loss: 0.1441 - val_accuracy: 0.9688\n",
      "Epoch 17/30\n",
      "835/835 [==============================] - 984s 1s/step - loss: 0.0195 - accuracy: 0.9940 - val_loss: 0.2324 - val_accuracy: 0.9688\n",
      "Epoch 18/30\n",
      "835/835 [==============================] - 984s 1s/step - loss: 0.0137 - accuracy: 0.9958 - val_loss: 0.0721 - val_accuracy: 0.9688\n",
      "Epoch 19/30\n",
      "835/835 [==============================] - 984s 1s/step - loss: 0.0148 - accuracy: 0.9955 - val_loss: 0.0948 - val_accuracy: 0.9375\n",
      "Epoch 20/30\n",
      "835/835 [==============================] - 984s 1s/step - loss: 0.0145 - accuracy: 0.9956 - val_loss: 0.1739 - val_accuracy: 0.9688\n",
      "Epoch 21/30\n",
      "835/835 [==============================] - 985s 1s/step - loss: 0.0088 - accuracy: 0.9969 - val_loss: 0.0905 - val_accuracy: 0.9688\n",
      "Epoch 22/30\n",
      "835/835 [==============================] - 985s 1s/step - loss: 0.0077 - accuracy: 0.9976 - val_loss: 0.2963 - val_accuracy: 0.9688\n",
      "Epoch 23/30\n",
      "835/835 [==============================] - 985s 1s/step - loss: 0.0075 - accuracy: 0.9977 - val_loss: 0.1120 - val_accuracy: 0.9688\n",
      "Epoch 24/30\n",
      "835/835 [==============================] - 986s 1s/step - loss: 0.0070 - accuracy: 0.9978 - val_loss: 0.1660 - val_accuracy: 0.9688\n",
      "Epoch 25/30\n",
      "835/835 [==============================] - 986s 1s/step - loss: 0.0052 - accuracy: 0.9983 - val_loss: 0.4031 - val_accuracy: 0.9688\n",
      "Epoch 26/30\n",
      "835/835 [==============================] - 990s 1s/step - loss: 0.0056 - accuracy: 0.9979 - val_loss: 0.2828 - val_accuracy: 0.9688\n",
      "Epoch 27/30\n",
      "835/835 [==============================] - 982s 1s/step - loss: 0.0052 - accuracy: 0.9982 - val_loss: 0.3377 - val_accuracy: 0.9688\n",
      "Epoch 28/30\n",
      "835/835 [==============================] - 983s 1s/step - loss: 0.0050 - accuracy: 0.9981 - val_loss: 0.3756 - val_accuracy: 0.9688\n",
      "Epoch 29/30\n",
      "835/835 [==============================] - 985s 1s/step - loss: 0.0048 - accuracy: 0.9983 - val_loss: 0.3582 - val_accuracy: 0.9688\n",
      "Epoch 30/30\n",
      "835/835 [==============================] - 983s 1s/step - loss: 0.0040 - accuracy: 0.9984 - val_loss: 0.2691 - val_accuracy: 0.9688\n",
      "INFO:tensorflow:Assets written to: ../opticnet/opticnet_30epochs_41742.0_images_True_newWeights_False_lastLayerOnly_rescale-symmetric_normalization/assets\n",
      "Test acc for opticnet: 0.990702\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.59832795 0.59790351 0.60750793 0.6042247 ]\n",
      "Training xception for 0.6% of train size (aka 50090 images) with pretrained: False and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 135 trainable: 135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "   6/1002 [..............................] - ETA: 22:16 - loss: 1.3835 - accuracy: 0.2734WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1629s vs `on_train_batch_begin` time: 0.1982s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1629s vs `on_train_batch_end` time: 0.8730s). Check your callbacks.\n",
      "1002/1002 [==============================] - 786s 777ms/step - loss: 1.1292 - accuracy: 0.7090 - val_loss: 1.2335 - val_accuracy: 0.5625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "1002/1002 [==============================] - 775s 773ms/step - loss: 0.6982 - accuracy: 0.8153 - val_loss: 0.6630 - val_accuracy: 0.8750\n",
      "Epoch 3/30\n",
      "1002/1002 [==============================] - 774s 772ms/step - loss: 0.4354 - accuracy: 0.8973 - val_loss: 0.2564 - val_accuracy: 0.9688\n",
      "Epoch 4/30\n",
      "1002/1002 [==============================] - 774s 773ms/step - loss: 0.3168 - accuracy: 0.9237 - val_loss: 0.1893 - val_accuracy: 0.9688\n",
      "Epoch 5/30\n",
      "1002/1002 [==============================] - 773s 772ms/step - loss: 0.2480 - accuracy: 0.9388 - val_loss: 0.1687 - val_accuracy: 0.9688\n",
      "Epoch 6/30\n",
      "1002/1002 [==============================] - 773s 772ms/step - loss: 0.2066 - accuracy: 0.9474 - val_loss: 0.0829 - val_accuracy: 1.0000\n",
      "Epoch 7/30\n",
      "1002/1002 [==============================] - 776s 775ms/step - loss: 0.1767 - accuracy: 0.9555 - val_loss: 0.0641 - val_accuracy: 1.0000\n",
      "Epoch 8/30\n",
      "1002/1002 [==============================] - 774s 773ms/step - loss: 0.1525 - accuracy: 0.9603 - val_loss: 0.0703 - val_accuracy: 1.0000\n",
      "Epoch 9/30\n",
      "1002/1002 [==============================] - 774s 773ms/step - loss: 0.1371 - accuracy: 0.9648 - val_loss: 0.0428 - val_accuracy: 1.0000\n",
      "Epoch 10/30\n",
      "1002/1002 [==============================] - 773s 771ms/step - loss: 0.1127 - accuracy: 0.9706 - val_loss: 0.0654 - val_accuracy: 0.9688\n",
      "Epoch 11/30\n",
      "1002/1002 [==============================] - 773s 771ms/step - loss: 0.1043 - accuracy: 0.9746 - val_loss: 0.0364 - val_accuracy: 1.0000\n",
      "Epoch 12/30\n",
      "1002/1002 [==============================] - 772s 770ms/step - loss: 0.0879 - accuracy: 0.9780 - val_loss: 0.0268 - val_accuracy: 1.0000\n",
      "Epoch 13/30\n",
      "1002/1002 [==============================] - 772s 771ms/step - loss: 0.0774 - accuracy: 0.9814 - val_loss: 0.0254 - val_accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "1002/1002 [==============================] - 773s 772ms/step - loss: 0.0701 - accuracy: 0.9834 - val_loss: 0.0243 - val_accuracy: 1.0000\n",
      "Epoch 15/30\n",
      "1002/1002 [==============================] - 773s 771ms/step - loss: 0.0577 - accuracy: 0.9875 - val_loss: 0.0189 - val_accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "1002/1002 [==============================] - 772s 770ms/step - loss: 0.0512 - accuracy: 0.9896 - val_loss: 0.0174 - val_accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "1002/1002 [==============================] - 773s 771ms/step - loss: 0.0467 - accuracy: 0.9907 - val_loss: 0.0160 - val_accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "1002/1002 [==============================] - 771s 770ms/step - loss: 0.0455 - accuracy: 0.9915 - val_loss: 0.0194 - val_accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "1002/1002 [==============================] - 772s 771ms/step - loss: 0.0436 - accuracy: 0.9918 - val_loss: 0.0171 - val_accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "1002/1002 [==============================] - 771s 770ms/step - loss: 0.0406 - accuracy: 0.9921 - val_loss: 0.1767 - val_accuracy: 0.9688\n",
      "Epoch 21/30\n",
      "1002/1002 [==============================] - 773s 771ms/step - loss: 0.0350 - accuracy: 0.9940 - val_loss: 0.0136 - val_accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "1002/1002 [==============================] - 771s 770ms/step - loss: 0.0362 - accuracy: 0.9940 - val_loss: 0.1830 - val_accuracy: 0.9688\n",
      "Epoch 23/30\n",
      "1002/1002 [==============================] - 773s 771ms/step - loss: 0.0353 - accuracy: 0.9938 - val_loss: 0.1896 - val_accuracy: 0.9688\n",
      "Epoch 24/30\n",
      "1002/1002 [==============================] - 771s 769ms/step - loss: 0.0312 - accuracy: 0.9946 - val_loss: 0.1725 - val_accuracy: 0.9688\n",
      "Epoch 25/30\n",
      "1002/1002 [==============================] - 772s 771ms/step - loss: 0.0290 - accuracy: 0.9949 - val_loss: 0.0352 - val_accuracy: 0.9688\n",
      "Epoch 26/30\n",
      "1002/1002 [==============================] - 772s 771ms/step - loss: 0.0313 - accuracy: 0.9946 - val_loss: 0.1298 - val_accuracy: 0.9688\n",
      "Epoch 27/30\n",
      "1002/1002 [==============================] - 772s 771ms/step - loss: 0.0295 - accuracy: 0.9947 - val_loss: 0.1874 - val_accuracy: 0.9688\n",
      "Epoch 28/30\n",
      "1002/1002 [==============================] - 772s 771ms/step - loss: 0.0278 - accuracy: 0.9952 - val_loss: 0.0465 - val_accuracy: 0.9688\n",
      "Epoch 29/30\n",
      "1002/1002 [==============================] - 771s 770ms/step - loss: 0.0301 - accuracy: 0.9949 - val_loss: 0.1927 - val_accuracy: 0.9688\n",
      "Epoch 30/30\n",
      "1002/1002 [==============================] - 771s 769ms/step - loss: 0.0280 - accuracy: 0.9954 - val_loss: 0.1702 - val_accuracy: 0.9688\n",
      "INFO:tensorflow:Assets written to: ../xception/xception_30epochs_50090.4_images_True_newWeights_False_lastLayerOnly_rescale-symmetric_normalization/assets\n",
      "Test acc for xception: 0.995868\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training resnet for 0.6% of train size (aka 50090 images) with pretrained: False and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 178 trainable: 178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "   6/1002 [..............................] - ETA: 11:59 - loss: 1.3770 - accuracy: 0.3226WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1042s vs `on_train_batch_begin` time: 0.1928s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1042s vs `on_train_batch_end` time: 0.3316s). Check your callbacks.\n",
      "1002/1002 [==============================] - 211s 204ms/step - loss: 1.1956 - accuracy: 0.6102 - val_loss: 1.6159 - val_accuracy: 0.2812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "1002/1002 [==============================] - 199s 199ms/step - loss: 0.8754 - accuracy: 0.7082 - val_loss: 1.1903 - val_accuracy: 0.5625\n",
      "Epoch 3/30\n",
      "1002/1002 [==============================] - 199s 199ms/step - loss: 0.7832 - accuracy: 0.7375 - val_loss: 0.9717 - val_accuracy: 0.5938\n",
      "Epoch 4/30\n",
      "1002/1002 [==============================] - 199s 199ms/step - loss: 0.7213 - accuracy: 0.7536 - val_loss: 1.9534 - val_accuracy: 0.2812\n",
      "Epoch 5/30\n",
      "1002/1002 [==============================] - 199s 199ms/step - loss: 0.6809 - accuracy: 0.7681 - val_loss: 1.1053 - val_accuracy: 0.6562\n",
      "Epoch 6/30\n",
      "1002/1002 [==============================] - 199s 199ms/step - loss: 0.6318 - accuracy: 0.7957 - val_loss: 0.7711 - val_accuracy: 0.7500\n",
      "Epoch 7/30\n",
      "1002/1002 [==============================] - 199s 198ms/step - loss: 0.5795 - accuracy: 0.8099 - val_loss: 1.2012 - val_accuracy: 0.5312\n",
      "Epoch 8/30\n",
      "1002/1002 [==============================] - 199s 198ms/step - loss: 0.5016 - accuracy: 0.8307 - val_loss: 0.8035 - val_accuracy: 0.6875\n",
      "Epoch 9/30\n",
      "1002/1002 [==============================] - 199s 199ms/step - loss: 0.4336 - accuracy: 0.8511 - val_loss: 0.8311 - val_accuracy: 0.6250\n",
      "Epoch 10/30\n",
      "1002/1002 [==============================] - 199s 199ms/step - loss: 0.3878 - accuracy: 0.8631 - val_loss: 0.3685 - val_accuracy: 0.9375\n",
      "Epoch 11/30\n",
      "1002/1002 [==============================] - 199s 199ms/step - loss: 0.3296 - accuracy: 0.9188 - val_loss: 0.3452 - val_accuracy: 0.9375\n",
      "Epoch 12/30\n",
      "1002/1002 [==============================] - 199s 199ms/step - loss: 0.2797 - accuracy: 0.9292 - val_loss: 0.2202 - val_accuracy: 0.9688\n",
      "Epoch 13/30\n",
      "1002/1002 [==============================] - 199s 199ms/step - loss: 0.2451 - accuracy: 0.9368 - val_loss: 0.1618 - val_accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "1002/1002 [==============================] - 199s 199ms/step - loss: 0.2198 - accuracy: 0.9421 - val_loss: 0.2343 - val_accuracy: 0.9375\n",
      "Epoch 15/30\n",
      "1002/1002 [==============================] - 199s 199ms/step - loss: 0.2051 - accuracy: 0.9467 - val_loss: 0.1001 - val_accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "1002/1002 [==============================] - 199s 199ms/step - loss: 0.1902 - accuracy: 0.9496 - val_loss: 0.0988 - val_accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "1002/1002 [==============================] - 199s 199ms/step - loss: 0.1754 - accuracy: 0.9538 - val_loss: 0.0877 - val_accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "1002/1002 [==============================] - 199s 199ms/step - loss: 0.1679 - accuracy: 0.9559 - val_loss: 0.0998 - val_accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "1002/1002 [==============================] - 199s 199ms/step - loss: 0.1488 - accuracy: 0.9609 - val_loss: 0.0664 - val_accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "1002/1002 [==============================] - 199s 199ms/step - loss: 0.1475 - accuracy: 0.9625 - val_loss: 0.0558 - val_accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "1002/1002 [==============================] - 199s 199ms/step - loss: 0.1388 - accuracy: 0.9652 - val_loss: 0.0527 - val_accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "1002/1002 [==============================] - 199s 199ms/step - loss: 0.1323 - accuracy: 0.9655 - val_loss: 0.0499 - val_accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "1002/1002 [==============================] - 199s 199ms/step - loss: 0.1267 - accuracy: 0.9677 - val_loss: 0.0549 - val_accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "1002/1002 [==============================] - 199s 199ms/step - loss: 0.1222 - accuracy: 0.9695 - val_loss: 0.0618 - val_accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "1002/1002 [==============================] - 199s 199ms/step - loss: 0.1143 - accuracy: 0.9719 - val_loss: 0.0413 - val_accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "1002/1002 [==============================] - 199s 199ms/step - loss: 0.1065 - accuracy: 0.9743 - val_loss: 0.0443 - val_accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "1002/1002 [==============================] - 199s 199ms/step - loss: 0.1025 - accuracy: 0.9755 - val_loss: 0.0391 - val_accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "1002/1002 [==============================] - 199s 199ms/step - loss: 0.0968 - accuracy: 0.9778 - val_loss: 0.0407 - val_accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "1002/1002 [==============================] - 199s 199ms/step - loss: 0.0972 - accuracy: 0.9775 - val_loss: 0.0384 - val_accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "1002/1002 [==============================] - 199s 199ms/step - loss: 0.0984 - accuracy: 0.9770 - val_loss: 0.0346 - val_accuracy: 1.0000\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_50090.4_images_True_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.993802\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training opticnet for 0.6% of train size (aka 50090 images) with pretrained: False and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 276 trainable: 276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "   6/1002 [..............................] - ETA: 30:15 - loss: 23.7573 - accuracy: 0.2911WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.4649s vs `on_train_batch_end` time: 1.0344s). Check your callbacks.\n",
      "1002/1002 [==============================] - 1193s 1s/step - loss: 2.2728 - accuracy: 0.6349 - val_loss: 1.3037 - val_accuracy: 0.5312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "1002/1002 [==============================] - 1174s 1s/step - loss: 0.3159 - accuracy: 0.8928 - val_loss: 0.2117 - val_accuracy: 0.9062\n",
      "Epoch 3/30\n",
      "1002/1002 [==============================] - 1173s 1s/step - loss: 0.2351 - accuracy: 0.9230 - val_loss: 0.6924 - val_accuracy: 0.8125\n",
      "Epoch 4/30\n",
      "1002/1002 [==============================] - 1174s 1s/step - loss: 0.1908 - accuracy: 0.9375 - val_loss: 0.0350 - val_accuracy: 0.9688\n",
      "Epoch 5/30\n",
      "1002/1002 [==============================] - 1174s 1s/step - loss: 0.1645 - accuracy: 0.9453 - val_loss: 0.0382 - val_accuracy: 0.9688\n",
      "Epoch 6/30\n",
      "1002/1002 [==============================] - 1175s 1s/step - loss: 0.1487 - accuracy: 0.9490 - val_loss: 0.0963 - val_accuracy: 0.9688\n",
      "Epoch 7/30\n",
      "1002/1002 [==============================] - 1175s 1s/step - loss: 0.1286 - accuracy: 0.9573 - val_loss: 0.0695 - val_accuracy: 0.9688\n",
      "Epoch 8/30\n",
      "1002/1002 [==============================] - 1176s 1s/step - loss: 0.1044 - accuracy: 0.9656 - val_loss: 0.0413 - val_accuracy: 0.9688\n",
      "Epoch 9/30\n",
      "1002/1002 [==============================] - 1175s 1s/step - loss: 0.0918 - accuracy: 0.9681 - val_loss: 0.0322 - val_accuracy: 0.9688\n",
      "Epoch 10/30\n",
      "1002/1002 [==============================] - 1177s 1s/step - loss: 0.0776 - accuracy: 0.9730 - val_loss: 0.0075 - val_accuracy: 1.0000\n",
      "Epoch 11/30\n",
      "1002/1002 [==============================] - 1175s 1s/step - loss: 0.0641 - accuracy: 0.9786 - val_loss: 0.0062 - val_accuracy: 1.0000\n",
      "Epoch 12/30\n",
      "1002/1002 [==============================] - 1174s 1s/step - loss: 0.0485 - accuracy: 0.9837 - val_loss: 0.0826 - val_accuracy: 0.9688\n",
      "Epoch 13/30\n",
      "1002/1002 [==============================] - 1177s 1s/step - loss: 0.0363 - accuracy: 0.9881 - val_loss: 0.0285 - val_accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "1002/1002 [==============================] - 1170s 1s/step - loss: 0.0332 - accuracy: 0.9894 - val_loss: 0.1819 - val_accuracy: 0.9688\n",
      "Epoch 15/30\n",
      "1002/1002 [==============================] - 1177s 1s/step - loss: 0.0237 - accuracy: 0.9931 - val_loss: 0.0206 - val_accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "1002/1002 [==============================] - 1175s 1s/step - loss: 0.0202 - accuracy: 0.9940 - val_loss: 0.1008 - val_accuracy: 0.9688\n",
      "Epoch 17/30\n",
      "1002/1002 [==============================] - 1178s 1s/step - loss: 0.0175 - accuracy: 0.9950 - val_loss: 0.1284 - val_accuracy: 0.9688\n",
      "Epoch 18/30\n",
      "1002/1002 [==============================] - 1175s 1s/step - loss: 0.0144 - accuracy: 0.9959 - val_loss: 0.0249 - val_accuracy: 0.9688\n",
      "Epoch 19/30\n",
      "1002/1002 [==============================] - 1177s 1s/step - loss: 0.0137 - accuracy: 0.9959 - val_loss: 0.2510 - val_accuracy: 0.9688\n",
      "Epoch 20/30\n",
      "1002/1002 [==============================] - 1177s 1s/step - loss: 0.0105 - accuracy: 0.9967 - val_loss: 0.3264 - val_accuracy: 0.9688\n",
      "Epoch 21/30\n",
      "1002/1002 [==============================] - 1177s 1s/step - loss: 0.0106 - accuracy: 0.9969 - val_loss: 0.1036 - val_accuracy: 0.9688\n",
      "Epoch 22/30\n",
      "1002/1002 [==============================] - 1176s 1s/step - loss: 0.0084 - accuracy: 0.9974 - val_loss: 0.2709 - val_accuracy: 0.9688\n",
      "Epoch 23/30\n",
      "1002/1002 [==============================] - 1178s 1s/step - loss: 0.0091 - accuracy: 0.9972 - val_loss: 0.0180 - val_accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "1002/1002 [==============================] - 1177s 1s/step - loss: 0.0071 - accuracy: 0.9974 - val_loss: 0.1610 - val_accuracy: 0.9688\n",
      "Epoch 25/30\n",
      "1002/1002 [==============================] - 1175s 1s/step - loss: 0.0065 - accuracy: 0.9977 - val_loss: 0.0787 - val_accuracy: 0.9688\n",
      "Epoch 26/30\n",
      "1002/1002 [==============================] - 1177s 1s/step - loss: 0.0063 - accuracy: 0.9978 - val_loss: 0.1675 - val_accuracy: 0.9688\n",
      "Epoch 27/30\n",
      "1002/1002 [==============================] - 1178s 1s/step - loss: 0.0055 - accuracy: 0.9980 - val_loss: 0.1956 - val_accuracy: 0.9688\n",
      "Epoch 28/30\n",
      "1002/1002 [==============================] - 1176s 1s/step - loss: 0.0051 - accuracy: 0.9977 - val_loss: 0.1668 - val_accuracy: 0.9688\n",
      "Epoch 29/30\n",
      "1002/1002 [==============================] - 1176s 1s/step - loss: 0.0050 - accuracy: 0.9980 - val_loss: 0.1206 - val_accuracy: 0.9688\n",
      "Epoch 30/30\n",
      "1002/1002 [==============================] - 1176s 1s/step - loss: 0.0048 - accuracy: 0.9979 - val_loss: 0.1069 - val_accuracy: 0.9688\n",
      "INFO:tensorflow:Assets written to: ../opticnet/opticnet_30epochs_50090.4_images_True_newWeights_False_lastLayerOnly_rescale-symmetric_normalization/assets\n",
      "Test acc for opticnet: 0.993802\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.7466084  0.75032926 0.75625661 0.75069638]\n",
      "Training xception for 0.75% of train size (aka 62613 images) with pretrained: False and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 135 trainable: 135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "   6/1253 [..............................] - ETA: 26:43 - loss: 1.3825 - accuracy: 0.4341WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1598s vs `on_train_batch_begin` time: 0.1971s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1598s vs `on_train_batch_end` time: 0.8392s). Check your callbacks.\n",
      "1253/1253 [==============================] - 990s 786ms/step - loss: 1.1023 - accuracy: 0.7120 - val_loss: 0.9103 - val_accuracy: 0.7188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "1253/1253 [==============================] - 983s 784ms/step - loss: 0.5958 - accuracy: 0.8495 - val_loss: 0.9018 - val_accuracy: 0.7188\n",
      "Epoch 3/30\n",
      "1253/1253 [==============================] - 982s 784ms/step - loss: 0.3785 - accuracy: 0.9056 - val_loss: 1.1758 - val_accuracy: 0.6250\n",
      "Epoch 4/30\n",
      "1253/1253 [==============================] - 1006s 803ms/step - loss: 0.2638 - accuracy: 0.9360 - val_loss: 0.1039 - val_accuracy: 1.0000\n",
      "Epoch 5/30\n",
      "1253/1253 [==============================] - 987s 788ms/step - loss: 0.1992 - accuracy: 0.9506 - val_loss: 0.1027 - val_accuracy: 0.9688\n",
      "Epoch 6/30\n",
      "1253/1253 [==============================] - 984s 785ms/step - loss: 0.1693 - accuracy: 0.9567 - val_loss: 0.0521 - val_accuracy: 1.0000\n",
      "Epoch 7/30\n",
      "1253/1253 [==============================] - 981s 783ms/step - loss: 0.1450 - accuracy: 0.9622 - val_loss: 0.2725 - val_accuracy: 0.9375\n",
      "Epoch 8/30\n",
      "1253/1253 [==============================] - 981s 783ms/step - loss: 0.1207 - accuracy: 0.9688 - val_loss: 0.0386 - val_accuracy: 1.0000\n",
      "Epoch 9/30\n",
      "1253/1253 [==============================] - 994s 793ms/step - loss: 0.1001 - accuracy: 0.9751 - val_loss: 0.0359 - val_accuracy: 1.0000\n",
      "Epoch 10/30\n",
      "1253/1253 [==============================] - 1003s 801ms/step - loss: 0.0878 - accuracy: 0.9778 - val_loss: 0.0238 - val_accuracy: 1.0000\n",
      "Epoch 11/30\n",
      "1253/1253 [==============================] - 1012s 808ms/step - loss: 0.0785 - accuracy: 0.9801 - val_loss: 0.0205 - val_accuracy: 1.0000\n",
      "Epoch 12/30\n",
      "1253/1253 [==============================] - 987s 788ms/step - loss: 0.0665 - accuracy: 0.9837 - val_loss: 0.0210 - val_accuracy: 1.0000\n",
      "Epoch 13/30\n",
      "1253/1253 [==============================] - 997s 795ms/step - loss: 0.0598 - accuracy: 0.9864 - val_loss: 0.0295 - val_accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "1253/1253 [==============================] - 994s 793ms/step - loss: 0.0515 - accuracy: 0.9888 - val_loss: 0.0155 - val_accuracy: 1.0000\n",
      "Epoch 15/30\n",
      "1253/1253 [==============================] - 992s 792ms/step - loss: 0.0443 - accuracy: 0.9908 - val_loss: 0.0179 - val_accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "1253/1253 [==============================] - 1005s 802ms/step - loss: 0.0421 - accuracy: 0.9911 - val_loss: 0.0181 - val_accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "1253/1253 [==============================] - 990s 790ms/step - loss: 0.0380 - accuracy: 0.9920 - val_loss: 0.0115 - val_accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "1253/1253 [==============================] - 985s 786ms/step - loss: 0.0340 - accuracy: 0.9930 - val_loss: 0.0106 - val_accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "1253/1253 [==============================] - 982s 784ms/step - loss: 0.0310 - accuracy: 0.9940 - val_loss: 0.0103 - val_accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "1253/1253 [==============================] - 991s 791ms/step - loss: 0.0280 - accuracy: 0.9941 - val_loss: 0.0188 - val_accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "1253/1253 [==============================] - 981s 783ms/step - loss: 0.0293 - accuracy: 0.9941 - val_loss: 0.0370 - val_accuracy: 0.9688\n",
      "Epoch 22/30\n",
      "1253/1253 [==============================] - 993s 793ms/step - loss: 0.0253 - accuracy: 0.9951 - val_loss: 0.1003 - val_accuracy: 0.9688\n",
      "Epoch 23/30\n",
      "1253/1253 [==============================] - 987s 787ms/step - loss: 0.0241 - accuracy: 0.9951 - val_loss: 0.1228 - val_accuracy: 0.9688\n",
      "Epoch 24/30\n",
      "1253/1253 [==============================] - 983s 784ms/step - loss: 0.0216 - accuracy: 0.9957 - val_loss: 0.1559 - val_accuracy: 0.9688\n",
      "Epoch 25/30\n",
      "1253/1253 [==============================] - 991s 791ms/step - loss: 0.0213 - accuracy: 0.9955 - val_loss: 0.1093 - val_accuracy: 0.9688\n",
      "Epoch 26/30\n",
      "1253/1253 [==============================] - 991s 791ms/step - loss: 0.0206 - accuracy: 0.9958 - val_loss: 0.1305 - val_accuracy: 0.9688\n",
      "Epoch 27/30\n",
      "1253/1253 [==============================] - 985s 786ms/step - loss: 0.0207 - accuracy: 0.9960 - val_loss: 0.1846 - val_accuracy: 0.9688\n",
      "Epoch 28/30\n",
      "1253/1253 [==============================] - 1002s 800ms/step - loss: 0.0192 - accuracy: 0.9961 - val_loss: 0.1361 - val_accuracy: 0.9688\n",
      "Epoch 29/30\n",
      "1253/1253 [==============================] - 1002s 800ms/step - loss: 0.0203 - accuracy: 0.9955 - val_loss: 0.1410 - val_accuracy: 0.9688\n",
      "Epoch 30/30\n",
      "1253/1253 [==============================] - 978s 780ms/step - loss: 0.0205 - accuracy: 0.9956 - val_loss: 0.0667 - val_accuracy: 0.9688\n",
      "INFO:tensorflow:Assets written to: ../xception/xception_30epochs_62613.0_images_True_newWeights_False_lastLayerOnly_rescale-symmetric_normalization/assets\n",
      "Test acc for xception: 0.998967\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training resnet for 0.75% of train size (aka 62613 images) with pretrained: False and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 178 trainable: 178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "   6/1253 [..............................] - ETA: 15:09 - loss: 1.3808 - accuracy: 0.3591WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1007s vs `on_train_batch_begin` time: 0.1963s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1007s vs `on_train_batch_end` time: 0.3355s). Check your callbacks.\n",
      "1253/1253 [==============================] - 259s 201ms/step - loss: 1.1580 - accuracy: 0.6411 - val_loss: 1.4945 - val_accuracy: 0.3438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "1253/1253 [==============================] - 249s 199ms/step - loss: 0.8199 - accuracy: 0.7319 - val_loss: 2.1179 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "1253/1253 [==============================] - 249s 199ms/step - loss: 0.7307 - accuracy: 0.7556 - val_loss: 1.1182 - val_accuracy: 0.5938\n",
      "Epoch 4/30\n",
      "1253/1253 [==============================] - 249s 199ms/step - loss: 0.6873 - accuracy: 0.7703 - val_loss: 0.9614 - val_accuracy: 0.7188\n",
      "Epoch 5/30\n",
      "1253/1253 [==============================] - 249s 199ms/step - loss: 0.6436 - accuracy: 0.7908 - val_loss: 0.7302 - val_accuracy: 0.7500\n",
      "Epoch 6/30\n",
      "1253/1253 [==============================] - 249s 199ms/step - loss: 0.5766 - accuracy: 0.8073 - val_loss: 0.7602 - val_accuracy: 0.7188\n",
      "Epoch 7/30\n",
      "1253/1253 [==============================] - 249s 199ms/step - loss: 0.5090 - accuracy: 0.8314 - val_loss: 0.5149 - val_accuracy: 0.8438\n",
      "Epoch 8/30\n",
      "1253/1253 [==============================] - 249s 199ms/step - loss: 0.4444 - accuracy: 0.8658 - val_loss: 0.3855 - val_accuracy: 0.9375\n",
      "Epoch 9/30\n",
      "1253/1253 [==============================] - 249s 199ms/step - loss: 0.3655 - accuracy: 0.8954 - val_loss: 0.3067 - val_accuracy: 0.9062\n",
      "Epoch 10/30\n",
      "1253/1253 [==============================] - 249s 199ms/step - loss: 0.2915 - accuracy: 0.9203 - val_loss: 0.7059 - val_accuracy: 0.7812\n",
      "Epoch 11/30\n",
      "1253/1253 [==============================] - 249s 199ms/step - loss: 0.2454 - accuracy: 0.9341 - val_loss: 0.1130 - val_accuracy: 1.0000\n",
      "Epoch 12/30\n",
      "1253/1253 [==============================] - 249s 199ms/step - loss: 0.2161 - accuracy: 0.9413 - val_loss: 0.1050 - val_accuracy: 1.0000\n",
      "Epoch 13/30\n",
      "1253/1253 [==============================] - 249s 199ms/step - loss: 0.1945 - accuracy: 0.9458 - val_loss: 0.0844 - val_accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "1253/1253 [==============================] - 249s 199ms/step - loss: 0.1718 - accuracy: 0.9521 - val_loss: 0.0755 - val_accuracy: 1.0000\n",
      "Epoch 15/30\n",
      "1253/1253 [==============================] - 249s 199ms/step - loss: 0.1616 - accuracy: 0.9553 - val_loss: 0.0596 - val_accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "1253/1253 [==============================] - 249s 199ms/step - loss: 0.1508 - accuracy: 0.9584 - val_loss: 0.0458 - val_accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "1253/1253 [==============================] - 249s 199ms/step - loss: 0.1388 - accuracy: 0.9617 - val_loss: 0.0741 - val_accuracy: 0.9688\n",
      "Epoch 18/30\n",
      "1253/1253 [==============================] - 249s 199ms/step - loss: 0.1317 - accuracy: 0.9623 - val_loss: 0.0361 - val_accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "1253/1253 [==============================] - 249s 199ms/step - loss: 0.1216 - accuracy: 0.9663 - val_loss: 0.0358 - val_accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "1253/1253 [==============================] - 249s 199ms/step - loss: 0.1139 - accuracy: 0.9684 - val_loss: 0.0389 - val_accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "1253/1253 [==============================] - 249s 199ms/step - loss: 0.1109 - accuracy: 0.9696 - val_loss: 0.0292 - val_accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "1253/1253 [==============================] - 249s 199ms/step - loss: 0.1017 - accuracy: 0.9720 - val_loss: 0.0372 - val_accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "1253/1253 [==============================] - 249s 199ms/step - loss: 0.0926 - accuracy: 0.9746 - val_loss: 0.0272 - val_accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "1253/1253 [==============================] - 249s 199ms/step - loss: 0.0935 - accuracy: 0.9759 - val_loss: 0.0259 - val_accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "1253/1253 [==============================] - 249s 199ms/step - loss: 0.0918 - accuracy: 0.9755 - val_loss: 0.0254 - val_accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "1253/1253 [==============================] - 249s 199ms/step - loss: 0.0852 - accuracy: 0.9789 - val_loss: 0.0255 - val_accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "1253/1253 [==============================] - 249s 199ms/step - loss: 0.0802 - accuracy: 0.9787 - val_loss: 0.0220 - val_accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "1253/1253 [==============================] - 249s 199ms/step - loss: 0.0754 - accuracy: 0.9812 - val_loss: 0.0227 - val_accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "1253/1253 [==============================] - 249s 199ms/step - loss: 0.0740 - accuracy: 0.9816 - val_loss: 0.0266 - val_accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "1253/1253 [==============================] - 249s 199ms/step - loss: 0.0727 - accuracy: 0.9818 - val_loss: 0.0206 - val_accuracy: 1.0000\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_62613.0_images_True_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.993802\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training opticnet for 0.75% of train size (aka 62613 images) with pretrained: False and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 276 trainable: 276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "   6/1253 [..............................] - ETA: 38:26 - loss: 30.5848 - accuracy: 0.2742WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.4648s vs `on_train_batch_end` time: 1.0540s). Check your callbacks.\n",
      "1253/1253 [==============================] - 1492s 1s/step - loss: 2.0953 - accuracy: 0.6595 - val_loss: 1.3666 - val_accuracy: 0.3750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "1253/1253 [==============================] - 1473s 1s/step - loss: 0.2865 - accuracy: 0.9038 - val_loss: 0.3395 - val_accuracy: 0.9062\n",
      "Epoch 3/30\n",
      "1253/1253 [==============================] - 1473s 1s/step - loss: 0.2116 - accuracy: 0.9294 - val_loss: 1.1787 - val_accuracy: 0.7500\n",
      "Epoch 4/30\n",
      "1253/1253 [==============================] - 1473s 1s/step - loss: 0.1891 - accuracy: 0.9370 - val_loss: 0.1462 - val_accuracy: 0.9688\n",
      "Epoch 5/30\n",
      "1253/1253 [==============================] - 1472s 1s/step - loss: 0.1699 - accuracy: 0.9424 - val_loss: 0.0416 - val_accuracy: 1.0000\n",
      "Epoch 6/30\n",
      "1253/1253 [==============================] - 1471s 1s/step - loss: 0.1540 - accuracy: 0.9481 - val_loss: 0.1135 - val_accuracy: 0.9375\n",
      "Epoch 7/30\n",
      "1253/1253 [==============================] - 1472s 1s/step - loss: 0.1377 - accuracy: 0.9527 - val_loss: 0.0631 - val_accuracy: 1.0000\n",
      "Epoch 8/30\n",
      "1253/1253 [==============================] - 1473s 1s/step - loss: 0.1221 - accuracy: 0.9582 - val_loss: 0.0351 - val_accuracy: 1.0000\n",
      "Epoch 9/30\n",
      "1253/1253 [==============================] - 1472s 1s/step - loss: 0.1030 - accuracy: 0.9641 - val_loss: 0.0279 - val_accuracy: 1.0000\n",
      "Epoch 10/30\n",
      "1253/1253 [==============================] - 1472s 1s/step - loss: 0.0918 - accuracy: 0.9684 - val_loss: 0.0310 - val_accuracy: 0.9688\n",
      "Epoch 11/30\n",
      "1253/1253 [==============================] - 1473s 1s/step - loss: 0.0825 - accuracy: 0.9712 - val_loss: 0.0152 - val_accuracy: 1.0000\n",
      "Epoch 12/30\n",
      "1253/1253 [==============================] - 1472s 1s/step - loss: 0.0672 - accuracy: 0.9768 - val_loss: 0.1293 - val_accuracy: 0.9688\n",
      "Epoch 13/30\n",
      "1253/1253 [==============================] - 1472s 1s/step - loss: 0.0584 - accuracy: 0.9793 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "1253/1253 [==============================] - 1472s 1s/step - loss: 0.0463 - accuracy: 0.9836 - val_loss: 0.0427 - val_accuracy: 0.9688\n",
      "Epoch 15/30\n",
      "1253/1253 [==============================] - 1472s 1s/step - loss: 0.0351 - accuracy: 0.9879 - val_loss: 0.0098 - val_accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "1253/1253 [==============================] - 1471s 1s/step - loss: 0.0306 - accuracy: 0.9895 - val_loss: 0.1322 - val_accuracy: 0.9688\n",
      "Epoch 17/30\n",
      "1253/1253 [==============================] - 1472s 1s/step - loss: 0.0241 - accuracy: 0.9922 - val_loss: 0.0396 - val_accuracy: 0.9688\n",
      "Epoch 18/30\n",
      "1253/1253 [==============================] - 1472s 1s/step - loss: 0.0189 - accuracy: 0.9941 - val_loss: 0.0471 - val_accuracy: 0.9688\n",
      "Epoch 19/30\n",
      "1253/1253 [==============================] - 1470s 1s/step - loss: 0.0173 - accuracy: 0.9947 - val_loss: 0.1707 - val_accuracy: 0.9688\n",
      "Epoch 20/30\n",
      "1253/1253 [==============================] - 1474s 1s/step - loss: 0.0157 - accuracy: 0.9950 - val_loss: 0.0086 - val_accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "1253/1253 [==============================] - 1473s 1s/step - loss: 0.0151 - accuracy: 0.9954 - val_loss: 0.0420 - val_accuracy: 0.9688\n",
      "Epoch 22/30\n",
      "1253/1253 [==============================] - 1472s 1s/step - loss: 0.0122 - accuracy: 0.9959 - val_loss: 0.1677 - val_accuracy: 0.9688\n",
      "Epoch 23/30\n",
      "1253/1253 [==============================] - 1472s 1s/step - loss: 0.0105 - accuracy: 0.9964 - val_loss: 0.0989 - val_accuracy: 0.9688\n",
      "Epoch 24/30\n",
      "1253/1253 [==============================] - 1472s 1s/step - loss: 0.0101 - accuracy: 0.9967 - val_loss: 0.1608 - val_accuracy: 0.9688\n",
      "Epoch 25/30\n",
      "1253/1253 [==============================] - 1471s 1s/step - loss: 0.0105 - accuracy: 0.9966 - val_loss: 0.0444 - val_accuracy: 0.9688\n",
      "Epoch 26/30\n",
      "1253/1253 [==============================] - 1470s 1s/step - loss: 0.0087 - accuracy: 0.9970 - val_loss: 0.0297 - val_accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "1253/1253 [==============================] - 1472s 1s/step - loss: 0.0079 - accuracy: 0.9972 - val_loss: 0.0272 - val_accuracy: 0.9688\n",
      "Epoch 28/30\n",
      "1253/1253 [==============================] - 1472s 1s/step - loss: 0.0074 - accuracy: 0.9971 - val_loss: 0.1231 - val_accuracy: 0.9688\n",
      "Epoch 29/30\n",
      "1253/1253 [==============================] - 1473s 1s/step - loss: 0.0070 - accuracy: 0.9973 - val_loss: 0.0838 - val_accuracy: 0.9688\n",
      "Epoch 30/30\n",
      "1253/1253 [==============================] - 1472s 1s/step - loss: 0.0062 - accuracy: 0.9975 - val_loss: 0.1018 - val_accuracy: 0.9688\n",
      "INFO:tensorflow:Assets written to: ../opticnet/opticnet_30epochs_62613.0_images_True_newWeights_False_lastLayerOnly_rescale-symmetric_normalization/assets\n",
      "Test acc for opticnet: 0.995868\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.89918298 0.90025534 0.89857244 0.90320334]\n",
      "Training xception for 0.9% of train size (aka 75135 images) with pretrained: False and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 135 trainable: 135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "   6/1503 [..............................] - ETA: 33:07 - loss: 1.3828 - accuracy: 0.3998WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1596s vs `on_train_batch_begin` time: 0.1952s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1596s vs `on_train_batch_end` time: 0.8697s). Check your callbacks.\n",
      "1503/1503 [==============================] - 1268s 840ms/step - loss: 1.0881 - accuracy: 0.7116 - val_loss: 1.3365 - val_accuracy: 0.5625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "1503/1503 [==============================] - 1260s 839ms/step - loss: 0.6451 - accuracy: 0.8081 - val_loss: 0.4540 - val_accuracy: 0.9375\n",
      "Epoch 3/30\n",
      "1503/1503 [==============================] - 1266s 842ms/step - loss: 0.4035 - accuracy: 0.8951 - val_loss: 0.2178 - val_accuracy: 0.9688\n",
      "Epoch 4/30\n",
      "1503/1503 [==============================] - 1258s 837ms/step - loss: 0.2494 - accuracy: 0.9372 - val_loss: 0.0982 - val_accuracy: 1.0000\n",
      "Epoch 5/30\n",
      "1503/1503 [==============================] - 1261s 839ms/step - loss: 0.1865 - accuracy: 0.9517 - val_loss: 0.0817 - val_accuracy: 1.0000\n",
      "Epoch 6/30\n",
      "1503/1503 [==============================] - 1265s 842ms/step - loss: 0.1535 - accuracy: 0.9590 - val_loss: 0.0461 - val_accuracy: 1.0000\n",
      "Epoch 7/30\n",
      "1503/1503 [==============================] - 1264s 841ms/step - loss: 0.1293 - accuracy: 0.9647 - val_loss: 0.0565 - val_accuracy: 1.0000\n",
      "Epoch 8/30\n",
      "1503/1503 [==============================] - 1261s 839ms/step - loss: 0.1080 - accuracy: 0.9705 - val_loss: 0.0256 - val_accuracy: 1.0000\n",
      "Epoch 9/30\n",
      "1503/1503 [==============================] - 1261s 839ms/step - loss: 0.0918 - accuracy: 0.9755 - val_loss: 0.0243 - val_accuracy: 1.0000\n",
      "Epoch 10/30\n",
      "1503/1503 [==============================] - 1260s 838ms/step - loss: 0.0774 - accuracy: 0.9797 - val_loss: 0.0176 - val_accuracy: 1.0000\n",
      "Epoch 11/30\n",
      "1503/1503 [==============================] - 1270s 845ms/step - loss: 0.0671 - accuracy: 0.9831 - val_loss: 0.0175 - val_accuracy: 1.0000\n",
      "Epoch 12/30\n",
      "1503/1503 [==============================] - 1264s 841ms/step - loss: 0.0602 - accuracy: 0.9851 - val_loss: 0.0141 - val_accuracy: 1.0000\n",
      "Epoch 13/30\n",
      "1503/1503 [==============================] - 1262s 840ms/step - loss: 0.0521 - accuracy: 0.9878 - val_loss: 0.0131 - val_accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "1503/1503 [==============================] - 1216s 809ms/step - loss: 0.0464 - accuracy: 0.9892 - val_loss: 0.0437 - val_accuracy: 0.9688\n",
      "Epoch 15/30\n",
      "1503/1503 [==============================] - 1175s 781ms/step - loss: 0.0443 - accuracy: 0.9902 - val_loss: 0.0112 - val_accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "1503/1503 [==============================] - 1262s 839ms/step - loss: 0.0409 - accuracy: 0.9908 - val_loss: 0.0138 - val_accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "1503/1503 [==============================] - 1261s 839ms/step - loss: 0.0349 - accuracy: 0.9930 - val_loss: 0.0094 - val_accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "1503/1503 [==============================] - 1262s 840ms/step - loss: 0.0329 - accuracy: 0.9928 - val_loss: 0.0087 - val_accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "1503/1503 [==============================] - 1273s 847ms/step - loss: 0.0292 - accuracy: 0.9939 - val_loss: 0.0101 - val_accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "1503/1503 [==============================] - 1261s 839ms/step - loss: 0.0291 - accuracy: 0.9937 - val_loss: 0.0803 - val_accuracy: 0.9688\n",
      "Epoch 21/30\n",
      "1503/1503 [==============================] - 1264s 841ms/step - loss: 0.0254 - accuracy: 0.9945 - val_loss: 0.0078 - val_accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "1503/1503 [==============================] - 1264s 841ms/step - loss: 0.0248 - accuracy: 0.9947 - val_loss: 0.0102 - val_accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "1503/1503 [==============================] - 1264s 841ms/step - loss: 0.0226 - accuracy: 0.9952 - val_loss: 0.0201 - val_accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "1503/1503 [==============================] - 1268s 844ms/step - loss: 0.0222 - accuracy: 0.9950 - val_loss: 0.0083 - val_accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "1503/1503 [==============================] - 1262s 840ms/step - loss: 0.0213 - accuracy: 0.9951 - val_loss: 0.0078 - val_accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "1503/1503 [==============================] - 1263s 840ms/step - loss: 0.0204 - accuracy: 0.9954 - val_loss: 0.0206 - val_accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "1503/1503 [==============================] - 1274s 847ms/step - loss: 0.0185 - accuracy: 0.9956 - val_loss: 0.0238 - val_accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "1503/1503 [==============================] - 1262s 840ms/step - loss: 0.0162 - accuracy: 0.9963 - val_loss: 0.0127 - val_accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "1503/1503 [==============================] - 1263s 840ms/step - loss: 0.0170 - accuracy: 0.9959 - val_loss: 0.0250 - val_accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "1503/1503 [==============================] - 1267s 843ms/step - loss: 0.0173 - accuracy: 0.9957 - val_loss: 0.0694 - val_accuracy: 0.9688\n",
      "INFO:tensorflow:Assets written to: ../xception/xception_30epochs_75135.6_images_True_newWeights_False_lastLayerOnly_rescale-symmetric_normalization/assets\n",
      "Test acc for xception: 0.995868\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training resnet for 0.9% of train size (aka 75135 images) with pretrained: False and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 178 trainable: 178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "   6/1503 [..............................] - ETA: 14:43 - loss: 1.3760 - accuracy: 0.4070WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1016s vs `on_train_batch_end` time: 0.3243s). Check your callbacks.\n",
      "1503/1503 [==============================] - 308s 200ms/step - loss: 1.2706 - accuracy: 0.4384 - val_loss: 1.5606 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "1503/1503 [==============================] - 298s 198ms/step - loss: 1.2293 - accuracy: 0.4469 - val_loss: 1.5548 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "1503/1503 [==============================] - 298s 198ms/step - loss: 1.2313 - accuracy: 0.4436 - val_loss: 1.5553 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "1503/1503 [==============================] - 298s 198ms/step - loss: 1.2282 - accuracy: 0.4476 - val_loss: 1.5551 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "1503/1503 [==============================] - 298s 198ms/step - loss: 1.2304 - accuracy: 0.4458 - val_loss: 1.5552 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "1503/1503 [==============================] - 298s 198ms/step - loss: 1.2325 - accuracy: 0.4437 - val_loss: 1.5608 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "1503/1503 [==============================] - 298s 198ms/step - loss: 1.2294 - accuracy: 0.4461 - val_loss: 1.5564 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "1503/1503 [==============================] - 298s 198ms/step - loss: 1.2302 - accuracy: 0.4458 - val_loss: 1.5541 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "1503/1503 [==============================] - 298s 198ms/step - loss: 1.2313 - accuracy: 0.4457 - val_loss: 1.5568 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "1503/1503 [==============================] - 298s 198ms/step - loss: 1.2305 - accuracy: 0.4449 - val_loss: 1.5565 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "1503/1503 [==============================] - 298s 198ms/step - loss: 1.2320 - accuracy: 0.4431 - val_loss: 1.5576 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "1503/1503 [==============================] - 298s 198ms/step - loss: 1.2286 - accuracy: 0.4458 - val_loss: 1.5574 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "1503/1503 [==============================] - 298s 198ms/step - loss: 1.2302 - accuracy: 0.4468 - val_loss: 1.5583 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "1503/1503 [==============================] - 298s 198ms/step - loss: 1.2295 - accuracy: 0.4454 - val_loss: 1.5570 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "1503/1503 [==============================] - 298s 198ms/step - loss: 1.2318 - accuracy: 0.4429 - val_loss: 1.5584 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "1503/1503 [==============================] - 298s 198ms/step - loss: 1.2327 - accuracy: 0.4423 - val_loss: 1.5590 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "1503/1503 [==============================] - 298s 198ms/step - loss: 1.2317 - accuracy: 0.4455 - val_loss: 1.5568 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "1503/1503 [==============================] - 298s 198ms/step - loss: 1.2295 - accuracy: 0.4468 - val_loss: 1.5574 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "1503/1503 [==============================] - 298s 198ms/step - loss: 1.2325 - accuracy: 0.4432 - val_loss: 1.5578 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "1503/1503 [==============================] - 298s 198ms/step - loss: 1.2292 - accuracy: 0.4451 - val_loss: 1.5574 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "1503/1503 [==============================] - 298s 198ms/step - loss: 1.2302 - accuracy: 0.4455 - val_loss: 1.5571 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "1503/1503 [==============================] - 298s 198ms/step - loss: 1.2280 - accuracy: 0.4477 - val_loss: 1.5564 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "1503/1503 [==============================] - 298s 198ms/step - loss: 1.2282 - accuracy: 0.4476 - val_loss: 1.5564 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "1503/1503 [==============================] - 298s 198ms/step - loss: 1.2296 - accuracy: 0.4461 - val_loss: 1.5569 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "1503/1503 [==============================] - 298s 198ms/step - loss: 1.2295 - accuracy: 0.4468 - val_loss: 1.5570 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "1503/1503 [==============================] - 298s 198ms/step - loss: 1.2293 - accuracy: 0.4480 - val_loss: 1.5567 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "1503/1503 [==============================] - 298s 198ms/step - loss: 1.2279 - accuracy: 0.4474 - val_loss: 1.5568 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "1503/1503 [==============================] - 298s 198ms/step - loss: 1.2290 - accuracy: 0.4465 - val_loss: 1.5570 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "1503/1503 [==============================] - 298s 198ms/step - loss: 1.2297 - accuracy: 0.4478 - val_loss: 1.5569 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "1503/1503 [==============================] - 298s 198ms/step - loss: 1.2306 - accuracy: 0.4450 - val_loss: 1.5569 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_75135.6_images_True_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training opticnet for 0.9% of train size (aka 75135 images) with pretrained: False and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 276 trainable: 276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "   6/1503 [..............................] - ETA: 41:42 - loss: 26.3815 - accuracy: 0.3180WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.4646s vs `on_train_batch_end` time: 1.0452s). Check your callbacks.\n",
      "1503/1503 [==============================] - 1778s 1s/step - loss: 1.7232 - accuracy: 0.6721 - val_loss: 0.6238 - val_accuracy: 0.7500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "1503/1503 [==============================] - 1760s 1s/step - loss: 0.2479 - accuracy: 0.9197 - val_loss: 0.3535 - val_accuracy: 0.7500\n",
      "Epoch 3/30\n",
      "1503/1503 [==============================] - 1760s 1s/step - loss: 0.1970 - accuracy: 0.9339 - val_loss: 0.2176 - val_accuracy: 0.9375\n",
      "Epoch 4/30\n",
      "1503/1503 [==============================] - 1761s 1s/step - loss: 0.1645 - accuracy: 0.9450 - val_loss: 0.9041 - val_accuracy: 0.7188\n",
      "Epoch 5/30\n",
      "1503/1503 [==============================] - 1761s 1s/step - loss: 0.1465 - accuracy: 0.9498 - val_loss: 0.1500 - val_accuracy: 0.9062\n",
      "Epoch 6/30\n",
      "1503/1503 [==============================] - 1749s 1s/step - loss: 0.1312 - accuracy: 0.9541 - val_loss: 0.0672 - val_accuracy: 1.0000\n",
      "Epoch 7/30\n",
      "1503/1503 [==============================] - 1759s 1s/step - loss: 0.1120 - accuracy: 0.9614 - val_loss: 0.0701 - val_accuracy: 0.9688\n",
      "Epoch 8/30\n",
      "1503/1503 [==============================] - 1734s 1s/step - loss: 0.0941 - accuracy: 0.9674 - val_loss: 0.0192 - val_accuracy: 1.0000\n",
      "Epoch 9/30\n",
      "1503/1503 [==============================] - 1734s 1s/step - loss: 0.0783 - accuracy: 0.9728 - val_loss: 0.3033 - val_accuracy: 0.9062\n",
      "Epoch 10/30\n",
      "1503/1503 [==============================] - 1758s 1s/step - loss: 0.0677 - accuracy: 0.9765 - val_loss: 0.0431 - val_accuracy: 0.9688\n",
      "Epoch 11/30\n",
      "1503/1503 [==============================] - 1769s 1s/step - loss: 0.0524 - accuracy: 0.9823 - val_loss: 0.0259 - val_accuracy: 1.0000\n",
      "Epoch 12/30\n",
      "1503/1503 [==============================] - 1761s 1s/step - loss: 0.0413 - accuracy: 0.9867 - val_loss: 0.1215 - val_accuracy: 0.9688\n",
      "Epoch 13/30\n",
      "1503/1503 [==============================] - 1761s 1s/step - loss: 0.0337 - accuracy: 0.9890 - val_loss: 0.0137 - val_accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "1503/1503 [==============================] - 1760s 1s/step - loss: 0.0272 - accuracy: 0.9914 - val_loss: 0.0516 - val_accuracy: 0.9688\n",
      "Epoch 15/30\n",
      "1503/1503 [==============================] - 1760s 1s/step - loss: 0.0236 - accuracy: 0.9922 - val_loss: 0.1216 - val_accuracy: 0.9688\n",
      "Epoch 16/30\n",
      "1503/1503 [==============================] - 1760s 1s/step - loss: 0.0188 - accuracy: 0.9937 - val_loss: 0.0472 - val_accuracy: 0.9688\n",
      "Epoch 17/30\n",
      "1503/1503 [==============================] - 1759s 1s/step - loss: 0.0176 - accuracy: 0.9943 - val_loss: 0.0722 - val_accuracy: 0.9688\n",
      "Epoch 18/30\n",
      "1503/1503 [==============================] - 1756s 1s/step - loss: 0.0148 - accuracy: 0.9948 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "1503/1503 [==============================] - 1762s 1s/step - loss: 0.0146 - accuracy: 0.9947 - val_loss: 0.0283 - val_accuracy: 0.9688\n",
      "Epoch 20/30\n",
      "1503/1503 [==============================] - 1760s 1s/step - loss: 0.0107 - accuracy: 0.9963 - val_loss: 0.0245 - val_accuracy: 0.9688\n",
      "Epoch 21/30\n",
      "1503/1503 [==============================] - 1760s 1s/step - loss: 0.0108 - accuracy: 0.9960 - val_loss: 0.0061 - val_accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "1503/1503 [==============================] - 1760s 1s/step - loss: 0.0100 - accuracy: 0.9964 - val_loss: 0.0246 - val_accuracy: 0.9688\n",
      "Epoch 23/30\n",
      "1503/1503 [==============================] - 1762s 1s/step - loss: 0.0091 - accuracy: 0.9962 - val_loss: 0.0046 - val_accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "1503/1503 [==============================] - 1761s 1s/step - loss: 0.0087 - accuracy: 0.9965 - val_loss: 0.0072 - val_accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "1503/1503 [==============================] - 1764s 1s/step - loss: 0.0091 - accuracy: 0.9959 - val_loss: 0.0240 - val_accuracy: 0.9688\n",
      "Epoch 26/30\n",
      "1503/1503 [==============================] - 1765s 1s/step - loss: 0.0070 - accuracy: 0.9968 - val_loss: 0.0224 - val_accuracy: 0.9688\n",
      "Epoch 27/30\n",
      "1503/1503 [==============================] - 1761s 1s/step - loss: 0.0069 - accuracy: 0.9963 - val_loss: 0.0220 - val_accuracy: 0.9688\n",
      "Epoch 28/30\n",
      "1503/1503 [==============================] - 1760s 1s/step - loss: 0.0061 - accuracy: 0.9968 - val_loss: 0.0256 - val_accuracy: 0.9688\n",
      "Epoch 29/30\n",
      "1503/1503 [==============================] - 1758s 1s/step - loss: 0.0060 - accuracy: 0.9970 - val_loss: 0.0241 - val_accuracy: 0.9688\n",
      "Epoch 30/30\n",
      "1503/1503 [==============================] - 1762s 1s/step - loss: 0.0057 - accuracy: 0.9969 - val_loss: 0.0391 - val_accuracy: 0.9688\n",
      "INFO:tensorflow:Assets written to: ../opticnet/opticnet_30epochs_75135.6_images_True_newWeights_False_lastLayerOnly_rescale-symmetric_normalization/assets\n",
      "Test acc for opticnet: 0.994835\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [1. 1. 1. 1.]\n",
      "Training xception for 1.0% of train size (aka 83484 images) with pretrained: False and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 135 trainable: 135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "   6/1670 [..............................] - ETA: 31:20 - loss: 1.3818 - accuracy: 0.3362WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1580s vs `on_train_batch_end` time: 0.8099s). Check your callbacks.\n",
      "1670/1670 [==============================] - 1291s 770ms/step - loss: 1.0366 - accuracy: 0.7417 - val_loss: 0.6430 - val_accuracy: 0.8125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "1670/1670 [==============================] - 1285s 770ms/step - loss: 0.4419 - accuracy: 0.8979 - val_loss: 0.1728 - val_accuracy: 1.0000\n",
      "Epoch 3/30\n",
      "1670/1670 [==============================] - 1284s 769ms/step - loss: 0.2787 - accuracy: 0.9317 - val_loss: 0.1511 - val_accuracy: 0.9688\n",
      "Epoch 4/30\n",
      "1670/1670 [==============================] - 1287s 771ms/step - loss: 0.2037 - accuracy: 0.9472 - val_loss: 0.0583 - val_accuracy: 1.0000\n",
      "Epoch 5/30\n",
      "1670/1670 [==============================] - 1287s 770ms/step - loss: 0.1655 - accuracy: 0.9537 - val_loss: 0.1692 - val_accuracy: 0.9062\n",
      "Epoch 6/30\n",
      "1670/1670 [==============================] - 1287s 771ms/step - loss: 0.1373 - accuracy: 0.9604 - val_loss: 0.0424 - val_accuracy: 1.0000\n",
      "Epoch 7/30\n",
      "1670/1670 [==============================] - 1291s 773ms/step - loss: 0.1142 - accuracy: 0.9680 - val_loss: 0.0238 - val_accuracy: 1.0000\n",
      "Epoch 8/30\n",
      "1670/1670 [==============================] - 1294s 775ms/step - loss: 0.0991 - accuracy: 0.9708 - val_loss: 0.1069 - val_accuracy: 0.9375\n",
      "Epoch 9/30\n",
      "1670/1670 [==============================] - 1295s 775ms/step - loss: 0.0842 - accuracy: 0.9751 - val_loss: 0.0185 - val_accuracy: 1.0000\n",
      "Epoch 10/30\n",
      "1670/1670 [==============================] - 1297s 777ms/step - loss: 0.0709 - accuracy: 0.9799 - val_loss: 0.0137 - val_accuracy: 1.0000\n",
      "Epoch 11/30\n",
      "1670/1670 [==============================] - 1296s 776ms/step - loss: 0.0575 - accuracy: 0.9841 - val_loss: 0.0150 - val_accuracy: 1.0000\n",
      "Epoch 12/30\n",
      "1670/1670 [==============================] - 1298s 777ms/step - loss: 0.0508 - accuracy: 0.9859 - val_loss: 0.0817 - val_accuracy: 0.9375\n",
      "Epoch 13/30\n",
      "1670/1670 [==============================] - 1295s 775ms/step - loss: 0.0419 - accuracy: 0.9889 - val_loss: 0.0139 - val_accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "1670/1670 [==============================] - 1293s 774ms/step - loss: 0.0373 - accuracy: 0.9907 - val_loss: 0.0089 - val_accuracy: 1.0000\n",
      "Epoch 15/30\n",
      "1670/1670 [==============================] - 1288s 771ms/step - loss: 0.0312 - accuracy: 0.9919 - val_loss: 0.0073 - val_accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "1670/1670 [==============================] - 1286s 770ms/step - loss: 0.0314 - accuracy: 0.9927 - val_loss: 0.0634 - val_accuracy: 0.9688\n",
      "Epoch 17/30\n",
      "1670/1670 [==============================] - 1285s 770ms/step - loss: 0.0289 - accuracy: 0.9928 - val_loss: 0.0634 - val_accuracy: 0.9688\n",
      "Epoch 18/30\n",
      "1670/1670 [==============================] - 1284s 769ms/step - loss: 0.0266 - accuracy: 0.9935 - val_loss: 0.0377 - val_accuracy: 0.9688\n",
      "Epoch 19/30\n",
      "1670/1670 [==============================] - 1329s 796ms/step - loss: 0.0237 - accuracy: 0.9942 - val_loss: 0.0188 - val_accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "1670/1670 [==============================] - 1283s 768ms/step - loss: 0.0216 - accuracy: 0.9943 - val_loss: 0.0338 - val_accuracy: 0.9688\n",
      "Epoch 21/30\n",
      "1670/1670 [==============================] - 1331s 797ms/step - loss: 0.0200 - accuracy: 0.9950 - val_loss: 0.0324 - val_accuracy: 0.9688\n",
      "Epoch 22/30\n",
      "1670/1670 [==============================] - 1282s 767ms/step - loss: 0.0185 - accuracy: 0.9949 - val_loss: 0.0268 - val_accuracy: 0.9688\n",
      "Epoch 23/30\n",
      "1670/1670 [==============================] - 1282s 768ms/step - loss: 0.0170 - accuracy: 0.9953 - val_loss: 0.0341 - val_accuracy: 0.9688\n",
      "Epoch 24/30\n",
      "1670/1670 [==============================] - 1282s 768ms/step - loss: 0.0177 - accuracy: 0.9950 - val_loss: 0.0320 - val_accuracy: 0.9688\n",
      "Epoch 25/30\n",
      "1670/1670 [==============================] - 1282s 768ms/step - loss: 0.0164 - accuracy: 0.9954 - val_loss: 0.0332 - val_accuracy: 0.9688\n",
      "Epoch 26/30\n",
      "1670/1670 [==============================] - 1281s 767ms/step - loss: 0.0143 - accuracy: 0.9956 - val_loss: 0.0334 - val_accuracy: 0.9688\n",
      "Epoch 27/30\n",
      "1670/1670 [==============================] - 1280s 767ms/step - loss: 0.0138 - accuracy: 0.9960 - val_loss: 0.0325 - val_accuracy: 0.9688\n",
      "Epoch 28/30\n",
      "1670/1670 [==============================] - 1282s 768ms/step - loss: 0.0143 - accuracy: 0.9958 - val_loss: 0.0302 - val_accuracy: 0.9688\n",
      "Epoch 29/30\n",
      "1670/1670 [==============================] - 1283s 769ms/step - loss: 0.0122 - accuracy: 0.9961 - val_loss: 0.0309 - val_accuracy: 0.9688\n",
      "Epoch 30/30\n",
      "1670/1670 [==============================] - 1282s 768ms/step - loss: 0.0135 - accuracy: 0.9956 - val_loss: 0.0313 - val_accuracy: 0.9688\n",
      "INFO:tensorflow:Assets written to: ../xception/xception_30epochs_83484.0_images_True_newWeights_False_lastLayerOnly_rescale-symmetric_normalization/assets\n",
      "Test acc for xception: 0.995868\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training resnet for 1.0% of train size (aka 83484 images) with pretrained: False and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 178 trainable: 178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "   6/1670 [..............................] - ETA: 16:36 - loss: 1.3771 - accuracy: 0.2915WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1024s vs `on_train_batch_end` time: 0.3280s). Check your callbacks.\n",
      "1670/1670 [==============================] - 341s 200ms/step - loss: 1.2646 - accuracy: 0.4410 - val_loss: 1.5646 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "1670/1670 [==============================] - 332s 199ms/step - loss: 1.2307 - accuracy: 0.4480 - val_loss: 1.5577 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "1670/1670 [==============================] - 332s 199ms/step - loss: 1.2298 - accuracy: 0.4458 - val_loss: 1.5511 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "1670/1670 [==============================] - 333s 199ms/step - loss: 1.2297 - accuracy: 0.4454 - val_loss: 1.5604 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "1670/1670 [==============================] - 332s 199ms/step - loss: 1.2303 - accuracy: 0.4460 - val_loss: 1.5609 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "1670/1670 [==============================] - 332s 199ms/step - loss: 1.2312 - accuracy: 0.4440 - val_loss: 1.5596 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "1670/1670 [==============================] - 332s 199ms/step - loss: 1.2288 - accuracy: 0.4466 - val_loss: 1.5610 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "1670/1670 [==============================] - 333s 199ms/step - loss: 1.2268 - accuracy: 0.4485 - val_loss: 1.5507 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "1670/1670 [==============================] - 332s 199ms/step - loss: 1.2311 - accuracy: 0.4450 - val_loss: 1.5577 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "1670/1670 [==============================] - 333s 199ms/step - loss: 1.2256 - accuracy: 0.4483 - val_loss: 1.5536 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "1670/1670 [==============================] - 333s 199ms/step - loss: 1.2287 - accuracy: 0.4456 - val_loss: 1.5562 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "1670/1670 [==============================] - 333s 199ms/step - loss: 1.2313 - accuracy: 0.4451 - val_loss: 1.5560 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "1670/1670 [==============================] - 333s 199ms/step - loss: 1.2320 - accuracy: 0.4465 - val_loss: 1.5586 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "1670/1670 [==============================] - 333s 199ms/step - loss: 1.2293 - accuracy: 0.4441 - val_loss: 1.5568 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "1670/1670 [==============================] - 333s 199ms/step - loss: 1.2327 - accuracy: 0.4464 - val_loss: 1.5590 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "1670/1670 [==============================] - 333s 199ms/step - loss: 1.2306 - accuracy: 0.4467 - val_loss: 1.5577 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "1670/1670 [==============================] - 333s 199ms/step - loss: 1.2282 - accuracy: 0.4455 - val_loss: 1.5571 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "1670/1670 [==============================] - 333s 199ms/step - loss: 1.2324 - accuracy: 0.4451 - val_loss: 1.5585 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "1670/1670 [==============================] - 333s 199ms/step - loss: 1.2296 - accuracy: 0.4427 - val_loss: 1.5573 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "1670/1670 [==============================] - 333s 199ms/step - loss: 1.2305 - accuracy: 0.4453 - val_loss: 1.5577 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "1670/1670 [==============================] - 333s 199ms/step - loss: 1.2257 - accuracy: 0.4492 - val_loss: 1.5565 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "1670/1670 [==============================] - 333s 199ms/step - loss: 1.2298 - accuracy: 0.4449 - val_loss: 1.5568 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "1670/1670 [==============================] - 332s 199ms/step - loss: 1.2307 - accuracy: 0.4442 - val_loss: 1.5578 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "1670/1670 [==============================] - 332s 199ms/step - loss: 1.2301 - accuracy: 0.4440 - val_loss: 1.5573 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "1670/1670 [==============================] - 332s 199ms/step - loss: 1.2306 - accuracy: 0.4471 - val_loss: 1.5573 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "1670/1670 [==============================] - 333s 199ms/step - loss: 1.2280 - accuracy: 0.4477 - val_loss: 1.5572 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "1670/1670 [==============================] - 333s 199ms/step - loss: 1.2314 - accuracy: 0.4461 - val_loss: 1.5573 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "1670/1670 [==============================] - 333s 199ms/step - loss: 1.2265 - accuracy: 0.4469 - val_loss: 1.5573 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "1670/1670 [==============================] - 332s 199ms/step - loss: 1.2283 - accuracy: 0.4459 - val_loss: 1.5572 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "1670/1670 [==============================] - 333s 199ms/step - loss: 1.2303 - accuracy: 0.4452 - val_loss: 1.5573 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_83484.0_images_True_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training opticnet for 1.0% of train size (aka 83484 images) with pretrained: False and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 276 trainable: 276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "   6/1670 [..............................] - ETA: 50:34 - loss: 27.3317 - accuracy: 0.3461WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.4615s vs `on_train_batch_end` time: 1.0825s). Check your callbacks.\n",
      "1670/1670 [==============================] - 1969s 1s/step - loss: 1.6365 - accuracy: 0.6773 - val_loss: 1.4397 - val_accuracy: 0.4062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "1670/1670 [==============================] - 1949s 1s/step - loss: 0.2469 - accuracy: 0.9186 - val_loss: 1.5079 - val_accuracy: 0.4375\n",
      "Epoch 3/30\n",
      "1670/1670 [==============================] - 1950s 1s/step - loss: 0.1849 - accuracy: 0.9384 - val_loss: 0.0179 - val_accuracy: 1.0000\n",
      "Epoch 4/30\n",
      "1670/1670 [==============================] - 1948s 1s/step - loss: 0.1645 - accuracy: 0.9438 - val_loss: 0.4209 - val_accuracy: 0.8438\n",
      "Epoch 5/30\n",
      "1670/1670 [==============================] - 1945s 1s/step - loss: 0.1405 - accuracy: 0.9533 - val_loss: 0.0232 - val_accuracy: 1.0000\n",
      "Epoch 6/30\n",
      "1670/1670 [==============================] - 1947s 1s/step - loss: 0.1224 - accuracy: 0.9575 - val_loss: 0.0097 - val_accuracy: 1.0000\n",
      "Epoch 7/30\n",
      "1670/1670 [==============================] - 1944s 1s/step - loss: 0.1071 - accuracy: 0.9637 - val_loss: 0.0049 - val_accuracy: 1.0000\n",
      "Epoch 8/30\n",
      "1670/1670 [==============================] - 1946s 1s/step - loss: 0.0901 - accuracy: 0.9689 - val_loss: 0.0132 - val_accuracy: 1.0000\n",
      "Epoch 9/30\n",
      "1670/1670 [==============================] - 1947s 1s/step - loss: 0.0753 - accuracy: 0.9737 - val_loss: 0.0079 - val_accuracy: 1.0000\n",
      "Epoch 10/30\n",
      "1670/1670 [==============================] - 1948s 1s/step - loss: 0.0613 - accuracy: 0.9791 - val_loss: 0.0256 - val_accuracy: 1.0000\n",
      "Epoch 11/30\n",
      "1670/1670 [==============================] - 1947s 1s/step - loss: 0.0475 - accuracy: 0.9841 - val_loss: 0.0268 - val_accuracy: 0.9688\n",
      "Epoch 12/30\n",
      "1670/1670 [==============================] - 1953s 1s/step - loss: 0.0397 - accuracy: 0.9863 - val_loss: 0.0124 - val_accuracy: 1.0000\n",
      "Epoch 13/30\n",
      "1670/1670 [==============================] - 1948s 1s/step - loss: 0.0306 - accuracy: 0.9903 - val_loss: 0.0115 - val_accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "1670/1670 [==============================] - 1951s 1s/step - loss: 0.0275 - accuracy: 0.9912 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
      "Epoch 15/30\n",
      "1670/1670 [==============================] - 1952s 1s/step - loss: 0.0226 - accuracy: 0.9925 - val_loss: 0.0073 - val_accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "1670/1670 [==============================] - 1951s 1s/step - loss: 0.0193 - accuracy: 0.9936 - val_loss: 0.0124 - val_accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "1670/1670 [==============================] - 1956s 1s/step - loss: 0.0169 - accuracy: 0.9943 - val_loss: 0.0464 - val_accuracy: 0.9688\n",
      "Epoch 18/30\n",
      "1670/1670 [==============================] - 1957s 1s/step - loss: 0.0157 - accuracy: 0.9951 - val_loss: 0.0433 - val_accuracy: 0.9688\n",
      "Epoch 19/30\n",
      "1670/1670 [==============================] - 1958s 1s/step - loss: 0.0139 - accuracy: 0.9952 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "1670/1670 [==============================] - 1952s 1s/step - loss: 0.0129 - accuracy: 0.9954 - val_loss: 0.0288 - val_accuracy: 0.9688\n",
      "Epoch 21/30\n",
      "1670/1670 [==============================] - 1969s 1s/step - loss: 0.0125 - accuracy: 0.9958 - val_loss: 0.0125 - val_accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "1670/1670 [==============================] - 1970s 1s/step - loss: 0.0107 - accuracy: 0.9958 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "1670/1670 [==============================] - 1972s 1s/step - loss: 0.0104 - accuracy: 0.9958 - val_loss: 0.0245 - val_accuracy: 0.9688\n",
      "Epoch 24/30\n",
      "1670/1670 [==============================] - 1972s 1s/step - loss: 0.0104 - accuracy: 0.9956 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "1670/1670 [==============================] - 1975s 1s/step - loss: 0.0079 - accuracy: 0.9965 - val_loss: 0.0219 - val_accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "1670/1670 [==============================] - 1957s 1s/step - loss: 0.0076 - accuracy: 0.9964 - val_loss: 0.0293 - val_accuracy: 0.9688\n",
      "Epoch 27/30\n",
      "1670/1670 [==============================] - 1959s 1s/step - loss: 0.0069 - accuracy: 0.9969 - val_loss: 0.0117 - val_accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "1670/1670 [==============================] - 1957s 1s/step - loss: 0.0069 - accuracy: 0.9967 - val_loss: 0.0142 - val_accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "1670/1670 [==============================] - 1957s 1s/step - loss: 0.0068 - accuracy: 0.9966 - val_loss: 0.0283 - val_accuracy: 0.9688\n",
      "Epoch 30/30\n",
      "1670/1670 [==============================] - 1961s 1s/step - loss: 0.0069 - accuracy: 0.9963 - val_loss: 0.0120 - val_accuracy: 1.0000\n",
      "INFO:tensorflow:Assets written to: ../opticnet/opticnet_30epochs_83484.0_images_True_newWeights_False_lastLayerOnly_rescale-symmetric_normalization/assets\n",
      "Test acc for opticnet: 0.998967\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.0101463  0.00983739 0.01039831 0.00963324]\n",
      "Training xception for 0.01% of train size (aka 834 images) with pretrained: True and onlyLastLayersTrained: True...\n",
      "\n",
      "Total: 135 trainable: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      " 6/17 [=========>....................] - ETA: 5s - loss: 1.3919 - accuracy: 0.0850WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1193s vs `on_train_batch_begin` time: 0.1330s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1193s vs `on_train_batch_end` time: 0.2083s). Check your callbacks.\n",
      "17/17 [==============================] - 10s 323ms/step - loss: 1.3900 - accuracy: 0.1090 - val_loss: 1.3853 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "17/17 [==============================] - 2s 124ms/step - loss: 1.3889 - accuracy: 0.1243 - val_loss: 1.3853 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "17/17 [==============================] - 2s 124ms/step - loss: 1.3887 - accuracy: 0.1192 - val_loss: 1.3853 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "17/17 [==============================] - 2s 124ms/step - loss: 1.3903 - accuracy: 0.1132 - val_loss: 1.3853 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "17/17 [==============================] - 2s 124ms/step - loss: 1.3881 - accuracy: 0.1203 - val_loss: 1.3853 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "17/17 [==============================] - 2s 124ms/step - loss: 1.3897 - accuracy: 0.1109 - val_loss: 1.3853 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "17/17 [==============================] - 2s 124ms/step - loss: 1.3890 - accuracy: 0.1163 - val_loss: 1.3853 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "17/17 [==============================] - 2s 124ms/step - loss: 1.3893 - accuracy: 0.1067 - val_loss: 1.3853 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "17/17 [==============================] - 2s 125ms/step - loss: 1.3892 - accuracy: 0.1254 - val_loss: 1.3853 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "17/17 [==============================] - 2s 125ms/step - loss: 1.3885 - accuracy: 0.1247 - val_loss: 1.3853 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "17/17 [==============================] - 2s 124ms/step - loss: 1.3881 - accuracy: 0.1422 - val_loss: 1.3853 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "17/17 [==============================] - 2s 124ms/step - loss: 1.3895 - accuracy: 0.1135 - val_loss: 1.3853 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "17/17 [==============================] - 2s 125ms/step - loss: 1.3900 - accuracy: 0.1240 - val_loss: 1.3853 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "17/17 [==============================] - 2s 126ms/step - loss: 1.3889 - accuracy: 0.1181 - val_loss: 1.3853 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "17/17 [==============================] - 2s 125ms/step - loss: 1.3887 - accuracy: 0.1324 - val_loss: 1.3853 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "17/17 [==============================] - 2s 126ms/step - loss: 1.3884 - accuracy: 0.1156 - val_loss: 1.3853 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "17/17 [==============================] - 2s 125ms/step - loss: 1.3892 - accuracy: 0.1137 - val_loss: 1.3853 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "17/17 [==============================] - 2s 124ms/step - loss: 1.3881 - accuracy: 0.1345 - val_loss: 1.3853 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "17/17 [==============================] - 2s 124ms/step - loss: 1.3888 - accuracy: 0.1273 - val_loss: 1.3853 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "17/17 [==============================] - 2s 125ms/step - loss: 1.3890 - accuracy: 0.1269 - val_loss: 1.3853 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "17/17 [==============================] - 2s 126ms/step - loss: 1.3897 - accuracy: 0.1154 - val_loss: 1.3853 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "17/17 [==============================] - 2s 125ms/step - loss: 1.3892 - accuracy: 0.1138 - val_loss: 1.3853 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "17/17 [==============================] - 2s 125ms/step - loss: 1.3890 - accuracy: 0.1007 - val_loss: 1.3853 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "17/17 [==============================] - 2s 124ms/step - loss: 1.3891 - accuracy: 0.1238 - val_loss: 1.3853 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "17/17 [==============================] - 2s 126ms/step - loss: 1.3882 - accuracy: 0.1413 - val_loss: 1.3853 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "17/17 [==============================] - 2s 125ms/step - loss: 1.3888 - accuracy: 0.1369 - val_loss: 1.3853 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "17/17 [==============================] - 2s 125ms/step - loss: 1.3882 - accuracy: 0.1286 - val_loss: 1.3853 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "17/17 [==============================] - 2s 125ms/step - loss: 1.3889 - accuracy: 0.1359 - val_loss: 1.3853 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "17/17 [==============================] - 2s 125ms/step - loss: 1.3886 - accuracy: 0.1184 - val_loss: 1.3853 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "17/17 [==============================] - 2s 124ms/step - loss: 1.3895 - accuracy: 0.1178 - val_loss: 1.3853 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../xception/xception_30epochs_834.84_images_False_newWeights_True_lastLayerOnly_rescale-symmetric_normalization/assets\n",
      "Test acc for xception: 0.247934\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training resnet for 0.01% of train size (aka 834 images) with pretrained: True and onlyLastLayersTrained: True...\n",
      "\n",
      "Total: 178 trainable: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      " 6/17 [=========>....................] - ETA: 4s - loss: 1.3908 - accuracy: 0.2298WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0598s vs `on_train_batch_begin` time: 0.1366s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0598s vs `on_train_batch_end` time: 0.1662s). Check your callbacks.\n",
      "17/17 [==============================] - 8s 263ms/step - loss: 1.3913 - accuracy: 0.2276 - val_loss: 1.3918 - val_accuracy: 0.1562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.3915 - accuracy: 0.2221 - val_loss: 1.3918 - val_accuracy: 0.1562\n",
      "Epoch 3/30\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.3914 - accuracy: 0.2361 - val_loss: 1.3918 - val_accuracy: 0.1562\n",
      "Epoch 4/30\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.3917 - accuracy: 0.2323 - val_loss: 1.3918 - val_accuracy: 0.1562\n",
      "Epoch 5/30\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.3921 - accuracy: 0.2407 - val_loss: 1.3918 - val_accuracy: 0.1562\n",
      "Epoch 6/30\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.3907 - accuracy: 0.2429 - val_loss: 1.3918 - val_accuracy: 0.1562\n",
      "Epoch 7/30\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.3908 - accuracy: 0.2397 - val_loss: 1.3918 - val_accuracy: 0.1562\n",
      "Epoch 8/30\n",
      "17/17 [==============================] - 1s 59ms/step - loss: 1.3915 - accuracy: 0.2323 - val_loss: 1.3918 - val_accuracy: 0.1562\n",
      "Epoch 9/30\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.3919 - accuracy: 0.2242 - val_loss: 1.3918 - val_accuracy: 0.1562\n",
      "Epoch 10/30\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.3909 - accuracy: 0.2144 - val_loss: 1.3918 - val_accuracy: 0.1562\n",
      "Epoch 11/30\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.3919 - accuracy: 0.2334 - val_loss: 1.3918 - val_accuracy: 0.1562\n",
      "Epoch 12/30\n",
      "17/17 [==============================] - 1s 59ms/step - loss: 1.3911 - accuracy: 0.2335 - val_loss: 1.3918 - val_accuracy: 0.1562\n",
      "Epoch 13/30\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.3912 - accuracy: 0.2155 - val_loss: 1.3918 - val_accuracy: 0.1562\n",
      "Epoch 14/30\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.3913 - accuracy: 0.2198 - val_loss: 1.3918 - val_accuracy: 0.1562\n",
      "Epoch 15/30\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.3918 - accuracy: 0.2183 - val_loss: 1.3918 - val_accuracy: 0.1562\n",
      "Epoch 16/30\n",
      "17/17 [==============================] - 1s 59ms/step - loss: 1.3922 - accuracy: 0.2327 - val_loss: 1.3918 - val_accuracy: 0.1562\n",
      "Epoch 17/30\n",
      "17/17 [==============================] - 1s 59ms/step - loss: 1.3928 - accuracy: 0.2178 - val_loss: 1.3918 - val_accuracy: 0.1562\n",
      "Epoch 18/30\n",
      "17/17 [==============================] - 1s 59ms/step - loss: 1.3921 - accuracy: 0.2307 - val_loss: 1.3918 - val_accuracy: 0.1562\n",
      "Epoch 19/30\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.3914 - accuracy: 0.2311 - val_loss: 1.3918 - val_accuracy: 0.1562\n",
      "Epoch 20/30\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.3904 - accuracy: 0.2378 - val_loss: 1.3918 - val_accuracy: 0.1562\n",
      "Epoch 21/30\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.3909 - accuracy: 0.2305 - val_loss: 1.3918 - val_accuracy: 0.1562\n",
      "Epoch 22/30\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.3921 - accuracy: 0.1914 - val_loss: 1.3918 - val_accuracy: 0.1562\n",
      "Epoch 23/30\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.3919 - accuracy: 0.2091 - val_loss: 1.3918 - val_accuracy: 0.1562\n",
      "Epoch 24/30\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.3930 - accuracy: 0.2149 - val_loss: 1.3918 - val_accuracy: 0.1562\n",
      "Epoch 25/30\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.3913 - accuracy: 0.2274 - val_loss: 1.3918 - val_accuracy: 0.1562\n",
      "Epoch 26/30\n",
      "17/17 [==============================] - 1s 59ms/step - loss: 1.3918 - accuracy: 0.2158 - val_loss: 1.3918 - val_accuracy: 0.1562\n",
      "Epoch 27/30\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.3916 - accuracy: 0.2293 - val_loss: 1.3918 - val_accuracy: 0.1562\n",
      "Epoch 28/30\n",
      "17/17 [==============================] - 1s 59ms/step - loss: 1.3925 - accuracy: 0.2228 - val_loss: 1.3918 - val_accuracy: 0.1562\n",
      "Epoch 29/30\n",
      "17/17 [==============================] - 1s 59ms/step - loss: 1.3921 - accuracy: 0.2232 - val_loss: 1.3918 - val_accuracy: 0.1562\n",
      "Epoch 30/30\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.3907 - accuracy: 0.2453 - val_loss: 1.3918 - val_accuracy: 0.1562\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_834.84_images_False_newWeights_True_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.237603\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training opticnet for 0.01% of train size (aka 834 images) with pretrained: True and onlyLastLayersTrained: True...\n",
      "\n",
      "Total: 276 trainable: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "17/17 [==============================] - 17s 679ms/step - loss: 276.8884 - accuracy: 0.1475 - val_loss: 217.3077 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "17/17 [==============================] - 5s 292ms/step - loss: 272.3087 - accuracy: 0.1527 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "17/17 [==============================] - 5s 293ms/step - loss: 288.3607 - accuracy: 0.1268 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "17/17 [==============================] - 5s 293ms/step - loss: 276.3252 - accuracy: 0.1433 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "17/17 [==============================] - 5s 293ms/step - loss: 279.8295 - accuracy: 0.1462 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "17/17 [==============================] - 5s 294ms/step - loss: 280.9861 - accuracy: 0.1423 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "17/17 [==============================] - 5s 295ms/step - loss: 285.3850 - accuracy: 0.1254 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "17/17 [==============================] - 5s 295ms/step - loss: 281.3499 - accuracy: 0.1456 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "17/17 [==============================] - 5s 295ms/step - loss: 274.1077 - accuracy: 0.1281 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "17/17 [==============================] - 5s 296ms/step - loss: 275.5504 - accuracy: 0.1656 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "17/17 [==============================] - 5s 295ms/step - loss: 283.0128 - accuracy: 0.1369 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "17/17 [==============================] - 5s 296ms/step - loss: 284.3747 - accuracy: 0.1391 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "17/17 [==============================] - 5s 296ms/step - loss: 278.6924 - accuracy: 0.1510 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "17/17 [==============================] - 5s 295ms/step - loss: 276.1698 - accuracy: 0.1483 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "17/17 [==============================] - 5s 296ms/step - loss: 281.6707 - accuracy: 0.1534 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "17/17 [==============================] - 5s 294ms/step - loss: 284.8460 - accuracy: 0.1408 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "17/17 [==============================] - 5s 296ms/step - loss: 278.9299 - accuracy: 0.1429 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "17/17 [==============================] - 5s 296ms/step - loss: 277.2834 - accuracy: 0.1519 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "17/17 [==============================] - 5s 295ms/step - loss: 280.6755 - accuracy: 0.1526 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "17/17 [==============================] - 5s 296ms/step - loss: 277.0820 - accuracy: 0.1471 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "17/17 [==============================] - 5s 295ms/step - loss: 285.9831 - accuracy: 0.1363 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "17/17 [==============================] - 5s 295ms/step - loss: 276.4578 - accuracy: 0.1463 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "17/17 [==============================] - 5s 295ms/step - loss: 288.4403 - accuracy: 0.1325 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "17/17 [==============================] - 5s 295ms/step - loss: 273.2158 - accuracy: 0.1518 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "17/17 [==============================] - 5s 295ms/step - loss: 273.7972 - accuracy: 0.1502 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "17/17 [==============================] - 5s 296ms/step - loss: 283.1607 - accuracy: 0.1283 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "17/17 [==============================] - 5s 295ms/step - loss: 282.2806 - accuracy: 0.1488 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "17/17 [==============================] - 5s 295ms/step - loss: 284.4000 - accuracy: 0.1500 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "17/17 [==============================] - 5s 296ms/step - loss: 274.2911 - accuracy: 0.1540 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "17/17 [==============================] - 5s 295ms/step - loss: 288.3342 - accuracy: 0.1249 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../opticnet/opticnet_30epochs_834.84_images_False_newWeights_True_lastLayerOnly_rescale-symmetric_normalization/assets\n",
      "Test acc for opticnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.02451074 0.02513103 0.02467395 0.02634633]\n",
      "Training xception for 0.025% of train size (aka 2087 images) with pretrained: True and onlyLastLayersTrained: True...\n",
      "\n",
      "Total: 135 trainable: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      " 6/42 [===>..........................] - ETA: 17s - loss: 1.3808 - accuracy: 0.3009WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1179s vs `on_train_batch_begin` time: 0.1355s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1179s vs `on_train_batch_end` time: 0.1829s). Check your callbacks.\n",
      "42/42 [==============================] - 11s 197ms/step - loss: 1.3790 - accuracy: 0.2908 - val_loss: 1.3814 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "42/42 [==============================] - 5s 121ms/step - loss: 1.3781 - accuracy: 0.2872 - val_loss: 1.3814 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "42/42 [==============================] - 5s 121ms/step - loss: 1.3763 - accuracy: 0.3028 - val_loss: 1.3814 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "42/42 [==============================] - 5s 122ms/step - loss: 1.3791 - accuracy: 0.2804 - val_loss: 1.3814 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "42/42 [==============================] - 5s 123ms/step - loss: 1.3791 - accuracy: 0.2784 - val_loss: 1.3814 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "42/42 [==============================] - 5s 121ms/step - loss: 1.3785 - accuracy: 0.2831 - val_loss: 1.3814 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "42/42 [==============================] - 5s 122ms/step - loss: 1.3790 - accuracy: 0.2796 - val_loss: 1.3814 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "42/42 [==============================] - 5s 123ms/step - loss: 1.3769 - accuracy: 0.2876 - val_loss: 1.3814 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "42/42 [==============================] - 5s 122ms/step - loss: 1.3786 - accuracy: 0.2852 - val_loss: 1.3814 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "42/42 [==============================] - 5s 123ms/step - loss: 1.3769 - accuracy: 0.3046 - val_loss: 1.3814 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "42/42 [==============================] - 5s 122ms/step - loss: 1.3789 - accuracy: 0.2975 - val_loss: 1.3814 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "42/42 [==============================] - 5s 123ms/step - loss: 1.3774 - accuracy: 0.2870 - val_loss: 1.3814 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "42/42 [==============================] - 5s 122ms/step - loss: 1.3795 - accuracy: 0.2777 - val_loss: 1.3814 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "42/42 [==============================] - 5s 122ms/step - loss: 1.3777 - accuracy: 0.2983 - val_loss: 1.3814 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "42/42 [==============================] - 5s 123ms/step - loss: 1.3776 - accuracy: 0.2937 - val_loss: 1.3814 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "42/42 [==============================] - 5s 123ms/step - loss: 1.3782 - accuracy: 0.2990 - val_loss: 1.3814 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "42/42 [==============================] - 5s 123ms/step - loss: 1.3780 - accuracy: 0.2987 - val_loss: 1.3814 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "42/42 [==============================] - 5s 123ms/step - loss: 1.3777 - accuracy: 0.3039 - val_loss: 1.3814 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "42/42 [==============================] - 5s 123ms/step - loss: 1.3779 - accuracy: 0.2932 - val_loss: 1.3814 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "42/42 [==============================] - 5s 123ms/step - loss: 1.3787 - accuracy: 0.2878 - val_loss: 1.3814 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "42/42 [==============================] - 5s 123ms/step - loss: 1.3779 - accuracy: 0.2947 - val_loss: 1.3814 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "42/42 [==============================] - 5s 123ms/step - loss: 1.3784 - accuracy: 0.2807 - val_loss: 1.3814 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "42/42 [==============================] - 5s 123ms/step - loss: 1.3780 - accuracy: 0.2847 - val_loss: 1.3814 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "42/42 [==============================] - 5s 123ms/step - loss: 1.3785 - accuracy: 0.2888 - val_loss: 1.3814 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "42/42 [==============================] - 5s 123ms/step - loss: 1.3777 - accuracy: 0.2965 - val_loss: 1.3814 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "42/42 [==============================] - 5s 123ms/step - loss: 1.3773 - accuracy: 0.3070 - val_loss: 1.3814 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "42/42 [==============================] - 5s 123ms/step - loss: 1.3781 - accuracy: 0.2897 - val_loss: 1.3814 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "42/42 [==============================] - 5s 123ms/step - loss: 1.3790 - accuracy: 0.2843 - val_loss: 1.3814 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "42/42 [==============================] - 5s 123ms/step - loss: 1.3776 - accuracy: 0.3020 - val_loss: 1.3814 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "42/42 [==============================] - 5s 123ms/step - loss: 1.3796 - accuracy: 0.2743 - val_loss: 1.3814 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../xception/xception_30epochs_2087.1_images_False_newWeights_True_lastLayerOnly_rescale-symmetric_normalization/assets\n",
      "Test acc for xception: 0.233471\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training resnet for 0.025% of train size (aka 2087 images) with pretrained: True and onlyLastLayersTrained: True...\n",
      "\n",
      "Total: 178 trainable: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      " 6/42 [===>..........................] - ETA: 14s - loss: 1.3882 - accuracy: 0.1557WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0618s vs `on_train_batch_begin` time: 0.1346s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0618s vs `on_train_batch_end` time: 0.1578s). Check your callbacks.\n",
      "42/42 [==============================] - 9s 136ms/step - loss: 1.3879 - accuracy: 0.1716 - val_loss: 1.3795 - val_accuracy: 0.3750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "42/42 [==============================] - 2s 57ms/step - loss: 1.3878 - accuracy: 0.1842 - val_loss: 1.3795 - val_accuracy: 0.3750\n",
      "Epoch 3/30\n",
      "42/42 [==============================] - 2s 58ms/step - loss: 1.3874 - accuracy: 0.1900 - val_loss: 1.3795 - val_accuracy: 0.3750\n",
      "Epoch 4/30\n",
      "42/42 [==============================] - 2s 58ms/step - loss: 1.3882 - accuracy: 0.1707 - val_loss: 1.3795 - val_accuracy: 0.3750\n",
      "Epoch 5/30\n",
      "42/42 [==============================] - 2s 57ms/step - loss: 1.3880 - accuracy: 0.1816 - val_loss: 1.3795 - val_accuracy: 0.3750\n",
      "Epoch 6/30\n",
      "42/42 [==============================] - 2s 58ms/step - loss: 1.3883 - accuracy: 0.1873 - val_loss: 1.3795 - val_accuracy: 0.3750\n",
      "Epoch 7/30\n",
      "42/42 [==============================] - 2s 58ms/step - loss: 1.3871 - accuracy: 0.1872 - val_loss: 1.3795 - val_accuracy: 0.3750\n",
      "Epoch 8/30\n",
      "42/42 [==============================] - 2s 58ms/step - loss: 1.3875 - accuracy: 0.1911 - val_loss: 1.3795 - val_accuracy: 0.3750\n",
      "Epoch 9/30\n",
      "42/42 [==============================] - 2s 58ms/step - loss: 1.3878 - accuracy: 0.1832 - val_loss: 1.3795 - val_accuracy: 0.3750\n",
      "Epoch 10/30\n",
      "42/42 [==============================] - 2s 58ms/step - loss: 1.3879 - accuracy: 0.1715 - val_loss: 1.3795 - val_accuracy: 0.3750\n",
      "Epoch 11/30\n",
      "42/42 [==============================] - 2s 57ms/step - loss: 1.3879 - accuracy: 0.1866 - val_loss: 1.3795 - val_accuracy: 0.3750\n",
      "Epoch 12/30\n",
      "42/42 [==============================] - 2s 58ms/step - loss: 1.3878 - accuracy: 0.1937 - val_loss: 1.3795 - val_accuracy: 0.3750\n",
      "Epoch 13/30\n",
      "42/42 [==============================] - 2s 57ms/step - loss: 1.3882 - accuracy: 0.1757 - val_loss: 1.3795 - val_accuracy: 0.3750\n",
      "Epoch 14/30\n",
      "42/42 [==============================] - 2s 57ms/step - loss: 1.3870 - accuracy: 0.1930 - val_loss: 1.3795 - val_accuracy: 0.3750\n",
      "Epoch 15/30\n",
      "42/42 [==============================] - 2s 57ms/step - loss: 1.3872 - accuracy: 0.1771 - val_loss: 1.3795 - val_accuracy: 0.3750\n",
      "Epoch 16/30\n",
      "42/42 [==============================] - 2s 58ms/step - loss: 1.3881 - accuracy: 0.1751 - val_loss: 1.3795 - val_accuracy: 0.3750\n",
      "Epoch 17/30\n",
      "42/42 [==============================] - 2s 57ms/step - loss: 1.3872 - accuracy: 0.1988 - val_loss: 1.3795 - val_accuracy: 0.3750\n",
      "Epoch 18/30\n",
      "42/42 [==============================] - 2s 57ms/step - loss: 1.3880 - accuracy: 0.1793 - val_loss: 1.3795 - val_accuracy: 0.3750\n",
      "Epoch 19/30\n",
      "42/42 [==============================] - 2s 58ms/step - loss: 1.3882 - accuracy: 0.1792 - val_loss: 1.3795 - val_accuracy: 0.3750\n",
      "Epoch 20/30\n",
      "42/42 [==============================] - 2s 58ms/step - loss: 1.3874 - accuracy: 0.1930 - val_loss: 1.3795 - val_accuracy: 0.3750\n",
      "Epoch 21/30\n",
      "42/42 [==============================] - 2s 58ms/step - loss: 1.3886 - accuracy: 0.1719 - val_loss: 1.3795 - val_accuracy: 0.3750\n",
      "Epoch 22/30\n",
      "42/42 [==============================] - 2s 58ms/step - loss: 1.3872 - accuracy: 0.1902 - val_loss: 1.3795 - val_accuracy: 0.3750\n",
      "Epoch 23/30\n",
      "42/42 [==============================] - 2s 58ms/step - loss: 1.3876 - accuracy: 0.1751 - val_loss: 1.3795 - val_accuracy: 0.3750\n",
      "Epoch 24/30\n",
      "42/42 [==============================] - 2s 57ms/step - loss: 1.3875 - accuracy: 0.1799 - val_loss: 1.3795 - val_accuracy: 0.3750\n",
      "Epoch 25/30\n",
      "42/42 [==============================] - 2s 58ms/step - loss: 1.3871 - accuracy: 0.1917 - val_loss: 1.3795 - val_accuracy: 0.3750\n",
      "Epoch 26/30\n",
      "42/42 [==============================] - 2s 58ms/step - loss: 1.3875 - accuracy: 0.1767 - val_loss: 1.3795 - val_accuracy: 0.3750\n",
      "Epoch 27/30\n",
      "42/42 [==============================] - 2s 58ms/step - loss: 1.3873 - accuracy: 0.1846 - val_loss: 1.3795 - val_accuracy: 0.3750\n",
      "Epoch 28/30\n",
      "42/42 [==============================] - 2s 58ms/step - loss: 1.3872 - accuracy: 0.1890 - val_loss: 1.3795 - val_accuracy: 0.3750\n",
      "Epoch 29/30\n",
      "42/42 [==============================] - 2s 58ms/step - loss: 1.3876 - accuracy: 0.1857 - val_loss: 1.3795 - val_accuracy: 0.3750\n",
      "Epoch 30/30\n",
      "42/42 [==============================] - 2s 58ms/step - loss: 1.3885 - accuracy: 0.1721 - val_loss: 1.3795 - val_accuracy: 0.3750\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_2087.1_images_False_newWeights_True_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.236570\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training opticnet for 0.025% of train size (aka 2087 images) with pretrained: True and onlyLastLayersTrained: True...\n",
      "\n",
      "Total: 276 trainable: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "42/42 [==============================] - 22s 397ms/step - loss: 294.1921 - accuracy: 0.1229 - val_loss: 217.3077 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "42/42 [==============================] - 12s 289ms/step - loss: 285.6142 - accuracy: 0.1359 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "42/42 [==============================] - 12s 290ms/step - loss: 284.5070 - accuracy: 0.1376 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "42/42 [==============================] - 12s 290ms/step - loss: 283.3910 - accuracy: 0.1431 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "42/42 [==============================] - 12s 290ms/step - loss: 283.7209 - accuracy: 0.1403 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "42/42 [==============================] - 12s 291ms/step - loss: 283.6203 - accuracy: 0.1346 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "42/42 [==============================] - 12s 291ms/step - loss: 286.0670 - accuracy: 0.1341 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "42/42 [==============================] - 12s 291ms/step - loss: 295.2072 - accuracy: 0.1194 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "42/42 [==============================] - 12s 291ms/step - loss: 279.1895 - accuracy: 0.1388 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "42/42 [==============================] - 12s 290ms/step - loss: 287.4602 - accuracy: 0.1300 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "42/42 [==============================] - 12s 291ms/step - loss: 283.3713 - accuracy: 0.1403 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "42/42 [==============================] - 12s 291ms/step - loss: 287.1279 - accuracy: 0.1332 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "42/42 [==============================] - 12s 291ms/step - loss: 288.9608 - accuracy: 0.1295 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "42/42 [==============================] - 12s 291ms/step - loss: 279.9704 - accuracy: 0.1540 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "42/42 [==============================] - 12s 291ms/step - loss: 285.6714 - accuracy: 0.1310 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "42/42 [==============================] - 12s 291ms/step - loss: 288.6190 - accuracy: 0.1365 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "42/42 [==============================] - 12s 291ms/step - loss: 279.0184 - accuracy: 0.1458 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "42/42 [==============================] - 12s 291ms/step - loss: 288.7739 - accuracy: 0.1312 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "42/42 [==============================] - 12s 291ms/step - loss: 286.9611 - accuracy: 0.1332 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "42/42 [==============================] - 12s 291ms/step - loss: 290.9785 - accuracy: 0.1449 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "42/42 [==============================] - 12s 291ms/step - loss: 287.9854 - accuracy: 0.1272 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "42/42 [==============================] - 12s 291ms/step - loss: 282.0681 - accuracy: 0.1382 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "42/42 [==============================] - 12s 291ms/step - loss: 282.5854 - accuracy: 0.1361 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "42/42 [==============================] - 12s 291ms/step - loss: 281.6769 - accuracy: 0.1359 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "42/42 [==============================] - 12s 291ms/step - loss: 290.7106 - accuracy: 0.1281 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "42/42 [==============================] - 12s 291ms/step - loss: 285.0742 - accuracy: 0.1405 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "42/42 [==============================] - 12s 291ms/step - loss: 288.4388 - accuracy: 0.1305 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "42/42 [==============================] - 12s 291ms/step - loss: 285.6384 - accuracy: 0.1340 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "42/42 [==============================] - 12s 291ms/step - loss: 290.1411 - accuracy: 0.1160 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "42/42 [==============================] - 12s 291ms/step - loss: 287.0488 - accuracy: 0.1407 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../opticnet/opticnet_30epochs_2087.1_images_False_newWeights_True_lastLayerOnly_rescale-symmetric_normalization/assets\n",
      "Test acc for opticnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.0498575  0.04993952 0.05172718 0.04839833]\n",
      "Training xception for 0.05% of train size (aka 4174 images) with pretrained: True and onlyLastLayersTrained: True...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total: 135 trainable: 2\n",
      "Epoch 1/30\n",
      " 6/84 [=>............................] - ETA: 40s - loss: 1.3849 - accuracy: 0.1254WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1174s vs `on_train_batch_begin` time: 0.1343s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1174s vs `on_train_batch_end` time: 0.1959s). Check your callbacks.\n",
      "84/84 [==============================] - 16s 157ms/step - loss: 1.3849 - accuracy: 0.1498 - val_loss: 1.3874 - val_accuracy: 0.2188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "84/84 [==============================] - 10s 120ms/step - loss: 1.3846 - accuracy: 0.1478 - val_loss: 1.3874 - val_accuracy: 0.2188\n",
      "Epoch 3/30\n",
      "84/84 [==============================] - 10s 121ms/step - loss: 1.3844 - accuracy: 0.1543 - val_loss: 1.3874 - val_accuracy: 0.2188\n",
      "Epoch 4/30\n",
      "84/84 [==============================] - 10s 122ms/step - loss: 1.3841 - accuracy: 0.1618 - val_loss: 1.3874 - val_accuracy: 0.2188\n",
      "Epoch 5/30\n",
      "84/84 [==============================] - 10s 122ms/step - loss: 1.3847 - accuracy: 0.1511 - val_loss: 1.3874 - val_accuracy: 0.2188\n",
      "Epoch 6/30\n",
      "84/84 [==============================] - 10s 122ms/step - loss: 1.3845 - accuracy: 0.1591 - val_loss: 1.3874 - val_accuracy: 0.2188\n",
      "Epoch 7/30\n",
      "84/84 [==============================] - 10s 122ms/step - loss: 1.3843 - accuracy: 0.1515 - val_loss: 1.3874 - val_accuracy: 0.2188\n",
      "Epoch 8/30\n",
      "84/84 [==============================] - 10s 122ms/step - loss: 1.3847 - accuracy: 0.1512 - val_loss: 1.3874 - val_accuracy: 0.2188\n",
      "Epoch 9/30\n",
      "84/84 [==============================] - 10s 122ms/step - loss: 1.3853 - accuracy: 0.1466 - val_loss: 1.3874 - val_accuracy: 0.2188\n",
      "Epoch 10/30\n",
      "84/84 [==============================] - 10s 122ms/step - loss: 1.3845 - accuracy: 0.1548 - val_loss: 1.3874 - val_accuracy: 0.2188\n",
      "Epoch 11/30\n",
      "84/84 [==============================] - 10s 122ms/step - loss: 1.3847 - accuracy: 0.1563 - val_loss: 1.3874 - val_accuracy: 0.2188\n",
      "Epoch 12/30\n",
      "84/84 [==============================] - 10s 122ms/step - loss: 1.3845 - accuracy: 0.1491 - val_loss: 1.3874 - val_accuracy: 0.2188\n",
      "Epoch 13/30\n",
      "84/84 [==============================] - 10s 122ms/step - loss: 1.3850 - accuracy: 0.1469 - val_loss: 1.3874 - val_accuracy: 0.2188\n",
      "Epoch 14/30\n",
      "84/84 [==============================] - 10s 122ms/step - loss: 1.3847 - accuracy: 0.1503 - val_loss: 1.3874 - val_accuracy: 0.2188\n",
      "Epoch 15/30\n",
      "84/84 [==============================] - 10s 122ms/step - loss: 1.3851 - accuracy: 0.1475 - val_loss: 1.3874 - val_accuracy: 0.2188\n",
      "Epoch 16/30\n",
      "84/84 [==============================] - 10s 123ms/step - loss: 1.3847 - accuracy: 0.1565 - val_loss: 1.3874 - val_accuracy: 0.2188\n",
      "Epoch 17/30\n",
      "84/84 [==============================] - 10s 122ms/step - loss: 1.3857 - accuracy: 0.1400 - val_loss: 1.3874 - val_accuracy: 0.2188\n",
      "Epoch 18/30\n",
      "84/84 [==============================] - 10s 123ms/step - loss: 1.3843 - accuracy: 0.1553 - val_loss: 1.3874 - val_accuracy: 0.2188\n",
      "Epoch 19/30\n",
      "84/84 [==============================] - 10s 123ms/step - loss: 1.3843 - accuracy: 0.1562 - val_loss: 1.3874 - val_accuracy: 0.2188\n",
      "Epoch 20/30\n",
      "84/84 [==============================] - 10s 122ms/step - loss: 1.3851 - accuracy: 0.1413 - val_loss: 1.3874 - val_accuracy: 0.2188\n",
      "Epoch 21/30\n",
      "84/84 [==============================] - 10s 123ms/step - loss: 1.3846 - accuracy: 0.1529 - val_loss: 1.3874 - val_accuracy: 0.2188\n",
      "Epoch 22/30\n",
      "84/84 [==============================] - 10s 123ms/step - loss: 1.3852 - accuracy: 0.1419 - val_loss: 1.3874 - val_accuracy: 0.2188\n",
      "Epoch 23/30\n",
      "84/84 [==============================] - 10s 122ms/step - loss: 1.3845 - accuracy: 0.1503 - val_loss: 1.3874 - val_accuracy: 0.2188\n",
      "Epoch 24/30\n",
      "84/84 [==============================] - 10s 123ms/step - loss: 1.3847 - accuracy: 0.1542 - val_loss: 1.3874 - val_accuracy: 0.2188\n",
      "Epoch 25/30\n",
      "84/84 [==============================] - 10s 123ms/step - loss: 1.3845 - accuracy: 0.1505 - val_loss: 1.3874 - val_accuracy: 0.2188\n",
      "Epoch 26/30\n",
      "84/84 [==============================] - 10s 123ms/step - loss: 1.3846 - accuracy: 0.1486 - val_loss: 1.3874 - val_accuracy: 0.2188\n",
      "Epoch 27/30\n",
      "84/84 [==============================] - 10s 123ms/step - loss: 1.3841 - accuracy: 0.1569 - val_loss: 1.3874 - val_accuracy: 0.2188\n",
      "Epoch 28/30\n",
      "84/84 [==============================] - 10s 122ms/step - loss: 1.3843 - accuracy: 0.1561 - val_loss: 1.3874 - val_accuracy: 0.2188\n",
      "Epoch 29/30\n",
      "84/84 [==============================] - 10s 123ms/step - loss: 1.3847 - accuracy: 0.1523 - val_loss: 1.3874 - val_accuracy: 0.2188\n",
      "Epoch 30/30\n",
      "84/84 [==============================] - 10s 122ms/step - loss: 1.3850 - accuracy: 0.1465 - val_loss: 1.3874 - val_accuracy: 0.2188\n",
      "INFO:tensorflow:Assets written to: ../xception/xception_30epochs_4174.2_images_False_newWeights_True_lastLayerOnly_rescale-symmetric_normalization/assets\n",
      "Test acc for xception: 0.245868\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training resnet for 0.05% of train size (aka 4174 images) with pretrained: True and onlyLastLayersTrained: True...\n",
      "\n",
      "Total: 178 trainable: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      " 6/84 [=>............................] - ETA: 50s - loss: 1.3908 - accuracy: 0.2092 WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0603s vs `on_train_batch_begin` time: 0.1396s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0603s vs `on_train_batch_end` time: 0.3449s). Check your callbacks.\n",
      "84/84 [==============================] - 13s 110ms/step - loss: 1.3914 - accuracy: 0.2350 - val_loss: 1.3866 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "84/84 [==============================] - 5s 57ms/step - loss: 1.3913 - accuracy: 0.2325 - val_loss: 1.3866 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "84/84 [==============================] - 5s 56ms/step - loss: 1.3916 - accuracy: 0.2388 - val_loss: 1.3866 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "84/84 [==============================] - 5s 57ms/step - loss: 1.3912 - accuracy: 0.2349 - val_loss: 1.3866 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "84/84 [==============================] - 5s 56ms/step - loss: 1.3916 - accuracy: 0.2396 - val_loss: 1.3866 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "84/84 [==============================] - 5s 57ms/step - loss: 1.3918 - accuracy: 0.2275 - val_loss: 1.3866 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "84/84 [==============================] - 5s 57ms/step - loss: 1.3921 - accuracy: 0.2272 - val_loss: 1.3866 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "84/84 [==============================] - 5s 57ms/step - loss: 1.3916 - accuracy: 0.2266 - val_loss: 1.3866 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "84/84 [==============================] - 5s 57ms/step - loss: 1.3917 - accuracy: 0.2342 - val_loss: 1.3866 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "84/84 [==============================] - 5s 57ms/step - loss: 1.3920 - accuracy: 0.2239 - val_loss: 1.3866 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "84/84 [==============================] - 5s 57ms/step - loss: 1.3913 - accuracy: 0.2333 - val_loss: 1.3866 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "84/84 [==============================] - 5s 57ms/step - loss: 1.3911 - accuracy: 0.2236 - val_loss: 1.3866 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "84/84 [==============================] - 5s 57ms/step - loss: 1.3918 - accuracy: 0.2292 - val_loss: 1.3866 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "84/84 [==============================] - 5s 57ms/step - loss: 1.3910 - accuracy: 0.2380 - val_loss: 1.3866 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "84/84 [==============================] - 5s 57ms/step - loss: 1.3913 - accuracy: 0.2291 - val_loss: 1.3866 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "84/84 [==============================] - 5s 57ms/step - loss: 1.3910 - accuracy: 0.2466 - val_loss: 1.3866 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "84/84 [==============================] - 5s 57ms/step - loss: 1.3913 - accuracy: 0.2337 - val_loss: 1.3866 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "84/84 [==============================] - 5s 57ms/step - loss: 1.3913 - accuracy: 0.2224 - val_loss: 1.3866 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "84/84 [==============================] - 5s 57ms/step - loss: 1.3918 - accuracy: 0.2315 - val_loss: 1.3866 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "84/84 [==============================] - 5s 57ms/step - loss: 1.3918 - accuracy: 0.2301 - val_loss: 1.3866 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "84/84 [==============================] - 5s 57ms/step - loss: 1.3916 - accuracy: 0.2271 - val_loss: 1.3866 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "84/84 [==============================] - 5s 57ms/step - loss: 1.3916 - accuracy: 0.2322 - val_loss: 1.3866 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "84/84 [==============================] - 5s 57ms/step - loss: 1.3916 - accuracy: 0.2308 - val_loss: 1.3866 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "84/84 [==============================] - 5s 57ms/step - loss: 1.3918 - accuracy: 0.2216 - val_loss: 1.3866 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "84/84 [==============================] - 5s 57ms/step - loss: 1.3915 - accuracy: 0.2267 - val_loss: 1.3866 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "84/84 [==============================] - 5s 57ms/step - loss: 1.3916 - accuracy: 0.2243 - val_loss: 1.3866 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "84/84 [==============================] - 5s 57ms/step - loss: 1.3921 - accuracy: 0.2307 - val_loss: 1.3866 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "84/84 [==============================] - 5s 57ms/step - loss: 1.3920 - accuracy: 0.2393 - val_loss: 1.3866 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "84/84 [==============================] - 5s 57ms/step - loss: 1.3918 - accuracy: 0.2232 - val_loss: 1.3866 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "84/84 [==============================] - 5s 57ms/step - loss: 1.3917 - accuracy: 0.2281 - val_loss: 1.3866 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_4174.2_images_False_newWeights_True_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.285124\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training opticnet for 0.05% of train size (aka 4174 images) with pretrained: True and onlyLastLayersTrained: True...\n",
      "\n",
      "Total: 276 trainable: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "84/84 [==============================] - 35s 342ms/step - loss: 286.9713 - accuracy: 0.1415 - val_loss: 217.3077 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "84/84 [==============================] - 24s 288ms/step - loss: 289.4790 - accuracy: 0.1312 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "84/84 [==============================] - 24s 288ms/step - loss: 283.8497 - accuracy: 0.1475 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "84/84 [==============================] - 24s 289ms/step - loss: 282.1213 - accuracy: 0.1531 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "84/84 [==============================] - 24s 289ms/step - loss: 283.6430 - accuracy: 0.1388 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "84/84 [==============================] - 24s 289ms/step - loss: 286.4879 - accuracy: 0.1415 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "84/84 [==============================] - 24s 289ms/step - loss: 286.2715 - accuracy: 0.1416 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "84/84 [==============================] - 24s 289ms/step - loss: 282.2959 - accuracy: 0.1457 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "84/84 [==============================] - 24s 289ms/step - loss: 287.4768 - accuracy: 0.1402 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "84/84 [==============================] - 24s 289ms/step - loss: 286.6676 - accuracy: 0.1388 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "84/84 [==============================] - 24s 289ms/step - loss: 286.4818 - accuracy: 0.1380 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "84/84 [==============================] - 24s 289ms/step - loss: 285.5701 - accuracy: 0.1418 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "84/84 [==============================] - 24s 289ms/step - loss: 289.1559 - accuracy: 0.1345 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "84/84 [==============================] - 24s 289ms/step - loss: 285.1842 - accuracy: 0.1409 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "84/84 [==============================] - 24s 289ms/step - loss: 284.2429 - accuracy: 0.1401 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "84/84 [==============================] - 24s 289ms/step - loss: 283.8308 - accuracy: 0.1481 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "84/84 [==============================] - 24s 289ms/step - loss: 286.4300 - accuracy: 0.1353 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "84/84 [==============================] - 24s 289ms/step - loss: 291.5836 - accuracy: 0.1317 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "84/84 [==============================] - 24s 288ms/step - loss: 285.0964 - accuracy: 0.1422 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "84/84 [==============================] - 24s 289ms/step - loss: 285.1397 - accuracy: 0.1412 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "84/84 [==============================] - 24s 289ms/step - loss: 284.1029 - accuracy: 0.1397 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "84/84 [==============================] - 24s 288ms/step - loss: 288.4193 - accuracy: 0.1402 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "84/84 [==============================] - 24s 289ms/step - loss: 283.7676 - accuracy: 0.1407 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "84/84 [==============================] - 24s 289ms/step - loss: 284.8963 - accuracy: 0.1398 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "84/84 [==============================] - 24s 289ms/step - loss: 279.6006 - accuracy: 0.1542 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "84/84 [==============================] - 24s 288ms/step - loss: 284.6616 - accuracy: 0.1347 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "84/84 [==============================] - 24s 289ms/step - loss: 285.7668 - accuracy: 0.1395 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "84/84 [==============================] - 24s 289ms/step - loss: 288.0596 - accuracy: 0.1325 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "84/84 [==============================] - 24s 289ms/step - loss: 286.1063 - accuracy: 0.1421 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "84/84 [==============================] - 24s 288ms/step - loss: 287.1964 - accuracy: 0.1371 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../opticnet/opticnet_30epochs_4174.2_images_False_newWeights_True_lastLayerOnly_rescale-symmetric_normalization/assets\n",
      "Test acc for opticnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.07376021 0.07496304 0.07701798 0.07625348]\n",
      "Training xception for 0.075% of train size (aka 6261 images) with pretrained: True and onlyLastLayersTrained: True...\n",
      "\n",
      "Total: 135 trainable: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/126 [>.............................] - ETA: 1:01 - loss: 1.3855 - accuracy: 0.4054WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1201s vs `on_train_batch_begin` time: 0.1310s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1201s vs `on_train_batch_end` time: 0.1974s). Check your callbacks.\n",
      "126/126 [==============================] - 21s 145ms/step - loss: 1.3846 - accuracy: 0.4063 - val_loss: 1.3838 - val_accuracy: 0.3438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "126/126 [==============================] - 15s 120ms/step - loss: 1.3847 - accuracy: 0.3908 - val_loss: 1.3838 - val_accuracy: 0.3438\n",
      "Epoch 3/30\n",
      "126/126 [==============================] - 15s 121ms/step - loss: 1.3846 - accuracy: 0.3963 - val_loss: 1.3838 - val_accuracy: 0.3438\n",
      "Epoch 4/30\n",
      "126/126 [==============================] - 15s 121ms/step - loss: 1.3845 - accuracy: 0.3962 - val_loss: 1.3838 - val_accuracy: 0.3438\n",
      "Epoch 5/30\n",
      "126/126 [==============================] - 15s 122ms/step - loss: 1.3845 - accuracy: 0.4039 - val_loss: 1.3838 - val_accuracy: 0.3438\n",
      "Epoch 6/30\n",
      "126/126 [==============================] - 15s 122ms/step - loss: 1.3847 - accuracy: 0.3995 - val_loss: 1.3838 - val_accuracy: 0.3438\n",
      "Epoch 7/30\n",
      "126/126 [==============================] - 15s 122ms/step - loss: 1.3846 - accuracy: 0.3980 - val_loss: 1.3838 - val_accuracy: 0.3438\n",
      "Epoch 8/30\n",
      "126/126 [==============================] - 15s 122ms/step - loss: 1.3846 - accuracy: 0.3884 - val_loss: 1.3838 - val_accuracy: 0.3438\n",
      "Epoch 9/30\n",
      "126/126 [==============================] - 15s 122ms/step - loss: 1.3845 - accuracy: 0.3897 - val_loss: 1.3838 - val_accuracy: 0.3438\n",
      "Epoch 10/30\n",
      "126/126 [==============================] - 15s 123ms/step - loss: 1.3845 - accuracy: 0.4043 - val_loss: 1.3838 - val_accuracy: 0.3438\n",
      "Epoch 11/30\n",
      "126/126 [==============================] - 15s 122ms/step - loss: 1.3845 - accuracy: 0.3950 - val_loss: 1.3838 - val_accuracy: 0.3438\n",
      "Epoch 12/30\n",
      "126/126 [==============================] - 15s 122ms/step - loss: 1.3849 - accuracy: 0.3907 - val_loss: 1.3838 - val_accuracy: 0.3438\n",
      "Epoch 13/30\n",
      "126/126 [==============================] - 15s 122ms/step - loss: 1.3848 - accuracy: 0.3866 - val_loss: 1.3838 - val_accuracy: 0.3438\n",
      "Epoch 14/30\n",
      "126/126 [==============================] - 15s 122ms/step - loss: 1.3845 - accuracy: 0.4002 - val_loss: 1.3838 - val_accuracy: 0.3438\n",
      "Epoch 15/30\n",
      "126/126 [==============================] - 15s 122ms/step - loss: 1.3845 - accuracy: 0.4050 - val_loss: 1.3838 - val_accuracy: 0.3438\n",
      "Epoch 16/30\n",
      "126/126 [==============================] - 15s 122ms/step - loss: 1.3846 - accuracy: 0.3943 - val_loss: 1.3838 - val_accuracy: 0.3438\n",
      "Epoch 17/30\n",
      "126/126 [==============================] - 15s 122ms/step - loss: 1.3845 - accuracy: 0.4004 - val_loss: 1.3838 - val_accuracy: 0.3438\n",
      "Epoch 18/30\n",
      "126/126 [==============================] - 15s 122ms/step - loss: 1.3847 - accuracy: 0.3976 - val_loss: 1.3838 - val_accuracy: 0.3438\n",
      "Epoch 19/30\n",
      "126/126 [==============================] - 15s 122ms/step - loss: 1.3844 - accuracy: 0.4020 - val_loss: 1.3838 - val_accuracy: 0.3438\n",
      "Epoch 20/30\n",
      "126/126 [==============================] - 15s 122ms/step - loss: 1.3846 - accuracy: 0.4024 - val_loss: 1.3838 - val_accuracy: 0.3438\n",
      "Epoch 21/30\n",
      "126/126 [==============================] - 15s 122ms/step - loss: 1.3844 - accuracy: 0.4030 - val_loss: 1.3838 - val_accuracy: 0.3438\n",
      "Epoch 22/30\n",
      "126/126 [==============================] - 15s 122ms/step - loss: 1.3844 - accuracy: 0.3970 - val_loss: 1.3838 - val_accuracy: 0.3438\n",
      "Epoch 23/30\n",
      "126/126 [==============================] - 15s 122ms/step - loss: 1.3845 - accuracy: 0.3991 - val_loss: 1.3838 - val_accuracy: 0.3438\n",
      "Epoch 24/30\n",
      "126/126 [==============================] - 15s 122ms/step - loss: 1.3845 - accuracy: 0.3917 - val_loss: 1.3838 - val_accuracy: 0.3438\n",
      "Epoch 25/30\n",
      "126/126 [==============================] - 15s 122ms/step - loss: 1.3847 - accuracy: 0.3943 - val_loss: 1.3838 - val_accuracy: 0.3438\n",
      "Epoch 26/30\n",
      "126/126 [==============================] - 15s 123ms/step - loss: 1.3846 - accuracy: 0.4024 - val_loss: 1.3838 - val_accuracy: 0.3438\n",
      "Epoch 27/30\n",
      "126/126 [==============================] - 15s 122ms/step - loss: 1.3849 - accuracy: 0.3827 - val_loss: 1.3838 - val_accuracy: 0.3438\n",
      "Epoch 28/30\n",
      "126/126 [==============================] - 15s 122ms/step - loss: 1.3845 - accuracy: 0.3997 - val_loss: 1.3838 - val_accuracy: 0.3438\n",
      "Epoch 29/30\n",
      "126/126 [==============================] - 15s 122ms/step - loss: 1.3844 - accuracy: 0.3973 - val_loss: 1.3838 - val_accuracy: 0.3438\n",
      "Epoch 30/30\n",
      "126/126 [==============================] - 15s 122ms/step - loss: 1.3845 - accuracy: 0.4023 - val_loss: 1.3838 - val_accuracy: 0.3438\n",
      "INFO:tensorflow:Assets written to: ../xception/xception_30epochs_6261.3_images_False_newWeights_True_lastLayerOnly_rescale-symmetric_normalization/assets\n",
      "Test acc for xception: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training resnet for 0.075% of train size (aka 6261 images) with pretrained: True and onlyLastLayersTrained: True...\n",
      "\n",
      "Total: 178 trainable: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/126 [>.............................] - ETA: 47s - loss: 1.3838 - accuracy: 0.3539WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0606s vs `on_train_batch_begin` time: 0.1255s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0606s vs `on_train_batch_end` time: 0.1510s). Check your callbacks.\n",
      "126/126 [==============================] - 14s 80ms/step - loss: 1.3847 - accuracy: 0.3095 - val_loss: 1.3915 - val_accuracy: 0.1875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "126/126 [==============================] - 7s 56ms/step - loss: 1.3849 - accuracy: 0.3004 - val_loss: 1.3915 - val_accuracy: 0.1875\n",
      "Epoch 3/30\n",
      "126/126 [==============================] - 7s 56ms/step - loss: 1.3847 - accuracy: 0.3048 - val_loss: 1.3915 - val_accuracy: 0.1875\n",
      "Epoch 4/30\n",
      "126/126 [==============================] - 7s 57ms/step - loss: 1.3847 - accuracy: 0.3118 - val_loss: 1.3915 - val_accuracy: 0.1875\n",
      "Epoch 5/30\n",
      "126/126 [==============================] - 7s 56ms/step - loss: 1.3846 - accuracy: 0.3053 - val_loss: 1.3915 - val_accuracy: 0.1875\n",
      "Epoch 6/30\n",
      "126/126 [==============================] - 7s 56ms/step - loss: 1.3853 - accuracy: 0.2896 - val_loss: 1.3915 - val_accuracy: 0.1875\n",
      "Epoch 7/30\n",
      "126/126 [==============================] - 7s 57ms/step - loss: 1.3846 - accuracy: 0.3121 - val_loss: 1.3915 - val_accuracy: 0.1875\n",
      "Epoch 8/30\n",
      "126/126 [==============================] - 7s 57ms/step - loss: 1.3845 - accuracy: 0.3136 - val_loss: 1.3915 - val_accuracy: 0.1875\n",
      "Epoch 9/30\n",
      "126/126 [==============================] - 7s 57ms/step - loss: 1.3847 - accuracy: 0.3049 - val_loss: 1.3915 - val_accuracy: 0.1875\n",
      "Epoch 10/30\n",
      "126/126 [==============================] - 7s 57ms/step - loss: 1.3850 - accuracy: 0.2990 - val_loss: 1.3915 - val_accuracy: 0.1875\n",
      "Epoch 11/30\n",
      "126/126 [==============================] - 7s 57ms/step - loss: 1.3846 - accuracy: 0.3074 - val_loss: 1.3915 - val_accuracy: 0.1875\n",
      "Epoch 12/30\n",
      "126/126 [==============================] - 7s 57ms/step - loss: 1.3845 - accuracy: 0.3003 - val_loss: 1.3915 - val_accuracy: 0.1875\n",
      "Epoch 13/30\n",
      "126/126 [==============================] - 7s 57ms/step - loss: 1.3847 - accuracy: 0.3089 - val_loss: 1.3915 - val_accuracy: 0.1875\n",
      "Epoch 14/30\n",
      "126/126 [==============================] - 7s 57ms/step - loss: 1.3848 - accuracy: 0.3014 - val_loss: 1.3915 - val_accuracy: 0.1875\n",
      "Epoch 15/30\n",
      "126/126 [==============================] - 7s 57ms/step - loss: 1.3848 - accuracy: 0.3023 - val_loss: 1.3915 - val_accuracy: 0.1875\n",
      "Epoch 16/30\n",
      "126/126 [==============================] - 7s 57ms/step - loss: 1.3846 - accuracy: 0.3070 - val_loss: 1.3915 - val_accuracy: 0.1875\n",
      "Epoch 17/30\n",
      "126/126 [==============================] - 7s 57ms/step - loss: 1.3845 - accuracy: 0.3043 - val_loss: 1.3915 - val_accuracy: 0.1875\n",
      "Epoch 18/30\n",
      "126/126 [==============================] - 7s 57ms/step - loss: 1.3846 - accuracy: 0.3134 - val_loss: 1.3915 - val_accuracy: 0.1875\n",
      "Epoch 19/30\n",
      "126/126 [==============================] - 7s 57ms/step - loss: 1.3846 - accuracy: 0.3058 - val_loss: 1.3915 - val_accuracy: 0.1875\n",
      "Epoch 20/30\n",
      "126/126 [==============================] - 7s 57ms/step - loss: 1.3845 - accuracy: 0.3090 - val_loss: 1.3915 - val_accuracy: 0.1875\n",
      "Epoch 21/30\n",
      "126/126 [==============================] - 7s 57ms/step - loss: 1.3849 - accuracy: 0.3092 - val_loss: 1.3915 - val_accuracy: 0.1875\n",
      "Epoch 22/30\n",
      "126/126 [==============================] - 7s 57ms/step - loss: 1.3847 - accuracy: 0.3063 - val_loss: 1.3915 - val_accuracy: 0.1875\n",
      "Epoch 23/30\n",
      "126/126 [==============================] - 7s 57ms/step - loss: 1.3849 - accuracy: 0.3037 - val_loss: 1.3915 - val_accuracy: 0.1875\n",
      "Epoch 24/30\n",
      "126/126 [==============================] - 7s 56ms/step - loss: 1.3848 - accuracy: 0.2973 - val_loss: 1.3915 - val_accuracy: 0.1875\n",
      "Epoch 25/30\n",
      "126/126 [==============================] - 7s 57ms/step - loss: 1.3843 - accuracy: 0.3092 - val_loss: 1.3915 - val_accuracy: 0.1875\n",
      "Epoch 26/30\n",
      "126/126 [==============================] - 7s 57ms/step - loss: 1.3847 - accuracy: 0.2998 - val_loss: 1.3915 - val_accuracy: 0.1875\n",
      "Epoch 27/30\n",
      "126/126 [==============================] - 7s 57ms/step - loss: 1.3844 - accuracy: 0.3071 - val_loss: 1.3915 - val_accuracy: 0.1875\n",
      "Epoch 28/30\n",
      "126/126 [==============================] - 7s 57ms/step - loss: 1.3848 - accuracy: 0.3039 - val_loss: 1.3915 - val_accuracy: 0.1875\n",
      "Epoch 29/30\n",
      "126/126 [==============================] - 7s 57ms/step - loss: 1.3847 - accuracy: 0.3109 - val_loss: 1.3915 - val_accuracy: 0.1875\n",
      "Epoch 30/30\n",
      "126/126 [==============================] - 7s 57ms/step - loss: 1.3848 - accuracy: 0.3048 - val_loss: 1.3915 - val_accuracy: 0.1875\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_6261.3_images_False_newWeights_True_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.269628\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training opticnet for 0.075% of train size (aka 6261 images) with pretrained: True and onlyLastLayersTrained: True...\n",
      "\n",
      "Total: 276 trainable: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "126/126 [==============================] - 46s 321ms/step - loss: 286.1259 - accuracy: 0.1455 - val_loss: 217.3077 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "126/126 [==============================] - 36s 287ms/step - loss: 287.9319 - accuracy: 0.1352 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "126/126 [==============================] - 36s 287ms/step - loss: 284.0319 - accuracy: 0.1421 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "126/126 [==============================] - 36s 288ms/step - loss: 292.9916 - accuracy: 0.1350 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "126/126 [==============================] - 36s 288ms/step - loss: 287.9657 - accuracy: 0.1391 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "126/126 [==============================] - 36s 287ms/step - loss: 289.4676 - accuracy: 0.1394 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "126/126 [==============================] - 36s 287ms/step - loss: 287.8115 - accuracy: 0.1357 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "126/126 [==============================] - 36s 287ms/step - loss: 290.0661 - accuracy: 0.1377 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "126/126 [==============================] - 36s 287ms/step - loss: 288.2670 - accuracy: 0.1371 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "126/126 [==============================] - 36s 287ms/step - loss: 289.8552 - accuracy: 0.1360 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "126/126 [==============================] - 36s 288ms/step - loss: 283.6251 - accuracy: 0.1503 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "126/126 [==============================] - 36s 287ms/step - loss: 288.4209 - accuracy: 0.1387 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "126/126 [==============================] - 36s 288ms/step - loss: 286.2334 - accuracy: 0.1337 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "126/126 [==============================] - 36s 288ms/step - loss: 289.7504 - accuracy: 0.1388 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "126/126 [==============================] - 36s 288ms/step - loss: 288.2685 - accuracy: 0.1277 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "126/126 [==============================] - 36s 288ms/step - loss: 292.3465 - accuracy: 0.1320 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "126/126 [==============================] - 36s 288ms/step - loss: 291.0818 - accuracy: 0.1399 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "126/126 [==============================] - 36s 288ms/step - loss: 288.3876 - accuracy: 0.1374 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "126/126 [==============================] - 36s 288ms/step - loss: 288.9862 - accuracy: 0.1354 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "126/126 [==============================] - 36s 288ms/step - loss: 286.9228 - accuracy: 0.1392 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "126/126 [==============================] - 36s 288ms/step - loss: 288.6313 - accuracy: 0.1354 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "126/126 [==============================] - 36s 288ms/step - loss: 287.2693 - accuracy: 0.1406 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "126/126 [==============================] - 36s 288ms/step - loss: 284.7985 - accuracy: 0.1388 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "126/126 [==============================] - 36s 288ms/step - loss: 287.0883 - accuracy: 0.1387 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "126/126 [==============================] - 36s 288ms/step - loss: 285.7146 - accuracy: 0.1398 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "126/126 [==============================] - 36s 288ms/step - loss: 286.2148 - accuracy: 0.1443 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "126/126 [==============================] - 36s 288ms/step - loss: 288.1419 - accuracy: 0.1389 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "126/126 [==============================] - 36s 288ms/step - loss: 287.3248 - accuracy: 0.1354 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "126/126 [==============================] - 36s 287ms/step - loss: 291.2990 - accuracy: 0.1367 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "126/126 [==============================] - 36s 287ms/step - loss: 284.9775 - accuracy: 0.1389 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../opticnet/opticnet_30epochs_6261.3_images_False_newWeights_True_lastLayerOnly_rescale-symmetric_normalization/assets\n",
      "Test acc for opticnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.08835265 0.09025669 0.09111738 0.09238626]\n",
      "Training xception for 0.09% of train size (aka 7513 images) with pretrained: True and onlyLastLayersTrained: True...\n",
      "\n",
      "Total: 135 trainable: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/151 [>.............................] - ETA: 1:11 - loss: 1.3992 - accuracy: 0.1262WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1172s vs `on_train_batch_begin` time: 0.1297s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1172s vs `on_train_batch_end` time: 0.1855s). Check your callbacks.\n",
      "151/151 [==============================] - 24s 140ms/step - loss: 1.3969 - accuracy: 0.1498 - val_loss: 1.3899 - val_accuracy: 0.2188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "151/151 [==============================] - 18s 120ms/step - loss: 1.3960 - accuracy: 0.1585 - val_loss: 1.3899 - val_accuracy: 0.2188\n",
      "Epoch 3/30\n",
      "151/151 [==============================] - 18s 122ms/step - loss: 1.3962 - accuracy: 0.1553 - val_loss: 1.3899 - val_accuracy: 0.2188\n",
      "Epoch 4/30\n",
      "151/151 [==============================] - 18s 122ms/step - loss: 1.3970 - accuracy: 0.1473 - val_loss: 1.3899 - val_accuracy: 0.2188\n",
      "Epoch 5/30\n",
      "151/151 [==============================] - 19s 123ms/step - loss: 1.3973 - accuracy: 0.1496 - val_loss: 1.3899 - val_accuracy: 0.2188\n",
      "Epoch 6/30\n",
      "151/151 [==============================] - 19s 123ms/step - loss: 1.3958 - accuracy: 0.1570 - val_loss: 1.3899 - val_accuracy: 0.2188\n",
      "Epoch 7/30\n",
      "151/151 [==============================] - 19s 123ms/step - loss: 1.3976 - accuracy: 0.1438 - val_loss: 1.3899 - val_accuracy: 0.2188\n",
      "Epoch 8/30\n",
      "151/151 [==============================] - 19s 122ms/step - loss: 1.3967 - accuracy: 0.1556 - val_loss: 1.3899 - val_accuracy: 0.2188\n",
      "Epoch 9/30\n",
      "151/151 [==============================] - 19s 123ms/step - loss: 1.3965 - accuracy: 0.1546 - val_loss: 1.3899 - val_accuracy: 0.2188\n",
      "Epoch 10/30\n",
      "151/151 [==============================] - 18s 122ms/step - loss: 1.3960 - accuracy: 0.1565 - val_loss: 1.3899 - val_accuracy: 0.2188\n",
      "Epoch 11/30\n",
      "151/151 [==============================] - 19s 123ms/step - loss: 1.3960 - accuracy: 0.1618 - val_loss: 1.3899 - val_accuracy: 0.2188\n",
      "Epoch 12/30\n",
      "151/151 [==============================] - 18s 122ms/step - loss: 1.3954 - accuracy: 0.1678 - val_loss: 1.3899 - val_accuracy: 0.2188\n",
      "Epoch 13/30\n",
      "151/151 [==============================] - 19s 123ms/step - loss: 1.3964 - accuracy: 0.1521 - val_loss: 1.3899 - val_accuracy: 0.2188\n",
      "Epoch 14/30\n",
      "151/151 [==============================] - 19s 123ms/step - loss: 1.3967 - accuracy: 0.1538 - val_loss: 1.3899 - val_accuracy: 0.2188\n",
      "Epoch 15/30\n",
      "151/151 [==============================] - 19s 123ms/step - loss: 1.3966 - accuracy: 0.1577 - val_loss: 1.3899 - val_accuracy: 0.2188\n",
      "Epoch 16/30\n",
      "151/151 [==============================] - 19s 123ms/step - loss: 1.3958 - accuracy: 0.1552 - val_loss: 1.3899 - val_accuracy: 0.2188\n",
      "Epoch 17/30\n",
      "151/151 [==============================] - 19s 123ms/step - loss: 1.3967 - accuracy: 0.1542 - val_loss: 1.3899 - val_accuracy: 0.2188\n",
      "Epoch 18/30\n",
      "151/151 [==============================] - 18s 122ms/step - loss: 1.3961 - accuracy: 0.1584 - val_loss: 1.3899 - val_accuracy: 0.2188\n",
      "Epoch 19/30\n",
      "151/151 [==============================] - 18s 122ms/step - loss: 1.3970 - accuracy: 0.1537 - val_loss: 1.3899 - val_accuracy: 0.2188\n",
      "Epoch 20/30\n",
      "151/151 [==============================] - 18s 122ms/step - loss: 1.3973 - accuracy: 0.1455 - val_loss: 1.3899 - val_accuracy: 0.2188\n",
      "Epoch 21/30\n",
      "151/151 [==============================] - 18s 122ms/step - loss: 1.3969 - accuracy: 0.1520 - val_loss: 1.3899 - val_accuracy: 0.2188\n",
      "Epoch 22/30\n",
      "151/151 [==============================] - 18s 122ms/step - loss: 1.3963 - accuracy: 0.1527 - val_loss: 1.3899 - val_accuracy: 0.2188\n",
      "Epoch 23/30\n",
      "151/151 [==============================] - 18s 122ms/step - loss: 1.3965 - accuracy: 0.1527 - val_loss: 1.3899 - val_accuracy: 0.2188\n",
      "Epoch 24/30\n",
      "151/151 [==============================] - 18s 122ms/step - loss: 1.3969 - accuracy: 0.1549 - val_loss: 1.3899 - val_accuracy: 0.2188\n",
      "Epoch 25/30\n",
      "151/151 [==============================] - 19s 123ms/step - loss: 1.3969 - accuracy: 0.1512 - val_loss: 1.3899 - val_accuracy: 0.2188\n",
      "Epoch 26/30\n",
      "151/151 [==============================] - 18s 122ms/step - loss: 1.3961 - accuracy: 0.1623 - val_loss: 1.3899 - val_accuracy: 0.2188\n",
      "Epoch 27/30\n",
      "151/151 [==============================] - 18s 122ms/step - loss: 1.3971 - accuracy: 0.1474 - val_loss: 1.3899 - val_accuracy: 0.2188\n",
      "Epoch 28/30\n",
      "151/151 [==============================] - 19s 123ms/step - loss: 1.3970 - accuracy: 0.1530 - val_loss: 1.3899 - val_accuracy: 0.2188\n",
      "Epoch 29/30\n",
      "151/151 [==============================] - 19s 123ms/step - loss: 1.3961 - accuracy: 0.1616 - val_loss: 1.3899 - val_accuracy: 0.2188\n",
      "Epoch 30/30\n",
      "151/151 [==============================] - 18s 122ms/step - loss: 1.3968 - accuracy: 0.1494 - val_loss: 1.3899 - val_accuracy: 0.2188\n",
      "INFO:tensorflow:Assets written to: ../xception/xception_30epochs_7513.5599999999995_images_False_newWeights_True_lastLayerOnly_rescale-symmetric_normalization/assets\n",
      "Test acc for xception: 0.241736\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training resnet for 0.09% of train size (aka 7513 images) with pretrained: True and onlyLastLayersTrained: True...\n",
      "\n",
      "Total: 178 trainable: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/151 [>.............................] - ETA: 56s - loss: 1.3905 - accuracy: 0.2203 WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0581s vs `on_train_batch_begin` time: 0.1270s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0581s vs `on_train_batch_end` time: 0.1508s). Check your callbacks.\n",
      "151/151 [==============================] - 15s 76ms/step - loss: 1.3892 - accuracy: 0.2648 - val_loss: 1.3874 - val_accuracy: 0.2812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "151/151 [==============================] - 9s 56ms/step - loss: 1.3892 - accuracy: 0.2661 - val_loss: 1.3874 - val_accuracy: 0.2812\n",
      "Epoch 3/30\n",
      "151/151 [==============================] - 8s 56ms/step - loss: 1.3892 - accuracy: 0.2669 - val_loss: 1.3874 - val_accuracy: 0.2812\n",
      "Epoch 4/30\n",
      "151/151 [==============================] - 9s 56ms/step - loss: 1.3889 - accuracy: 0.2722 - val_loss: 1.3874 - val_accuracy: 0.2812\n",
      "Epoch 5/30\n",
      "151/151 [==============================] - 9s 56ms/step - loss: 1.3890 - accuracy: 0.2699 - val_loss: 1.3874 - val_accuracy: 0.2812\n",
      "Epoch 6/30\n",
      "151/151 [==============================] - 9s 57ms/step - loss: 1.3894 - accuracy: 0.2635 - val_loss: 1.3874 - val_accuracy: 0.2812\n",
      "Epoch 7/30\n",
      "151/151 [==============================] - 9s 57ms/step - loss: 1.3892 - accuracy: 0.2615 - val_loss: 1.3874 - val_accuracy: 0.2812\n",
      "Epoch 8/30\n",
      "151/151 [==============================] - 9s 57ms/step - loss: 1.3891 - accuracy: 0.2713 - val_loss: 1.3874 - val_accuracy: 0.2812\n",
      "Epoch 9/30\n",
      "151/151 [==============================] - 9s 57ms/step - loss: 1.3887 - accuracy: 0.2730 - val_loss: 1.3874 - val_accuracy: 0.2812\n",
      "Epoch 10/30\n",
      "151/151 [==============================] - 9s 57ms/step - loss: 1.3887 - accuracy: 0.2799 - val_loss: 1.3874 - val_accuracy: 0.2812\n",
      "Epoch 11/30\n",
      "151/151 [==============================] - 9s 57ms/step - loss: 1.3888 - accuracy: 0.2793 - val_loss: 1.3874 - val_accuracy: 0.2812\n",
      "Epoch 12/30\n",
      "151/151 [==============================] - 8s 56ms/step - loss: 1.3891 - accuracy: 0.2697 - val_loss: 1.3874 - val_accuracy: 0.2812\n",
      "Epoch 13/30\n",
      "151/151 [==============================] - 9s 57ms/step - loss: 1.3890 - accuracy: 0.2745 - val_loss: 1.3874 - val_accuracy: 0.2812\n",
      "Epoch 14/30\n",
      "151/151 [==============================] - 9s 57ms/step - loss: 1.3891 - accuracy: 0.2768 - val_loss: 1.3874 - val_accuracy: 0.2812\n",
      "Epoch 15/30\n",
      "151/151 [==============================] - 9s 57ms/step - loss: 1.3896 - accuracy: 0.2653 - val_loss: 1.3874 - val_accuracy: 0.2812\n",
      "Epoch 16/30\n",
      "151/151 [==============================] - 9s 57ms/step - loss: 1.3892 - accuracy: 0.2657 - val_loss: 1.3874 - val_accuracy: 0.2812\n",
      "Epoch 17/30\n",
      "151/151 [==============================] - 9s 57ms/step - loss: 1.3893 - accuracy: 0.2597 - val_loss: 1.3874 - val_accuracy: 0.2812\n",
      "Epoch 18/30\n",
      "151/151 [==============================] - 9s 57ms/step - loss: 1.3889 - accuracy: 0.2745 - val_loss: 1.3874 - val_accuracy: 0.2812\n",
      "Epoch 19/30\n",
      "151/151 [==============================] - 9s 57ms/step - loss: 1.3891 - accuracy: 0.2737 - val_loss: 1.3874 - val_accuracy: 0.2812\n",
      "Epoch 20/30\n",
      "151/151 [==============================] - 9s 57ms/step - loss: 1.3889 - accuracy: 0.2678 - val_loss: 1.3874 - val_accuracy: 0.2812\n",
      "Epoch 21/30\n",
      "151/151 [==============================] - 9s 57ms/step - loss: 1.3890 - accuracy: 0.2738 - val_loss: 1.3874 - val_accuracy: 0.2812\n",
      "Epoch 22/30\n",
      "151/151 [==============================] - 9s 57ms/step - loss: 1.3889 - accuracy: 0.2788 - val_loss: 1.3874 - val_accuracy: 0.2812\n",
      "Epoch 23/30\n",
      "151/151 [==============================] - 9s 57ms/step - loss: 1.3892 - accuracy: 0.2688 - val_loss: 1.3874 - val_accuracy: 0.2812\n",
      "Epoch 24/30\n",
      "151/151 [==============================] - 9s 57ms/step - loss: 1.3891 - accuracy: 0.2742 - val_loss: 1.3874 - val_accuracy: 0.2812\n",
      "Epoch 25/30\n",
      "151/151 [==============================] - 9s 57ms/step - loss: 1.3892 - accuracy: 0.2652 - val_loss: 1.3874 - val_accuracy: 0.2812\n",
      "Epoch 26/30\n",
      "151/151 [==============================] - 9s 57ms/step - loss: 1.3894 - accuracy: 0.2682 - val_loss: 1.3874 - val_accuracy: 0.2812\n",
      "Epoch 27/30\n",
      "151/151 [==============================] - 9s 57ms/step - loss: 1.3887 - accuracy: 0.2726 - val_loss: 1.3874 - val_accuracy: 0.2812\n",
      "Epoch 28/30\n",
      "151/151 [==============================] - 9s 57ms/step - loss: 1.3894 - accuracy: 0.2701 - val_loss: 1.3874 - val_accuracy: 0.2812\n",
      "Epoch 29/30\n",
      "151/151 [==============================] - 9s 57ms/step - loss: 1.3892 - accuracy: 0.2667 - val_loss: 1.3874 - val_accuracy: 0.2812\n",
      "Epoch 30/30\n",
      "151/151 [==============================] - 9s 57ms/step - loss: 1.3889 - accuracy: 0.2707 - val_loss: 1.3874 - val_accuracy: 0.2812\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_7513.5599999999995_images_False_newWeights_True_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.303719\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training opticnet for 0.09% of train size (aka 7513 images) with pretrained: True and onlyLastLayersTrained: True...\n",
      "\n",
      "Total: 276 trainable: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "151/151 [==============================] - 54s 316ms/step - loss: 288.0681 - accuracy: 0.1423 - val_loss: 217.3077 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "151/151 [==============================] - 43s 288ms/step - loss: 285.7535 - accuracy: 0.1381 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "151/151 [==============================] - 43s 288ms/step - loss: 289.9222 - accuracy: 0.1367 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "151/151 [==============================] - 44s 288ms/step - loss: 293.0866 - accuracy: 0.1315 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "151/151 [==============================] - 44s 288ms/step - loss: 286.8756 - accuracy: 0.1399 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "151/151 [==============================] - 44s 288ms/step - loss: 288.7617 - accuracy: 0.1335 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "151/151 [==============================] - 43s 288ms/step - loss: 286.6999 - accuracy: 0.1385 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "151/151 [==============================] - 44s 288ms/step - loss: 288.1095 - accuracy: 0.1365 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "151/151 [==============================] - 44s 288ms/step - loss: 287.8014 - accuracy: 0.1351 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "151/151 [==============================] - 43s 288ms/step - loss: 290.9649 - accuracy: 0.1335 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "151/151 [==============================] - 44s 288ms/step - loss: 286.8448 - accuracy: 0.1399 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "151/151 [==============================] - 44s 289ms/step - loss: 289.4921 - accuracy: 0.1374 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "151/151 [==============================] - 44s 288ms/step - loss: 288.7890 - accuracy: 0.1348 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "151/151 [==============================] - 44s 289ms/step - loss: 288.9929 - accuracy: 0.1329 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "151/151 [==============================] - 44s 288ms/step - loss: 284.2739 - accuracy: 0.1394 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "151/151 [==============================] - 44s 288ms/step - loss: 288.4770 - accuracy: 0.1395 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "151/151 [==============================] - 43s 288ms/step - loss: 285.0783 - accuracy: 0.1395 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "151/151 [==============================] - 43s 288ms/step - loss: 290.6886 - accuracy: 0.1410 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "151/151 [==============================] - 44s 288ms/step - loss: 288.9239 - accuracy: 0.1407 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "151/151 [==============================] - 43s 288ms/step - loss: 287.7697 - accuracy: 0.1386 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "151/151 [==============================] - 44s 289ms/step - loss: 291.1431 - accuracy: 0.1346 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "151/151 [==============================] - 44s 289ms/step - loss: 290.8102 - accuracy: 0.1356 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "151/151 [==============================] - 44s 288ms/step - loss: 290.2608 - accuracy: 0.1313 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "151/151 [==============================] - 43s 288ms/step - loss: 287.6581 - accuracy: 0.1390 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "151/151 [==============================] - 43s 288ms/step - loss: 288.3130 - accuracy: 0.1393 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "151/151 [==============================] - 44s 288ms/step - loss: 286.8733 - accuracy: 0.1371 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "151/151 [==============================] - 44s 288ms/step - loss: 288.4575 - accuracy: 0.1415 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "151/151 [==============================] - 44s 288ms/step - loss: 286.4601 - accuracy: 0.1394 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "151/151 [==============================] - 44s 288ms/step - loss: 290.6366 - accuracy: 0.1337 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "151/151 [==============================] - 43s 288ms/step - loss: 285.4029 - accuracy: 0.1390 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../opticnet/opticnet_30epochs_7513.5599999999995_images_False_newWeights_True_lastLayerOnly_rescale-symmetric_normalization/assets\n",
      "Test acc for opticnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.09777693 0.10020159 0.10133944 0.10410864]\n",
      "Training xception for 0.1% of train size (aka 8348 images) with pretrained: True and onlyLastLayersTrained: True...\n",
      "\n",
      "Total: 135 trainable: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/167 [>.............................] - ETA: 1:18 - loss: 1.3789 - accuracy: 0.3471WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1173s vs `on_train_batch_begin` time: 0.1257s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1173s vs `on_train_batch_end` time: 0.1836s). Check your callbacks.\n",
      "167/167 [==============================] - 26s 137ms/step - loss: 1.3822 - accuracy: 0.2939 - val_loss: 1.3866 - val_accuracy: 0.2812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "167/167 [==============================] - 20s 121ms/step - loss: 1.3827 - accuracy: 0.2917 - val_loss: 1.3866 - val_accuracy: 0.2812\n",
      "Epoch 3/30\n",
      "167/167 [==============================] - 20s 122ms/step - loss: 1.3826 - accuracy: 0.2861 - val_loss: 1.3866 - val_accuracy: 0.2812\n",
      "Epoch 4/30\n",
      "167/167 [==============================] - 21s 123ms/step - loss: 1.3818 - accuracy: 0.3032 - val_loss: 1.3866 - val_accuracy: 0.2812\n",
      "Epoch 5/30\n",
      "167/167 [==============================] - 20s 123ms/step - loss: 1.3824 - accuracy: 0.2887 - val_loss: 1.3866 - val_accuracy: 0.2812\n",
      "Epoch 6/30\n",
      "167/167 [==============================] - 21s 123ms/step - loss: 1.3825 - accuracy: 0.2823 - val_loss: 1.3866 - val_accuracy: 0.2812\n",
      "Epoch 7/30\n",
      "167/167 [==============================] - 20s 123ms/step - loss: 1.3828 - accuracy: 0.2900 - val_loss: 1.3866 - val_accuracy: 0.2812\n",
      "Epoch 8/30\n",
      "167/167 [==============================] - 21s 123ms/step - loss: 1.3821 - accuracy: 0.2912 - val_loss: 1.3866 - val_accuracy: 0.2812\n",
      "Epoch 9/30\n",
      "167/167 [==============================] - 20s 123ms/step - loss: 1.3826 - accuracy: 0.2840 - val_loss: 1.3866 - val_accuracy: 0.2812\n",
      "Epoch 10/30\n",
      "167/167 [==============================] - 21s 123ms/step - loss: 1.3831 - accuracy: 0.2849 - val_loss: 1.3866 - val_accuracy: 0.2812\n",
      "Epoch 11/30\n",
      "167/167 [==============================] - 20s 123ms/step - loss: 1.3824 - accuracy: 0.2990 - val_loss: 1.3866 - val_accuracy: 0.2812\n",
      "Epoch 12/30\n",
      "167/167 [==============================] - 21s 123ms/step - loss: 1.3818 - accuracy: 0.3000 - val_loss: 1.3866 - val_accuracy: 0.2812\n",
      "Epoch 13/30\n",
      "167/167 [==============================] - 21s 123ms/step - loss: 1.3826 - accuracy: 0.2900 - val_loss: 1.3866 - val_accuracy: 0.2812\n",
      "Epoch 14/30\n",
      "167/167 [==============================] - 21s 123ms/step - loss: 1.3820 - accuracy: 0.2942 - val_loss: 1.3866 - val_accuracy: 0.2812\n",
      "Epoch 15/30\n",
      "167/167 [==============================] - 21s 123ms/step - loss: 1.3827 - accuracy: 0.2868 - val_loss: 1.3866 - val_accuracy: 0.2812\n",
      "Epoch 16/30\n",
      "167/167 [==============================] - 21s 123ms/step - loss: 1.3822 - accuracy: 0.2960 - val_loss: 1.3866 - val_accuracy: 0.2812\n",
      "Epoch 17/30\n",
      "167/167 [==============================] - 21s 123ms/step - loss: 1.3828 - accuracy: 0.2901 - val_loss: 1.3866 - val_accuracy: 0.2812\n",
      "Epoch 18/30\n",
      "167/167 [==============================] - 21s 123ms/step - loss: 1.3821 - accuracy: 0.2907 - val_loss: 1.3866 - val_accuracy: 0.2812\n",
      "Epoch 19/30\n",
      "167/167 [==============================] - 21s 123ms/step - loss: 1.3829 - accuracy: 0.2829 - val_loss: 1.3866 - val_accuracy: 0.2812\n",
      "Epoch 20/30\n",
      "167/167 [==============================] - 21s 123ms/step - loss: 1.3818 - accuracy: 0.2930 - val_loss: 1.3866 - val_accuracy: 0.2812\n",
      "Epoch 21/30\n",
      "167/167 [==============================] - 21s 123ms/step - loss: 1.3827 - accuracy: 0.2841 - val_loss: 1.3866 - val_accuracy: 0.2812\n",
      "Epoch 22/30\n",
      "167/167 [==============================] - 21s 123ms/step - loss: 1.3825 - accuracy: 0.2877 - val_loss: 1.3866 - val_accuracy: 0.2812\n",
      "Epoch 23/30\n",
      "167/167 [==============================] - 20s 122ms/step - loss: 1.3824 - accuracy: 0.2953 - val_loss: 1.3866 - val_accuracy: 0.2812\n",
      "Epoch 24/30\n",
      "167/167 [==============================] - 21s 123ms/step - loss: 1.3829 - accuracy: 0.2860 - val_loss: 1.3866 - val_accuracy: 0.2812\n",
      "Epoch 25/30\n",
      "167/167 [==============================] - 21s 123ms/step - loss: 1.3823 - accuracy: 0.2947 - val_loss: 1.3866 - val_accuracy: 0.2812\n",
      "Epoch 26/30\n",
      "167/167 [==============================] - 21s 123ms/step - loss: 1.3823 - accuracy: 0.2935 - val_loss: 1.3866 - val_accuracy: 0.2812\n",
      "Epoch 27/30\n",
      "167/167 [==============================] - 20s 123ms/step - loss: 1.3829 - accuracy: 0.2850 - val_loss: 1.3866 - val_accuracy: 0.2812\n",
      "Epoch 28/30\n",
      "167/167 [==============================] - 21s 123ms/step - loss: 1.3825 - accuracy: 0.2965 - val_loss: 1.3866 - val_accuracy: 0.2812\n",
      "Epoch 29/30\n",
      "167/167 [==============================] - 21s 123ms/step - loss: 1.3827 - accuracy: 0.2895 - val_loss: 1.3866 - val_accuracy: 0.2812\n",
      "Epoch 30/30\n",
      "167/167 [==============================] - 20s 123ms/step - loss: 1.3826 - accuracy: 0.2910 - val_loss: 1.3866 - val_accuracy: 0.2812\n",
      "INFO:tensorflow:Assets written to: ../xception/xception_30epochs_8348.4_images_False_newWeights_True_lastLayerOnly_rescale-symmetric_normalization/assets\n",
      "Test acc for xception: 0.253099\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training resnet for 0.1% of train size (aka 8348 images) with pretrained: True and onlyLastLayersTrained: True...\n",
      "\n",
      "Total: 178 trainable: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/167 [>.............................] - ETA: 1:02 - loss: 1.3848 - accuracy: 0.2874WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0597s vs `on_train_batch_begin` time: 0.1245s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0597s vs `on_train_batch_end` time: 0.1471s). Check your callbacks.\n",
      "167/167 [==============================] - 16s 74ms/step - loss: 1.3845 - accuracy: 0.2746 - val_loss: 1.3836 - val_accuracy: 0.2812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "167/167 [==============================] - 9s 56ms/step - loss: 1.3846 - accuracy: 0.2802 - val_loss: 1.3836 - val_accuracy: 0.2812\n",
      "Epoch 3/30\n",
      "167/167 [==============================] - 9s 56ms/step - loss: 1.3843 - accuracy: 0.2822 - val_loss: 1.3836 - val_accuracy: 0.2812\n",
      "Epoch 4/30\n",
      "167/167 [==============================] - 9s 57ms/step - loss: 1.3846 - accuracy: 0.2824 - val_loss: 1.3836 - val_accuracy: 0.2812\n",
      "Epoch 5/30\n",
      "167/167 [==============================] - 9s 57ms/step - loss: 1.3844 - accuracy: 0.2838 - val_loss: 1.3836 - val_accuracy: 0.2812\n",
      "Epoch 6/30\n",
      "167/167 [==============================] - 9s 57ms/step - loss: 1.3845 - accuracy: 0.2830 - val_loss: 1.3836 - val_accuracy: 0.2812\n",
      "Epoch 7/30\n",
      "167/167 [==============================] - 9s 57ms/step - loss: 1.3843 - accuracy: 0.2848 - val_loss: 1.3836 - val_accuracy: 0.2812\n",
      "Epoch 8/30\n",
      "167/167 [==============================] - 9s 57ms/step - loss: 1.3846 - accuracy: 0.2866 - val_loss: 1.3836 - val_accuracy: 0.2812\n",
      "Epoch 9/30\n",
      "167/167 [==============================] - 10s 57ms/step - loss: 1.3844 - accuracy: 0.2844 - val_loss: 1.3836 - val_accuracy: 0.2812\n",
      "Epoch 10/30\n",
      "167/167 [==============================] - 9s 57ms/step - loss: 1.3846 - accuracy: 0.2855 - val_loss: 1.3836 - val_accuracy: 0.2812\n",
      "Epoch 11/30\n",
      "167/167 [==============================] - 10s 57ms/step - loss: 1.3843 - accuracy: 0.2859 - val_loss: 1.3836 - val_accuracy: 0.2812\n",
      "Epoch 12/30\n",
      "167/167 [==============================] - 10s 57ms/step - loss: 1.3849 - accuracy: 0.2760 - val_loss: 1.3836 - val_accuracy: 0.2812\n",
      "Epoch 13/30\n",
      "167/167 [==============================] - 10s 57ms/step - loss: 1.3846 - accuracy: 0.2786 - val_loss: 1.3836 - val_accuracy: 0.2812\n",
      "Epoch 14/30\n",
      "167/167 [==============================] - 10s 57ms/step - loss: 1.3842 - accuracy: 0.2814 - val_loss: 1.3836 - val_accuracy: 0.2812\n",
      "Epoch 15/30\n",
      "167/167 [==============================] - 10s 57ms/step - loss: 1.3847 - accuracy: 0.2773 - val_loss: 1.3836 - val_accuracy: 0.2812\n",
      "Epoch 16/30\n",
      "167/167 [==============================] - 10s 57ms/step - loss: 1.3844 - accuracy: 0.2826 - val_loss: 1.3836 - val_accuracy: 0.2812\n",
      "Epoch 17/30\n",
      "167/167 [==============================] - 9s 57ms/step - loss: 1.3846 - accuracy: 0.2740 - val_loss: 1.3836 - val_accuracy: 0.2812\n",
      "Epoch 18/30\n",
      "167/167 [==============================] - 10s 57ms/step - loss: 1.3845 - accuracy: 0.2819 - val_loss: 1.3836 - val_accuracy: 0.2812\n",
      "Epoch 19/30\n",
      "167/167 [==============================] - 9s 57ms/step - loss: 1.3845 - accuracy: 0.2769 - val_loss: 1.3836 - val_accuracy: 0.2812\n",
      "Epoch 20/30\n",
      "167/167 [==============================] - 10s 57ms/step - loss: 1.3848 - accuracy: 0.2747 - val_loss: 1.3836 - val_accuracy: 0.2812\n",
      "Epoch 21/30\n",
      "167/167 [==============================] - 9s 57ms/step - loss: 1.3847 - accuracy: 0.2777 - val_loss: 1.3836 - val_accuracy: 0.2812\n",
      "Epoch 22/30\n",
      "167/167 [==============================] - 10s 57ms/step - loss: 1.3844 - accuracy: 0.2798 - val_loss: 1.3836 - val_accuracy: 0.2812\n",
      "Epoch 23/30\n",
      "167/167 [==============================] - 10s 57ms/step - loss: 1.3848 - accuracy: 0.2798 - val_loss: 1.3836 - val_accuracy: 0.2812\n",
      "Epoch 24/30\n",
      "167/167 [==============================] - 10s 57ms/step - loss: 1.3847 - accuracy: 0.2801 - val_loss: 1.3836 - val_accuracy: 0.2812\n",
      "Epoch 25/30\n",
      "167/167 [==============================] - 10s 57ms/step - loss: 1.3844 - accuracy: 0.2828 - val_loss: 1.3836 - val_accuracy: 0.2812\n",
      "Epoch 26/30\n",
      "167/167 [==============================] - 10s 57ms/step - loss: 1.3845 - accuracy: 0.2846 - val_loss: 1.3836 - val_accuracy: 0.2812\n",
      "Epoch 27/30\n",
      "167/167 [==============================] - 10s 57ms/step - loss: 1.3848 - accuracy: 0.2758 - val_loss: 1.3836 - val_accuracy: 0.2812\n",
      "Epoch 28/30\n",
      "167/167 [==============================] - 10s 57ms/step - loss: 1.3844 - accuracy: 0.2828 - val_loss: 1.3836 - val_accuracy: 0.2812\n",
      "Epoch 29/30\n",
      "167/167 [==============================] - 10s 57ms/step - loss: 1.3850 - accuracy: 0.2716 - val_loss: 1.3836 - val_accuracy: 0.2812\n",
      "Epoch 30/30\n",
      "167/167 [==============================] - 10s 57ms/step - loss: 1.3847 - accuracy: 0.2808 - val_loss: 1.3836 - val_accuracy: 0.2812\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_8348.4_images_False_newWeights_True_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.319215\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training opticnet for 0.1% of train size (aka 8348 images) with pretrained: True and onlyLastLayersTrained: True...\n",
      "\n",
      "Total: 276 trainable: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "167/167 [==============================] - 58s 312ms/step - loss: 286.4736 - accuracy: 0.1385 - val_loss: 217.3077 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "167/167 [==============================] - 48s 287ms/step - loss: 290.6371 - accuracy: 0.1348 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "167/167 [==============================] - 48s 288ms/step - loss: 289.8274 - accuracy: 0.1386 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "167/167 [==============================] - 48s 289ms/step - loss: 288.2693 - accuracy: 0.1377 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "167/167 [==============================] - 48s 289ms/step - loss: 288.2191 - accuracy: 0.1365 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "167/167 [==============================] - 48s 288ms/step - loss: 289.6643 - accuracy: 0.1399 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "167/167 [==============================] - 48s 288ms/step - loss: 285.6065 - accuracy: 0.1456 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "167/167 [==============================] - 48s 288ms/step - loss: 289.6596 - accuracy: 0.1282 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "167/167 [==============================] - 48s 289ms/step - loss: 288.4923 - accuracy: 0.1355 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "167/167 [==============================] - 48s 289ms/step - loss: 286.3867 - accuracy: 0.1424 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "167/167 [==============================] - 48s 289ms/step - loss: 287.7944 - accuracy: 0.1371 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "167/167 [==============================] - 48s 289ms/step - loss: 289.1649 - accuracy: 0.1393 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "167/167 [==============================] - 48s 289ms/step - loss: 285.1438 - accuracy: 0.1412 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "167/167 [==============================] - 48s 289ms/step - loss: 286.1586 - accuracy: 0.1383 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "167/167 [==============================] - 48s 289ms/step - loss: 286.0978 - accuracy: 0.1391 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "167/167 [==============================] - 48s 289ms/step - loss: 286.5736 - accuracy: 0.1466 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "167/167 [==============================] - 48s 289ms/step - loss: 284.7577 - accuracy: 0.1423 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "167/167 [==============================] - 48s 289ms/step - loss: 288.5207 - accuracy: 0.1406 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "167/167 [==============================] - 48s 289ms/step - loss: 287.0584 - accuracy: 0.1361 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "167/167 [==============================] - 48s 290ms/step - loss: 286.0907 - accuracy: 0.1463 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "167/167 [==============================] - 48s 289ms/step - loss: 287.3106 - accuracy: 0.1373 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "167/167 [==============================] - 48s 289ms/step - loss: 289.7853 - accuracy: 0.1410 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "167/167 [==============================] - 48s 289ms/step - loss: 286.7702 - accuracy: 0.1404 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "167/167 [==============================] - 48s 289ms/step - loss: 286.8131 - accuracy: 0.1403 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "167/167 [==============================] - 48s 289ms/step - loss: 286.0628 - accuracy: 0.1346 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "167/167 [==============================] - 48s 289ms/step - loss: 287.6322 - accuracy: 0.1429 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "167/167 [==============================] - 48s 289ms/step - loss: 290.0902 - accuracy: 0.1344 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "167/167 [==============================] - 48s 289ms/step - loss: 286.7834 - accuracy: 0.1394 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "167/167 [==============================] - 48s 288ms/step - loss: 285.8403 - accuracy: 0.1419 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "167/167 [==============================] - 48s 288ms/step - loss: 289.3117 - accuracy: 0.1318 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../opticnet/opticnet_30epochs_8348.4_images_False_newWeights_True_lastLayerOnly_rescale-symmetric_normalization/assets\n",
      "Test acc for opticnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.24943948 0.24918694 0.24735636 0.25870474]\n",
      "Training xception for 0.25% of train size (aka 20871 images) with pretrained: True and onlyLastLayersTrained: True...\n",
      "\n",
      "Total: 135 trainable: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/418 [..............................] - ETA: 3:27 - loss: 1.3819 - accuracy: 0.1427WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1169s vs `on_train_batch_begin` time: 0.1378s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1169s vs `on_train_batch_end` time: 0.1840s). Check your callbacks.\n",
      "418/418 [==============================] - 56s 127ms/step - loss: 1.3807 - accuracy: 0.1678 - val_loss: 1.3808 - val_accuracy: 0.2188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "418/418 [==============================] - 51s 122ms/step - loss: 1.3804 - accuracy: 0.1672 - val_loss: 1.3808 - val_accuracy: 0.2188\n",
      "Epoch 3/30\n",
      "418/418 [==============================] - 51s 122ms/step - loss: 1.3804 - accuracy: 0.1639 - val_loss: 1.3808 - val_accuracy: 0.2188\n",
      "Epoch 4/30\n",
      "418/418 [==============================] - 51s 122ms/step - loss: 1.3799 - accuracy: 0.1709 - val_loss: 1.3808 - val_accuracy: 0.2188\n",
      "Epoch 5/30\n",
      "418/418 [==============================] - 51s 122ms/step - loss: 1.3804 - accuracy: 0.1655 - val_loss: 1.3808 - val_accuracy: 0.2188\n",
      "Epoch 6/30\n",
      "418/418 [==============================] - 51s 122ms/step - loss: 1.3800 - accuracy: 0.1724 - val_loss: 1.3808 - val_accuracy: 0.2188\n",
      "Epoch 7/30\n",
      "418/418 [==============================] - 51s 123ms/step - loss: 1.3801 - accuracy: 0.1694 - val_loss: 1.3808 - val_accuracy: 0.2188\n",
      "Epoch 8/30\n",
      "418/418 [==============================] - 51s 123ms/step - loss: 1.3802 - accuracy: 0.1665 - val_loss: 1.3808 - val_accuracy: 0.2188\n",
      "Epoch 9/30\n",
      "418/418 [==============================] - 51s 123ms/step - loss: 1.3805 - accuracy: 0.1615 - val_loss: 1.3808 - val_accuracy: 0.2188\n",
      "Epoch 10/30\n",
      "418/418 [==============================] - 51s 123ms/step - loss: 1.3801 - accuracy: 0.1721 - val_loss: 1.3808 - val_accuracy: 0.2188\n",
      "Epoch 11/30\n",
      "418/418 [==============================] - 51s 123ms/step - loss: 1.3803 - accuracy: 0.1673 - val_loss: 1.3808 - val_accuracy: 0.2188\n",
      "Epoch 12/30\n",
      "418/418 [==============================] - 51s 122ms/step - loss: 1.3801 - accuracy: 0.1675 - val_loss: 1.3808 - val_accuracy: 0.2188\n",
      "Epoch 13/30\n",
      "418/418 [==============================] - 51s 122ms/step - loss: 1.3805 - accuracy: 0.1660 - val_loss: 1.3808 - val_accuracy: 0.2188\n",
      "Epoch 14/30\n",
      "418/418 [==============================] - 51s 122ms/step - loss: 1.3803 - accuracy: 0.1706 - val_loss: 1.3808 - val_accuracy: 0.2188\n",
      "Epoch 15/30\n",
      "418/418 [==============================] - 51s 123ms/step - loss: 1.3797 - accuracy: 0.1714 - val_loss: 1.3808 - val_accuracy: 0.2188\n",
      "Epoch 16/30\n",
      "418/418 [==============================] - 51s 123ms/step - loss: 1.3805 - accuracy: 0.1651 - val_loss: 1.3808 - val_accuracy: 0.2188\n",
      "Epoch 17/30\n",
      "418/418 [==============================] - 51s 123ms/step - loss: 1.3800 - accuracy: 0.1689 - val_loss: 1.3808 - val_accuracy: 0.2188\n",
      "Epoch 18/30\n",
      "418/418 [==============================] - 51s 123ms/step - loss: 1.3800 - accuracy: 0.1726 - val_loss: 1.3808 - val_accuracy: 0.2188\n",
      "Epoch 19/30\n",
      "418/418 [==============================] - 51s 123ms/step - loss: 1.3801 - accuracy: 0.1685 - val_loss: 1.3808 - val_accuracy: 0.2188\n",
      "Epoch 20/30\n",
      "418/418 [==============================] - 51s 123ms/step - loss: 1.3801 - accuracy: 0.1687 - val_loss: 1.3808 - val_accuracy: 0.2188\n",
      "Epoch 21/30\n",
      "418/418 [==============================] - 51s 123ms/step - loss: 1.3808 - accuracy: 0.1635 - val_loss: 1.3808 - val_accuracy: 0.2188\n",
      "Epoch 22/30\n",
      "418/418 [==============================] - 51s 123ms/step - loss: 1.3802 - accuracy: 0.1701 - val_loss: 1.3808 - val_accuracy: 0.2188\n",
      "Epoch 23/30\n",
      "418/418 [==============================] - 51s 123ms/step - loss: 1.3801 - accuracy: 0.1648 - val_loss: 1.3808 - val_accuracy: 0.2188\n",
      "Epoch 24/30\n",
      "418/418 [==============================] - 51s 123ms/step - loss: 1.3804 - accuracy: 0.1673 - val_loss: 1.3808 - val_accuracy: 0.2188\n",
      "Epoch 25/30\n",
      "418/418 [==============================] - 51s 123ms/step - loss: 1.3803 - accuracy: 0.1706 - val_loss: 1.3808 - val_accuracy: 0.2188\n",
      "Epoch 26/30\n",
      "418/418 [==============================] - 51s 122ms/step - loss: 1.3800 - accuracy: 0.1654 - val_loss: 1.3808 - val_accuracy: 0.2188\n",
      "Epoch 27/30\n",
      "418/418 [==============================] - 51s 123ms/step - loss: 1.3801 - accuracy: 0.1674 - val_loss: 1.3808 - val_accuracy: 0.2188\n",
      "Epoch 28/30\n",
      "418/418 [==============================] - 51s 123ms/step - loss: 1.3803 - accuracy: 0.1681 - val_loss: 1.3808 - val_accuracy: 0.2188\n",
      "Epoch 29/30\n",
      "418/418 [==============================] - 51s 123ms/step - loss: 1.3803 - accuracy: 0.1702 - val_loss: 1.3808 - val_accuracy: 0.2188\n",
      "Epoch 30/30\n",
      "418/418 [==============================] - 51s 123ms/step - loss: 1.3803 - accuracy: 0.1693 - val_loss: 1.3808 - val_accuracy: 0.2188\n",
      "INFO:tensorflow:Assets written to: ../xception/xception_30epochs_20871.0_images_False_newWeights_True_lastLayerOnly_rescale-symmetric_normalization/assets\n",
      "Test acc for xception: 0.260331\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training resnet for 0.25% of train size (aka 20871 images) with pretrained: True and onlyLastLayersTrained: True...\n",
      "\n",
      "Total: 178 trainable: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/418 [..............................] - ETA: 2:47 - loss: 1.3813 - accuracy: 0.3956WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0609s vs `on_train_batch_begin` time: 0.1277s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0609s vs `on_train_batch_end` time: 0.1606s). Check your callbacks.\n",
      "418/418 [==============================] - 30s 63ms/step - loss: 1.3809 - accuracy: 0.3534 - val_loss: 1.3860 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "418/418 [==============================] - 23s 56ms/step - loss: 1.3812 - accuracy: 0.3453 - val_loss: 1.3860 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "418/418 [==============================] - 24s 56ms/step - loss: 1.3807 - accuracy: 0.3501 - val_loss: 1.3860 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "418/418 [==============================] - 24s 57ms/step - loss: 1.3810 - accuracy: 0.3485 - val_loss: 1.3860 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "418/418 [==============================] - 24s 57ms/step - loss: 1.3810 - accuracy: 0.3476 - val_loss: 1.3860 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "418/418 [==============================] - 24s 57ms/step - loss: 1.3807 - accuracy: 0.3520 - val_loss: 1.3860 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "418/418 [==============================] - 24s 57ms/step - loss: 1.3806 - accuracy: 0.3520 - val_loss: 1.3860 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "418/418 [==============================] - 24s 57ms/step - loss: 1.3808 - accuracy: 0.3507 - val_loss: 1.3860 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "418/418 [==============================] - 24s 57ms/step - loss: 1.3811 - accuracy: 0.3482 - val_loss: 1.3860 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "418/418 [==============================] - 24s 57ms/step - loss: 1.3809 - accuracy: 0.3482 - val_loss: 1.3860 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "418/418 [==============================] - 24s 57ms/step - loss: 1.3810 - accuracy: 0.3494 - val_loss: 1.3860 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "418/418 [==============================] - 24s 57ms/step - loss: 1.3808 - accuracy: 0.3538 - val_loss: 1.3860 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "418/418 [==============================] - 24s 57ms/step - loss: 1.3810 - accuracy: 0.3511 - val_loss: 1.3860 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "418/418 [==============================] - 24s 57ms/step - loss: 1.3808 - accuracy: 0.3568 - val_loss: 1.3860 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "418/418 [==============================] - 24s 57ms/step - loss: 1.3810 - accuracy: 0.3529 - val_loss: 1.3860 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "418/418 [==============================] - 24s 57ms/step - loss: 1.3806 - accuracy: 0.3551 - val_loss: 1.3860 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "418/418 [==============================] - 24s 57ms/step - loss: 1.3813 - accuracy: 0.3387 - val_loss: 1.3860 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "418/418 [==============================] - 24s 57ms/step - loss: 1.3809 - accuracy: 0.3518 - val_loss: 1.3860 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "418/418 [==============================] - 24s 57ms/step - loss: 1.3808 - accuracy: 0.3512 - val_loss: 1.3860 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "418/418 [==============================] - 24s 57ms/step - loss: 1.3811 - accuracy: 0.3484 - val_loss: 1.3860 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "418/418 [==============================] - 24s 57ms/step - loss: 1.3810 - accuracy: 0.3484 - val_loss: 1.3860 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "418/418 [==============================] - 24s 57ms/step - loss: 1.3811 - accuracy: 0.3482 - val_loss: 1.3860 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "418/418 [==============================] - 24s 57ms/step - loss: 1.3812 - accuracy: 0.3444 - val_loss: 1.3860 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "418/418 [==============================] - 24s 57ms/step - loss: 1.3809 - accuracy: 0.3523 - val_loss: 1.3860 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "418/418 [==============================] - 24s 57ms/step - loss: 1.3806 - accuracy: 0.3519 - val_loss: 1.3860 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "418/418 [==============================] - 24s 57ms/step - loss: 1.3809 - accuracy: 0.3515 - val_loss: 1.3860 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "418/418 [==============================] - 24s 57ms/step - loss: 1.3808 - accuracy: 0.3486 - val_loss: 1.3860 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "418/418 [==============================] - 24s 57ms/step - loss: 1.3812 - accuracy: 0.3457 - val_loss: 1.3860 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "418/418 [==============================] - 24s 57ms/step - loss: 1.3811 - accuracy: 0.3477 - val_loss: 1.3860 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "418/418 [==============================] - 24s 57ms/step - loss: 1.3809 - accuracy: 0.3490 - val_loss: 1.3860 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_20871.0_images_False_newWeights_True_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.273760\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training opticnet for 0.25% of train size (aka 20871 images) with pretrained: True and onlyLastLayersTrained: True...\n",
      "\n",
      "Total: 276 trainable: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "418/418 [==============================] - 132s 299ms/step - loss: 288.0347 - accuracy: 0.1347 - val_loss: 217.3077 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "418/418 [==============================] - 121s 288ms/step - loss: 286.8889 - accuracy: 0.1340 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "418/418 [==============================] - 121s 289ms/step - loss: 288.7813 - accuracy: 0.1357 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "418/418 [==============================] - 121s 289ms/step - loss: 289.7397 - accuracy: 0.1286 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "418/418 [==============================] - 121s 289ms/step - loss: 288.7593 - accuracy: 0.1343 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "418/418 [==============================] - 121s 288ms/step - loss: 291.1101 - accuracy: 0.1337 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "418/418 [==============================] - 121s 289ms/step - loss: 289.8522 - accuracy: 0.1332 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "418/418 [==============================] - 121s 289ms/step - loss: 290.0284 - accuracy: 0.1325 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "418/418 [==============================] - 121s 288ms/step - loss: 288.7886 - accuracy: 0.1372 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "418/418 [==============================] - 121s 288ms/step - loss: 290.9427 - accuracy: 0.1325 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "418/418 [==============================] - 121s 289ms/step - loss: 289.4331 - accuracy: 0.1342 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "418/418 [==============================] - 120s 288ms/step - loss: 292.1107 - accuracy: 0.1305 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "418/418 [==============================] - 120s 288ms/step - loss: 286.3598 - accuracy: 0.1409 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "418/418 [==============================] - 121s 289ms/step - loss: 289.9971 - accuracy: 0.1370 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "418/418 [==============================] - 121s 289ms/step - loss: 286.7519 - accuracy: 0.1389 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "418/418 [==============================] - 121s 289ms/step - loss: 286.2826 - accuracy: 0.1358 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "418/418 [==============================] - 121s 288ms/step - loss: 288.8402 - accuracy: 0.1343 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "418/418 [==============================] - 121s 289ms/step - loss: 286.1832 - accuracy: 0.1392 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "418/418 [==============================] - 121s 289ms/step - loss: 290.1517 - accuracy: 0.1309 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "418/418 [==============================] - 243s 583ms/step - loss: 289.4992 - accuracy: 0.1336 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "418/418 [==============================] - 257s 614ms/step - loss: 289.3956 - accuracy: 0.1321 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "418/418 [==============================] - 257s 614ms/step - loss: 290.6633 - accuracy: 0.1361 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "418/418 [==============================] - 257s 615ms/step - loss: 288.1577 - accuracy: 0.1373 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "418/418 [==============================] - 257s 614ms/step - loss: 287.9456 - accuracy: 0.1366 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "418/418 [==============================] - 257s 614ms/step - loss: 287.5043 - accuracy: 0.1366 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "418/418 [==============================] - 257s 615ms/step - loss: 288.3272 - accuracy: 0.1318 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "418/418 [==============================] - 257s 614ms/step - loss: 288.2612 - accuracy: 0.1346 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "418/418 [==============================] - 257s 614ms/step - loss: 290.6244 - accuracy: 0.1339 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "418/418 [==============================] - 257s 614ms/step - loss: 289.2186 - accuracy: 0.1316 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "418/418 [==============================] - 257s 615ms/step - loss: 290.6277 - accuracy: 0.1297 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../opticnet/opticnet_30epochs_20871.0_images_False_newWeights_True_lastLayerOnly_rescale-symmetric_normalization/assets\n",
      "Test acc for opticnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.40068402 0.39922053 0.39813183 0.4036676 ]\n",
      "Training xception for 0.4% of train size (aka 33393 images) with pretrained: True and onlyLastLayersTrained: True...\n",
      "\n",
      "Total: 135 trainable: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "668/668 [==============================] - 176s 259ms/step - loss: 1.3737 - accuracy: 0.4320 - val_loss: 1.3824 - val_accuracy: 0.3125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "668/668 [==============================] - 170s 254ms/step - loss: 1.3738 - accuracy: 0.4258 - val_loss: 1.3824 - val_accuracy: 0.3125\n",
      "Epoch 3/30\n",
      "668/668 [==============================] - 170s 254ms/step - loss: 1.3735 - accuracy: 0.4326 - val_loss: 1.3824 - val_accuracy: 0.3125\n",
      "Epoch 4/30\n",
      "668/668 [==============================] - 169s 254ms/step - loss: 1.3737 - accuracy: 0.4292 - val_loss: 1.3824 - val_accuracy: 0.3125\n",
      "Epoch 5/30\n",
      "668/668 [==============================] - 170s 254ms/step - loss: 1.3738 - accuracy: 0.4304 - val_loss: 1.3824 - val_accuracy: 0.3125\n",
      "Epoch 6/30\n",
      "668/668 [==============================] - 106s 158ms/step - loss: 1.3736 - accuracy: 0.4250 - val_loss: 1.3824 - val_accuracy: 0.3125\n",
      "Epoch 7/30\n",
      "668/668 [==============================] - 82s 123ms/step - loss: 1.3736 - accuracy: 0.4296 - val_loss: 1.3824 - val_accuracy: 0.3125\n",
      "Epoch 8/30\n",
      "668/668 [==============================] - 82s 123ms/step - loss: 1.3735 - accuracy: 0.4325 - val_loss: 1.3824 - val_accuracy: 0.3125\n",
      "Epoch 9/30\n",
      "668/668 [==============================] - 82s 122ms/step - loss: 1.3738 - accuracy: 0.4281 - val_loss: 1.3824 - val_accuracy: 0.3125\n",
      "Epoch 10/30\n",
      "668/668 [==============================] - 82s 122ms/step - loss: 1.3738 - accuracy: 0.4262 - val_loss: 1.3824 - val_accuracy: 0.3125\n",
      "Epoch 11/30\n",
      "668/668 [==============================] - 82s 122ms/step - loss: 1.3738 - accuracy: 0.4316 - val_loss: 1.3824 - val_accuracy: 0.3125\n",
      "Epoch 12/30\n",
      "668/668 [==============================] - 82s 122ms/step - loss: 1.3737 - accuracy: 0.4273 - val_loss: 1.3824 - val_accuracy: 0.3125\n",
      "Epoch 13/30\n",
      "668/668 [==============================] - 82s 122ms/step - loss: 1.3737 - accuracy: 0.4314 - val_loss: 1.3824 - val_accuracy: 0.3125\n",
      "Epoch 14/30\n",
      "668/668 [==============================] - 82s 122ms/step - loss: 1.3735 - accuracy: 0.4329 - val_loss: 1.3824 - val_accuracy: 0.3125\n",
      "Epoch 15/30\n",
      "668/668 [==============================] - 82s 122ms/step - loss: 1.3736 - accuracy: 0.4298 - val_loss: 1.3824 - val_accuracy: 0.3125\n",
      "Epoch 16/30\n",
      "668/668 [==============================] - 82s 123ms/step - loss: 1.3736 - accuracy: 0.4300 - val_loss: 1.3824 - val_accuracy: 0.3125\n",
      "Epoch 17/30\n",
      "668/668 [==============================] - 82s 123ms/step - loss: 1.3737 - accuracy: 0.4327 - val_loss: 1.3824 - val_accuracy: 0.3125\n",
      "Epoch 18/30\n",
      "668/668 [==============================] - 82s 122ms/step - loss: 1.3738 - accuracy: 0.4320 - val_loss: 1.3824 - val_accuracy: 0.3125\n",
      "Epoch 19/30\n",
      "668/668 [==============================] - 82s 122ms/step - loss: 1.3736 - accuracy: 0.4315 - val_loss: 1.3824 - val_accuracy: 0.3125\n",
      "Epoch 20/30\n",
      "668/668 [==============================] - 82s 122ms/step - loss: 1.3738 - accuracy: 0.4249 - val_loss: 1.3824 - val_accuracy: 0.3125\n",
      "Epoch 21/30\n",
      "668/668 [==============================] - 82s 122ms/step - loss: 1.3737 - accuracy: 0.4275 - val_loss: 1.3824 - val_accuracy: 0.3125\n",
      "Epoch 22/30\n",
      "668/668 [==============================] - 82s 123ms/step - loss: 1.3737 - accuracy: 0.4282 - val_loss: 1.3824 - val_accuracy: 0.3125\n",
      "Epoch 23/30\n",
      "668/668 [==============================] - 82s 123ms/step - loss: 1.3738 - accuracy: 0.4276 - val_loss: 1.3824 - val_accuracy: 0.3125\n",
      "Epoch 24/30\n",
      "668/668 [==============================] - 82s 123ms/step - loss: 1.3737 - accuracy: 0.4329 - val_loss: 1.3824 - val_accuracy: 0.3125\n",
      "Epoch 25/30\n",
      "668/668 [==============================] - 82s 122ms/step - loss: 1.3737 - accuracy: 0.4280 - val_loss: 1.3824 - val_accuracy: 0.3125\n",
      "Epoch 26/30\n",
      "668/668 [==============================] - 82s 122ms/step - loss: 1.3739 - accuracy: 0.4273 - val_loss: 1.3824 - val_accuracy: 0.3125\n",
      "Epoch 27/30\n",
      "668/668 [==============================] - 82s 123ms/step - loss: 1.3736 - accuracy: 0.4270 - val_loss: 1.3824 - val_accuracy: 0.3125\n",
      "Epoch 28/30\n",
      "668/668 [==============================] - 82s 123ms/step - loss: 1.3737 - accuracy: 0.4362 - val_loss: 1.3824 - val_accuracy: 0.3125\n",
      "Epoch 29/30\n",
      "668/668 [==============================] - 82s 123ms/step - loss: 1.3738 - accuracy: 0.4289 - val_loss: 1.3824 - val_accuracy: 0.3125\n",
      "Epoch 30/30\n",
      "668/668 [==============================] - 82s 122ms/step - loss: 1.3739 - accuracy: 0.4256 - val_loss: 1.3824 - val_accuracy: 0.3125\n",
      "INFO:tensorflow:Assets written to: ../xception/xception_30epochs_33393.6_images_False_newWeights_True_lastLayerOnly_rescale-symmetric_normalization/assets\n",
      "Test acc for xception: 0.267562\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training resnet for 0.4% of train size (aka 33393 images) with pretrained: True and onlyLastLayersTrained: True...\n",
      "\n",
      "Total: 178 trainable: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/668 [..............................] - ETA: 4:42 - loss: 1.3822 - accuracy: 0.2948WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0602s vs `on_train_batch_begin` time: 0.1301s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0602s vs `on_train_batch_end` time: 0.1762s). Check your callbacks.\n",
      "668/668 [==============================] - 45s 61ms/step - loss: 1.3798 - accuracy: 0.3580 - val_loss: 1.3880 - val_accuracy: 0.1250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "668/668 [==============================] - 38s 56ms/step - loss: 1.3795 - accuracy: 0.3650 - val_loss: 1.3880 - val_accuracy: 0.1250\n",
      "Epoch 3/30\n",
      "668/668 [==============================] - 38s 57ms/step - loss: 1.3797 - accuracy: 0.3607 - val_loss: 1.3880 - val_accuracy: 0.1250\n",
      "Epoch 4/30\n",
      "668/668 [==============================] - 38s 57ms/step - loss: 1.3795 - accuracy: 0.3630 - val_loss: 1.3880 - val_accuracy: 0.1250\n",
      "Epoch 5/30\n",
      "668/668 [==============================] - 38s 57ms/step - loss: 1.3794 - accuracy: 0.3638 - val_loss: 1.3880 - val_accuracy: 0.1250\n",
      "Epoch 6/30\n",
      "668/668 [==============================] - 38s 57ms/step - loss: 1.3796 - accuracy: 0.3633 - val_loss: 1.3880 - val_accuracy: 0.1250\n",
      "Epoch 7/30\n",
      "668/668 [==============================] - 38s 57ms/step - loss: 1.3798 - accuracy: 0.3630 - val_loss: 1.3880 - val_accuracy: 0.1250\n",
      "Epoch 8/30\n",
      "668/668 [==============================] - 38s 57ms/step - loss: 1.3797 - accuracy: 0.3611 - val_loss: 1.3880 - val_accuracy: 0.1250\n",
      "Epoch 9/30\n",
      "668/668 [==============================] - 38s 57ms/step - loss: 1.3795 - accuracy: 0.3658 - val_loss: 1.3880 - val_accuracy: 0.1250\n",
      "Epoch 10/30\n",
      "668/668 [==============================] - 38s 57ms/step - loss: 1.3798 - accuracy: 0.3604 - val_loss: 1.3880 - val_accuracy: 0.1250\n",
      "Epoch 11/30\n",
      "668/668 [==============================] - 38s 57ms/step - loss: 1.3797 - accuracy: 0.3610 - val_loss: 1.3880 - val_accuracy: 0.1250\n",
      "Epoch 12/30\n",
      "668/668 [==============================] - 38s 57ms/step - loss: 1.3799 - accuracy: 0.3596 - val_loss: 1.3880 - val_accuracy: 0.1250\n",
      "Epoch 13/30\n",
      "668/668 [==============================] - 38s 57ms/step - loss: 1.3796 - accuracy: 0.3641 - val_loss: 1.3880 - val_accuracy: 0.1250\n",
      "Epoch 14/30\n",
      "668/668 [==============================] - 38s 56ms/step - loss: 1.3796 - accuracy: 0.3595 - val_loss: 1.3880 - val_accuracy: 0.1250\n",
      "Epoch 15/30\n",
      "668/668 [==============================] - 38s 56ms/step - loss: 1.3797 - accuracy: 0.3636 - val_loss: 1.3880 - val_accuracy: 0.1250\n",
      "Epoch 16/30\n",
      "668/668 [==============================] - 38s 57ms/step - loss: 1.3796 - accuracy: 0.3626 - val_loss: 1.3880 - val_accuracy: 0.1250\n",
      "Epoch 17/30\n",
      "668/668 [==============================] - 38s 57ms/step - loss: 1.3797 - accuracy: 0.3601 - val_loss: 1.3880 - val_accuracy: 0.1250\n",
      "Epoch 18/30\n",
      "668/668 [==============================] - 38s 57ms/step - loss: 1.3798 - accuracy: 0.3634 - val_loss: 1.3880 - val_accuracy: 0.1250\n",
      "Epoch 19/30\n",
      "668/668 [==============================] - 38s 57ms/step - loss: 1.3796 - accuracy: 0.3654 - val_loss: 1.3880 - val_accuracy: 0.1250\n",
      "Epoch 20/30\n",
      "668/668 [==============================] - 38s 57ms/step - loss: 1.3799 - accuracy: 0.3566 - val_loss: 1.3880 - val_accuracy: 0.1250\n",
      "Epoch 21/30\n",
      "668/668 [==============================] - 38s 57ms/step - loss: 1.3797 - accuracy: 0.3595 - val_loss: 1.3880 - val_accuracy: 0.1250\n",
      "Epoch 22/30\n",
      "668/668 [==============================] - 38s 57ms/step - loss: 1.3798 - accuracy: 0.3624 - val_loss: 1.3880 - val_accuracy: 0.1250\n",
      "Epoch 23/30\n",
      "668/668 [==============================] - 38s 57ms/step - loss: 1.3796 - accuracy: 0.3641 - val_loss: 1.3880 - val_accuracy: 0.1250\n",
      "Epoch 24/30\n",
      "668/668 [==============================] - 38s 57ms/step - loss: 1.3797 - accuracy: 0.3635 - val_loss: 1.3880 - val_accuracy: 0.1250\n",
      "Epoch 25/30\n",
      "668/668 [==============================] - 38s 57ms/step - loss: 1.3798 - accuracy: 0.3610 - val_loss: 1.3880 - val_accuracy: 0.1250\n",
      "Epoch 26/30\n",
      "668/668 [==============================] - 38s 57ms/step - loss: 1.3795 - accuracy: 0.3617 - val_loss: 1.3880 - val_accuracy: 0.1250\n",
      "Epoch 27/30\n",
      "668/668 [==============================] - 38s 57ms/step - loss: 1.3796 - accuracy: 0.3639 - val_loss: 1.3880 - val_accuracy: 0.1250\n",
      "Epoch 28/30\n",
      "668/668 [==============================] - 38s 57ms/step - loss: 1.3798 - accuracy: 0.3581 - val_loss: 1.3880 - val_accuracy: 0.1250\n",
      "Epoch 29/30\n",
      "668/668 [==============================] - 38s 57ms/step - loss: 1.3795 - accuracy: 0.3650 - val_loss: 1.3880 - val_accuracy: 0.1250\n",
      "Epoch 30/30\n",
      "668/668 [==============================] - 38s 57ms/step - loss: 1.3797 - accuracy: 0.3611 - val_loss: 1.3880 - val_accuracy: 0.1250\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_33393.6_images_False_newWeights_True_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.267562\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training opticnet for 0.4% of train size (aka 33393 images) with pretrained: True and onlyLastLayersTrained: True...\n",
      "\n",
      "Total: 276 trainable: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "668/668 [==============================] - 203s 294ms/step - loss: 288.5134 - accuracy: 0.1366 - val_loss: 217.3077 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "668/668 [==============================] - 193s 289ms/step - loss: 289.8131 - accuracy: 0.1360 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "668/668 [==============================] - 193s 289ms/step - loss: 289.8289 - accuracy: 0.1288 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "668/668 [==============================] - 192s 288ms/step - loss: 288.7419 - accuracy: 0.1321 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "668/668 [==============================] - 193s 288ms/step - loss: 288.4391 - accuracy: 0.1377 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "668/668 [==============================] - 193s 289ms/step - loss: 288.4946 - accuracy: 0.1341 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "668/668 [==============================] - 193s 289ms/step - loss: 290.0023 - accuracy: 0.1343 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "668/668 [==============================] - 193s 288ms/step - loss: 289.1215 - accuracy: 0.1359 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "668/668 [==============================] - 193s 288ms/step - loss: 289.9985 - accuracy: 0.1330 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "668/668 [==============================] - 193s 288ms/step - loss: 288.1671 - accuracy: 0.1366 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "668/668 [==============================] - 193s 289ms/step - loss: 286.9751 - accuracy: 0.1375 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "668/668 [==============================] - 193s 289ms/step - loss: 288.0153 - accuracy: 0.1362 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "668/668 [==============================] - 193s 289ms/step - loss: 289.1543 - accuracy: 0.1356 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "668/668 [==============================] - 193s 288ms/step - loss: 289.4991 - accuracy: 0.1354 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "668/668 [==============================] - 193s 288ms/step - loss: 288.9714 - accuracy: 0.1358 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "668/668 [==============================] - 193s 288ms/step - loss: 288.9267 - accuracy: 0.1364 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "668/668 [==============================] - 193s 288ms/step - loss: 289.8343 - accuracy: 0.1342 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "668/668 [==============================] - 192s 288ms/step - loss: 291.2272 - accuracy: 0.1343 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "668/668 [==============================] - 193s 288ms/step - loss: 289.3587 - accuracy: 0.1346 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "668/668 [==============================] - 193s 288ms/step - loss: 289.7027 - accuracy: 0.1375 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "668/668 [==============================] - 193s 288ms/step - loss: 288.8970 - accuracy: 0.1340 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "668/668 [==============================] - 192s 288ms/step - loss: 290.5409 - accuracy: 0.1331 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "668/668 [==============================] - 193s 288ms/step - loss: 289.0521 - accuracy: 0.1355 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "668/668 [==============================] - 192s 288ms/step - loss: 288.5057 - accuracy: 0.1370 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "668/668 [==============================] - 193s 288ms/step - loss: 289.2304 - accuracy: 0.1337 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "668/668 [==============================] - 192s 288ms/step - loss: 289.2160 - accuracy: 0.1371 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "668/668 [==============================] - 193s 288ms/step - loss: 290.1156 - accuracy: 0.1311 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "668/668 [==============================] - 192s 288ms/step - loss: 288.5792 - accuracy: 0.1375 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "668/668 [==============================] - 193s 288ms/step - loss: 290.5090 - accuracy: 0.1355 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "668/668 [==============================] - 193s 289ms/step - loss: 287.8807 - accuracy: 0.1365 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../opticnet/opticnet_30epochs_33393.6_images_False_newWeights_True_lastLayerOnly_rescale-symmetric_normalization/assets\n",
      "Test acc for opticnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.49766293 0.4985889  0.50608037 0.50522284]\n",
      "Training xception for 0.5% of train size (aka 41742 images) with pretrained: True and onlyLastLayersTrained: True...\n",
      "\n",
      "Total: 135 trainable: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/835 [..............................] - ETA: 7:25 - loss: 1.3770 - accuracy: 0.3921WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1147s vs `on_train_batch_begin` time: 0.1423s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1147s vs `on_train_batch_end` time: 0.2106s). Check your callbacks.\n",
      "835/835 [==============================] - 107s 124ms/step - loss: 1.3759 - accuracy: 0.4198 - val_loss: 1.3846 - val_accuracy: 0.2812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "835/835 [==============================] - 102s 122ms/step - loss: 1.3758 - accuracy: 0.4216 - val_loss: 1.3846 - val_accuracy: 0.2812\n",
      "Epoch 3/30\n",
      "835/835 [==============================] - 103s 123ms/step - loss: 1.3759 - accuracy: 0.4208 - val_loss: 1.3846 - val_accuracy: 0.2812\n",
      "Epoch 4/30\n",
      "835/835 [==============================] - 103s 123ms/step - loss: 1.3758 - accuracy: 0.4224 - val_loss: 1.3846 - val_accuracy: 0.2812\n",
      "Epoch 5/30\n",
      "835/835 [==============================] - 103s 123ms/step - loss: 1.3760 - accuracy: 0.4199 - val_loss: 1.3846 - val_accuracy: 0.2812\n",
      "Epoch 6/30\n",
      "835/835 [==============================] - 103s 123ms/step - loss: 1.3759 - accuracy: 0.4214 - val_loss: 1.3846 - val_accuracy: 0.2812\n",
      "Epoch 7/30\n",
      "835/835 [==============================] - 103s 123ms/step - loss: 1.3759 - accuracy: 0.4193 - val_loss: 1.3846 - val_accuracy: 0.2812\n",
      "Epoch 8/30\n",
      "835/835 [==============================] - 103s 123ms/step - loss: 1.3758 - accuracy: 0.4206 - val_loss: 1.3846 - val_accuracy: 0.2812\n",
      "Epoch 9/30\n",
      "835/835 [==============================] - 103s 123ms/step - loss: 1.3760 - accuracy: 0.4208 - val_loss: 1.3846 - val_accuracy: 0.2812\n",
      "Epoch 10/30\n",
      "835/835 [==============================] - 103s 123ms/step - loss: 1.3759 - accuracy: 0.4209 - val_loss: 1.3846 - val_accuracy: 0.2812\n",
      "Epoch 11/30\n",
      "835/835 [==============================] - 103s 123ms/step - loss: 1.3760 - accuracy: 0.4179 - val_loss: 1.3846 - val_accuracy: 0.2812\n",
      "Epoch 12/30\n",
      "835/835 [==============================] - 103s 123ms/step - loss: 1.3758 - accuracy: 0.4227 - val_loss: 1.3846 - val_accuracy: 0.2812\n",
      "Epoch 13/30\n",
      "835/835 [==============================] - 103s 123ms/step - loss: 1.3758 - accuracy: 0.4212 - val_loss: 1.3846 - val_accuracy: 0.2812\n",
      "Epoch 14/30\n",
      "835/835 [==============================] - 102s 123ms/step - loss: 1.3757 - accuracy: 0.4243 - val_loss: 1.3846 - val_accuracy: 0.2812\n",
      "Epoch 15/30\n",
      "835/835 [==============================] - 103s 123ms/step - loss: 1.3759 - accuracy: 0.4215 - val_loss: 1.3846 - val_accuracy: 0.2812\n",
      "Epoch 16/30\n",
      "835/835 [==============================] - 103s 123ms/step - loss: 1.3758 - accuracy: 0.4212 - val_loss: 1.3846 - val_accuracy: 0.2812\n",
      "Epoch 17/30\n",
      "835/835 [==============================] - 103s 123ms/step - loss: 1.3759 - accuracy: 0.4192 - val_loss: 1.3846 - val_accuracy: 0.2812\n",
      "Epoch 18/30\n",
      "835/835 [==============================] - 103s 123ms/step - loss: 1.3759 - accuracy: 0.4206 - val_loss: 1.3846 - val_accuracy: 0.2812\n",
      "Epoch 19/30\n",
      "835/835 [==============================] - 103s 123ms/step - loss: 1.3758 - accuracy: 0.4221 - val_loss: 1.3846 - val_accuracy: 0.2812\n",
      "Epoch 20/30\n",
      "835/835 [==============================] - 102s 123ms/step - loss: 1.3758 - accuracy: 0.4213 - val_loss: 1.3846 - val_accuracy: 0.2812\n",
      "Epoch 21/30\n",
      "835/835 [==============================] - 102s 122ms/step - loss: 1.3758 - accuracy: 0.4227 - val_loss: 1.3846 - val_accuracy: 0.2812\n",
      "Epoch 22/30\n",
      "835/835 [==============================] - 103s 123ms/step - loss: 1.3759 - accuracy: 0.4213 - val_loss: 1.3846 - val_accuracy: 0.2812\n",
      "Epoch 23/30\n",
      "835/835 [==============================] - 102s 123ms/step - loss: 1.3758 - accuracy: 0.4242 - val_loss: 1.3846 - val_accuracy: 0.2812\n",
      "Epoch 24/30\n",
      "835/835 [==============================] - 102s 123ms/step - loss: 1.3758 - accuracy: 0.4237 - val_loss: 1.3846 - val_accuracy: 0.2812\n",
      "Epoch 25/30\n",
      "835/835 [==============================] - 103s 123ms/step - loss: 1.3757 - accuracy: 0.4229 - val_loss: 1.3846 - val_accuracy: 0.2812\n",
      "Epoch 26/30\n",
      "835/835 [==============================] - 103s 123ms/step - loss: 1.3760 - accuracy: 0.4192 - val_loss: 1.3846 - val_accuracy: 0.2812\n",
      "Epoch 27/30\n",
      "835/835 [==============================] - 103s 123ms/step - loss: 1.3759 - accuracy: 0.4212 - val_loss: 1.3846 - val_accuracy: 0.2812\n",
      "Epoch 28/30\n",
      "835/835 [==============================] - 103s 123ms/step - loss: 1.3758 - accuracy: 0.4219 - val_loss: 1.3846 - val_accuracy: 0.2812\n",
      "Epoch 29/30\n",
      "835/835 [==============================] - 102s 123ms/step - loss: 1.3760 - accuracy: 0.4187 - val_loss: 1.3846 - val_accuracy: 0.2812\n",
      "Epoch 30/30\n",
      "835/835 [==============================] - 102s 122ms/step - loss: 1.3757 - accuracy: 0.4255 - val_loss: 1.3846 - val_accuracy: 0.2812\n",
      "INFO:tensorflow:Assets written to: ../xception/xception_30epochs_41742.0_images_False_newWeights_True_lastLayerOnly_rescale-symmetric_normalization/assets\n",
      "Test acc for xception: 0.251033\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training resnet for 0.5% of train size (aka 41742 images) with pretrained: True and onlyLastLayersTrained: True...\n",
      "\n",
      "Total: 178 trainable: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/835 [..............................] - ETA: 5:36 - loss: 1.3833 - accuracy: 0.2760WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0579s vs `on_train_batch_begin` time: 0.1376s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0579s vs `on_train_batch_end` time: 0.1526s). Check your callbacks.\n",
      "835/835 [==============================] - 53s 59ms/step - loss: 1.3845 - accuracy: 0.2474 - val_loss: 1.3811 - val_accuracy: 0.3750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "835/835 [==============================] - 47s 57ms/step - loss: 1.3846 - accuracy: 0.2469 - val_loss: 1.3811 - val_accuracy: 0.3750\n",
      "Epoch 3/30\n",
      "835/835 [==============================] - 47s 57ms/step - loss: 1.3846 - accuracy: 0.2456 - val_loss: 1.3811 - val_accuracy: 0.3750\n",
      "Epoch 4/30\n",
      "835/835 [==============================] - 47s 57ms/step - loss: 1.3848 - accuracy: 0.2426 - val_loss: 1.3811 - val_accuracy: 0.3750\n",
      "Epoch 5/30\n",
      "835/835 [==============================] - 47s 57ms/step - loss: 1.3846 - accuracy: 0.2462 - val_loss: 1.3811 - val_accuracy: 0.3750\n",
      "Epoch 6/30\n",
      "835/835 [==============================] - 47s 57ms/step - loss: 1.3847 - accuracy: 0.2416 - val_loss: 1.3811 - val_accuracy: 0.3750\n",
      "Epoch 7/30\n",
      "835/835 [==============================] - 47s 57ms/step - loss: 1.3846 - accuracy: 0.2491 - val_loss: 1.3811 - val_accuracy: 0.3750\n",
      "Epoch 8/30\n",
      "835/835 [==============================] - 48s 57ms/step - loss: 1.3846 - accuracy: 0.2424 - val_loss: 1.3811 - val_accuracy: 0.3750\n",
      "Epoch 9/30\n",
      "835/835 [==============================] - 48s 57ms/step - loss: 1.3847 - accuracy: 0.2461 - val_loss: 1.3811 - val_accuracy: 0.3750\n",
      "Epoch 10/30\n",
      "835/835 [==============================] - 47s 57ms/step - loss: 1.3847 - accuracy: 0.2452 - val_loss: 1.3811 - val_accuracy: 0.3750\n",
      "Epoch 11/30\n",
      "835/835 [==============================] - 47s 57ms/step - loss: 1.3846 - accuracy: 0.2440 - val_loss: 1.3811 - val_accuracy: 0.3750\n",
      "Epoch 12/30\n",
      "835/835 [==============================] - 47s 57ms/step - loss: 1.3848 - accuracy: 0.2440 - val_loss: 1.3811 - val_accuracy: 0.3750\n",
      "Epoch 13/30\n",
      "835/835 [==============================] - 47s 57ms/step - loss: 1.3847 - accuracy: 0.2432 - val_loss: 1.3811 - val_accuracy: 0.3750\n",
      "Epoch 14/30\n",
      "835/835 [==============================] - 47s 57ms/step - loss: 1.3846 - accuracy: 0.2447 - val_loss: 1.3811 - val_accuracy: 0.3750\n",
      "Epoch 15/30\n",
      "835/835 [==============================] - 47s 57ms/step - loss: 1.3847 - accuracy: 0.2449 - val_loss: 1.3811 - val_accuracy: 0.3750\n",
      "Epoch 16/30\n",
      "835/835 [==============================] - 48s 57ms/step - loss: 1.3847 - accuracy: 0.2434 - val_loss: 1.3811 - val_accuracy: 0.3750\n",
      "Epoch 17/30\n",
      "835/835 [==============================] - 47s 57ms/step - loss: 1.3846 - accuracy: 0.2441 - val_loss: 1.3811 - val_accuracy: 0.3750\n",
      "Epoch 18/30\n",
      "835/835 [==============================] - 47s 56ms/step - loss: 1.3847 - accuracy: 0.2441 - val_loss: 1.3811 - val_accuracy: 0.3750\n",
      "Epoch 19/30\n",
      "835/835 [==============================] - 47s 57ms/step - loss: 1.3847 - accuracy: 0.2413 - val_loss: 1.3811 - val_accuracy: 0.3750\n",
      "Epoch 20/30\n",
      "835/835 [==============================] - 48s 57ms/step - loss: 1.3847 - accuracy: 0.2443 - val_loss: 1.3811 - val_accuracy: 0.3750\n",
      "Epoch 21/30\n",
      "835/835 [==============================] - 47s 57ms/step - loss: 1.3847 - accuracy: 0.2425 - val_loss: 1.3811 - val_accuracy: 0.3750\n",
      "Epoch 22/30\n",
      "835/835 [==============================] - 47s 57ms/step - loss: 1.3846 - accuracy: 0.2470 - val_loss: 1.3811 - val_accuracy: 0.3750\n",
      "Epoch 23/30\n",
      "835/835 [==============================] - 47s 57ms/step - loss: 1.3847 - accuracy: 0.2423 - val_loss: 1.3811 - val_accuracy: 0.3750\n",
      "Epoch 24/30\n",
      "835/835 [==============================] - 47s 57ms/step - loss: 1.3847 - accuracy: 0.2446 - val_loss: 1.3811 - val_accuracy: 0.3750\n",
      "Epoch 25/30\n",
      "835/835 [==============================] - 47s 57ms/step - loss: 1.3848 - accuracy: 0.2425 - val_loss: 1.3811 - val_accuracy: 0.3750\n",
      "Epoch 26/30\n",
      "835/835 [==============================] - 47s 57ms/step - loss: 1.3847 - accuracy: 0.2465 - val_loss: 1.3811 - val_accuracy: 0.3750\n",
      "Epoch 27/30\n",
      "835/835 [==============================] - 47s 57ms/step - loss: 1.3848 - accuracy: 0.2415 - val_loss: 1.3811 - val_accuracy: 0.3750\n",
      "Epoch 28/30\n",
      "835/835 [==============================] - 47s 57ms/step - loss: 1.3847 - accuracy: 0.2416 - val_loss: 1.3811 - val_accuracy: 0.3750\n",
      "Epoch 29/30\n",
      "835/835 [==============================] - 47s 57ms/step - loss: 1.3847 - accuracy: 0.2462 - val_loss: 1.3811 - val_accuracy: 0.3750\n",
      "Epoch 30/30\n",
      "835/835 [==============================] - 47s 56ms/step - loss: 1.3846 - accuracy: 0.2467 - val_loss: 1.3811 - val_accuracy: 0.3750\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_41742.0_images_False_newWeights_True_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.282025\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training opticnet for 0.5% of train size (aka 41742 images) with pretrained: True and onlyLastLayersTrained: True...\n",
      "\n",
      "Total: 276 trainable: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "835/835 [==============================] - 251s 293ms/step - loss: 287.5638 - accuracy: 0.1371 - val_loss: 217.3077 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "835/835 [==============================] - 241s 288ms/step - loss: 287.2843 - accuracy: 0.1380 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "835/835 [==============================] - 241s 288ms/step - loss: 288.2123 - accuracy: 0.1351 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "835/835 [==============================] - 240s 288ms/step - loss: 286.7500 - accuracy: 0.1383 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "835/835 [==============================] - 241s 288ms/step - loss: 289.9055 - accuracy: 0.1339 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "835/835 [==============================] - 241s 288ms/step - loss: 289.0062 - accuracy: 0.1364 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "835/835 [==============================] - 241s 288ms/step - loss: 288.3150 - accuracy: 0.1372 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "835/835 [==============================] - 241s 288ms/step - loss: 288.3477 - accuracy: 0.1369 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "835/835 [==============================] - 241s 288ms/step - loss: 287.9400 - accuracy: 0.1396 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "835/835 [==============================] - 241s 288ms/step - loss: 288.8593 - accuracy: 0.1359 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "835/835 [==============================] - 240s 288ms/step - loss: 290.0193 - accuracy: 0.1337 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "835/835 [==============================] - 241s 288ms/step - loss: 287.8676 - accuracy: 0.1377 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "835/835 [==============================] - 241s 288ms/step - loss: 286.3565 - accuracy: 0.1412 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "835/835 [==============================] - 241s 288ms/step - loss: 287.9681 - accuracy: 0.1360 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "835/835 [==============================] - 241s 288ms/step - loss: 288.0051 - accuracy: 0.1364 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "835/835 [==============================] - 241s 288ms/step - loss: 289.9701 - accuracy: 0.1372 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "835/835 [==============================] - 241s 288ms/step - loss: 288.0079 - accuracy: 0.1363 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "835/835 [==============================] - 241s 288ms/step - loss: 286.3005 - accuracy: 0.1390 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "835/835 [==============================] - 241s 288ms/step - loss: 287.9382 - accuracy: 0.1383 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "835/835 [==============================] - 240s 288ms/step - loss: 288.6219 - accuracy: 0.1353 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "835/835 [==============================] - 241s 288ms/step - loss: 287.8466 - accuracy: 0.1373 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "835/835 [==============================] - 241s 288ms/step - loss: 288.9471 - accuracy: 0.1385 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "835/835 [==============================] - 241s 288ms/step - loss: 289.0542 - accuracy: 0.1380 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "835/835 [==============================] - 240s 288ms/step - loss: 286.9925 - accuracy: 0.1404 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "835/835 [==============================] - 240s 288ms/step - loss: 287.8474 - accuracy: 0.1373 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "835/835 [==============================] - 240s 288ms/step - loss: 288.2371 - accuracy: 0.1414 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "835/835 [==============================] - 240s 288ms/step - loss: 288.0627 - accuracy: 0.1364 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "835/835 [==============================] - 240s 288ms/step - loss: 288.4609 - accuracy: 0.1365 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "835/835 [==============================] - 240s 288ms/step - loss: 289.8156 - accuracy: 0.1358 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "835/835 [==============================] - 240s 288ms/step - loss: 288.9972 - accuracy: 0.1347 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../opticnet/opticnet_30epochs_41742.0_images_False_newWeights_True_lastLayerOnly_rescale-symmetric_normalization/assets\n",
      "Test acc for opticnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.59832795 0.59790351 0.60750793 0.6042247 ]\n",
      "Training xception for 0.6% of train size (aka 50090 images) with pretrained: True and onlyLastLayersTrained: True...\n",
      "\n",
      "Total: 135 trainable: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "   6/1002 [..............................] - ETA: 8:54 - loss: 1.3836 - accuracy: 0.3979 WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1183s vs `on_train_batch_begin` time: 0.1420s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1183s vs `on_train_batch_end` time: 0.2069s). Check your callbacks.\n",
      "1002/1002 [==============================] - 127s 124ms/step - loss: 1.3822 - accuracy: 0.4243 - val_loss: 1.3864 - val_accuracy: 0.2188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "1002/1002 [==============================] - 122s 122ms/step - loss: 1.3822 - accuracy: 0.4247 - val_loss: 1.3864 - val_accuracy: 0.2188\n",
      "Epoch 3/30\n",
      "1002/1002 [==============================] - 123s 122ms/step - loss: 1.3822 - accuracy: 0.4213 - val_loss: 1.3864 - val_accuracy: 0.2188\n",
      "Epoch 4/30\n",
      "1002/1002 [==============================] - 123s 122ms/step - loss: 1.3823 - accuracy: 0.4201 - val_loss: 1.3864 - val_accuracy: 0.2188\n",
      "Epoch 5/30\n",
      "1002/1002 [==============================] - 123s 122ms/step - loss: 1.3822 - accuracy: 0.4261 - val_loss: 1.3864 - val_accuracy: 0.2188\n",
      "Epoch 6/30\n",
      "1002/1002 [==============================] - 123s 122ms/step - loss: 1.3821 - accuracy: 0.4229 - val_loss: 1.3864 - val_accuracy: 0.2188\n",
      "Epoch 7/30\n",
      "1002/1002 [==============================] - 123s 122ms/step - loss: 1.3824 - accuracy: 0.4240 - val_loss: 1.3864 - val_accuracy: 0.2188\n",
      "Epoch 8/30\n",
      "1002/1002 [==============================] - 123s 123ms/step - loss: 1.3823 - accuracy: 0.4227 - val_loss: 1.3864 - val_accuracy: 0.2188\n",
      "Epoch 9/30\n",
      "1002/1002 [==============================] - 123s 123ms/step - loss: 1.3821 - accuracy: 0.4240 - val_loss: 1.3864 - val_accuracy: 0.2188\n",
      "Epoch 10/30\n",
      "1002/1002 [==============================] - 123s 123ms/step - loss: 1.3822 - accuracy: 0.4248 - val_loss: 1.3864 - val_accuracy: 0.2188\n",
      "Epoch 11/30\n",
      "1002/1002 [==============================] - 123s 122ms/step - loss: 1.3823 - accuracy: 0.4251 - val_loss: 1.3864 - val_accuracy: 0.2188\n",
      "Epoch 12/30\n",
      "1002/1002 [==============================] - 123s 122ms/step - loss: 1.3822 - accuracy: 0.4247 - val_loss: 1.3864 - val_accuracy: 0.2188\n",
      "Epoch 13/30\n",
      "1002/1002 [==============================] - 123s 122ms/step - loss: 1.3822 - accuracy: 0.4263 - val_loss: 1.3864 - val_accuracy: 0.2188\n",
      "Epoch 14/30\n",
      "1002/1002 [==============================] - 123s 122ms/step - loss: 1.3822 - accuracy: 0.4220 - val_loss: 1.3864 - val_accuracy: 0.2188\n",
      "Epoch 15/30\n",
      "1002/1002 [==============================] - 123s 123ms/step - loss: 1.3820 - accuracy: 0.4267 - val_loss: 1.3864 - val_accuracy: 0.2188\n",
      "Epoch 16/30\n",
      "1002/1002 [==============================] - 123s 123ms/step - loss: 1.3823 - accuracy: 0.4186 - val_loss: 1.3864 - val_accuracy: 0.2188\n",
      "Epoch 17/30\n",
      "1002/1002 [==============================] - 123s 123ms/step - loss: 1.3822 - accuracy: 0.4253 - val_loss: 1.3864 - val_accuracy: 0.2188\n",
      "Epoch 18/30\n",
      "1002/1002 [==============================] - 123s 123ms/step - loss: 1.3820 - accuracy: 0.4264 - val_loss: 1.3864 - val_accuracy: 0.2188\n",
      "Epoch 19/30\n",
      "1002/1002 [==============================] - 122s 122ms/step - loss: 1.3826 - accuracy: 0.4178 - val_loss: 1.3864 - val_accuracy: 0.2188\n",
      "Epoch 20/30\n",
      "1002/1002 [==============================] - 123s 122ms/step - loss: 1.3821 - accuracy: 0.4262 - val_loss: 1.3864 - val_accuracy: 0.2188\n",
      "Epoch 21/30\n",
      "1002/1002 [==============================] - 123s 122ms/step - loss: 1.3824 - accuracy: 0.4203 - val_loss: 1.3864 - val_accuracy: 0.2188\n",
      "Epoch 22/30\n",
      "1002/1002 [==============================] - 123s 122ms/step - loss: 1.3822 - accuracy: 0.4250 - val_loss: 1.3864 - val_accuracy: 0.2188\n",
      "Epoch 23/30\n",
      "1002/1002 [==============================] - 123s 122ms/step - loss: 1.3823 - accuracy: 0.4218 - val_loss: 1.3864 - val_accuracy: 0.2188\n",
      "Epoch 24/30\n",
      "1002/1002 [==============================] - 122s 122ms/step - loss: 1.3823 - accuracy: 0.4207 - val_loss: 1.3864 - val_accuracy: 0.2188\n",
      "Epoch 25/30\n",
      "1002/1002 [==============================] - 123s 122ms/step - loss: 1.3823 - accuracy: 0.4247 - val_loss: 1.3864 - val_accuracy: 0.2188\n",
      "Epoch 26/30\n",
      "1002/1002 [==============================] - 123s 122ms/step - loss: 1.3823 - accuracy: 0.4235 - val_loss: 1.3864 - val_accuracy: 0.2188\n",
      "Epoch 27/30\n",
      "1002/1002 [==============================] - 123s 123ms/step - loss: 1.3824 - accuracy: 0.4224 - val_loss: 1.3864 - val_accuracy: 0.2188\n",
      "Epoch 28/30\n",
      "1002/1002 [==============================] - 123s 123ms/step - loss: 1.3821 - accuracy: 0.4285 - val_loss: 1.3864 - val_accuracy: 0.2188\n",
      "Epoch 29/30\n",
      "1002/1002 [==============================] - 123s 122ms/step - loss: 1.3821 - accuracy: 0.4256 - val_loss: 1.3864 - val_accuracy: 0.2188\n",
      "Epoch 30/30\n",
      "1002/1002 [==============================] - 123s 123ms/step - loss: 1.3823 - accuracy: 0.4233 - val_loss: 1.3864 - val_accuracy: 0.2188\n",
      "INFO:tensorflow:Assets written to: ../xception/xception_30epochs_50090.4_images_False_newWeights_True_lastLayerOnly_rescale-symmetric_normalization/assets\n",
      "Test acc for xception: 0.260331\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training resnet for 0.6% of train size (aka 50090 images) with pretrained: True and onlyLastLayersTrained: True...\n",
      "\n",
      "Total: 178 trainable: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "   6/1002 [..............................] - ETA: 6:45 - loss: 1.3823 - accuracy: 0.3546WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0607s vs `on_train_batch_begin` time: 0.1390s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0607s vs `on_train_batch_end` time: 0.1496s). Check your callbacks.\n",
      "1002/1002 [==============================] - 63s 59ms/step - loss: 1.3796 - accuracy: 0.4024 - val_loss: 1.3828 - val_accuracy: 0.2812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "1002/1002 [==============================] - 57s 57ms/step - loss: 1.3795 - accuracy: 0.4027 - val_loss: 1.3828 - val_accuracy: 0.2812\n",
      "Epoch 3/30\n",
      "1002/1002 [==============================] - 57s 57ms/step - loss: 1.3796 - accuracy: 0.4023 - val_loss: 1.3828 - val_accuracy: 0.2812\n",
      "Epoch 4/30\n",
      "1002/1002 [==============================] - 57s 57ms/step - loss: 1.3798 - accuracy: 0.3953 - val_loss: 1.3828 - val_accuracy: 0.2812\n",
      "Epoch 5/30\n",
      "1002/1002 [==============================] - 57s 57ms/step - loss: 1.3796 - accuracy: 0.4031 - val_loss: 1.3828 - val_accuracy: 0.2812\n",
      "Epoch 6/30\n",
      "1002/1002 [==============================] - 57s 57ms/step - loss: 1.3797 - accuracy: 0.4005 - val_loss: 1.3828 - val_accuracy: 0.2812\n",
      "Epoch 7/30\n",
      "1002/1002 [==============================] - 57s 57ms/step - loss: 1.3795 - accuracy: 0.4047 - val_loss: 1.3828 - val_accuracy: 0.2812\n",
      "Epoch 8/30\n",
      "1002/1002 [==============================] - 57s 57ms/step - loss: 1.3797 - accuracy: 0.4001 - val_loss: 1.3828 - val_accuracy: 0.2812\n",
      "Epoch 9/30\n",
      "1002/1002 [==============================] - 57s 57ms/step - loss: 1.3797 - accuracy: 0.3981 - val_loss: 1.3828 - val_accuracy: 0.2812\n",
      "Epoch 10/30\n",
      "1002/1002 [==============================] - 57s 57ms/step - loss: 1.3797 - accuracy: 0.4009 - val_loss: 1.3828 - val_accuracy: 0.2812\n",
      "Epoch 11/30\n",
      "1002/1002 [==============================] - 57s 57ms/step - loss: 1.3796 - accuracy: 0.4003 - val_loss: 1.3828 - val_accuracy: 0.2812\n",
      "Epoch 12/30\n",
      "1002/1002 [==============================] - 57s 57ms/step - loss: 1.3796 - accuracy: 0.4015 - val_loss: 1.3828 - val_accuracy: 0.2812\n",
      "Epoch 13/30\n",
      "1002/1002 [==============================] - 57s 57ms/step - loss: 1.3795 - accuracy: 0.4012 - val_loss: 1.3828 - val_accuracy: 0.2812\n",
      "Epoch 14/30\n",
      "1002/1002 [==============================] - 57s 57ms/step - loss: 1.3795 - accuracy: 0.4027 - val_loss: 1.3828 - val_accuracy: 0.2812\n",
      "Epoch 15/30\n",
      "1002/1002 [==============================] - 57s 57ms/step - loss: 1.3797 - accuracy: 0.4021 - val_loss: 1.3828 - val_accuracy: 0.2812\n",
      "Epoch 16/30\n",
      "1002/1002 [==============================] - 57s 57ms/step - loss: 1.3796 - accuracy: 0.4010 - val_loss: 1.3828 - val_accuracy: 0.2812\n",
      "Epoch 17/30\n",
      "1002/1002 [==============================] - 57s 57ms/step - loss: 1.3796 - accuracy: 0.3988 - val_loss: 1.3828 - val_accuracy: 0.2812\n",
      "Epoch 18/30\n",
      "1002/1002 [==============================] - 57s 57ms/step - loss: 1.3797 - accuracy: 0.3975 - val_loss: 1.3828 - val_accuracy: 0.2812\n",
      "Epoch 19/30\n",
      "1002/1002 [==============================] - 57s 57ms/step - loss: 1.3798 - accuracy: 0.3967 - val_loss: 1.3828 - val_accuracy: 0.2812\n",
      "Epoch 20/30\n",
      "1002/1002 [==============================] - 57s 57ms/step - loss: 1.3795 - accuracy: 0.4051 - val_loss: 1.3828 - val_accuracy: 0.2812\n",
      "Epoch 21/30\n",
      "1002/1002 [==============================] - 57s 57ms/step - loss: 1.3795 - accuracy: 0.4040 - val_loss: 1.3828 - val_accuracy: 0.2812\n",
      "Epoch 22/30\n",
      "1002/1002 [==============================] - 57s 57ms/step - loss: 1.3796 - accuracy: 0.4015 - val_loss: 1.3828 - val_accuracy: 0.2812\n",
      "Epoch 23/30\n",
      "1002/1002 [==============================] - 57s 57ms/step - loss: 1.3796 - accuracy: 0.4023 - val_loss: 1.3828 - val_accuracy: 0.2812\n",
      "Epoch 24/30\n",
      "1002/1002 [==============================] - 57s 57ms/step - loss: 1.3797 - accuracy: 0.4006 - val_loss: 1.3828 - val_accuracy: 0.2812\n",
      "Epoch 25/30\n",
      "1002/1002 [==============================] - 57s 56ms/step - loss: 1.3795 - accuracy: 0.4031 - val_loss: 1.3828 - val_accuracy: 0.2812\n",
      "Epoch 26/30\n",
      "1002/1002 [==============================] - 57s 57ms/step - loss: 1.3797 - accuracy: 0.3991 - val_loss: 1.3828 - val_accuracy: 0.2812\n",
      "Epoch 27/30\n",
      "1002/1002 [==============================] - 57s 57ms/step - loss: 1.3795 - accuracy: 0.4049 - val_loss: 1.3828 - val_accuracy: 0.2812\n",
      "Epoch 28/30\n",
      "1002/1002 [==============================] - 56s 56ms/step - loss: 1.3796 - accuracy: 0.4006 - val_loss: 1.3828 - val_accuracy: 0.2812\n",
      "Epoch 29/30\n",
      "1002/1002 [==============================] - 57s 56ms/step - loss: 1.3796 - accuracy: 0.3993 - val_loss: 1.3828 - val_accuracy: 0.2812\n",
      "Epoch 30/30\n",
      "1002/1002 [==============================] - 57s 57ms/step - loss: 1.3797 - accuracy: 0.3994 - val_loss: 1.3828 - val_accuracy: 0.2812\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_50090.4_images_False_newWeights_True_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.268595\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training opticnet for 0.6% of train size (aka 50090 images) with pretrained: True and onlyLastLayersTrained: True...\n",
      "\n",
      "Total: 276 trainable: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1002/1002 [==============================] - 298s 291ms/step - loss: 289.1057 - accuracy: 0.1353 - val_loss: 217.3077 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "1002/1002 [==============================] - 288s 288ms/step - loss: 287.6328 - accuracy: 0.1377 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "1002/1002 [==============================] - 288s 288ms/step - loss: 287.6553 - accuracy: 0.1366 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "1002/1002 [==============================] - 288s 288ms/step - loss: 287.5412 - accuracy: 0.1372 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "1002/1002 [==============================] - 288s 288ms/step - loss: 288.8600 - accuracy: 0.1390 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "1002/1002 [==============================] - 289s 288ms/step - loss: 289.0934 - accuracy: 0.1357 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "1002/1002 [==============================] - 288s 288ms/step - loss: 287.3830 - accuracy: 0.1403 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "1002/1002 [==============================] - 288s 288ms/step - loss: 288.9617 - accuracy: 0.1371 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "1002/1002 [==============================] - 288s 288ms/step - loss: 288.8268 - accuracy: 0.1393 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "1002/1002 [==============================] - 288s 288ms/step - loss: 289.1100 - accuracy: 0.1374 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "1002/1002 [==============================] - 288s 287ms/step - loss: 288.1325 - accuracy: 0.1362 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "1002/1002 [==============================] - 288s 287ms/step - loss: 287.2961 - accuracy: 0.1386 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "1002/1002 [==============================] - 288s 288ms/step - loss: 289.0012 - accuracy: 0.1369 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "1002/1002 [==============================] - 288s 288ms/step - loss: 287.1023 - accuracy: 0.1395 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "1002/1002 [==============================] - 288s 288ms/step - loss: 288.7090 - accuracy: 0.1350 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "1002/1002 [==============================] - 288s 288ms/step - loss: 288.7028 - accuracy: 0.1370 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "1002/1002 [==============================] - 288s 288ms/step - loss: 288.8151 - accuracy: 0.1375 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "1002/1002 [==============================] - 288s 287ms/step - loss: 287.0861 - accuracy: 0.1388 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "1002/1002 [==============================] - 288s 287ms/step - loss: 288.5370 - accuracy: 0.1374 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "1002/1002 [==============================] - 288s 288ms/step - loss: 287.6043 - accuracy: 0.1392 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "1002/1002 [==============================] - 288s 288ms/step - loss: 288.4858 - accuracy: 0.1365 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "1002/1002 [==============================] - 288s 288ms/step - loss: 288.9485 - accuracy: 0.1373 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "1002/1002 [==============================] - 288s 288ms/step - loss: 289.9228 - accuracy: 0.1375 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "1002/1002 [==============================] - 288s 288ms/step - loss: 288.7544 - accuracy: 0.1357 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "1002/1002 [==============================] - 288s 288ms/step - loss: 288.9518 - accuracy: 0.1392 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "1002/1002 [==============================] - 288s 288ms/step - loss: 286.9901 - accuracy: 0.1395 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "1002/1002 [==============================] - 288s 287ms/step - loss: 288.1483 - accuracy: 0.1363 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "1002/1002 [==============================] - 288s 288ms/step - loss: 289.6874 - accuracy: 0.1349 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "1002/1002 [==============================] - 288s 288ms/step - loss: 289.2843 - accuracy: 0.1368 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "1002/1002 [==============================] - 288s 288ms/step - loss: 287.7070 - accuracy: 0.1399 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../opticnet/opticnet_30epochs_50090.4_images_False_newWeights_True_lastLayerOnly_rescale-symmetric_normalization/assets\n",
      "Test acc for opticnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.7466084  0.75032926 0.75625661 0.75069638]\n",
      "Training xception for 0.75% of train size (aka 62613 images) with pretrained: True and onlyLastLayersTrained: True...\n",
      "\n",
      "Total: 135 trainable: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "   6/1253 [..............................] - ETA: 11:33 - loss: 1.3881 - accuracy: 0.1997WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1171s vs `on_train_batch_begin` time: 0.1710s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1171s vs `on_train_batch_end` time: 0.1951s). Check your callbacks.\n",
      "1253/1253 [==============================] - 160s 125ms/step - loss: 1.3896 - accuracy: 0.1740 - val_loss: 1.3883 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "1253/1253 [==============================] - 153s 122ms/step - loss: 1.3893 - accuracy: 0.1771 - val_loss: 1.3883 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "1253/1253 [==============================] - 154s 123ms/step - loss: 1.3892 - accuracy: 0.1797 - val_loss: 1.3883 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "1253/1253 [==============================] - 154s 123ms/step - loss: 1.3895 - accuracy: 0.1764 - val_loss: 1.3883 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "1253/1253 [==============================] - 153s 122ms/step - loss: 1.3894 - accuracy: 0.1780 - val_loss: 1.3883 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "1253/1253 [==============================] - 154s 123ms/step - loss: 1.3893 - accuracy: 0.1780 - val_loss: 1.3883 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "1253/1253 [==============================] - 153s 122ms/step - loss: 1.3894 - accuracy: 0.1777 - val_loss: 1.3883 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "1253/1253 [==============================] - 154s 123ms/step - loss: 1.3894 - accuracy: 0.1777 - val_loss: 1.3883 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "1253/1253 [==============================] - 154s 123ms/step - loss: 1.3895 - accuracy: 0.1760 - val_loss: 1.3883 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "1253/1253 [==============================] - 153s 122ms/step - loss: 1.3895 - accuracy: 0.1764 - val_loss: 1.3883 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "1253/1253 [==============================] - 153s 122ms/step - loss: 1.3894 - accuracy: 0.1764 - val_loss: 1.3883 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "1253/1253 [==============================] - 153s 122ms/step - loss: 1.3893 - accuracy: 0.1787 - val_loss: 1.3883 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "1253/1253 [==============================] - 154s 123ms/step - loss: 1.3892 - accuracy: 0.1808 - val_loss: 1.3883 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "1253/1253 [==============================] - 153s 122ms/step - loss: 1.3893 - accuracy: 0.1779 - val_loss: 1.3883 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "1253/1253 [==============================] - 154s 123ms/step - loss: 1.3895 - accuracy: 0.1768 - val_loss: 1.3883 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "1253/1253 [==============================] - 153s 122ms/step - loss: 1.3893 - accuracy: 0.1785 - val_loss: 1.3883 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "1253/1253 [==============================] - 154s 123ms/step - loss: 1.3895 - accuracy: 0.1759 - val_loss: 1.3883 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "1253/1253 [==============================] - 154s 123ms/step - loss: 1.3895 - accuracy: 0.1762 - val_loss: 1.3883 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "1253/1253 [==============================] - 153s 122ms/step - loss: 1.3895 - accuracy: 0.1746 - val_loss: 1.3883 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "1253/1253 [==============================] - 154s 123ms/step - loss: 1.3895 - accuracy: 0.1761 - val_loss: 1.3883 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "1253/1253 [==============================] - 154s 123ms/step - loss: 1.3894 - accuracy: 0.1774 - val_loss: 1.3883 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "1253/1253 [==============================] - 154s 123ms/step - loss: 1.3894 - accuracy: 0.1766 - val_loss: 1.3883 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "1253/1253 [==============================] - 154s 123ms/step - loss: 1.3894 - accuracy: 0.1756 - val_loss: 1.3883 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "1253/1253 [==============================] - 154s 123ms/step - loss: 1.3894 - accuracy: 0.1767 - val_loss: 1.3883 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "1253/1253 [==============================] - 154s 123ms/step - loss: 1.3894 - accuracy: 0.1777 - val_loss: 1.3883 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "1253/1253 [==============================] - 154s 123ms/step - loss: 1.3894 - accuracy: 0.1780 - val_loss: 1.3883 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "1253/1253 [==============================] - 154s 123ms/step - loss: 1.3894 - accuracy: 0.1766 - val_loss: 1.3883 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "1253/1253 [==============================] - 154s 123ms/step - loss: 1.3894 - accuracy: 0.1781 - val_loss: 1.3883 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "1253/1253 [==============================] - 154s 123ms/step - loss: 1.3895 - accuracy: 0.1752 - val_loss: 1.3883 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "1253/1253 [==============================] - 153s 122ms/step - loss: 1.3894 - accuracy: 0.1755 - val_loss: 1.3883 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../xception/xception_30epochs_62613.0_images_False_newWeights_True_lastLayerOnly_rescale-symmetric_normalization/assets\n",
      "Test acc for xception: 0.257231\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training resnet for 0.75% of train size (aka 62613 images) with pretrained: True and onlyLastLayersTrained: True...\n",
      "\n",
      "Total: 178 trainable: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "   6/1253 [..............................] - ETA: 10:16 - loss: 1.3833 - accuracy: 0.3417WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0588s vs `on_train_batch_begin` time: 0.1712s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0588s vs `on_train_batch_end` time: 0.1921s). Check your callbacks.\n",
      "1253/1253 [==============================] - 79s 59ms/step - loss: 1.3827 - accuracy: 0.3303 - val_loss: 1.3890 - val_accuracy: 0.2188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "1253/1253 [==============================] - 71s 57ms/step - loss: 1.3827 - accuracy: 0.3290 - val_loss: 1.3890 - val_accuracy: 0.2188\n",
      "Epoch 3/30\n",
      "1253/1253 [==============================] - 71s 57ms/step - loss: 1.3827 - accuracy: 0.3288 - val_loss: 1.3890 - val_accuracy: 0.2188\n",
      "Epoch 4/30\n",
      "1253/1253 [==============================] - 71s 57ms/step - loss: 1.3826 - accuracy: 0.3270 - val_loss: 1.3890 - val_accuracy: 0.2188\n",
      "Epoch 5/30\n",
      "1253/1253 [==============================] - 71s 57ms/step - loss: 1.3827 - accuracy: 0.3298 - val_loss: 1.3890 - val_accuracy: 0.2188\n",
      "Epoch 6/30\n",
      "1253/1253 [==============================] - 71s 57ms/step - loss: 1.3827 - accuracy: 0.3303 - val_loss: 1.3890 - val_accuracy: 0.2188\n",
      "Epoch 7/30\n",
      "1253/1253 [==============================] - 71s 57ms/step - loss: 1.3826 - accuracy: 0.3296 - val_loss: 1.3890 - val_accuracy: 0.2188\n",
      "Epoch 8/30\n",
      "1253/1253 [==============================] - 71s 57ms/step - loss: 1.3826 - accuracy: 0.3309 - val_loss: 1.3890 - val_accuracy: 0.2188\n",
      "Epoch 9/30\n",
      "1253/1253 [==============================] - 71s 57ms/step - loss: 1.3826 - accuracy: 0.3303 - val_loss: 1.3890 - val_accuracy: 0.2188\n",
      "Epoch 10/30\n",
      "1253/1253 [==============================] - 72s 57ms/step - loss: 1.3827 - accuracy: 0.3272 - val_loss: 1.3890 - val_accuracy: 0.2188\n",
      "Epoch 11/30\n",
      "1253/1253 [==============================] - 71s 57ms/step - loss: 1.3825 - accuracy: 0.3349 - val_loss: 1.3890 - val_accuracy: 0.2188\n",
      "Epoch 12/30\n",
      "1253/1253 [==============================] - 72s 57ms/step - loss: 1.3826 - accuracy: 0.3291 - val_loss: 1.3890 - val_accuracy: 0.2188\n",
      "Epoch 13/30\n",
      "1253/1253 [==============================] - 84s 67ms/step - loss: 1.3825 - accuracy: 0.3312 - val_loss: 1.3890 - val_accuracy: 0.2188\n",
      "Epoch 14/30\n",
      "1253/1253 [==============================] - 71s 57ms/step - loss: 1.3828 - accuracy: 0.3286 - val_loss: 1.3890 - val_accuracy: 0.2188\n",
      "Epoch 15/30\n",
      "1253/1253 [==============================] - 71s 57ms/step - loss: 1.3826 - accuracy: 0.3298 - val_loss: 1.3890 - val_accuracy: 0.2188\n",
      "Epoch 16/30\n",
      "1253/1253 [==============================] - 71s 57ms/step - loss: 1.3827 - accuracy: 0.3300 - val_loss: 1.3890 - val_accuracy: 0.2188\n",
      "Epoch 17/30\n",
      "1253/1253 [==============================] - 72s 57ms/step - loss: 1.3826 - accuracy: 0.3294 - val_loss: 1.3890 - val_accuracy: 0.2188\n",
      "Epoch 18/30\n",
      "1253/1253 [==============================] - 71s 57ms/step - loss: 1.3827 - accuracy: 0.3259 - val_loss: 1.3890 - val_accuracy: 0.2188\n",
      "Epoch 19/30\n",
      "1253/1253 [==============================] - 71s 57ms/step - loss: 1.3825 - accuracy: 0.3303 - val_loss: 1.3890 - val_accuracy: 0.2188\n",
      "Epoch 20/30\n",
      "1253/1253 [==============================] - 71s 57ms/step - loss: 1.3826 - accuracy: 0.3298 - val_loss: 1.3890 - val_accuracy: 0.2188\n",
      "Epoch 21/30\n",
      "1253/1253 [==============================] - 84s 67ms/step - loss: 1.3826 - accuracy: 0.3299 - val_loss: 1.3890 - val_accuracy: 0.2188\n",
      "Epoch 22/30\n",
      "1253/1253 [==============================] - 71s 57ms/step - loss: 1.3826 - accuracy: 0.3316 - val_loss: 1.3890 - val_accuracy: 0.2188\n",
      "Epoch 23/30\n",
      "1253/1253 [==============================] - 71s 57ms/step - loss: 1.3826 - accuracy: 0.3269 - val_loss: 1.3890 - val_accuracy: 0.2188\n",
      "Epoch 24/30\n",
      "1253/1253 [==============================] - 71s 57ms/step - loss: 1.3825 - accuracy: 0.3309 - val_loss: 1.3890 - val_accuracy: 0.2188\n",
      "Epoch 25/30\n",
      "1253/1253 [==============================] - 72s 57ms/step - loss: 1.3826 - accuracy: 0.3318 - val_loss: 1.3890 - val_accuracy: 0.2188\n",
      "Epoch 26/30\n",
      "1253/1253 [==============================] - 72s 57ms/step - loss: 1.3826 - accuracy: 0.3307 - val_loss: 1.3890 - val_accuracy: 0.2188\n",
      "Epoch 27/30\n",
      "1253/1253 [==============================] - 85s 68ms/step - loss: 1.3826 - accuracy: 0.3319 - val_loss: 1.3890 - val_accuracy: 0.2188\n",
      "Epoch 28/30\n",
      "1253/1253 [==============================] - 72s 57ms/step - loss: 1.3827 - accuracy: 0.3260 - val_loss: 1.3890 - val_accuracy: 0.2188\n",
      "Epoch 29/30\n",
      "1253/1253 [==============================] - 72s 57ms/step - loss: 1.3827 - accuracy: 0.3292 - val_loss: 1.3890 - val_accuracy: 0.2188\n",
      "Epoch 30/30\n",
      "1253/1253 [==============================] - 71s 57ms/step - loss: 1.3827 - accuracy: 0.3295 - val_loss: 1.3890 - val_accuracy: 0.2188\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_62613.0_images_False_newWeights_True_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.238636\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training opticnet for 0.75% of train size (aka 62613 images) with pretrained: True and onlyLastLayersTrained: True...\n",
      "\n",
      "Total: 276 trainable: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1253/1253 [==============================] - 371s 292ms/step - loss: 288.3500 - accuracy: 0.1362 - val_loss: 217.3077 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "1253/1253 [==============================] - 361s 288ms/step - loss: 289.1524 - accuracy: 0.1348 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "1253/1253 [==============================] - 361s 288ms/step - loss: 288.4290 - accuracy: 0.1367 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "1253/1253 [==============================] - 361s 288ms/step - loss: 288.6695 - accuracy: 0.1349 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "1253/1253 [==============================] - 361s 288ms/step - loss: 287.8036 - accuracy: 0.1367 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "1253/1253 [==============================] - 363s 290ms/step - loss: 287.8047 - accuracy: 0.1360 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "1253/1253 [==============================] - 361s 288ms/step - loss: 287.3768 - accuracy: 0.1393 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "1253/1253 [==============================] - 360s 288ms/step - loss: 287.8146 - accuracy: 0.1385 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "1253/1253 [==============================] - 361s 288ms/step - loss: 289.0765 - accuracy: 0.1354 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "1253/1253 [==============================] - 361s 288ms/step - loss: 286.7121 - accuracy: 0.1383 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "1253/1253 [==============================] - 361s 288ms/step - loss: 286.9994 - accuracy: 0.1392 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "1253/1253 [==============================] - 361s 288ms/step - loss: 287.7766 - accuracy: 0.1393 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "1253/1253 [==============================] - 361s 288ms/step - loss: 288.2820 - accuracy: 0.1367 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "1253/1253 [==============================] - 360s 288ms/step - loss: 287.4471 - accuracy: 0.1373 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "1253/1253 [==============================] - 361s 288ms/step - loss: 288.6278 - accuracy: 0.1378 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "1253/1253 [==============================] - 361s 288ms/step - loss: 288.0409 - accuracy: 0.1362 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "1253/1253 [==============================] - 360s 288ms/step - loss: 287.8697 - accuracy: 0.1366 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "1253/1253 [==============================] - 361s 288ms/step - loss: 289.1775 - accuracy: 0.1368 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "1253/1253 [==============================] - 361s 288ms/step - loss: 289.1433 - accuracy: 0.1365 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "1253/1253 [==============================] - 361s 288ms/step - loss: 287.8712 - accuracy: 0.1374 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "1253/1253 [==============================] - 361s 288ms/step - loss: 288.3706 - accuracy: 0.1360 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "1253/1253 [==============================] - 361s 288ms/step - loss: 288.0985 - accuracy: 0.1378 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "1253/1253 [==============================] - 361s 288ms/step - loss: 288.8529 - accuracy: 0.1366 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "1253/1253 [==============================] - 361s 288ms/step - loss: 287.8932 - accuracy: 0.1377 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "1253/1253 [==============================] - 361s 288ms/step - loss: 286.5497 - accuracy: 0.1386 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "1253/1253 [==============================] - 361s 288ms/step - loss: 287.4701 - accuracy: 0.1385 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "1253/1253 [==============================] - 361s 288ms/step - loss: 287.9267 - accuracy: 0.1359 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "1253/1253 [==============================] - 361s 288ms/step - loss: 288.1428 - accuracy: 0.1368 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "1253/1253 [==============================] - 361s 288ms/step - loss: 287.9484 - accuracy: 0.1365 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "1253/1253 [==============================] - 361s 288ms/step - loss: 287.0642 - accuracy: 0.1384 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../opticnet/opticnet_30epochs_62613.0_images_False_newWeights_True_lastLayerOnly_rescale-symmetric_normalization/assets\n",
      "Test acc for opticnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.89918298 0.90025534 0.89857244 0.90320334]\n",
      "Training xception for 0.9% of train size (aka 75135 images) with pretrained: True and onlyLastLayersTrained: True...\n",
      "\n",
      "Total: 135 trainable: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "   6/1503 [..............................] - ETA: 16:40 - loss: 1.3713 - accuracy: 0.4232WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1222s vs `on_train_batch_begin` time: 0.2524s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1222s vs `on_train_batch_end` time: 0.2029s). Check your callbacks.\n",
      "1503/1503 [==============================] - 191s 125ms/step - loss: 1.3728 - accuracy: 0.4103 - val_loss: 1.3828 - val_accuracy: 0.2812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "1503/1503 [==============================] - 185s 123ms/step - loss: 1.3727 - accuracy: 0.4116 - val_loss: 1.3828 - val_accuracy: 0.2812\n",
      "Epoch 3/30\n",
      "1503/1503 [==============================] - 185s 123ms/step - loss: 1.3727 - accuracy: 0.4123 - val_loss: 1.3828 - val_accuracy: 0.2812\n",
      "Epoch 4/30\n",
      "1503/1503 [==============================] - 184s 123ms/step - loss: 1.3726 - accuracy: 0.4137 - val_loss: 1.3828 - val_accuracy: 0.2812\n",
      "Epoch 5/30\n",
      "1503/1503 [==============================] - 184s 123ms/step - loss: 1.3727 - accuracy: 0.4118 - val_loss: 1.3828 - val_accuracy: 0.2812\n",
      "Epoch 6/30\n",
      "1503/1503 [==============================] - 184s 123ms/step - loss: 1.3729 - accuracy: 0.4098 - val_loss: 1.3828 - val_accuracy: 0.2812\n",
      "Epoch 7/30\n",
      "1503/1503 [==============================] - 185s 123ms/step - loss: 1.3724 - accuracy: 0.4148 - val_loss: 1.3828 - val_accuracy: 0.2812\n",
      "Epoch 8/30\n",
      "1503/1503 [==============================] - 185s 123ms/step - loss: 1.3730 - accuracy: 0.4092 - val_loss: 1.3828 - val_accuracy: 0.2812\n",
      "Epoch 9/30\n",
      "1503/1503 [==============================] - 185s 123ms/step - loss: 1.3728 - accuracy: 0.4104 - val_loss: 1.3828 - val_accuracy: 0.2812\n",
      "Epoch 10/30\n",
      "1503/1503 [==============================] - 185s 123ms/step - loss: 1.3727 - accuracy: 0.4116 - val_loss: 1.3828 - val_accuracy: 0.2812\n",
      "Epoch 11/30\n",
      "1503/1503 [==============================] - 185s 123ms/step - loss: 1.3726 - accuracy: 0.4144 - val_loss: 1.3828 - val_accuracy: 0.2812\n",
      "Epoch 12/30\n",
      "1503/1503 [==============================] - 185s 123ms/step - loss: 1.3730 - accuracy: 0.4083 - val_loss: 1.3828 - val_accuracy: 0.2812\n",
      "Epoch 13/30\n",
      "1503/1503 [==============================] - 185s 123ms/step - loss: 1.3729 - accuracy: 0.4097 - val_loss: 1.3828 - val_accuracy: 0.2812\n",
      "Epoch 14/30\n",
      "1503/1503 [==============================] - 185s 123ms/step - loss: 1.3727 - accuracy: 0.4122 - val_loss: 1.3828 - val_accuracy: 0.2812\n",
      "Epoch 15/30\n",
      "1503/1503 [==============================] - 185s 123ms/step - loss: 1.3727 - accuracy: 0.4121 - val_loss: 1.3828 - val_accuracy: 0.2812\n",
      "Epoch 16/30\n",
      "1503/1503 [==============================] - 186s 124ms/step - loss: 1.3728 - accuracy: 0.4109 - val_loss: 1.3828 - val_accuracy: 0.2812\n",
      "Epoch 17/30\n",
      "1503/1503 [==============================] - 186s 124ms/step - loss: 1.3728 - accuracy: 0.4096 - val_loss: 1.3828 - val_accuracy: 0.2812\n",
      "Epoch 18/30\n",
      "1503/1503 [==============================] - 185s 123ms/step - loss: 1.3727 - accuracy: 0.4124 - val_loss: 1.3828 - val_accuracy: 0.2812\n",
      "Epoch 19/30\n",
      "1503/1503 [==============================] - 184s 123ms/step - loss: 1.3726 - accuracy: 0.4129 - val_loss: 1.3828 - val_accuracy: 0.2812\n",
      "Epoch 20/30\n",
      "1503/1503 [==============================] - 184s 123ms/step - loss: 1.3728 - accuracy: 0.4096 - val_loss: 1.3828 - val_accuracy: 0.2812\n",
      "Epoch 21/30\n",
      "1503/1503 [==============================] - 184s 122ms/step - loss: 1.3730 - accuracy: 0.4087 - val_loss: 1.3828 - val_accuracy: 0.2812\n",
      "Epoch 22/30\n",
      "1503/1503 [==============================] - 184s 122ms/step - loss: 1.3730 - accuracy: 0.4090 - val_loss: 1.3828 - val_accuracy: 0.2812\n",
      "Epoch 23/30\n",
      "1503/1503 [==============================] - 184s 123ms/step - loss: 1.3728 - accuracy: 0.4099 - val_loss: 1.3828 - val_accuracy: 0.2812\n",
      "Epoch 24/30\n",
      "1503/1503 [==============================] - 185s 123ms/step - loss: 1.3726 - accuracy: 0.4132 - val_loss: 1.3828 - val_accuracy: 0.2812\n",
      "Epoch 25/30\n",
      "1503/1503 [==============================] - 184s 123ms/step - loss: 1.3727 - accuracy: 0.4118 - val_loss: 1.3828 - val_accuracy: 0.2812\n",
      "Epoch 26/30\n",
      "1503/1503 [==============================] - 184s 123ms/step - loss: 1.3728 - accuracy: 0.4106 - val_loss: 1.3828 - val_accuracy: 0.2812\n",
      "Epoch 27/30\n",
      "1503/1503 [==============================] - 184s 123ms/step - loss: 1.3728 - accuracy: 0.4106 - val_loss: 1.3828 - val_accuracy: 0.2812\n",
      "Epoch 28/30\n",
      "1503/1503 [==============================] - 184s 122ms/step - loss: 1.3728 - accuracy: 0.4111 - val_loss: 1.3828 - val_accuracy: 0.2812\n",
      "Epoch 29/30\n",
      "1503/1503 [==============================] - 184s 122ms/step - loss: 1.3728 - accuracy: 0.4113 - val_loss: 1.3828 - val_accuracy: 0.2812\n",
      "Epoch 30/30\n",
      "1503/1503 [==============================] - 184s 122ms/step - loss: 1.3729 - accuracy: 0.4091 - val_loss: 1.3828 - val_accuracy: 0.2812\n",
      "INFO:tensorflow:Assets written to: ../xception/xception_30epochs_75135.6_images_False_newWeights_True_lastLayerOnly_rescale-symmetric_normalization/assets\n",
      "Test acc for xception: 0.243802\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training resnet for 0.9% of train size (aka 75135 images) with pretrained: True and onlyLastLayersTrained: True...\n",
      "\n",
      "Total: 178 trainable: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "   6/1503 [..............................] - ETA: 12:18 - loss: 1.3773 - accuracy: 0.3706WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0613s vs `on_train_batch_begin` time: 0.1679s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0613s vs `on_train_batch_end` time: 0.1925s). Check your callbacks.\n",
      "1503/1503 [==============================] - 92s 58ms/step - loss: 1.3776 - accuracy: 0.3790 - val_loss: 1.3826 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "1503/1503 [==============================] - 86s 57ms/step - loss: 1.3775 - accuracy: 0.3809 - val_loss: 1.3826 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "1503/1503 [==============================] - 86s 57ms/step - loss: 1.3776 - accuracy: 0.3786 - val_loss: 1.3826 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "1503/1503 [==============================] - 86s 57ms/step - loss: 1.3777 - accuracy: 0.3773 - val_loss: 1.3826 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "1503/1503 [==============================] - 86s 57ms/step - loss: 1.3777 - accuracy: 0.3793 - val_loss: 1.3826 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "1503/1503 [==============================] - 85s 57ms/step - loss: 1.3775 - accuracy: 0.3810 - val_loss: 1.3826 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "1503/1503 [==============================] - 85s 57ms/step - loss: 1.3776 - accuracy: 0.3795 - val_loss: 1.3826 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "1503/1503 [==============================] - 85s 57ms/step - loss: 1.3775 - accuracy: 0.3826 - val_loss: 1.3826 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "1503/1503 [==============================] - 85s 57ms/step - loss: 1.3776 - accuracy: 0.3792 - val_loss: 1.3826 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "1503/1503 [==============================] - 86s 57ms/step - loss: 1.3776 - accuracy: 0.3799 - val_loss: 1.3826 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "1503/1503 [==============================] - 85s 57ms/step - loss: 1.3777 - accuracy: 0.3786 - val_loss: 1.3826 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "1503/1503 [==============================] - 85s 57ms/step - loss: 1.3776 - accuracy: 0.3789 - val_loss: 1.3826 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "1503/1503 [==============================] - 85s 57ms/step - loss: 1.3776 - accuracy: 0.3784 - val_loss: 1.3826 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "1503/1503 [==============================] - 85s 57ms/step - loss: 1.3776 - accuracy: 0.3776 - val_loss: 1.3826 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "1503/1503 [==============================] - 85s 57ms/step - loss: 1.3776 - accuracy: 0.3809 - val_loss: 1.3826 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "1503/1503 [==============================] - 85s 57ms/step - loss: 1.3775 - accuracy: 0.3811 - val_loss: 1.3826 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "1503/1503 [==============================] - 85s 57ms/step - loss: 1.3774 - accuracy: 0.3815 - val_loss: 1.3826 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "1503/1503 [==============================] - 86s 57ms/step - loss: 1.3775 - accuracy: 0.3788 - val_loss: 1.3826 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "1503/1503 [==============================] - 86s 57ms/step - loss: 1.3776 - accuracy: 0.3782 - val_loss: 1.3826 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "1503/1503 [==============================] - 85s 57ms/step - loss: 1.3775 - accuracy: 0.3835 - val_loss: 1.3826 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "1503/1503 [==============================] - 85s 57ms/step - loss: 1.3775 - accuracy: 0.3811 - val_loss: 1.3826 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "1503/1503 [==============================] - 85s 57ms/step - loss: 1.3774 - accuracy: 0.3840 - val_loss: 1.3826 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "1503/1503 [==============================] - 85s 57ms/step - loss: 1.3775 - accuracy: 0.3817 - val_loss: 1.3826 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "1503/1503 [==============================] - 85s 57ms/step - loss: 1.3775 - accuracy: 0.3792 - val_loss: 1.3826 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "1503/1503 [==============================] - 85s 57ms/step - loss: 1.3777 - accuracy: 0.3766 - val_loss: 1.3826 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "1503/1503 [==============================] - 85s 57ms/step - loss: 1.3777 - accuracy: 0.3778 - val_loss: 1.3826 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "1503/1503 [==============================] - 85s 57ms/step - loss: 1.3777 - accuracy: 0.3783 - val_loss: 1.3826 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "1503/1503 [==============================] - 85s 57ms/step - loss: 1.3775 - accuracy: 0.3799 - val_loss: 1.3826 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "1503/1503 [==============================] - 85s 57ms/step - loss: 1.3776 - accuracy: 0.3778 - val_loss: 1.3826 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "1503/1503 [==============================] - 85s 57ms/step - loss: 1.3775 - accuracy: 0.3800 - val_loss: 1.3826 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_75135.6_images_False_newWeights_True_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.268595\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training opticnet for 0.9% of train size (aka 75135 images) with pretrained: True and onlyLastLayersTrained: True...\n",
      "\n",
      "Total: 276 trainable: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1503/1503 [==============================] - 443s 291ms/step - loss: 288.3704 - accuracy: 0.1364 - val_loss: 217.3077 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "1503/1503 [==============================] - 433s 288ms/step - loss: 289.1993 - accuracy: 0.1349 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "1503/1503 [==============================] - 433s 288ms/step - loss: 289.3387 - accuracy: 0.1339 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "1503/1503 [==============================] - 433s 288ms/step - loss: 287.8082 - accuracy: 0.1348 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "1503/1503 [==============================] - 434s 289ms/step - loss: 287.1753 - accuracy: 0.1368 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "1503/1503 [==============================] - 433s 288ms/step - loss: 289.2916 - accuracy: 0.1364 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "1503/1503 [==============================] - 433s 288ms/step - loss: 288.9797 - accuracy: 0.1357 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "1503/1503 [==============================] - 433s 288ms/step - loss: 288.9809 - accuracy: 0.1351 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "1503/1503 [==============================] - 433s 288ms/step - loss: 289.3512 - accuracy: 0.1361 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "1503/1503 [==============================] - 433s 288ms/step - loss: 288.7787 - accuracy: 0.1352 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "1503/1503 [==============================] - 433s 288ms/step - loss: 288.7359 - accuracy: 0.1340 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "1503/1503 [==============================] - 433s 288ms/step - loss: 288.9349 - accuracy: 0.1344 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "1503/1503 [==============================] - 433s 288ms/step - loss: 288.4854 - accuracy: 0.1374 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "1503/1503 [==============================] - 433s 288ms/step - loss: 289.7020 - accuracy: 0.1362 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "1503/1503 [==============================] - 433s 288ms/step - loss: 289.5223 - accuracy: 0.1336 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "1503/1503 [==============================] - 433s 288ms/step - loss: 289.1298 - accuracy: 0.1345 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "1503/1503 [==============================] - 433s 288ms/step - loss: 288.6956 - accuracy: 0.1342 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "1503/1503 [==============================] - 433s 288ms/step - loss: 289.2714 - accuracy: 0.1346 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "1503/1503 [==============================] - 433s 288ms/step - loss: 288.0523 - accuracy: 0.1370 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "1503/1503 [==============================] - 433s 288ms/step - loss: 289.4505 - accuracy: 0.1343 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "1503/1503 [==============================] - 433s 288ms/step - loss: 288.2808 - accuracy: 0.1361 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "1503/1503 [==============================] - 433s 288ms/step - loss: 288.8271 - accuracy: 0.1358 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "1503/1503 [==============================] - 433s 288ms/step - loss: 288.2694 - accuracy: 0.1368 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "1503/1503 [==============================] - 433s 288ms/step - loss: 288.1775 - accuracy: 0.1341 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "1503/1503 [==============================] - 433s 288ms/step - loss: 287.4425 - accuracy: 0.1371 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "1503/1503 [==============================] - 432s 288ms/step - loss: 289.3881 - accuracy: 0.1349 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "1503/1503 [==============================] - 433s 288ms/step - loss: 289.0688 - accuracy: 0.1339 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "1503/1503 [==============================] - 433s 288ms/step - loss: 288.9255 - accuracy: 0.1349 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "1503/1503 [==============================] - 433s 288ms/step - loss: 289.3625 - accuracy: 0.1344 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "1503/1503 [==============================] - 433s 288ms/step - loss: 287.4693 - accuracy: 0.1374 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../opticnet/opticnet_30epochs_75135.6_images_False_newWeights_True_lastLayerOnly_rescale-symmetric_normalization/assets\n",
      "Test acc for opticnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [1. 1. 1. 1.]\n",
      "Training xception for 1.0% of train size (aka 83484 images) with pretrained: True and onlyLastLayersTrained: True...\n",
      "\n",
      "Total: 135 trainable: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "   6/1670 [..............................] - ETA: 16:23 - loss: 1.4075 - accuracy: 0.0918WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1148s vs `on_train_batch_begin` time: 0.1774s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1148s vs `on_train_batch_end` time: 0.2200s). Check your callbacks.\n",
      "1670/1670 [==============================] - 210s 123ms/step - loss: 1.4018 - accuracy: 0.1276 - val_loss: 1.3910 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "1670/1670 [==============================] - 205s 123ms/step - loss: 1.4016 - accuracy: 0.1274 - val_loss: 1.3910 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "1670/1670 [==============================] - 205s 123ms/step - loss: 1.4016 - accuracy: 0.1277 - val_loss: 1.3910 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "1670/1670 [==============================] - 205s 123ms/step - loss: 1.4017 - accuracy: 0.1270 - val_loss: 1.3910 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "1670/1670 [==============================] - 205s 123ms/step - loss: 1.4019 - accuracy: 0.1243 - val_loss: 1.3910 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "1670/1670 [==============================] - 205s 123ms/step - loss: 1.4016 - accuracy: 0.1275 - val_loss: 1.3910 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "1670/1670 [==============================] - 205s 123ms/step - loss: 1.4014 - accuracy: 0.1286 - val_loss: 1.3910 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "1670/1670 [==============================] - 205s 123ms/step - loss: 1.4015 - accuracy: 0.1285 - val_loss: 1.3910 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "1670/1670 [==============================] - 205s 123ms/step - loss: 1.4015 - accuracy: 0.1274 - val_loss: 1.3910 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "1670/1670 [==============================] - 205s 123ms/step - loss: 1.4016 - accuracy: 0.1268 - val_loss: 1.3910 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "1670/1670 [==============================] - 205s 123ms/step - loss: 1.4016 - accuracy: 0.1276 - val_loss: 1.3910 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "1670/1670 [==============================] - 205s 123ms/step - loss: 1.4016 - accuracy: 0.1268 - val_loss: 1.3910 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "1670/1670 [==============================] - 205s 123ms/step - loss: 1.4015 - accuracy: 0.1278 - val_loss: 1.3910 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "1670/1670 [==============================] - 205s 123ms/step - loss: 1.4019 - accuracy: 0.1238 - val_loss: 1.3910 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "1670/1670 [==============================] - 205s 123ms/step - loss: 1.4017 - accuracy: 0.1270 - val_loss: 1.3910 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "1670/1670 [==============================] - 205s 123ms/step - loss: 1.4018 - accuracy: 0.1254 - val_loss: 1.3910 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "1670/1670 [==============================] - 205s 122ms/step - loss: 1.4016 - accuracy: 0.1271 - val_loss: 1.3910 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "1670/1670 [==============================] - 205s 123ms/step - loss: 1.4017 - accuracy: 0.1258 - val_loss: 1.3910 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "1670/1670 [==============================] - 205s 123ms/step - loss: 1.4017 - accuracy: 0.1265 - val_loss: 1.3910 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "1670/1670 [==============================] - 205s 123ms/step - loss: 1.4017 - accuracy: 0.1284 - val_loss: 1.3910 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "1670/1670 [==============================] - 205s 123ms/step - loss: 1.4015 - accuracy: 0.1298 - val_loss: 1.3910 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "1670/1670 [==============================] - 205s 123ms/step - loss: 1.4019 - accuracy: 0.1267 - val_loss: 1.3910 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "1670/1670 [==============================] - 205s 123ms/step - loss: 1.4016 - accuracy: 0.1292 - val_loss: 1.3910 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "1670/1670 [==============================] - 205s 123ms/step - loss: 1.4017 - accuracy: 0.1263 - val_loss: 1.3910 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "1670/1670 [==============================] - 205s 123ms/step - loss: 1.4015 - accuracy: 0.1295 - val_loss: 1.3910 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "1670/1670 [==============================] - 204s 122ms/step - loss: 1.4017 - accuracy: 0.1255 - val_loss: 1.3910 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "1670/1670 [==============================] - 205s 123ms/step - loss: 1.4016 - accuracy: 0.1270 - val_loss: 1.3910 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "1670/1670 [==============================] - 205s 123ms/step - loss: 1.4017 - accuracy: 0.1274 - val_loss: 1.3910 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "1670/1670 [==============================] - 205s 123ms/step - loss: 1.4016 - accuracy: 0.1276 - val_loss: 1.3910 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "1670/1670 [==============================] - 205s 123ms/step - loss: 1.4015 - accuracy: 0.1295 - val_loss: 1.3910 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../xception/xception_30epochs_83484.0_images_False_newWeights_True_lastLayerOnly_rescale-symmetric_normalization/assets\n",
      "Test acc for xception: 0.253099\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training resnet for 1.0% of train size (aka 83484 images) with pretrained: True and onlyLastLayersTrained: True...\n",
      "\n",
      "Total: 178 trainable: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "   6/1670 [..............................] - ETA: 14:54 - loss: 1.3866 - accuracy: 0.2147WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0630s vs `on_train_batch_begin` time: 0.1981s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0630s vs `on_train_batch_end` time: 0.1974s). Check your callbacks.\n",
      "1670/1670 [==============================] - 107s 58ms/step - loss: 1.3870 - accuracy: 0.2153 - val_loss: 1.3835 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "1670/1670 [==============================] - 93s 56ms/step - loss: 1.3870 - accuracy: 0.2169 - val_loss: 1.3835 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "1670/1670 [==============================] - 94s 56ms/step - loss: 1.3869 - accuracy: 0.2166 - val_loss: 1.3835 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "1670/1670 [==============================] - 94s 56ms/step - loss: 1.3870 - accuracy: 0.2141 - val_loss: 1.3835 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "1670/1670 [==============================] - 94s 56ms/step - loss: 1.3870 - accuracy: 0.2144 - val_loss: 1.3835 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "1670/1670 [==============================] - 94s 56ms/step - loss: 1.3869 - accuracy: 0.2199 - val_loss: 1.3835 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "1670/1670 [==============================] - 94s 56ms/step - loss: 1.3870 - accuracy: 0.2170 - val_loss: 1.3835 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "1670/1670 [==============================] - 93s 56ms/step - loss: 1.3869 - accuracy: 0.2170 - val_loss: 1.3835 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "1670/1670 [==============================] - 93s 56ms/step - loss: 1.3870 - accuracy: 0.2188 - val_loss: 1.3835 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "1670/1670 [==============================] - 94s 56ms/step - loss: 1.3869 - accuracy: 0.2177 - val_loss: 1.3835 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "1670/1670 [==============================] - 94s 56ms/step - loss: 1.3871 - accuracy: 0.2134 - val_loss: 1.3835 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "1670/1670 [==============================] - 93s 56ms/step - loss: 1.3870 - accuracy: 0.2159 - val_loss: 1.3835 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "1670/1670 [==============================] - 93s 56ms/step - loss: 1.3870 - accuracy: 0.2160 - val_loss: 1.3835 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "1670/1670 [==============================] - 94s 56ms/step - loss: 1.3870 - accuracy: 0.2148 - val_loss: 1.3835 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "1670/1670 [==============================] - 94s 56ms/step - loss: 1.3870 - accuracy: 0.2179 - val_loss: 1.3835 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "1670/1670 [==============================] - 93s 56ms/step - loss: 1.3870 - accuracy: 0.2175 - val_loss: 1.3835 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "1670/1670 [==============================] - 94s 56ms/step - loss: 1.3870 - accuracy: 0.2176 - val_loss: 1.3835 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "1670/1670 [==============================] - 94s 56ms/step - loss: 1.3870 - accuracy: 0.2143 - val_loss: 1.3835 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "1670/1670 [==============================] - 94s 56ms/step - loss: 1.3870 - accuracy: 0.2167 - val_loss: 1.3835 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "1670/1670 [==============================] - 94s 56ms/step - loss: 1.3870 - accuracy: 0.2167 - val_loss: 1.3835 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "1670/1670 [==============================] - 94s 56ms/step - loss: 1.3870 - accuracy: 0.2165 - val_loss: 1.3835 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "1670/1670 [==============================] - 93s 56ms/step - loss: 1.3870 - accuracy: 0.2156 - val_loss: 1.3835 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "1670/1670 [==============================] - 94s 56ms/step - loss: 1.3870 - accuracy: 0.2157 - val_loss: 1.3835 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "1670/1670 [==============================] - 93s 56ms/step - loss: 1.3870 - accuracy: 0.2141 - val_loss: 1.3835 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "1670/1670 [==============================] - 93s 56ms/step - loss: 1.3871 - accuracy: 0.2165 - val_loss: 1.3835 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "1670/1670 [==============================] - 93s 56ms/step - loss: 1.3869 - accuracy: 0.2168 - val_loss: 1.3835 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "1670/1670 [==============================] - 93s 56ms/step - loss: 1.3871 - accuracy: 0.2162 - val_loss: 1.3835 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "1670/1670 [==============================] - 93s 56ms/step - loss: 1.3871 - accuracy: 0.2134 - val_loss: 1.3835 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "1670/1670 [==============================] - 93s 56ms/step - loss: 1.3871 - accuracy: 0.2136 - val_loss: 1.3835 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "1670/1670 [==============================] - 93s 56ms/step - loss: 1.3870 - accuracy: 0.2163 - val_loss: 1.3835 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_83484.0_images_False_newWeights_True_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.284091\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training opticnet for 1.0% of train size (aka 83484 images) with pretrained: True and onlyLastLayersTrained: True...\n",
      "\n",
      "Total: 276 trainable: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1670/1670 [==============================] - 493s 291ms/step - loss: 290.1525 - accuracy: 0.1342 - val_loss: 217.3077 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "1670/1670 [==============================] - 481s 288ms/step - loss: 287.3099 - accuracy: 0.1358 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "1670/1670 [==============================] - 480s 288ms/step - loss: 288.2027 - accuracy: 0.1375 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "1670/1670 [==============================] - 481s 288ms/step - loss: 287.8099 - accuracy: 0.1372 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "1670/1670 [==============================] - 481s 288ms/step - loss: 288.2497 - accuracy: 0.1373 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "1670/1670 [==============================] - 480s 288ms/step - loss: 289.5599 - accuracy: 0.1353 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "1670/1670 [==============================] - 481s 288ms/step - loss: 288.4218 - accuracy: 0.1354 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "1670/1670 [==============================] - 480s 288ms/step - loss: 288.8042 - accuracy: 0.1359 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "1670/1670 [==============================] - 480s 288ms/step - loss: 289.3248 - accuracy: 0.1335 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "1670/1670 [==============================] - 481s 288ms/step - loss: 288.2088 - accuracy: 0.1366 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "1670/1670 [==============================] - 481s 288ms/step - loss: 289.5141 - accuracy: 0.1357 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "1670/1670 [==============================] - 480s 288ms/step - loss: 289.2409 - accuracy: 0.1371 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "1670/1670 [==============================] - 480s 288ms/step - loss: 289.2759 - accuracy: 0.1370 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "1670/1670 [==============================] - 481s 288ms/step - loss: 288.8226 - accuracy: 0.1358 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "1670/1670 [==============================] - 481s 288ms/step - loss: 289.1407 - accuracy: 0.1335 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "1670/1670 [==============================] - 481s 288ms/step - loss: 289.1337 - accuracy: 0.1355 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "1670/1670 [==============================] - 481s 288ms/step - loss: 288.1058 - accuracy: 0.1356 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "1670/1670 [==============================] - 480s 288ms/step - loss: 289.3898 - accuracy: 0.1353 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "1670/1670 [==============================] - 481s 288ms/step - loss: 289.0189 - accuracy: 0.1354 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "1670/1670 [==============================] - 480s 287ms/step - loss: 289.0837 - accuracy: 0.1363 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "1670/1670 [==============================] - 481s 288ms/step - loss: 288.8349 - accuracy: 0.1347 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "1670/1670 [==============================] - 481s 288ms/step - loss: 289.3582 - accuracy: 0.1358 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "1670/1670 [==============================] - 481s 288ms/step - loss: 288.8710 - accuracy: 0.1349 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "1670/1670 [==============================] - 481s 288ms/step - loss: 288.6365 - accuracy: 0.1351 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "1670/1670 [==============================] - 481s 288ms/step - loss: 288.7726 - accuracy: 0.1376 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "1670/1670 [==============================] - 481s 288ms/step - loss: 289.1171 - accuracy: 0.1345 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "1670/1670 [==============================] - 481s 288ms/step - loss: 287.9662 - accuracy: 0.1354 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "1670/1670 [==============================] - 480s 288ms/step - loss: 288.9188 - accuracy: 0.1351 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "1670/1670 [==============================] - 481s 288ms/step - loss: 287.8833 - accuracy: 0.1386 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "1670/1670 [==============================] - 481s 288ms/step - loss: 288.6853 - accuracy: 0.1368 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../opticnet/opticnet_30epochs_83484.0_images_False_newWeights_True_lastLayerOnly_rescale-symmetric_normalization/assets\n",
      "Test acc for opticnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.0101463  0.00983739 0.01039831 0.00963324]\n",
      "Training xception for 0.01% of train size (aka 834 images) with pretrained: True and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 135 trainable: 135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      " 6/17 [=========>....................] - ETA: 13s - loss: 1.3777 - accuracy: 0.4698WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1718s vs `on_train_batch_end` time: 0.8228s). Check your callbacks.\n",
      "17/17 [==============================] - 21s 967ms/step - loss: 1.3619 - accuracy: 0.5941 - val_loss: 1.3577 - val_accuracy: 0.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "17/17 [==============================] - 13s 738ms/step - loss: 1.3140 - accuracy: 0.8060 - val_loss: 1.3887 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "17/17 [==============================] - 13s 737ms/step - loss: 1.2926 - accuracy: 0.8047 - val_loss: 1.3157 - val_accuracy: 0.6562\n",
      "Epoch 4/30\n",
      "17/17 [==============================] - 13s 748ms/step - loss: 1.2668 - accuracy: 0.8450 - val_loss: 1.3496 - val_accuracy: 0.4062\n",
      "Epoch 5/30\n",
      "17/17 [==============================] - 13s 746ms/step - loss: 1.2497 - accuracy: 0.8304 - val_loss: 1.3287 - val_accuracy: 0.4688\n",
      "Epoch 6/30\n",
      "17/17 [==============================] - 13s 744ms/step - loss: 1.2443 - accuracy: 0.7788 - val_loss: 1.3242 - val_accuracy: 0.5000\n",
      "Epoch 7/30\n",
      "17/17 [==============================] - 13s 751ms/step - loss: 1.2459 - accuracy: 0.7207 - val_loss: 1.3202 - val_accuracy: 0.5000\n",
      "Epoch 8/30\n",
      "17/17 [==============================] - 13s 747ms/step - loss: 1.2242 - accuracy: 0.7557 - val_loss: 1.3177 - val_accuracy: 0.5000\n",
      "Epoch 9/30\n",
      "17/17 [==============================] - 13s 754ms/step - loss: 1.2110 - accuracy: 0.7500 - val_loss: 1.3217 - val_accuracy: 0.5000\n",
      "Epoch 10/30\n",
      "17/17 [==============================] - 13s 747ms/step - loss: 1.1987 - accuracy: 0.7512 - val_loss: 1.2913 - val_accuracy: 0.5000\n",
      "Epoch 11/30\n",
      "17/17 [==============================] - 13s 747ms/step - loss: 1.1998 - accuracy: 0.7288 - val_loss: 1.2846 - val_accuracy: 0.5000\n",
      "Epoch 12/30\n",
      "17/17 [==============================] - 13s 751ms/step - loss: 1.1890 - accuracy: 0.7527 - val_loss: 1.2975 - val_accuracy: 0.5000\n",
      "Epoch 13/30\n",
      "17/17 [==============================] - 13s 744ms/step - loss: 1.1744 - accuracy: 0.7672 - val_loss: 1.2780 - val_accuracy: 0.5000\n",
      "Epoch 14/30\n",
      "17/17 [==============================] - 13s 750ms/step - loss: 1.1613 - accuracy: 0.7756 - val_loss: 1.2704 - val_accuracy: 0.5000\n",
      "Epoch 15/30\n",
      "17/17 [==============================] - 13s 750ms/step - loss: 1.1640 - accuracy: 0.7562 - val_loss: 1.2673 - val_accuracy: 0.5000\n",
      "Epoch 16/30\n",
      "17/17 [==============================] - 13s 760ms/step - loss: 1.1640 - accuracy: 0.7396 - val_loss: 1.2647 - val_accuracy: 0.5000\n",
      "Epoch 17/30\n",
      "17/17 [==============================] - 13s 747ms/step - loss: 1.1551 - accuracy: 0.7470 - val_loss: 1.2622 - val_accuracy: 0.5000\n",
      "Epoch 18/30\n",
      "17/17 [==============================] - 13s 746ms/step - loss: 1.1486 - accuracy: 0.7586 - val_loss: 1.2601 - val_accuracy: 0.5000\n",
      "Epoch 19/30\n",
      "17/17 [==============================] - 13s 748ms/step - loss: 1.1464 - accuracy: 0.7490 - val_loss: 1.2693 - val_accuracy: 0.4688\n",
      "Epoch 20/30\n",
      "17/17 [==============================] - 13s 745ms/step - loss: 1.1376 - accuracy: 0.7633 - val_loss: 1.2582 - val_accuracy: 0.5000\n",
      "Epoch 21/30\n",
      "17/17 [==============================] - 13s 748ms/step - loss: 1.1387 - accuracy: 0.7516 - val_loss: 1.2549 - val_accuracy: 0.5000\n",
      "Epoch 22/30\n",
      "17/17 [==============================] - 13s 745ms/step - loss: 1.1251 - accuracy: 0.7762 - val_loss: 1.2536 - val_accuracy: 0.5000\n",
      "Epoch 23/30\n",
      "17/17 [==============================] - 13s 750ms/step - loss: 1.1271 - accuracy: 0.7694 - val_loss: 1.2524 - val_accuracy: 0.5000\n",
      "Epoch 24/30\n",
      "17/17 [==============================] - 13s 747ms/step - loss: 1.1325 - accuracy: 0.7574 - val_loss: 1.2513 - val_accuracy: 0.5000\n",
      "Epoch 25/30\n",
      "17/17 [==============================] - 13s 751ms/step - loss: 1.1205 - accuracy: 0.7756 - val_loss: 1.2504 - val_accuracy: 0.5000\n",
      "Epoch 26/30\n",
      "17/17 [==============================] - 13s 751ms/step - loss: 1.1296 - accuracy: 0.7470 - val_loss: 1.2495 - val_accuracy: 0.5000\n",
      "Epoch 27/30\n",
      "17/17 [==============================] - 13s 750ms/step - loss: 1.1146 - accuracy: 0.7778 - val_loss: 1.2487 - val_accuracy: 0.5000\n",
      "Epoch 28/30\n",
      "17/17 [==============================] - 13s 752ms/step - loss: 1.1262 - accuracy: 0.7515 - val_loss: 1.2480 - val_accuracy: 0.5000\n",
      "Epoch 29/30\n",
      "17/17 [==============================] - 13s 791ms/step - loss: 1.1219 - accuracy: 0.7568 - val_loss: 1.2474 - val_accuracy: 0.5000\n",
      "Epoch 30/30\n",
      "17/17 [==============================] - 13s 742ms/step - loss: 1.1255 - accuracy: 0.7488 - val_loss: 1.2468 - val_accuracy: 0.5000\n",
      "INFO:tensorflow:Assets written to: ../xception/xception_30epochs_834.84_images_False_newWeights_False_lastLayerOnly_rescale-symmetric_normalization/assets\n",
      "Test acc for xception: 0.500000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training resnet for 0.01% of train size (aka 834 images) with pretrained: True and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 178 trainable: 178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      " 6/17 [=========>....................] - ETA: 7s - loss: 1.3738 - accuracy: 0.4714WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1242s vs `on_train_batch_begin` time: 0.1275s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1242s vs `on_train_batch_end` time: 0.3307s). Check your callbacks.\n",
      "17/17 [==============================] - 15s 432ms/step - loss: 1.3550 - accuracy: 0.5857 - val_loss: 1.3885 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "17/17 [==============================] - 3s 196ms/step - loss: 1.3158 - accuracy: 0.6805 - val_loss: 1.3947 - val_accuracy: 0.1875\n",
      "Epoch 3/30\n",
      "17/17 [==============================] - 3s 195ms/step - loss: 1.2996 - accuracy: 0.6790 - val_loss: 1.3936 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "17/17 [==============================] - 3s 195ms/step - loss: 1.2862 - accuracy: 0.6967 - val_loss: 1.3957 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "17/17 [==============================] - 3s 195ms/step - loss: 1.2642 - accuracy: 0.7240 - val_loss: 1.3979 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "17/17 [==============================] - 3s 195ms/step - loss: 1.2588 - accuracy: 0.7052 - val_loss: 1.4309 - val_accuracy: 0.1250\n",
      "Epoch 7/30\n",
      "17/17 [==============================] - 3s 195ms/step - loss: 1.2417 - accuracy: 0.7274 - val_loss: 1.3748 - val_accuracy: 0.3438\n",
      "Epoch 8/30\n",
      "17/17 [==============================] - 3s 195ms/step - loss: 1.2253 - accuracy: 0.7340 - val_loss: 1.3624 - val_accuracy: 0.4062\n",
      "Epoch 9/30\n",
      "17/17 [==============================] - 3s 195ms/step - loss: 1.1996 - accuracy: 0.7591 - val_loss: 1.4018 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "17/17 [==============================] - 3s 196ms/step - loss: 1.1842 - accuracy: 0.7585 - val_loss: 1.3968 - val_accuracy: 0.2812\n",
      "Epoch 11/30\n",
      "17/17 [==============================] - 3s 195ms/step - loss: 1.1768 - accuracy: 0.7442 - val_loss: 1.3194 - val_accuracy: 0.5000\n",
      "Epoch 12/30\n",
      "17/17 [==============================] - 3s 195ms/step - loss: 1.1773 - accuracy: 0.7151 - val_loss: 1.2792 - val_accuracy: 0.5000\n",
      "Epoch 13/30\n",
      "17/17 [==============================] - 3s 196ms/step - loss: 1.1785 - accuracy: 0.7200 - val_loss: 1.3289 - val_accuracy: 0.5000\n",
      "Epoch 14/30\n",
      "17/17 [==============================] - 3s 196ms/step - loss: 1.1686 - accuracy: 0.7312 - val_loss: 1.2988 - val_accuracy: 0.5000\n",
      "Epoch 15/30\n",
      "17/17 [==============================] - 3s 196ms/step - loss: 1.1675 - accuracy: 0.7171 - val_loss: 1.2656 - val_accuracy: 0.5000\n",
      "Epoch 16/30\n",
      "17/17 [==============================] - 3s 195ms/step - loss: 1.1421 - accuracy: 0.7491 - val_loss: 1.2710 - val_accuracy: 0.5000\n",
      "Epoch 17/30\n",
      "17/17 [==============================] - 3s 195ms/step - loss: 1.1468 - accuracy: 0.7380 - val_loss: 1.2690 - val_accuracy: 0.5000\n",
      "Epoch 18/30\n",
      "17/17 [==============================] - 3s 195ms/step - loss: 1.1400 - accuracy: 0.7472 - val_loss: 1.2638 - val_accuracy: 0.5000\n",
      "Epoch 19/30\n",
      "17/17 [==============================] - 3s 195ms/step - loss: 1.1295 - accuracy: 0.7493 - val_loss: 1.2617 - val_accuracy: 0.5000\n",
      "Epoch 20/30\n",
      "17/17 [==============================] - 3s 196ms/step - loss: 1.1244 - accuracy: 0.7661 - val_loss: 1.2645 - val_accuracy: 0.5000\n",
      "Epoch 21/30\n",
      "17/17 [==============================] - 3s 196ms/step - loss: 1.1301 - accuracy: 0.7539 - val_loss: 1.2636 - val_accuracy: 0.5000\n",
      "Epoch 22/30\n",
      "17/17 [==============================] - 3s 196ms/step - loss: 1.1352 - accuracy: 0.7196 - val_loss: 1.2520 - val_accuracy: 0.5000\n",
      "Epoch 23/30\n",
      "17/17 [==============================] - 3s 195ms/step - loss: 1.1221 - accuracy: 0.7457 - val_loss: 1.2502 - val_accuracy: 0.5000\n",
      "Epoch 24/30\n",
      "17/17 [==============================] - 3s 196ms/step - loss: 1.1074 - accuracy: 0.7641 - val_loss: 1.2423 - val_accuracy: 0.5000\n",
      "Epoch 25/30\n",
      "17/17 [==============================] - 3s 196ms/step - loss: 1.1127 - accuracy: 0.7536 - val_loss: 1.2446 - val_accuracy: 0.5000\n",
      "Epoch 26/30\n",
      "17/17 [==============================] - 3s 196ms/step - loss: 1.1020 - accuracy: 0.7599 - val_loss: 1.2441 - val_accuracy: 0.5000\n",
      "Epoch 27/30\n",
      "17/17 [==============================] - 3s 196ms/step - loss: 1.1073 - accuracy: 0.7593 - val_loss: 1.2412 - val_accuracy: 0.5000\n",
      "Epoch 28/30\n",
      "17/17 [==============================] - 3s 196ms/step - loss: 1.1011 - accuracy: 0.7751 - val_loss: 1.2343 - val_accuracy: 0.5000\n",
      "Epoch 29/30\n",
      "17/17 [==============================] - 3s 196ms/step - loss: 1.1170 - accuracy: 0.7356 - val_loss: 1.2320 - val_accuracy: 0.5000\n",
      "Epoch 30/30\n",
      "17/17 [==============================] - 3s 195ms/step - loss: 1.0967 - accuracy: 0.7602 - val_loss: 1.2313 - val_accuracy: 0.5000\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_834.84_images_False_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.493802\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training opticnet for 0.01% of train size (aka 834 images) with pretrained: True and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 276 trainable: 276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      " 6/17 [=========>....................] - ETA: 19s - loss: 5.4237 - accuracy: 0.1552 WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.4684s vs `on_train_batch_end` time: 1.0469s). Check your callbacks.\n",
      "17/17 [==============================] - 36s 1s/step - loss: 3.1880 - accuracy: 0.3908 - val_loss: 7.3423 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.5159 - accuracy: 0.8063 - val_loss: 4.1250 - val_accuracy: 0.3125\n",
      "Epoch 3/30\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2626 - accuracy: 0.9116 - val_loss: 1.0739 - val_accuracy: 0.5625\n",
      "Epoch 4/30\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.1634 - accuracy: 0.9421 - val_loss: 1.0633 - val_accuracy: 0.5938\n",
      "Epoch 5/30\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.0754 - accuracy: 0.9790 - val_loss: 0.6957 - val_accuracy: 0.6875\n",
      "Epoch 6/30\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.0573 - accuracy: 0.9824 - val_loss: 0.4396 - val_accuracy: 0.8125\n",
      "Epoch 7/30\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.0263 - accuracy: 0.9915 - val_loss: 0.2808 - val_accuracy: 0.8750\n",
      "Epoch 8/30\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.0152 - accuracy: 0.9964 - val_loss: 0.1032 - val_accuracy: 0.9688\n",
      "Epoch 9/30\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.0119 - accuracy: 0.9961 - val_loss: 0.1303 - val_accuracy: 0.9375\n",
      "Epoch 10/30\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0865 - val_accuracy: 0.9688\n",
      "Epoch 11/30\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0903 - val_accuracy: 0.9375\n",
      "Epoch 12/30\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0385 - val_accuracy: 1.0000\n",
      "Epoch 13/30\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.0019 - accuracy: 0.9990 - val_loss: 0.0253 - val_accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.0026 - accuracy: 0.9994 - val_loss: 0.0215 - val_accuracy: 1.0000\n",
      "Epoch 15/30\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0073 - val_accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "17/17 [==============================] - 20s 1s/step - loss: 9.7248e-04 - accuracy: 1.0000 - val_loss: 0.0097 - val_accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0056 - val_accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "17/17 [==============================] - 20s 1s/step - loss: 4.5349e-04 - accuracy: 1.0000 - val_loss: 0.0051 - val_accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "17/17 [==============================] - 20s 1s/step - loss: 7.2203e-04 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "17/17 [==============================] - 20s 1s/step - loss: 5.8480e-04 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "17/17 [==============================] - 20s 1s/step - loss: 6.2373e-04 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "17/17 [==============================] - 20s 1s/step - loss: 4.3724e-04 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "17/17 [==============================] - 20s 1s/step - loss: 4.7941e-04 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "17/17 [==============================] - 20s 1s/step - loss: 4.0179e-04 - accuracy: 1.0000 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "17/17 [==============================] - 20s 1s/step - loss: 3.9753e-04 - accuracy: 1.0000 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "17/17 [==============================] - 20s 1s/step - loss: 4.4831e-04 - accuracy: 1.0000 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "17/17 [==============================] - 20s 1s/step - loss: 5.5802e-04 - accuracy: 1.0000 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "17/17 [==============================] - 20s 1s/step - loss: 3.0560e-04 - accuracy: 1.0000 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "17/17 [==============================] - 20s 1s/step - loss: 6.8162e-04 - accuracy: 1.0000 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "17/17 [==============================] - 20s 1s/step - loss: 9.9776e-04 - accuracy: 1.0000 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
      "INFO:tensorflow:Assets written to: ../opticnet/opticnet_30epochs_834.84_images_False_newWeights_False_lastLayerOnly_rescale-symmetric_normalization/assets\n",
      "Test acc for opticnet: 0.978306\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.02451074 0.02513103 0.02467395 0.02634633]\n",
      "Training xception for 0.025% of train size (aka 2087 images) with pretrained: True and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 135 trainable: 135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      " 6/42 [===>..........................] - ETA: 45s - loss: 1.3708 - accuracy: 0.0671WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1658s vs `on_train_batch_end` time: 0.8490s). Check your callbacks.\n",
      "42/42 [==============================] - 42s 887ms/step - loss: 1.3589 - accuracy: 0.3205 - val_loss: 1.3738 - val_accuracy: 0.3438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "42/42 [==============================] - 32s 761ms/step - loss: 1.3014 - accuracy: 0.8318 - val_loss: 1.3871 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "42/42 [==============================] - 32s 762ms/step - loss: 1.2511 - accuracy: 0.8229 - val_loss: 1.3926 - val_accuracy: 0.2812\n",
      "Epoch 4/30\n",
      "42/42 [==============================] - 32s 766ms/step - loss: 1.2085 - accuracy: 0.8412 - val_loss: 1.2473 - val_accuracy: 0.7500\n",
      "Epoch 5/30\n",
      "42/42 [==============================] - 32s 765ms/step - loss: 1.1752 - accuracy: 0.8247 - val_loss: 1.2300 - val_accuracy: 0.7500\n",
      "Epoch 6/30\n",
      "42/42 [==============================] - 32s 763ms/step - loss: 1.1407 - accuracy: 0.8412 - val_loss: 1.2662 - val_accuracy: 0.6250\n",
      "Epoch 7/30\n",
      "42/42 [==============================] - 32s 773ms/step - loss: 1.1178 - accuracy: 0.8482 - val_loss: 1.1998 - val_accuracy: 0.7500\n",
      "Epoch 8/30\n",
      "42/42 [==============================] - 32s 772ms/step - loss: 1.0971 - accuracy: 0.8418 - val_loss: 1.1867 - val_accuracy: 0.7500\n",
      "Epoch 9/30\n",
      "42/42 [==============================] - 32s 769ms/step - loss: 1.0624 - accuracy: 0.8689 - val_loss: 1.1756 - val_accuracy: 0.7500\n",
      "Epoch 10/30\n",
      "42/42 [==============================] - 32s 769ms/step - loss: 1.0472 - accuracy: 0.8623 - val_loss: 1.1821 - val_accuracy: 0.7188\n",
      "Epoch 11/30\n",
      "42/42 [==============================] - 32s 764ms/step - loss: 1.0313 - accuracy: 0.8695 - val_loss: 1.1568 - val_accuracy: 0.7500\n",
      "Epoch 12/30\n",
      "42/42 [==============================] - 32s 764ms/step - loss: 1.0099 - accuracy: 0.8764 - val_loss: 1.1488 - val_accuracy: 0.7500\n",
      "Epoch 13/30\n",
      "42/42 [==============================] - 32s 764ms/step - loss: 0.9909 - accuracy: 0.8868 - val_loss: 1.1418 - val_accuracy: 0.7500\n",
      "Epoch 14/30\n",
      "42/42 [==============================] - 32s 763ms/step - loss: 0.9927 - accuracy: 0.8758 - val_loss: 1.1357 - val_accuracy: 0.7500\n",
      "Epoch 15/30\n",
      "42/42 [==============================] - 32s 765ms/step - loss: 0.9791 - accuracy: 0.8782 - val_loss: 1.1303 - val_accuracy: 0.7500\n",
      "Epoch 16/30\n",
      "42/42 [==============================] - 32s 763ms/step - loss: 0.9677 - accuracy: 0.8845 - val_loss: 1.1255 - val_accuracy: 0.7500\n",
      "Epoch 17/30\n",
      "42/42 [==============================] - 32s 765ms/step - loss: 0.9695 - accuracy: 0.8704 - val_loss: 1.1211 - val_accuracy: 0.7500\n",
      "Epoch 18/30\n",
      "42/42 [==============================] - 32s 765ms/step - loss: 0.9498 - accuracy: 0.8949 - val_loss: 1.1172 - val_accuracy: 0.7500\n",
      "Epoch 19/30\n",
      "42/42 [==============================] - 32s 762ms/step - loss: 0.9601 - accuracy: 0.8754 - val_loss: 1.1138 - val_accuracy: 0.7500\n",
      "Epoch 20/30\n",
      "42/42 [==============================] - 32s 761ms/step - loss: 0.9560 - accuracy: 0.8710 - val_loss: 1.1107 - val_accuracy: 0.7500\n",
      "Epoch 21/30\n",
      "42/42 [==============================] - 32s 766ms/step - loss: 0.9375 - accuracy: 0.8846 - val_loss: 1.1080 - val_accuracy: 0.7500\n",
      "Epoch 22/30\n",
      "42/42 [==============================] - 32s 764ms/step - loss: 0.9395 - accuracy: 0.8760 - val_loss: 1.1055 - val_accuracy: 0.7500\n",
      "Epoch 23/30\n",
      "42/42 [==============================] - 32s 762ms/step - loss: 0.9400 - accuracy: 0.8780 - val_loss: 1.1032 - val_accuracy: 0.7500\n",
      "Epoch 24/30\n",
      "42/42 [==============================] - 32s 764ms/step - loss: 0.9291 - accuracy: 0.8863 - val_loss: 1.1013 - val_accuracy: 0.7500\n",
      "Epoch 25/30\n",
      "42/42 [==============================] - 32s 763ms/step - loss: 0.9362 - accuracy: 0.8733 - val_loss: 1.0995 - val_accuracy: 0.7500\n",
      "Epoch 26/30\n",
      "42/42 [==============================] - 32s 763ms/step - loss: 0.9334 - accuracy: 0.8743 - val_loss: 1.0979 - val_accuracy: 0.7500\n",
      "Epoch 27/30\n",
      "42/42 [==============================] - 32s 768ms/step - loss: 0.9186 - accuracy: 0.8857 - val_loss: 1.0965 - val_accuracy: 0.7500\n",
      "Epoch 28/30\n",
      "42/42 [==============================] - 32s 761ms/step - loss: 0.9275 - accuracy: 0.8749 - val_loss: 1.0951 - val_accuracy: 0.7500\n",
      "Epoch 29/30\n",
      "42/42 [==============================] - 32s 765ms/step - loss: 0.9138 - accuracy: 0.8816 - val_loss: 1.0940 - val_accuracy: 0.7500\n",
      "Epoch 30/30\n",
      "42/42 [==============================] - 32s 765ms/step - loss: 0.9177 - accuracy: 0.8793 - val_loss: 1.0929 - val_accuracy: 0.7500\n",
      "INFO:tensorflow:Assets written to: ../xception/xception_30epochs_2087.1_images_False_newWeights_False_lastLayerOnly_rescale-symmetric_normalization/assets\n",
      "Test acc for xception: 0.740702\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training resnet for 0.025% of train size (aka 2087 images) with pretrained: True and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 178 trainable: 178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      " 6/42 [===>..........................] - ETA: 25s - loss: 1.4065 - accuracy: 0.0267WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1049s vs `on_train_batch_begin` time: 0.1533s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1049s vs `on_train_batch_end` time: 0.3514s). Check your callbacks.\n",
      "42/42 [==============================] - 21s 291ms/step - loss: 1.3859 - accuracy: 0.2144 - val_loss: 1.3876 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "42/42 [==============================] - 8s 195ms/step - loss: 1.3437 - accuracy: 0.4479 - val_loss: 1.3943 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "42/42 [==============================] - 8s 195ms/step - loss: 1.3198 - accuracy: 0.4407 - val_loss: 1.4136 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "42/42 [==============================] - 8s 195ms/step - loss: 1.2667 - accuracy: 0.4419 - val_loss: 1.4054 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "42/42 [==============================] - 8s 196ms/step - loss: 1.2370 - accuracy: 0.6478 - val_loss: 1.4105 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "42/42 [==============================] - 8s 196ms/step - loss: 1.1957 - accuracy: 0.6842 - val_loss: 1.4466 - val_accuracy: 0.1875\n",
      "Epoch 7/30\n",
      "42/42 [==============================] - 8s 196ms/step - loss: 1.1768 - accuracy: 0.6887 - val_loss: 1.3603 - val_accuracy: 0.5000\n",
      "Epoch 8/30\n",
      "42/42 [==============================] - 8s 197ms/step - loss: 1.1362 - accuracy: 0.7193 - val_loss: 1.4074 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "42/42 [==============================] - 8s 196ms/step - loss: 1.1137 - accuracy: 0.7321 - val_loss: 1.2977 - val_accuracy: 0.5000\n",
      "Epoch 10/30\n",
      "42/42 [==============================] - 8s 196ms/step - loss: 1.1010 - accuracy: 0.7205 - val_loss: 1.2985 - val_accuracy: 0.5000\n",
      "Epoch 11/30\n",
      "42/42 [==============================] - 8s 196ms/step - loss: 1.0691 - accuracy: 0.7438 - val_loss: 1.3235 - val_accuracy: 0.5000\n",
      "Epoch 12/30\n",
      "42/42 [==============================] - 8s 197ms/step - loss: 1.0590 - accuracy: 0.7474 - val_loss: 1.2576 - val_accuracy: 0.5000\n",
      "Epoch 13/30\n",
      "42/42 [==============================] - 8s 196ms/step - loss: 1.0413 - accuracy: 0.7413 - val_loss: 1.2285 - val_accuracy: 0.5000\n",
      "Epoch 14/30\n",
      "42/42 [==============================] - 8s 197ms/step - loss: 1.0279 - accuracy: 0.7550 - val_loss: 1.2493 - val_accuracy: 0.5000\n",
      "Epoch 15/30\n",
      "42/42 [==============================] - 8s 197ms/step - loss: 1.0241 - accuracy: 0.7470 - val_loss: 1.2272 - val_accuracy: 0.4375\n",
      "Epoch 16/30\n",
      "42/42 [==============================] - 8s 197ms/step - loss: 1.0036 - accuracy: 0.7437 - val_loss: 1.2023 - val_accuracy: 0.5000\n",
      "Epoch 17/30\n",
      "42/42 [==============================] - 8s 197ms/step - loss: 1.0025 - accuracy: 0.7434 - val_loss: 1.1948 - val_accuracy: 0.5000\n",
      "Epoch 18/30\n",
      "42/42 [==============================] - 8s 197ms/step - loss: 0.9816 - accuracy: 0.7664 - val_loss: 1.1941 - val_accuracy: 0.5000\n",
      "Epoch 19/30\n",
      "42/42 [==============================] - 8s 197ms/step - loss: 0.9930 - accuracy: 0.7463 - val_loss: 1.1990 - val_accuracy: 0.5000\n",
      "Epoch 20/30\n",
      "42/42 [==============================] - 8s 197ms/step - loss: 0.9810 - accuracy: 0.7501 - val_loss: 1.1775 - val_accuracy: 0.5000\n",
      "Epoch 21/30\n",
      "42/42 [==============================] - 8s 197ms/step - loss: 0.9730 - accuracy: 0.7601 - val_loss: 1.1745 - val_accuracy: 0.5000\n",
      "Epoch 22/30\n",
      "42/42 [==============================] - 8s 197ms/step - loss: 0.9683 - accuracy: 0.7533 - val_loss: 1.1796 - val_accuracy: 0.5000\n",
      "Epoch 23/30\n",
      "42/42 [==============================] - 8s 197ms/step - loss: 0.9669 - accuracy: 0.7407 - val_loss: 1.1771 - val_accuracy: 0.5000\n",
      "Epoch 24/30\n",
      "42/42 [==============================] - 8s 197ms/step - loss: 0.9494 - accuracy: 0.7664 - val_loss: 1.1723 - val_accuracy: 0.5000\n",
      "Epoch 25/30\n",
      "42/42 [==============================] - 8s 197ms/step - loss: 0.9706 - accuracy: 0.7312 - val_loss: 1.1735 - val_accuracy: 0.5000\n",
      "Epoch 26/30\n",
      "42/42 [==============================] - 8s 197ms/step - loss: 0.9557 - accuracy: 0.7640 - val_loss: 1.1640 - val_accuracy: 0.5000\n",
      "Epoch 27/30\n",
      "42/42 [==============================] - 8s 197ms/step - loss: 0.9548 - accuracy: 0.7480 - val_loss: 1.1627 - val_accuracy: 0.5000\n",
      "Epoch 28/30\n",
      "42/42 [==============================] - 8s 197ms/step - loss: 0.9510 - accuracy: 0.7555 - val_loss: 1.1613 - val_accuracy: 0.5000\n",
      "Epoch 29/30\n",
      "42/42 [==============================] - 8s 197ms/step - loss: 0.9424 - accuracy: 0.7576 - val_loss: 1.1610 - val_accuracy: 0.5000\n",
      "Epoch 30/30\n",
      "42/42 [==============================] - 8s 197ms/step - loss: 0.9499 - accuracy: 0.7459 - val_loss: 1.1591 - val_accuracy: 0.5000\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_2087.1_images_False_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.500000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training opticnet for 0.025% of train size (aka 2087 images) with pretrained: True and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 276 trainable: 276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      " 6/42 [===>..........................] - ETA: 1:04 - loss: 5.4031 - accuracy: 0.1634WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.4679s vs `on_train_batch_end` time: 1.0552s). Check your callbacks.\n",
      "42/42 [==============================] - 65s 1s/step - loss: 1.9792 - accuracy: 0.5828 - val_loss: 4.9018 - val_accuracy: 0.4375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "42/42 [==============================] - 49s 1s/step - loss: 0.2181 - accuracy: 0.9283 - val_loss: 1.1373 - val_accuracy: 0.6250\n",
      "Epoch 3/30\n",
      "42/42 [==============================] - 49s 1s/step - loss: 0.1348 - accuracy: 0.9535 - val_loss: 0.1698 - val_accuracy: 0.9375\n",
      "Epoch 4/30\n",
      "42/42 [==============================] - 49s 1s/step - loss: 0.0813 - accuracy: 0.9747 - val_loss: 0.1032 - val_accuracy: 0.9688\n",
      "Epoch 5/30\n",
      "42/42 [==============================] - 49s 1s/step - loss: 0.0577 - accuracy: 0.9769 - val_loss: 0.0631 - val_accuracy: 0.9688\n",
      "Epoch 6/30\n",
      "42/42 [==============================] - 49s 1s/step - loss: 0.0186 - accuracy: 0.9953 - val_loss: 0.3457 - val_accuracy: 0.9375\n",
      "Epoch 7/30\n",
      "42/42 [==============================] - 49s 1s/step - loss: 0.0234 - accuracy: 0.9890 - val_loss: 0.2467 - val_accuracy: 0.9375\n",
      "Epoch 8/30\n",
      "42/42 [==============================] - 49s 1s/step - loss: 0.0202 - accuracy: 0.9953 - val_loss: 0.0045 - val_accuracy: 1.0000\n",
      "Epoch 9/30\n",
      "42/42 [==============================] - 49s 1s/step - loss: 0.0205 - accuracy: 0.9921 - val_loss: 0.0063 - val_accuracy: 1.0000\n",
      "Epoch 10/30\n",
      "42/42 [==============================] - 49s 1s/step - loss: 0.0129 - accuracy: 0.9943 - val_loss: 0.0161 - val_accuracy: 1.0000\n",
      "Epoch 11/30\n",
      "42/42 [==============================] - 49s 1s/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.1010 - val_accuracy: 0.9688\n",
      "Epoch 12/30\n",
      "42/42 [==============================] - 49s 1s/step - loss: 0.0027 - accuracy: 0.9991 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
      "Epoch 13/30\n",
      "42/42 [==============================] - 49s 1s/step - loss: 0.0040 - accuracy: 0.9989 - val_loss: 0.1984 - val_accuracy: 0.9375\n",
      "Epoch 14/30\n",
      "42/42 [==============================] - 49s 1s/step - loss: 5.4582e-04 - accuracy: 1.0000 - val_loss: 0.1199 - val_accuracy: 0.9375\n",
      "Epoch 15/30\n",
      "42/42 [==============================] - 49s 1s/step - loss: 5.3121e-04 - accuracy: 1.0000 - val_loss: 0.1238 - val_accuracy: 0.9375\n",
      "Epoch 16/30\n",
      "42/42 [==============================] - 49s 1s/step - loss: 3.9192e-04 - accuracy: 1.0000 - val_loss: 0.1366 - val_accuracy: 0.9375\n",
      "Epoch 17/30\n",
      "42/42 [==============================] - 49s 1s/step - loss: 2.2410e-04 - accuracy: 1.0000 - val_loss: 0.1129 - val_accuracy: 0.9375\n",
      "Epoch 18/30\n",
      "42/42 [==============================] - 49s 1s/step - loss: 2.8670e-04 - accuracy: 1.0000 - val_loss: 0.0981 - val_accuracy: 0.9375\n",
      "Epoch 19/30\n",
      "42/42 [==============================] - 49s 1s/step - loss: 3.1793e-04 - accuracy: 1.0000 - val_loss: 0.1004 - val_accuracy: 0.9375\n",
      "Epoch 20/30\n",
      "42/42 [==============================] - 49s 1s/step - loss: 2.3538e-04 - accuracy: 1.0000 - val_loss: 0.0869 - val_accuracy: 0.9375\n",
      "Epoch 21/30\n",
      "42/42 [==============================] - 48s 1s/step - loss: 2.4506e-04 - accuracy: 1.0000 - val_loss: 0.0569 - val_accuracy: 0.9688\n",
      "Epoch 22/30\n",
      "42/42 [==============================] - 49s 1s/step - loss: 1.3480e-04 - accuracy: 1.0000 - val_loss: 0.0572 - val_accuracy: 0.9688\n",
      "Epoch 23/30\n",
      "42/42 [==============================] - 49s 1s/step - loss: 2.3110e-04 - accuracy: 1.0000 - val_loss: 0.0878 - val_accuracy: 0.9688\n",
      "Epoch 24/30\n",
      "42/42 [==============================] - 49s 1s/step - loss: 1.6948e-04 - accuracy: 1.0000 - val_loss: 0.0835 - val_accuracy: 0.9688\n",
      "Epoch 25/30\n",
      "42/42 [==============================] - 49s 1s/step - loss: 2.1607e-04 - accuracy: 1.0000 - val_loss: 0.0792 - val_accuracy: 0.9688\n",
      "Epoch 26/30\n",
      "42/42 [==============================] - 49s 1s/step - loss: 1.7874e-04 - accuracy: 1.0000 - val_loss: 0.0776 - val_accuracy: 0.9688\n",
      "Epoch 27/30\n",
      "42/42 [==============================] - 49s 1s/step - loss: 1.9519e-04 - accuracy: 1.0000 - val_loss: 0.0714 - val_accuracy: 0.9688\n",
      "Epoch 28/30\n",
      "42/42 [==============================] - 49s 1s/step - loss: 2.5463e-04 - accuracy: 1.0000 - val_loss: 0.0679 - val_accuracy: 0.9688\n",
      "Epoch 29/30\n",
      "42/42 [==============================] - 49s 1s/step - loss: 1.1174e-04 - accuracy: 1.0000 - val_loss: 0.0711 - val_accuracy: 0.9688\n",
      "Epoch 30/30\n",
      "42/42 [==============================] - 49s 1s/step - loss: 1.5777e-04 - accuracy: 1.0000 - val_loss: 0.0664 - val_accuracy: 0.9688\n",
      "INFO:tensorflow:Assets written to: ../opticnet/opticnet_30epochs_2087.1_images_False_newWeights_False_lastLayerOnly_rescale-symmetric_normalization/assets\n",
      "Test acc for opticnet: 0.987603\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.0498575  0.04993952 0.05172718 0.04839833]\n",
      "Training xception for 0.05% of train size (aka 4174 images) with pretrained: True and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 135 trainable: 135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      " 6/84 [=>............................] - ETA: 1:35 - loss: 1.3991 - accuracy: 0.1113WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1610s vs `on_train_batch_end` time: 0.8389s). Check your callbacks.\n",
      "84/84 [==============================] - 71s 790ms/step - loss: 1.3679 - accuracy: 0.3536 - val_loss: 1.3221 - val_accuracy: 0.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "84/84 [==============================] - 64s 757ms/step - loss: 1.2524 - accuracy: 0.7326 - val_loss: 1.3320 - val_accuracy: 0.3750\n",
      "Epoch 3/30\n",
      "84/84 [==============================] - 63s 752ms/step - loss: 1.1698 - accuracy: 0.7426 - val_loss: 1.3034 - val_accuracy: 0.5000\n",
      "Epoch 4/30\n",
      "84/84 [==============================] - 64s 757ms/step - loss: 1.1268 - accuracy: 0.7388 - val_loss: 1.2927 - val_accuracy: 0.5000\n",
      "Epoch 5/30\n",
      "84/84 [==============================] - 64s 758ms/step - loss: 1.0703 - accuracy: 0.7569 - val_loss: 1.2833 - val_accuracy: 0.5000\n",
      "Epoch 6/30\n",
      "84/84 [==============================] - 63s 755ms/step - loss: 1.0410 - accuracy: 0.7465 - val_loss: 1.1962 - val_accuracy: 0.5000\n",
      "Epoch 7/30\n",
      "84/84 [==============================] - 64s 758ms/step - loss: 0.9831 - accuracy: 0.7573 - val_loss: 1.0975 - val_accuracy: 0.5000\n",
      "Epoch 8/30\n",
      "84/84 [==============================] - 63s 755ms/step - loss: 0.9430 - accuracy: 0.7835 - val_loss: 1.0695 - val_accuracy: 0.7500\n",
      "Epoch 9/30\n",
      "84/84 [==============================] - 64s 756ms/step - loss: 0.9097 - accuracy: 0.8141 - val_loss: 1.0388 - val_accuracy: 0.7188\n",
      "Epoch 10/30\n",
      "84/84 [==============================] - 63s 752ms/step - loss: 0.8908 - accuracy: 0.8170 - val_loss: 1.0359 - val_accuracy: 0.7188\n",
      "Epoch 11/30\n",
      "84/84 [==============================] - 63s 754ms/step - loss: 0.8683 - accuracy: 0.8223 - val_loss: 1.0210 - val_accuracy: 0.7188\n",
      "Epoch 12/30\n",
      "84/84 [==============================] - 63s 754ms/step - loss: 0.8564 - accuracy: 0.8147 - val_loss: 0.9959 - val_accuracy: 0.7188\n",
      "Epoch 13/30\n",
      "84/84 [==============================] - 64s 756ms/step - loss: 0.8209 - accuracy: 0.8344 - val_loss: 0.9841 - val_accuracy: 0.7188\n",
      "Epoch 14/30\n",
      "84/84 [==============================] - 64s 757ms/step - loss: 0.8119 - accuracy: 0.8249 - val_loss: 0.9325 - val_accuracy: 0.7188\n",
      "Epoch 15/30\n",
      "84/84 [==============================] - 63s 755ms/step - loss: 0.7588 - accuracy: 0.8375 - val_loss: 0.8687 - val_accuracy: 0.7188\n",
      "Epoch 16/30\n",
      "84/84 [==============================] - 64s 756ms/step - loss: 0.7426 - accuracy: 0.9220 - val_loss: 0.8423 - val_accuracy: 0.9688\n",
      "Epoch 17/30\n",
      "84/84 [==============================] - 63s 755ms/step - loss: 0.7087 - accuracy: 0.9618 - val_loss: 0.8019 - val_accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "84/84 [==============================] - 64s 757ms/step - loss: 0.6906 - accuracy: 0.9653 - val_loss: 0.7877 - val_accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "84/84 [==============================] - 64s 756ms/step - loss: 0.6792 - accuracy: 0.9701 - val_loss: 0.8349 - val_accuracy: 0.9688\n",
      "Epoch 20/30\n",
      "84/84 [==============================] - 64s 757ms/step - loss: 0.6703 - accuracy: 0.9695 - val_loss: 0.7655 - val_accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "84/84 [==============================] - 64s 758ms/step - loss: 0.6576 - accuracy: 0.9718 - val_loss: 0.7563 - val_accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "84/84 [==============================] - 64s 757ms/step - loss: 0.6398 - accuracy: 0.9758 - val_loss: 0.7485 - val_accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "84/84 [==============================] - 63s 754ms/step - loss: 0.6377 - accuracy: 0.9718 - val_loss: 0.7417 - val_accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "84/84 [==============================] - 63s 756ms/step - loss: 0.6271 - accuracy: 0.9776 - val_loss: 0.7356 - val_accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "84/84 [==============================] - 64s 758ms/step - loss: 0.6214 - accuracy: 0.9798 - val_loss: 0.7303 - val_accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "84/84 [==============================] - 63s 754ms/step - loss: 0.6194 - accuracy: 0.9750 - val_loss: 0.7254 - val_accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "84/84 [==============================] - 64s 757ms/step - loss: 0.6164 - accuracy: 0.9771 - val_loss: 0.7212 - val_accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "84/84 [==============================] - 64s 759ms/step - loss: 0.6006 - accuracy: 0.9838 - val_loss: 0.7252 - val_accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "84/84 [==============================] - 64s 757ms/step - loss: 0.6027 - accuracy: 0.9807 - val_loss: 0.7146 - val_accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "84/84 [==============================] - 64s 757ms/step - loss: 0.6011 - accuracy: 0.9806 - val_loss: 0.7112 - val_accuracy: 1.0000\n",
      "INFO:tensorflow:Assets written to: ../xception/xception_30epochs_4174.2_images_False_newWeights_False_lastLayerOnly_rescale-symmetric_normalization/assets\n",
      "Test acc for xception: 0.979339\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training resnet for 0.05% of train size (aka 4174 images) with pretrained: True and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 178 trainable: 178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      " 6/84 [=>............................] - ETA: 1:11 - loss: 1.3871 - accuracy: 0.3471WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1089s vs `on_train_batch_begin` time: 0.1474s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1089s vs `on_train_batch_end` time: 0.5356s). Check your callbacks.\n",
      "84/84 [==============================] - 28s 258ms/step - loss: 1.3635 - accuracy: 0.3774 - val_loss: 1.3529 - val_accuracy: 0.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "84/84 [==============================] - 16s 195ms/step - loss: 1.2765 - accuracy: 0.6994 - val_loss: 1.3602 - val_accuracy: 0.4062\n",
      "Epoch 3/30\n",
      "84/84 [==============================] - 16s 196ms/step - loss: 1.2016 - accuracy: 0.7357 - val_loss: 1.3150 - val_accuracy: 0.5000\n",
      "Epoch 4/30\n",
      "84/84 [==============================] - 16s 196ms/step - loss: 1.1556 - accuracy: 0.7238 - val_loss: 1.3385 - val_accuracy: 0.4688\n",
      "Epoch 5/30\n",
      "84/84 [==============================] - 16s 196ms/step - loss: 1.1152 - accuracy: 0.7329 - val_loss: 1.3663 - val_accuracy: 0.4375\n",
      "Epoch 6/30\n",
      "84/84 [==============================] - 17s 197ms/step - loss: 1.0856 - accuracy: 0.7309 - val_loss: 1.4022 - val_accuracy: 0.3750\n",
      "Epoch 7/30\n",
      "84/84 [==============================] - 17s 196ms/step - loss: 1.0392 - accuracy: 0.7508 - val_loss: 1.4304 - val_accuracy: 0.3438\n",
      "Epoch 8/30\n",
      "84/84 [==============================] - 17s 197ms/step - loss: 1.0029 - accuracy: 0.7385 - val_loss: 1.2880 - val_accuracy: 0.5000\n",
      "Epoch 9/30\n",
      "84/84 [==============================] - 17s 197ms/step - loss: 0.9483 - accuracy: 0.7403 - val_loss: 1.1154 - val_accuracy: 0.5000\n",
      "Epoch 10/30\n",
      "84/84 [==============================] - 17s 197ms/step - loss: 0.9119 - accuracy: 0.7407 - val_loss: 1.1206 - val_accuracy: 0.5000\n",
      "Epoch 11/30\n",
      "84/84 [==============================] - 17s 197ms/step - loss: 0.8928 - accuracy: 0.7470 - val_loss: 1.0622 - val_accuracy: 0.7500\n",
      "Epoch 12/30\n",
      "84/84 [==============================] - 17s 197ms/step - loss: 0.8570 - accuracy: 0.8609 - val_loss: 1.0700 - val_accuracy: 0.7188\n",
      "Epoch 13/30\n",
      "84/84 [==============================] - 17s 196ms/step - loss: 0.8372 - accuracy: 0.8642 - val_loss: 1.0254 - val_accuracy: 0.7500\n",
      "Epoch 14/30\n",
      "84/84 [==============================] - 17s 197ms/step - loss: 0.8161 - accuracy: 0.8700 - val_loss: 1.0650 - val_accuracy: 0.7188\n",
      "Epoch 15/30\n",
      "84/84 [==============================] - 17s 197ms/step - loss: 0.8180 - accuracy: 0.8535 - val_loss: 1.0665 - val_accuracy: 0.7188\n",
      "Epoch 16/30\n",
      "84/84 [==============================] - 17s 197ms/step - loss: 0.7837 - accuracy: 0.8742 - val_loss: 0.9652 - val_accuracy: 0.7500\n",
      "Epoch 17/30\n",
      "84/84 [==============================] - 17s 197ms/step - loss: 0.7680 - accuracy: 0.8742 - val_loss: 0.9642 - val_accuracy: 0.7500\n",
      "Epoch 18/30\n",
      "84/84 [==============================] - 17s 198ms/step - loss: 0.7473 - accuracy: 0.8819 - val_loss: 0.9533 - val_accuracy: 0.7500\n",
      "Epoch 19/30\n",
      "84/84 [==============================] - 17s 197ms/step - loss: 0.7146 - accuracy: 0.8921 - val_loss: 0.9469 - val_accuracy: 0.7188\n",
      "Epoch 20/30\n",
      "84/84 [==============================] - 17s 197ms/step - loss: 0.7164 - accuracy: 0.8817 - val_loss: 0.9059 - val_accuracy: 0.7500\n",
      "Epoch 21/30\n",
      "84/84 [==============================] - 17s 197ms/step - loss: 0.7119 - accuracy: 0.8805 - val_loss: 0.9024 - val_accuracy: 0.7500\n",
      "Epoch 22/30\n",
      "84/84 [==============================] - 17s 197ms/step - loss: 0.7021 - accuracy: 0.8810 - val_loss: 0.8808 - val_accuracy: 0.7500\n",
      "Epoch 23/30\n",
      "84/84 [==============================] - 16s 196ms/step - loss: 0.7060 - accuracy: 0.8714 - val_loss: 0.8483 - val_accuracy: 0.7500\n",
      "Epoch 24/30\n",
      "84/84 [==============================] - 17s 197ms/step - loss: 0.6858 - accuracy: 0.8833 - val_loss: 0.8998 - val_accuracy: 0.7500\n",
      "Epoch 25/30\n",
      "84/84 [==============================] - 17s 197ms/step - loss: 0.6812 - accuracy: 0.8844 - val_loss: 0.9082 - val_accuracy: 0.7500\n",
      "Epoch 26/30\n",
      "84/84 [==============================] - 17s 197ms/step - loss: 0.6650 - accuracy: 0.8876 - val_loss: 0.8937 - val_accuracy: 0.7500\n",
      "Epoch 27/30\n",
      "84/84 [==============================] - 17s 197ms/step - loss: 0.6781 - accuracy: 0.8784 - val_loss: 0.8658 - val_accuracy: 0.7500\n",
      "Epoch 28/30\n",
      "84/84 [==============================] - 17s 197ms/step - loss: 0.6630 - accuracy: 0.8877 - val_loss: 0.8802 - val_accuracy: 0.7500\n",
      "Epoch 29/30\n",
      "84/84 [==============================] - 17s 197ms/step - loss: 0.6578 - accuracy: 0.8845 - val_loss: 0.8922 - val_accuracy: 0.7500\n",
      "Epoch 30/30\n",
      "84/84 [==============================] - 17s 197ms/step - loss: 0.6631 - accuracy: 0.8811 - val_loss: 0.8174 - val_accuracy: 0.7500\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_4174.2_images_False_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.743802\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training opticnet for 0.05% of train size (aka 4174 images) with pretrained: True and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 276 trainable: 276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      " 6/84 [=>............................] - ETA: 2:22 - loss: 5.5698 - accuracy: 0.1665WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.4683s vs `on_train_batch_end` time: 1.0839s). Check your callbacks.\n",
      "84/84 [==============================] - 116s 1s/step - loss: 1.4056 - accuracy: 0.6750 - val_loss: 1.2262 - val_accuracy: 0.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "84/84 [==============================] - 98s 1s/step - loss: 0.1820 - accuracy: 0.9373 - val_loss: 0.1092 - val_accuracy: 0.9375\n",
      "Epoch 3/30\n",
      "84/84 [==============================] - 98s 1s/step - loss: 0.1240 - accuracy: 0.9626 - val_loss: 0.0857 - val_accuracy: 0.9688\n",
      "Epoch 4/30\n",
      "84/84 [==============================] - 98s 1s/step - loss: 0.0704 - accuracy: 0.9799 - val_loss: 0.0100 - val_accuracy: 1.0000\n",
      "Epoch 5/30\n",
      "84/84 [==============================] - 98s 1s/step - loss: 0.0566 - accuracy: 0.9808 - val_loss: 0.4567 - val_accuracy: 0.8438\n",
      "Epoch 6/30\n",
      "84/84 [==============================] - 98s 1s/step - loss: 0.0925 - accuracy: 0.9703 - val_loss: 0.0109 - val_accuracy: 1.0000\n",
      "Epoch 7/30\n",
      "84/84 [==============================] - 98s 1s/step - loss: 0.0273 - accuracy: 0.9933 - val_loss: 0.0099 - val_accuracy: 1.0000\n",
      "Epoch 8/30\n",
      "84/84 [==============================] - 98s 1s/step - loss: 0.0141 - accuracy: 0.9965 - val_loss: 0.0071 - val_accuracy: 1.0000\n",
      "Epoch 9/30\n",
      "84/84 [==============================] - 98s 1s/step - loss: 0.0064 - accuracy: 0.9990 - val_loss: 0.0158 - val_accuracy: 1.0000\n",
      "Epoch 10/30\n",
      "84/84 [==============================] - 98s 1s/step - loss: 0.0200 - accuracy: 0.9946 - val_loss: 9.8944e-04 - val_accuracy: 1.0000\n",
      "Epoch 11/30\n",
      "84/84 [==============================] - 98s 1s/step - loss: 0.0123 - accuracy: 0.9953 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 12/30\n",
      "84/84 [==============================] - 98s 1s/step - loss: 0.0114 - accuracy: 0.9976 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
      "Epoch 13/30\n",
      "84/84 [==============================] - 98s 1s/step - loss: 0.0025 - accuracy: 0.9996 - val_loss: 1.8408e-04 - val_accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "84/84 [==============================] - 98s 1s/step - loss: 0.0063 - accuracy: 0.9993 - val_loss: 3.4775e-04 - val_accuracy: 1.0000\n",
      "Epoch 15/30\n",
      "84/84 [==============================] - 98s 1s/step - loss: 0.0020 - accuracy: 0.9995 - val_loss: 1.1990e-04 - val_accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "84/84 [==============================] - 98s 1s/step - loss: 0.0018 - accuracy: 0.9987 - val_loss: 2.3006e-04 - val_accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "84/84 [==============================] - 98s 1s/step - loss: 0.0016 - accuracy: 0.9997 - val_loss: 5.0399e-04 - val_accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "84/84 [==============================] - 98s 1s/step - loss: 7.0767e-04 - accuracy: 0.9996 - val_loss: 2.6616e-04 - val_accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "84/84 [==============================] - 98s 1s/step - loss: 5.0531e-04 - accuracy: 0.9999 - val_loss: 3.8672e-04 - val_accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "84/84 [==============================] - 98s 1s/step - loss: 0.0013 - accuracy: 0.9993 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "84/84 [==============================] - 98s 1s/step - loss: 0.0026 - accuracy: 0.9993 - val_loss: 3.3553e-04 - val_accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "84/84 [==============================] - 98s 1s/step - loss: 0.0021 - accuracy: 0.9984 - val_loss: 5.3848e-04 - val_accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "84/84 [==============================] - 98s 1s/step - loss: 6.0530e-04 - accuracy: 0.9997 - val_loss: 1.8322e-04 - val_accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "84/84 [==============================] - 98s 1s/step - loss: 6.0381e-04 - accuracy: 0.9996 - val_loss: 1.2276e-04 - val_accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "84/84 [==============================] - 98s 1s/step - loss: 3.5089e-04 - accuracy: 0.9999 - val_loss: 1.4060e-04 - val_accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "84/84 [==============================] - 97s 1s/step - loss: 4.8870e-04 - accuracy: 1.0000 - val_loss: 3.3605e-05 - val_accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "84/84 [==============================] - 98s 1s/step - loss: 6.6695e-04 - accuracy: 0.9997 - val_loss: 6.9565e-05 - val_accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "84/84 [==============================] - 98s 1s/step - loss: 5.5300e-04 - accuracy: 0.9997 - val_loss: 6.0862e-05 - val_accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "84/84 [==============================] - 98s 1s/step - loss: 0.0031 - accuracy: 0.9982 - val_loss: 8.9140e-05 - val_accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "84/84 [==============================] - 98s 1s/step - loss: 0.0024 - accuracy: 0.9993 - val_loss: 2.5531e-04 - val_accuracy: 1.0000\n",
      "INFO:tensorflow:Assets written to: ../opticnet/opticnet_30epochs_4174.2_images_False_newWeights_False_lastLayerOnly_rescale-symmetric_normalization/assets\n",
      "Test acc for opticnet: 0.991736\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.07376021 0.07496304 0.07701798 0.07625348]\n",
      "Training xception for 0.075% of train size (aka 6261 images) with pretrained: True and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 135 trainable: 135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/126 [>.............................] - ETA: 2:27 - loss: 1.3607 - accuracy: 0.3211WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1641s vs `on_train_batch_end` time: 0.8419s). Check your callbacks.\n",
      "126/126 [==============================] - 104s 784ms/step - loss: 1.3122 - accuracy: 0.7165 - val_loss: 1.2866 - val_accuracy: 0.5625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "126/126 [==============================] - 96s 761ms/step - loss: 1.1449 - accuracy: 0.8388 - val_loss: 1.1486 - val_accuracy: 0.7188\n",
      "Epoch 3/30\n",
      "126/126 [==============================] - 96s 763ms/step - loss: 1.0262 - accuracy: 0.8560 - val_loss: 1.2756 - val_accuracy: 0.5312\n",
      "Epoch 4/30\n",
      "126/126 [==============================] - 96s 763ms/step - loss: 0.9463 - accuracy: 0.8562 - val_loss: 1.0349 - val_accuracy: 0.7500\n",
      "Epoch 5/30\n",
      "126/126 [==============================] - 96s 763ms/step - loss: 0.8871 - accuracy: 0.8525 - val_loss: 1.0004 - val_accuracy: 0.7500\n",
      "Epoch 6/30\n",
      "126/126 [==============================] - 96s 762ms/step - loss: 0.8294 - accuracy: 0.8644 - val_loss: 0.9698 - val_accuracy: 0.7500\n",
      "Epoch 7/30\n",
      "126/126 [==============================] - 96s 761ms/step - loss: 0.7938 - accuracy: 0.8634 - val_loss: 0.9442 - val_accuracy: 0.7500\n",
      "Epoch 8/30\n",
      "126/126 [==============================] - 96s 762ms/step - loss: 0.7507 - accuracy: 0.8707 - val_loss: 0.9224 - val_accuracy: 0.7500\n",
      "Epoch 9/30\n",
      "126/126 [==============================] - 96s 762ms/step - loss: 0.7024 - accuracy: 0.8875 - val_loss: 0.9027 - val_accuracy: 0.7500\n",
      "Epoch 10/30\n",
      "126/126 [==============================] - 96s 762ms/step - loss: 0.7009 - accuracy: 0.8704 - val_loss: 0.8867 - val_accuracy: 0.7500\n",
      "Epoch 11/30\n",
      "126/126 [==============================] - 96s 764ms/step - loss: 0.6783 - accuracy: 0.8761 - val_loss: 0.8716 - val_accuracy: 0.7500\n",
      "Epoch 12/30\n",
      "126/126 [==============================] - 96s 763ms/step - loss: 0.6574 - accuracy: 0.8781 - val_loss: 0.8576 - val_accuracy: 0.7500\n",
      "Epoch 13/30\n",
      "126/126 [==============================] - 96s 764ms/step - loss: 0.6441 - accuracy: 0.8789 - val_loss: 0.8458 - val_accuracy: 0.7500\n",
      "Epoch 14/30\n",
      "126/126 [==============================] - 96s 761ms/step - loss: 0.6220 - accuracy: 0.8842 - val_loss: 0.8352 - val_accuracy: 0.7500\n",
      "Epoch 15/30\n",
      "126/126 [==============================] - 96s 761ms/step - loss: 0.6045 - accuracy: 0.8890 - val_loss: 0.8256 - val_accuracy: 0.7500\n",
      "Epoch 16/30\n",
      "126/126 [==============================] - 96s 764ms/step - loss: 0.6048 - accuracy: 0.8821 - val_loss: 0.7568 - val_accuracy: 0.7500\n",
      "Epoch 17/30\n",
      "126/126 [==============================] - 96s 762ms/step - loss: 0.5929 - accuracy: 0.8677 - val_loss: 0.7024 - val_accuracy: 0.7500\n",
      "Epoch 18/30\n",
      "126/126 [==============================] - 96s 760ms/step - loss: 0.5456 - accuracy: 0.8847 - val_loss: 0.6960 - val_accuracy: 0.7500\n",
      "Epoch 19/30\n",
      "126/126 [==============================] - 96s 763ms/step - loss: 0.5285 - accuracy: 0.8906 - val_loss: 0.6616 - val_accuracy: 0.7500\n",
      "Epoch 20/30\n",
      "126/126 [==============================] - 96s 764ms/step - loss: 0.5241 - accuracy: 0.8821 - val_loss: 0.6474 - val_accuracy: 0.7500\n",
      "Epoch 21/30\n",
      "126/126 [==============================] - 96s 760ms/step - loss: 0.5038 - accuracy: 0.8882 - val_loss: 0.6350 - val_accuracy: 0.7500\n",
      "Epoch 22/30\n",
      "126/126 [==============================] - 96s 761ms/step - loss: 0.4960 - accuracy: 0.8854 - val_loss: 0.6527 - val_accuracy: 0.7500\n",
      "Epoch 23/30\n",
      "126/126 [==============================] - 96s 761ms/step - loss: 0.4875 - accuracy: 0.8882 - val_loss: 0.6415 - val_accuracy: 0.7500\n",
      "Epoch 24/30\n",
      "126/126 [==============================] - 96s 763ms/step - loss: 0.4851 - accuracy: 0.8832 - val_loss: 0.6077 - val_accuracy: 0.7500\n",
      "Epoch 25/30\n",
      "126/126 [==============================] - 96s 759ms/step - loss: 0.4656 - accuracy: 0.8979 - val_loss: 0.6009 - val_accuracy: 0.7500\n",
      "Epoch 26/30\n",
      "126/126 [==============================] - 96s 761ms/step - loss: 0.4746 - accuracy: 0.8849 - val_loss: 0.6016 - val_accuracy: 0.7500\n",
      "Epoch 27/30\n",
      "126/126 [==============================] - 96s 759ms/step - loss: 0.4660 - accuracy: 0.8873 - val_loss: 0.5897 - val_accuracy: 0.7500\n",
      "Epoch 28/30\n",
      "126/126 [==============================] - 96s 761ms/step - loss: 0.4613 - accuracy: 0.8841 - val_loss: 0.5877 - val_accuracy: 0.7500\n",
      "Epoch 29/30\n",
      "126/126 [==============================] - 96s 758ms/step - loss: 0.4573 - accuracy: 0.8881 - val_loss: 0.5810 - val_accuracy: 0.7500\n",
      "Epoch 30/30\n",
      "126/126 [==============================] - 96s 761ms/step - loss: 0.4455 - accuracy: 0.8918 - val_loss: 0.5769 - val_accuracy: 0.7500\n",
      "INFO:tensorflow:Assets written to: ../xception/xception_30epochs_6261.3_images_False_newWeights_False_lastLayerOnly_rescale-symmetric_normalization/assets\n",
      "Test acc for xception: 0.747934\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training resnet for 0.075% of train size (aka 6261 images) with pretrained: True and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 178 trainable: 178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/126 [>.............................] - ETA: 1:18 - loss: 1.3763 - accuracy: 0.1274WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1038s vs `on_train_batch_begin` time: 0.1387s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1038s vs `on_train_batch_end` time: 0.3286s). Check your callbacks.\n",
      "126/126 [==============================] - 35s 223ms/step - loss: 1.3393 - accuracy: 0.5808 - val_loss: 1.3845 - val_accuracy: 0.2812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "126/126 [==============================] - 25s 195ms/step - loss: 1.2152 - accuracy: 0.7186 - val_loss: 1.4346 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "126/126 [==============================] - 25s 196ms/step - loss: 1.1249 - accuracy: 0.7349 - val_loss: 1.3001 - val_accuracy: 0.5000\n",
      "Epoch 4/30\n",
      "126/126 [==============================] - 25s 196ms/step - loss: 1.0640 - accuracy: 0.7280 - val_loss: 1.3139 - val_accuracy: 0.5000\n",
      "Epoch 5/30\n",
      "126/126 [==============================] - 25s 197ms/step - loss: 0.9503 - accuracy: 0.8281 - val_loss: 1.0691 - val_accuracy: 0.7188\n",
      "Epoch 6/30\n",
      "126/126 [==============================] - 25s 197ms/step - loss: 0.8788 - accuracy: 0.8303 - val_loss: 1.0198 - val_accuracy: 0.6250\n",
      "Epoch 7/30\n",
      "126/126 [==============================] - 25s 197ms/step - loss: 0.8066 - accuracy: 0.8478 - val_loss: 1.4425 - val_accuracy: 0.4375\n",
      "Epoch 8/30\n",
      "126/126 [==============================] - 25s 197ms/step - loss: 0.7818 - accuracy: 0.8367 - val_loss: 0.8337 - val_accuracy: 0.7188\n",
      "Epoch 9/30\n",
      "126/126 [==============================] - 25s 197ms/step - loss: 0.7011 - accuracy: 0.8957 - val_loss: 0.8099 - val_accuracy: 0.8750\n",
      "Epoch 10/30\n",
      "126/126 [==============================] - 25s 197ms/step - loss: 0.6808 - accuracy: 0.9060 - val_loss: 0.7692 - val_accuracy: 0.9062\n",
      "Epoch 11/30\n",
      "126/126 [==============================] - 25s 197ms/step - loss: 0.6554 - accuracy: 0.9082 - val_loss: 0.9671 - val_accuracy: 0.7812\n",
      "Epoch 12/30\n",
      "126/126 [==============================] - 25s 197ms/step - loss: 0.6154 - accuracy: 0.9234 - val_loss: 0.6667 - val_accuracy: 0.9688\n",
      "Epoch 13/30\n",
      "126/126 [==============================] - 25s 197ms/step - loss: 0.5826 - accuracy: 0.9300 - val_loss: 0.6606 - val_accuracy: 0.9688\n",
      "Epoch 14/30\n",
      "126/126 [==============================] - 25s 197ms/step - loss: 0.5744 - accuracy: 0.9307 - val_loss: 0.6075 - val_accuracy: 0.9688\n",
      "Epoch 15/30\n",
      "126/126 [==============================] - 25s 197ms/step - loss: 0.5541 - accuracy: 0.9334 - val_loss: 0.5679 - val_accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "126/126 [==============================] - 25s 197ms/step - loss: 0.5318 - accuracy: 0.9386 - val_loss: 0.6772 - val_accuracy: 0.9062\n",
      "Epoch 17/30\n",
      "126/126 [==============================] - 25s 197ms/step - loss: 0.5183 - accuracy: 0.9441 - val_loss: 0.5373 - val_accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "126/126 [==============================] - 25s 196ms/step - loss: 0.4964 - accuracy: 0.9522 - val_loss: 0.5269 - val_accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "126/126 [==============================] - 25s 196ms/step - loss: 0.4892 - accuracy: 0.9518 - val_loss: 0.5431 - val_accuracy: 0.9688\n",
      "Epoch 20/30\n",
      "126/126 [==============================] - 25s 196ms/step - loss: 0.4845 - accuracy: 0.9498 - val_loss: 0.5024 - val_accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "126/126 [==============================] - 25s 197ms/step - loss: 0.4699 - accuracy: 0.9554 - val_loss: 0.4939 - val_accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "126/126 [==============================] - 25s 197ms/step - loss: 0.4618 - accuracy: 0.9554 - val_loss: 0.4874 - val_accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "126/126 [==============================] - 25s 196ms/step - loss: 0.4441 - accuracy: 0.9641 - val_loss: 0.4802 - val_accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "126/126 [==============================] - 25s 196ms/step - loss: 0.4466 - accuracy: 0.9592 - val_loss: 0.4734 - val_accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "126/126 [==============================] - 25s 197ms/step - loss: 0.4307 - accuracy: 0.9671 - val_loss: 0.4681 - val_accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "126/126 [==============================] - 25s 197ms/step - loss: 0.4201 - accuracy: 0.9698 - val_loss: 0.4632 - val_accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "126/126 [==============================] - 25s 197ms/step - loss: 0.4207 - accuracy: 0.9693 - val_loss: 0.4588 - val_accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "126/126 [==============================] - 25s 196ms/step - loss: 0.4110 - accuracy: 0.9712 - val_loss: 0.4894 - val_accuracy: 0.9688\n",
      "Epoch 29/30\n",
      "126/126 [==============================] - 25s 197ms/step - loss: 0.4124 - accuracy: 0.9673 - val_loss: 0.4514 - val_accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "126/126 [==============================] - 25s 196ms/step - loss: 0.4095 - accuracy: 0.9690 - val_loss: 0.4543 - val_accuracy: 1.0000\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_6261.3_images_False_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.982438\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training opticnet for 0.075% of train size (aka 6261 images) with pretrained: True and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 276 trainable: 276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/126 [>.............................] - ETA: 3:31 - loss: 5.3772 - accuracy: 0.1723WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.4642s vs `on_train_batch_end` time: 1.0421s). Check your callbacks.\n",
      "126/126 [==============================] - 162s 1s/step - loss: 1.0765 - accuracy: 0.7463 - val_loss: 0.1949 - val_accuracy: 0.9375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "126/126 [==============================] - 147s 1s/step - loss: 0.1374 - accuracy: 0.9544 - val_loss: 0.0049 - val_accuracy: 1.0000\n",
      "Epoch 3/30\n",
      "126/126 [==============================] - 147s 1s/step - loss: 0.0957 - accuracy: 0.9708 - val_loss: 0.1459 - val_accuracy: 0.9375\n",
      "Epoch 4/30\n",
      "126/126 [==============================] - 147s 1s/step - loss: 0.0764 - accuracy: 0.9753 - val_loss: 0.0113 - val_accuracy: 1.0000\n",
      "Epoch 5/30\n",
      "126/126 [==============================] - 147s 1s/step - loss: 0.0484 - accuracy: 0.9815 - val_loss: 0.0080 - val_accuracy: 1.0000\n",
      "Epoch 6/30\n",
      "126/126 [==============================] - 147s 1s/step - loss: 0.0376 - accuracy: 0.9886 - val_loss: 0.0206 - val_accuracy: 1.0000\n",
      "Epoch 7/30\n",
      "126/126 [==============================] - 146s 1s/step - loss: 0.0252 - accuracy: 0.9918 - val_loss: 0.0805 - val_accuracy: 0.9688\n",
      "Epoch 8/30\n",
      "126/126 [==============================] - 146s 1s/step - loss: 0.0307 - accuracy: 0.9905 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
      "Epoch 9/30\n",
      "126/126 [==============================] - 145s 1s/step - loss: 0.0223 - accuracy: 0.9927 - val_loss: 0.0196 - val_accuracy: 1.0000\n",
      "Epoch 10/30\n",
      "126/126 [==============================] - 146s 1s/step - loss: 0.0084 - accuracy: 0.9972 - val_loss: 7.1723e-05 - val_accuracy: 1.0000\n",
      "Epoch 11/30\n",
      "126/126 [==============================] - 146s 1s/step - loss: 0.0098 - accuracy: 0.9966 - val_loss: 6.5215e-04 - val_accuracy: 1.0000\n",
      "Epoch 12/30\n",
      "126/126 [==============================] - 146s 1s/step - loss: 0.0042 - accuracy: 0.9993 - val_loss: 4.4889e-05 - val_accuracy: 1.0000\n",
      "Epoch 13/30\n",
      "126/126 [==============================] - 146s 1s/step - loss: 0.0041 - accuracy: 0.9989 - val_loss: 1.6643e-04 - val_accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "126/126 [==============================] - 147s 1s/step - loss: 0.0017 - accuracy: 0.9997 - val_loss: 3.5670e-04 - val_accuracy: 1.0000\n",
      "Epoch 15/30\n",
      "126/126 [==============================] - 147s 1s/step - loss: 0.0010 - accuracy: 0.9999 - val_loss: 9.4008e-05 - val_accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "126/126 [==============================] - 146s 1s/step - loss: 0.0017 - accuracy: 0.9994 - val_loss: 5.7748e-05 - val_accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "126/126 [==============================] - 147s 1s/step - loss: 0.0018 - accuracy: 0.9991 - val_loss: 6.1692e-05 - val_accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "126/126 [==============================] - 146s 1s/step - loss: 8.0203e-04 - accuracy: 0.9997 - val_loss: 6.2170e-05 - val_accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "126/126 [==============================] - 146s 1s/step - loss: 0.0011 - accuracy: 0.9993 - val_loss: 7.1312e-05 - val_accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "126/126 [==============================] - 146s 1s/step - loss: 0.0013 - accuracy: 0.9994 - val_loss: 1.0122e-04 - val_accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "126/126 [==============================] - 145s 1s/step - loss: 0.0013 - accuracy: 0.9991 - val_loss: 3.9612e-05 - val_accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "126/126 [==============================] - 145s 1s/step - loss: 0.0011 - accuracy: 0.9995 - val_loss: 5.5445e-05 - val_accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "126/126 [==============================] - 146s 1s/step - loss: 0.0016 - accuracy: 0.9994 - val_loss: 3.9600e-05 - val_accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "126/126 [==============================] - 147s 1s/step - loss: 0.0011 - accuracy: 0.9997 - val_loss: 8.4326e-05 - val_accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "126/126 [==============================] - 146s 1s/step - loss: 0.0013 - accuracy: 0.9994 - val_loss: 3.6367e-05 - val_accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "126/126 [==============================] - 146s 1s/step - loss: 0.0017 - accuracy: 0.9993 - val_loss: 8.8820e-05 - val_accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "126/126 [==============================] - 146s 1s/step - loss: 0.0013 - accuracy: 0.9991 - val_loss: 5.0521e-05 - val_accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "126/126 [==============================] - 146s 1s/step - loss: 0.0013 - accuracy: 0.9994 - val_loss: 4.9991e-05 - val_accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "126/126 [==============================] - 147s 1s/step - loss: 9.6051e-04 - accuracy: 0.9996 - val_loss: 5.3427e-05 - val_accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "126/126 [==============================] - 147s 1s/step - loss: 0.0010 - accuracy: 0.9997 - val_loss: 3.8052e-05 - val_accuracy: 1.0000\n",
      "INFO:tensorflow:Assets written to: ../opticnet/opticnet_30epochs_6261.3_images_False_newWeights_False_lastLayerOnly_rescale-symmetric_normalization/assets\n",
      "Test acc for opticnet: 0.994835\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.08835265 0.09025669 0.09111738 0.09238626]\n",
      "Training xception for 0.09% of train size (aka 7513 images) with pretrained: True and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 135 trainable: 135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/151 [>.............................] - ETA: 3:01 - loss: 1.3704 - accuracy: 0.1606WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1649s vs `on_train_batch_end` time: 0.8322s). Check your callbacks.\n",
      "151/151 [==============================] - 126s 804ms/step - loss: 1.3101 - accuracy: 0.6783 - val_loss: 1.2582 - val_accuracy: 0.7188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "151/151 [==============================] - 119s 785ms/step - loss: 1.0951 - accuracy: 0.9289 - val_loss: 1.1788 - val_accuracy: 0.6250\n",
      "Epoch 3/30\n",
      "151/151 [==============================] - 121s 799ms/step - loss: 0.9555 - accuracy: 0.9206 - val_loss: 0.8983 - val_accuracy: 0.9688\n",
      "Epoch 4/30\n",
      "151/151 [==============================] - 121s 801ms/step - loss: 0.8241 - accuracy: 0.9501 - val_loss: 0.8150 - val_accuracy: 0.9688\n",
      "Epoch 5/30\n",
      "151/151 [==============================] - 121s 802ms/step - loss: 0.7331 - accuracy: 0.9589 - val_loss: 0.8113 - val_accuracy: 0.9375\n",
      "Epoch 6/30\n",
      "151/151 [==============================] - 121s 801ms/step - loss: 0.6640 - accuracy: 0.9619 - val_loss: 0.7833 - val_accuracy: 0.9062\n",
      "Epoch 7/30\n",
      "151/151 [==============================] - 120s 793ms/step - loss: 0.6272 - accuracy: 0.9448 - val_loss: 0.6842 - val_accuracy: 0.9375\n",
      "Epoch 8/30\n",
      "151/151 [==============================] - 121s 798ms/step - loss: 0.5702 - accuracy: 0.9620 - val_loss: 0.6171 - val_accuracy: 0.9688\n",
      "Epoch 9/30\n",
      "151/151 [==============================] - 118s 780ms/step - loss: 0.5386 - accuracy: 0.9634 - val_loss: 0.6033 - val_accuracy: 0.9688\n",
      "Epoch 10/30\n",
      "151/151 [==============================] - 121s 800ms/step - loss: 0.5140 - accuracy: 0.9632 - val_loss: 0.5110 - val_accuracy: 1.0000\n",
      "Epoch 11/30\n",
      "151/151 [==============================] - 119s 788ms/step - loss: 0.4755 - accuracy: 0.9692 - val_loss: 0.5196 - val_accuracy: 0.9688\n",
      "Epoch 12/30\n",
      "151/151 [==============================] - 119s 789ms/step - loss: 0.4469 - accuracy: 0.9717 - val_loss: 0.4631 - val_accuracy: 1.0000\n",
      "Epoch 13/30\n",
      "151/151 [==============================] - 119s 789ms/step - loss: 0.4374 - accuracy: 0.9683 - val_loss: 0.4433 - val_accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "151/151 [==============================] - 116s 767ms/step - loss: 0.4115 - accuracy: 0.9741 - val_loss: 0.4260 - val_accuracy: 1.0000\n",
      "Epoch 15/30\n",
      "151/151 [==============================] - 116s 771ms/step - loss: 0.3925 - accuracy: 0.9783 - val_loss: 0.4110 - val_accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "151/151 [==============================] - 118s 779ms/step - loss: 0.3758 - accuracy: 0.9789 - val_loss: 0.3978 - val_accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "151/151 [==============================] - 119s 790ms/step - loss: 0.3695 - accuracy: 0.9796 - val_loss: 0.3862 - val_accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "151/151 [==============================] - 120s 793ms/step - loss: 0.3577 - accuracy: 0.9795 - val_loss: 0.3758 - val_accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "151/151 [==============================] - 118s 783ms/step - loss: 0.3443 - accuracy: 0.9832 - val_loss: 0.3664 - val_accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "151/151 [==============================] - 118s 784ms/step - loss: 0.3367 - accuracy: 0.9827 - val_loss: 0.3581 - val_accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "151/151 [==============================] - 119s 787ms/step - loss: 0.3260 - accuracy: 0.9845 - val_loss: 0.3509 - val_accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "151/151 [==============================] - 117s 774ms/step - loss: 0.3228 - accuracy: 0.9845 - val_loss: 0.3442 - val_accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "151/151 [==============================] - 118s 783ms/step - loss: 0.3125 - accuracy: 0.9854 - val_loss: 0.3384 - val_accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "151/151 [==============================] - 118s 782ms/step - loss: 0.3083 - accuracy: 0.9857 - val_loss: 0.3330 - val_accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "151/151 [==============================] - 117s 775ms/step - loss: 0.3001 - accuracy: 0.9872 - val_loss: 0.3283 - val_accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "151/151 [==============================] - 119s 787ms/step - loss: 0.2983 - accuracy: 0.9868 - val_loss: 0.3240 - val_accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "151/151 [==============================] - 119s 787ms/step - loss: 0.2904 - accuracy: 0.9878 - val_loss: 0.3202 - val_accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "151/151 [==============================] - 117s 777ms/step - loss: 0.2893 - accuracy: 0.9878 - val_loss: 0.3167 - val_accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "151/151 [==============================] - 118s 781ms/step - loss: 0.2858 - accuracy: 0.9883 - val_loss: 0.3136 - val_accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "151/151 [==============================] - 116s 769ms/step - loss: 0.2958 - accuracy: 0.9832 - val_loss: 0.3108 - val_accuracy: 1.0000\n",
      "INFO:tensorflow:Assets written to: ../xception/xception_30epochs_7513.5599999999995_images_False_newWeights_False_lastLayerOnly_rescale-symmetric_normalization/assets\n",
      "Test acc for xception: 0.990702\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training resnet for 0.09% of train size (aka 7513 images) with pretrained: True and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 178 trainable: 178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/151 [>.............................] - ETA: 2:17 - loss: 1.4003 - accuracy: 0.0193WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1047s vs `on_train_batch_begin` time: 0.1490s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1047s vs `on_train_batch_end` time: 0.5643s). Check your callbacks.\n",
      "151/151 [==============================] - 41s 229ms/step - loss: 1.3441 - accuracy: 0.4382 - val_loss: 1.2773 - val_accuracy: 0.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "151/151 [==============================] - 30s 195ms/step - loss: 1.1593 - accuracy: 0.7341 - val_loss: 1.2506 - val_accuracy: 0.5938\n",
      "Epoch 3/30\n",
      "151/151 [==============================] - 30s 196ms/step - loss: 1.0325 - accuracy: 0.8357 - val_loss: 1.2585 - val_accuracy: 0.5000\n",
      "Epoch 4/30\n",
      "151/151 [==============================] - 30s 197ms/step - loss: 0.9459 - accuracy: 0.8385 - val_loss: 1.1432 - val_accuracy: 0.6875\n",
      "Epoch 5/30\n",
      "151/151 [==============================] - 30s 196ms/step - loss: 0.8805 - accuracy: 0.8478 - val_loss: 1.0439 - val_accuracy: 0.7500\n",
      "Epoch 6/30\n",
      "151/151 [==============================] - 30s 197ms/step - loss: 0.8318 - accuracy: 0.8452 - val_loss: 1.0573 - val_accuracy: 0.7188\n",
      "Epoch 7/30\n",
      "151/151 [==============================] - 30s 197ms/step - loss: 0.7799 - accuracy: 0.8572 - val_loss: 1.0965 - val_accuracy: 0.6562\n",
      "Epoch 8/30\n",
      "151/151 [==============================] - 30s 197ms/step - loss: 0.7178 - accuracy: 0.8643 - val_loss: 0.8460 - val_accuracy: 0.7500\n",
      "Epoch 9/30\n",
      "151/151 [==============================] - 30s 197ms/step - loss: 0.6539 - accuracy: 0.8730 - val_loss: 0.8130 - val_accuracy: 0.6875\n",
      "Epoch 10/30\n",
      "151/151 [==============================] - 30s 197ms/step - loss: 0.6222 - accuracy: 0.8710 - val_loss: 0.8182 - val_accuracy: 0.8750\n",
      "Epoch 11/30\n",
      "151/151 [==============================] - 30s 197ms/step - loss: 0.6000 - accuracy: 0.9226 - val_loss: 0.9391 - val_accuracy: 0.7812\n",
      "Epoch 12/30\n",
      "151/151 [==============================] - 30s 197ms/step - loss: 0.5554 - accuracy: 0.9405 - val_loss: 0.7343 - val_accuracy: 0.8750\n",
      "Epoch 13/30\n",
      "151/151 [==============================] - 30s 197ms/step - loss: 0.5431 - accuracy: 0.9332 - val_loss: 0.5676 - val_accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "151/151 [==============================] - 30s 197ms/step - loss: 0.5334 - accuracy: 0.9333 - val_loss: 0.5933 - val_accuracy: 0.9688\n",
      "Epoch 15/30\n",
      "151/151 [==============================] - 30s 197ms/step - loss: 0.4952 - accuracy: 0.9474 - val_loss: 0.5561 - val_accuracy: 0.9688\n",
      "Epoch 16/30\n",
      "151/151 [==============================] - 30s 197ms/step - loss: 0.4943 - accuracy: 0.9421 - val_loss: 0.5099 - val_accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "151/151 [==============================] - 30s 197ms/step - loss: 0.4670 - accuracy: 0.9497 - val_loss: 0.5167 - val_accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "151/151 [==============================] - 30s 197ms/step - loss: 0.4625 - accuracy: 0.9499 - val_loss: 0.5666 - val_accuracy: 0.9375\n",
      "Epoch 19/30\n",
      "151/151 [==============================] - 30s 197ms/step - loss: 0.4383 - accuracy: 0.9587 - val_loss: 0.4680 - val_accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "151/151 [==============================] - 30s 197ms/step - loss: 0.4234 - accuracy: 0.9605 - val_loss: 0.4571 - val_accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "151/151 [==============================] - 30s 197ms/step - loss: 0.4198 - accuracy: 0.9585 - val_loss: 0.4790 - val_accuracy: 0.9688\n",
      "Epoch 22/30\n",
      "151/151 [==============================] - 30s 196ms/step - loss: 0.4033 - accuracy: 0.9675 - val_loss: 0.4393 - val_accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "151/151 [==============================] - 30s 197ms/step - loss: 0.3917 - accuracy: 0.9686 - val_loss: 0.4316 - val_accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "151/151 [==============================] - 30s 197ms/step - loss: 0.3849 - accuracy: 0.9688 - val_loss: 0.4250 - val_accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "151/151 [==============================] - 30s 197ms/step - loss: 0.3902 - accuracy: 0.9674 - val_loss: 0.4204 - val_accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "151/151 [==============================] - 30s 197ms/step - loss: 0.3877 - accuracy: 0.9638 - val_loss: 0.4314 - val_accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "151/151 [==============================] - 30s 197ms/step - loss: 0.3792 - accuracy: 0.9679 - val_loss: 0.4097 - val_accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "151/151 [==============================] - 30s 197ms/step - loss: 0.3695 - accuracy: 0.9705 - val_loss: 0.4047 - val_accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "151/151 [==============================] - 30s 197ms/step - loss: 0.3675 - accuracy: 0.9692 - val_loss: 0.4021 - val_accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "151/151 [==============================] - 30s 197ms/step - loss: 0.3625 - accuracy: 0.9711 - val_loss: 0.3973 - val_accuracy: 1.0000\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_7513.5599999999995_images_False_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.972107\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training opticnet for 0.09% of train size (aka 7513 images) with pretrained: True and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 276 trainable: 276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/151 [>.............................] - ETA: 4:23 - loss: 5.2850 - accuracy: 0.1477WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.4661s vs `on_train_batch_end` time: 1.0824s). Check your callbacks.\n",
      "151/151 [==============================] - 195s 1s/step - loss: 1.0061 - accuracy: 0.7317 - val_loss: 0.0813 - val_accuracy: 0.9688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "151/151 [==============================] - 176s 1s/step - loss: 0.1742 - accuracy: 0.9419 - val_loss: 0.1216 - val_accuracy: 0.9688\n",
      "Epoch 3/30\n",
      "151/151 [==============================] - 177s 1s/step - loss: 0.1134 - accuracy: 0.9630 - val_loss: 0.0172 - val_accuracy: 1.0000\n",
      "Epoch 4/30\n",
      "151/151 [==============================] - 177s 1s/step - loss: 0.0836 - accuracy: 0.9738 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
      "Epoch 5/30\n",
      "151/151 [==============================] - 177s 1s/step - loss: 0.0870 - accuracy: 0.9712 - val_loss: 0.0043 - val_accuracy: 1.0000\n",
      "Epoch 6/30\n",
      "151/151 [==============================] - 177s 1s/step - loss: 0.0669 - accuracy: 0.9768 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
      "Epoch 7/30\n",
      "151/151 [==============================] - 177s 1s/step - loss: 0.0364 - accuracy: 0.9873 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
      "Epoch 8/30\n",
      "151/151 [==============================] - 177s 1s/step - loss: 0.0244 - accuracy: 0.9921 - val_loss: 0.0121 - val_accuracy: 1.0000\n",
      "Epoch 9/30\n",
      "151/151 [==============================] - 177s 1s/step - loss: 0.0227 - accuracy: 0.9925 - val_loss: 9.8151e-04 - val_accuracy: 1.0000\n",
      "Epoch 10/30\n",
      "151/151 [==============================] - 176s 1s/step - loss: 0.0050 - accuracy: 0.9987 - val_loss: 8.4643e-04 - val_accuracy: 1.0000\n",
      "Epoch 11/30\n",
      "151/151 [==============================] - 177s 1s/step - loss: 0.0080 - accuracy: 0.9973 - val_loss: 4.7104e-04 - val_accuracy: 1.0000\n",
      "Epoch 12/30\n",
      "151/151 [==============================] - 177s 1s/step - loss: 0.0055 - accuracy: 0.9983 - val_loss: 0.0087 - val_accuracy: 1.0000\n",
      "Epoch 13/30\n",
      "151/151 [==============================] - 177s 1s/step - loss: 0.0041 - accuracy: 0.9990 - val_loss: 0.0101 - val_accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "151/151 [==============================] - 177s 1s/step - loss: 0.0018 - accuracy: 0.9998 - val_loss: 3.6962e-04 - val_accuracy: 1.0000\n",
      "Epoch 15/30\n",
      "151/151 [==============================] - 177s 1s/step - loss: 0.0021 - accuracy: 0.9995 - val_loss: 0.0087 - val_accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "151/151 [==============================] - 177s 1s/step - loss: 0.0027 - accuracy: 0.9995 - val_loss: 2.8002e-04 - val_accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "151/151 [==============================] - 177s 1s/step - loss: 0.0034 - accuracy: 0.9988 - val_loss: 4.2365e-04 - val_accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "151/151 [==============================] - 177s 1s/step - loss: 0.0025 - accuracy: 0.9991 - val_loss: 3.6602e-04 - val_accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "151/151 [==============================] - 177s 1s/step - loss: 0.0011 - accuracy: 0.9996 - val_loss: 9.8491e-04 - val_accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "151/151 [==============================] - 177s 1s/step - loss: 0.0018 - accuracy: 0.9993 - val_loss: 4.4543e-04 - val_accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "151/151 [==============================] - 177s 1s/step - loss: 0.0012 - accuracy: 0.9997 - val_loss: 3.3509e-04 - val_accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "151/151 [==============================] - 176s 1s/step - loss: 0.0012 - accuracy: 0.9990 - val_loss: 2.6326e-04 - val_accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "151/151 [==============================] - 177s 1s/step - loss: 6.1427e-04 - accuracy: 0.9997 - val_loss: 1.8271e-04 - val_accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "151/151 [==============================] - 177s 1s/step - loss: 0.0013 - accuracy: 0.9990 - val_loss: 1.9403e-04 - val_accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "151/151 [==============================] - 177s 1s/step - loss: 8.9942e-04 - accuracy: 0.9995 - val_loss: 1.9043e-04 - val_accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "151/151 [==============================] - 177s 1s/step - loss: 6.1067e-04 - accuracy: 0.9997 - val_loss: 1.2602e-04 - val_accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "151/151 [==============================] - 177s 1s/step - loss: 4.8598e-04 - accuracy: 0.9999 - val_loss: 1.1994e-04 - val_accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "151/151 [==============================] - 177s 1s/step - loss: 0.0011 - accuracy: 0.9990 - val_loss: 1.3667e-04 - val_accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "151/151 [==============================] - 177s 1s/step - loss: 7.9473e-04 - accuracy: 0.9996 - val_loss: 9.6510e-05 - val_accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "151/151 [==============================] - 177s 1s/step - loss: 0.0013 - accuracy: 0.9991 - val_loss: 1.0126e-04 - val_accuracy: 1.0000\n",
      "INFO:tensorflow:Assets written to: ../opticnet/opticnet_30epochs_7513.5599999999995_images_False_newWeights_False_lastLayerOnly_rescale-symmetric_normalization/assets\n",
      "Test acc for opticnet: 0.989669\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.09777693 0.10020159 0.10133944 0.10410864]\n",
      "Training xception for 0.1% of train size (aka 8348 images) with pretrained: True and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 135 trainable: 135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/167 [>.............................] - ETA: 3:28 - loss: 1.3960 - accuracy: 0.0092WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1623s vs `on_train_batch_begin` time: 0.1829s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1623s vs `on_train_batch_end` time: 0.8525s). Check your callbacks.\n",
      "167/167 [==============================] - 148s 855ms/step - loss: 1.3334 - accuracy: 0.4608 - val_loss: 1.2296 - val_accuracy: 0.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "167/167 [==============================] - 143s 857ms/step - loss: 1.1140 - accuracy: 0.7655 - val_loss: 1.2537 - val_accuracy: 0.6562\n",
      "Epoch 3/30\n",
      "167/167 [==============================] - 144s 860ms/step - loss: 0.9547 - accuracy: 0.8815 - val_loss: 1.1219 - val_accuracy: 0.7500\n",
      "Epoch 4/30\n",
      "167/167 [==============================] - 145s 868ms/step - loss: 0.8539 - accuracy: 0.9358 - val_loss: 0.8875 - val_accuracy: 0.9688\n",
      "Epoch 5/30\n",
      "167/167 [==============================] - 143s 859ms/step - loss: 0.7479 - accuracy: 0.9585 - val_loss: 0.8668 - val_accuracy: 0.9062\n",
      "Epoch 6/30\n",
      "167/167 [==============================] - 145s 866ms/step - loss: 0.6791 - accuracy: 0.9586 - val_loss: 0.7450 - val_accuracy: 0.9688\n",
      "Epoch 7/30\n",
      "167/167 [==============================] - 142s 850ms/step - loss: 0.6273 - accuracy: 0.9569 - val_loss: 0.7077 - val_accuracy: 0.9688\n",
      "Epoch 8/30\n",
      "167/167 [==============================] - 144s 862ms/step - loss: 0.5758 - accuracy: 0.9668 - val_loss: 0.6146 - val_accuracy: 1.0000\n",
      "Epoch 9/30\n",
      "167/167 [==============================] - 141s 841ms/step - loss: 0.5260 - accuracy: 0.9702 - val_loss: 0.5741 - val_accuracy: 1.0000\n",
      "Epoch 10/30\n",
      "167/167 [==============================] - 142s 848ms/step - loss: 0.4973 - accuracy: 0.9715 - val_loss: 0.5728 - val_accuracy: 0.9688\n",
      "Epoch 11/30\n",
      "167/167 [==============================] - 139s 833ms/step - loss: 0.4653 - accuracy: 0.9755 - val_loss: 0.5090 - val_accuracy: 1.0000\n",
      "Epoch 12/30\n",
      "167/167 [==============================] - 144s 865ms/step - loss: 0.4405 - accuracy: 0.9756 - val_loss: 0.4835 - val_accuracy: 1.0000\n",
      "Epoch 13/30\n",
      "167/167 [==============================] - 140s 839ms/step - loss: 0.4210 - accuracy: 0.9769 - val_loss: 0.4606 - val_accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "167/167 [==============================] - 142s 851ms/step - loss: 0.3952 - accuracy: 0.9813 - val_loss: 0.4408 - val_accuracy: 1.0000\n",
      "Epoch 15/30\n",
      "167/167 [==============================] - 144s 860ms/step - loss: 0.3799 - accuracy: 0.9820 - val_loss: 0.4236 - val_accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "167/167 [==============================] - 141s 844ms/step - loss: 0.3657 - accuracy: 0.9817 - val_loss: 0.4084 - val_accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "167/167 [==============================] - 139s 834ms/step - loss: 0.3599 - accuracy: 0.9804 - val_loss: 0.3951 - val_accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "167/167 [==============================] - 144s 862ms/step - loss: 0.3381 - accuracy: 0.9859 - val_loss: 0.3833 - val_accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "167/167 [==============================] - 149s 890ms/step - loss: 0.3329 - accuracy: 0.9839 - val_loss: 0.3726 - val_accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "167/167 [==============================] - 142s 852ms/step - loss: 0.3205 - accuracy: 0.9863 - val_loss: 0.3631 - val_accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "167/167 [==============================] - 145s 869ms/step - loss: 0.3154 - accuracy: 0.9849 - val_loss: 0.3546 - val_accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "167/167 [==============================] - 144s 865ms/step - loss: 0.3062 - accuracy: 0.9883 - val_loss: 0.3472 - val_accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "167/167 [==============================] - 144s 862ms/step - loss: 0.3066 - accuracy: 0.9862 - val_loss: 0.3405 - val_accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "167/167 [==============================] - 140s 836ms/step - loss: 0.2944 - accuracy: 0.9872 - val_loss: 0.3345 - val_accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "167/167 [==============================] - 142s 849ms/step - loss: 0.2915 - accuracy: 0.9873 - val_loss: 0.3291 - val_accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "167/167 [==============================] - 141s 845ms/step - loss: 0.2852 - accuracy: 0.9882 - val_loss: 0.3244 - val_accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "167/167 [==============================] - 140s 836ms/step - loss: 0.2826 - accuracy: 0.9875 - val_loss: 0.3200 - val_accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "167/167 [==============================] - 143s 856ms/step - loss: 0.2773 - accuracy: 0.9881 - val_loss: 0.3162 - val_accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "167/167 [==============================] - 143s 857ms/step - loss: 0.2753 - accuracy: 0.9889 - val_loss: 0.3135 - val_accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "167/167 [==============================] - 143s 856ms/step - loss: 0.2774 - accuracy: 0.9869 - val_loss: 0.3095 - val_accuracy: 1.0000\n",
      "INFO:tensorflow:Assets written to: ../xception/xception_30epochs_8348.4_images_False_newWeights_False_lastLayerOnly_rescale-symmetric_normalization/assets\n",
      "Test acc for xception: 0.991736\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training resnet for 0.1% of train size (aka 8348 images) with pretrained: True and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 178 trainable: 178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/167 [>.............................] - ETA: 1:54 - loss: 1.3788 - accuracy: 0.2998WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1020s vs `on_train_batch_begin` time: 0.1805s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1020s vs `on_train_batch_end` time: 0.3375s). Check your callbacks.\n",
      "167/167 [==============================] - 43s 219ms/step - loss: 1.3156 - accuracy: 0.6879 - val_loss: 1.3083 - val_accuracy: 0.5625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "167/167 [==============================] - 33s 197ms/step - loss: 1.1312 - accuracy: 0.8386 - val_loss: 1.3206 - val_accuracy: 0.4688\n",
      "Epoch 3/30\n",
      "167/167 [==============================] - 33s 198ms/step - loss: 1.0012 - accuracy: 0.8586 - val_loss: 1.1760 - val_accuracy: 0.6875\n",
      "Epoch 4/30\n",
      "167/167 [==============================] - 33s 198ms/step - loss: 0.8984 - accuracy: 0.8594 - val_loss: 1.0565 - val_accuracy: 0.6562\n",
      "Epoch 5/30\n",
      "167/167 [==============================] - 33s 198ms/step - loss: 0.8158 - accuracy: 0.8377 - val_loss: 0.8784 - val_accuracy: 0.7500\n",
      "Epoch 6/30\n",
      "167/167 [==============================] - 33s 198ms/step - loss: 0.7459 - accuracy: 0.8444 - val_loss: 0.9299 - val_accuracy: 0.8438\n",
      "Epoch 7/30\n",
      "167/167 [==============================] - 33s 198ms/step - loss: 0.6665 - accuracy: 0.9319 - val_loss: 0.7845 - val_accuracy: 0.9062\n",
      "Epoch 8/30\n",
      "167/167 [==============================] - 33s 198ms/step - loss: 0.6164 - accuracy: 0.9392 - val_loss: 0.7649 - val_accuracy: 0.9062\n",
      "Epoch 9/30\n",
      "167/167 [==============================] - 33s 198ms/step - loss: 0.5868 - accuracy: 0.9368 - val_loss: 0.7057 - val_accuracy: 0.9375\n",
      "Epoch 10/30\n",
      "167/167 [==============================] - 33s 198ms/step - loss: 0.5494 - accuracy: 0.9439 - val_loss: 0.6269 - val_accuracy: 0.9688\n",
      "Epoch 11/30\n",
      "167/167 [==============================] - 33s 198ms/step - loss: 0.5117 - accuracy: 0.9497 - val_loss: 0.6084 - val_accuracy: 0.9688\n",
      "Epoch 12/30\n",
      "167/167 [==============================] - 33s 198ms/step - loss: 0.4871 - accuracy: 0.9529 - val_loss: 0.5131 - val_accuracy: 1.0000\n",
      "Epoch 13/30\n",
      "167/167 [==============================] - 33s 198ms/step - loss: 0.4647 - accuracy: 0.9526 - val_loss: 0.4846 - val_accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "167/167 [==============================] - 33s 198ms/step - loss: 0.4420 - accuracy: 0.9601 - val_loss: 0.5226 - val_accuracy: 0.9688\n",
      "Epoch 15/30\n",
      "167/167 [==============================] - 33s 198ms/step - loss: 0.4367 - accuracy: 0.9559 - val_loss: 0.4768 - val_accuracy: 0.9688\n",
      "Epoch 16/30\n",
      "167/167 [==============================] - 33s 198ms/step - loss: 0.4056 - accuracy: 0.9668 - val_loss: 0.4621 - val_accuracy: 0.9688\n",
      "Epoch 17/30\n",
      "167/167 [==============================] - 33s 198ms/step - loss: 0.4017 - accuracy: 0.9616 - val_loss: 0.4095 - val_accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "167/167 [==============================] - 33s 198ms/step - loss: 0.3793 - accuracy: 0.9683 - val_loss: 0.4373 - val_accuracy: 0.9688\n",
      "Epoch 19/30\n",
      "167/167 [==============================] - 33s 198ms/step - loss: 0.3783 - accuracy: 0.9650 - val_loss: 0.3909 - val_accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "167/167 [==============================] - 33s 198ms/step - loss: 0.3599 - accuracy: 0.9707 - val_loss: 0.4182 - val_accuracy: 0.9688\n",
      "Epoch 21/30\n",
      "167/167 [==============================] - 33s 198ms/step - loss: 0.3467 - accuracy: 0.9741 - val_loss: 0.4101 - val_accuracy: 0.9688\n",
      "Epoch 22/30\n",
      "167/167 [==============================] - 33s 198ms/step - loss: 0.3510 - accuracy: 0.9701 - val_loss: 0.4029 - val_accuracy: 0.9688\n",
      "Epoch 23/30\n",
      "167/167 [==============================] - 33s 198ms/step - loss: 0.3321 - accuracy: 0.9753 - val_loss: 0.3965 - val_accuracy: 0.9688\n",
      "Epoch 24/30\n",
      "167/167 [==============================] - 33s 198ms/step - loss: 0.3304 - accuracy: 0.9736 - val_loss: 0.3908 - val_accuracy: 0.9688\n",
      "Epoch 25/30\n",
      "167/167 [==============================] - 33s 198ms/step - loss: 0.3224 - accuracy: 0.9766 - val_loss: 0.3856 - val_accuracy: 0.9688\n",
      "Epoch 26/30\n",
      "167/167 [==============================] - 33s 198ms/step - loss: 0.3145 - accuracy: 0.9778 - val_loss: 0.3810 - val_accuracy: 0.9688\n",
      "Epoch 27/30\n",
      "167/167 [==============================] - 33s 198ms/step - loss: 0.3127 - accuracy: 0.9775 - val_loss: 0.3761 - val_accuracy: 0.9688\n",
      "Epoch 28/30\n",
      "167/167 [==============================] - 33s 198ms/step - loss: 0.3112 - accuracy: 0.9756 - val_loss: 0.3731 - val_accuracy: 0.9688\n",
      "Epoch 29/30\n",
      "167/167 [==============================] - 33s 198ms/step - loss: 0.3014 - accuracy: 0.9793 - val_loss: 0.3696 - val_accuracy: 0.9688\n",
      "Epoch 30/30\n",
      "167/167 [==============================] - 33s 198ms/step - loss: 0.3058 - accuracy: 0.9759 - val_loss: 0.3670 - val_accuracy: 0.9688\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_8348.4_images_False_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.987603\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training opticnet for 0.1% of train size (aka 8348 images) with pretrained: True and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 276 trainable: 276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/167 [>.............................] - ETA: 4:59 - loss: 5.4074 - accuracy: 0.1592WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.4656s vs `on_train_batch_end` time: 1.0809s). Check your callbacks.\n",
      "167/167 [==============================] - 215s 1s/step - loss: 0.9202 - accuracy: 0.7746 - val_loss: 0.1768 - val_accuracy: 0.9375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "167/167 [==============================] - 196s 1s/step - loss: 0.1523 - accuracy: 0.9498 - val_loss: 0.0582 - val_accuracy: 0.9688\n",
      "Epoch 3/30\n",
      "167/167 [==============================] - 196s 1s/step - loss: 0.1077 - accuracy: 0.9646 - val_loss: 0.0185 - val_accuracy: 1.0000\n",
      "Epoch 4/30\n",
      "167/167 [==============================] - 196s 1s/step - loss: 0.0789 - accuracy: 0.9753 - val_loss: 0.1014 - val_accuracy: 0.9688\n",
      "Epoch 5/30\n",
      "167/167 [==============================] - 197s 1s/step - loss: 0.0565 - accuracy: 0.9800 - val_loss: 0.0098 - val_accuracy: 1.0000\n",
      "Epoch 6/30\n",
      "167/167 [==============================] - 201s 1s/step - loss: 0.0606 - accuracy: 0.9828 - val_loss: 0.0102 - val_accuracy: 1.0000\n",
      "Epoch 7/30\n",
      "167/167 [==============================] - 197s 1s/step - loss: 0.0237 - accuracy: 0.9931 - val_loss: 0.0041 - val_accuracy: 1.0000\n",
      "Epoch 8/30\n",
      "167/167 [==============================] - 196s 1s/step - loss: 0.0190 - accuracy: 0.9933 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
      "Epoch 9/30\n",
      "167/167 [==============================] - 197s 1s/step - loss: 0.0157 - accuracy: 0.9950 - val_loss: 8.4503e-04 - val_accuracy: 1.0000\n",
      "Epoch 10/30\n",
      "167/167 [==============================] - 196s 1s/step - loss: 0.0107 - accuracy: 0.9966 - val_loss: 1.2509e-04 - val_accuracy: 1.0000\n",
      "Epoch 11/30\n",
      "167/167 [==============================] - 196s 1s/step - loss: 0.0094 - accuracy: 0.9972 - val_loss: 9.3059e-05 - val_accuracy: 1.0000\n",
      "Epoch 12/30\n",
      "167/167 [==============================] - 197s 1s/step - loss: 0.0076 - accuracy: 0.9971 - val_loss: 3.3107e-05 - val_accuracy: 1.0000\n",
      "Epoch 13/30\n",
      "167/167 [==============================] - 197s 1s/step - loss: 0.0057 - accuracy: 0.9977 - val_loss: 5.3420e-05 - val_accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "167/167 [==============================] - 197s 1s/step - loss: 0.0058 - accuracy: 0.9987 - val_loss: 5.8961e-04 - val_accuracy: 1.0000\n",
      "Epoch 15/30\n",
      "167/167 [==============================] - 197s 1s/step - loss: 0.0034 - accuracy: 0.9989 - val_loss: 5.0044e-04 - val_accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "167/167 [==============================] - 196s 1s/step - loss: 0.0040 - accuracy: 0.9984 - val_loss: 1.8417e-05 - val_accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "167/167 [==============================] - 196s 1s/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 1.4634e-04 - val_accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "167/167 [==============================] - 196s 1s/step - loss: 0.0021 - accuracy: 0.9992 - val_loss: 2.2748e-05 - val_accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "167/167 [==============================] - 197s 1s/step - loss: 0.0012 - accuracy: 0.9997 - val_loss: 2.3692e-04 - val_accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "167/167 [==============================] - 197s 1s/step - loss: 0.0010 - accuracy: 0.9998 - val_loss: 1.6205e-06 - val_accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "167/167 [==============================] - 196s 1s/step - loss: 0.0021 - accuracy: 0.9991 - val_loss: 4.5041e-05 - val_accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "167/167 [==============================] - 197s 1s/step - loss: 6.9255e-04 - accuracy: 0.9997 - val_loss: 1.3704e-05 - val_accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "167/167 [==============================] - 197s 1s/step - loss: 9.7851e-04 - accuracy: 0.9995 - val_loss: 7.7183e-05 - val_accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "167/167 [==============================] - 196s 1s/step - loss: 0.0017 - accuracy: 0.9992 - val_loss: 5.4708e-05 - val_accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "167/167 [==============================] - 196s 1s/step - loss: 0.0014 - accuracy: 0.9995 - val_loss: 1.2304e-05 - val_accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "167/167 [==============================] - 197s 1s/step - loss: 0.0015 - accuracy: 0.9994 - val_loss: 7.4903e-05 - val_accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "167/167 [==============================] - 197s 1s/step - loss: 0.0013 - accuracy: 0.9990 - val_loss: 4.7700e-05 - val_accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "167/167 [==============================] - 197s 1s/step - loss: 0.0016 - accuracy: 0.9987 - val_loss: 8.6800e-05 - val_accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "167/167 [==============================] - 197s 1s/step - loss: 8.5035e-04 - accuracy: 0.9995 - val_loss: 1.5723e-05 - val_accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "167/167 [==============================] - 196s 1s/step - loss: 6.4920e-04 - accuracy: 0.9997 - val_loss: 4.7449e-05 - val_accuracy: 1.0000\n",
      "INFO:tensorflow:Assets written to: ../opticnet/opticnet_30epochs_8348.4_images_False_newWeights_False_lastLayerOnly_rescale-symmetric_normalization/assets\n",
      "Test acc for opticnet: 0.994835\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.24943948 0.24918694 0.24735636 0.25870474]\n",
      "Training xception for 0.25% of train size (aka 20871 images) with pretrained: True and onlyLastLayersTrained: False...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total: 135 trainable: 135\n",
      "Epoch 1/30\n",
      "  6/418 [..............................] - ETA: 8:44 - loss: 1.3997 - accuracy: 0.1300WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1623s vs `on_train_batch_begin` time: 0.1824s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1623s vs `on_train_batch_end` time: 0.8306s). Check your callbacks.\n",
      "418/418 [==============================] - 330s 778ms/step - loss: 1.2457 - accuracy: 0.7426 - val_loss: 1.0487 - val_accuracy: 0.8750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "418/418 [==============================] - 324s 774ms/step - loss: 0.8244 - accuracy: 0.9350 - val_loss: 0.8912 - val_accuracy: 0.8125\n",
      "Epoch 3/30\n",
      "418/418 [==============================] - 324s 775ms/step - loss: 0.6100 - accuracy: 0.9410 - val_loss: 0.5254 - val_accuracy: 1.0000\n",
      "Epoch 4/30\n",
      "418/418 [==============================] - 323s 774ms/step - loss: 0.4720 - accuracy: 0.9500 - val_loss: 0.5467 - val_accuracy: 0.9375\n",
      "Epoch 5/30\n",
      "418/418 [==============================] - 323s 774ms/step - loss: 0.3751 - accuracy: 0.9586 - val_loss: 0.3185 - val_accuracy: 1.0000\n",
      "Epoch 6/30\n",
      "418/418 [==============================] - 323s 772ms/step - loss: 0.3223 - accuracy: 0.9607 - val_loss: 0.3511 - val_accuracy: 0.9688\n",
      "Epoch 7/30\n",
      "418/418 [==============================] - 323s 773ms/step - loss: 0.2861 - accuracy: 0.9617 - val_loss: 0.2175 - val_accuracy: 1.0000\n",
      "Epoch 8/30\n",
      "418/418 [==============================] - 323s 774ms/step - loss: 0.2415 - accuracy: 0.9694 - val_loss: 0.1848 - val_accuracy: 1.0000\n",
      "Epoch 9/30\n",
      "418/418 [==============================] - 323s 773ms/step - loss: 0.2150 - accuracy: 0.9711 - val_loss: 0.1993 - val_accuracy: 0.9688\n",
      "Epoch 10/30\n",
      "418/418 [==============================] - 324s 775ms/step - loss: 0.1967 - accuracy: 0.9736 - val_loss: 0.1412 - val_accuracy: 1.0000\n",
      "Epoch 11/30\n",
      "418/418 [==============================] - 324s 775ms/step - loss: 0.1761 - accuracy: 0.9757 - val_loss: 0.1263 - val_accuracy: 1.0000\n",
      "Epoch 12/30\n",
      "418/418 [==============================] - 325s 778ms/step - loss: 0.1650 - accuracy: 0.9767 - val_loss: 0.1123 - val_accuracy: 1.0000\n",
      "Epoch 13/30\n",
      "418/418 [==============================] - 325s 777ms/step - loss: 0.1458 - accuracy: 0.9807 - val_loss: 0.1282 - val_accuracy: 0.9688\n",
      "Epoch 14/30\n",
      "418/418 [==============================] - 324s 776ms/step - loss: 0.1459 - accuracy: 0.9781 - val_loss: 0.0930 - val_accuracy: 1.0000\n",
      "Epoch 15/30\n",
      "418/418 [==============================] - 324s 775ms/step - loss: 0.1253 - accuracy: 0.9833 - val_loss: 0.0847 - val_accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "418/418 [==============================] - 324s 775ms/step - loss: 0.1164 - accuracy: 0.9847 - val_loss: 0.0783 - val_accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "418/418 [==============================] - 324s 775ms/step - loss: 0.1119 - accuracy: 0.9853 - val_loss: 0.0727 - val_accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "418/418 [==============================] - 324s 775ms/step - loss: 0.1017 - accuracy: 0.9870 - val_loss: 0.0681 - val_accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "418/418 [==============================] - 323s 774ms/step - loss: 0.0996 - accuracy: 0.9870 - val_loss: 0.0640 - val_accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "418/418 [==============================] - 324s 775ms/step - loss: 0.0971 - accuracy: 0.9870 - val_loss: 0.0605 - val_accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "418/418 [==============================] - 324s 774ms/step - loss: 0.0941 - accuracy: 0.9877 - val_loss: 0.0576 - val_accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "418/418 [==============================] - 324s 774ms/step - loss: 0.0874 - accuracy: 0.9889 - val_loss: 0.0551 - val_accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "418/418 [==============================] - 323s 773ms/step - loss: 0.0838 - accuracy: 0.9895 - val_loss: 0.0529 - val_accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "418/418 [==============================] - 324s 776ms/step - loss: 0.0779 - accuracy: 0.9906 - val_loss: 0.0508 - val_accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "418/418 [==============================] - 323s 773ms/step - loss: 0.0807 - accuracy: 0.9896 - val_loss: 0.0491 - val_accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "418/418 [==============================] - 324s 776ms/step - loss: 0.0867 - accuracy: 0.9877 - val_loss: 0.0477 - val_accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "418/418 [==============================] - 324s 774ms/step - loss: 0.0826 - accuracy: 0.9886 - val_loss: 0.0464 - val_accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "418/418 [==============================] - 323s 774ms/step - loss: 0.0789 - accuracy: 0.9893 - val_loss: 0.0453 - val_accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "418/418 [==============================] - 323s 774ms/step - loss: 0.0741 - accuracy: 0.9905 - val_loss: 0.0443 - val_accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "418/418 [==============================] - 323s 774ms/step - loss: 0.0768 - accuracy: 0.9897 - val_loss: 0.0434 - val_accuracy: 1.0000\n",
      "INFO:tensorflow:Assets written to: ../xception/xception_30epochs_20871.0_images_False_newWeights_False_lastLayerOnly_rescale-symmetric_normalization/assets\n",
      "Test acc for xception: 0.990702\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training resnet for 0.25% of train size (aka 20871 images) with pretrained: True and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 178 trainable: 178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/418 [..............................] - ETA: 5:00 - loss: 1.3732 - accuracy: 0.2757WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1032s vs `on_train_batch_begin` time: 0.1806s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1032s vs `on_train_batch_end` time: 0.3501s). Check your callbacks.\n",
      "418/418 [==============================] - 93s 206ms/step - loss: 1.2322 - accuracy: 0.7571 - val_loss: 1.0847 - val_accuracy: 0.6250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "418/418 [==============================] - 83s 198ms/step - loss: 0.8475 - accuracy: 0.8431 - val_loss: 0.8438 - val_accuracy: 0.9062\n",
      "Epoch 3/30\n",
      "418/418 [==============================] - 83s 198ms/step - loss: 0.6466 - accuracy: 0.9137 - val_loss: 1.4217 - val_accuracy: 0.4688\n",
      "Epoch 4/30\n",
      "418/418 [==============================] - 83s 198ms/step - loss: 0.5410 - accuracy: 0.9119 - val_loss: 0.8318 - val_accuracy: 0.8125\n",
      "Epoch 5/30\n",
      "418/418 [==============================] - 83s 198ms/step - loss: 0.4383 - accuracy: 0.9319 - val_loss: 0.4569 - val_accuracy: 0.9375\n",
      "Epoch 6/30\n",
      "418/418 [==============================] - 83s 198ms/step - loss: 0.3804 - accuracy: 0.9370 - val_loss: 0.4220 - val_accuracy: 0.9375\n",
      "Epoch 7/30\n",
      "418/418 [==============================] - 83s 198ms/step - loss: 0.3457 - accuracy: 0.9372 - val_loss: 0.5665 - val_accuracy: 0.8125\n",
      "Epoch 8/30\n",
      "418/418 [==============================] - 83s 198ms/step - loss: 0.3039 - accuracy: 0.9465 - val_loss: 0.2760 - val_accuracy: 0.9688\n",
      "Epoch 9/30\n",
      "418/418 [==============================] - 83s 198ms/step - loss: 0.2854 - accuracy: 0.9470 - val_loss: 0.1812 - val_accuracy: 1.0000\n",
      "Epoch 10/30\n",
      "418/418 [==============================] - 83s 198ms/step - loss: 0.2431 - accuracy: 0.9577 - val_loss: 0.2382 - val_accuracy: 0.9688\n",
      "Epoch 11/30\n",
      "418/418 [==============================] - 83s 198ms/step - loss: 0.2417 - accuracy: 0.9538 - val_loss: 0.1438 - val_accuracy: 1.0000\n",
      "Epoch 12/30\n",
      "418/418 [==============================] - 83s 198ms/step - loss: 0.2167 - accuracy: 0.9607 - val_loss: 0.1296 - val_accuracy: 1.0000\n",
      "Epoch 13/30\n",
      "418/418 [==============================] - 83s 198ms/step - loss: 0.2040 - accuracy: 0.9632 - val_loss: 0.1178 - val_accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "418/418 [==============================] - 83s 198ms/step - loss: 0.1832 - accuracy: 0.9682 - val_loss: 0.1074 - val_accuracy: 1.0000\n",
      "Epoch 15/30\n",
      "418/418 [==============================] - 83s 198ms/step - loss: 0.1672 - accuracy: 0.9716 - val_loss: 0.2110 - val_accuracy: 0.9375\n",
      "Epoch 16/30\n",
      "418/418 [==============================] - 83s 198ms/step - loss: 0.1569 - accuracy: 0.9736 - val_loss: 0.1623 - val_accuracy: 0.9688\n",
      "Epoch 17/30\n",
      "418/418 [==============================] - 83s 198ms/step - loss: 0.1572 - accuracy: 0.9722 - val_loss: 0.0871 - val_accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "418/418 [==============================] - 83s 198ms/step - loss: 0.1467 - accuracy: 0.9737 - val_loss: 0.1542 - val_accuracy: 0.9688\n",
      "Epoch 19/30\n",
      "418/418 [==============================] - 83s 198ms/step - loss: 0.1363 - accuracy: 0.9776 - val_loss: 0.0824 - val_accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "418/418 [==============================] - 83s 198ms/step - loss: 0.1370 - accuracy: 0.9768 - val_loss: 0.0885 - val_accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "418/418 [==============================] - 83s 198ms/step - loss: 0.1228 - accuracy: 0.9804 - val_loss: 0.0707 - val_accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "418/418 [==============================] - 83s 198ms/step - loss: 0.1210 - accuracy: 0.9801 - val_loss: 0.0839 - val_accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "418/418 [==============================] - 83s 198ms/step - loss: 0.1169 - accuracy: 0.9812 - val_loss: 0.0856 - val_accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "418/418 [==============================] - 83s 198ms/step - loss: 0.1113 - accuracy: 0.9831 - val_loss: 0.1373 - val_accuracy: 0.9688\n",
      "Epoch 25/30\n",
      "418/418 [==============================] - 83s 197ms/step - loss: 0.1072 - accuracy: 0.9845 - val_loss: 0.0611 - val_accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "418/418 [==============================] - 83s 198ms/step - loss: 0.0999 - accuracy: 0.9854 - val_loss: 0.1343 - val_accuracy: 0.9688\n",
      "Epoch 27/30\n",
      "418/418 [==============================] - 83s 198ms/step - loss: 0.1026 - accuracy: 0.9847 - val_loss: 0.0973 - val_accuracy: 0.9688\n",
      "Epoch 28/30\n",
      "418/418 [==============================] - 83s 198ms/step - loss: 0.1007 - accuracy: 0.9846 - val_loss: 0.0839 - val_accuracy: 0.9688\n",
      "Epoch 29/30\n",
      "418/418 [==============================] - 83s 198ms/step - loss: 0.0955 - accuracy: 0.9852 - val_loss: 0.1127 - val_accuracy: 0.9688\n",
      "Epoch 30/30\n",
      "418/418 [==============================] - 83s 198ms/step - loss: 0.0979 - accuracy: 0.9858 - val_loss: 0.0610 - val_accuracy: 1.0000\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_20871.0_images_False_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.993802\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training opticnet for 0.25% of train size (aka 20871 images) with pretrained: True and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 276 trainable: 276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/418 [..............................] - ETA: 12:34 - loss: 5.5873 - accuracy: 0.1659WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.4646s vs `on_train_batch_end` time: 1.0566s). Check your callbacks.\n",
      "418/418 [==============================] - 507s 1s/step - loss: 0.5623 - accuracy: 0.8535 - val_loss: 0.0121 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "418/418 [==============================] - 490s 1s/step - loss: 0.1329 - accuracy: 0.9564 - val_loss: 0.0592 - val_accuracy: 1.0000\n",
      "Epoch 3/30\n",
      "418/418 [==============================] - 491s 1s/step - loss: 0.0996 - accuracy: 0.9665 - val_loss: 0.0627 - val_accuracy: 0.9688\n",
      "Epoch 4/30\n",
      "418/418 [==============================] - 491s 1s/step - loss: 0.0878 - accuracy: 0.9712 - val_loss: 0.0043 - val_accuracy: 1.0000\n",
      "Epoch 5/30\n",
      "418/418 [==============================] - 491s 1s/step - loss: 0.0683 - accuracy: 0.9762 - val_loss: 0.0385 - val_accuracy: 1.0000\n",
      "Epoch 6/30\n",
      "418/418 [==============================] - 489s 1s/step - loss: 0.0484 - accuracy: 0.9845 - val_loss: 0.0136 - val_accuracy: 1.0000\n",
      "Epoch 7/30\n",
      "418/418 [==============================] - 491s 1s/step - loss: 0.0386 - accuracy: 0.9873 - val_loss: 0.0163 - val_accuracy: 1.0000\n",
      "Epoch 8/30\n",
      "418/418 [==============================] - 491s 1s/step - loss: 0.0297 - accuracy: 0.9901 - val_loss: 0.0168 - val_accuracy: 1.0000\n",
      "Epoch 9/30\n",
      "418/418 [==============================] - 491s 1s/step - loss: 0.0192 - accuracy: 0.9939 - val_loss: 0.0120 - val_accuracy: 1.0000\n",
      "Epoch 10/30\n",
      "418/418 [==============================] - 489s 1s/step - loss: 0.0152 - accuracy: 0.9952 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 11/30\n",
      "418/418 [==============================] - 491s 1s/step - loss: 0.0117 - accuracy: 0.9965 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
      "Epoch 12/30\n",
      "418/418 [==============================] - 492s 1s/step - loss: 0.0128 - accuracy: 0.9958 - val_loss: 0.0046 - val_accuracy: 1.0000\n",
      "Epoch 13/30\n",
      "418/418 [==============================] - 491s 1s/step - loss: 0.0078 - accuracy: 0.9979 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "418/418 [==============================] - 490s 1s/step - loss: 0.0068 - accuracy: 0.9979 - val_loss: 5.4506e-04 - val_accuracy: 1.0000\n",
      "Epoch 15/30\n",
      "418/418 [==============================] - 491s 1s/step - loss: 0.0056 - accuracy: 0.9982 - val_loss: 6.6401e-04 - val_accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "418/418 [==============================] - 489s 1s/step - loss: 0.0065 - accuracy: 0.9983 - val_loss: 9.1117e-04 - val_accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "418/418 [==============================] - 492s 1s/step - loss: 0.0069 - accuracy: 0.9981 - val_loss: 4.2792e-04 - val_accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "418/418 [==============================] - 491s 1s/step - loss: 0.0031 - accuracy: 0.9991 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "418/418 [==============================] - 490s 1s/step - loss: 0.0033 - accuracy: 0.9987 - val_loss: 5.3019e-05 - val_accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "418/418 [==============================] - 492s 1s/step - loss: 0.0033 - accuracy: 0.9987 - val_loss: 2.2873e-04 - val_accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "418/418 [==============================] - 491s 1s/step - loss: 0.0026 - accuracy: 0.9985 - val_loss: 5.3326e-05 - val_accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "418/418 [==============================] - 490s 1s/step - loss: 0.0021 - accuracy: 0.9990 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "418/418 [==============================] - 490s 1s/step - loss: 0.0017 - accuracy: 0.9992 - val_loss: 1.7339e-04 - val_accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "418/418 [==============================] - 492s 1s/step - loss: 0.0019 - accuracy: 0.9992 - val_loss: 9.4252e-05 - val_accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "418/418 [==============================] - 490s 1s/step - loss: 0.0022 - accuracy: 0.9988 - val_loss: 2.5901e-05 - val_accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "418/418 [==============================] - 489s 1s/step - loss: 0.0012 - accuracy: 0.9995 - val_loss: 1.5269e-05 - val_accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "418/418 [==============================] - 490s 1s/step - loss: 0.0016 - accuracy: 0.9990 - val_loss: 7.3847e-05 - val_accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "418/418 [==============================] - 490s 1s/step - loss: 0.0017 - accuracy: 0.9989 - val_loss: 3.1799e-05 - val_accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "418/418 [==============================] - 490s 1s/step - loss: 0.0016 - accuracy: 0.9992 - val_loss: 4.8800e-06 - val_accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "418/418 [==============================] - 489s 1s/step - loss: 0.0018 - accuracy: 0.9991 - val_loss: 6.8021e-06 - val_accuracy: 1.0000\n",
      "INFO:tensorflow:Assets written to: ../opticnet/opticnet_30epochs_20871.0_images_False_newWeights_False_lastLayerOnly_rescale-symmetric_normalization/assets\n",
      "Test acc for opticnet: 0.992769\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.40068402 0.39922053 0.39813183 0.4036676 ]\n",
      "Training xception for 0.4% of train size (aka 33393 images) with pretrained: True and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 135 trainable: 135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/668 [..............................] - ETA: 13:51 - loss: 1.3908 - accuracy: 0.4862WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1592s vs `on_train_batch_begin` time: 0.1818s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1592s vs `on_train_batch_end` time: 0.8200s). Check your callbacks.\n",
      "668/668 [==============================] - 521s 772ms/step - loss: 1.1703 - accuracy: 0.7512 - val_loss: 0.9594 - val_accuracy: 0.7188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "668/668 [==============================] - 514s 769ms/step - loss: 0.7358 - accuracy: 0.8297 - val_loss: 1.0823 - val_accuracy: 0.6250\n",
      "Epoch 3/30\n",
      "668/668 [==============================] - 513s 767ms/step - loss: 0.5809 - accuracy: 0.8352 - val_loss: 0.4599 - val_accuracy: 1.0000\n",
      "Epoch 4/30\n",
      "668/668 [==============================] - 514s 769ms/step - loss: 0.3915 - accuracy: 0.9518 - val_loss: 0.2539 - val_accuracy: 1.0000\n",
      "Epoch 5/30\n",
      "668/668 [==============================] - 515s 771ms/step - loss: 0.2668 - accuracy: 0.9607 - val_loss: 0.2342 - val_accuracy: 0.9688\n",
      "Epoch 6/30\n",
      "668/668 [==============================] - 513s 768ms/step - loss: 0.2034 - accuracy: 0.9691 - val_loss: 0.1324 - val_accuracy: 1.0000\n",
      "Epoch 7/30\n",
      "668/668 [==============================] - 514s 769ms/step - loss: 0.1724 - accuracy: 0.9733 - val_loss: 0.1022 - val_accuracy: 1.0000\n",
      "Epoch 8/30\n",
      "668/668 [==============================] - 512s 766ms/step - loss: 0.1387 - accuracy: 0.9781 - val_loss: 0.0816 - val_accuracy: 1.0000\n",
      "Epoch 9/30\n",
      "668/668 [==============================] - 513s 768ms/step - loss: 0.1201 - accuracy: 0.9811 - val_loss: 0.0671 - val_accuracy: 1.0000\n",
      "Epoch 10/30\n",
      "668/668 [==============================] - 513s 768ms/step - loss: 0.1047 - accuracy: 0.9827 - val_loss: 0.0560 - val_accuracy: 1.0000\n",
      "Epoch 11/30\n",
      "668/668 [==============================] - 513s 769ms/step - loss: 0.0907 - accuracy: 0.9848 - val_loss: 0.0471 - val_accuracy: 1.0000\n",
      "Epoch 12/30\n",
      "668/668 [==============================] - 514s 770ms/step - loss: 0.0816 - accuracy: 0.9871 - val_loss: 0.0405 - val_accuracy: 1.0000\n",
      "Epoch 13/30\n",
      "668/668 [==============================] - 513s 768ms/step - loss: 0.0667 - accuracy: 0.9898 - val_loss: 0.0357 - val_accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "668/668 [==============================] - 513s 768ms/step - loss: 0.0659 - accuracy: 0.9895 - val_loss: 0.0318 - val_accuracy: 1.0000\n",
      "Epoch 15/30\n",
      "668/668 [==============================] - 512s 767ms/step - loss: 0.0551 - accuracy: 0.9919 - val_loss: 0.0287 - val_accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "668/668 [==============================] - 513s 769ms/step - loss: 0.0559 - accuracy: 0.9914 - val_loss: 0.0263 - val_accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "668/668 [==============================] - 514s 770ms/step - loss: 0.0522 - accuracy: 0.9923 - val_loss: 0.0244 - val_accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "668/668 [==============================] - 513s 768ms/step - loss: 0.0490 - accuracy: 0.9929 - val_loss: 0.0228 - val_accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "668/668 [==============================] - 513s 768ms/step - loss: 0.0475 - accuracy: 0.9928 - val_loss: 0.0215 - val_accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "668/668 [==============================] - 511s 766ms/step - loss: 0.0452 - accuracy: 0.9933 - val_loss: 0.0204 - val_accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "668/668 [==============================] - 513s 769ms/step - loss: 0.0421 - accuracy: 0.9941 - val_loss: 0.0196 - val_accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "668/668 [==============================] - 514s 770ms/step - loss: 0.0437 - accuracy: 0.9933 - val_loss: 0.0188 - val_accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "668/668 [==============================] - 513s 767ms/step - loss: 0.0400 - accuracy: 0.9941 - val_loss: 0.0184 - val_accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "668/668 [==============================] - 512s 767ms/step - loss: 0.0427 - accuracy: 0.9937 - val_loss: 0.0177 - val_accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "668/668 [==============================] - 515s 771ms/step - loss: 0.0352 - accuracy: 0.9951 - val_loss: 0.0172 - val_accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "668/668 [==============================] - 512s 767ms/step - loss: 0.0399 - accuracy: 0.9943 - val_loss: 0.0168 - val_accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "668/668 [==============================] - 511s 765ms/step - loss: 0.0408 - accuracy: 0.9940 - val_loss: 0.0165 - val_accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "668/668 [==============================] - 512s 767ms/step - loss: 0.0419 - accuracy: 0.9936 - val_loss: 0.0162 - val_accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "668/668 [==============================] - 513s 768ms/step - loss: 0.0378 - accuracy: 0.9944 - val_loss: 0.0160 - val_accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "668/668 [==============================] - 513s 767ms/step - loss: 0.0356 - accuracy: 0.9950 - val_loss: 0.0158 - val_accuracy: 1.0000\n",
      "INFO:tensorflow:Assets written to: ../xception/xception_30epochs_33393.6_images_False_newWeights_False_lastLayerOnly_rescale-symmetric_normalization/assets\n",
      "Test acc for xception: 0.991736\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training resnet for 0.4% of train size (aka 33393 images) with pretrained: True and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 178 trainable: 178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/668 [..............................] - ETA: 8:02 - loss: 1.3590 - accuracy: 0.4099WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1023s vs `on_train_batch_begin` time: 0.1851s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1023s vs `on_train_batch_end` time: 0.3450s). Check your callbacks.\n",
      "668/668 [==============================] - 143s 204ms/step - loss: 1.1536 - accuracy: 0.8252 - val_loss: 0.8578 - val_accuracy: 0.9375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "668/668 [==============================] - 132s 197ms/step - loss: 0.6525 - accuracy: 0.9283 - val_loss: 0.9037 - val_accuracy: 0.7188\n",
      "Epoch 3/30\n",
      "668/668 [==============================] - 132s 198ms/step - loss: 0.4439 - accuracy: 0.9377 - val_loss: 0.4120 - val_accuracy: 0.9688\n",
      "Epoch 4/30\n",
      "668/668 [==============================] - 132s 198ms/step - loss: 0.3468 - accuracy: 0.9419 - val_loss: 0.2755 - val_accuracy: 0.9688\n",
      "Epoch 5/30\n",
      "668/668 [==============================] - 132s 197ms/step - loss: 0.2768 - accuracy: 0.9517 - val_loss: 0.1669 - val_accuracy: 1.0000\n",
      "Epoch 6/30\n",
      "668/668 [==============================] - 132s 197ms/step - loss: 0.2333 - accuracy: 0.9558 - val_loss: 0.1982 - val_accuracy: 0.9688\n",
      "Epoch 7/30\n",
      "668/668 [==============================] - 132s 197ms/step - loss: 0.2008 - accuracy: 0.9616 - val_loss: 0.1076 - val_accuracy: 1.0000\n",
      "Epoch 8/30\n",
      "668/668 [==============================] - 132s 197ms/step - loss: 0.1763 - accuracy: 0.9661 - val_loss: 0.0847 - val_accuracy: 1.0000\n",
      "Epoch 9/30\n",
      "668/668 [==============================] - 132s 197ms/step - loss: 0.1460 - accuracy: 0.9722 - val_loss: 0.1438 - val_accuracy: 0.9688\n",
      "Epoch 10/30\n",
      "668/668 [==============================] - 132s 197ms/step - loss: 0.1296 - accuracy: 0.9749 - val_loss: 0.1234 - val_accuracy: 0.9688\n",
      "Epoch 11/30\n",
      "668/668 [==============================] - 132s 197ms/step - loss: 0.1204 - accuracy: 0.9768 - val_loss: 0.0581 - val_accuracy: 1.0000\n",
      "Epoch 12/30\n",
      "668/668 [==============================] - 132s 198ms/step - loss: 0.0987 - accuracy: 0.9819 - val_loss: 0.0448 - val_accuracy: 1.0000\n",
      "Epoch 13/30\n",
      "668/668 [==============================] - 132s 198ms/step - loss: 0.0924 - accuracy: 0.9833 - val_loss: 0.0993 - val_accuracy: 0.9688\n",
      "Epoch 14/30\n",
      "668/668 [==============================] - 132s 198ms/step - loss: 0.0883 - accuracy: 0.9840 - val_loss: 0.0444 - val_accuracy: 1.0000\n",
      "Epoch 15/30\n",
      "668/668 [==============================] - 132s 198ms/step - loss: 0.0756 - accuracy: 0.9874 - val_loss: 0.0380 - val_accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "668/668 [==============================] - 132s 198ms/step - loss: 0.0702 - accuracy: 0.9885 - val_loss: 0.0295 - val_accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "668/668 [==============================] - 132s 197ms/step - loss: 0.0670 - accuracy: 0.9890 - val_loss: 0.0282 - val_accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "668/668 [==============================] - 132s 197ms/step - loss: 0.0574 - accuracy: 0.9910 - val_loss: 0.0298 - val_accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "668/668 [==============================] - 132s 197ms/step - loss: 0.0582 - accuracy: 0.9912 - val_loss: 0.0254 - val_accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "668/668 [==============================] - 132s 198ms/step - loss: 0.0561 - accuracy: 0.9912 - val_loss: 0.0243 - val_accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "668/668 [==============================] - 132s 198ms/step - loss: 0.0533 - accuracy: 0.9920 - val_loss: 0.0241 - val_accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "668/668 [==============================] - 132s 198ms/step - loss: 0.0520 - accuracy: 0.9923 - val_loss: 0.0310 - val_accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "668/668 [==============================] - 132s 197ms/step - loss: 0.0545 - accuracy: 0.9915 - val_loss: 0.0266 - val_accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "668/668 [==============================] - 132s 197ms/step - loss: 0.0505 - accuracy: 0.9923 - val_loss: 0.0213 - val_accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "668/668 [==============================] - 132s 197ms/step - loss: 0.0505 - accuracy: 0.9923 - val_loss: 0.0215 - val_accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "668/668 [==============================] - 132s 197ms/step - loss: 0.0455 - accuracy: 0.9936 - val_loss: 0.0200 - val_accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "668/668 [==============================] - 132s 198ms/step - loss: 0.0518 - accuracy: 0.9918 - val_loss: 0.0192 - val_accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "668/668 [==============================] - 132s 197ms/step - loss: 0.0465 - accuracy: 0.9928 - val_loss: 0.0183 - val_accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "668/668 [==============================] - 132s 198ms/step - loss: 0.0441 - accuracy: 0.9934 - val_loss: 0.0189 - val_accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "668/668 [==============================] - 132s 197ms/step - loss: 0.0428 - accuracy: 0.9940 - val_loss: 0.0181 - val_accuracy: 1.0000\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_33393.6_images_False_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.991736\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training opticnet for 0.4% of train size (aka 33393 images) with pretrained: True and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 276 trainable: 276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/668 [..............................] - ETA: 20:11 - loss: 5.5256 - accuracy: 0.1183  WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.4664s vs `on_train_batch_end` time: 1.0559s). Check your callbacks.\n",
      "668/668 [==============================] - 800s 1s/step - loss: 0.4488 - accuracy: 0.8747 - val_loss: 0.1007 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "668/668 [==============================] - 784s 1s/step - loss: 0.1272 - accuracy: 0.9587 - val_loss: 0.0375 - val_accuracy: 1.0000\n",
      "Epoch 3/30\n",
      "668/668 [==============================] - 783s 1s/step - loss: 0.1063 - accuracy: 0.9655 - val_loss: 0.0201 - val_accuracy: 1.0000\n",
      "Epoch 4/30\n",
      "668/668 [==============================] - 783s 1s/step - loss: 0.0835 - accuracy: 0.9726 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
      "Epoch 5/30\n",
      "668/668 [==============================] - 784s 1s/step - loss: 0.0687 - accuracy: 0.9772 - val_loss: 0.0457 - val_accuracy: 1.0000\n",
      "Epoch 6/30\n",
      "668/668 [==============================] - 781s 1s/step - loss: 0.0527 - accuracy: 0.9827 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
      "Epoch 7/30\n",
      "668/668 [==============================] - 782s 1s/step - loss: 0.0356 - accuracy: 0.9882 - val_loss: 0.0035 - val_accuracy: 1.0000\n",
      "Epoch 8/30\n",
      "668/668 [==============================] - 782s 1s/step - loss: 0.0294 - accuracy: 0.9897 - val_loss: 9.6450e-04 - val_accuracy: 1.0000\n",
      "Epoch 9/30\n",
      "668/668 [==============================] - 782s 1s/step - loss: 0.0202 - accuracy: 0.9945 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
      "Epoch 10/30\n",
      "668/668 [==============================] - 781s 1s/step - loss: 0.0216 - accuracy: 0.9936 - val_loss: 6.1803e-04 - val_accuracy: 1.0000\n",
      "Epoch 11/30\n",
      "668/668 [==============================] - 779s 1s/step - loss: 0.0153 - accuracy: 0.9952 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
      "Epoch 12/30\n",
      "668/668 [==============================] - 780s 1s/step - loss: 0.0124 - accuracy: 0.9957 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
      "Epoch 13/30\n",
      "668/668 [==============================] - 783s 1s/step - loss: 0.0102 - accuracy: 0.9971 - val_loss: 3.6934e-04 - val_accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "668/668 [==============================] - 784s 1s/step - loss: 0.0072 - accuracy: 0.9979 - val_loss: 0.0045 - val_accuracy: 1.0000\n",
      "Epoch 15/30\n",
      "668/668 [==============================] - 782s 1s/step - loss: 0.0083 - accuracy: 0.9980 - val_loss: 3.1990e-04 - val_accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "668/668 [==============================] - 781s 1s/step - loss: 0.0049 - accuracy: 0.9986 - val_loss: 6.7137e-04 - val_accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "668/668 [==============================] - 783s 1s/step - loss: 0.0083 - accuracy: 0.9971 - val_loss: 2.6446e-04 - val_accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "668/668 [==============================] - 781s 1s/step - loss: 0.0054 - accuracy: 0.9982 - val_loss: 2.8171e-05 - val_accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "668/668 [==============================] - 783s 1s/step - loss: 0.0039 - accuracy: 0.9985 - val_loss: 8.3336e-05 - val_accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "668/668 [==============================] - 783s 1s/step - loss: 0.0054 - accuracy: 0.9979 - val_loss: 5.3457e-05 - val_accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "668/668 [==============================] - 784s 1s/step - loss: 0.0037 - accuracy: 0.9983 - val_loss: 1.9769e-04 - val_accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "668/668 [==============================] - 783s 1s/step - loss: 0.0035 - accuracy: 0.9982 - val_loss: 4.1228e-05 - val_accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "668/668 [==============================] - 783s 1s/step - loss: 0.0039 - accuracy: 0.9981 - val_loss: 1.4351e-04 - val_accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "668/668 [==============================] - 783s 1s/step - loss: 0.0027 - accuracy: 0.9985 - val_loss: 5.7101e-05 - val_accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "668/668 [==============================] - 783s 1s/step - loss: 0.0018 - accuracy: 0.9991 - val_loss: 6.3323e-05 - val_accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "668/668 [==============================] - 783s 1s/step - loss: 0.0025 - accuracy: 0.9984 - val_loss: 2.7211e-05 - val_accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "668/668 [==============================] - 783s 1s/step - loss: 0.0020 - accuracy: 0.9989 - val_loss: 3.1450e-05 - val_accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "668/668 [==============================] - 781s 1s/step - loss: 0.0022 - accuracy: 0.9987 - val_loss: 1.4509e-05 - val_accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "668/668 [==============================] - 782s 1s/step - loss: 0.0021 - accuracy: 0.9989 - val_loss: 7.7357e-05 - val_accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "668/668 [==============================] - 783s 1s/step - loss: 0.0021 - accuracy: 0.9987 - val_loss: 1.3988e-05 - val_accuracy: 1.0000\n",
      "INFO:tensorflow:Assets written to: ../opticnet/opticnet_30epochs_33393.6_images_False_newWeights_False_lastLayerOnly_rescale-symmetric_normalization/assets\n",
      "Test acc for opticnet: 0.993802\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.49766293 0.4985889  0.50608037 0.50522284]\n",
      "Training xception for 0.5% of train size (aka 41742 images) with pretrained: True and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 135 trainable: 135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/835 [..............................] - ETA: 18:02 - loss: 1.3714 - accuracy: 0.5129WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1607s vs `on_train_batch_begin` time: 0.1871s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1607s vs `on_train_batch_end` time: 0.8559s). Check your callbacks.\n",
      "835/835 [==============================] - 650s 772ms/step - loss: 1.1256 - accuracy: 0.8040 - val_loss: 0.9440 - val_accuracy: 0.6875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "835/835 [==============================] - 640s 767ms/step - loss: 0.6580 - accuracy: 0.8339 - val_loss: 0.4423 - val_accuracy: 1.0000\n",
      "Epoch 3/30\n",
      "835/835 [==============================] - 641s 768ms/step - loss: 0.3666 - accuracy: 0.9578 - val_loss: 0.2333 - val_accuracy: 1.0000\n",
      "Epoch 4/30\n",
      "835/835 [==============================] - 641s 768ms/step - loss: 0.2447 - accuracy: 0.9645 - val_loss: 0.1539 - val_accuracy: 1.0000\n",
      "Epoch 5/30\n",
      "835/835 [==============================] - 643s 770ms/step - loss: 0.1785 - accuracy: 0.9739 - val_loss: 0.1023 - val_accuracy: 1.0000\n",
      "Epoch 6/30\n",
      "835/835 [==============================] - 641s 768ms/step - loss: 0.1332 - accuracy: 0.9796 - val_loss: 0.0726 - val_accuracy: 1.0000\n",
      "Epoch 7/30\n",
      "835/835 [==============================] - 643s 771ms/step - loss: 0.1032 - accuracy: 0.9841 - val_loss: 0.0546 - val_accuracy: 1.0000\n",
      "Epoch 8/30\n",
      "835/835 [==============================] - 642s 769ms/step - loss: 0.0843 - accuracy: 0.9865 - val_loss: 0.0486 - val_accuracy: 1.0000\n",
      "Epoch 9/30\n",
      "835/835 [==============================] - 644s 771ms/step - loss: 0.0695 - accuracy: 0.9889 - val_loss: 0.0344 - val_accuracy: 1.0000\n",
      "Epoch 10/30\n",
      "835/835 [==============================] - 643s 770ms/step - loss: 0.0638 - accuracy: 0.9901 - val_loss: 0.0285 - val_accuracy: 1.0000\n",
      "Epoch 11/30\n",
      "835/835 [==============================] - 643s 770ms/step - loss: 0.0558 - accuracy: 0.9913 - val_loss: 0.0575 - val_accuracy: 0.9688\n",
      "Epoch 12/30\n",
      "835/835 [==============================] - 642s 769ms/step - loss: 0.0508 - accuracy: 0.9922 - val_loss: 0.0213 - val_accuracy: 1.0000\n",
      "Epoch 13/30\n",
      "835/835 [==============================] - 642s 769ms/step - loss: 0.0497 - accuracy: 0.9919 - val_loss: 0.0191 - val_accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "835/835 [==============================] - 643s 770ms/step - loss: 0.0448 - accuracy: 0.9932 - val_loss: 0.0175 - val_accuracy: 1.0000\n",
      "Epoch 15/30\n",
      "835/835 [==============================] - 644s 772ms/step - loss: 0.0440 - accuracy: 0.9930 - val_loss: 0.0165 - val_accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "835/835 [==============================] - 644s 771ms/step - loss: 0.0441 - accuracy: 0.9927 - val_loss: 0.0149 - val_accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "835/835 [==============================] - 646s 774ms/step - loss: 0.0426 - accuracy: 0.9931 - val_loss: 0.0140 - val_accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "835/835 [==============================] - 645s 773ms/step - loss: 0.0396 - accuracy: 0.9939 - val_loss: 0.0135 - val_accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "835/835 [==============================] - 647s 774ms/step - loss: 0.0396 - accuracy: 0.9937 - val_loss: 0.0129 - val_accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "835/835 [==============================] - 649s 777ms/step - loss: 0.0369 - accuracy: 0.9944 - val_loss: 0.0127 - val_accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "835/835 [==============================] - 646s 774ms/step - loss: 0.0345 - accuracy: 0.9945 - val_loss: 0.0122 - val_accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "835/835 [==============================] - 648s 776ms/step - loss: 0.0381 - accuracy: 0.9938 - val_loss: 0.0118 - val_accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "835/835 [==============================] - 647s 775ms/step - loss: 0.0342 - accuracy: 0.9947 - val_loss: 0.0117 - val_accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "835/835 [==============================] - 647s 775ms/step - loss: 0.0331 - accuracy: 0.9948 - val_loss: 0.0113 - val_accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "835/835 [==============================] - 647s 775ms/step - loss: 0.0288 - accuracy: 0.9958 - val_loss: 0.0113 - val_accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "835/835 [==============================] - 648s 776ms/step - loss: 0.0312 - accuracy: 0.9950 - val_loss: 0.0110 - val_accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "835/835 [==============================] - 649s 777ms/step - loss: 0.0321 - accuracy: 0.9952 - val_loss: 0.0109 - val_accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "835/835 [==============================] - 649s 777ms/step - loss: 0.0346 - accuracy: 0.9944 - val_loss: 0.0110 - val_accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "835/835 [==============================] - 647s 775ms/step - loss: 0.0311 - accuracy: 0.9952 - val_loss: 0.0106 - val_accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "835/835 [==============================] - 647s 775ms/step - loss: 0.0320 - accuracy: 0.9950 - val_loss: 0.0104 - val_accuracy: 1.0000\n",
      "INFO:tensorflow:Assets written to: ../xception/xception_30epochs_41742.0_images_False_newWeights_False_lastLayerOnly_rescale-symmetric_normalization/assets\n",
      "Test acc for xception: 0.988636\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training resnet for 0.5% of train size (aka 41742 images) with pretrained: True and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 178 trainable: 178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/835 [..............................] - ETA: 9:51 - loss: 1.3796 - accuracy: 0.3039 WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1020s vs `on_train_batch_begin` time: 0.1830s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1020s vs `on_train_batch_end` time: 0.3358s). Check your callbacks.\n",
      "835/835 [==============================] - 175s 202ms/step - loss: 1.1282 - accuracy: 0.7738 - val_loss: 0.8278 - val_accuracy: 0.8750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "835/835 [==============================] - 166s 198ms/step - loss: 0.5545 - accuracy: 0.9437 - val_loss: 0.6415 - val_accuracy: 0.8750\n",
      "Epoch 3/30\n",
      "835/835 [==============================] - 166s 198ms/step - loss: 0.3493 - accuracy: 0.9517 - val_loss: 0.2709 - val_accuracy: 0.9688\n",
      "Epoch 4/30\n",
      "835/835 [==============================] - 165s 198ms/step - loss: 0.2477 - accuracy: 0.9611 - val_loss: 0.1633 - val_accuracy: 1.0000\n",
      "Epoch 5/30\n",
      "835/835 [==============================] - 166s 198ms/step - loss: 0.1881 - accuracy: 0.9681 - val_loss: 0.1657 - val_accuracy: 0.9688\n",
      "Epoch 6/30\n",
      "835/835 [==============================] - 166s 199ms/step - loss: 0.1491 - accuracy: 0.9740 - val_loss: 0.0857 - val_accuracy: 1.0000\n",
      "Epoch 7/30\n",
      "835/835 [==============================] - 166s 198ms/step - loss: 0.1159 - accuracy: 0.9795 - val_loss: 0.0637 - val_accuracy: 1.0000\n",
      "Epoch 8/30\n",
      "835/835 [==============================] - 165s 198ms/step - loss: 0.0992 - accuracy: 0.9825 - val_loss: 0.0514 - val_accuracy: 1.0000\n",
      "Epoch 9/30\n",
      "835/835 [==============================] - 166s 198ms/step - loss: 0.0877 - accuracy: 0.9842 - val_loss: 0.0366 - val_accuracy: 1.0000\n",
      "Epoch 10/30\n",
      "835/835 [==============================] - 165s 198ms/step - loss: 0.0766 - accuracy: 0.9866 - val_loss: 0.0312 - val_accuracy: 1.0000\n",
      "Epoch 11/30\n",
      "835/835 [==============================] - 166s 198ms/step - loss: 0.0672 - accuracy: 0.9890 - val_loss: 0.0285 - val_accuracy: 1.0000\n",
      "Epoch 12/30\n",
      "835/835 [==============================] - 165s 198ms/step - loss: 0.0626 - accuracy: 0.9892 - val_loss: 0.0230 - val_accuracy: 1.0000\n",
      "Epoch 13/30\n",
      "835/835 [==============================] - 166s 198ms/step - loss: 0.0585 - accuracy: 0.9899 - val_loss: 0.0272 - val_accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "835/835 [==============================] - 166s 199ms/step - loss: 0.0527 - accuracy: 0.9911 - val_loss: 0.0279 - val_accuracy: 1.0000\n",
      "Epoch 15/30\n",
      "835/835 [==============================] - 166s 199ms/step - loss: 0.0472 - accuracy: 0.9922 - val_loss: 0.0222 - val_accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "835/835 [==============================] - 166s 199ms/step - loss: 0.0442 - accuracy: 0.9930 - val_loss: 0.0642 - val_accuracy: 0.9688\n",
      "Epoch 17/30\n",
      "835/835 [==============================] - 166s 198ms/step - loss: 0.0434 - accuracy: 0.9931 - val_loss: 0.0434 - val_accuracy: 0.9688\n",
      "Epoch 18/30\n",
      "835/835 [==============================] - 165s 198ms/step - loss: 0.0434 - accuracy: 0.9933 - val_loss: 0.0966 - val_accuracy: 0.9688\n",
      "Epoch 19/30\n",
      "835/835 [==============================] - 166s 198ms/step - loss: 0.0403 - accuracy: 0.9934 - val_loss: 0.1173 - val_accuracy: 0.9688\n",
      "Epoch 20/30\n",
      "835/835 [==============================] - 166s 199ms/step - loss: 0.0373 - accuracy: 0.9939 - val_loss: 0.1045 - val_accuracy: 0.9375\n",
      "Epoch 21/30\n",
      "835/835 [==============================] - 166s 199ms/step - loss: 0.0370 - accuracy: 0.9943 - val_loss: 0.1156 - val_accuracy: 0.9688\n",
      "Epoch 22/30\n",
      "835/835 [==============================] - 166s 198ms/step - loss: 0.0321 - accuracy: 0.9951 - val_loss: 0.1335 - val_accuracy: 0.9688\n",
      "Epoch 23/30\n",
      "835/835 [==============================] - 166s 198ms/step - loss: 0.0352 - accuracy: 0.9948 - val_loss: 0.1275 - val_accuracy: 0.9375\n",
      "Epoch 24/30\n",
      "835/835 [==============================] - 166s 199ms/step - loss: 0.0374 - accuracy: 0.9943 - val_loss: 0.1526 - val_accuracy: 0.9375\n",
      "Epoch 25/30\n",
      "835/835 [==============================] - 166s 198ms/step - loss: 0.0342 - accuracy: 0.9948 - val_loss: 0.1663 - val_accuracy: 0.9375\n",
      "Epoch 26/30\n",
      "835/835 [==============================] - 166s 198ms/step - loss: 0.0350 - accuracy: 0.9944 - val_loss: 0.1559 - val_accuracy: 0.9375\n",
      "Epoch 27/30\n",
      "835/835 [==============================] - 166s 198ms/step - loss: 0.0334 - accuracy: 0.9951 - val_loss: 0.2050 - val_accuracy: 0.9375\n",
      "Epoch 28/30\n",
      "835/835 [==============================] - 166s 198ms/step - loss: 0.0332 - accuracy: 0.9946 - val_loss: 0.1757 - val_accuracy: 0.9375\n",
      "Epoch 29/30\n",
      "835/835 [==============================] - 166s 198ms/step - loss: 0.0331 - accuracy: 0.9948 - val_loss: 0.1510 - val_accuracy: 0.9375\n",
      "Epoch 30/30\n",
      "835/835 [==============================] - 166s 198ms/step - loss: 0.0299 - accuracy: 0.9952 - val_loss: 0.1486 - val_accuracy: 0.9688\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_41742.0_images_False_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.991736\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training opticnet for 0.5% of train size (aka 41742 images) with pretrained: True and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 276 trainable: 276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/835 [..............................] - ETA: 25:28 - loss: 5.7337 - accuracy: 0.1174  WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.4648s vs `on_train_batch_end` time: 1.0695s). Check your callbacks.\n",
      "835/835 [==============================] - 998s 1s/step - loss: 0.3976 - accuracy: 0.8877 - val_loss: 0.0208 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "835/835 [==============================] - 981s 1s/step - loss: 0.1272 - accuracy: 0.9577 - val_loss: 0.0355 - val_accuracy: 1.0000\n",
      "Epoch 3/30\n",
      "835/835 [==============================] - 982s 1s/step - loss: 0.1037 - accuracy: 0.9644 - val_loss: 0.0581 - val_accuracy: 1.0000\n",
      "Epoch 4/30\n",
      "835/835 [==============================] - 979s 1s/step - loss: 0.0869 - accuracy: 0.9707 - val_loss: 0.0214 - val_accuracy: 1.0000\n",
      "Epoch 5/30\n",
      "835/835 [==============================] - 984s 1s/step - loss: 0.0690 - accuracy: 0.9756 - val_loss: 0.0449 - val_accuracy: 0.9688\n",
      "Epoch 6/30\n",
      "835/835 [==============================] - 984s 1s/step - loss: 0.0590 - accuracy: 0.9804 - val_loss: 0.0319 - val_accuracy: 1.0000\n",
      "Epoch 7/30\n",
      "835/835 [==============================] - 983s 1s/step - loss: 0.0417 - accuracy: 0.9866 - val_loss: 0.0174 - val_accuracy: 1.0000\n",
      "Epoch 8/30\n",
      "835/835 [==============================] - 984s 1s/step - loss: 0.0333 - accuracy: 0.9886 - val_loss: 0.0242 - val_accuracy: 1.0000\n",
      "Epoch 9/30\n",
      "835/835 [==============================] - 977s 1s/step - loss: 0.0245 - accuracy: 0.9921 - val_loss: 0.1674 - val_accuracy: 0.9688\n",
      "Epoch 10/30\n",
      "835/835 [==============================] - 983s 1s/step - loss: 0.0210 - accuracy: 0.9941 - val_loss: 0.0530 - val_accuracy: 0.9688\n",
      "Epoch 11/30\n",
      "835/835 [==============================] - 978s 1s/step - loss: 0.0163 - accuracy: 0.9951 - val_loss: 0.1190 - val_accuracy: 0.9688\n",
      "Epoch 12/30\n",
      "835/835 [==============================] - 979s 1s/step - loss: 0.0118 - accuracy: 0.9966 - val_loss: 0.0664 - val_accuracy: 0.9688\n",
      "Epoch 13/30\n",
      "835/835 [==============================] - 972s 1s/step - loss: 0.0116 - accuracy: 0.9965 - val_loss: 0.0461 - val_accuracy: 0.9688\n",
      "Epoch 14/30\n",
      "835/835 [==============================] - 979s 1s/step - loss: 0.0118 - accuracy: 0.9966 - val_loss: 0.2903 - val_accuracy: 0.9688\n",
      "Epoch 15/30\n",
      "835/835 [==============================] - 983s 1s/step - loss: 0.0077 - accuracy: 0.9977 - val_loss: 0.0898 - val_accuracy: 0.9688\n",
      "Epoch 16/30\n",
      "835/835 [==============================] - 983s 1s/step - loss: 0.0057 - accuracy: 0.9981 - val_loss: 0.0965 - val_accuracy: 0.9688\n",
      "Epoch 17/30\n",
      "835/835 [==============================] - 983s 1s/step - loss: 0.0073 - accuracy: 0.9977 - val_loss: 0.0710 - val_accuracy: 0.9688\n",
      "Epoch 18/30\n",
      "835/835 [==============================] - 982s 1s/step - loss: 0.0052 - accuracy: 0.9981 - val_loss: 0.1379 - val_accuracy: 0.9688\n",
      "Epoch 19/30\n",
      "835/835 [==============================] - 983s 1s/step - loss: 0.0048 - accuracy: 0.9982 - val_loss: 0.1584 - val_accuracy: 0.9688\n",
      "Epoch 20/30\n",
      "835/835 [==============================] - 979s 1s/step - loss: 0.0038 - accuracy: 0.9983 - val_loss: 0.0999 - val_accuracy: 0.9688\n",
      "Epoch 21/30\n",
      "835/835 [==============================] - 976s 1s/step - loss: 0.0049 - accuracy: 0.9977 - val_loss: 0.1642 - val_accuracy: 0.9688\n",
      "Epoch 22/30\n",
      "835/835 [==============================] - 982s 1s/step - loss: 0.0034 - accuracy: 0.9982 - val_loss: 0.1249 - val_accuracy: 0.9688\n",
      "Epoch 23/30\n",
      "835/835 [==============================] - 982s 1s/step - loss: 0.0030 - accuracy: 0.9984 - val_loss: 0.1085 - val_accuracy: 0.9688\n",
      "Epoch 24/30\n",
      "835/835 [==============================] - 982s 1s/step - loss: 0.0033 - accuracy: 0.9984 - val_loss: 0.2203 - val_accuracy: 0.9688\n",
      "Epoch 25/30\n",
      "835/835 [==============================] - 982s 1s/step - loss: 0.0033 - accuracy: 0.9977 - val_loss: 0.1495 - val_accuracy: 0.9688\n",
      "Epoch 26/30\n",
      "835/835 [==============================] - 979s 1s/step - loss: 0.0031 - accuracy: 0.9980 - val_loss: 0.1405 - val_accuracy: 0.9688\n",
      "Epoch 27/30\n",
      "835/835 [==============================] - 981s 1s/step - loss: 0.0025 - accuracy: 0.9984 - val_loss: 0.1864 - val_accuracy: 0.9688\n",
      "Epoch 28/30\n",
      "835/835 [==============================] - 975s 1s/step - loss: 0.0029 - accuracy: 0.9983 - val_loss: 0.1728 - val_accuracy: 0.9688\n",
      "Epoch 29/30\n",
      "835/835 [==============================] - 966s 1s/step - loss: 0.0022 - accuracy: 0.9985 - val_loss: 0.1413 - val_accuracy: 0.9688\n",
      "Epoch 30/30\n",
      "835/835 [==============================] - 968s 1s/step - loss: 0.0022 - accuracy: 0.9986 - val_loss: 0.1830 - val_accuracy: 0.9688\n",
      "INFO:tensorflow:Assets written to: ../opticnet/opticnet_30epochs_41742.0_images_False_newWeights_False_lastLayerOnly_rescale-symmetric_normalization/assets\n",
      "Test acc for opticnet: 0.996901\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.59832795 0.59790351 0.60750793 0.6042247 ]\n",
      "Training xception for 0.6% of train size (aka 50090 images) with pretrained: True and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 135 trainable: 135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "   6/1002 [..............................] - ETA: 21:35 - loss: 1.3839 - accuracy: 0.3046WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1602s vs `on_train_batch_begin` time: 0.1839s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1602s vs `on_train_batch_end` time: 0.8550s). Check your callbacks.\n",
      "1002/1002 [==============================] - 783s 777ms/step - loss: 1.0743 - accuracy: 0.7818 - val_loss: 0.5786 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "1002/1002 [==============================] - 771s 769ms/step - loss: 0.4472 - accuracy: 0.9635 - val_loss: 0.2789 - val_accuracy: 1.0000\n",
      "Epoch 3/30\n",
      "1002/1002 [==============================] - 774s 773ms/step - loss: 0.2604 - accuracy: 0.9689 - val_loss: 0.1560 - val_accuracy: 1.0000\n",
      "Epoch 4/30\n",
      "1002/1002 [==============================] - 775s 773ms/step - loss: 0.1775 - accuracy: 0.9748 - val_loss: 0.0976 - val_accuracy: 1.0000\n",
      "Epoch 5/30\n",
      "1002/1002 [==============================] - 775s 774ms/step - loss: 0.1188 - accuracy: 0.9840 - val_loss: 0.0654 - val_accuracy: 1.0000\n",
      "Epoch 6/30\n",
      "1002/1002 [==============================] - 775s 773ms/step - loss: 0.0898 - accuracy: 0.9870 - val_loss: 0.0473 - val_accuracy: 1.0000\n",
      "Epoch 7/30\n",
      "1002/1002 [==============================] - 776s 775ms/step - loss: 0.0697 - accuracy: 0.9897 - val_loss: 0.0395 - val_accuracy: 1.0000\n",
      "Epoch 8/30\n",
      "1002/1002 [==============================] - 775s 773ms/step - loss: 0.0586 - accuracy: 0.9910 - val_loss: 0.0814 - val_accuracy: 0.9688\n",
      "Epoch 9/30\n",
      "1002/1002 [==============================] - 776s 774ms/step - loss: 0.0512 - accuracy: 0.9919 - val_loss: 0.1207 - val_accuracy: 0.9688\n",
      "Epoch 10/30\n",
      "1002/1002 [==============================] - 775s 773ms/step - loss: 0.0464 - accuracy: 0.9926 - val_loss: 0.0589 - val_accuracy: 0.9688\n",
      "Epoch 11/30\n",
      "1002/1002 [==============================] - 778s 777ms/step - loss: 0.0427 - accuracy: 0.9932 - val_loss: 0.0174 - val_accuracy: 1.0000\n",
      "Epoch 12/30\n",
      "1002/1002 [==============================] - 778s 776ms/step - loss: 0.0386 - accuracy: 0.9937 - val_loss: 0.0738 - val_accuracy: 0.9688\n",
      "Epoch 13/30\n",
      "1002/1002 [==============================] - 773s 771ms/step - loss: 0.0380 - accuracy: 0.9939 - val_loss: 0.0130 - val_accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "1002/1002 [==============================] - 777s 776ms/step - loss: 0.0349 - accuracy: 0.9942 - val_loss: 0.0186 - val_accuracy: 1.0000\n",
      "Epoch 15/30\n",
      "1002/1002 [==============================] - 771s 770ms/step - loss: 0.0324 - accuracy: 0.9948 - val_loss: 0.0697 - val_accuracy: 0.9688\n",
      "Epoch 16/30\n",
      "1002/1002 [==============================] - 775s 773ms/step - loss: 0.0315 - accuracy: 0.9949 - val_loss: 0.1291 - val_accuracy: 0.9688\n",
      "Epoch 17/30\n",
      "1002/1002 [==============================] - 773s 772ms/step - loss: 0.0322 - accuracy: 0.9946 - val_loss: 0.0822 - val_accuracy: 0.9688\n",
      "Epoch 18/30\n",
      "1002/1002 [==============================] - 778s 777ms/step - loss: 0.0319 - accuracy: 0.9948 - val_loss: 0.0784 - val_accuracy: 0.9688\n",
      "Epoch 19/30\n",
      "1002/1002 [==============================] - 776s 774ms/step - loss: 0.0304 - accuracy: 0.9949 - val_loss: 0.0343 - val_accuracy: 0.9688\n",
      "Epoch 20/30\n",
      "1002/1002 [==============================] - 776s 774ms/step - loss: 0.0277 - accuracy: 0.9956 - val_loss: 0.1588 - val_accuracy: 0.9688\n",
      "Epoch 21/30\n",
      "1002/1002 [==============================] - 777s 775ms/step - loss: 0.0273 - accuracy: 0.9955 - val_loss: 0.1765 - val_accuracy: 0.9688\n",
      "Epoch 22/30\n",
      "1002/1002 [==============================] - 774s 772ms/step - loss: 0.0289 - accuracy: 0.9953 - val_loss: 0.1631 - val_accuracy: 0.9688\n",
      "Epoch 23/30\n",
      "1002/1002 [==============================] - 774s 773ms/step - loss: 0.0302 - accuracy: 0.9953 - val_loss: 0.1973 - val_accuracy: 0.9688\n",
      "Epoch 24/30\n",
      "1002/1002 [==============================] - 776s 775ms/step - loss: 0.0276 - accuracy: 0.9953 - val_loss: 0.1828 - val_accuracy: 0.9688\n",
      "Epoch 25/30\n",
      "1002/1002 [==============================] - 776s 775ms/step - loss: 0.0282 - accuracy: 0.9952 - val_loss: 0.1808 - val_accuracy: 0.9688\n",
      "Epoch 26/30\n",
      "1002/1002 [==============================] - 774s 773ms/step - loss: 0.0260 - accuracy: 0.9958 - val_loss: 0.0490 - val_accuracy: 0.9688\n",
      "Epoch 27/30\n",
      "1002/1002 [==============================] - 774s 773ms/step - loss: 0.0262 - accuracy: 0.9957 - val_loss: 0.1980 - val_accuracy: 0.9688\n",
      "Epoch 28/30\n",
      "1002/1002 [==============================] - 776s 775ms/step - loss: 0.0245 - accuracy: 0.9965 - val_loss: 0.1705 - val_accuracy: 0.9688\n",
      "Epoch 29/30\n",
      "1002/1002 [==============================] - 778s 776ms/step - loss: 0.0254 - accuracy: 0.9961 - val_loss: 0.1771 - val_accuracy: 0.9688\n",
      "Epoch 30/30\n",
      "1002/1002 [==============================] - 779s 778ms/step - loss: 0.0240 - accuracy: 0.9963 - val_loss: 0.1858 - val_accuracy: 0.9688\n",
      "INFO:tensorflow:Assets written to: ../xception/xception_30epochs_50090.4_images_False_newWeights_False_lastLayerOnly_rescale-symmetric_normalization/assets\n",
      "Test acc for xception: 0.991736\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training resnet for 0.6% of train size (aka 50090 images) with pretrained: True and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 178 trainable: 178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "   6/1002 [..............................] - ETA: 11:51 - loss: 1.3811 - accuracy: 0.2997WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1014s vs `on_train_batch_begin` time: 0.1771s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1014s vs `on_train_batch_end` time: 0.3423s). Check your callbacks.\n",
      "1002/1002 [==============================] - 208s 200ms/step - loss: 1.0733 - accuracy: 0.8098 - val_loss: 0.6884 - val_accuracy: 0.9375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "1002/1002 [==============================] - 198s 198ms/step - loss: 0.4499 - accuracy: 0.9597 - val_loss: 0.3266 - val_accuracy: 0.9688\n",
      "Epoch 3/30\n",
      "1002/1002 [==============================] - 198s 198ms/step - loss: 0.2583 - accuracy: 0.9686 - val_loss: 0.1540 - val_accuracy: 1.0000\n",
      "Epoch 4/30\n",
      "1002/1002 [==============================] - 198s 198ms/step - loss: 0.1724 - accuracy: 0.9760 - val_loss: 0.2048 - val_accuracy: 0.9688\n",
      "Epoch 5/30\n",
      "1002/1002 [==============================] - 198s 197ms/step - loss: 0.1234 - accuracy: 0.9816 - val_loss: 0.1820 - val_accuracy: 0.9688\n",
      "Epoch 6/30\n",
      "1002/1002 [==============================] - 198s 197ms/step - loss: 0.0984 - accuracy: 0.9842 - val_loss: 0.0447 - val_accuracy: 1.0000\n",
      "Epoch 7/30\n",
      "1002/1002 [==============================] - 198s 198ms/step - loss: 0.0779 - accuracy: 0.9870 - val_loss: 0.0426 - val_accuracy: 1.0000\n",
      "Epoch 8/30\n",
      "1002/1002 [==============================] - 198s 198ms/step - loss: 0.0649 - accuracy: 0.9889 - val_loss: 0.1110 - val_accuracy: 0.9688\n",
      "Epoch 9/30\n",
      "1002/1002 [==============================] - 198s 198ms/step - loss: 0.0551 - accuracy: 0.9907 - val_loss: 0.0462 - val_accuracy: 1.0000\n",
      "Epoch 10/30\n",
      "1002/1002 [==============================] - 198s 198ms/step - loss: 0.0525 - accuracy: 0.9906 - val_loss: 0.0409 - val_accuracy: 1.0000\n",
      "Epoch 11/30\n",
      "1002/1002 [==============================] - 198s 198ms/step - loss: 0.0496 - accuracy: 0.9916 - val_loss: 0.0167 - val_accuracy: 1.0000\n",
      "Epoch 12/30\n",
      "1002/1002 [==============================] - 198s 198ms/step - loss: 0.0432 - accuracy: 0.9930 - val_loss: 0.0159 - val_accuracy: 1.0000\n",
      "Epoch 13/30\n",
      "1002/1002 [==============================] - 198s 197ms/step - loss: 0.0414 - accuracy: 0.9934 - val_loss: 0.0302 - val_accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "1002/1002 [==============================] - 198s 198ms/step - loss: 0.0367 - accuracy: 0.9943 - val_loss: 0.1159 - val_accuracy: 0.9688\n",
      "Epoch 15/30\n",
      "1002/1002 [==============================] - 198s 198ms/step - loss: 0.0384 - accuracy: 0.9937 - val_loss: 0.0445 - val_accuracy: 0.9688\n",
      "Epoch 16/30\n",
      "1002/1002 [==============================] - 198s 198ms/step - loss: 0.0354 - accuracy: 0.9943 - val_loss: 0.1454 - val_accuracy: 0.9688\n",
      "Epoch 17/30\n",
      "1002/1002 [==============================] - 198s 197ms/step - loss: 0.0328 - accuracy: 0.9949 - val_loss: 0.1270 - val_accuracy: 0.9688\n",
      "Epoch 18/30\n",
      "1002/1002 [==============================] - 198s 198ms/step - loss: 0.0346 - accuracy: 0.9941 - val_loss: 0.1448 - val_accuracy: 0.9688\n",
      "Epoch 19/30\n",
      "1002/1002 [==============================] - 198s 198ms/step - loss: 0.0352 - accuracy: 0.9942 - val_loss: 0.1119 - val_accuracy: 0.9688\n",
      "Epoch 20/30\n",
      "1002/1002 [==============================] - 198s 198ms/step - loss: 0.0335 - accuracy: 0.9946 - val_loss: 0.1109 - val_accuracy: 0.9688\n",
      "Epoch 21/30\n",
      "1002/1002 [==============================] - 198s 198ms/step - loss: 0.0298 - accuracy: 0.9953 - val_loss: 0.1128 - val_accuracy: 0.9688\n",
      "Epoch 22/30\n",
      "1002/1002 [==============================] - 198s 198ms/step - loss: 0.0260 - accuracy: 0.9960 - val_loss: 0.1211 - val_accuracy: 0.9688\n",
      "Epoch 23/30\n",
      "1002/1002 [==============================] - 199s 198ms/step - loss: 0.0287 - accuracy: 0.9948 - val_loss: 0.1320 - val_accuracy: 0.9688\n",
      "Epoch 24/30\n",
      "1002/1002 [==============================] - 198s 198ms/step - loss: 0.0287 - accuracy: 0.9950 - val_loss: 0.1341 - val_accuracy: 0.9688\n",
      "Epoch 25/30\n",
      "1002/1002 [==============================] - 198s 198ms/step - loss: 0.0266 - accuracy: 0.9951 - val_loss: 0.1005 - val_accuracy: 0.9688\n",
      "Epoch 26/30\n",
      "1002/1002 [==============================] - 198s 198ms/step - loss: 0.0249 - accuracy: 0.9958 - val_loss: 0.1385 - val_accuracy: 0.9688\n",
      "Epoch 27/30\n",
      "1002/1002 [==============================] - 198s 198ms/step - loss: 0.0273 - accuracy: 0.9957 - val_loss: 0.1261 - val_accuracy: 0.9688\n",
      "Epoch 28/30\n",
      "1002/1002 [==============================] - 199s 198ms/step - loss: 0.0275 - accuracy: 0.9952 - val_loss: 0.1348 - val_accuracy: 0.9688\n",
      "Epoch 29/30\n",
      "1002/1002 [==============================] - 199s 198ms/step - loss: 0.0282 - accuracy: 0.9950 - val_loss: 0.1303 - val_accuracy: 0.9688\n",
      "Epoch 30/30\n",
      "1002/1002 [==============================] - 198s 198ms/step - loss: 0.0252 - accuracy: 0.9957 - val_loss: 0.1309 - val_accuracy: 0.9688\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_50090.4_images_False_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.995868\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training opticnet for 0.6% of train size (aka 50090 images) with pretrained: True and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 276 trainable: 276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "   6/1002 [..............................] - ETA: 30:48 - loss: 5.1485 - accuracy: 0.2016  WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.4643s vs `on_train_batch_end` time: 1.0761s). Check your callbacks.\n",
      "1002/1002 [==============================] - 1187s 1s/step - loss: 0.3703 - accuracy: 0.8949 - val_loss: 0.6174 - val_accuracy: 0.7500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "1002/1002 [==============================] - 1169s 1s/step - loss: 0.1334 - accuracy: 0.9573 - val_loss: 0.0494 - val_accuracy: 1.0000\n",
      "Epoch 3/30\n",
      "1002/1002 [==============================] - 1169s 1s/step - loss: 0.1062 - accuracy: 0.9642 - val_loss: 0.0148 - val_accuracy: 1.0000\n",
      "Epoch 4/30\n",
      "1002/1002 [==============================] - 1168s 1s/step - loss: 0.0856 - accuracy: 0.9712 - val_loss: 0.0329 - val_accuracy: 0.9688\n",
      "Epoch 5/30\n",
      "1002/1002 [==============================] - 1172s 1s/step - loss: 0.0690 - accuracy: 0.9755 - val_loss: 0.0456 - val_accuracy: 1.0000\n",
      "Epoch 6/30\n",
      "1002/1002 [==============================] - 1174s 1s/step - loss: 0.0580 - accuracy: 0.9802 - val_loss: 0.0290 - val_accuracy: 1.0000\n",
      "Epoch 7/30\n",
      "1002/1002 [==============================] - 1171s 1s/step - loss: 0.0448 - accuracy: 0.9849 - val_loss: 0.1388 - val_accuracy: 0.9688\n",
      "Epoch 8/30\n",
      "1002/1002 [==============================] - 1174s 1s/step - loss: 0.0319 - accuracy: 0.9895 - val_loss: 0.0450 - val_accuracy: 0.9688\n",
      "Epoch 9/30\n",
      "1002/1002 [==============================] - 1172s 1s/step - loss: 0.0268 - accuracy: 0.9908 - val_loss: 0.0895 - val_accuracy: 0.9688\n",
      "Epoch 10/30\n",
      "1002/1002 [==============================] - 1176s 1s/step - loss: 0.0224 - accuracy: 0.9924 - val_loss: 0.1474 - val_accuracy: 0.9688\n",
      "Epoch 11/30\n",
      "1002/1002 [==============================] - 1178s 1s/step - loss: 0.0183 - accuracy: 0.9941 - val_loss: 0.1102 - val_accuracy: 0.9688\n",
      "Epoch 12/30\n",
      "1002/1002 [==============================] - 1175s 1s/step - loss: 0.0138 - accuracy: 0.9956 - val_loss: 0.0144 - val_accuracy: 1.0000\n",
      "Epoch 13/30\n",
      "1002/1002 [==============================] - 1178s 1s/step - loss: 0.0122 - accuracy: 0.9959 - val_loss: 0.2709 - val_accuracy: 0.9688\n",
      "Epoch 14/30\n",
      "1002/1002 [==============================] - 1174s 1s/step - loss: 0.0107 - accuracy: 0.9966 - val_loss: 0.0774 - val_accuracy: 0.9688\n",
      "Epoch 15/30\n",
      "1002/1002 [==============================] - 1174s 1s/step - loss: 0.0093 - accuracy: 0.9972 - val_loss: 0.0851 - val_accuracy: 0.9688\n",
      "Epoch 16/30\n",
      "1002/1002 [==============================] - 1173s 1s/step - loss: 0.0081 - accuracy: 0.9969 - val_loss: 0.2068 - val_accuracy: 0.9688\n",
      "Epoch 17/30\n",
      "1002/1002 [==============================] - 1174s 1s/step - loss: 0.0075 - accuracy: 0.9972 - val_loss: 0.1673 - val_accuracy: 0.9688\n",
      "Epoch 18/30\n",
      "1002/1002 [==============================] - 1174s 1s/step - loss: 0.0068 - accuracy: 0.9972 - val_loss: 0.1525 - val_accuracy: 0.9688\n",
      "Epoch 19/30\n",
      "1002/1002 [==============================] - 1177s 1s/step - loss: 0.0053 - accuracy: 0.9978 - val_loss: 0.1601 - val_accuracy: 0.9688\n",
      "Epoch 20/30\n",
      "1002/1002 [==============================] - 1175s 1s/step - loss: 0.0059 - accuracy: 0.9975 - val_loss: 0.2059 - val_accuracy: 0.9688\n",
      "Epoch 21/30\n",
      "1002/1002 [==============================] - 1175s 1s/step - loss: 0.0047 - accuracy: 0.9975 - val_loss: 0.1742 - val_accuracy: 0.9688\n",
      "Epoch 22/30\n",
      "1002/1002 [==============================] - 1176s 1s/step - loss: 0.0047 - accuracy: 0.9976 - val_loss: 0.2100 - val_accuracy: 0.9688\n",
      "Epoch 23/30\n",
      "1002/1002 [==============================] - 1178s 1s/step - loss: 0.0053 - accuracy: 0.9973 - val_loss: 0.1838 - val_accuracy: 0.9688\n",
      "Epoch 24/30\n",
      "1002/1002 [==============================] - 1175s 1s/step - loss: 0.0042 - accuracy: 0.9979 - val_loss: 0.2230 - val_accuracy: 0.9688\n",
      "Epoch 25/30\n",
      "1002/1002 [==============================] - 1172s 1s/step - loss: 0.0034 - accuracy: 0.9982 - val_loss: 0.2019 - val_accuracy: 0.9688\n",
      "Epoch 26/30\n",
      "1002/1002 [==============================] - 1170s 1s/step - loss: 0.0034 - accuracy: 0.9979 - val_loss: 0.2240 - val_accuracy: 0.9688\n",
      "Epoch 27/30\n",
      "1002/1002 [==============================] - 1171s 1s/step - loss: 0.0031 - accuracy: 0.9982 - val_loss: 0.2650 - val_accuracy: 0.9688\n",
      "Epoch 28/30\n",
      "1002/1002 [==============================] - 1174s 1s/step - loss: 0.0033 - accuracy: 0.9982 - val_loss: 0.2532 - val_accuracy: 0.9688\n",
      "Epoch 29/30\n",
      "1002/1002 [==============================] - 1172s 1s/step - loss: 0.0032 - accuracy: 0.9979 - val_loss: 0.2653 - val_accuracy: 0.9688\n",
      "Epoch 30/30\n",
      "1002/1002 [==============================] - 1174s 1s/step - loss: 0.0029 - accuracy: 0.9979 - val_loss: 0.2131 - val_accuracy: 0.9688\n",
      "INFO:tensorflow:Assets written to: ../opticnet/opticnet_30epochs_50090.4_images_False_newWeights_False_lastLayerOnly_rescale-symmetric_normalization/assets\n",
      "Test acc for opticnet: 0.996901\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.7466084  0.75032926 0.75625661 0.75069638]\n",
      "Training xception for 0.75% of train size (aka 62613 images) with pretrained: True and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 135 trainable: 135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "   6/1253 [..............................] - ETA: 26:25 - loss: 1.3917 - accuracy: 0.2605WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1598s vs `on_train_batch_begin` time: 0.1875s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1598s vs `on_train_batch_end` time: 0.8291s). Check your callbacks.\n",
      "1253/1253 [==============================] - 974s 773ms/step - loss: 1.0217 - accuracy: 0.9061 - val_loss: 0.5320 - val_accuracy: 0.9688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "1253/1253 [==============================] - 964s 770ms/step - loss: 0.3569 - accuracy: 0.9674 - val_loss: 0.2013 - val_accuracy: 1.0000\n",
      "Epoch 3/30\n",
      "1253/1253 [==============================] - 965s 770ms/step - loss: 0.1948 - accuracy: 0.9750 - val_loss: 0.1084 - val_accuracy: 1.0000\n",
      "Epoch 4/30\n",
      "1253/1253 [==============================] - 965s 770ms/step - loss: 0.1198 - accuracy: 0.9833 - val_loss: 0.0581 - val_accuracy: 1.0000\n",
      "Epoch 5/30\n",
      "1253/1253 [==============================] - 963s 769ms/step - loss: 0.0821 - accuracy: 0.9878 - val_loss: 0.0371 - val_accuracy: 1.0000\n",
      "Epoch 6/30\n",
      "1253/1253 [==============================] - 964s 769ms/step - loss: 0.0620 - accuracy: 0.9901 - val_loss: 0.0270 - val_accuracy: 1.0000\n",
      "Epoch 7/30\n",
      "1253/1253 [==============================] - 966s 771ms/step - loss: 0.0512 - accuracy: 0.9917 - val_loss: 0.0197 - val_accuracy: 1.0000\n",
      "Epoch 8/30\n",
      "1253/1253 [==============================] - 966s 771ms/step - loss: 0.0468 - accuracy: 0.9919 - val_loss: 0.0159 - val_accuracy: 1.0000\n",
      "Epoch 9/30\n",
      "1253/1253 [==============================] - 964s 769ms/step - loss: 0.0426 - accuracy: 0.9927 - val_loss: 0.0134 - val_accuracy: 1.0000\n",
      "Epoch 10/30\n",
      "1253/1253 [==============================] - 966s 771ms/step - loss: 0.0383 - accuracy: 0.9931 - val_loss: 0.0116 - val_accuracy: 1.0000\n",
      "Epoch 11/30\n",
      "1253/1253 [==============================] - 965s 770ms/step - loss: 0.0335 - accuracy: 0.9943 - val_loss: 0.0106 - val_accuracy: 1.0000\n",
      "Epoch 12/30\n",
      "1253/1253 [==============================] - 966s 771ms/step - loss: 0.0330 - accuracy: 0.9945 - val_loss: 0.0100 - val_accuracy: 1.0000\n",
      "Epoch 13/30\n",
      "1253/1253 [==============================] - 965s 770ms/step - loss: 0.0292 - accuracy: 0.9948 - val_loss: 0.0097 - val_accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "1253/1253 [==============================] - 968s 773ms/step - loss: 0.0318 - accuracy: 0.9945 - val_loss: 0.0089 - val_accuracy: 1.0000\n",
      "Epoch 15/30\n",
      "1253/1253 [==============================] - 967s 772ms/step - loss: 0.0288 - accuracy: 0.9950 - val_loss: 0.0085 - val_accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "1253/1253 [==============================] - 966s 771ms/step - loss: 0.0285 - accuracy: 0.9950 - val_loss: 0.0077 - val_accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "1253/1253 [==============================] - 964s 769ms/step - loss: 0.0276 - accuracy: 0.9949 - val_loss: 0.0074 - val_accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "1253/1253 [==============================] - 967s 772ms/step - loss: 0.0301 - accuracy: 0.9948 - val_loss: 0.0070 - val_accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "1253/1253 [==============================] - 966s 771ms/step - loss: 0.0271 - accuracy: 0.9948 - val_loss: 0.0068 - val_accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "1253/1253 [==============================] - 963s 768ms/step - loss: 0.0264 - accuracy: 0.9949 - val_loss: 0.0067 - val_accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "1253/1253 [==============================] - 965s 770ms/step - loss: 0.0238 - accuracy: 0.9956 - val_loss: 0.0062 - val_accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "1253/1253 [==============================] - 967s 771ms/step - loss: 0.0259 - accuracy: 0.9952 - val_loss: 0.0060 - val_accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "1253/1253 [==============================] - 966s 771ms/step - loss: 0.0220 - accuracy: 0.9955 - val_loss: 0.0066 - val_accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "1253/1253 [==============================] - 964s 770ms/step - loss: 0.0242 - accuracy: 0.9952 - val_loss: 0.0057 - val_accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "1253/1253 [==============================] - 965s 770ms/step - loss: 0.0221 - accuracy: 0.9955 - val_loss: 0.0056 - val_accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "1253/1253 [==============================] - 966s 771ms/step - loss: 0.0227 - accuracy: 0.9955 - val_loss: 0.0054 - val_accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "1253/1253 [==============================] - 966s 771ms/step - loss: 0.0214 - accuracy: 0.9959 - val_loss: 0.0053 - val_accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "1253/1253 [==============================] - 964s 769ms/step - loss: 0.0183 - accuracy: 0.9965 - val_loss: 0.0054 - val_accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "1253/1253 [==============================] - 965s 770ms/step - loss: 0.0212 - accuracy: 0.9958 - val_loss: 0.0050 - val_accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "1253/1253 [==============================] - 966s 771ms/step - loss: 0.0207 - accuracy: 0.9960 - val_loss: 0.0050 - val_accuracy: 1.0000\n",
      "INFO:tensorflow:Assets written to: ../xception/xception_30epochs_62613.0_images_False_newWeights_False_lastLayerOnly_rescale-symmetric_normalization/assets\n",
      "Test acc for xception: 0.995868\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training resnet for 0.75% of train size (aka 62613 images) with pretrained: True and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 178 trainable: 178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "   6/1253 [..............................] - ETA: 15:36 - loss: 1.3975 - accuracy: 0.3911WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1011s vs `on_train_batch_begin` time: 0.1871s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1011s vs `on_train_batch_end` time: 0.3619s). Check your callbacks.\n",
      "1253/1253 [==============================] - 259s 200ms/step - loss: 1.0596 - accuracy: 0.7776 - val_loss: 0.8138 - val_accuracy: 0.7500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "1253/1253 [==============================] - 248s 198ms/step - loss: 0.5322 - accuracy: 0.8787 - val_loss: 0.6201 - val_accuracy: 0.7500\n",
      "Epoch 3/30\n",
      "1253/1253 [==============================] - 248s 198ms/step - loss: 0.4081 - accuracy: 0.8830 - val_loss: 0.5615 - val_accuracy: 0.7500\n",
      "Epoch 4/30\n",
      "1253/1253 [==============================] - 248s 198ms/step - loss: 0.3103 - accuracy: 0.9098 - val_loss: 0.1579 - val_accuracy: 1.0000\n",
      "Epoch 5/30\n",
      "1253/1253 [==============================] - 248s 198ms/step - loss: 0.1474 - accuracy: 0.9765 - val_loss: 0.0862 - val_accuracy: 1.0000\n",
      "Epoch 6/30\n",
      "1253/1253 [==============================] - 248s 198ms/step - loss: 0.0984 - accuracy: 0.9828 - val_loss: 0.0637 - val_accuracy: 1.0000\n",
      "Epoch 7/30\n",
      "1253/1253 [==============================] - 248s 198ms/step - loss: 0.0737 - accuracy: 0.9870 - val_loss: 0.0334 - val_accuracy: 1.0000\n",
      "Epoch 8/30\n",
      "1253/1253 [==============================] - 248s 198ms/step - loss: 0.0611 - accuracy: 0.9893 - val_loss: 0.0335 - val_accuracy: 1.0000\n",
      "Epoch 9/30\n",
      "1253/1253 [==============================] - 248s 198ms/step - loss: 0.0529 - accuracy: 0.9901 - val_loss: 0.0478 - val_accuracy: 0.9688\n",
      "Epoch 10/30\n",
      "1253/1253 [==============================] - 248s 198ms/step - loss: 0.0475 - accuracy: 0.9912 - val_loss: 0.0396 - val_accuracy: 1.0000\n",
      "Epoch 11/30\n",
      "1253/1253 [==============================] - 248s 198ms/step - loss: 0.0423 - accuracy: 0.9924 - val_loss: 0.0624 - val_accuracy: 0.9688\n",
      "Epoch 12/30\n",
      "1253/1253 [==============================] - 248s 198ms/step - loss: 0.0373 - accuracy: 0.9933 - val_loss: 0.0545 - val_accuracy: 0.9688\n",
      "Epoch 13/30\n",
      "1253/1253 [==============================] - 248s 198ms/step - loss: 0.0397 - accuracy: 0.9930 - val_loss: 0.0737 - val_accuracy: 0.9688\n",
      "Epoch 14/30\n",
      "1253/1253 [==============================] - 248s 198ms/step - loss: 0.0368 - accuracy: 0.9932 - val_loss: 0.1013 - val_accuracy: 0.9688\n",
      "Epoch 15/30\n",
      "1253/1253 [==============================] - 248s 198ms/step - loss: 0.0341 - accuracy: 0.9941 - val_loss: 0.1339 - val_accuracy: 0.9688\n",
      "Epoch 16/30\n",
      "1253/1253 [==============================] - 248s 198ms/step - loss: 0.0342 - accuracy: 0.9935 - val_loss: 0.0282 - val_accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "1253/1253 [==============================] - 248s 198ms/step - loss: 0.0307 - accuracy: 0.9942 - val_loss: 0.0577 - val_accuracy: 0.9688\n",
      "Epoch 18/30\n",
      "1253/1253 [==============================] - 248s 198ms/step - loss: 0.0273 - accuracy: 0.9951 - val_loss: 0.0934 - val_accuracy: 0.9688\n",
      "Epoch 19/30\n",
      "1253/1253 [==============================] - 248s 198ms/step - loss: 0.0282 - accuracy: 0.9949 - val_loss: 0.0678 - val_accuracy: 0.9688\n",
      "Epoch 20/30\n",
      "1253/1253 [==============================] - 248s 198ms/step - loss: 0.0276 - accuracy: 0.9951 - val_loss: 0.1023 - val_accuracy: 0.9688\n",
      "Epoch 21/30\n",
      "1253/1253 [==============================] - 248s 198ms/step - loss: 0.0256 - accuracy: 0.9948 - val_loss: 0.0680 - val_accuracy: 0.9688\n",
      "Epoch 22/30\n",
      "1253/1253 [==============================] - 248s 198ms/step - loss: 0.0264 - accuracy: 0.9954 - val_loss: 0.0962 - val_accuracy: 0.9688\n",
      "Epoch 23/30\n",
      "1253/1253 [==============================] - 248s 198ms/step - loss: 0.0264 - accuracy: 0.9952 - val_loss: 0.0788 - val_accuracy: 0.9688\n",
      "Epoch 24/30\n",
      "1253/1253 [==============================] - 248s 198ms/step - loss: 0.0252 - accuracy: 0.9951 - val_loss: 0.0954 - val_accuracy: 0.9688\n",
      "Epoch 25/30\n",
      "1253/1253 [==============================] - 248s 198ms/step - loss: 0.0257 - accuracy: 0.9950 - val_loss: 0.0935 - val_accuracy: 0.9688\n",
      "Epoch 26/30\n",
      "1253/1253 [==============================] - 248s 198ms/step - loss: 0.0224 - accuracy: 0.9955 - val_loss: 0.1034 - val_accuracy: 0.9688\n",
      "Epoch 27/30\n",
      "1253/1253 [==============================] - 248s 198ms/step - loss: 0.0222 - accuracy: 0.9957 - val_loss: 0.0961 - val_accuracy: 0.9688\n",
      "Epoch 28/30\n",
      "1253/1253 [==============================] - 248s 198ms/step - loss: 0.0238 - accuracy: 0.9952 - val_loss: 0.0921 - val_accuracy: 0.9688\n",
      "Epoch 29/30\n",
      "1253/1253 [==============================] - 248s 198ms/step - loss: 0.0216 - accuracy: 0.9956 - val_loss: 0.1050 - val_accuracy: 0.9688\n",
      "Epoch 30/30\n",
      "1253/1253 [==============================] - 248s 198ms/step - loss: 0.0220 - accuracy: 0.9959 - val_loss: 0.1182 - val_accuracy: 0.9688\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_62613.0_images_False_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.994835\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training opticnet for 0.75% of train size (aka 62613 images) with pretrained: True and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 276 trainable: 276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "   6/1253 [..............................] - ETA: 37:30 - loss: 5.6588 - accuracy: 0.1596  WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.4653s vs `on_train_batch_end` time: 1.0348s). Check your callbacks.\n",
      "1253/1253 [==============================] - 1485s 1s/step - loss: 0.3517 - accuracy: 0.8981 - val_loss: 0.1179 - val_accuracy: 0.9375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "1253/1253 [==============================] - 1468s 1s/step - loss: 0.1259 - accuracy: 0.9569 - val_loss: 0.0442 - val_accuracy: 1.0000\n",
      "Epoch 3/30\n",
      "1253/1253 [==============================] - 1469s 1s/step - loss: 0.1041 - accuracy: 0.9652 - val_loss: 0.0934 - val_accuracy: 0.9688\n",
      "Epoch 4/30\n",
      "1253/1253 [==============================] - 1468s 1s/step - loss: 0.0863 - accuracy: 0.9706 - val_loss: 0.0120 - val_accuracy: 1.0000\n",
      "Epoch 5/30\n",
      "1253/1253 [==============================] - 1469s 1s/step - loss: 0.0702 - accuracy: 0.9765 - val_loss: 0.0428 - val_accuracy: 1.0000\n",
      "Epoch 6/30\n",
      "1253/1253 [==============================] - 1469s 1s/step - loss: 0.0579 - accuracy: 0.9805 - val_loss: 0.0377 - val_accuracy: 0.9688\n",
      "Epoch 7/30\n",
      "1253/1253 [==============================] - 1470s 1s/step - loss: 0.0472 - accuracy: 0.9841 - val_loss: 0.0100 - val_accuracy: 1.0000\n",
      "Epoch 8/30\n",
      "1253/1253 [==============================] - 1469s 1s/step - loss: 0.0360 - accuracy: 0.9880 - val_loss: 0.0099 - val_accuracy: 1.0000\n",
      "Epoch 9/30\n",
      "1253/1253 [==============================] - 1469s 1s/step - loss: 0.0287 - accuracy: 0.9905 - val_loss: 0.0140 - val_accuracy: 1.0000\n",
      "Epoch 10/30\n",
      "1253/1253 [==============================] - 1470s 1s/step - loss: 0.0236 - accuracy: 0.9924 - val_loss: 0.0310 - val_accuracy: 0.9688\n",
      "Epoch 11/30\n",
      "1253/1253 [==============================] - 1469s 1s/step - loss: 0.0212 - accuracy: 0.9933 - val_loss: 0.0384 - val_accuracy: 0.9688\n",
      "Epoch 12/30\n",
      "1253/1253 [==============================] - 1467s 1s/step - loss: 0.0171 - accuracy: 0.9944 - val_loss: 0.0466 - val_accuracy: 0.9688\n",
      "Epoch 13/30\n",
      "1253/1253 [==============================] - 1466s 1s/step - loss: 0.0150 - accuracy: 0.9949 - val_loss: 0.0043 - val_accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "1253/1253 [==============================] - 1469s 1s/step - loss: 0.0124 - accuracy: 0.9961 - val_loss: 0.0130 - val_accuracy: 1.0000\n",
      "Epoch 15/30\n",
      "1253/1253 [==============================] - 1472s 1s/step - loss: 0.0118 - accuracy: 0.9961 - val_loss: 0.1810 - val_accuracy: 0.9688\n",
      "Epoch 16/30\n",
      "1253/1253 [==============================] - 1474s 1s/step - loss: 0.0113 - accuracy: 0.9959 - val_loss: 0.0759 - val_accuracy: 0.9688\n",
      "Epoch 17/30\n",
      "1253/1253 [==============================] - 1471s 1s/step - loss: 0.0091 - accuracy: 0.9969 - val_loss: 0.1908 - val_accuracy: 0.9688\n",
      "Epoch 18/30\n",
      "1253/1253 [==============================] - 1472s 1s/step - loss: 0.0079 - accuracy: 0.9970 - val_loss: 0.1432 - val_accuracy: 0.9688\n",
      "Epoch 19/30\n",
      "1253/1253 [==============================] - 1474s 1s/step - loss: 0.0075 - accuracy: 0.9969 - val_loss: 0.1557 - val_accuracy: 0.9688\n",
      "Epoch 20/30\n",
      "1253/1253 [==============================] - 1480s 1s/step - loss: 0.0064 - accuracy: 0.9970 - val_loss: 0.1284 - val_accuracy: 0.9688\n",
      "Epoch 21/30\n",
      "1253/1253 [==============================] - 1479s 1s/step - loss: 0.0066 - accuracy: 0.9970 - val_loss: 0.1067 - val_accuracy: 0.9688\n",
      "Epoch 22/30\n",
      "1253/1253 [==============================] - 1475s 1s/step - loss: 0.0061 - accuracy: 0.9970 - val_loss: 0.1568 - val_accuracy: 0.9688\n",
      "Epoch 23/30\n",
      "1253/1253 [==============================] - 1472s 1s/step - loss: 0.0048 - accuracy: 0.9973 - val_loss: 0.2150 - val_accuracy: 0.9688\n",
      "Epoch 24/30\n",
      "1253/1253 [==============================] - 1472s 1s/step - loss: 0.0053 - accuracy: 0.9973 - val_loss: 0.1445 - val_accuracy: 0.9688\n",
      "Epoch 25/30\n",
      "1253/1253 [==============================] - 1474s 1s/step - loss: 0.0045 - accuracy: 0.9974 - val_loss: 0.1803 - val_accuracy: 0.9688\n",
      "Epoch 26/30\n",
      "1253/1253 [==============================] - 1474s 1s/step - loss: 0.0040 - accuracy: 0.9977 - val_loss: 0.1657 - val_accuracy: 0.9688\n",
      "Epoch 27/30\n",
      "1253/1253 [==============================] - 1470s 1s/step - loss: 0.0035 - accuracy: 0.9980 - val_loss: 0.1848 - val_accuracy: 0.9688\n",
      "Epoch 28/30\n",
      "1253/1253 [==============================] - 1474s 1s/step - loss: 0.0041 - accuracy: 0.9973 - val_loss: 0.1885 - val_accuracy: 0.9688\n",
      "Epoch 29/30\n",
      "1253/1253 [==============================] - 1471s 1s/step - loss: 0.0036 - accuracy: 0.9975 - val_loss: 0.2424 - val_accuracy: 0.9688\n",
      "Epoch 30/30\n",
      "1253/1253 [==============================] - 1470s 1s/step - loss: 0.0039 - accuracy: 0.9971 - val_loss: 0.2096 - val_accuracy: 0.9688\n",
      "INFO:tensorflow:Assets written to: ../opticnet/opticnet_30epochs_62613.0_images_False_newWeights_False_lastLayerOnly_rescale-symmetric_normalization/assets\n",
      "Test acc for opticnet: 0.996901\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.89918298 0.90025534 0.89857244 0.90320334]\n",
      "Training xception for 0.9% of train size (aka 75135 images) with pretrained: True and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 135 trainable: 135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "   6/1503 [..............................] - ETA: 32:43 - loss: 1.3988 - accuracy: 0.1085WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1596s vs `on_train_batch_begin` time: 0.1845s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1596s vs `on_train_batch_end` time: 0.8599s). Check your callbacks.\n",
      "1503/1503 [==============================] - 1154s 763ms/step - loss: 0.9428 - accuracy: 0.8766 - val_loss: 0.3568 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "1503/1503 [==============================] - 1140s 758ms/step - loss: 0.2716 - accuracy: 0.9764 - val_loss: 0.2061 - val_accuracy: 0.9688\n",
      "Epoch 3/30\n",
      "1503/1503 [==============================] - 1142s 759ms/step - loss: 0.1395 - accuracy: 0.9817 - val_loss: 0.0642 - val_accuracy: 1.0000\n",
      "Epoch 4/30\n",
      "1503/1503 [==============================] - 1142s 760ms/step - loss: 0.0883 - accuracy: 0.9865 - val_loss: 0.0367 - val_accuracy: 1.0000\n",
      "Epoch 5/30\n",
      "1503/1503 [==============================] - 1142s 760ms/step - loss: 0.0664 - accuracy: 0.9887 - val_loss: 0.0279 - val_accuracy: 1.0000\n",
      "Epoch 6/30\n",
      "1503/1503 [==============================] - 1140s 758ms/step - loss: 0.0503 - accuracy: 0.9907 - val_loss: 0.0170 - val_accuracy: 1.0000\n",
      "Epoch 7/30\n",
      "1503/1503 [==============================] - 1144s 761ms/step - loss: 0.0455 - accuracy: 0.9914 - val_loss: 0.0135 - val_accuracy: 1.0000\n",
      "Epoch 8/30\n",
      "1503/1503 [==============================] - 1142s 760ms/step - loss: 0.0376 - accuracy: 0.9930 - val_loss: 0.0110 - val_accuracy: 1.0000\n",
      "Epoch 9/30\n",
      "1503/1503 [==============================] - 1142s 760ms/step - loss: 0.0346 - accuracy: 0.9938 - val_loss: 0.0083 - val_accuracy: 1.0000\n",
      "Epoch 10/30\n",
      "1503/1503 [==============================] - 1143s 760ms/step - loss: 0.0310 - accuracy: 0.9939 - val_loss: 0.0103 - val_accuracy: 1.0000\n",
      "Epoch 11/30\n",
      "1503/1503 [==============================] - 1141s 759ms/step - loss: 0.0279 - accuracy: 0.9946 - val_loss: 0.0220 - val_accuracy: 1.0000\n",
      "Epoch 12/30\n",
      "1503/1503 [==============================] - 1142s 760ms/step - loss: 0.0248 - accuracy: 0.9952 - val_loss: 0.0228 - val_accuracy: 1.0000\n",
      "Epoch 13/30\n",
      "1503/1503 [==============================] - 1142s 760ms/step - loss: 0.0241 - accuracy: 0.9950 - val_loss: 0.0183 - val_accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "1503/1503 [==============================] - 1141s 759ms/step - loss: 0.0231 - accuracy: 0.9949 - val_loss: 0.0316 - val_accuracy: 0.9688\n",
      "Epoch 15/30\n",
      "1503/1503 [==============================] - 1141s 759ms/step - loss: 0.0232 - accuracy: 0.9953 - val_loss: 0.0345 - val_accuracy: 0.9688\n",
      "Epoch 16/30\n",
      "1503/1503 [==============================] - 1141s 759ms/step - loss: 0.0229 - accuracy: 0.9955 - val_loss: 0.0271 - val_accuracy: 0.9688\n",
      "Epoch 17/30\n",
      "1503/1503 [==============================] - 1138s 757ms/step - loss: 0.0202 - accuracy: 0.9955 - val_loss: 0.0366 - val_accuracy: 0.9688\n",
      "Epoch 18/30\n",
      "1503/1503 [==============================] - 1145s 762ms/step - loss: 0.0194 - accuracy: 0.9955 - val_loss: 0.0379 - val_accuracy: 0.9688\n",
      "Epoch 19/30\n",
      "1503/1503 [==============================] - 1142s 760ms/step - loss: 0.0198 - accuracy: 0.9955 - val_loss: 0.0285 - val_accuracy: 0.9688\n",
      "Epoch 20/30\n",
      "1503/1503 [==============================] - 1142s 760ms/step - loss: 0.0212 - accuracy: 0.9955 - val_loss: 0.0316 - val_accuracy: 0.9688\n",
      "Epoch 21/30\n",
      "1503/1503 [==============================] - 1142s 760ms/step - loss: 0.0188 - accuracy: 0.9959 - val_loss: 0.0309 - val_accuracy: 0.9688\n",
      "Epoch 22/30\n",
      "1503/1503 [==============================] - 1141s 759ms/step - loss: 0.0184 - accuracy: 0.9961 - val_loss: 0.0245 - val_accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "1503/1503 [==============================] - 1142s 760ms/step - loss: 0.0178 - accuracy: 0.9959 - val_loss: 0.0291 - val_accuracy: 0.9688\n",
      "Epoch 24/30\n",
      "1503/1503 [==============================] - 1142s 760ms/step - loss: 0.0174 - accuracy: 0.9961 - val_loss: 0.0317 - val_accuracy: 0.9688\n",
      "Epoch 25/30\n",
      "1503/1503 [==============================] - 1142s 760ms/step - loss: 0.0182 - accuracy: 0.9959 - val_loss: 0.0319 - val_accuracy: 0.9688\n",
      "Epoch 26/30\n",
      "1503/1503 [==============================] - 1141s 759ms/step - loss: 0.0172 - accuracy: 0.9959 - val_loss: 0.0331 - val_accuracy: 0.9688\n",
      "Epoch 27/30\n",
      "1503/1503 [==============================] - 1143s 760ms/step - loss: 0.0166 - accuracy: 0.9962 - val_loss: 0.0290 - val_accuracy: 0.9688\n",
      "Epoch 28/30\n",
      "1503/1503 [==============================] - 1142s 760ms/step - loss: 0.0169 - accuracy: 0.9959 - val_loss: 0.0306 - val_accuracy: 0.9688\n",
      "Epoch 29/30\n",
      "1503/1503 [==============================] - 1142s 760ms/step - loss: 0.0183 - accuracy: 0.9959 - val_loss: 0.0275 - val_accuracy: 0.9688\n",
      "Epoch 30/30\n",
      "1503/1503 [==============================] - 1140s 758ms/step - loss: 0.0169 - accuracy: 0.9960 - val_loss: 0.0285 - val_accuracy: 0.9688\n",
      "INFO:tensorflow:Assets written to: ../xception/xception_30epochs_75135.6_images_False_newWeights_False_lastLayerOnly_rescale-symmetric_normalization/assets\n",
      "Test acc for xception: 0.995868\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training resnet for 0.9% of train size (aka 75135 images) with pretrained: True and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 178 trainable: 178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "   6/1503 [..............................] - ETA: 18:26 - loss: 1.3991 - accuracy: 5.5556e-04WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1048s vs `on_train_batch_begin` time: 0.1848s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1048s vs `on_train_batch_end` time: 0.3517s). Check your callbacks.\n",
      "1503/1503 [==============================] - 308s 199ms/step - loss: 1.0223 - accuracy: 0.8102 - val_loss: 0.7517 - val_accuracy: 0.7500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "1503/1503 [==============================] - 297s 197ms/step - loss: 0.4539 - accuracy: 0.8823 - val_loss: 0.5459 - val_accuracy: 0.7500\n",
      "Epoch 3/30\n",
      "1503/1503 [==============================] - 296s 197ms/step - loss: 0.3059 - accuracy: 0.9069 - val_loss: 0.0922 - val_accuracy: 1.0000\n",
      "Epoch 4/30\n",
      "1503/1503 [==============================] - 296s 197ms/step - loss: 0.1156 - accuracy: 0.9801 - val_loss: 0.0504 - val_accuracy: 1.0000\n",
      "Epoch 5/30\n",
      "1503/1503 [==============================] - 296s 197ms/step - loss: 0.0761 - accuracy: 0.9857 - val_loss: 0.0842 - val_accuracy: 0.9688\n",
      "Epoch 6/30\n",
      "1503/1503 [==============================] - 297s 197ms/step - loss: 0.0568 - accuracy: 0.9893 - val_loss: 0.0603 - val_accuracy: 0.9688\n",
      "Epoch 7/30\n",
      "1503/1503 [==============================] - 296s 197ms/step - loss: 0.0466 - accuracy: 0.9914 - val_loss: 0.0196 - val_accuracy: 1.0000\n",
      "Epoch 8/30\n",
      "1503/1503 [==============================] - 297s 197ms/step - loss: 0.0414 - accuracy: 0.9923 - val_loss: 0.0138 - val_accuracy: 1.0000\n",
      "Epoch 9/30\n",
      "1503/1503 [==============================] - 296s 197ms/step - loss: 0.0361 - accuracy: 0.9936 - val_loss: 0.0334 - val_accuracy: 1.0000\n",
      "Epoch 10/30\n",
      "1503/1503 [==============================] - 296s 197ms/step - loss: 0.0351 - accuracy: 0.9932 - val_loss: 0.0291 - val_accuracy: 1.0000\n",
      "Epoch 11/30\n",
      "1503/1503 [==============================] - 297s 197ms/step - loss: 0.0331 - accuracy: 0.9934 - val_loss: 0.0439 - val_accuracy: 0.9688\n",
      "Epoch 12/30\n",
      "1503/1503 [==============================] - 297s 197ms/step - loss: 0.0298 - accuracy: 0.9943 - val_loss: 0.0248 - val_accuracy: 1.0000\n",
      "Epoch 13/30\n",
      "1503/1503 [==============================] - 297s 197ms/step - loss: 0.0277 - accuracy: 0.9943 - val_loss: 0.0304 - val_accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "1503/1503 [==============================] - 296s 197ms/step - loss: 0.0276 - accuracy: 0.9945 - val_loss: 0.0881 - val_accuracy: 0.9688\n",
      "Epoch 15/30\n",
      "1503/1503 [==============================] - 297s 198ms/step - loss: 0.0277 - accuracy: 0.9942 - val_loss: 0.0452 - val_accuracy: 0.9688\n",
      "Epoch 16/30\n",
      "1503/1503 [==============================] - 297s 197ms/step - loss: 0.0259 - accuracy: 0.9947 - val_loss: 0.0236 - val_accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "1503/1503 [==============================] - 297s 197ms/step - loss: 0.0237 - accuracy: 0.9948 - val_loss: 0.0309 - val_accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "1503/1503 [==============================] - 297s 197ms/step - loss: 0.0209 - accuracy: 0.9958 - val_loss: 0.0456 - val_accuracy: 0.9688\n",
      "Epoch 19/30\n",
      "1503/1503 [==============================] - 297s 197ms/step - loss: 0.0220 - accuracy: 0.9951 - val_loss: 0.0262 - val_accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "1503/1503 [==============================] - 297s 197ms/step - loss: 0.0207 - accuracy: 0.9953 - val_loss: 0.0320 - val_accuracy: 0.9688\n",
      "Epoch 21/30\n",
      "1503/1503 [==============================] - 296s 197ms/step - loss: 0.0206 - accuracy: 0.9954 - val_loss: 0.0378 - val_accuracy: 0.9688\n",
      "Epoch 22/30\n",
      "1503/1503 [==============================] - 297s 197ms/step - loss: 0.0190 - accuracy: 0.9956 - val_loss: 0.0275 - val_accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "1503/1503 [==============================] - 297s 197ms/step - loss: 0.0190 - accuracy: 0.9956 - val_loss: 0.0307 - val_accuracy: 0.9688\n",
      "Epoch 24/30\n",
      "1503/1503 [==============================] - 296s 197ms/step - loss: 0.0173 - accuracy: 0.9959 - val_loss: 0.0299 - val_accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "1503/1503 [==============================] - 296s 197ms/step - loss: 0.0200 - accuracy: 0.9952 - val_loss: 0.0302 - val_accuracy: 0.9688\n",
      "Epoch 26/30\n",
      "1503/1503 [==============================] - 297s 197ms/step - loss: 0.0175 - accuracy: 0.9957 - val_loss: 0.0313 - val_accuracy: 0.9688\n",
      "Epoch 27/30\n",
      "1503/1503 [==============================] - 297s 197ms/step - loss: 0.0186 - accuracy: 0.9956 - val_loss: 0.0314 - val_accuracy: 0.9688\n",
      "Epoch 28/30\n",
      "1503/1503 [==============================] - 297s 197ms/step - loss: 0.0162 - accuracy: 0.9961 - val_loss: 0.0335 - val_accuracy: 0.9688\n",
      "Epoch 29/30\n",
      "1503/1503 [==============================] - 297s 197ms/step - loss: 0.0180 - accuracy: 0.9956 - val_loss: 0.0314 - val_accuracy: 0.9688\n",
      "Epoch 30/30\n",
      "1503/1503 [==============================] - 296s 197ms/step - loss: 0.0154 - accuracy: 0.9960 - val_loss: 0.0346 - val_accuracy: 0.9688\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_75135.6_images_False_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.995868\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training opticnet for 0.9% of train size (aka 75135 images) with pretrained: True and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 276 trainable: 276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "   6/1503 [..............................] - ETA: 46:32 - loss: 5.4143 - accuracy: 0.1458  WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.4644s vs `on_train_batch_end` time: 1.0795s). Check your callbacks.\n",
      "1503/1503 [==============================] - 1778s 1s/step - loss: 0.3029 - accuracy: 0.9110 - val_loss: 0.0143 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "1503/1503 [==============================] - 1759s 1s/step - loss: 0.1286 - accuracy: 0.9561 - val_loss: 0.0531 - val_accuracy: 1.0000\n",
      "Epoch 3/30\n",
      "1503/1503 [==============================] - 1760s 1s/step - loss: 0.1061 - accuracy: 0.9636 - val_loss: 0.0262 - val_accuracy: 1.0000\n",
      "Epoch 4/30\n",
      "1503/1503 [==============================] - 1759s 1s/step - loss: 0.0836 - accuracy: 0.9728 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
      "Epoch 5/30\n",
      "1503/1503 [==============================] - 1760s 1s/step - loss: 0.0735 - accuracy: 0.9749 - val_loss: 0.0262 - val_accuracy: 1.0000\n",
      "Epoch 6/30\n",
      "1503/1503 [==============================] - 1760s 1s/step - loss: 0.0589 - accuracy: 0.9796 - val_loss: 0.0064 - val_accuracy: 1.0000\n",
      "Epoch 7/30\n",
      "1503/1503 [==============================] - 1759s 1s/step - loss: 0.0464 - accuracy: 0.9841 - val_loss: 0.0083 - val_accuracy: 1.0000\n",
      "Epoch 8/30\n",
      "1503/1503 [==============================] - 1754s 1s/step - loss: 0.0354 - accuracy: 0.9878 - val_loss: 0.0063 - val_accuracy: 1.0000\n",
      "Epoch 9/30\n",
      "1503/1503 [==============================] - 1763s 1s/step - loss: 0.0290 - accuracy: 0.9905 - val_loss: 0.0461 - val_accuracy: 0.9688\n",
      "Epoch 10/30\n",
      "1503/1503 [==============================] - 1764s 1s/step - loss: 0.0254 - accuracy: 0.9913 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
      "Epoch 11/30\n",
      "1503/1503 [==============================] - 1754s 1s/step - loss: 0.0195 - accuracy: 0.9933 - val_loss: 0.0084 - val_accuracy: 1.0000\n",
      "Epoch 12/30\n",
      "1503/1503 [==============================] - 1758s 1s/step - loss: 0.0180 - accuracy: 0.9942 - val_loss: 0.0320 - val_accuracy: 0.9688\n",
      "Epoch 13/30\n",
      "1503/1503 [==============================] - 1765s 1s/step - loss: 0.0157 - accuracy: 0.9949 - val_loss: 0.0097 - val_accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "1503/1503 [==============================] - 1766s 1s/step - loss: 0.0118 - accuracy: 0.9957 - val_loss: 0.0302 - val_accuracy: 0.9688\n",
      "Epoch 15/30\n",
      "1503/1503 [==============================] - 1769s 1s/step - loss: 0.0127 - accuracy: 0.9955 - val_loss: 0.0074 - val_accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "1503/1503 [==============================] - 1771s 1s/step - loss: 0.0104 - accuracy: 0.9962 - val_loss: 0.0272 - val_accuracy: 0.9688\n",
      "Epoch 17/30\n",
      "1503/1503 [==============================] - 1772s 1s/step - loss: 0.0104 - accuracy: 0.9958 - val_loss: 0.0229 - val_accuracy: 0.9688\n",
      "Epoch 18/30\n",
      "1503/1503 [==============================] - 1774s 1s/step - loss: 0.0091 - accuracy: 0.9960 - val_loss: 0.0408 - val_accuracy: 0.9688\n",
      "Epoch 19/30\n",
      "1503/1503 [==============================] - 1776s 1s/step - loss: 0.0077 - accuracy: 0.9964 - val_loss: 0.0341 - val_accuracy: 0.9688\n",
      "Epoch 20/30\n",
      "1503/1503 [==============================] - 1774s 1s/step - loss: 0.0073 - accuracy: 0.9965 - val_loss: 0.0178 - val_accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "1503/1503 [==============================] - 1774s 1s/step - loss: 0.0070 - accuracy: 0.9965 - val_loss: 0.0059 - val_accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "1503/1503 [==============================] - 1772s 1s/step - loss: 0.0073 - accuracy: 0.9962 - val_loss: 0.0219 - val_accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "1503/1503 [==============================] - 1770s 1s/step - loss: 0.0056 - accuracy: 0.9970 - val_loss: 0.0123 - val_accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "1503/1503 [==============================] - 1768s 1s/step - loss: 0.0054 - accuracy: 0.9969 - val_loss: 0.0192 - val_accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "1503/1503 [==============================] - 1769s 1s/step - loss: 0.0054 - accuracy: 0.9969 - val_loss: 0.0188 - val_accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "1503/1503 [==============================] - 1767s 1s/step - loss: 0.0046 - accuracy: 0.9971 - val_loss: 0.0142 - val_accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "1503/1503 [==============================] - 1768s 1s/step - loss: 0.0051 - accuracy: 0.9967 - val_loss: 0.0160 - val_accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "1503/1503 [==============================] - 1764s 1s/step - loss: 0.0046 - accuracy: 0.9970 - val_loss: 0.0204 - val_accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "1503/1503 [==============================] - 1765s 1s/step - loss: 0.0042 - accuracy: 0.9974 - val_loss: 0.0127 - val_accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "1503/1503 [==============================] - 1756s 1s/step - loss: 0.0039 - accuracy: 0.9975 - val_loss: 0.0138 - val_accuracy: 1.0000\n",
      "INFO:tensorflow:Assets written to: ../opticnet/opticnet_30epochs_75135.6_images_False_newWeights_False_lastLayerOnly_rescale-symmetric_normalization/assets\n",
      "Test acc for opticnet: 0.996901\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [1. 1. 1. 1.]\n",
      "Training xception for 1.0% of train size (aka 83484 images) with pretrained: True and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 135 trainable: 135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "   6/1670 [..............................] - ETA: 35:10 - loss: 1.3799 - accuracy: 0.4528WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1576s vs `on_train_batch_begin` time: 0.1846s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1576s vs `on_train_batch_end` time: 0.8273s). Check your callbacks.\n",
      "1670/1670 [==============================] - 1280s 763ms/step - loss: 0.8944 - accuracy: 0.9024 - val_loss: 0.2699 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "1670/1670 [==============================] - 1272s 762ms/step - loss: 0.2177 - accuracy: 0.9793 - val_loss: 0.0944 - val_accuracy: 1.0000\n",
      "Epoch 3/30\n",
      "1670/1670 [==============================] - 1274s 763ms/step - loss: 0.1059 - accuracy: 0.9861 - val_loss: 0.0457 - val_accuracy: 1.0000\n",
      "Epoch 4/30\n",
      "1670/1670 [==============================] - 1272s 762ms/step - loss: 0.0682 - accuracy: 0.9891 - val_loss: 0.0247 - val_accuracy: 1.0000\n",
      "Epoch 5/30\n",
      "1670/1670 [==============================] - 1273s 762ms/step - loss: 0.0492 - accuracy: 0.9914 - val_loss: 0.0172 - val_accuracy: 1.0000\n",
      "Epoch 6/30\n",
      "1670/1670 [==============================] - 1272s 762ms/step - loss: 0.0360 - accuracy: 0.9930 - val_loss: 0.0221 - val_accuracy: 1.0000\n",
      "Epoch 7/30\n",
      "1670/1670 [==============================] - 1274s 763ms/step - loss: 0.0315 - accuracy: 0.9934 - val_loss: 0.0235 - val_accuracy: 1.0000\n",
      "Epoch 8/30\n",
      "1670/1670 [==============================] - 1273s 762ms/step - loss: 0.0275 - accuracy: 0.9937 - val_loss: 0.0273 - val_accuracy: 1.0000\n",
      "Epoch 9/30\n",
      "1670/1670 [==============================] - 1272s 762ms/step - loss: 0.0266 - accuracy: 0.9947 - val_loss: 0.0262 - val_accuracy: 1.0000\n",
      "Epoch 10/30\n",
      "1670/1670 [==============================] - 1273s 762ms/step - loss: 0.0252 - accuracy: 0.9943 - val_loss: 0.0344 - val_accuracy: 1.0000\n",
      "Epoch 11/30\n",
      "1670/1670 [==============================] - 1272s 762ms/step - loss: 0.0216 - accuracy: 0.9948 - val_loss: 0.0331 - val_accuracy: 0.9688\n",
      "Epoch 12/30\n",
      "1670/1670 [==============================] - 1272s 762ms/step - loss: 0.0203 - accuracy: 0.9950 - val_loss: 0.0324 - val_accuracy: 0.9688\n",
      "Epoch 13/30\n",
      "1670/1670 [==============================] - 1271s 761ms/step - loss: 0.0205 - accuracy: 0.9951 - val_loss: 0.0343 - val_accuracy: 0.9688\n",
      "Epoch 14/30\n",
      "1670/1670 [==============================] - 1271s 761ms/step - loss: 0.0186 - accuracy: 0.9951 - val_loss: 0.0261 - val_accuracy: 0.9688\n",
      "Epoch 15/30\n",
      "1670/1670 [==============================] - 1270s 761ms/step - loss: 0.0194 - accuracy: 0.9948 - val_loss: 0.0325 - val_accuracy: 0.9688\n",
      "Epoch 16/30\n",
      "1670/1670 [==============================] - 1271s 761ms/step - loss: 0.0164 - accuracy: 0.9960 - val_loss: 0.0280 - val_accuracy: 0.9688\n",
      "Epoch 17/30\n",
      "1670/1670 [==============================] - 1272s 762ms/step - loss: 0.0165 - accuracy: 0.9955 - val_loss: 0.0282 - val_accuracy: 0.9688\n",
      "Epoch 18/30\n",
      "1670/1670 [==============================] - 1270s 760ms/step - loss: 0.0157 - accuracy: 0.9959 - val_loss: 0.0300 - val_accuracy: 0.9688\n",
      "Epoch 19/30\n",
      "1670/1670 [==============================] - 1271s 761ms/step - loss: 0.0156 - accuracy: 0.9965 - val_loss: 0.0207 - val_accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "1670/1670 [==============================] - 1273s 762ms/step - loss: 0.0159 - accuracy: 0.9954 - val_loss: 0.0205 - val_accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "1670/1670 [==============================] - 1271s 761ms/step - loss: 0.0146 - accuracy: 0.9958 - val_loss: 0.0233 - val_accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "1670/1670 [==============================] - 1272s 762ms/step - loss: 0.0142 - accuracy: 0.9958 - val_loss: 0.0210 - val_accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "1670/1670 [==============================] - 1271s 761ms/step - loss: 0.0149 - accuracy: 0.9956 - val_loss: 0.0247 - val_accuracy: 0.9688\n",
      "Epoch 24/30\n",
      "1670/1670 [==============================] - 1270s 761ms/step - loss: 0.0124 - accuracy: 0.9967 - val_loss: 0.0218 - val_accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "1670/1670 [==============================] - 1270s 761ms/step - loss: 0.0129 - accuracy: 0.9960 - val_loss: 0.0277 - val_accuracy: 0.9688\n",
      "Epoch 26/30\n",
      "1670/1670 [==============================] - 1269s 760ms/step - loss: 0.0134 - accuracy: 0.9963 - val_loss: 0.0210 - val_accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "1670/1670 [==============================] - 1270s 761ms/step - loss: 0.0136 - accuracy: 0.9961 - val_loss: 0.0251 - val_accuracy: 0.9688\n",
      "Epoch 28/30\n",
      "1670/1670 [==============================] - 1270s 761ms/step - loss: 0.0129 - accuracy: 0.9967 - val_loss: 0.0235 - val_accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "1670/1670 [==============================] - 1271s 761ms/step - loss: 0.0136 - accuracy: 0.9961 - val_loss: 0.0264 - val_accuracy: 0.9688\n",
      "Epoch 30/30\n",
      "1670/1670 [==============================] - 1273s 762ms/step - loss: 0.0139 - accuracy: 0.9959 - val_loss: 0.0199 - val_accuracy: 1.0000\n",
      "INFO:tensorflow:Assets written to: ../xception/xception_30epochs_83484.0_images_False_newWeights_False_lastLayerOnly_rescale-symmetric_normalization/assets\n",
      "Test acc for xception: 0.998967\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training resnet for 1.0% of train size (aka 83484 images) with pretrained: True and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 178 trainable: 178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "   6/1670 [..............................] - ETA: 19:09 - loss: 1.3822 - accuracy: 0.0000e+00WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1074s vs `on_train_batch_begin` time: 0.1369s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1074s vs `on_train_batch_end` time: 0.3563s). Check your callbacks.\n",
      "1670/1670 [==============================] - 341s 199ms/step - loss: 0.9310 - accuracy: 0.8440 - val_loss: 0.3020 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "1670/1670 [==============================] - 330s 198ms/step - loss: 0.2339 - accuracy: 0.9781 - val_loss: 0.1018 - val_accuracy: 1.0000\n",
      "Epoch 3/30\n",
      "1670/1670 [==============================] - 330s 198ms/step - loss: 0.1133 - accuracy: 0.9845 - val_loss: 0.0671 - val_accuracy: 1.0000\n",
      "Epoch 4/30\n",
      "1670/1670 [==============================] - 330s 197ms/step - loss: 0.0717 - accuracy: 0.9882 - val_loss: 0.0273 - val_accuracy: 1.0000\n",
      "Epoch 5/30\n",
      "1670/1670 [==============================] - 330s 198ms/step - loss: 0.0540 - accuracy: 0.9900 - val_loss: 0.0306 - val_accuracy: 1.0000\n",
      "Epoch 6/30\n",
      "1670/1670 [==============================] - 330s 197ms/step - loss: 0.0425 - accuracy: 0.9914 - val_loss: 0.0160 - val_accuracy: 1.0000\n",
      "Epoch 7/30\n",
      "1670/1670 [==============================] - 330s 197ms/step - loss: 0.0377 - accuracy: 0.9923 - val_loss: 0.0513 - val_accuracy: 1.0000\n",
      "Epoch 8/30\n",
      "1670/1670 [==============================] - 330s 198ms/step - loss: 0.0319 - accuracy: 0.9936 - val_loss: 0.0194 - val_accuracy: 1.0000\n",
      "Epoch 9/30\n",
      "1670/1670 [==============================] - 330s 198ms/step - loss: 0.0277 - accuracy: 0.9943 - val_loss: 0.0328 - val_accuracy: 0.9688\n",
      "Epoch 10/30\n",
      "1670/1670 [==============================] - 331s 198ms/step - loss: 0.0253 - accuracy: 0.9942 - val_loss: 0.0195 - val_accuracy: 1.0000\n",
      "Epoch 11/30\n",
      "1670/1670 [==============================] - 330s 198ms/step - loss: 0.0246 - accuracy: 0.9944 - val_loss: 0.0100 - val_accuracy: 1.0000\n",
      "Epoch 12/30\n",
      "1670/1670 [==============================] - 330s 198ms/step - loss: 0.0214 - accuracy: 0.9949 - val_loss: 0.0302 - val_accuracy: 0.9688\n",
      "Epoch 13/30\n",
      "1670/1670 [==============================] - 330s 198ms/step - loss: 0.0220 - accuracy: 0.9947 - val_loss: 0.0371 - val_accuracy: 0.9688\n",
      "Epoch 14/30\n",
      "1670/1670 [==============================] - 330s 198ms/step - loss: 0.0193 - accuracy: 0.9954 - val_loss: 0.0228 - val_accuracy: 1.0000\n",
      "Epoch 15/30\n",
      "1670/1670 [==============================] - 330s 198ms/step - loss: 0.0182 - accuracy: 0.9955 - val_loss: 0.0225 - val_accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "1670/1670 [==============================] - 330s 198ms/step - loss: 0.0192 - accuracy: 0.9954 - val_loss: 0.0270 - val_accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "1670/1670 [==============================] - 330s 198ms/step - loss: 0.0161 - accuracy: 0.9959 - val_loss: 0.0277 - val_accuracy: 0.9688\n",
      "Epoch 18/30\n",
      "1670/1670 [==============================] - 330s 198ms/step - loss: 0.0187 - accuracy: 0.9953 - val_loss: 0.0281 - val_accuracy: 0.9688\n",
      "Epoch 19/30\n",
      "1670/1670 [==============================] - 330s 198ms/step - loss: 0.0172 - accuracy: 0.9954 - val_loss: 0.0301 - val_accuracy: 0.9688\n",
      "Epoch 20/30\n",
      "1670/1670 [==============================] - 331s 198ms/step - loss: 0.0177 - accuracy: 0.9952 - val_loss: 0.0317 - val_accuracy: 0.9688\n",
      "Epoch 21/30\n",
      "1670/1670 [==============================] - 330s 198ms/step - loss: 0.0180 - accuracy: 0.9952 - val_loss: 0.0244 - val_accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "1670/1670 [==============================] - 330s 198ms/step - loss: 0.0157 - accuracy: 0.9963 - val_loss: 0.0317 - val_accuracy: 0.9688\n",
      "Epoch 23/30\n",
      "1670/1670 [==============================] - 330s 198ms/step - loss: 0.0155 - accuracy: 0.9959 - val_loss: 0.0259 - val_accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "1670/1670 [==============================] - 330s 198ms/step - loss: 0.0157 - accuracy: 0.9958 - val_loss: 0.0247 - val_accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "1670/1670 [==============================] - 331s 198ms/step - loss: 0.0158 - accuracy: 0.9955 - val_loss: 0.0221 - val_accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "1670/1670 [==============================] - 330s 198ms/step - loss: 0.0150 - accuracy: 0.9957 - val_loss: 0.0232 - val_accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "1670/1670 [==============================] - 331s 198ms/step - loss: 0.0155 - accuracy: 0.9960 - val_loss: 0.0232 - val_accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "1670/1670 [==============================] - 330s 198ms/step - loss: 0.0156 - accuracy: 0.9960 - val_loss: 0.0238 - val_accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "1670/1670 [==============================] - 330s 198ms/step - loss: 0.0147 - accuracy: 0.9958 - val_loss: 0.0247 - val_accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "1670/1670 [==============================] - 330s 198ms/step - loss: 0.0155 - accuracy: 0.9961 - val_loss: 0.0247 - val_accuracy: 1.0000\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_83484.0_images_False_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.995868\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training opticnet for 1.0% of train size (aka 83484 images) with pretrained: True and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 276 trainable: 276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "   6/1670 [..............................] - ETA: 50:25 - loss: 5.4719 - accuracy: 0.1788 WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.4668s vs `on_train_batch_end` time: 1.0913s). Check your callbacks.\n",
      "1670/1670 [==============================] - 1978s 1s/step - loss: 0.3038 - accuracy: 0.9117 - val_loss: 0.0668 - val_accuracy: 0.9688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "1670/1670 [==============================] - 1957s 1s/step - loss: 0.1203 - accuracy: 0.9594 - val_loss: 0.1515 - val_accuracy: 0.9688\n",
      "Epoch 3/30\n",
      "1670/1670 [==============================] - 1958s 1s/step - loss: 0.1060 - accuracy: 0.9653 - val_loss: 0.0161 - val_accuracy: 1.0000\n",
      "Epoch 4/30\n",
      "1670/1670 [==============================] - 1959s 1s/step - loss: 0.0874 - accuracy: 0.9706 - val_loss: 0.0111 - val_accuracy: 1.0000\n",
      "Epoch 5/30\n",
      "1670/1670 [==============================] - 1960s 1s/step - loss: 0.0708 - accuracy: 0.9759 - val_loss: 0.0051 - val_accuracy: 1.0000\n",
      "Epoch 6/30\n",
      "1670/1670 [==============================] - 1960s 1s/step - loss: 0.0573 - accuracy: 0.9807 - val_loss: 0.0777 - val_accuracy: 0.9688\n",
      "Epoch 7/30\n",
      "1670/1670 [==============================] - 1963s 1s/step - loss: 0.0451 - accuracy: 0.9842 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
      "Epoch 8/30\n",
      "1670/1670 [==============================] - 1963s 1s/step - loss: 0.0360 - accuracy: 0.9879 - val_loss: 0.0215 - val_accuracy: 1.0000\n",
      "Epoch 9/30\n",
      "1670/1670 [==============================] - 1958s 1s/step - loss: 0.0304 - accuracy: 0.9895 - val_loss: 0.0118 - val_accuracy: 1.0000\n",
      "Epoch 10/30\n",
      "1670/1670 [==============================] - 1965s 1s/step - loss: 0.0233 - accuracy: 0.9924 - val_loss: 0.0091 - val_accuracy: 1.0000\n",
      "Epoch 11/30\n",
      "1670/1670 [==============================] - 1967s 1s/step - loss: 0.0191 - accuracy: 0.9936 - val_loss: 0.0177 - val_accuracy: 1.0000\n",
      "Epoch 12/30\n",
      "1670/1670 [==============================] - 1966s 1s/step - loss: 0.0191 - accuracy: 0.9940 - val_loss: 0.0085 - val_accuracy: 1.0000\n",
      "Epoch 13/30\n",
      "1670/1670 [==============================] - 1965s 1s/step - loss: 0.0168 - accuracy: 0.9946 - val_loss: 0.0574 - val_accuracy: 0.9688\n",
      "Epoch 14/30\n",
      "1670/1670 [==============================] - 1964s 1s/step - loss: 0.0136 - accuracy: 0.9950 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
      "Epoch 15/30\n",
      "1670/1670 [==============================] - 1962s 1s/step - loss: 0.0118 - accuracy: 0.9955 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "1670/1670 [==============================] - 1961s 1s/step - loss: 0.0113 - accuracy: 0.9956 - val_loss: 0.0078 - val_accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "1670/1670 [==============================] - 1959s 1s/step - loss: 0.0099 - accuracy: 0.9957 - val_loss: 0.0191 - val_accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "1670/1670 [==============================] - 1959s 1s/step - loss: 0.0086 - accuracy: 0.9962 - val_loss: 0.0069 - val_accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "1670/1670 [==============================] - 1957s 1s/step - loss: 0.0088 - accuracy: 0.9954 - val_loss: 0.0411 - val_accuracy: 0.9688\n",
      "Epoch 20/30\n",
      "1670/1670 [==============================] - 1956s 1s/step - loss: 0.0074 - accuracy: 0.9964 - val_loss: 0.0219 - val_accuracy: 0.9688\n",
      "Epoch 21/30\n",
      "1670/1670 [==============================] - 1957s 1s/step - loss: 0.0069 - accuracy: 0.9964 - val_loss: 0.0194 - val_accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "1670/1670 [==============================] - 2126s 1s/step - loss: 0.0071 - accuracy: 0.9958 - val_loss: 0.0119 - val_accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "1670/1670 [==============================] - 3960s 2s/step - loss: 0.0069 - accuracy: 0.9963 - val_loss: 0.0342 - val_accuracy: 0.9688\n",
      "Epoch 24/30\n",
      "1670/1670 [==============================] - 2770s 2s/step - loss: 0.0057 - accuracy: 0.9963 - val_loss: 0.0171 - val_accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "1670/1670 [==============================] - 1956s 1s/step - loss: 0.0056 - accuracy: 0.9967 - val_loss: 0.0251 - val_accuracy: 0.9688\n",
      "Epoch 26/30\n",
      "1670/1670 [==============================] - 1957s 1s/step - loss: 0.0054 - accuracy: 0.9966 - val_loss: 0.0043 - val_accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "1670/1670 [==============================] - 1955s 1s/step - loss: 0.0051 - accuracy: 0.9967 - val_loss: 0.0245 - val_accuracy: 0.9688\n",
      "Epoch 28/30\n",
      "1670/1670 [==============================] - 1958s 1s/step - loss: 0.0047 - accuracy: 0.9972 - val_loss: 0.0260 - val_accuracy: 0.9688\n",
      "Epoch 29/30\n",
      "1670/1670 [==============================] - 1958s 1s/step - loss: 0.0049 - accuracy: 0.9968 - val_loss: 0.0274 - val_accuracy: 0.9688\n",
      "Epoch 30/30\n",
      "1670/1670 [==============================] - 1955s 1s/step - loss: 0.0047 - accuracy: 0.9967 - val_loss: 0.0252 - val_accuracy: 0.9688\n",
      "INFO:tensorflow:Assets written to: ../opticnet/opticnet_30epochs_83484.0_images_False_newWeights_False_lastLayerOnly_rescale-symmetric_normalization/assets\n",
      "Test acc for opticnet: 0.995868\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import datetime\n",
    "\n",
    "maxTrain = len(y_train)\n",
    "for newWeights in [True, False]:\n",
    "    tLayer = [False] if newWeights else [True, False] # do not train only last layer if new weights will be produced \n",
    "    for trainLastLayerOnly in tLayer:\n",
    "        for p in [0.01, 0.025, 0.05, 0.075, 0.09, 0.1, 0.25, 0.4, 0.5, 0.6, 0.75, 0.9, 1.0]:\n",
    "            #X_trn, X_tst, y_trn, y_tst\n",
    "            if p < 1:\n",
    "                X_t, _, y_t, _ = train_test_split(images, y_train, test_size=1-p, random_state=234)\n",
    "            else:\n",
    "                X_t = images; y_t = y_train;\n",
    "            print(f\"Labels fraction: {sum(y_t == 1) / sum(y_train == 1)}\")\n",
    "            for net in [\"xception\", \"resnet\", \"opticnet\"]:\n",
    "                print(f\"Training {net} for {p}% of train size (aka {len(X_t)} images) with pretrained: {not newWeights} and onlyLastLayersTrained: {trainLastLayerOnly}...\")\n",
    "                model, size, normalization = emptyModelGenerator(net, newWeights=newWeights, lastOnly=trainLastLayerOnly)\n",
    "                printTrainableLayers(model) # see if model is really well trained\n",
    "                X_trn = resizeIms(X_t, size)\n",
    "                #X_trn = normalizeIms(X_trn, normalization=normalization)\n",
    "                X_val = resizeIms(x_val, size)\n",
    "                #X_val = normalizeIms(X_val, normalization=normalization)\n",
    "                log_dir = f\"logs/{net}/fit/{p}trainSet_\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "                tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "                optimizer = Adam(learning_rate) # create new optimizers\n",
    "                time_callback = TimeHistory()\n",
    "                model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "                hist = model.fit(X_trn, y_t, epochs=epochs, validation_data = (X_val, y_validation), batch_size=batch_size,\n",
    "                            shuffle=True, max_queue_size=20,\n",
    "                            use_multiprocessing=True, workers=5, \n",
    "                            callbacks=[CustomCallback(fraction=0.9, model=net), tensorboard_callback, time_callback])\n",
    "                trainTime = sum(time_callback.times)\n",
    "                model.save(f\"../{net}/{net}_{epochs}epochs_{p*maxTrain}_images_{newWeights}_newWeights_{trainLastLayerOnly}_lastLayerOnly_{normalization}_normalization\")\n",
    "                tstAcc = testPredict(model, size, name=net) #, normalization=normalization)\n",
    "                results = results.append({\n",
    "                    'model': net, \n",
    "                    'train set images': len(X_t), \n",
    "                    'pretrained': not newWeights, \n",
    "                    'pretrained dataset': None if newWeights else (\"OCT2017,Srinivasan2014\" if net == \"opticnet\" else \"Imagenet\"),\n",
    "                    'Trained layers': \"Last dense\" if trainLastLayerOnly else \"All\", \n",
    "                    'epochs': epochs, \n",
    "                    'batch size': batch_size, \n",
    "                    'learning rate': learning_rate, \n",
    "                    'optimizer': optimizer._name,\n",
    "                    'training time (seconds)': trainTime, \n",
    "                    'train accuracy': hist.history[\"accuracy\"][-1], \n",
    "                    'train loss': hist.history[\"loss\"][-1],\n",
    "                    'validation accuracy': hist.history[\"val_accuracy\"][-1], \n",
    "                    'validation loss': hist.history[\"val_loss\"][-1], \n",
    "                    'test accuracy': tstAcc,\n",
    "                    #'normalization': normalization\n",
    "                }, ignore_index=True)\n",
    "                results.to_csv(\"Results_temp.csv\", index=False)\n",
    "                del model\n",
    "                del X_trn\n",
    "                del X_val\n",
    "                print(\"Done!\\n\" + '-'*50, end='\\n\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
