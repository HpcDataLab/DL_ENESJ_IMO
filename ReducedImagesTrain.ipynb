{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "import os\n",
    "import cv2\n",
    "import pickle\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version is: 2.4.1\n"
     ]
    }
   ],
   "source": [
    "print(f\"Tensorflow version is: {tf.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataPath = \"../../data/OCT/OCT2017/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of Classes Detected : 4\n"
     ]
    }
   ],
   "source": [
    "labels_available = os.listdir(os.path.join(dataPath, \"train\"))\n",
    "print(\"Total Number of Classes Detected :\",len(labels_available))\n",
    "\n",
    "labels_list = ['NORMAL',\"CNV\",\"DME\",\"DRUSEN\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NORMAL CNV DME DRUSEN "
     ]
    }
   ],
   "source": [
    "images=[]\n",
    "y_trn=[]\n",
    "for x in labels_list:\n",
    "    xPath = os.path.join(dataPath, \"train\", x)\n",
    "    myPicList = os.listdir(xPath)\n",
    "    for y in myPicList:\n",
    "        images.append(cv2.imread(os.path.join(xPath, y)))\n",
    "        y_trn.append(labels_list.index(x))\n",
    "    print(x ,end=\" \")\n",
    "\n",
    "y_train = to_categorical(y_trn,len(labels_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NORMAL CNV DME DRUSEN "
     ]
    }
   ],
   "source": [
    "x_val=[]\n",
    "y_val=[]\n",
    "for x in labels_list:\n",
    "    xPath = os.path.join(dataPath, \"val\", x)\n",
    "    myPicList = os.listdir(xPath)\n",
    "    for y in myPicList:\n",
    "        x_val.append(cv2.imread(os.path.join(xPath, y)))\n",
    "        y_val.append(labels_list.index(x))\n",
    "    print(x ,end=\" \")\n",
    "\n",
    "y_validation = to_categorical(y_val,len(labels_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NORMAL CNV DME DRUSEN "
     ]
    }
   ],
   "source": [
    "x_tst=[]\n",
    "y_tst=[]\n",
    "for x in labels_list:\n",
    "    xPath = os.path.join(dataPath, \"test\", x)\n",
    "    myPicList = os.listdir(xPath)\n",
    "    for y in myPicList:\n",
    "        x_tst.append(cv2.imread(os.path.join(xPath, y)))\n",
    "        y_tst.append(labels_list.index(x))\n",
    "    print(x ,end=\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of images per category and set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label\t\tTrain\t\tValidation\t\tTest\n",
      "NORMAL\t\t26315\t\t8\t\t\t242\n",
      "CNV\t\t37205\t\t8\t\t\t242\n",
      "DME\t\t11348\t\t8\t\t\t242\n",
      "DRUSEN\t\t8616\t\t8\t\t\t242\n"
     ]
    }
   ],
   "source": [
    "def getNumberOfItems(labels, itemLabel):\n",
    "    return sum(list(map(lambda x: x == itemLabel, labels))) \n",
    "\n",
    "\n",
    "print(\"Label\\t\\tTrain\\t\\tValidation\\t\\tTest\")\n",
    "for i, label in enumerate(labels_list):\n",
    "    print(f\"{label}\\t\\t{getNumberOfItems(y_trn, i)}\\t\\t{getNumberOfItems(y_val, i)}\\t\\t\\t{getNumberOfItems(y_tst, i)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resizeIm(im, size):\n",
    "    if im.shape[2] == 1:\n",
    "        im = cv2.cvtColor(im,cv2.COLOR_GRAY2RGB)\n",
    "    return cv2.resize(im, size)\n",
    "\n",
    "def resizeIms(x, size):\n",
    "    return np.array(list(map(lambda im: resizeIm(im, size), x)))\n",
    "\n",
    "# Substract the mean specified by Mean (https://www.mathworks.com/help/deeplearning/ref/nnet.cnn.layer.imageinputlayer.html)\n",
    "# Substract mean by channel\n",
    "def zerocenter(x):\n",
    "    return (x - np.mean(x, axis=(0, 1))) / (2*np.std(x, axis=(0, 1)))\n",
    "\n",
    "# Rescale the input to be in the range [-1, 1] using the minimum and maximum values specified by Min and Max, respectively. (https://www.mathworks.com/help/deeplearning/ref/nnet.cnn.layer.imageinputlayer.html)\n",
    "# Compute using the formula: $x\\prime = 2 * \\frac{x - \\min{x}}{\\max{x} - \\min{x}} - 1$ taken from: https://stats.stackexchange.com/a/178629\n",
    "def rescaleSymmetric(x):\n",
    "    x = zerocenter(x)\n",
    "    return 2 * (x - np.min(x, axis=(0, 1)))/np.ptp(x, axis=(0, 1)) - 1\n",
    "\n",
    "def normalizeIms(x, normalization):\n",
    "    if normalization == \"zerocenter\":\n",
    "        func = zerocenter\n",
    "    elif normalization == \"rescale-symmetric\":\n",
    "        func = rescaleSymmetric\n",
    "    else:\n",
    "        return x\n",
    "    return np.array(list(map(lambda im: func(im), x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self,fraction, model):\n",
    "        super(CustomCallback,self).__init__()\n",
    "        self.fraction = fraction\n",
    "        self.train_a = [];\n",
    "        self.val_a =[];\n",
    "        self.logPath = os.path.join(model, \"log.txt\")\n",
    "\n",
    "        if not os.path.isdir(model):\n",
    "            os.mkdir(model)\n",
    "\n",
    "        with open(self.logPath,'w') as f:\n",
    "            f.write('Starting of logging..\\n')\n",
    "\n",
    "        self.fig = plt.figure(figsize=(4,3))\n",
    "        self.ax = plt.subplot(1,1,1)\n",
    "        plt.ion()\n",
    "\n",
    "    def on_train_begin(self,logs=None):\n",
    "        self.fig.show()\n",
    "        self.fig.canvas.draw()\n",
    "\n",
    "    def on_train_end(self,logs=None):\n",
    "        with open(self.logPath,'a') as f:\n",
    "              f.write('End of logging..\\n')\n",
    "    \n",
    "    def on_epoch_begin(self,epoch,logs=None):\n",
    "        lr= tf.keras.backend.get_value(self.model.optimizer.lr)\n",
    "        lr *= self.fraction\n",
    "        tf.keras.backend.set_value(self.model.optimizer.lr,lr)\n",
    "        with open(self.logPath,'a') as f:\n",
    "            f.write('At epoch {:02d}, learning rate changed to {:.4f}\\n'.format(epoch,lr))\n",
    "    \n",
    "    def on_epoch_end(self,epoch,logs=None):\n",
    "        val_acc = logs.get('val_accuracy')\n",
    "        train_acc = logs.get('accuracy')\n",
    "        self.train_a.append(train_acc)\n",
    "        self.val_a.append(val_acc)\n",
    "        with open(self.logPath,'a') as f:\n",
    "            f.write('At epoch {:02d}, training accuracy: {:.3f}, validation accuracy: {:.3f}\\n'.format(epoch,train_acc,val_acc))\n",
    "        self.ax.clear()\n",
    "        self.ax.plot(range(1+epoch),self.train_a,label=\"Training\")\n",
    "        self.ax.plot(range(1+epoch),self.val_a,label=\"Validation\")\n",
    "        self.ax.set_xlabel('Epochs')\n",
    "        self.ax.set_ylabel('Accuracy')\n",
    "        self.ax.legend()\n",
    "        self.fig.canvas.draw()\n",
    "        self.fig.show()\n",
    "        \n",
    "class TimeHistory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.times = []\n",
    "\n",
    "    def on_epoch_begin(self, batch, logs={}):\n",
    "        self.epoch_time_start = time.time()\n",
    "\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.times.append(time.time() - self.epoch_time_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "# xception base model\n",
    "#from tensorflow.keras.applications.xception import Xception\n",
    "#from tensorflow.keras.applications.xception import preprocess_input, decode_predictions\n",
    "#xceptionNetModel = Xception(weights='imagenet')\n",
    "#xceptionNetModel.save(\"../Xception.hdf5\")\n",
    "\n",
    "xceptionNetModel = tf.keras.models.load_model('../Xception.hdf5')\n",
    "\n",
    "# opticnet base model\n",
    "opticNetModel = tf.keras.models.load_model('../Optic_net-4_classes-Kermany2018.hdf5')\n",
    "\n",
    "# resnet base model\n",
    "#from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "#from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "#resNetModel = ResNet50(weights='imagenet')\n",
    "#resNetModel.save(\"../Resnet50.hdf5\")\n",
    "\n",
    "resNetModel = tf.keras.models.load_model('../Resnet50.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 221, 221, 32)      4736      \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 221, 221, 32)      128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 110, 110, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 104, 104, 32)      50208     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 104, 104, 32)      128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 52, 52, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 48, 48, 64)        51264     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 48, 48, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 24, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 20, 20, 128)       204928    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 20, 20, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 10, 10, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 8, 8, 256)         295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d (AveragePo (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               131200    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4)                 132       \n",
      "_________________________________________________________________\n",
      "softmax (Softmax)            (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 743,812\n",
      "Trainable params: 742,788\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "conv_init = tf.keras.initializers.RandomNormal(mean=0., stddev=1.) # convolutional layer with zero mean and 1 sd\n",
    "#batch_init = tf.keras.initializers.RandomNormal(mean=1., stddev=0.02) # non-sense here\n",
    "\n",
    "octnet = keras.models.Sequential() # empty model\n",
    "\n",
    "octnet.add(keras.layers.Conv2D(32, (7, 7), activation=\"relu\", use_bias=True, input_shape=(227, 227, 3), kernel_initializer=conv_init))\n",
    "octnet.add(keras.layers.BatchNormalization())\n",
    "octnet.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "octnet.add(keras.layers.Conv2D(32, (7, 7), activation=\"relu\", use_bias=True, kernel_initializer=conv_init))\n",
    "octnet.add(keras.layers.BatchNormalization())\n",
    "octnet.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "octnet.add(keras.layers.Conv2D(64, (5, 5), activation=\"relu\", use_bias=True, kernel_initializer=conv_init))\n",
    "octnet.add(keras.layers.BatchNormalization())\n",
    "octnet.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "octnet.add(keras.layers.Conv2D(128, (5, 5), activation=\"relu\", use_bias=True, kernel_initializer=conv_init))\n",
    "octnet.add(keras.layers.BatchNormalization())\n",
    "octnet.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "octnet.add(keras.layers.Conv2D(256, (3, 3), activation=\"relu\", use_bias=True, kernel_initializer=conv_init))\n",
    "octnet.add(keras.layers.BatchNormalization())\n",
    "octnet.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "#octnet.add(keras.layers.Conv2D(512, (3, 3), activation=\"relu\", use_bias=True))\n",
    "#octnet.add(keras.layers.BatchNormalization())\n",
    "#octnet.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "octnet.add(keras.layers.AveragePooling2D())\n",
    "octnet.add(keras.layers.Flatten())\n",
    "octnet.add(keras.layers.Dense(128))\n",
    "octnet.add(keras.layers.Dropout(0.5))\n",
    "octnet.add(keras.layers.Dense(32))\n",
    "octnet.add(keras.layers.Dropout(0.5))\n",
    "octnet.add(keras.layers.Dense(4))\n",
    "octnet.add(keras.layers.Softmax())\n",
    "\n",
    "octnet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emptyModelGenerator(model, newWeights=False, lastOnly=False):\n",
    "    model = model.lower() # lower case model name\n",
    "    if model == \"resnet\":\n",
    "        x = resNetModel.output\n",
    "        predictions = Dense(len(labels_list), activation='softmax')(x)\n",
    "        newModel = Model(inputs=resNetModel.input, outputs=predictions)\n",
    "        size = (224, 224)\n",
    "        normalization = \"zerocenter\"\n",
    "    elif model == \"xception\":\n",
    "        x = xceptionNetModel.output\n",
    "        predictions = Dense(len(labels_list), activation='softmax')(x)\n",
    "        newModel = Model(inputs=xceptionNetModel.input, outputs=predictions)\n",
    "        size = (299, 299)\n",
    "        normalization = \"rescale-symmetric\"\n",
    "    elif model == \"opticnet\":\n",
    "        newModel = tf.keras.models.load_model('../Optic_net-4_classes-Kermany2018.hdf5')\n",
    "        size = (224, 224)\n",
    "        normalization = \"rescale-symmetric\"\n",
    "    elif model == \"octnet\":\n",
    "        newModel = tf.keras.models.clone_model(octnet)\n",
    "        size = (227, 227)\n",
    "        normalization = \"zerocenter\"\n",
    "    if newWeights:\n",
    "        newModel = tf.keras.models.clone_model(newModel)\n",
    "    if lastOnly:\n",
    "        newModel = lastDenseTrainable(newModel) # block all layer except the last dense ones\n",
    "    else:\n",
    "        newModel.trainable = True\n",
    "    return newModel, size, normalization\n",
    "\n",
    "\n",
    "def lastDenseTrainable(model):\n",
    "    model.trainable = False\n",
    "    for i in range(1, len(model.layers)):\n",
    "        if model.layers[-i].__class__.__name__ == \"Dense\":\n",
    "            model.layers[-i].trainable= True\n",
    "        elif model.layers[-i].__class__.__name__ == \"Activation\":\n",
    "            continue\n",
    "        else:\n",
    "            break\n",
    "    return model\n",
    "    \n",
    "\n",
    "def testPredict(model, size, name=None, normalization=None):\n",
    "    X_test = resizeIms(x_tst, size)\n",
    "    if normalization:\n",
    "        X_test = normalizeIms(X_test, normalization)\n",
    "    X_test = np.array(X_test)\n",
    "    Y_test = np.array(y_tst)\n",
    "    \n",
    "    prediction = model.predict(X_test)\n",
    "    preds = np.argmax(prediction, axis=1)\n",
    "    acc = sum(preds == Y_test) / len(Y_test)\n",
    "    print(f'Test acc for {name if name else \"model\"}: {acc:.6f}')\n",
    "    return acc\n",
    "    \n",
    "\n",
    "def computeConfussionMatrix(predictions, labels):\n",
    "    num_labels = len(labels_list)\n",
    "    cMatrix = np.zeros(shape=(num_labels, num_labels))\n",
    "    for i in len(predictions):\n",
    "        p = int(predictions[i])\n",
    "        t = int(predictions[i])\n",
    "        cMatrix[t, p] += 1\n",
    "    print(cMatrix)\n",
    "    ax = sns.heatmap(cMatrix, cmap=\"Blues\", annot=True, fmt=\"d\", xticklabels=labels_list, yticklabels=labels_list)\n",
    "    plt.xlabel(\"Predicted label\")\n",
    "    plt.ylabel(\"True label\")\n",
    "    plt.title(\"Confusion matrix\")\n",
    "    plt.show();\n",
    "    return cMatrix\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "**************************************************\n",
      "Model: xception\n",
      "**************************************************\n",
      "\n",
      "Total: 135 trainable: 2\n",
      "\n",
      "\n",
      "**************************************************\n",
      "Model: resnet\n",
      "**************************************************\n",
      "\n",
      "Total: 178 trainable: 2\n",
      "\n",
      "\n",
      "**************************************************\n",
      "Model: opticnet\n",
      "**************************************************\n",
      "\n",
      "Total: 276 trainable: 2\n",
      "\n",
      "\n",
      "**************************************************\n",
      "Model: octnet\n",
      "**************************************************\n",
      "\n",
      "Total: 23 trainable: 0\n"
     ]
    }
   ],
   "source": [
    "models = [\"xception\", \"resnet\", \"opticnet\", \"octnet\"]\n",
    "\n",
    "def printTrainableLayers(m):\n",
    "    a = 0\n",
    "    for l in m.layers:\n",
    "        #l.trainable = True\n",
    "        if l.trainable:\n",
    "            #print(l.name, l.trainable)\n",
    "            a += 1\n",
    "    print(f\"\\nTotal: {len(m.layers)} trainable: {a}\")\n",
    "\n",
    "for mod in models:\n",
    "    print(\"\\n\\n\" + (\"*\"*50) + \"\\nModel: \" + mod + '\\n' + (\"*\"*50))\n",
    "    m = emptyModelGenerator(mod, newWeights=False, lastOnly=True)[0]\n",
    "    printTrainableLayers(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "momentum = 0.9\n",
    "optim = lambda lr: Adam(learning_rate=lr)\n",
    "#optim = lambda lr, momentum: SGD(learning_rate=lr, momentum=momentum)\n",
    "epochs = 30\n",
    "batch_size = 50\n",
    "#batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "results = pd.read_csv(\"Results_temp.csv\")\n",
    "results[\"normalization\"] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pandas as pd\n",
    "#res = pd.read_csv(\"Results_temp.csv\")\n",
    "#res.to_csv(\"Results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels fraction: [0.0100323  0.01083188 0.00863588 0.00800836]\n",
      "Training octnet for 0.01% of train size (aka 834 images) with pretrained: False and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 23 trainable: 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      " 5/17 [=======>......................] - ETA: 0s - loss: 4.6082 - accuracy: 0.3063WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0191s vs `on_train_batch_end` time: 0.0295s). Check your callbacks.\n",
      "17/17 [==============================] - 12s 116ms/step - loss: 4.5105 - accuracy: 0.3470 - val_loss: 463.5843 - val_accuracy: 0.2500\n",
      "Epoch 2/30\n",
      " 1/17 [>.............................] - ETA: 0s - loss: 4.7905 - accuracy: 0.4000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 1s 43ms/step - loss: 3.0709 - accuracy: 0.4812 - val_loss: 122.0998 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 2.2997 - accuracy: 0.5203 - val_loss: 36.9008 - val_accuracy: 0.3750\n",
      "Epoch 4/30\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 1.6845 - accuracy: 0.5730 - val_loss: 26.5846 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 1.7707 - accuracy: 0.5917 - val_loss: 12.1131 - val_accuracy: 0.4688\n",
      "Epoch 6/30\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 1.6440 - accuracy: 0.5984 - val_loss: 12.9047 - val_accuracy: 0.3438\n",
      "Epoch 7/30\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 1.3625 - accuracy: 0.6864 - val_loss: 4.7462 - val_accuracy: 0.5000\n",
      "Epoch 8/30\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 1.2795 - accuracy: 0.6861 - val_loss: 2.7696 - val_accuracy: 0.5312\n",
      "Epoch 9/30\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 1.1850 - accuracy: 0.6676 - val_loss: 3.0028 - val_accuracy: 0.5000\n",
      "Epoch 10/30\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 1.2210 - accuracy: 0.6876 - val_loss: 2.5783 - val_accuracy: 0.5000\n",
      "Epoch 11/30\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 1.0922 - accuracy: 0.7098 - val_loss: 1.2224 - val_accuracy: 0.5625\n",
      "Epoch 12/30\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.9606 - accuracy: 0.7001 - val_loss: 2.0786 - val_accuracy: 0.5000\n",
      "Epoch 13/30\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.9652 - accuracy: 0.7279 - val_loss: 1.2517 - val_accuracy: 0.5938\n",
      "Epoch 14/30\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.8772 - accuracy: 0.7036 - val_loss: 1.4741 - val_accuracy: 0.5625\n",
      "Epoch 15/30\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.7739 - accuracy: 0.7395 - val_loss: 1.1256 - val_accuracy: 0.5625\n",
      "Epoch 16/30\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.7657 - accuracy: 0.7537 - val_loss: 1.2199 - val_accuracy: 0.5938\n",
      "Epoch 17/30\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.8387 - accuracy: 0.7631 - val_loss: 1.2687 - val_accuracy: 0.5625\n",
      "Epoch 18/30\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.7743 - accuracy: 0.7607 - val_loss: 1.2189 - val_accuracy: 0.5938\n",
      "Epoch 19/30\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.7928 - accuracy: 0.7284 - val_loss: 1.1478 - val_accuracy: 0.5938\n",
      "Epoch 20/30\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.5951 - accuracy: 0.7946 - val_loss: 1.0260 - val_accuracy: 0.6562\n",
      "Epoch 21/30\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.6498 - accuracy: 0.7721 - val_loss: 1.1768 - val_accuracy: 0.5625\n",
      "Epoch 22/30\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.6162 - accuracy: 0.7772 - val_loss: 1.2031 - val_accuracy: 0.5938\n",
      "Epoch 23/30\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.6802 - accuracy: 0.7675 - val_loss: 1.0028 - val_accuracy: 0.6562\n",
      "Epoch 24/30\n",
      "17/17 [==============================] - 1s 42ms/step - loss: 0.6166 - accuracy: 0.7986 - val_loss: 1.2170 - val_accuracy: 0.5625\n",
      "Epoch 25/30\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.6909 - accuracy: 0.7763 - val_loss: 0.9870 - val_accuracy: 0.6562\n",
      "Epoch 26/30\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.5627 - accuracy: 0.8047 - val_loss: 1.0663 - val_accuracy: 0.6562\n",
      "Epoch 27/30\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.5209 - accuracy: 0.8178 - val_loss: 1.0153 - val_accuracy: 0.6562\n",
      "Epoch 28/30\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.5231 - accuracy: 0.8078 - val_loss: 1.0223 - val_accuracy: 0.6562\n",
      "Epoch 29/30\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.6014 - accuracy: 0.8098 - val_loss: 1.1184 - val_accuracy: 0.5938\n",
      "Epoch 30/30\n",
      "17/17 [==============================] - 1s 43ms/step - loss: 0.6331 - accuracy: 0.8040 - val_loss: 1.1228 - val_accuracy: 0.5938\n",
      "INFO:tensorflow:Assets written to: ../octnet/octnet_30epochs_835_images_True_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for octnet: 0.587810\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.02420673 0.02577611 0.02634826 0.02228412]\n",
      "Training octnet for 0.025% of train size (aka 2087 images) with pretrained: False and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 23 trainable: 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      " 5/42 [==>...........................] - ETA: 3s - loss: 4.9259 - accuracy: 0.2507WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0186s vs `on_train_batch_end` time: 0.0543s). Check your callbacks.\n",
      "42/42 [==============================] - 4s 63ms/step - loss: 4.0538 - accuracy: 0.3790 - val_loss: 40.3523 - val_accuracy: 0.4062\n",
      "Epoch 2/30\n",
      " 1/42 [..............................] - ETA: 1s - loss: 2.5673 - accuracy: 0.4600"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 2s 42ms/step - loss: 2.3355 - accuracy: 0.5237 - val_loss: 5.0973 - val_accuracy: 0.5000\n",
      "Epoch 3/30\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 1.6786 - accuracy: 0.5784 - val_loss: 2.7065 - val_accuracy: 0.5000\n",
      "Epoch 4/30\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 1.5885 - accuracy: 0.6333 - val_loss: 1.7106 - val_accuracy: 0.5312\n",
      "Epoch 5/30\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 1.4181 - accuracy: 0.6222 - val_loss: 1.0247 - val_accuracy: 0.5938\n",
      "Epoch 6/30\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 1.1589 - accuracy: 0.6654 - val_loss: 0.9467 - val_accuracy: 0.5938\n",
      "Epoch 7/30\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 1.0095 - accuracy: 0.6824 - val_loss: 1.0751 - val_accuracy: 0.5938\n",
      "Epoch 8/30\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.9148 - accuracy: 0.7119 - val_loss: 0.8151 - val_accuracy: 0.5938\n",
      "Epoch 9/30\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.9274 - accuracy: 0.7003 - val_loss: 0.9725 - val_accuracy: 0.5625\n",
      "Epoch 10/30\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.8339 - accuracy: 0.7455 - val_loss: 1.0546 - val_accuracy: 0.5625\n",
      "Epoch 11/30\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.8246 - accuracy: 0.7330 - val_loss: 0.7414 - val_accuracy: 0.7188\n",
      "Epoch 12/30\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.6999 - accuracy: 0.7689 - val_loss: 0.7982 - val_accuracy: 0.6250\n",
      "Epoch 13/30\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.6246 - accuracy: 0.7794 - val_loss: 0.8407 - val_accuracy: 0.6250\n",
      "Epoch 14/30\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.6723 - accuracy: 0.7563 - val_loss: 0.8286 - val_accuracy: 0.6562\n",
      "Epoch 15/30\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.5954 - accuracy: 0.7792 - val_loss: 0.8231 - val_accuracy: 0.6562\n",
      "Epoch 16/30\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.5782 - accuracy: 0.7793 - val_loss: 0.8287 - val_accuracy: 0.6875\n",
      "Epoch 17/30\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.5879 - accuracy: 0.7720 - val_loss: 0.8467 - val_accuracy: 0.6250\n",
      "Epoch 18/30\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.5597 - accuracy: 0.8030 - val_loss: 0.8891 - val_accuracy: 0.6875\n",
      "Epoch 19/30\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.5119 - accuracy: 0.8076 - val_loss: 0.8127 - val_accuracy: 0.6250\n",
      "Epoch 20/30\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.5179 - accuracy: 0.8186 - val_loss: 0.7264 - val_accuracy: 0.6875\n",
      "Epoch 21/30\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.5257 - accuracy: 0.8001 - val_loss: 0.7698 - val_accuracy: 0.6562\n",
      "Epoch 22/30\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.5113 - accuracy: 0.8117 - val_loss: 0.7907 - val_accuracy: 0.6250\n",
      "Epoch 23/30\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.4694 - accuracy: 0.8279 - val_loss: 0.8005 - val_accuracy: 0.6250\n",
      "Epoch 24/30\n",
      "42/42 [==============================] - 2s 42ms/step - loss: 0.4572 - accuracy: 0.8397 - val_loss: 0.8019 - val_accuracy: 0.6250\n",
      "Epoch 25/30\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.4769 - accuracy: 0.8192 - val_loss: 0.7972 - val_accuracy: 0.6250\n",
      "Epoch 26/30\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.4515 - accuracy: 0.8324 - val_loss: 0.7867 - val_accuracy: 0.6875\n",
      "Epoch 27/30\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.4370 - accuracy: 0.8398 - val_loss: 0.8361 - val_accuracy: 0.6562\n",
      "Epoch 28/30\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.4117 - accuracy: 0.8455 - val_loss: 0.7271 - val_accuracy: 0.6250\n",
      "Epoch 29/30\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.4555 - accuracy: 0.8329 - val_loss: 0.7420 - val_accuracy: 0.6250\n",
      "Epoch 30/30\n",
      "42/42 [==============================] - 2s 41ms/step - loss: 0.3978 - accuracy: 0.8502 - val_loss: 0.7720 - val_accuracy: 0.6250\n",
      "INFO:tensorflow:Assets written to: ../octnet/octnet_30epochs_2087_images_True_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for octnet: 0.700413\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.04902147 0.05096089 0.0489073  0.05025534]\n",
      "Training octnet for 0.05% of train size (aka 4174 images) with pretrained: False and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 23 trainable: 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      " 5/84 [>.............................] - ETA: 6s - loss: 5.3363 - accuracy: 0.3102 WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0190s vs `on_train_batch_end` time: 0.0533s). Check your callbacks.\n",
      "84/84 [==============================] - 5s 50ms/step - loss: 3.4300 - accuracy: 0.4453 - val_loss: 5.2326 - val_accuracy: 0.5000\n",
      "Epoch 2/30\n",
      " 1/84 [..............................] - ETA: 3s - loss: 2.2985 - accuracy: 0.5600"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84/84 [==============================] - 3s 41ms/step - loss: 1.7257 - accuracy: 0.5734 - val_loss: 4.5016 - val_accuracy: 0.4062\n",
      "Epoch 3/30\n",
      "84/84 [==============================] - 3s 41ms/step - loss: 1.3401 - accuracy: 0.6205 - val_loss: 1.5161 - val_accuracy: 0.5938\n",
      "Epoch 4/30\n",
      "84/84 [==============================] - 3s 42ms/step - loss: 1.0277 - accuracy: 0.6827 - val_loss: 1.0355 - val_accuracy: 0.6250\n",
      "Epoch 5/30\n",
      "84/84 [==============================] - 3s 41ms/step - loss: 0.9117 - accuracy: 0.6978 - val_loss: 0.9465 - val_accuracy: 0.6562\n",
      "Epoch 6/30\n",
      "84/84 [==============================] - 3s 41ms/step - loss: 0.8159 - accuracy: 0.7235 - val_loss: 0.9285 - val_accuracy: 0.7188\n",
      "Epoch 7/30\n",
      "84/84 [==============================] - 3s 41ms/step - loss: 0.7275 - accuracy: 0.7495 - val_loss: 0.9516 - val_accuracy: 0.6250\n",
      "Epoch 8/30\n",
      "84/84 [==============================] - 3s 41ms/step - loss: 0.6683 - accuracy: 0.7608 - val_loss: 1.0005 - val_accuracy: 0.7188\n",
      "Epoch 9/30\n",
      "84/84 [==============================] - 3s 41ms/step - loss: 0.6026 - accuracy: 0.7770 - val_loss: 0.7316 - val_accuracy: 0.7500\n",
      "Epoch 10/30\n",
      "84/84 [==============================] - 3s 41ms/step - loss: 0.6131 - accuracy: 0.7691 - val_loss: 0.6863 - val_accuracy: 0.7500\n",
      "Epoch 11/30\n",
      "84/84 [==============================] - 3s 41ms/step - loss: 0.5635 - accuracy: 0.7999 - val_loss: 0.7262 - val_accuracy: 0.7500\n",
      "Epoch 12/30\n",
      "84/84 [==============================] - 3s 41ms/step - loss: 0.5100 - accuracy: 0.8084 - val_loss: 0.9715 - val_accuracy: 0.7500\n",
      "Epoch 13/30\n",
      "84/84 [==============================] - 3s 41ms/step - loss: 0.4919 - accuracy: 0.8149 - val_loss: 0.7616 - val_accuracy: 0.7812\n",
      "Epoch 14/30\n",
      "84/84 [==============================] - 3s 41ms/step - loss: 0.4568 - accuracy: 0.8326 - val_loss: 0.6672 - val_accuracy: 0.7188\n",
      "Epoch 15/30\n",
      "84/84 [==============================] - 3s 41ms/step - loss: 0.4333 - accuracy: 0.8439 - val_loss: 0.6727 - val_accuracy: 0.7188\n",
      "Epoch 16/30\n",
      "84/84 [==============================] - 3s 41ms/step - loss: 0.4509 - accuracy: 0.8355 - val_loss: 0.6589 - val_accuracy: 0.7500\n",
      "Epoch 17/30\n",
      "84/84 [==============================] - 3s 41ms/step - loss: 0.4137 - accuracy: 0.8489 - val_loss: 0.6681 - val_accuracy: 0.8125\n",
      "Epoch 18/30\n",
      "84/84 [==============================] - 3s 41ms/step - loss: 0.4128 - accuracy: 0.8488 - val_loss: 0.7773 - val_accuracy: 0.8125\n",
      "Epoch 19/30\n",
      "84/84 [==============================] - 3s 41ms/step - loss: 0.3751 - accuracy: 0.8562 - val_loss: 0.7154 - val_accuracy: 0.7812\n",
      "Epoch 20/30\n",
      "84/84 [==============================] - 3s 41ms/step - loss: 0.3749 - accuracy: 0.8645 - val_loss: 0.6483 - val_accuracy: 0.7500\n",
      "Epoch 21/30\n",
      "84/84 [==============================] - 3s 41ms/step - loss: 0.3297 - accuracy: 0.8736 - val_loss: 0.7383 - val_accuracy: 0.8125\n",
      "Epoch 22/30\n",
      "84/84 [==============================] - 3s 41ms/step - loss: 0.3371 - accuracy: 0.8765 - val_loss: 0.6562 - val_accuracy: 0.8125\n",
      "Epoch 23/30\n",
      "84/84 [==============================] - 3s 41ms/step - loss: 0.3320 - accuracy: 0.8789 - val_loss: 0.6450 - val_accuracy: 0.8125\n",
      "Epoch 24/30\n",
      "84/84 [==============================] - 4s 42ms/step - loss: 0.3009 - accuracy: 0.8897 - val_loss: 0.6714 - val_accuracy: 0.8125\n",
      "Epoch 25/30\n",
      "84/84 [==============================] - 3s 41ms/step - loss: 0.2911 - accuracy: 0.8982 - val_loss: 0.8412 - val_accuracy: 0.7812\n",
      "Epoch 26/30\n",
      "84/84 [==============================] - 3s 41ms/step - loss: 0.3121 - accuracy: 0.8907 - val_loss: 0.7484 - val_accuracy: 0.8125\n",
      "Epoch 27/30\n",
      "84/84 [==============================] - 3s 41ms/step - loss: 0.2985 - accuracy: 0.8981 - val_loss: 0.6468 - val_accuracy: 0.8125\n",
      "Epoch 28/30\n",
      "84/84 [==============================] - 3s 41ms/step - loss: 0.3036 - accuracy: 0.8901 - val_loss: 0.7417 - val_accuracy: 0.8125\n",
      "Epoch 29/30\n",
      "84/84 [==============================] - 3s 41ms/step - loss: 0.2992 - accuracy: 0.8930 - val_loss: 0.6980 - val_accuracy: 0.8125\n",
      "Epoch 30/30\n",
      "84/84 [==============================] - 3s 41ms/step - loss: 0.3047 - accuracy: 0.8889 - val_loss: 0.7181 - val_accuracy: 0.8125\n",
      "INFO:tensorflow:Assets written to: ../octnet/octnet_30epochs_4174_images_True_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for octnet: 0.763430\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.07501425 0.07571563 0.07340501 0.07393222]\n",
      "Training octnet for 0.075% of train size (aka 6261 images) with pretrained: False and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 23 trainable: 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  5/126 [>.............................] - ETA: 10s - loss: 4.5545 - accuracy: 0.3584WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0189s vs `on_train_batch_end` time: 0.0533s). Check your callbacks.\n",
      "126/126 [==============================] - 7s 46ms/step - loss: 3.3011 - accuracy: 0.4367 - val_loss: 4.1317 - val_accuracy: 0.5000\n",
      "Epoch 2/30\n",
      "  1/126 [..............................] - ETA: 5s - loss: 0.7915 - accuracy: 0.6800"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126/126 [==============================] - 5s 41ms/step - loss: 1.5125 - accuracy: 0.6063 - val_loss: 0.9118 - val_accuracy: 0.6250\n",
      "Epoch 3/30\n",
      "126/126 [==============================] - 5s 41ms/step - loss: 1.1930 - accuracy: 0.6513 - val_loss: 0.9335 - val_accuracy: 0.6250\n",
      "Epoch 4/30\n",
      "126/126 [==============================] - 5s 41ms/step - loss: 0.8986 - accuracy: 0.7142 - val_loss: 0.5487 - val_accuracy: 0.7812\n",
      "Epoch 5/30\n",
      "126/126 [==============================] - 5s 41ms/step - loss: 0.8050 - accuracy: 0.7214 - val_loss: 0.8011 - val_accuracy: 0.7188\n",
      "Epoch 6/30\n",
      "126/126 [==============================] - 5s 41ms/step - loss: 0.7267 - accuracy: 0.7492 - val_loss: 0.7173 - val_accuracy: 0.7500\n",
      "Epoch 7/30\n",
      "126/126 [==============================] - 5s 41ms/step - loss: 0.6550 - accuracy: 0.7661 - val_loss: 0.5515 - val_accuracy: 0.7500\n",
      "Epoch 8/30\n",
      "126/126 [==============================] - 5s 41ms/step - loss: 0.6114 - accuracy: 0.7830 - val_loss: 0.6445 - val_accuracy: 0.7812\n",
      "Epoch 9/30\n",
      "126/126 [==============================] - 5s 41ms/step - loss: 0.5699 - accuracy: 0.7962 - val_loss: 0.4916 - val_accuracy: 0.8125\n",
      "Epoch 10/30\n",
      "126/126 [==============================] - 5s 41ms/step - loss: 0.5628 - accuracy: 0.8064 - val_loss: 0.5794 - val_accuracy: 0.8125\n",
      "Epoch 11/30\n",
      "126/126 [==============================] - 5s 41ms/step - loss: 0.5196 - accuracy: 0.8211 - val_loss: 0.4773 - val_accuracy: 0.8125\n",
      "Epoch 12/30\n",
      "126/126 [==============================] - 5s 41ms/step - loss: 0.4772 - accuracy: 0.8248 - val_loss: 0.6282 - val_accuracy: 0.7188\n",
      "Epoch 13/30\n",
      "126/126 [==============================] - 5s 41ms/step - loss: 0.4469 - accuracy: 0.8386 - val_loss: 0.6543 - val_accuracy: 0.7812\n",
      "Epoch 14/30\n",
      "126/126 [==============================] - 5s 41ms/step - loss: 0.4153 - accuracy: 0.8505 - val_loss: 0.6125 - val_accuracy: 0.7500\n",
      "Epoch 15/30\n",
      "126/126 [==============================] - 5s 41ms/step - loss: 0.4162 - accuracy: 0.8585 - val_loss: 0.4357 - val_accuracy: 0.8438\n",
      "Epoch 16/30\n",
      "126/126 [==============================] - 5s 41ms/step - loss: 0.4105 - accuracy: 0.8540 - val_loss: 0.4576 - val_accuracy: 0.8750\n",
      "Epoch 17/30\n",
      "126/126 [==============================] - 5s 41ms/step - loss: 0.3958 - accuracy: 0.8591 - val_loss: 0.4950 - val_accuracy: 0.8125\n",
      "Epoch 18/30\n",
      "126/126 [==============================] - 5s 41ms/step - loss: 0.3650 - accuracy: 0.8734 - val_loss: 0.4191 - val_accuracy: 0.8438\n",
      "Epoch 19/30\n",
      "126/126 [==============================] - 5s 41ms/step - loss: 0.3508 - accuracy: 0.8711 - val_loss: 0.4955 - val_accuracy: 0.8125\n",
      "Epoch 20/30\n",
      "126/126 [==============================] - 5s 41ms/step - loss: 0.3312 - accuracy: 0.8787 - val_loss: 0.4873 - val_accuracy: 0.8438\n",
      "Epoch 21/30\n",
      "126/126 [==============================] - 5s 41ms/step - loss: 0.3252 - accuracy: 0.8807 - val_loss: 0.5315 - val_accuracy: 0.8750\n",
      "Epoch 22/30\n",
      "126/126 [==============================] - 5s 41ms/step - loss: 0.3188 - accuracy: 0.8821 - val_loss: 0.4953 - val_accuracy: 0.8750\n",
      "Epoch 23/30\n",
      "126/126 [==============================] - 5s 41ms/step - loss: 0.3121 - accuracy: 0.8906 - val_loss: 0.5258 - val_accuracy: 0.8438\n",
      "Epoch 24/30\n",
      "126/126 [==============================] - 5s 41ms/step - loss: 0.3092 - accuracy: 0.8921 - val_loss: 0.4612 - val_accuracy: 0.8125\n",
      "Epoch 25/30\n",
      "126/126 [==============================] - 5s 41ms/step - loss: 0.2796 - accuracy: 0.8965 - val_loss: 0.4517 - val_accuracy: 0.8750\n",
      "Epoch 26/30\n",
      "126/126 [==============================] - 5s 41ms/step - loss: 0.2858 - accuracy: 0.8936 - val_loss: 0.4286 - val_accuracy: 0.8750\n",
      "Epoch 27/30\n",
      "126/126 [==============================] - 5s 41ms/step - loss: 0.2767 - accuracy: 0.9028 - val_loss: 0.5299 - val_accuracy: 0.8125\n",
      "Epoch 28/30\n",
      "126/126 [==============================] - 5s 41ms/step - loss: 0.2735 - accuracy: 0.9014 - val_loss: 0.4237 - val_accuracy: 0.8750\n",
      "Epoch 29/30\n",
      "126/126 [==============================] - 5s 41ms/step - loss: 0.2679 - accuracy: 0.9037 - val_loss: 0.4665 - val_accuracy: 0.8438\n",
      "Epoch 30/30\n",
      "126/126 [==============================] - 5s 41ms/step - loss: 0.2558 - accuracy: 0.9010 - val_loss: 0.4787 - val_accuracy: 0.8438\n",
      "INFO:tensorflow:Assets written to: ../octnet/octnet_30epochs_6261_images_True_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for octnet: 0.826446\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.08956869 0.0906061  0.09067677 0.08774373]\n",
      "Training octnet for 0.09% of train size (aka 7513 images) with pretrained: False and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 23 trainable: 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  5/151 [..............................] - ETA: 13s - loss: 6.0427 - accuracy: 0.2499WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0186s vs `on_train_batch_end` time: 0.0542s). Check your callbacks.\n",
      "151/151 [==============================] - 8s 45ms/step - loss: 3.5842 - accuracy: 0.4174 - val_loss: 1.0823 - val_accuracy: 0.5938\n",
      "Epoch 2/30\n",
      "  1/151 [..............................] - ETA: 6s - loss: 1.0084 - accuracy: 0.6600"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151/151 [==============================] - 6s 41ms/step - loss: 1.5861 - accuracy: 0.6079 - val_loss: 1.2941 - val_accuracy: 0.5625\n",
      "Epoch 3/30\n",
      "151/151 [==============================] - 6s 41ms/step - loss: 1.1017 - accuracy: 0.6655 - val_loss: 1.0329 - val_accuracy: 0.6250\n",
      "Epoch 4/30\n",
      "151/151 [==============================] - 6s 40ms/step - loss: 0.8948 - accuracy: 0.7094 - val_loss: 0.7323 - val_accuracy: 0.7188\n",
      "Epoch 5/30\n",
      "151/151 [==============================] - 6s 41ms/step - loss: 0.7179 - accuracy: 0.7561 - val_loss: 0.6581 - val_accuracy: 0.7188\n",
      "Epoch 6/30\n",
      "151/151 [==============================] - 6s 41ms/step - loss: 0.6776 - accuracy: 0.7711 - val_loss: 0.4597 - val_accuracy: 0.7812\n",
      "Epoch 7/30\n",
      "151/151 [==============================] - 6s 41ms/step - loss: 0.5967 - accuracy: 0.7820 - val_loss: 0.5131 - val_accuracy: 0.8438\n",
      "Epoch 8/30\n",
      "151/151 [==============================] - 6s 41ms/step - loss: 0.5620 - accuracy: 0.8010 - val_loss: 0.4488 - val_accuracy: 0.8125\n",
      "Epoch 9/30\n",
      "151/151 [==============================] - 6s 41ms/step - loss: 0.5193 - accuracy: 0.8096 - val_loss: 0.6782 - val_accuracy: 0.6250\n",
      "Epoch 10/30\n",
      "151/151 [==============================] - 6s 41ms/step - loss: 0.5079 - accuracy: 0.8176 - val_loss: 0.4555 - val_accuracy: 0.8125\n",
      "Epoch 11/30\n",
      "151/151 [==============================] - 6s 41ms/step - loss: 0.4587 - accuracy: 0.8350 - val_loss: 0.4001 - val_accuracy: 0.8438\n",
      "Epoch 12/30\n",
      "151/151 [==============================] - 6s 41ms/step - loss: 0.4267 - accuracy: 0.8512 - val_loss: 0.3857 - val_accuracy: 0.8438\n",
      "Epoch 13/30\n",
      "151/151 [==============================] - 6s 41ms/step - loss: 0.4213 - accuracy: 0.8554 - val_loss: 0.3507 - val_accuracy: 0.8438\n",
      "Epoch 14/30\n",
      "151/151 [==============================] - 6s 41ms/step - loss: 0.3867 - accuracy: 0.8617 - val_loss: 0.3278 - val_accuracy: 0.8750\n",
      "Epoch 15/30\n",
      "151/151 [==============================] - 6s 41ms/step - loss: 0.3644 - accuracy: 0.8679 - val_loss: 0.2579 - val_accuracy: 0.9062\n",
      "Epoch 16/30\n",
      "151/151 [==============================] - 6s 41ms/step - loss: 0.3535 - accuracy: 0.8743 - val_loss: 0.4087 - val_accuracy: 0.8438\n",
      "Epoch 17/30\n",
      "151/151 [==============================] - 6s 41ms/step - loss: 0.3185 - accuracy: 0.8852 - val_loss: 0.2383 - val_accuracy: 0.9062\n",
      "Epoch 18/30\n",
      "151/151 [==============================] - 6s 41ms/step - loss: 0.3041 - accuracy: 0.8925 - val_loss: 0.3091 - val_accuracy: 0.8750\n",
      "Epoch 19/30\n",
      "151/151 [==============================] - 6s 41ms/step - loss: 0.3330 - accuracy: 0.8781 - val_loss: 0.3419 - val_accuracy: 0.8438\n",
      "Epoch 20/30\n",
      "151/151 [==============================] - 6s 41ms/step - loss: 0.2777 - accuracy: 0.8975 - val_loss: 0.2043 - val_accuracy: 0.9375\n",
      "Epoch 21/30\n",
      "151/151 [==============================] - 6s 41ms/step - loss: 0.2736 - accuracy: 0.8958 - val_loss: 0.2610 - val_accuracy: 0.9375\n",
      "Epoch 22/30\n",
      "151/151 [==============================] - 6s 41ms/step - loss: 0.2601 - accuracy: 0.9081 - val_loss: 0.3390 - val_accuracy: 0.8438\n",
      "Epoch 23/30\n",
      "151/151 [==============================] - 6s 41ms/step - loss: 0.2564 - accuracy: 0.9100 - val_loss: 0.2876 - val_accuracy: 0.8750\n",
      "Epoch 24/30\n",
      "151/151 [==============================] - 6s 41ms/step - loss: 0.2502 - accuracy: 0.9090 - val_loss: 0.2221 - val_accuracy: 0.9375\n",
      "Epoch 25/30\n",
      "151/151 [==============================] - 6s 41ms/step - loss: 0.2356 - accuracy: 0.9128 - val_loss: 0.2959 - val_accuracy: 0.8750\n",
      "Epoch 26/30\n",
      "151/151 [==============================] - 6s 41ms/step - loss: 0.2264 - accuracy: 0.9196 - val_loss: 0.2324 - val_accuracy: 0.9062\n",
      "Epoch 27/30\n",
      "151/151 [==============================] - 6s 41ms/step - loss: 0.2235 - accuracy: 0.9193 - val_loss: 0.2507 - val_accuracy: 0.9375\n",
      "Epoch 28/30\n",
      "151/151 [==============================] - 6s 41ms/step - loss: 0.2146 - accuracy: 0.9256 - val_loss: 0.2855 - val_accuracy: 0.9062\n",
      "Epoch 29/30\n",
      "151/151 [==============================] - 6s 41ms/step - loss: 0.2137 - accuracy: 0.9258 - val_loss: 0.2230 - val_accuracy: 0.9062\n",
      "Epoch 30/30\n",
      "151/151 [==============================] - 6s 41ms/step - loss: 0.2166 - accuracy: 0.9183 - val_loss: 0.2575 - val_accuracy: 0.9375\n",
      "INFO:tensorflow:Assets written to: ../octnet/octnet_30epochs_7514_images_True_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for octnet: 0.855372\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.09804294 0.10108856 0.10213253 0.09842154]\n",
      "Training octnet for 0.1% of train size (aka 8348 images) with pretrained: False and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 23 trainable: 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  5/167 [..............................] - ETA: 14s - loss: 4.0530 - accuracy: 0.3444WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0192s vs `on_train_batch_end` time: 0.0541s). Check your callbacks.\n",
      "167/167 [==============================] - 9s 47ms/step - loss: 2.6460 - accuracy: 0.4479 - val_loss: 1.1293 - val_accuracy: 0.5938\n",
      "Epoch 2/30\n",
      "  1/167 [..............................] - ETA: 6s - loss: 1.5075 - accuracy: 0.5600"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "167/167 [==============================] - 7s 41ms/step - loss: 1.2017 - accuracy: 0.6312 - val_loss: 0.7934 - val_accuracy: 0.6875\n",
      "Epoch 3/30\n",
      "167/167 [==============================] - 7s 41ms/step - loss: 0.8938 - accuracy: 0.6869 - val_loss: 0.7516 - val_accuracy: 0.6250\n",
      "Epoch 4/30\n",
      "167/167 [==============================] - 7s 41ms/step - loss: 0.7452 - accuracy: 0.7299 - val_loss: 0.7305 - val_accuracy: 0.5938\n",
      "Epoch 5/30\n",
      "167/167 [==============================] - 7s 41ms/step - loss: 0.6588 - accuracy: 0.7609 - val_loss: 0.5938 - val_accuracy: 0.7188\n",
      "Epoch 6/30\n",
      "167/167 [==============================] - 7s 41ms/step - loss: 0.5841 - accuracy: 0.7879 - val_loss: 0.7066 - val_accuracy: 0.6875\n",
      "Epoch 7/30\n",
      "167/167 [==============================] - 7s 41ms/step - loss: 0.5294 - accuracy: 0.8068 - val_loss: 0.6570 - val_accuracy: 0.7500\n",
      "Epoch 8/30\n",
      "167/167 [==============================] - 7s 41ms/step - loss: 0.5034 - accuracy: 0.8135 - val_loss: 0.4484 - val_accuracy: 0.8438\n",
      "Epoch 9/30\n",
      "167/167 [==============================] - 7s 41ms/step - loss: 0.4621 - accuracy: 0.8360 - val_loss: 0.5004 - val_accuracy: 0.8125\n",
      "Epoch 10/30\n",
      "167/167 [==============================] - 7s 41ms/step - loss: 0.4277 - accuracy: 0.8424 - val_loss: 0.4330 - val_accuracy: 0.7812\n",
      "Epoch 11/30\n",
      "167/167 [==============================] - 7s 41ms/step - loss: 0.4097 - accuracy: 0.8570 - val_loss: 0.3973 - val_accuracy: 0.8125\n",
      "Epoch 12/30\n",
      "167/167 [==============================] - 7s 41ms/step - loss: 0.3864 - accuracy: 0.8631 - val_loss: 0.3173 - val_accuracy: 0.8125\n",
      "Epoch 13/30\n",
      "167/167 [==============================] - 7s 41ms/step - loss: 0.3666 - accuracy: 0.8695 - val_loss: 0.4946 - val_accuracy: 0.7812\n",
      "Epoch 14/30\n",
      "167/167 [==============================] - 7s 41ms/step - loss: 0.3423 - accuracy: 0.8799 - val_loss: 0.3806 - val_accuracy: 0.8438\n",
      "Epoch 15/30\n",
      "167/167 [==============================] - 7s 41ms/step - loss: 0.3149 - accuracy: 0.8844 - val_loss: 0.4181 - val_accuracy: 0.8438\n",
      "Epoch 16/30\n",
      "167/167 [==============================] - 7s 41ms/step - loss: 0.3009 - accuracy: 0.8947 - val_loss: 0.3986 - val_accuracy: 0.7812\n",
      "Epoch 17/30\n",
      "167/167 [==============================] - 7s 42ms/step - loss: 0.2836 - accuracy: 0.8988 - val_loss: 0.3567 - val_accuracy: 0.8438\n",
      "Epoch 18/30\n",
      "167/167 [==============================] - 7s 42ms/step - loss: 0.2555 - accuracy: 0.9072 - val_loss: 0.3322 - val_accuracy: 0.8125\n",
      "Epoch 19/30\n",
      "167/167 [==============================] - 7s 41ms/step - loss: 0.2585 - accuracy: 0.9094 - val_loss: 0.2812 - val_accuracy: 0.8750\n",
      "Epoch 20/30\n",
      "167/167 [==============================] - 7s 41ms/step - loss: 0.2388 - accuracy: 0.9139 - val_loss: 0.3037 - val_accuracy: 0.8438\n",
      "Epoch 21/30\n",
      "167/167 [==============================] - 7s 42ms/step - loss: 0.2314 - accuracy: 0.9174 - val_loss: 0.2684 - val_accuracy: 0.8750\n",
      "Epoch 22/30\n",
      "167/167 [==============================] - 7s 41ms/step - loss: 0.2262 - accuracy: 0.9231 - val_loss: 0.3044 - val_accuracy: 0.8750\n",
      "Epoch 23/30\n",
      "167/167 [==============================] - 7s 41ms/step - loss: 0.2109 - accuracy: 0.9263 - val_loss: 0.3161 - val_accuracy: 0.8750\n",
      "Epoch 24/30\n",
      "167/167 [==============================] - 7s 41ms/step - loss: 0.1910 - accuracy: 0.9332 - val_loss: 0.2718 - val_accuracy: 0.8750\n",
      "Epoch 25/30\n",
      "167/167 [==============================] - 7s 41ms/step - loss: 0.1967 - accuracy: 0.9339 - val_loss: 0.3820 - val_accuracy: 0.8438\n",
      "Epoch 26/30\n",
      "167/167 [==============================] - 7s 41ms/step - loss: 0.2002 - accuracy: 0.9337 - val_loss: 0.2591 - val_accuracy: 0.8750\n",
      "Epoch 27/30\n",
      "167/167 [==============================] - 7s 41ms/step - loss: 0.1896 - accuracy: 0.9348 - val_loss: 0.2253 - val_accuracy: 0.8750\n",
      "Epoch 28/30\n",
      "167/167 [==============================] - 7s 42ms/step - loss: 0.1720 - accuracy: 0.9410 - val_loss: 0.2800 - val_accuracy: 0.9062\n",
      "Epoch 29/30\n",
      "167/167 [==============================] - 7s 41ms/step - loss: 0.1583 - accuracy: 0.9448 - val_loss: 0.2829 - val_accuracy: 0.8438\n",
      "Epoch 30/30\n",
      "167/167 [==============================] - 7s 41ms/step - loss: 0.1583 - accuracy: 0.9479 - val_loss: 0.2847 - val_accuracy: 0.9062\n",
      "INFO:tensorflow:Assets written to: ../octnet/octnet_30epochs_8348_images_True_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for octnet: 0.896694\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.25061752 0.25077275 0.247092   0.24860724]\n",
      "Training octnet for 0.25% of train size (aka 20871 images) with pretrained: False and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 23 trainable: 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  5/418 [..............................] - ETA: 38s - loss: 4.8092 - accuracy: 0.3170WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0182s vs `on_train_batch_end` time: 0.0560s). Check your callbacks.\n",
      "418/418 [==============================] - 19s 42ms/step - loss: 2.4496 - accuracy: 0.4819 - val_loss: 1.0116 - val_accuracy: 0.5000\n",
      "Epoch 2/30\n",
      "  1/418 [..............................] - ETA: 17s - loss: 0.7745 - accuracy: 0.7200"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "418/418 [==============================] - 17s 41ms/step - loss: 0.8643 - accuracy: 0.7091 - val_loss: 0.8392 - val_accuracy: 0.6562\n",
      "Epoch 3/30\n",
      "418/418 [==============================] - 17s 41ms/step - loss: 0.6393 - accuracy: 0.7786 - val_loss: 1.1401 - val_accuracy: 0.6562\n",
      "Epoch 4/30\n",
      "418/418 [==============================] - 17s 41ms/step - loss: 0.5406 - accuracy: 0.8086 - val_loss: 0.5991 - val_accuracy: 0.7812\n",
      "Epoch 5/30\n",
      "418/418 [==============================] - 17s 41ms/step - loss: 0.4947 - accuracy: 0.8289 - val_loss: 0.7605 - val_accuracy: 0.7500\n",
      "Epoch 6/30\n",
      "418/418 [==============================] - 17s 41ms/step - loss: 0.4537 - accuracy: 0.8410 - val_loss: 0.4545 - val_accuracy: 0.7812\n",
      "Epoch 7/30\n",
      "418/418 [==============================] - 17s 41ms/step - loss: 0.4030 - accuracy: 0.8575 - val_loss: 0.4675 - val_accuracy: 0.7812\n",
      "Epoch 8/30\n",
      "418/418 [==============================] - 17s 41ms/step - loss: 0.3657 - accuracy: 0.8747 - val_loss: 0.4279 - val_accuracy: 0.8750\n",
      "Epoch 9/30\n",
      "418/418 [==============================] - 17s 41ms/step - loss: 0.3332 - accuracy: 0.8839 - val_loss: 0.4197 - val_accuracy: 0.8750\n",
      "Epoch 10/30\n",
      "418/418 [==============================] - 17s 41ms/step - loss: 0.2899 - accuracy: 0.8989 - val_loss: 0.2180 - val_accuracy: 0.9375\n",
      "Epoch 11/30\n",
      "418/418 [==============================] - 17s 41ms/step - loss: 0.2751 - accuracy: 0.9022 - val_loss: 0.2886 - val_accuracy: 0.9375\n",
      "Epoch 12/30\n",
      "418/418 [==============================] - 17s 41ms/step - loss: 0.2604 - accuracy: 0.9112 - val_loss: 0.3845 - val_accuracy: 0.9375\n",
      "Epoch 13/30\n",
      "418/418 [==============================] - 17s 41ms/step - loss: 0.2259 - accuracy: 0.9239 - val_loss: 0.2728 - val_accuracy: 0.9062\n",
      "Epoch 14/30\n",
      "418/418 [==============================] - 17s 41ms/step - loss: 0.2080 - accuracy: 0.9291 - val_loss: 0.3191 - val_accuracy: 0.9062\n",
      "Epoch 15/30\n",
      "418/418 [==============================] - 17s 41ms/step - loss: 0.1837 - accuracy: 0.9379 - val_loss: 0.3399 - val_accuracy: 0.9062\n",
      "Epoch 16/30\n",
      "418/418 [==============================] - 17s 41ms/step - loss: 0.1703 - accuracy: 0.9396 - val_loss: 0.3948 - val_accuracy: 0.9062\n",
      "Epoch 17/30\n",
      "418/418 [==============================] - 17s 41ms/step - loss: 0.1590 - accuracy: 0.9452 - val_loss: 0.3038 - val_accuracy: 0.9062\n",
      "Epoch 18/30\n",
      "418/418 [==============================] - 17s 41ms/step - loss: 0.1460 - accuracy: 0.9501 - val_loss: 0.3403 - val_accuracy: 0.9062\n",
      "Epoch 19/30\n",
      "418/418 [==============================] - 17s 41ms/step - loss: 0.1379 - accuracy: 0.9500 - val_loss: 0.4913 - val_accuracy: 0.9062\n",
      "Epoch 20/30\n",
      "418/418 [==============================] - 17s 41ms/step - loss: 0.1302 - accuracy: 0.9537 - val_loss: 0.3622 - val_accuracy: 0.9062\n",
      "Epoch 21/30\n",
      "418/418 [==============================] - 17s 41ms/step - loss: 0.1142 - accuracy: 0.9609 - val_loss: 0.3664 - val_accuracy: 0.9062\n",
      "Epoch 22/30\n",
      "418/418 [==============================] - 17s 41ms/step - loss: 0.1030 - accuracy: 0.9648 - val_loss: 0.3896 - val_accuracy: 0.9062\n",
      "Epoch 23/30\n",
      "418/418 [==============================] - 17s 41ms/step - loss: 0.1001 - accuracy: 0.9647 - val_loss: 0.4499 - val_accuracy: 0.9062\n",
      "Epoch 24/30\n",
      "418/418 [==============================] - 17s 41ms/step - loss: 0.0972 - accuracy: 0.9676 - val_loss: 0.4277 - val_accuracy: 0.9062\n",
      "Epoch 25/30\n",
      "418/418 [==============================] - 17s 41ms/step - loss: 0.0912 - accuracy: 0.9693 - val_loss: 0.4284 - val_accuracy: 0.9062\n",
      "Epoch 26/30\n",
      "418/418 [==============================] - 17s 41ms/step - loss: 0.0846 - accuracy: 0.9702 - val_loss: 0.5686 - val_accuracy: 0.9062\n",
      "Epoch 27/30\n",
      "418/418 [==============================] - 17s 41ms/step - loss: 0.0809 - accuracy: 0.9740 - val_loss: 0.4941 - val_accuracy: 0.9062\n",
      "Epoch 28/30\n",
      "418/418 [==============================] - 17s 41ms/step - loss: 0.0845 - accuracy: 0.9706 - val_loss: 0.5492 - val_accuracy: 0.9062\n",
      "Epoch 29/30\n",
      "418/418 [==============================] - 17s 41ms/step - loss: 0.0773 - accuracy: 0.9742 - val_loss: 0.3713 - val_accuracy: 0.9062\n",
      "Epoch 30/30\n",
      "418/418 [==============================] - 17s 41ms/step - loss: 0.0816 - accuracy: 0.9717 - val_loss: 0.4885 - val_accuracy: 0.9062\n",
      "INFO:tensorflow:Assets written to: ../octnet/octnet_30epochs_20871_images_True_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for octnet: 0.938017\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.39931598 0.39956995 0.40236165 0.40076602]\n",
      "Training octnet for 0.4% of train size (aka 33393 images) with pretrained: False and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 23 trainable: 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  5/668 [..............................] - ETA: 1:01 - loss: 4.9668 - accuracy: 0.2895WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0193s vs `on_train_batch_end` time: 0.0552s). Check your callbacks.\n",
      "668/668 [==============================] - 29s 42ms/step - loss: 1.9609 - accuracy: 0.5601 - val_loss: 1.1816 - val_accuracy: 0.5625\n",
      "Epoch 2/30\n",
      "  1/668 [..............................] - ETA: 27s - loss: 0.7065 - accuracy: 0.7800"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "668/668 [==============================] - 27s 41ms/step - loss: 0.6443 - accuracy: 0.7732 - val_loss: 0.5444 - val_accuracy: 0.7500\n",
      "Epoch 3/30\n",
      "668/668 [==============================] - 27s 41ms/step - loss: 0.5021 - accuracy: 0.8211 - val_loss: 0.3508 - val_accuracy: 0.8125\n",
      "Epoch 4/30\n",
      "668/668 [==============================] - 27s 41ms/step - loss: 0.4167 - accuracy: 0.8544 - val_loss: 0.3097 - val_accuracy: 0.8750\n",
      "Epoch 5/30\n",
      "668/668 [==============================] - 27s 41ms/step - loss: 0.3503 - accuracy: 0.8789 - val_loss: 0.3592 - val_accuracy: 0.9062\n",
      "Epoch 6/30\n",
      "668/668 [==============================] - 27s 41ms/step - loss: 0.3071 - accuracy: 0.8948 - val_loss: 0.1954 - val_accuracy: 0.9062\n",
      "Epoch 7/30\n",
      "668/668 [==============================] - 27s 41ms/step - loss: 0.2801 - accuracy: 0.9038 - val_loss: 0.0556 - val_accuracy: 1.0000\n",
      "Epoch 8/30\n",
      "668/668 [==============================] - 27s 41ms/step - loss: 0.2510 - accuracy: 0.9158 - val_loss: 0.1267 - val_accuracy: 0.9688\n",
      "Epoch 9/30\n",
      "668/668 [==============================] - 27s 41ms/step - loss: 0.2198 - accuracy: 0.9261 - val_loss: 0.0848 - val_accuracy: 0.9688\n",
      "Epoch 10/30\n",
      "668/668 [==============================] - 27s 41ms/step - loss: 0.1899 - accuracy: 0.9355 - val_loss: 0.2812 - val_accuracy: 0.8438\n",
      "Epoch 11/30\n",
      "668/668 [==============================] - 27s 41ms/step - loss: 0.1877 - accuracy: 0.9380 - val_loss: 0.1558 - val_accuracy: 0.9375\n",
      "Epoch 12/30\n",
      "668/668 [==============================] - 28s 41ms/step - loss: 0.1577 - accuracy: 0.9476 - val_loss: 0.0185 - val_accuracy: 1.0000\n",
      "Epoch 13/30\n",
      "668/668 [==============================] - 27s 41ms/step - loss: 0.1444 - accuracy: 0.9522 - val_loss: 0.1121 - val_accuracy: 0.9688\n",
      "Epoch 14/30\n",
      "668/668 [==============================] - 27s 41ms/step - loss: 0.1245 - accuracy: 0.9574 - val_loss: 0.0957 - val_accuracy: 0.9375\n",
      "Epoch 15/30\n",
      "668/668 [==============================] - 27s 41ms/step - loss: 0.1202 - accuracy: 0.9607 - val_loss: 0.0676 - val_accuracy: 0.9688\n",
      "Epoch 16/30\n",
      "668/668 [==============================] - 27s 41ms/step - loss: 0.1068 - accuracy: 0.9645 - val_loss: 0.0569 - val_accuracy: 0.9688\n",
      "Epoch 17/30\n",
      "668/668 [==============================] - 27s 41ms/step - loss: 0.0979 - accuracy: 0.9674 - val_loss: 0.0333 - val_accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "668/668 [==============================] - 27s 41ms/step - loss: 0.0845 - accuracy: 0.9711 - val_loss: 0.1525 - val_accuracy: 0.9688\n",
      "Epoch 19/30\n",
      "668/668 [==============================] - 27s 41ms/step - loss: 0.0801 - accuracy: 0.9706 - val_loss: 0.1023 - val_accuracy: 0.9688\n",
      "Epoch 20/30\n",
      "668/668 [==============================] - 27s 41ms/step - loss: 0.0723 - accuracy: 0.9756 - val_loss: 0.0321 - val_accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "668/668 [==============================] - 27s 41ms/step - loss: 0.0672 - accuracy: 0.9771 - val_loss: 0.1010 - val_accuracy: 0.9688\n",
      "Epoch 22/30\n",
      "668/668 [==============================] - 27s 41ms/step - loss: 0.0581 - accuracy: 0.9801 - val_loss: 0.0560 - val_accuracy: 0.9688\n",
      "Epoch 23/30\n",
      "668/668 [==============================] - 27s 41ms/step - loss: 0.0524 - accuracy: 0.9828 - val_loss: 0.0271 - val_accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "668/668 [==============================] - 27s 41ms/step - loss: 0.0559 - accuracy: 0.9808 - val_loss: 0.0453 - val_accuracy: 0.9688\n",
      "Epoch 25/30\n",
      "668/668 [==============================] - 27s 41ms/step - loss: 0.0486 - accuracy: 0.9841 - val_loss: 0.0632 - val_accuracy: 0.9688\n",
      "Epoch 26/30\n",
      "668/668 [==============================] - 27s 41ms/step - loss: 0.0513 - accuracy: 0.9827 - val_loss: 0.0497 - val_accuracy: 0.9688\n",
      "Epoch 27/30\n",
      "668/668 [==============================] - 27s 41ms/step - loss: 0.0435 - accuracy: 0.9853 - val_loss: 0.0203 - val_accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "668/668 [==============================] - 27s 41ms/step - loss: 0.0397 - accuracy: 0.9865 - val_loss: 0.0198 - val_accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "668/668 [==============================] - 27s 41ms/step - loss: 0.0397 - accuracy: 0.9870 - val_loss: 0.0141 - val_accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "668/668 [==============================] - 28s 41ms/step - loss: 0.0386 - accuracy: 0.9868 - val_loss: 0.0213 - val_accuracy: 1.0000\n",
      "INFO:tensorflow:Assets written to: ../octnet/octnet_30epochs_33394_images_True_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for octnet: 0.966942\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.50279308 0.49955651 0.50035249 0.49292015]\n",
      "Training octnet for 0.5% of train size (aka 41742 images) with pretrained: False and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 23 trainable: 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  5/835 [..............................] - ETA: 1:17 - loss: 5.4101 - accuracy: 0.3649WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0187s vs `on_train_batch_end` time: 0.0567s). Check your callbacks.\n",
      "835/835 [==============================] - 36s 42ms/step - loss: 1.9809 - accuracy: 0.5762 - val_loss: 0.6174 - val_accuracy: 0.7500\n",
      "Epoch 2/30\n",
      "  1/835 [..............................] - ETA: 34s - loss: 0.7156 - accuracy: 0.7600"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "835/835 [==============================] - 34s 41ms/step - loss: 0.6185 - accuracy: 0.7813 - val_loss: 0.5487 - val_accuracy: 0.7812\n",
      "Epoch 3/30\n",
      "835/835 [==============================] - 34s 41ms/step - loss: 0.4761 - accuracy: 0.8321 - val_loss: 0.6625 - val_accuracy: 0.6875\n",
      "Epoch 4/30\n",
      "835/835 [==============================] - 34s 41ms/step - loss: 0.4000 - accuracy: 0.8586 - val_loss: 0.1995 - val_accuracy: 0.9062\n",
      "Epoch 5/30\n",
      "835/835 [==============================] - 34s 41ms/step - loss: 0.3493 - accuracy: 0.8803 - val_loss: 0.1264 - val_accuracy: 0.9688\n",
      "Epoch 6/30\n",
      "835/835 [==============================] - 34s 41ms/step - loss: 0.3066 - accuracy: 0.8950 - val_loss: 0.3340 - val_accuracy: 0.8750\n",
      "Epoch 7/30\n",
      "835/835 [==============================] - 34s 41ms/step - loss: 0.2627 - accuracy: 0.9111 - val_loss: 0.1055 - val_accuracy: 0.9688\n",
      "Epoch 8/30\n",
      "835/835 [==============================] - 34s 41ms/step - loss: 0.2366 - accuracy: 0.9190 - val_loss: 0.0576 - val_accuracy: 1.0000\n",
      "Epoch 9/30\n",
      "835/835 [==============================] - 34s 41ms/step - loss: 0.2107 - accuracy: 0.9295 - val_loss: 0.0214 - val_accuracy: 1.0000\n",
      "Epoch 10/30\n",
      "835/835 [==============================] - 34s 41ms/step - loss: 0.1942 - accuracy: 0.9339 - val_loss: 0.0160 - val_accuracy: 1.0000\n",
      "Epoch 11/30\n",
      "835/835 [==============================] - 34s 41ms/step - loss: 0.1732 - accuracy: 0.9404 - val_loss: 0.0205 - val_accuracy: 1.0000\n",
      "Epoch 12/30\n",
      "835/835 [==============================] - 34s 41ms/step - loss: 0.1489 - accuracy: 0.9497 - val_loss: 0.0225 - val_accuracy: 1.0000\n",
      "Epoch 13/30\n",
      "835/835 [==============================] - 34s 41ms/step - loss: 0.1367 - accuracy: 0.9529 - val_loss: 0.0148 - val_accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "835/835 [==============================] - 34s 41ms/step - loss: 0.1229 - accuracy: 0.9587 - val_loss: 0.0142 - val_accuracy: 1.0000\n",
      "Epoch 15/30\n",
      "835/835 [==============================] - 35s 41ms/step - loss: 0.1136 - accuracy: 0.9615 - val_loss: 0.0054 - val_accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "835/835 [==============================] - 34s 41ms/step - loss: 0.0995 - accuracy: 0.9669 - val_loss: 0.0166 - val_accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "835/835 [==============================] - 34s 41ms/step - loss: 0.0890 - accuracy: 0.9699 - val_loss: 0.0056 - val_accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "835/835 [==============================] - 34s 41ms/step - loss: 0.0833 - accuracy: 0.9710 - val_loss: 0.0057 - val_accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "835/835 [==============================] - 34s 41ms/step - loss: 0.0778 - accuracy: 0.9731 - val_loss: 0.0085 - val_accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "835/835 [==============================] - 36s 44ms/step - loss: 0.0679 - accuracy: 0.9764 - val_loss: 0.0035 - val_accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "835/835 [==============================] - 34s 41ms/step - loss: 0.0633 - accuracy: 0.9790 - val_loss: 0.0112 - val_accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "835/835 [==============================] - 34s 41ms/step - loss: 0.0607 - accuracy: 0.9783 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "835/835 [==============================] - 36s 43ms/step - loss: 0.0540 - accuracy: 0.9809 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "835/835 [==============================] - 34s 41ms/step - loss: 0.0545 - accuracy: 0.9815 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "835/835 [==============================] - 34s 41ms/step - loss: 0.0499 - accuracy: 0.9827 - val_loss: 0.0063 - val_accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "835/835 [==============================] - 34s 41ms/step - loss: 0.0451 - accuracy: 0.9852 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "835/835 [==============================] - 34s 41ms/step - loss: 0.0405 - accuracy: 0.9866 - val_loss: 0.0057 - val_accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "835/835 [==============================] - 34s 41ms/step - loss: 0.0426 - accuracy: 0.9854 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "835/835 [==============================] - 34s 41ms/step - loss: 0.0397 - accuracy: 0.9866 - val_loss: 0.0666 - val_accuracy: 0.9688\n",
      "Epoch 30/30\n",
      "835/835 [==============================] - 34s 41ms/step - loss: 0.0373 - accuracy: 0.9877 - val_loss: 0.0089 - val_accuracy: 1.0000\n",
      "INFO:tensorflow:Assets written to: ../octnet/octnet_30epochs_41742_images_True_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for octnet: 0.970041\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.60167205 0.60102137 0.59878393 0.59203807]\n",
      "Training octnet for 0.6% of train size (aka 50090 images) with pretrained: False and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 23 trainable: 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "   5/1002 [..............................] - ETA: 1:32 - loss: 4.4063 - accuracy: 0.2995WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0188s vs `on_train_batch_end` time: 0.0559s). Check your callbacks.\n",
      "1002/1002 [==============================] - 43s 42ms/step - loss: 1.9098 - accuracy: 0.5654 - val_loss: 0.5660 - val_accuracy: 0.7188\n",
      "Epoch 2/30\n",
      "   1/1002 [..............................] - ETA: 41s - loss: 0.6086 - accuracy: 0.8000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1002/1002 [==============================] - 41s 41ms/step - loss: 0.5692 - accuracy: 0.8013 - val_loss: 0.3525 - val_accuracy: 0.8750\n",
      "Epoch 3/30\n",
      "1002/1002 [==============================] - 41s 41ms/step - loss: 0.4113 - accuracy: 0.8599 - val_loss: 0.0993 - val_accuracy: 1.0000\n",
      "Epoch 4/30\n",
      "1002/1002 [==============================] - 41s 41ms/step - loss: 0.3430 - accuracy: 0.8823 - val_loss: 0.1083 - val_accuracy: 0.9688\n",
      "Epoch 5/30\n",
      "1002/1002 [==============================] - 41s 41ms/step - loss: 0.2976 - accuracy: 0.9003 - val_loss: 0.0613 - val_accuracy: 1.0000\n",
      "Epoch 6/30\n",
      "1002/1002 [==============================] - 41s 41ms/step - loss: 0.2670 - accuracy: 0.9115 - val_loss: 0.0235 - val_accuracy: 1.0000\n",
      "Epoch 7/30\n",
      "1002/1002 [==============================] - 41s 41ms/step - loss: 0.2489 - accuracy: 0.9164 - val_loss: 0.0280 - val_accuracy: 1.0000\n",
      "Epoch 8/30\n",
      "1002/1002 [==============================] - 41s 41ms/step - loss: 0.2173 - accuracy: 0.9291 - val_loss: 0.0382 - val_accuracy: 1.0000\n",
      "Epoch 9/30\n",
      "1002/1002 [==============================] - 41s 41ms/step - loss: 0.1935 - accuracy: 0.9351 - val_loss: 0.0318 - val_accuracy: 1.0000\n",
      "Epoch 10/30\n",
      "1002/1002 [==============================] - 42s 41ms/step - loss: 0.1730 - accuracy: 0.9439 - val_loss: 0.0201 - val_accuracy: 1.0000\n",
      "Epoch 11/30\n",
      "1002/1002 [==============================] - 41s 41ms/step - loss: 0.1659 - accuracy: 0.9447 - val_loss: 0.0352 - val_accuracy: 0.9688\n",
      "Epoch 12/30\n",
      "1002/1002 [==============================] - 41s 41ms/step - loss: 0.1516 - accuracy: 0.9479 - val_loss: 0.0248 - val_accuracy: 1.0000\n",
      "Epoch 13/30\n",
      "1002/1002 [==============================] - 41s 41ms/step - loss: 0.1281 - accuracy: 0.9560 - val_loss: 0.0142 - val_accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "1002/1002 [==============================] - 41s 41ms/step - loss: 0.1220 - accuracy: 0.9592 - val_loss: 0.0036 - val_accuracy: 1.0000\n",
      "Epoch 15/30\n",
      "1002/1002 [==============================] - 41s 41ms/step - loss: 0.1090 - accuracy: 0.9639 - val_loss: 0.0161 - val_accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "1002/1002 [==============================] - 42s 41ms/step - loss: 0.1005 - accuracy: 0.9665 - val_loss: 0.0117 - val_accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "1002/1002 [==============================] - 41s 41ms/step - loss: 0.0872 - accuracy: 0.9718 - val_loss: 0.0076 - val_accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "1002/1002 [==============================] - 42s 41ms/step - loss: 0.0830 - accuracy: 0.9721 - val_loss: 0.0077 - val_accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "1002/1002 [==============================] - 42s 41ms/step - loss: 0.0741 - accuracy: 0.9752 - val_loss: 0.0078 - val_accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "1002/1002 [==============================] - 42s 41ms/step - loss: 0.0695 - accuracy: 0.9767 - val_loss: 0.0178 - val_accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "1002/1002 [==============================] - 42s 41ms/step - loss: 0.0625 - accuracy: 0.9782 - val_loss: 0.0095 - val_accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "1002/1002 [==============================] - 42s 42ms/step - loss: 0.0578 - accuracy: 0.9811 - val_loss: 0.0102 - val_accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "1002/1002 [==============================] - 42s 41ms/step - loss: 0.0569 - accuracy: 0.9808 - val_loss: 0.0204 - val_accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "1002/1002 [==============================] - 42s 42ms/step - loss: 0.0515 - accuracy: 0.9827 - val_loss: 0.0079 - val_accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "1002/1002 [==============================] - 42s 41ms/step - loss: 0.0476 - accuracy: 0.9829 - val_loss: 0.0090 - val_accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "1002/1002 [==============================] - 42s 42ms/step - loss: 0.0495 - accuracy: 0.9835 - val_loss: 0.0094 - val_accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "1002/1002 [==============================] - 42s 41ms/step - loss: 0.0461 - accuracy: 0.9837 - val_loss: 0.0123 - val_accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "1002/1002 [==============================] - 42s 42ms/step - loss: 0.0401 - accuracy: 0.9863 - val_loss: 0.0199 - val_accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "1002/1002 [==============================] - 42s 42ms/step - loss: 0.0448 - accuracy: 0.9854 - val_loss: 0.0191 - val_accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "1002/1002 [==============================] - 41s 41ms/step - loss: 0.0410 - accuracy: 0.9854 - val_loss: 0.0190 - val_accuracy: 1.0000\n",
      "INFO:tensorflow:Assets written to: ../octnet/octnet_30epochs_50090_images_True_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for octnet: 0.982438\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.75265058 0.74871657 0.74929503 0.74837512]\n",
      "Training octnet for 0.75% of train size (aka 62613 images) with pretrained: False and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 23 trainable: 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "   5/1253 [..............................] - ETA: 1:55 - loss: 4.6303 - accuracy: 0.3261WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0186s vs `on_train_batch_end` time: 0.0563s). Check your callbacks.\n",
      "1253/1253 [==============================] - 53s 41ms/step - loss: 1.6340 - accuracy: 0.5936 - val_loss: 0.7983 - val_accuracy: 0.6875\n",
      "Epoch 2/30\n",
      "   1/1253 [..............................] - ETA: 51s - loss: 0.6734 - accuracy: 0.7600"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1253/1253 [==============================] - 52s 42ms/step - loss: 0.5262 - accuracy: 0.8153 - val_loss: 0.3286 - val_accuracy: 0.8125\n",
      "Epoch 3/30\n",
      "1253/1253 [==============================] - 52s 42ms/step - loss: 0.3877 - accuracy: 0.8660 - val_loss: 0.1574 - val_accuracy: 0.9688\n",
      "Epoch 4/30\n",
      "1253/1253 [==============================] - 52s 42ms/step - loss: 0.3095 - accuracy: 0.8950 - val_loss: 0.1350 - val_accuracy: 0.9062\n",
      "Epoch 5/30\n",
      "1253/1253 [==============================] - 52s 42ms/step - loss: 0.2698 - accuracy: 0.9109 - val_loss: 0.1265 - val_accuracy: 0.9062\n",
      "Epoch 6/30\n",
      "1253/1253 [==============================] - 52s 42ms/step - loss: 0.2372 - accuracy: 0.9209 - val_loss: 0.0671 - val_accuracy: 0.9688\n",
      "Epoch 7/30\n",
      "1253/1253 [==============================] - 52s 42ms/step - loss: 0.2044 - accuracy: 0.9325 - val_loss: 0.0563 - val_accuracy: 1.0000\n",
      "Epoch 8/30\n",
      "1253/1253 [==============================] - 52s 42ms/step - loss: 0.1794 - accuracy: 0.9415 - val_loss: 0.2287 - val_accuracy: 0.9062\n",
      "Epoch 9/30\n",
      "1253/1253 [==============================] - 52s 42ms/step - loss: 0.1628 - accuracy: 0.9467 - val_loss: 0.1389 - val_accuracy: 0.9688\n",
      "Epoch 10/30\n",
      "1253/1253 [==============================] - 52s 41ms/step - loss: 0.1445 - accuracy: 0.9520 - val_loss: 0.0585 - val_accuracy: 0.9688\n",
      "Epoch 11/30\n",
      "1253/1253 [==============================] - 52s 41ms/step - loss: 0.1307 - accuracy: 0.9561 - val_loss: 0.0317 - val_accuracy: 0.9688\n",
      "Epoch 12/30\n",
      "1253/1253 [==============================] - 52s 42ms/step - loss: 0.1079 - accuracy: 0.9636 - val_loss: 0.1929 - val_accuracy: 0.9688\n",
      "Epoch 13/30\n",
      "1253/1253 [==============================] - 52s 41ms/step - loss: 0.1002 - accuracy: 0.9669 - val_loss: 0.1203 - val_accuracy: 0.9688\n",
      "Epoch 14/30\n",
      "1253/1253 [==============================] - 52s 42ms/step - loss: 0.0850 - accuracy: 0.9718 - val_loss: 0.2920 - val_accuracy: 0.9688\n",
      "Epoch 15/30\n",
      "1253/1253 [==============================] - 52s 41ms/step - loss: 0.0787 - accuracy: 0.9729 - val_loss: 0.2014 - val_accuracy: 0.9688\n",
      "Epoch 16/30\n",
      "1253/1253 [==============================] - 52s 41ms/step - loss: 0.0719 - accuracy: 0.9760 - val_loss: 0.2941 - val_accuracy: 0.9688\n",
      "Epoch 17/30\n",
      "1253/1253 [==============================] - 52s 41ms/step - loss: 0.0629 - accuracy: 0.9799 - val_loss: 0.3119 - val_accuracy: 0.9688\n",
      "Epoch 18/30\n",
      "1253/1253 [==============================] - 52s 41ms/step - loss: 0.0545 - accuracy: 0.9831 - val_loss: 0.2220 - val_accuracy: 0.9688\n",
      "Epoch 19/30\n",
      "1253/1253 [==============================] - 52s 41ms/step - loss: 0.0533 - accuracy: 0.9825 - val_loss: 0.3021 - val_accuracy: 0.9375\n",
      "Epoch 20/30\n",
      "1253/1253 [==============================] - 52s 41ms/step - loss: 0.0477 - accuracy: 0.9836 - val_loss: 0.3282 - val_accuracy: 0.9688\n",
      "Epoch 21/30\n",
      "1253/1253 [==============================] - 52s 41ms/step - loss: 0.0424 - accuracy: 0.9857 - val_loss: 0.2729 - val_accuracy: 0.9688\n",
      "Epoch 22/30\n",
      "1253/1253 [==============================] - 52s 42ms/step - loss: 0.0382 - accuracy: 0.9874 - val_loss: 0.3912 - val_accuracy: 0.9688\n",
      "Epoch 23/30\n",
      "1253/1253 [==============================] - 52s 42ms/step - loss: 0.0352 - accuracy: 0.9883 - val_loss: 0.3870 - val_accuracy: 0.9688\n",
      "Epoch 24/30\n",
      "1253/1253 [==============================] - 52s 42ms/step - loss: 0.0319 - accuracy: 0.9894 - val_loss: 0.3795 - val_accuracy: 0.9688\n",
      "Epoch 25/30\n",
      "1253/1253 [==============================] - 52s 41ms/step - loss: 0.0325 - accuracy: 0.9892 - val_loss: 0.3458 - val_accuracy: 0.9688\n",
      "Epoch 26/30\n",
      "1253/1253 [==============================] - 52s 41ms/step - loss: 0.0297 - accuracy: 0.9899 - val_loss: 0.3432 - val_accuracy: 0.9688\n",
      "Epoch 27/30\n",
      "1253/1253 [==============================] - 52s 42ms/step - loss: 0.0314 - accuracy: 0.9894 - val_loss: 0.2866 - val_accuracy: 0.9375\n",
      "Epoch 28/30\n",
      "1253/1253 [==============================] - 52s 42ms/step - loss: 0.0243 - accuracy: 0.9920 - val_loss: 0.3465 - val_accuracy: 0.9688\n",
      "Epoch 29/30\n",
      "1253/1253 [==============================] - 52s 42ms/step - loss: 0.0293 - accuracy: 0.9906 - val_loss: 0.3768 - val_accuracy: 0.9688\n",
      "Epoch 30/30\n",
      "1253/1253 [==============================] - 52s 42ms/step - loss: 0.0279 - accuracy: 0.9908 - val_loss: 0.4353 - val_accuracy: 0.9688\n",
      "INFO:tensorflow:Assets written to: ../octnet/octnet_30epochs_62613_images_True_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for octnet: 0.980372\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.89895497 0.90022846 0.90306662 0.89809656]\n",
      "Training octnet for 0.9% of train size (aka 75135 images) with pretrained: False and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 23 trainable: 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "   5/1503 [..............................] - ETA: 2:18 - loss: 4.9993 - accuracy: 0.3115WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0184s vs `on_train_batch_end` time: 0.0561s). Check your callbacks.\n",
      "1503/1503 [==============================] - 64s 42ms/step - loss: 1.5483 - accuracy: 0.6207 - val_loss: 0.5938 - val_accuracy: 0.7500\n",
      "Epoch 2/30\n",
      "   1/1503 [..............................] - ETA: 1:01 - loss: 0.4636 - accuracy: 0.7800"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1503/1503 [==============================] - 62s 42ms/step - loss: 0.4922 - accuracy: 0.8252 - val_loss: 0.2289 - val_accuracy: 0.8438\n",
      "Epoch 3/30\n",
      "1503/1503 [==============================] - 63s 42ms/step - loss: 0.3699 - accuracy: 0.8739 - val_loss: 0.2278 - val_accuracy: 0.9375\n",
      "Epoch 4/30\n",
      "1503/1503 [==============================] - 63s 42ms/step - loss: 0.3036 - accuracy: 0.8979 - val_loss: 0.1583 - val_accuracy: 0.9062\n",
      "Epoch 5/30\n",
      "1503/1503 [==============================] - 63s 42ms/step - loss: 0.2504 - accuracy: 0.9162 - val_loss: 0.1558 - val_accuracy: 0.9688\n",
      "Epoch 6/30\n",
      "1503/1503 [==============================] - 63s 42ms/step - loss: 0.2263 - accuracy: 0.9252 - val_loss: 0.0545 - val_accuracy: 1.0000\n",
      "Epoch 7/30\n",
      "1503/1503 [==============================] - 63s 42ms/step - loss: 0.1957 - accuracy: 0.9354 - val_loss: 0.1486 - val_accuracy: 0.9375\n",
      "Epoch 8/30\n",
      "1503/1503 [==============================] - 63s 42ms/step - loss: 0.1764 - accuracy: 0.9417 - val_loss: 0.1308 - val_accuracy: 0.9688\n",
      "Epoch 9/30\n",
      "1503/1503 [==============================] - 63s 42ms/step - loss: 0.1537 - accuracy: 0.9492 - val_loss: 0.1110 - val_accuracy: 0.9688\n",
      "Epoch 10/30\n",
      "1503/1503 [==============================] - 62s 42ms/step - loss: 0.1352 - accuracy: 0.9551 - val_loss: 0.3220 - val_accuracy: 0.8750\n",
      "Epoch 11/30\n",
      "1503/1503 [==============================] - 63s 42ms/step - loss: 0.1216 - accuracy: 0.9596 - val_loss: 0.1505 - val_accuracy: 0.9375\n",
      "Epoch 12/30\n",
      "1503/1503 [==============================] - 63s 42ms/step - loss: 0.1073 - accuracy: 0.9632 - val_loss: 0.2064 - val_accuracy: 0.9688\n",
      "Epoch 13/30\n",
      "1503/1503 [==============================] - 63s 42ms/step - loss: 0.0928 - accuracy: 0.9680 - val_loss: 0.1129 - val_accuracy: 0.9688\n",
      "Epoch 14/30\n",
      "1503/1503 [==============================] - 63s 42ms/step - loss: 0.0832 - accuracy: 0.9730 - val_loss: 0.1039 - val_accuracy: 0.9688\n",
      "Epoch 15/30\n",
      "1503/1503 [==============================] - 62s 42ms/step - loss: 0.0716 - accuracy: 0.9759 - val_loss: 0.0962 - val_accuracy: 0.9688\n",
      "Epoch 16/30\n",
      "1503/1503 [==============================] - 62s 42ms/step - loss: 0.0643 - accuracy: 0.9787 - val_loss: 0.2388 - val_accuracy: 0.9688\n",
      "Epoch 17/30\n",
      "1503/1503 [==============================] - 62s 41ms/step - loss: 0.0585 - accuracy: 0.9803 - val_loss: 0.1850 - val_accuracy: 0.9688\n",
      "Epoch 18/30\n",
      "1503/1503 [==============================] - 62s 42ms/step - loss: 0.0519 - accuracy: 0.9825 - val_loss: 0.0352 - val_accuracy: 0.9688\n",
      "Epoch 19/30\n",
      "1503/1503 [==============================] - 63s 42ms/step - loss: 0.0463 - accuracy: 0.9855 - val_loss: 0.0956 - val_accuracy: 0.9688\n",
      "Epoch 20/30\n",
      "1503/1503 [==============================] - 63s 42ms/step - loss: 0.0463 - accuracy: 0.9847 - val_loss: 0.0738 - val_accuracy: 0.9688\n",
      "Epoch 21/30\n",
      "1503/1503 [==============================] - 63s 42ms/step - loss: 0.0384 - accuracy: 0.9876 - val_loss: 0.2458 - val_accuracy: 0.9375\n",
      "Epoch 22/30\n",
      "1503/1503 [==============================] - 63s 42ms/step - loss: 0.0361 - accuracy: 0.9879 - val_loss: 0.1110 - val_accuracy: 0.9688\n",
      "Epoch 23/30\n",
      "1503/1503 [==============================] - 62s 42ms/step - loss: 0.0371 - accuracy: 0.9875 - val_loss: 0.1670 - val_accuracy: 0.9375\n",
      "Epoch 24/30\n",
      "1503/1503 [==============================] - 63s 42ms/step - loss: 0.0313 - accuracy: 0.9896 - val_loss: 0.1271 - val_accuracy: 0.9688\n",
      "Epoch 25/30\n",
      "1503/1503 [==============================] - 63s 42ms/step - loss: 0.0323 - accuracy: 0.9898 - val_loss: 0.1799 - val_accuracy: 0.9688\n",
      "Epoch 26/30\n",
      "1503/1503 [==============================] - 63s 42ms/step - loss: 0.0307 - accuracy: 0.9898 - val_loss: 0.1498 - val_accuracy: 0.9688\n",
      "Epoch 27/30\n",
      "1503/1503 [==============================] - 62s 42ms/step - loss: 0.0264 - accuracy: 0.9907 - val_loss: 0.1375 - val_accuracy: 0.9688\n",
      "Epoch 28/30\n",
      "1503/1503 [==============================] - 62s 41ms/step - loss: 0.0268 - accuracy: 0.9916 - val_loss: 0.2890 - val_accuracy: 0.9688\n",
      "Epoch 29/30\n",
      "1503/1503 [==============================] - 62s 41ms/step - loss: 0.0269 - accuracy: 0.9913 - val_loss: 0.1205 - val_accuracy: 0.9688\n",
      "Epoch 30/30\n",
      "1503/1503 [==============================] - 62s 41ms/step - loss: 0.0253 - accuracy: 0.9914 - val_loss: 0.2039 - val_accuracy: 0.9375\n",
      "INFO:tensorflow:Assets written to: ../octnet/octnet_30epochs_75136_images_True_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for octnet: 0.986570\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [1. 1. 1. 1.]\n",
      "Training octnet for 1.0% of train size (aka 83484 images) with pretrained: False and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 23 trainable: 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "   5/1670 [..............................] - ETA: 2:37 - loss: 4.8465 - accuracy: 0.2455WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0191s vs `on_train_batch_end` time: 0.0572s). Check your callbacks.\n",
      "1670/1670 [==============================] - 70s 41ms/step - loss: 1.4623 - accuracy: 0.6277 - val_loss: 0.4425 - val_accuracy: 0.7500\n",
      "Epoch 2/30\n",
      "   1/1670 [..............................] - ETA: 1:08 - loss: 0.7153 - accuracy: 0.7800"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1670/1670 [==============================] - 68s 41ms/step - loss: 0.4644 - accuracy: 0.8371 - val_loss: 0.2269 - val_accuracy: 0.9375\n",
      "Epoch 3/30\n",
      "1670/1670 [==============================] - 68s 41ms/step - loss: 0.3352 - accuracy: 0.8866 - val_loss: 0.1611 - val_accuracy: 0.9375\n",
      "Epoch 4/30\n",
      "1670/1670 [==============================] - 68s 41ms/step - loss: 0.2798 - accuracy: 0.9080 - val_loss: 0.0344 - val_accuracy: 1.0000\n",
      "Epoch 5/30\n",
      "1670/1670 [==============================] - 68s 41ms/step - loss: 0.2420 - accuracy: 0.9192 - val_loss: 0.0228 - val_accuracy: 1.0000\n",
      "Epoch 6/30\n",
      "1670/1670 [==============================] - 68s 41ms/step - loss: 0.2109 - accuracy: 0.9298 - val_loss: 0.0261 - val_accuracy: 1.0000\n",
      "Epoch 7/30\n",
      "1670/1670 [==============================] - 68s 41ms/step - loss: 0.1820 - accuracy: 0.9388 - val_loss: 0.0617 - val_accuracy: 0.9688\n",
      "Epoch 8/30\n",
      "1670/1670 [==============================] - 68s 40ms/step - loss: 0.1650 - accuracy: 0.9457 - val_loss: 0.0111 - val_accuracy: 1.0000\n",
      "Epoch 9/30\n",
      "1670/1670 [==============================] - 68s 41ms/step - loss: 0.1463 - accuracy: 0.9518 - val_loss: 0.0185 - val_accuracy: 1.0000\n",
      "Epoch 10/30\n",
      "1670/1670 [==============================] - 68s 41ms/step - loss: 0.1324 - accuracy: 0.9563 - val_loss: 0.0244 - val_accuracy: 1.0000\n",
      "Epoch 11/30\n",
      "1670/1670 [==============================] - 68s 41ms/step - loss: 0.1097 - accuracy: 0.9630 - val_loss: 0.0404 - val_accuracy: 1.0000\n",
      "Epoch 12/30\n",
      "1670/1670 [==============================] - 68s 41ms/step - loss: 0.1044 - accuracy: 0.9641 - val_loss: 0.0413 - val_accuracy: 1.0000\n",
      "Epoch 13/30\n",
      "1670/1670 [==============================] - 68s 41ms/step - loss: 0.0896 - accuracy: 0.9698 - val_loss: 0.0269 - val_accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "1670/1670 [==============================] - 68s 40ms/step - loss: 0.0795 - accuracy: 0.9735 - val_loss: 0.0297 - val_accuracy: 0.9688\n",
      "Epoch 15/30\n",
      "1670/1670 [==============================] - 68s 41ms/step - loss: 0.0706 - accuracy: 0.9770 - val_loss: 0.0093 - val_accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "1670/1670 [==============================] - 68s 41ms/step - loss: 0.0659 - accuracy: 0.9778 - val_loss: 0.0129 - val_accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "1670/1670 [==============================] - 68s 41ms/step - loss: 0.0616 - accuracy: 0.9792 - val_loss: 0.0108 - val_accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "1670/1670 [==============================] - 68s 41ms/step - loss: 0.0524 - accuracy: 0.9822 - val_loss: 0.0097 - val_accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "1670/1670 [==============================] - 68s 41ms/step - loss: 0.0505 - accuracy: 0.9826 - val_loss: 0.0241 - val_accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "1670/1670 [==============================] - 68s 41ms/step - loss: 0.0452 - accuracy: 0.9842 - val_loss: 0.0172 - val_accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "1670/1670 [==============================] - 68s 41ms/step - loss: 0.0398 - accuracy: 0.9869 - val_loss: 0.0139 - val_accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "1670/1670 [==============================] - 68s 41ms/step - loss: 0.0390 - accuracy: 0.9871 - val_loss: 0.0389 - val_accuracy: 0.9688\n",
      "Epoch 23/30\n",
      "1670/1670 [==============================] - 68s 41ms/step - loss: 0.0376 - accuracy: 0.9872 - val_loss: 0.0340 - val_accuracy: 0.9688\n",
      "Epoch 24/30\n",
      "1670/1670 [==============================] - 68s 41ms/step - loss: 0.0347 - accuracy: 0.9883 - val_loss: 0.0326 - val_accuracy: 0.9688\n",
      "Epoch 25/30\n",
      "1670/1670 [==============================] - 68s 41ms/step - loss: 0.0323 - accuracy: 0.9886 - val_loss: 0.0101 - val_accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "1670/1670 [==============================] - 68s 41ms/step - loss: 0.0329 - accuracy: 0.9889 - val_loss: 0.0373 - val_accuracy: 0.9688\n",
      "Epoch 27/30\n",
      "1670/1670 [==============================] - 68s 41ms/step - loss: 0.0304 - accuracy: 0.9896 - val_loss: 0.0248 - val_accuracy: 0.9688\n",
      "Epoch 28/30\n",
      "1670/1670 [==============================] - 68s 41ms/step - loss: 0.0280 - accuracy: 0.9903 - val_loss: 0.0175 - val_accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "1670/1670 [==============================] - 68s 41ms/step - loss: 0.0280 - accuracy: 0.9907 - val_loss: 0.0351 - val_accuracy: 0.9688\n",
      "Epoch 30/30\n",
      "1670/1670 [==============================] - 68s 41ms/step - loss: 0.0285 - accuracy: 0.9906 - val_loss: 0.0413 - val_accuracy: 0.9688\n",
      "INFO:tensorflow:Assets written to: ../octnet/octnet_30epochs_83484_images_True_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for octnet: 0.986570\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import datetime\n",
    "\n",
    "maxTrain = len(y_train)\n",
    "for newWeights in [True]:\n",
    "    tLayer = [False] if newWeights else [True, False] # do not train only last layer if new weights will be produced \n",
    "    for trainLastLayerOnly in tLayer:\n",
    "        for p in [0.01, 0.025, 0.05, 0.075, 0.09, 0.1, 0.25, 0.4, 0.5, 0.6, 0.75, 0.9, 1.0]:\n",
    "            for r_state in [45687864]:\n",
    "                #X_trn, X_tst, y_trn, y_tst\n",
    "                if p < 1:\n",
    "                    X_t, _, y_t, _ = train_test_split(images, y_train, test_size=1-p, random_state=r_state)\n",
    "                else:\n",
    "                    X_t = images; y_t = y_train;\n",
    "                print(f\"Labels fraction: {sum(y_t == 1) / sum(y_train == 1)}\")\n",
    "                for net in [\"octnet\"]:\n",
    "                    print(f\"Training {net} for {p}% of train size (aka {len(X_t)} images) with pretrained: {not newWeights} and onlyLastLayersTrained: {trainLastLayerOnly}...\")\n",
    "                    model, size, normalization = emptyModelGenerator(net, newWeights=newWeights, lastOnly=trainLastLayerOnly)\n",
    "                    printTrainableLayers(model) # see if model is really well trained\n",
    "                    X_trn = resizeIms(X_t, size)\n",
    "                    #X_trn = normalizeIms(X_trn, normalization=normalization)\n",
    "                    X_val = resizeIms(x_val, size)\n",
    "                    #X_val = normalizeIms(X_val, normalization=normalization)\n",
    "                    log_dir = f\"logs/{net}/fit/{p}trainSet_\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "                    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "                    optimizer = Adam(learning_rate) # amsgrad=amsgrad) #SGD(learning_rate=learning_rate, momentum=momentum) #create new optimizers\n",
    "                    time_callback = TimeHistory()\n",
    "                    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "                    hist = model.fit(X_trn, y_t, epochs=epochs, validation_data = (X_val, y_validation), batch_size=batch_size,\n",
    "                                shuffle=True, max_queue_size=20,\n",
    "                                use_multiprocessing=True, workers=5, \n",
    "                                callbacks=[CustomCallback(fraction=0.9, model=net), tensorboard_callback, time_callback])\n",
    "                    trainTime = sum(time_callback.times)\n",
    "                    model.save(f\"../{net}/{net}_{epochs}epochs_{p*maxTrain:.0f}_images_{newWeights}_newWeights_{trainLastLayerOnly}_lastLayerOnly_{normalization}_normalization\")\n",
    "                    tstAcc = testPredict(model, size, name=net) #, normalization=normalization)\n",
    "                    results = results.append({\n",
    "                        'model': net, \n",
    "                        'train set images': len(X_t), \n",
    "                        'pretrained': not newWeights, \n",
    "                        'pretrained dataset': None if newWeights or net == \"octnet\" else (\"OCT2017,Srinivasan2014\" if net == \"opticnet\" else \"Imagenet\"),\n",
    "                        'Trained layers': \"Last dense\" if trainLastLayerOnly else \"All\", \n",
    "                        'epochs': epochs, \n",
    "                        'batch size': batch_size, \n",
    "                        'learning rate': f\"{learning_rate}_{momentum}\" if optimizer._name == \"SGD\" else learning_rate, \n",
    "                        'optimizer': optimizer._name,\n",
    "                        'training time (seconds)': trainTime, \n",
    "                        'train accuracy': hist.history[\"accuracy\"][-1], \n",
    "                        'train loss': hist.history[\"loss\"][-1],\n",
    "                        'validation accuracy': hist.history[\"val_accuracy\"][-1], \n",
    "                        'validation loss': hist.history[\"val_loss\"][-1], \n",
    "                        'test accuracy': tstAcc,\n",
    "                        #'normalization': normalization\n",
    "                    }, ignore_index=True)\n",
    "                    results.to_csv(\"Results_temp.csv\", index=False)\n",
    "                    del model\n",
    "                    del X_trn\n",
    "                    del X_val\n",
    "                    print(\"Done!\\n\" + '-'*50, end='\\n\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
