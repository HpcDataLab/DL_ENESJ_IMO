{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "import os\n",
    "import cv2\n",
    "import pickle\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version is: 2.4.1\n"
     ]
    }
   ],
   "source": [
    "print(f\"Tensorflow version is: {tf.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataPath = \"../../data/OCT/OCT2017/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of Classes Detected : 4\n"
     ]
    }
   ],
   "source": [
    "labels_available = os.listdir(os.path.join(dataPath, \"train\"))\n",
    "print(\"Total Number of Classes Detected :\",len(labels_available))\n",
    "\n",
    "labels_list = ['NORMAL',\"CNV\",\"DME\",\"DRUSEN\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NORMAL CNV DME DRUSEN "
     ]
    }
   ],
   "source": [
    "images=[]\n",
    "y_trn=[]\n",
    "for x in labels_list:\n",
    "    xPath = os.path.join(dataPath, \"train\", x)\n",
    "    myPicList = os.listdir(xPath)\n",
    "    for y in myPicList:\n",
    "        images.append(cv2.imread(os.path.join(xPath, y)))\n",
    "        y_trn.append(labels_list.index(x))\n",
    "    print(x ,end=\" \")\n",
    "\n",
    "y_train = to_categorical(y_trn,len(labels_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NORMAL CNV DME DRUSEN "
     ]
    }
   ],
   "source": [
    "x_val=[]\n",
    "y_val=[]\n",
    "for x in labels_list:\n",
    "    xPath = os.path.join(dataPath, \"val\", x)\n",
    "    myPicList = os.listdir(xPath)\n",
    "    for y in myPicList:\n",
    "        x_val.append(cv2.imread(os.path.join(xPath, y)))\n",
    "        y_val.append(labels_list.index(x))\n",
    "    print(x ,end=\" \")\n",
    "\n",
    "y_validation = to_categorical(y_val,len(labels_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NORMAL CNV DME DRUSEN "
     ]
    }
   ],
   "source": [
    "x_tst=[]\n",
    "y_tst=[]\n",
    "for x in labels_list:\n",
    "    xPath = os.path.join(dataPath, \"test\", x)\n",
    "    myPicList = os.listdir(xPath)\n",
    "    for y in myPicList:\n",
    "        x_tst.append(cv2.imread(os.path.join(xPath, y)))\n",
    "        y_tst.append(labels_list.index(x))\n",
    "    print(x ,end=\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of images per category and set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label\t\tTrain\t\tValidation\t\tTest\n",
      "NORMAL\t\t26315\t\t8\t\t\t242\n",
      "CNV\t\t37205\t\t8\t\t\t242\n",
      "DME\t\t11348\t\t8\t\t\t242\n",
      "DRUSEN\t\t8616\t\t8\t\t\t242\n"
     ]
    }
   ],
   "source": [
    "def getNumberOfItems(labels, itemLabel):\n",
    "    return sum(list(map(lambda x: x == itemLabel, labels))) \n",
    "\n",
    "\n",
    "print(\"Label\\t\\tTrain\\t\\tValidation\\t\\tTest\")\n",
    "for i, label in enumerate(labels_list):\n",
    "    print(f\"{label}\\t\\t{getNumberOfItems(y_trn, i)}\\t\\t{getNumberOfItems(y_val, i)}\\t\\t\\t{getNumberOfItems(y_tst, i)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resizeIm(im, size):\n",
    "    if im.shape[2] == 1:\n",
    "        im = cv2.cvtColor(im,cv2.COLOR_GRAY2RGB)\n",
    "    return cv2.resize(im, size)\n",
    "\n",
    "def resizeIms(x, size):\n",
    "    return np.array(list(map(lambda im: resizeIm(im, size), x)))\n",
    "\n",
    "# Substract the mean specified by Mean (https://www.mathworks.com/help/deeplearning/ref/nnet.cnn.layer.imageinputlayer.html)\n",
    "# Substract mean by channel\n",
    "def zerocenter(x):\n",
    "    return (x - np.mean(x, axis=(0, 1))) / (2*np.std(x, axis=(0, 1)))\n",
    "\n",
    "# Rescale the input to be in the range [-1, 1] using the minimum and maximum values specified by Min and Max, respectively. (https://www.mathworks.com/help/deeplearning/ref/nnet.cnn.layer.imageinputlayer.html)\n",
    "# Compute using the formula: $x\\prime = 2 * \\frac{x - \\min{x}}{\\max{x} - \\min{x}} - 1$ taken from: https://stats.stackexchange.com/a/178629\n",
    "def rescaleSymmetric(x):\n",
    "    x = zerocenter(x)\n",
    "    return 2 * (x - np.min(x, axis=(0, 1)))/np.ptp(x, axis=(0, 1)) - 1\n",
    "\n",
    "def normalizeIms(x, normalization):\n",
    "    if normalization == \"zerocenter\":\n",
    "        func = zerocenter\n",
    "    elif normalization == \"rescale-symmetric\":\n",
    "        func = rescaleSymmetric\n",
    "    else:\n",
    "        return x\n",
    "    return np.array(list(map(lambda im: func(im), x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self,fraction, model):\n",
    "        super(CustomCallback,self).__init__()\n",
    "        self.fraction = fraction\n",
    "        self.train_a = [];\n",
    "        self.val_a =[];\n",
    "        self.logPath = os.path.join(model, \"log.txt\")\n",
    "\n",
    "        if not os.path.isdir(model):\n",
    "            os.mkdir(model)\n",
    "\n",
    "        with open(self.logPath,'w') as f:\n",
    "            f.write('Starting of logging..\\n')\n",
    "\n",
    "        self.fig = plt.figure(figsize=(4,3))\n",
    "        self.ax = plt.subplot(1,1,1)\n",
    "        plt.ion()\n",
    "\n",
    "    def on_train_begin(self,logs=None):\n",
    "        self.fig.show()\n",
    "        self.fig.canvas.draw()\n",
    "\n",
    "    def on_train_end(self,logs=None):\n",
    "        with open(self.logPath,'a') as f:\n",
    "              f.write('End of logging..\\n')\n",
    "    \n",
    "    def on_epoch_begin(self,epoch,logs=None):\n",
    "        lr= tf.keras.backend.get_value(self.model.optimizer.lr)\n",
    "        lr *= self.fraction\n",
    "        tf.keras.backend.set_value(self.model.optimizer.lr,lr)\n",
    "        with open(self.logPath,'a') as f:\n",
    "            f.write('At epoch {:02d}, learning rate changed to {:.4f}\\n'.format(epoch,lr))\n",
    "    \n",
    "    def on_epoch_end(self,epoch,logs=None):\n",
    "        val_acc = logs.get('val_accuracy')\n",
    "        train_acc = logs.get('accuracy')\n",
    "        self.train_a.append(train_acc)\n",
    "        self.val_a.append(val_acc)\n",
    "        with open(self.logPath,'a') as f:\n",
    "            f.write('At epoch {:02d}, training accuracy: {:.3f}, validation accuracy: {:.3f}\\n'.format(epoch,train_acc,val_acc))\n",
    "        self.ax.clear()\n",
    "        self.ax.plot(range(1+epoch),self.train_a,label=\"Training\")\n",
    "        self.ax.plot(range(1+epoch),self.val_a,label=\"Validation\")\n",
    "        self.ax.set_xlabel('Epochs')\n",
    "        self.ax.set_ylabel('Accuracy')\n",
    "        self.ax.legend()\n",
    "        self.fig.canvas.draw()\n",
    "        self.fig.show()\n",
    "        \n",
    "class TimeHistory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.times = []\n",
    "\n",
    "    def on_epoch_begin(self, batch, logs={}):\n",
    "        self.epoch_time_start = time.time()\n",
    "\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.times.append(time.time() - self.epoch_time_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "# xception base model\n",
    "#from tensorflow.keras.applications.xception import Xception\n",
    "#from tensorflow.keras.applications.xception import preprocess_input, decode_predictions\n",
    "#xceptionNetModel = Xception(weights='imagenet')\n",
    "#xceptionNetModel.save(\"../Xception.hdf5\")\n",
    "\n",
    "xceptionNetModel = tf.keras.models.load_model('../Xception.hdf5')\n",
    "\n",
    "# opticnet base model\n",
    "opticNetModel = tf.keras.models.load_model('../Optic_net-4_classes-Kermany2018.hdf5')\n",
    "\n",
    "# resnet base model\n",
    "#from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "#from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "#resNetModel = ResNet50(weights='imagenet')\n",
    "#resNetModel.save(\"../Resnet50.hdf5\")\n",
    "\n",
    "resNetModel = tf.keras.models.load_model('../Resnet50.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 221, 221, 32)      4736      \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 221, 221, 32)      128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 110, 110, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 104, 104, 32)      50208     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 104, 104, 32)      128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 52, 52, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 48, 48, 64)        51264     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 48, 48, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 24, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 20, 20, 128)       204928    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 20, 20, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 10, 10, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 8, 8, 256)         295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d (AveragePo (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               131200    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4)                 132       \n",
      "_________________________________________________________________\n",
      "softmax (Softmax)            (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 743,812\n",
      "Trainable params: 742,788\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "conv_init = tf.keras.initializers.RandomNormal(mean=0., stddev=1.) # convolutional layer with zero mean and 1 sd\n",
    "#batch_init = tf.keras.initializers.RandomNormal(mean=1., stddev=0.02) # non-sense here\n",
    "\n",
    "octnet = keras.models.Sequential() # empty model\n",
    "\n",
    "octnet.add(keras.layers.Conv2D(32, (7, 7), activation=\"relu\", use_bias=True, input_shape=(227, 227, 3), kernel_initializer=conv_init))\n",
    "octnet.add(keras.layers.BatchNormalization())\n",
    "octnet.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "octnet.add(keras.layers.Conv2D(32, (7, 7), activation=\"relu\", use_bias=True, kernel_initializer=conv_init))\n",
    "octnet.add(keras.layers.BatchNormalization())\n",
    "octnet.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "octnet.add(keras.layers.Conv2D(64, (5, 5), activation=\"relu\", use_bias=True, kernel_initializer=conv_init))\n",
    "octnet.add(keras.layers.BatchNormalization())\n",
    "octnet.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "octnet.add(keras.layers.Conv2D(128, (5, 5), activation=\"relu\", use_bias=True, kernel_initializer=conv_init))\n",
    "octnet.add(keras.layers.BatchNormalization())\n",
    "octnet.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "octnet.add(keras.layers.Conv2D(256, (3, 3), activation=\"relu\", use_bias=True, kernel_initializer=conv_init))\n",
    "octnet.add(keras.layers.BatchNormalization())\n",
    "octnet.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "#octnet.add(keras.layers.Conv2D(512, (3, 3), activation=\"relu\", use_bias=True))\n",
    "#octnet.add(keras.layers.BatchNormalization())\n",
    "#octnet.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "octnet.add(keras.layers.AveragePooling2D())\n",
    "octnet.add(keras.layers.Flatten())\n",
    "octnet.add(keras.layers.Dense(128))\n",
    "octnet.add(keras.layers.Dropout(0.5))\n",
    "octnet.add(keras.layers.Dense(32))\n",
    "octnet.add(keras.layers.Dropout(0.5))\n",
    "octnet.add(keras.layers.Dense(4))\n",
    "octnet.add(keras.layers.Softmax())\n",
    "\n",
    "octnet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emptyModelGenerator(model, newWeights=False, lastOnly=False):\n",
    "    model = model.lower() # lower case model name\n",
    "    if model == \"resnet\":\n",
    "        x = resNetModel.output\n",
    "        predictions = Dense(len(labels_list), activation='softmax')(x)\n",
    "        newModel = Model(inputs=resNetModel.input, outputs=predictions)\n",
    "        size = (224, 224)\n",
    "        normalization = \"zerocenter\"\n",
    "    elif model == \"xception\":\n",
    "        x = xceptionNetModel.output\n",
    "        predictions = Dense(len(labels_list), activation='softmax')(x)\n",
    "        newModel = Model(inputs=xceptionNetModel.input, outputs=predictions)\n",
    "        size = (299, 299)\n",
    "        normalization = \"rescale-symmetric\"\n",
    "    elif model == \"opticnet\":\n",
    "        newModel = tf.keras.models.load_model('../Optic_net-4_classes-Kermany2018.hdf5')\n",
    "        size = (224, 224)\n",
    "        normalization = \"rescale-symmetric\"\n",
    "    elif model == \"octnet\":\n",
    "        newModel = tf.keras.models.clone_model(octnet)\n",
    "        size = (227, 227)\n",
    "        normalization = \"zerocenter\"\n",
    "    if newWeights:\n",
    "        newModel = tf.keras.models.clone_model(newModel)\n",
    "    if lastOnly:\n",
    "        newModel = lastDenseTrainable(newModel) # block all layer except the last dense ones\n",
    "    else:\n",
    "        newModel.trainable = True\n",
    "    return newModel, size, normalization\n",
    "\n",
    "\n",
    "def lastDenseTrainable(model):\n",
    "    model.trainable = False\n",
    "    for i in range(1, len(model.layers)):\n",
    "        if model.layers[-i].__class__.__name__ == \"Dense\":\n",
    "            model.layers[-i].trainable= True\n",
    "        elif model.layers[-i].__class__.__name__ == \"Activation\":\n",
    "            continue\n",
    "        else:\n",
    "            break\n",
    "    return model\n",
    "    \n",
    "\n",
    "def testPredict(model, size, name=None, normalization=None):\n",
    "    X_test = resizeIms(x_tst, size)\n",
    "    if normalization:\n",
    "        X_test = normalizeIms(X_test, normalization)\n",
    "    X_test = np.array(X_test)\n",
    "    Y_test = np.array(y_tst)\n",
    "    \n",
    "    prediction = model.predict(X_test)\n",
    "    preds = np.argmax(prediction, axis=1)\n",
    "    acc = sum(preds == Y_test) / len(Y_test)\n",
    "    print(f'Test acc for {name if name else \"model\"}: {acc:.6f}')\n",
    "    return acc\n",
    "    \n",
    "\n",
    "def computeConfussionMatrix(predictions, labels):\n",
    "    num_labels = len(labels_list)\n",
    "    cMatrix = np.zeros(shape=(num_labels, num_labels))\n",
    "    for i in len(predictions):\n",
    "        p = int(predictions[i])\n",
    "        t = int(predictions[i])\n",
    "        cMatrix[t, p] += 1\n",
    "    print(cMatrix)\n",
    "    ax = sns.heatmap(cMatrix, cmap=\"Blues\", annot=True, fmt=\"d\", xticklabels=labels_list, yticklabels=labels_list)\n",
    "    plt.xlabel(\"Predicted label\")\n",
    "    plt.ylabel(\"True label\")\n",
    "    plt.title(\"Confusion matrix\")\n",
    "    plt.show();\n",
    "    return cMatrix\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "**************************************************\n",
      "Model: xception\n",
      "**************************************************\n",
      "\n",
      "Total: 135 trainable: 2\n",
      "\n",
      "\n",
      "**************************************************\n",
      "Model: resnet\n",
      "**************************************************\n",
      "\n",
      "Total: 178 trainable: 2\n",
      "\n",
      "\n",
      "**************************************************\n",
      "Model: opticnet\n",
      "**************************************************\n",
      "\n",
      "Total: 276 trainable: 2\n",
      "\n",
      "\n",
      "**************************************************\n",
      "Model: octnet\n",
      "**************************************************\n",
      "\n",
      "Total: 23 trainable: 0\n"
     ]
    }
   ],
   "source": [
    "models = [\"xception\", \"resnet\", \"opticnet\", \"octnet\"]\n",
    "\n",
    "def printTrainableLayers(m):\n",
    "    a = 0\n",
    "    for l in m.layers:\n",
    "        #l.trainable = True\n",
    "        if l.trainable:\n",
    "            #print(l.name, l.trainable)\n",
    "            a += 1\n",
    "    print(f\"\\nTotal: {len(m.layers)} trainable: {a}\")\n",
    "\n",
    "for mod in models:\n",
    "    print(\"\\n\\n\" + (\"*\"*50) + \"\\nModel: \" + mod + '\\n' + (\"*\"*50))\n",
    "    m = emptyModelGenerator(mod, newWeights=False, lastOnly=True)[0]\n",
    "    printTrainableLayers(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "momentum = 0.6\n",
    "optim = lambda lr: Adam(learning_rate=lr)\n",
    "#optim = lambda lr, momentum: SGD(learning_rate=lr, momentum=momentum)\n",
    "epochs = 30\n",
    "batch_size = 50\n",
    "#batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "results = pd.read_csv(\"Results_temp.csv\")\n",
    "results[\"normalization\"] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pandas as pd\n",
    "#res = pd.read_csv(\"Results_temp.csv\")\n",
    "#res.to_csv(\"Results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels fraction: [1. 1. 1. 1.]\n",
      "Training opticnet for 1.0% of train size (aka 83484 images) with pretrained: False and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 276 trainable: 276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "   6/1670 [..............................] - ETA: 33:51 - loss: 36.1225 - accuracy: 0.2370WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.4548s vs `on_train_batch_end` time: 0.6386s). Check your callbacks.\n",
      "1670/1670 [==============================] - 1996s 1s/step - loss: 1.9297 - accuracy: 0.6536 - val_loss: 0.7137 - val_accuracy: 0.8125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "1670/1670 [==============================] - 1960s 1s/step - loss: 0.2455 - accuracy: 0.9184 - val_loss: 0.0706 - val_accuracy: 1.0000\n",
      "Epoch 3/30\n",
      "1670/1670 [==============================] - 1957s 1s/step - loss: 0.3111 - accuracy: 0.9162 - val_loss: 0.1143 - val_accuracy: 0.9688\n",
      "Epoch 4/30\n",
      "1670/1670 [==============================] - 1953s 1s/step - loss: 0.1728 - accuracy: 0.9415 - val_loss: 0.0320 - val_accuracy: 1.0000\n",
      "Epoch 5/30\n",
      "1670/1670 [==============================] - 1955s 1s/step - loss: 0.1518 - accuracy: 0.9497 - val_loss: 0.0698 - val_accuracy: 1.0000\n",
      "Epoch 6/30\n",
      "1670/1670 [==============================] - 1949s 1s/step - loss: 0.1336 - accuracy: 0.9533 - val_loss: 0.0508 - val_accuracy: 1.0000\n",
      "Epoch 7/30\n",
      "1670/1670 [==============================] - 1949s 1s/step - loss: 0.1198 - accuracy: 0.9572 - val_loss: 0.0635 - val_accuracy: 0.9688\n",
      "Epoch 8/30\n",
      "1670/1670 [==============================] - 1951s 1s/step - loss: 0.1076 - accuracy: 0.9639 - val_loss: 0.0132 - val_accuracy: 1.0000\n",
      "Epoch 9/30\n",
      "1670/1670 [==============================] - 1966s 1s/step - loss: 0.0916 - accuracy: 0.9685 - val_loss: 0.0565 - val_accuracy: 0.9688\n",
      "Epoch 10/30\n",
      "1670/1670 [==============================] - 1955s 1s/step - loss: 0.0821 - accuracy: 0.9719 - val_loss: 0.0200 - val_accuracy: 1.0000\n",
      "Epoch 11/30\n",
      "1670/1670 [==============================] - 1970s 1s/step - loss: 0.0642 - accuracy: 0.9775 - val_loss: 0.0046 - val_accuracy: 1.0000\n",
      "Epoch 12/30\n",
      "1670/1670 [==============================] - 1945s 1s/step - loss: 0.0507 - accuracy: 0.9821 - val_loss: 0.0080 - val_accuracy: 1.0000\n",
      "Epoch 13/30\n",
      "1670/1670 [==============================] - 1943s 1s/step - loss: 0.0416 - accuracy: 0.9859 - val_loss: 0.0072 - val_accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "1670/1670 [==============================] - 1943s 1s/step - loss: 0.0350 - accuracy: 0.9872 - val_loss: 0.0604 - val_accuracy: 0.9688\n",
      "Epoch 15/30\n",
      "1670/1670 [==============================] - 1942s 1s/step - loss: 0.0272 - accuracy: 0.9906 - val_loss: 0.0087 - val_accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "1670/1670 [==============================] - 1944s 1s/step - loss: 0.0227 - accuracy: 0.9925 - val_loss: 0.0112 - val_accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "1670/1670 [==============================] - 1944s 1s/step - loss: 0.0213 - accuracy: 0.9928 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "1670/1670 [==============================] - 1944s 1s/step - loss: 0.0172 - accuracy: 0.9944 - val_loss: 0.0189 - val_accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "1670/1670 [==============================] - 1943s 1s/step - loss: 0.0155 - accuracy: 0.9950 - val_loss: 0.0153 - val_accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "1670/1670 [==============================] - 1943s 1s/step - loss: 0.0139 - accuracy: 0.9953 - val_loss: 0.0074 - val_accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "1670/1670 [==============================] - 1943s 1s/step - loss: 0.0127 - accuracy: 0.9956 - val_loss: 0.0068 - val_accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "1670/1670 [==============================] - 1943s 1s/step - loss: 0.0111 - accuracy: 0.9957 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "1670/1670 [==============================] - 1943s 1s/step - loss: 0.0105 - accuracy: 0.9959 - val_loss: 0.0148 - val_accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "1670/1670 [==============================] - 1932s 1s/step - loss: 0.0095 - accuracy: 0.9962 - val_loss: 0.0108 - val_accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "1670/1670 [==============================] - 1931s 1s/step - loss: 0.0093 - accuracy: 0.9960 - val_loss: 0.0084 - val_accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "1670/1670 [==============================] - 1940s 1s/step - loss: 0.0087 - accuracy: 0.9964 - val_loss: 0.0153 - val_accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "1670/1670 [==============================] - 1940s 1s/step - loss: 0.0075 - accuracy: 0.9966 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "1670/1670 [==============================] - 1939s 1s/step - loss: 0.0071 - accuracy: 0.9968 - val_loss: 0.0171 - val_accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "1670/1670 [==============================] - 1940s 1s/step - loss: 0.0069 - accuracy: 0.9968 - val_loss: 0.0345 - val_accuracy: 0.9688\n",
      "Epoch 30/30\n",
      "1670/1670 [==============================] - 1940s 1s/step - loss: 0.0068 - accuracy: 0.9963 - val_loss: 0.0062 - val_accuracy: 1.0000\n",
      "INFO:tensorflow:Assets written to: ../opticnet/opticnet_30epochs_83484_images_True_newWeights_False_lastLayerOnly_rescale-symmetric_normalization/assets\n",
      "Test acc for opticnet: 0.998967\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training xception for 1.0% of train size (aka 83484 images) with pretrained: False and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 135 trainable: 135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "   6/1670 [..............................] - ETA: 26:31 - loss: 1.3828 - accuracy: 0.4124WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1545s vs `on_train_batch_end` time: 0.6683s). Check your callbacks.\n",
      "1670/1670 [==============================] - 1281s 763ms/step - loss: 1.0588 - accuracy: 0.7190 - val_loss: 0.8967 - val_accuracy: 0.6562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "1670/1670 [==============================] - 1276s 764ms/step - loss: 0.5558 - accuracy: 0.8259 - val_loss: 0.6468 - val_accuracy: 0.7188\n",
      "Epoch 3/30\n",
      "1670/1670 [==============================] - 1266s 758ms/step - loss: 0.4141 - accuracy: 0.8526 - val_loss: 0.4764 - val_accuracy: 0.7500\n",
      "Epoch 4/30\n",
      "1670/1670 [==============================] - 1264s 757ms/step - loss: 0.3413 - accuracy: 0.8680 - val_loss: 0.3450 - val_accuracy: 0.8438\n",
      "Epoch 5/30\n",
      "1670/1670 [==============================] - 1277s 765ms/step - loss: 0.2357 - accuracy: 0.9496 - val_loss: 0.1882 - val_accuracy: 0.9688\n",
      "Epoch 6/30\n",
      "1670/1670 [==============================] - 1279s 766ms/step - loss: 0.1668 - accuracy: 0.9586 - val_loss: 0.0693 - val_accuracy: 1.0000\n",
      "Epoch 7/30\n",
      "1670/1670 [==============================] - 1271s 761ms/step - loss: 0.1334 - accuracy: 0.9655 - val_loss: 0.0882 - val_accuracy: 1.0000\n",
      "Epoch 8/30\n",
      "1670/1670 [==============================] - 1273s 762ms/step - loss: 0.1122 - accuracy: 0.9703 - val_loss: 0.0320 - val_accuracy: 1.0000\n",
      "Epoch 9/30\n",
      "1670/1670 [==============================] - 1276s 764ms/step - loss: 0.0975 - accuracy: 0.9735 - val_loss: 0.0314 - val_accuracy: 1.0000\n",
      "Epoch 10/30\n",
      "1670/1670 [==============================] - 1273s 762ms/step - loss: 0.0816 - accuracy: 0.9786 - val_loss: 0.0219 - val_accuracy: 1.0000\n",
      "Epoch 11/30\n",
      "1670/1670 [==============================] - 1278s 765ms/step - loss: 0.0685 - accuracy: 0.9831 - val_loss: 0.0206 - val_accuracy: 1.0000\n",
      "Epoch 12/30\n",
      "1670/1670 [==============================] - 1283s 768ms/step - loss: 0.0589 - accuracy: 0.9847 - val_loss: 0.0649 - val_accuracy: 0.9688\n",
      "Epoch 13/30\n",
      "1670/1670 [==============================] - 1272s 762ms/step - loss: 0.0522 - accuracy: 0.9872 - val_loss: 0.0211 - val_accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "1670/1670 [==============================] - 1275s 764ms/step - loss: 0.0461 - accuracy: 0.9892 - val_loss: 0.0291 - val_accuracy: 1.0000\n",
      "Epoch 15/30\n",
      "1670/1670 [==============================] - 1279s 766ms/step - loss: 0.0389 - accuracy: 0.9910 - val_loss: 0.0200 - val_accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "1670/1670 [==============================] - 1276s 764ms/step - loss: 0.0382 - accuracy: 0.9914 - val_loss: 0.0279 - val_accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "1670/1670 [==============================] - 1280s 767ms/step - loss: 0.0321 - accuracy: 0.9928 - val_loss: 0.0192 - val_accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "1670/1670 [==============================] - 1278s 766ms/step - loss: 0.0295 - accuracy: 0.9936 - val_loss: 0.0215 - val_accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "1670/1670 [==============================] - 1283s 769ms/step - loss: 0.0279 - accuracy: 0.9939 - val_loss: 0.0307 - val_accuracy: 0.9688\n",
      "Epoch 20/30\n",
      "1670/1670 [==============================] - 1275s 764ms/step - loss: 0.0278 - accuracy: 0.9936 - val_loss: 0.0267 - val_accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "1670/1670 [==============================] - 1277s 765ms/step - loss: 0.0263 - accuracy: 0.9944 - val_loss: 0.0258 - val_accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "1670/1670 [==============================] - 1279s 766ms/step - loss: 0.0229 - accuracy: 0.9947 - val_loss: 0.0196 - val_accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "1670/1670 [==============================] - 1274s 763ms/step - loss: 0.0239 - accuracy: 0.9944 - val_loss: 0.0219 - val_accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "1670/1670 [==============================] - 1282s 768ms/step - loss: 0.0223 - accuracy: 0.9946 - val_loss: 0.0363 - val_accuracy: 0.9688\n",
      "Epoch 25/30\n",
      "1670/1670 [==============================] - 1271s 761ms/step - loss: 0.0208 - accuracy: 0.9948 - val_loss: 0.0160 - val_accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "1670/1670 [==============================] - 1273s 762ms/step - loss: 0.0186 - accuracy: 0.9951 - val_loss: 0.0238 - val_accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "1670/1670 [==============================] - 1273s 763ms/step - loss: 0.0176 - accuracy: 0.9954 - val_loss: 0.0196 - val_accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "1670/1670 [==============================] - 1273s 763ms/step - loss: 0.0199 - accuracy: 0.9952 - val_loss: 0.0332 - val_accuracy: 0.9688\n",
      "Epoch 29/30\n",
      "1670/1670 [==============================] - 1267s 759ms/step - loss: 0.0172 - accuracy: 0.9954 - val_loss: 0.0418 - val_accuracy: 0.9688\n",
      "Epoch 30/30\n",
      "1670/1670 [==============================] - 1269s 760ms/step - loss: 0.0171 - accuracy: 0.9954 - val_loss: 0.0234 - val_accuracy: 1.0000\n",
      "INFO:tensorflow:Assets written to: ../xception/xception_30epochs_83484_images_True_newWeights_False_lastLayerOnly_rescale-symmetric_normalization/assets\n",
      "Test acc for xception: 0.997934\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import datetime\n",
    "\n",
    "maxTrain = len(y_train)\n",
    "for newWeights in [True]:\n",
    "    tLayer = [False] if newWeights else [True, False] # do not train only last layer if new weights will be produced \n",
    "    for trainLastLayerOnly in tLayer:\n",
    "        #for p in [0.01, 0.025, 0.05, 0.075, 0.09, 0.1, 0.25, 0.4, 0.5, 0.6, 0.75, 0.9, 1.0]:\n",
    "        for p in [1.0]:\n",
    "            for r_state in [45687864]:\n",
    "                #X_trn, X_tst, y_trn, y_tst\n",
    "                if p < 1:\n",
    "                    X_t, _, y_t, _ = train_test_split(images, y_train, test_size=1-p, random_state=r_state)\n",
    "                else:\n",
    "                    X_t = images; y_t = y_train;\n",
    "                print(f\"Labels fraction: {sum(y_t == 1) / sum(y_train == 1)}\")\n",
    "                for net in [\"opticnet\", \"xception\"]:\n",
    "                    print(f\"Training {net} for {p}% of train size (aka {len(X_t)} images) with pretrained: {not newWeights} and onlyLastLayersTrained: {trainLastLayerOnly}...\")\n",
    "                    model, size, normalization = emptyModelGenerator(net, newWeights=newWeights, lastOnly=trainLastLayerOnly)\n",
    "                    printTrainableLayers(model) # see if model is really well trained\n",
    "                    X_trn = resizeIms(X_t, size)\n",
    "                    #X_trn = normalizeIms(X_trn, normalization=normalization)\n",
    "                    X_val = resizeIms(x_val, size)\n",
    "                    #X_val = normalizeIms(X_val, normalization=normalization)\n",
    "                    log_dir = f\"logs/{net}/fit/{p}trainSet_\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "                    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "                    optimizer = Adam(learning_rate)  # SGD(learning_rate=learning_rate, momentum=momentum)# amsgrad=amsgrad) #create new optimizers\n",
    "                    time_callback = TimeHistory()\n",
    "                    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "                    hist = model.fit(X_trn, y_t, epochs=epochs, validation_data = (X_val, y_validation), batch_size=batch_size,\n",
    "                                shuffle=True, max_queue_size=20,\n",
    "                                use_multiprocessing=True, workers=5, \n",
    "                                callbacks=[CustomCallback(fraction=0.9, model=net), tensorboard_callback, time_callback])\n",
    "                    trainTime = sum(time_callback.times)\n",
    "                    model.save(f\"../{net}/{net}_{epochs}epochs_{p*maxTrain:.0f}_images_{newWeights}_newWeights_{trainLastLayerOnly}_lastLayerOnly_{normalization}_normalization\")\n",
    "                    tstAcc = testPredict(model, size, name=net) #, normalization=normalization)\n",
    "                    results = results.append({\n",
    "                        'model': net, \n",
    "                        'train set images': len(X_t), \n",
    "                        'pretrained': not newWeights, \n",
    "                        'pretrained dataset': None if newWeights or net == \"octnet\" else (\"OCT2017,Srinivasan2014\" if net == \"opticnet\" else \"Imagenet\"),\n",
    "                        'Trained layers': \"Last dense\" if trainLastLayerOnly else \"All\", \n",
    "                        'epochs': epochs, \n",
    "                        'batch size': batch_size, \n",
    "                        'learning rate': f\"{learning_rate}_{momentum}\" if optimizer._name == \"SGD\" else learning_rate, \n",
    "                        'optimizer': optimizer._name,\n",
    "                        'training time (seconds)': trainTime, \n",
    "                        'train accuracy': hist.history[\"accuracy\"][-1], \n",
    "                        'train loss': hist.history[\"loss\"][-1],\n",
    "                        'validation accuracy': hist.history[\"val_accuracy\"][-1], \n",
    "                        'validation loss': hist.history[\"val_loss\"][-1], \n",
    "                        'test accuracy': tstAcc,\n",
    "                        #'normalization': normalization\n",
    "                    }, ignore_index=True)\n",
    "                    results.to_csv(\"Results_temp.csv\", index=False)\n",
    "                    del model\n",
    "                    del X_trn\n",
    "                    del X_val\n",
    "                    print(\"Done!\\n\" + '-'*50, end='\\n\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
