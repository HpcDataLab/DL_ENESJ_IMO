{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "import os\n",
    "import cv2\n",
    "import pickle\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataPath = \"../../data/OCT/OCT2017/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of Classes Detected : 4\n"
     ]
    }
   ],
   "source": [
    "labels_available = os.listdir(os.path.join(dataPath, \"train\"))\n",
    "print(\"Total Number of Classes Detected :\",len(labels_available))\n",
    "\n",
    "labels_list = ['NORMAL',\"CNV\",\"DME\",\"DRUSEN\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NORMAL CNV DME DRUSEN "
     ]
    }
   ],
   "source": [
    "images=[]\n",
    "y_trn=[]\n",
    "for x in labels_list:\n",
    "    xPath = os.path.join(dataPath, \"train\", x)\n",
    "    myPicList = os.listdir(xPath)\n",
    "    for y in myPicList:\n",
    "        images.append(cv2.imread(os.path.join(xPath, y)))\n",
    "        y_trn.append(labels_list.index(x))\n",
    "    print(x ,end=\" \")\n",
    "\n",
    "y_train = to_categorical(y_trn,len(labels_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NORMAL CNV DME DRUSEN "
     ]
    }
   ],
   "source": [
    "x_val=[]\n",
    "y_val=[]\n",
    "for x in labels_list:\n",
    "    xPath = os.path.join(dataPath, \"val\", x)\n",
    "    myPicList = os.listdir(xPath)\n",
    "    for y in myPicList:\n",
    "        x_val.append(cv2.imread(os.path.join(xPath, y)))\n",
    "        y_val.append(labels_list.index(x))\n",
    "    print(x ,end=\" \")\n",
    "\n",
    "y_validation = to_categorical(y_val,len(labels_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NORMAL CNV DME DRUSEN "
     ]
    }
   ],
   "source": [
    "x_tst=[]\n",
    "y_tst=[]\n",
    "for x in labels_list:\n",
    "    xPath = os.path.join(dataPath, \"test\", x)\n",
    "    myPicList = os.listdir(xPath)\n",
    "    for y in myPicList:\n",
    "        x_tst.append(cv2.imread(os.path.join(xPath, y)))\n",
    "        y_tst.append(labels_list.index(x))\n",
    "    print(x ,end=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resizeIm(im, size):\n",
    "    if im.shape[2] == 1:\n",
    "        im = cv2.cvtColor(im,cv2.COLOR_GRAY2RGB)\n",
    "    return cv2.resize(im, size)\n",
    "\n",
    "def resizeIms(x, size):\n",
    "    return np.array(list(map(lambda im: resizeIm(im, size), x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self,fraction, model):\n",
    "        super(CustomCallback,self).__init__()\n",
    "        self.fraction = fraction\n",
    "        self.train_a = [];\n",
    "        self.val_a =[];\n",
    "        self.logPath = os.path.join(model, \"log.txt\")\n",
    "\n",
    "        if not os.path.isdir(model):\n",
    "            os.mkdir(model)\n",
    "\n",
    "        with open(self.logPath,'w') as f:\n",
    "            f.write('Starting of logging..\\n')\n",
    "\n",
    "        self.fig = plt.figure(figsize=(4,3))\n",
    "        self.ax = plt.subplot(1,1,1)\n",
    "        plt.ion()\n",
    "\n",
    "    def on_train_begin(self,logs=None):\n",
    "        self.fig.show()\n",
    "        self.fig.canvas.draw()\n",
    "\n",
    "    def on_train_end(self,logs=None):\n",
    "        with open(self.logPath,'a') as f:\n",
    "              f.write('End of logging..\\n')\n",
    "    \n",
    "    def on_epoch_begin(self,epoch,logs=None):\n",
    "        lr= tf.keras.backend.get_value(self.model.optimizer.lr)\n",
    "        lr *= self.fraction\n",
    "        tf.keras.backend.set_value(self.model.optimizer.lr,lr)\n",
    "        with open(self.logPath,'a') as f:\n",
    "            f.write('At epoch {:02d}, learning rate changed to {:.4f}\\n'.format(epoch,lr))\n",
    "    \n",
    "    def on_epoch_end(self,epoch,logs=None):\n",
    "        val_acc = logs.get('val_accuracy')\n",
    "        train_acc = logs.get('accuracy')\n",
    "        self.train_a.append(train_acc)\n",
    "        self.val_a.append(val_acc)\n",
    "        with open(self.logPath,'a') as f:\n",
    "            f.write('At epoch {:02d}, training accuracy: {:.3f}, validation accuracy: {:.3f}\\n'.format(epoch,train_acc,val_acc))\n",
    "        self.ax.clear()\n",
    "        self.ax.plot(range(1+epoch),self.train_a,label=\"Training\")\n",
    "        self.ax.plot(range(1+epoch),self.val_a,label=\"Validation\")\n",
    "        self.ax.set_xlabel('Epochs')\n",
    "        self.ax.set_ylabel('Accuracy')\n",
    "        self.ax.legend()\n",
    "        self.fig.canvas.draw()\n",
    "        self.fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xception base model\n",
    "from tensorflow.keras.applications.xception import Xception\n",
    "from tensorflow.keras.applications.xception import preprocess_input, decode_predictions\n",
    "xceptionNetModel = Xception(weights='imagenet')\n",
    "\n",
    "# opticnet base model\n",
    "opticNetModel = tf.keras.models.load_model('../Optic_net-4_classes-Kermany2018.hdf5')\n",
    "\n",
    "# resnet base model\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "\n",
    "resNetModel = ResNet50(weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emptyModelGenerator(model):\n",
    "    model = model.lower()\n",
    "    if model == \"resnet\":\n",
    "        x = resNetModel.output\n",
    "        predictions = Dense(len(labels_list), activation='softmax')(x)\n",
    "        newModel = Model(inputs=resNetModel.input, outputs=predictions)\n",
    "        size = (224, 224)\n",
    "    elif model == \"xception\":\n",
    "        x = xceptionNetModel.output\n",
    "        predictions = Dense(len(labels_list), activation='softmax')(x)\n",
    "        newModel = Model(inputs=xceptionNetModel.input, outputs=predictions)\n",
    "        size = (299, 299)\n",
    "    elif model == \"opticnet\":\n",
    "        newModel = tf.keras.models.load_model('../Optic_net-4_classes-Kermany2018.hdf5')\n",
    "        size = (224, 224)\n",
    "    return newModel, size\n",
    "\n",
    "\n",
    "def testPredict(model, size):\n",
    "    X_test = resizeIms(x_tst, size)\n",
    "    X_test = np.array(X_test)\n",
    "    Y_test = np.array(y_tst)\n",
    "    \n",
    "    prediction = model.predict(X_test)\n",
    "    preds = np.argmax(prediction, axis=1)\n",
    "    acc = sum(preds == Y_test) / len(Y_test)\n",
    "    print(f'Test acc for {model}: {acc:.4f}')\n",
    "    \n",
    "\n",
    "nOptic = emptyModelGenerator(\"opticnet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = Adam(learning_rate=0.001)\n",
    "epochs = 30\n",
    "batch_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training opticnet for 0.1% of train size (aka 8348 images)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/167 [>.............................] - ETA: 3:03 - loss: 5.3647 - accuracy: 0.1782WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.4558s vs `on_train_batch_end` time: 0.5702s). Check your callbacks.\n",
      "167/167 [==============================] - 216s 1s/step - loss: 0.9171 - accuracy: 0.7730 - val_loss: 0.0495 - val_accuracy: 1.0000\n",
      "Epoch 2/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "167/167 [==============================] - 196s 1s/step - loss: 0.1521 - accuracy: 0.9507 - val_loss: 0.1273 - val_accuracy: 0.9688\n",
      "Epoch 3/30\n",
      "167/167 [==============================] - 196s 1s/step - loss: 0.1070 - accuracy: 0.9658 - val_loss: 0.0051 - val_accuracy: 1.0000\n",
      "Epoch 4/30\n",
      "167/167 [==============================] - 197s 1s/step - loss: 0.0853 - accuracy: 0.9729 - val_loss: 0.0405 - val_accuracy: 1.0000\n",
      "Epoch 5/30\n",
      "167/167 [==============================] - 197s 1s/step - loss: 0.0649 - accuracy: 0.9777 - val_loss: 0.0556 - val_accuracy: 1.0000\n",
      "Epoch 6/30\n",
      "167/167 [==============================] - 197s 1s/step - loss: 0.0422 - accuracy: 0.9885 - val_loss: 0.0325 - val_accuracy: 1.0000\n",
      "Epoch 7/30\n",
      "167/167 [==============================] - 197s 1s/step - loss: 0.0316 - accuracy: 0.9887 - val_loss: 0.0192 - val_accuracy: 1.0000\n",
      "Epoch 8/30\n",
      "167/167 [==============================] - 196s 1s/step - loss: 0.0160 - accuracy: 0.9954 - val_loss: 3.8572e-04 - val_accuracy: 1.0000\n",
      "Epoch 9/30\n",
      "167/167 [==============================] - 196s 1s/step - loss: 0.0176 - accuracy: 0.9939 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
      "Epoch 10/30\n",
      "167/167 [==============================] - 196s 1s/step - loss: 0.0113 - accuracy: 0.9968 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
      "Epoch 11/30\n",
      "167/167 [==============================] - 196s 1s/step - loss: 0.0083 - accuracy: 0.9979 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
      "Epoch 12/30\n",
      "167/167 [==============================] - 196s 1s/step - loss: 0.0064 - accuracy: 0.9991 - val_loss: 1.5574e-04 - val_accuracy: 1.0000\n",
      "Epoch 13/30\n",
      "167/167 [==============================] - 196s 1s/step - loss: 0.0017 - accuracy: 0.9997 - val_loss: 2.8564e-04 - val_accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "167/167 [==============================] - 196s 1s/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 8.9855e-05 - val_accuracy: 1.0000\n",
      "Epoch 15/30\n",
      "167/167 [==============================] - 197s 1s/step - loss: 0.0022 - accuracy: 0.9993 - val_loss: 1.0594e-05 - val_accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "167/167 [==============================] - 197s 1s/step - loss: 7.3206e-04 - accuracy: 0.9998 - val_loss: 2.2533e-05 - val_accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "167/167 [==============================] - 197s 1s/step - loss: 8.3072e-04 - accuracy: 0.9998 - val_loss: 6.5641e-05 - val_accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "167/167 [==============================] - 196s 1s/step - loss: 0.0016 - accuracy: 0.9992 - val_loss: 1.3417e-04 - val_accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "167/167 [==============================] - 196s 1s/step - loss: 0.0053 - accuracy: 0.9987 - val_loss: 8.2105e-05 - val_accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "167/167 [==============================] - 196s 1s/step - loss: 0.0013 - accuracy: 0.9995 - val_loss: 3.2042e-05 - val_accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "167/167 [==============================] - 196s 1s/step - loss: 9.4566e-04 - accuracy: 0.9995 - val_loss: 2.7049e-05 - val_accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "167/167 [==============================] - 197s 1s/step - loss: 8.3923e-04 - accuracy: 0.9996 - val_loss: 2.1613e-05 - val_accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "167/167 [==============================] - 197s 1s/step - loss: 5.4828e-04 - accuracy: 0.9998 - val_loss: 2.6329e-05 - val_accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "167/167 [==============================] - 197s 1s/step - loss: 0.0010 - accuracy: 0.9992 - val_loss: 3.4761e-05 - val_accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "167/167 [==============================] - 197s 1s/step - loss: 0.0012 - accuracy: 0.9991 - val_loss: 4.7371e-05 - val_accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "167/167 [==============================] - 197s 1s/step - loss: 4.9112e-04 - accuracy: 0.9997 - val_loss: 1.3243e-05 - val_accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "167/167 [==============================] - 197s 1s/step - loss: 8.7785e-04 - accuracy: 0.9995 - val_loss: 1.4714e-05 - val_accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "167/167 [==============================] - 197s 1s/step - loss: 8.1562e-04 - accuracy: 0.9993 - val_loss: 1.2930e-05 - val_accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "167/167 [==============================] - 197s 1s/step - loss: 4.0353e-04 - accuracy: 0.9998 - val_loss: 3.0991e-05 - val_accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "167/167 [==============================] - 197s 1s/step - loss: 3.2408e-04 - accuracy: 1.0000 - val_loss: 1.1008e-05 - val_accuracy: 1.0000\n",
      "INFO:tensorflow:Assets written to: ../opticnet/opticnet_30epochs_8348.4 images/assets\n",
      "Test acc for <tensorflow.python.keras.engine.functional.Functional object at 0x7f6ce58c08b0>: 0.9897\n",
      "Done!\n",
      "Training xception for 0.1% of train size (aka 8348 images)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/167 [>.............................] - ETA: 2:00 - loss: 1.3850 - accuracy: 0.3482WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1586s vs `on_train_batch_end` time: 0.5885s). Check your callbacks.\n",
      "167/167 [==============================] - 134s 772ms/step - loss: 1.3342 - accuracy: 0.7390 - val_loss: 1.2893 - val_accuracy: 0.9688\n",
      "Epoch 2/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "167/167 [==============================] - 131s 781ms/step - loss: 1.2713 - accuracy: 0.9248 - val_loss: 1.2713 - val_accuracy: 0.9688\n",
      "Epoch 3/30\n",
      "167/167 [==============================] - 130s 781ms/step - loss: 1.2491 - accuracy: 0.9362 - val_loss: 1.2555 - val_accuracy: 1.0000\n",
      "Epoch 4/30\n",
      "167/167 [==============================] - 130s 780ms/step - loss: 1.2335 - accuracy: 0.9518 - val_loss: 1.2460 - val_accuracy: 1.0000\n",
      "Epoch 5/30\n",
      "167/167 [==============================] - 130s 780ms/step - loss: 1.2182 - accuracy: 0.9623 - val_loss: 1.2380 - val_accuracy: 1.0000\n",
      "Epoch 6/30\n",
      "167/167 [==============================] - 130s 780ms/step - loss: 1.2103 - accuracy: 0.9561 - val_loss: 1.2345 - val_accuracy: 0.9688\n",
      "Epoch 7/30\n",
      "167/167 [==============================] - 129s 775ms/step - loss: 1.2008 - accuracy: 0.9644 - val_loss: 1.2261 - val_accuracy: 1.0000\n",
      "Epoch 8/30\n",
      "167/167 [==============================] - 131s 781ms/step - loss: 1.1948 - accuracy: 0.9642 - val_loss: 1.2268 - val_accuracy: 0.9688\n",
      "Epoch 9/30\n",
      "167/167 [==============================] - 130s 780ms/step - loss: 1.1890 - accuracy: 0.9642 - val_loss: 1.2241 - val_accuracy: 0.9688\n",
      "Epoch 10/30\n",
      "167/167 [==============================] - 128s 767ms/step - loss: 1.1817 - accuracy: 0.9709 - val_loss: 1.2137 - val_accuracy: 1.0000\n",
      "Epoch 11/30\n",
      "167/167 [==============================] - 127s 759ms/step - loss: 1.1765 - accuracy: 0.9734 - val_loss: 1.2127 - val_accuracy: 0.9688\n",
      "Epoch 12/30\n",
      "167/167 [==============================] - 127s 759ms/step - loss: 1.1731 - accuracy: 0.9728 - val_loss: 1.2100 - val_accuracy: 0.9688\n",
      "Epoch 13/30\n",
      "158/167 [===========================>..] - ETA: 6s - loss: 1.1690 - accuracy: 0.9750"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "maxTrain = len(y_train)\n",
    "for p in [0.1, 0.25, 0.4, 0.5, 0.6, 0.75, 0.9]:\n",
    "    #X_trn, X_tst, y_trn, y_tst\n",
    "    X_t, _, y_t, _ = train_test_split(images, y_train, test_size=1-p, random_state=123)\n",
    "    for net in [\"opticnet\", \"xception\", \"resnet\"]:\n",
    "        print(f\"Training {net} for {p}% of train size (aka {len(X_t)} images)...\")\n",
    "        model, size = emptyModelGenerator(net)\n",
    "        X_trn = resizeIms(X_t, size)\n",
    "        X_val = resizeIms(x_val, size)\n",
    "        model.compile(optimizer=optim, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "        hist = model.fit(X_trn, y_t, epochs=epochs, validation_data = (X_val, y_validation), batch_size=batch_size,\n",
    "                    shuffle=True, max_queue_size=20,\n",
    "                    use_multiprocessing=True, workers=5, \n",
    "                    callbacks=[CustomCallback(fraction=0.9, model=net)])\n",
    "        model.save(f\"../{net}/{net}_{epochs}epochs_{p*maxTrain} images\")\n",
    "        testPredict(model, size)\n",
    "        print(\"Done!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
