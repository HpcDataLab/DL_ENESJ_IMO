{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "import os\n",
    "import cv2\n",
    "import pickle\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataPath = \"../../data/OCT/OCT2017/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of Classes Detected : 4\n"
     ]
    }
   ],
   "source": [
    "labels_available = os.listdir(os.path.join(dataPath, \"train\"))\n",
    "print(\"Total Number of Classes Detected :\",len(labels_available))\n",
    "\n",
    "labels_list = ['NORMAL',\"CNV\",\"DME\",\"DRUSEN\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NORMAL CNV DME DRUSEN "
     ]
    }
   ],
   "source": [
    "images=[]\n",
    "y_trn=[]\n",
    "for x in labels_list:\n",
    "    xPath = os.path.join(dataPath, \"train\", x)\n",
    "    myPicList = os.listdir(xPath)\n",
    "    for y in myPicList:\n",
    "        images.append(cv2.imread(os.path.join(xPath, y)))\n",
    "        y_trn.append(labels_list.index(x))\n",
    "    print(x ,end=\" \")\n",
    "\n",
    "y_train = to_categorical(y_trn,len(labels_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NORMAL CNV DME DRUSEN "
     ]
    }
   ],
   "source": [
    "x_val=[]\n",
    "y_val=[]\n",
    "for x in labels_list:\n",
    "    xPath = os.path.join(dataPath, \"val\", x)\n",
    "    myPicList = os.listdir(xPath)\n",
    "    for y in myPicList:\n",
    "        x_val.append(cv2.imread(os.path.join(xPath, y)))\n",
    "        y_val.append(labels_list.index(x))\n",
    "    print(x ,end=\" \")\n",
    "\n",
    "y_validation = to_categorical(y_val,len(labels_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NORMAL CNV DME DRUSEN "
     ]
    }
   ],
   "source": [
    "x_tst=[]\n",
    "y_tst=[]\n",
    "for x in labels_list:\n",
    "    xPath = os.path.join(dataPath, \"test\", x)\n",
    "    myPicList = os.listdir(xPath)\n",
    "    for y in myPicList:\n",
    "        x_tst.append(cv2.imread(os.path.join(xPath, y)))\n",
    "        y_tst.append(labels_list.index(x))\n",
    "    print(x ,end=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resizeIm(im, size):\n",
    "    if im.shape[2] == 1:\n",
    "        im = cv2.cvtColor(im,cv2.COLOR_GRAY2RGB)\n",
    "    return cv2.resize(im, size)\n",
    "\n",
    "def resizeIms(x, size):\n",
    "    return np.array(list(map(lambda im: resizeIm(im, size), x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self,fraction, model):\n",
    "        super(CustomCallback,self).__init__()\n",
    "        self.fraction = fraction\n",
    "        self.train_a = [];\n",
    "        self.val_a =[];\n",
    "        self.logPath = os.path.join(model, \"log.txt\")\n",
    "\n",
    "        if not os.path.isdir(model):\n",
    "            os.mkdir(model)\n",
    "\n",
    "        with open(self.logPath,'w') as f:\n",
    "            f.write('Starting of logging..\\n')\n",
    "\n",
    "        self.fig = plt.figure(figsize=(4,3))\n",
    "        self.ax = plt.subplot(1,1,1)\n",
    "        plt.ion()\n",
    "\n",
    "    def on_train_begin(self,logs=None):\n",
    "        self.fig.show()\n",
    "        self.fig.canvas.draw()\n",
    "\n",
    "    def on_train_end(self,logs=None):\n",
    "        with open(self.logPath,'a') as f:\n",
    "              f.write('End of logging..\\n')\n",
    "    \n",
    "    def on_epoch_begin(self,epoch,logs=None):\n",
    "        lr= tf.keras.backend.get_value(self.model.optimizer.lr)\n",
    "        lr *= self.fraction\n",
    "        tf.keras.backend.set_value(self.model.optimizer.lr,lr)\n",
    "        with open(self.logPath,'a') as f:\n",
    "            f.write('At epoch {:02d}, learning rate changed to {:.4f}\\n'.format(epoch,lr))\n",
    "    \n",
    "    def on_epoch_end(self,epoch,logs=None):\n",
    "        val_acc = logs.get('val_accuracy')\n",
    "        train_acc = logs.get('accuracy')\n",
    "        self.train_a.append(train_acc)\n",
    "        self.val_a.append(val_acc)\n",
    "        with open(self.logPath,'a') as f:\n",
    "            f.write('At epoch {:02d}, training accuracy: {:.3f}, validation accuracy: {:.3f}\\n'.format(epoch,train_acc,val_acc))\n",
    "        self.ax.clear()\n",
    "        self.ax.plot(range(1+epoch),self.train_a,label=\"Training\")\n",
    "        self.ax.plot(range(1+epoch),self.val_a,label=\"Validation\")\n",
    "        self.ax.set_xlabel('Epochs')\n",
    "        self.ax.set_ylabel('Accuracy')\n",
    "        self.ax.legend()\n",
    "        self.fig.canvas.draw()\n",
    "        self.fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xception base model\n",
    "from tensorflow.keras.applications.xception import Xception\n",
    "from tensorflow.keras.applications.xception import preprocess_input, decode_predictions\n",
    "xceptionNetModel = Xception(weights='imagenet')\n",
    "\n",
    "# opticnet base model\n",
    "opticNetModel = tf.keras.models.load_model('../Optic_net-4_classes-Kermany2018.hdf5')\n",
    "\n",
    "# resnet base model\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "\n",
    "resNetModel = ResNet50(weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emptyModelGenerator(model, newWeights=False, lastOnly=False):\n",
    "    model = model.lower()\n",
    "    if model == \"resnet\":\n",
    "        x = resNetModel.output\n",
    "        predictions = Dense(len(labels_list), activation='softmax')(x)\n",
    "        newModel = Model(inputs=resNetModel.input, outputs=predictions)\n",
    "        size = (224, 224)\n",
    "    elif model == \"xception\":\n",
    "        x = xceptionNetModel.output\n",
    "        predictions = Dense(len(labels_list), activation='softmax')(x)\n",
    "        newModel = Model(inputs=xceptionNetModel.input, outputs=predictions)\n",
    "        size = (299, 299)\n",
    "    elif model == \"opticnet\":\n",
    "        newModel = tf.keras.models.load_model('../Optic_net-4_classes-Kermany2018.hdf5')\n",
    "        size = (224, 224)\n",
    "    if newWeights:\n",
    "        newModel = tf.keras.models.clone_model(newModel)\n",
    "    if lastOnly:\n",
    "        newModel = lastDenseTrainable(newModel) # block all layer except the last dense ones\n",
    "    return newModel, size\n",
    "\n",
    "\n",
    "def lastDenseTrainable(model):\n",
    "    model.trainable = False\n",
    "    for i in range(1, len(model.layers)):\n",
    "        if model.layers[-i].__class__.__name__ == \"Dense\":\n",
    "            model.layers[-i].trainable= True\n",
    "        elif model.layers[-i].__class__.__name__ == \"Activation\":\n",
    "            continue\n",
    "        else:\n",
    "            break\n",
    "    return model\n",
    "    \n",
    "\n",
    "def testPredict(model, size, name=None):\n",
    "    X_test = resizeIms(x_tst, size)\n",
    "    X_test = np.array(X_test)\n",
    "    Y_test = np.array(y_tst)\n",
    "    \n",
    "    prediction = model.predict(X_test)\n",
    "    preds = np.argmax(prediction, axis=1)\n",
    "    acc = sum(preds == Y_test) / len(Y_test)\n",
    "    print(f'Test acc for {name if name else \"model\"}: {acc:.6f}')\n",
    "    \n",
    "\n",
    "def computeConfussionMatrix(predictions, labels):\n",
    "    num_labels = len(labels_list)\n",
    "    cMatrix = np.zeros(shape=(num_labels, num_labels))\n",
    "    for i in len(predictions):\n",
    "        p = int(predictions[i])\n",
    "        t = int(predictions[i])\n",
    "        cMatrix[t, p] += 1\n",
    "    print(cMatrix)\n",
    "    ax = sns.heatmap(cMatrix, cmap=\"Blues\", annot=True, fmt=\"d\", xticklabels=labels_list, yticklabels=labels_list)\n",
    "    plt.xlabel(\"Predicted label\")\n",
    "    plt.ylabel(\"True label\")\n",
    "    plt.title(\"Confusion matrix\")\n",
    "    plt.show();\n",
    "    return cMatrix\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "models = [\"xception\", \"resnet\", \"opticnet\"]\n",
    "\n",
    "for mod in models:\n",
    "    print(\"\\n\\n\" + (\"*\"*50) + \"\\nModel: \" + mod + '\\n' + (\"*\"*50))\n",
    "    m = emptyModelGenerator(mod, newWeights=False, lastOnly=True)[0]\n",
    "    #m.trainable = False\n",
    "    a = 0\n",
    "    for l in m.layers:\n",
    "        #l.trainable = True\n",
    "        if l.trainable:\n",
    "            print(l.name, l.trainable)\n",
    "            a += 1\n",
    "            #print(l.trainable_weights)\n",
    "    print(f\"\\nTotal: {len(m.layers)} trainable: {a}\")\n",
    "    print(m.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "optim = Adam(learning_rate=0.001)\n",
    "epochs = 30\n",
    "batch_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels fraction: [0.09029071 0.09041795 0.08909059 0.08844011]\n",
      "Training xception for 0.09% of train size (aka 7513 images)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/151 [>.............................] - ETA: 1:27 - loss: 1.3877 - accuracy: 0.2682WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1135s vs `on_train_batch_begin` time: 0.2032s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1135s vs `on_train_batch_end` time: 0.2048s). Check your callbacks.\n",
      "151/151 [==============================] - 24s 140ms/step - loss: 1.3856 - accuracy: 0.2762 - val_loss: 1.3861 - val_accuracy: 0.2812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "151/151 [==============================] - 18s 117ms/step - loss: 1.3849 - accuracy: 0.2826 - val_loss: 1.3861 - val_accuracy: 0.2812\n",
      "Epoch 3/30\n",
      "151/151 [==============================] - 18s 119ms/step - loss: 1.3850 - accuracy: 0.2843 - val_loss: 1.3861 - val_accuracy: 0.2812\n",
      "Epoch 4/30\n",
      "151/151 [==============================] - 18s 120ms/step - loss: 1.3852 - accuracy: 0.2793 - val_loss: 1.3861 - val_accuracy: 0.2812\n",
      "Epoch 5/30\n",
      "151/151 [==============================] - 18s 121ms/step - loss: 1.3852 - accuracy: 0.2790 - val_loss: 1.3861 - val_accuracy: 0.2812\n",
      "Epoch 6/30\n",
      "151/151 [==============================] - 18s 121ms/step - loss: 1.3851 - accuracy: 0.2818 - val_loss: 1.3861 - val_accuracy: 0.2812\n",
      "Epoch 7/30\n",
      "151/151 [==============================] - 18s 122ms/step - loss: 1.3853 - accuracy: 0.2824 - val_loss: 1.3861 - val_accuracy: 0.2812\n",
      "Epoch 8/30\n",
      "151/151 [==============================] - 18s 122ms/step - loss: 1.3854 - accuracy: 0.2718 - val_loss: 1.3861 - val_accuracy: 0.2812\n",
      "Epoch 9/30\n",
      "151/151 [==============================] - 18s 122ms/step - loss: 1.3851 - accuracy: 0.2851 - val_loss: 1.3861 - val_accuracy: 0.2812\n",
      "Epoch 10/30\n",
      "151/151 [==============================] - 19s 123ms/step - loss: 1.3848 - accuracy: 0.2790 - val_loss: 1.3861 - val_accuracy: 0.2812\n",
      "Epoch 11/30\n",
      "151/151 [==============================] - 19s 123ms/step - loss: 1.3852 - accuracy: 0.2817 - val_loss: 1.3861 - val_accuracy: 0.2812\n",
      "Epoch 12/30\n",
      "151/151 [==============================] - 19s 123ms/step - loss: 1.3859 - accuracy: 0.2690 - val_loss: 1.3861 - val_accuracy: 0.2812\n",
      "Epoch 13/30\n",
      "151/151 [==============================] - 19s 123ms/step - loss: 1.3850 - accuracy: 0.2849 - val_loss: 1.3861 - val_accuracy: 0.2812\n",
      "Epoch 14/30\n",
      "151/151 [==============================] - 19s 123ms/step - loss: 1.3853 - accuracy: 0.2800 - val_loss: 1.3861 - val_accuracy: 0.2812\n",
      "Epoch 15/30\n",
      "151/151 [==============================] - 19s 123ms/step - loss: 1.3855 - accuracy: 0.2737 - val_loss: 1.3861 - val_accuracy: 0.2812\n",
      "Epoch 16/30\n",
      "151/151 [==============================] - 19s 123ms/step - loss: 1.3850 - accuracy: 0.2869 - val_loss: 1.3861 - val_accuracy: 0.2812\n",
      "Epoch 17/30\n",
      "151/151 [==============================] - 19s 123ms/step - loss: 1.3853 - accuracy: 0.2737 - val_loss: 1.3861 - val_accuracy: 0.2812\n",
      "Epoch 18/30\n",
      "151/151 [==============================] - 19s 123ms/step - loss: 1.3854 - accuracy: 0.2756 - val_loss: 1.3861 - val_accuracy: 0.2812\n",
      "Epoch 19/30\n",
      "151/151 [==============================] - 19s 123ms/step - loss: 1.3853 - accuracy: 0.2819 - val_loss: 1.3861 - val_accuracy: 0.2812\n",
      "Epoch 20/30\n",
      "151/151 [==============================] - 19s 123ms/step - loss: 1.3853 - accuracy: 0.2798 - val_loss: 1.3861 - val_accuracy: 0.2812\n",
      "Epoch 21/30\n",
      "151/151 [==============================] - 19s 123ms/step - loss: 1.3851 - accuracy: 0.2781 - val_loss: 1.3861 - val_accuracy: 0.2812\n",
      "Epoch 22/30\n",
      "151/151 [==============================] - 19s 123ms/step - loss: 1.3849 - accuracy: 0.2823 - val_loss: 1.3861 - val_accuracy: 0.2812\n",
      "Epoch 23/30\n",
      "151/151 [==============================] - 19s 123ms/step - loss: 1.3857 - accuracy: 0.2748 - val_loss: 1.3861 - val_accuracy: 0.2812\n",
      "Epoch 24/30\n",
      "151/151 [==============================] - 19s 123ms/step - loss: 1.3848 - accuracy: 0.2840 - val_loss: 1.3861 - val_accuracy: 0.2812\n",
      "Epoch 25/30\n",
      "151/151 [==============================] - 19s 123ms/step - loss: 1.3852 - accuracy: 0.2828 - val_loss: 1.3861 - val_accuracy: 0.2812\n",
      "Epoch 26/30\n",
      "151/151 [==============================] - 19s 123ms/step - loss: 1.3856 - accuracy: 0.2772 - val_loss: 1.3861 - val_accuracy: 0.2812\n",
      "Epoch 27/30\n",
      "151/151 [==============================] - 19s 123ms/step - loss: 1.3849 - accuracy: 0.2834 - val_loss: 1.3861 - val_accuracy: 0.2812\n",
      "Epoch 28/30\n",
      "151/151 [==============================] - 19s 123ms/step - loss: 1.3850 - accuracy: 0.2768 - val_loss: 1.3861 - val_accuracy: 0.2812\n",
      "Epoch 29/30\n",
      "151/151 [==============================] - 19s 123ms/step - loss: 1.3853 - accuracy: 0.2758 - val_loss: 1.3861 - val_accuracy: 0.2812\n",
      "Epoch 30/30\n",
      "151/151 [==============================] - 19s 123ms/step - loss: 1.3853 - accuracy: 0.2790 - val_loss: 1.3861 - val_accuracy: 0.2812\n",
      "INFO:tensorflow:Assets written to: ../xception/xception_30epochs_7513.5599999999995_images_False_newWeights_True_lastLayerOnly/assets\n",
      "Test acc for xception: 0.242769\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training resnet for 0.09% of train size (aka 7513 images)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/151 [>.............................] - ETA: 1:12 - loss: 1.3836 - accuracy: 0.3499WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0588s vs `on_train_batch_begin` time: 0.2007s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0588s vs `on_train_batch_end` time: 0.1695s). Check your callbacks.\n",
      "151/151 [==============================] - 16s 81ms/step - loss: 1.3837 - accuracy: 0.3173 - val_loss: 1.3874 - val_accuracy: 0.3125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "151/151 [==============================] - 9s 57ms/step - loss: 1.3835 - accuracy: 0.3178 - val_loss: 1.3874 - val_accuracy: 0.3125\n",
      "Epoch 3/30\n",
      "151/151 [==============================] - 9s 57ms/step - loss: 1.3835 - accuracy: 0.3168 - val_loss: 1.3874 - val_accuracy: 0.3125\n",
      "Epoch 4/30\n",
      "151/151 [==============================] - 9s 57ms/step - loss: 1.3837 - accuracy: 0.3190 - val_loss: 1.3874 - val_accuracy: 0.3125\n",
      "Epoch 5/30\n",
      "151/151 [==============================] - 9s 57ms/step - loss: 1.3836 - accuracy: 0.3149 - val_loss: 1.3874 - val_accuracy: 0.3125\n",
      "Epoch 6/30\n",
      "151/151 [==============================] - 9s 57ms/step - loss: 1.3834 - accuracy: 0.3250 - val_loss: 1.3874 - val_accuracy: 0.3125\n",
      "Epoch 7/30\n",
      "151/151 [==============================] - 9s 57ms/step - loss: 1.3837 - accuracy: 0.3120 - val_loss: 1.3874 - val_accuracy: 0.3125\n",
      "Epoch 8/30\n",
      "151/151 [==============================] - 9s 57ms/step - loss: 1.3838 - accuracy: 0.3153 - val_loss: 1.3874 - val_accuracy: 0.3125\n",
      "Epoch 9/30\n",
      "151/151 [==============================] - 9s 57ms/step - loss: 1.3836 - accuracy: 0.3148 - val_loss: 1.3874 - val_accuracy: 0.3125\n",
      "Epoch 10/30\n",
      "151/151 [==============================] - 9s 57ms/step - loss: 1.3834 - accuracy: 0.3198 - val_loss: 1.3874 - val_accuracy: 0.3125\n",
      "Epoch 11/30\n",
      "151/151 [==============================] - 9s 57ms/step - loss: 1.3834 - accuracy: 0.3152 - val_loss: 1.3874 - val_accuracy: 0.3125\n",
      "Epoch 12/30\n",
      "151/151 [==============================] - 9s 57ms/step - loss: 1.3834 - accuracy: 0.3131 - val_loss: 1.3874 - val_accuracy: 0.3125\n",
      "Epoch 13/30\n",
      "151/151 [==============================] - 9s 57ms/step - loss: 1.3838 - accuracy: 0.3089 - val_loss: 1.3874 - val_accuracy: 0.3125\n",
      "Epoch 14/30\n",
      "151/151 [==============================] - 9s 57ms/step - loss: 1.3837 - accuracy: 0.3159 - val_loss: 1.3874 - val_accuracy: 0.3125\n",
      "Epoch 15/30\n",
      "151/151 [==============================] - 9s 57ms/step - loss: 1.3838 - accuracy: 0.3139 - val_loss: 1.3874 - val_accuracy: 0.3125\n",
      "Epoch 16/30\n",
      "151/151 [==============================] - 9s 57ms/step - loss: 1.3834 - accuracy: 0.3259 - val_loss: 1.3874 - val_accuracy: 0.3125\n",
      "Epoch 17/30\n",
      "151/151 [==============================] - 9s 57ms/step - loss: 1.3836 - accuracy: 0.3134 - val_loss: 1.3874 - val_accuracy: 0.3125\n",
      "Epoch 18/30\n",
      "151/151 [==============================] - 9s 57ms/step - loss: 1.3836 - accuracy: 0.3187 - val_loss: 1.3874 - val_accuracy: 0.3125\n",
      "Epoch 19/30\n",
      "151/151 [==============================] - 9s 57ms/step - loss: 1.3838 - accuracy: 0.3121 - val_loss: 1.3874 - val_accuracy: 0.3125\n",
      "Epoch 20/30\n",
      "151/151 [==============================] - 9s 57ms/step - loss: 1.3839 - accuracy: 0.3074 - val_loss: 1.3874 - val_accuracy: 0.3125\n",
      "Epoch 21/30\n",
      "151/151 [==============================] - 9s 57ms/step - loss: 1.3834 - accuracy: 0.3227 - val_loss: 1.3874 - val_accuracy: 0.3125\n",
      "Epoch 22/30\n",
      "151/151 [==============================] - 9s 57ms/step - loss: 1.3834 - accuracy: 0.3145 - val_loss: 1.3874 - val_accuracy: 0.3125\n",
      "Epoch 23/30\n",
      "151/151 [==============================] - 9s 57ms/step - loss: 1.3833 - accuracy: 0.3214 - val_loss: 1.3874 - val_accuracy: 0.3125\n",
      "Epoch 24/30\n",
      "151/151 [==============================] - 9s 57ms/step - loss: 1.3836 - accuracy: 0.3150 - val_loss: 1.3874 - val_accuracy: 0.3125\n",
      "Epoch 25/30\n",
      "151/151 [==============================] - 9s 57ms/step - loss: 1.3836 - accuracy: 0.3182 - val_loss: 1.3874 - val_accuracy: 0.3125\n",
      "Epoch 26/30\n",
      "151/151 [==============================] - 9s 57ms/step - loss: 1.3835 - accuracy: 0.3137 - val_loss: 1.3874 - val_accuracy: 0.3125\n",
      "Epoch 27/30\n",
      "151/151 [==============================] - 9s 57ms/step - loss: 1.3833 - accuracy: 0.3175 - val_loss: 1.3874 - val_accuracy: 0.3125\n",
      "Epoch 28/30\n",
      "151/151 [==============================] - 9s 57ms/step - loss: 1.3831 - accuracy: 0.3279 - val_loss: 1.3874 - val_accuracy: 0.3125\n",
      "Epoch 29/30\n",
      "151/151 [==============================] - 9s 57ms/step - loss: 1.3833 - accuracy: 0.3241 - val_loss: 1.3874 - val_accuracy: 0.3125\n",
      "Epoch 30/30\n",
      "151/151 [==============================] - 9s 57ms/step - loss: 1.3834 - accuracy: 0.3256 - val_loss: 1.3874 - val_accuracy: 0.3125\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_7513.5599999999995_images_False_newWeights_True_lastLayerOnly/assets\n",
      "Test acc for resnet: 0.294421\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training opticnet for 0.09% of train size (aka 7513 images)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "151/151 [==============================] - 54s 320ms/step - loss: 289.6795 - accuracy: 0.1347 - val_loss: 217.3077 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "151/151 [==============================] - 43s 288ms/step - loss: 290.8201 - accuracy: 0.1345 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "151/151 [==============================] - 44s 289ms/step - loss: 293.8704 - accuracy: 0.1321 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "151/151 [==============================] - 44s 289ms/step - loss: 292.3050 - accuracy: 0.1293 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "151/151 [==============================] - 44s 289ms/step - loss: 290.7559 - accuracy: 0.1319 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "151/151 [==============================] - 44s 289ms/step - loss: 290.3148 - accuracy: 0.1381 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "151/151 [==============================] - 44s 289ms/step - loss: 292.9145 - accuracy: 0.1307 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "151/151 [==============================] - 44s 289ms/step - loss: 292.9000 - accuracy: 0.1341 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "151/151 [==============================] - 44s 289ms/step - loss: 294.3298 - accuracy: 0.1300 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "151/151 [==============================] - 44s 289ms/step - loss: 291.4670 - accuracy: 0.1360 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "151/151 [==============================] - 44s 289ms/step - loss: 291.5437 - accuracy: 0.1322 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "151/151 [==============================] - 44s 289ms/step - loss: 292.0527 - accuracy: 0.1359 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "151/151 [==============================] - 44s 289ms/step - loss: 294.3010 - accuracy: 0.1314 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "151/151 [==============================] - 44s 289ms/step - loss: 288.9484 - accuracy: 0.1456 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "151/151 [==============================] - 44s 289ms/step - loss: 294.3276 - accuracy: 0.1329 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "151/151 [==============================] - 44s 289ms/step - loss: 291.7879 - accuracy: 0.1338 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "151/151 [==============================] - 44s 289ms/step - loss: 293.0536 - accuracy: 0.1318 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "151/151 [==============================] - 44s 289ms/step - loss: 289.9216 - accuracy: 0.1377 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "151/151 [==============================] - 44s 289ms/step - loss: 290.8057 - accuracy: 0.1349 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "151/151 [==============================] - 44s 289ms/step - loss: 288.1902 - accuracy: 0.1382 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "151/151 [==============================] - 44s 289ms/step - loss: 287.7528 - accuracy: 0.1403 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "151/151 [==============================] - 44s 289ms/step - loss: 289.1933 - accuracy: 0.1396 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "151/151 [==============================] - 44s 289ms/step - loss: 290.6807 - accuracy: 0.1409 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "151/151 [==============================] - 44s 289ms/step - loss: 292.9821 - accuracy: 0.1292 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "151/151 [==============================] - 44s 289ms/step - loss: 289.4247 - accuracy: 0.1405 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "151/151 [==============================] - 44s 289ms/step - loss: 293.4928 - accuracy: 0.1297 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "151/151 [==============================] - 44s 289ms/step - loss: 294.3118 - accuracy: 0.1310 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "151/151 [==============================] - 44s 289ms/step - loss: 292.8785 - accuracy: 0.1366 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "151/151 [==============================] - 44s 289ms/step - loss: 294.0852 - accuracy: 0.1365 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "151/151 [==============================] - 44s 289ms/step - loss: 292.4107 - accuracy: 0.1297 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../opticnet/opticnet_30epochs_7513.5599999999995_images_False_newWeights_True_lastLayerOnly/assets\n",
      "Test acc for opticnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.10115903 0.10044349 0.09834332 0.09668059]\n",
      "Training xception for 0.1% of train size (aka 8348 images)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/167 [>.............................] - ETA: 1:37 - loss: 1.3825 - accuracy: 0.2962WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1204s vs `on_train_batch_begin` time: 0.1985s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1204s vs `on_train_batch_end` time: 0.2044s). Check your callbacks.\n",
      "167/167 [==============================] - 27s 143ms/step - loss: 1.3831 - accuracy: 0.3189 - val_loss: 1.3910 - val_accuracy: 0.2188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "167/167 [==============================] - 20s 122ms/step - loss: 1.3827 - accuracy: 0.3315 - val_loss: 1.3910 - val_accuracy: 0.2188\n",
      "Epoch 3/30\n",
      "167/167 [==============================] - 21s 123ms/step - loss: 1.3822 - accuracy: 0.3334 - val_loss: 1.3910 - val_accuracy: 0.2188\n",
      "Epoch 4/30\n",
      "167/167 [==============================] - 21s 123ms/step - loss: 1.3828 - accuracy: 0.3276 - val_loss: 1.3910 - val_accuracy: 0.2188\n",
      "Epoch 5/30\n",
      "167/167 [==============================] - 21s 124ms/step - loss: 1.3822 - accuracy: 0.3284 - val_loss: 1.3910 - val_accuracy: 0.2188\n",
      "Epoch 6/30\n",
      "167/167 [==============================] - 21s 124ms/step - loss: 1.3821 - accuracy: 0.3315 - val_loss: 1.3910 - val_accuracy: 0.2188\n",
      "Epoch 7/30\n",
      "167/167 [==============================] - 21s 124ms/step - loss: 1.3828 - accuracy: 0.3287 - val_loss: 1.3910 - val_accuracy: 0.2188\n",
      "Epoch 8/30\n",
      "167/167 [==============================] - 21s 124ms/step - loss: 1.3826 - accuracy: 0.3301 - val_loss: 1.3910 - val_accuracy: 0.2188\n",
      "Epoch 9/30\n",
      "167/167 [==============================] - 21s 124ms/step - loss: 1.3831 - accuracy: 0.3262 - val_loss: 1.3910 - val_accuracy: 0.2188\n",
      "Epoch 10/30\n",
      "167/167 [==============================] - 21s 124ms/step - loss: 1.3827 - accuracy: 0.3295 - val_loss: 1.3910 - val_accuracy: 0.2188\n",
      "Epoch 11/30\n",
      "167/167 [==============================] - 21s 124ms/step - loss: 1.3822 - accuracy: 0.3296 - val_loss: 1.3910 - val_accuracy: 0.2188\n",
      "Epoch 12/30\n",
      "167/167 [==============================] - 21s 124ms/step - loss: 1.3828 - accuracy: 0.3276 - val_loss: 1.3910 - val_accuracy: 0.2188\n",
      "Epoch 13/30\n",
      "167/167 [==============================] - 21s 124ms/step - loss: 1.3829 - accuracy: 0.3289 - val_loss: 1.3910 - val_accuracy: 0.2188\n",
      "Epoch 14/30\n",
      "167/167 [==============================] - 21s 124ms/step - loss: 1.3820 - accuracy: 0.3318 - val_loss: 1.3910 - val_accuracy: 0.2188\n",
      "Epoch 15/30\n",
      "167/167 [==============================] - 21s 124ms/step - loss: 1.3828 - accuracy: 0.3256 - val_loss: 1.3910 - val_accuracy: 0.2188\n",
      "Epoch 16/30\n",
      "167/167 [==============================] - 21s 124ms/step - loss: 1.3826 - accuracy: 0.3284 - val_loss: 1.3910 - val_accuracy: 0.2188\n",
      "Epoch 17/30\n",
      "167/167 [==============================] - 21s 124ms/step - loss: 1.3822 - accuracy: 0.3365 - val_loss: 1.3910 - val_accuracy: 0.2188\n",
      "Epoch 18/30\n",
      "167/167 [==============================] - 21s 124ms/step - loss: 1.3821 - accuracy: 0.3300 - val_loss: 1.3910 - val_accuracy: 0.2188\n",
      "Epoch 19/30\n",
      "167/167 [==============================] - 21s 124ms/step - loss: 1.3817 - accuracy: 0.3353 - val_loss: 1.3910 - val_accuracy: 0.2188\n",
      "Epoch 20/30\n",
      "167/167 [==============================] - 21s 125ms/step - loss: 1.3824 - accuracy: 0.3268 - val_loss: 1.3910 - val_accuracy: 0.2188\n",
      "Epoch 21/30\n",
      "167/167 [==============================] - 21s 124ms/step - loss: 1.3828 - accuracy: 0.3220 - val_loss: 1.3910 - val_accuracy: 0.2188\n",
      "Epoch 22/30\n",
      "167/167 [==============================] - 21s 124ms/step - loss: 1.3831 - accuracy: 0.3219 - val_loss: 1.3910 - val_accuracy: 0.2188\n",
      "Epoch 23/30\n",
      "167/167 [==============================] - 21s 124ms/step - loss: 1.3813 - accuracy: 0.3354 - val_loss: 1.3910 - val_accuracy: 0.2188\n",
      "Epoch 24/30\n",
      "167/167 [==============================] - 21s 124ms/step - loss: 1.3825 - accuracy: 0.3313 - val_loss: 1.3910 - val_accuracy: 0.2188\n",
      "Epoch 25/30\n",
      "167/167 [==============================] - 21s 124ms/step - loss: 1.3825 - accuracy: 0.3300 - val_loss: 1.3910 - val_accuracy: 0.2188\n",
      "Epoch 26/30\n",
      "167/167 [==============================] - 21s 124ms/step - loss: 1.3825 - accuracy: 0.3284 - val_loss: 1.3910 - val_accuracy: 0.2188\n",
      "Epoch 27/30\n",
      "167/167 [==============================] - 21s 124ms/step - loss: 1.3822 - accuracy: 0.3337 - val_loss: 1.3910 - val_accuracy: 0.2188\n",
      "Epoch 28/30\n",
      "167/167 [==============================] - 21s 124ms/step - loss: 1.3832 - accuracy: 0.3265 - val_loss: 1.3910 - val_accuracy: 0.2188\n",
      "Epoch 29/30\n",
      "167/167 [==============================] - 21s 124ms/step - loss: 1.3825 - accuracy: 0.3264 - val_loss: 1.3910 - val_accuracy: 0.2188\n",
      "Epoch 30/30\n",
      "167/167 [==============================] - 21s 124ms/step - loss: 1.3818 - accuracy: 0.3321 - val_loss: 1.3910 - val_accuracy: 0.2188\n",
      "INFO:tensorflow:Assets written to: ../xception/xception_30epochs_8348.4_images_False_newWeights_True_lastLayerOnly/assets\n",
      "Test acc for xception: 0.255165\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training resnet for 0.1% of train size (aka 8348 images)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/167 [>.............................] - ETA: 1:25 - loss: 1.3873 - accuracy: 0.1877WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0602s vs `on_train_batch_begin` time: 0.2046s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0602s vs `on_train_batch_end` time: 0.1869s). Check your callbacks.\n",
      "167/167 [==============================] - 17s 80ms/step - loss: 1.3877 - accuracy: 0.1921 - val_loss: 1.3879 - val_accuracy: 0.1875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "167/167 [==============================] - 10s 57ms/step - loss: 1.3878 - accuracy: 0.1885 - val_loss: 1.3879 - val_accuracy: 0.1875\n",
      "Epoch 3/30\n",
      "167/167 [==============================] - 10s 57ms/step - loss: 1.3880 - accuracy: 0.1890 - val_loss: 1.3879 - val_accuracy: 0.1875\n",
      "Epoch 4/30\n",
      "167/167 [==============================] - 10s 58ms/step - loss: 1.3880 - accuracy: 0.1842 - val_loss: 1.3879 - val_accuracy: 0.1875\n",
      "Epoch 5/30\n",
      "167/167 [==============================] - 10s 58ms/step - loss: 1.3879 - accuracy: 0.1914 - val_loss: 1.3879 - val_accuracy: 0.1875\n",
      "Epoch 6/30\n",
      "167/167 [==============================] - 10s 58ms/step - loss: 1.3879 - accuracy: 0.1941 - val_loss: 1.3879 - val_accuracy: 0.1875\n",
      "Epoch 7/30\n",
      "167/167 [==============================] - 10s 58ms/step - loss: 1.3882 - accuracy: 0.1862 - val_loss: 1.3879 - val_accuracy: 0.1875\n",
      "Epoch 8/30\n",
      "167/167 [==============================] - 10s 58ms/step - loss: 1.3877 - accuracy: 0.1927 - val_loss: 1.3879 - val_accuracy: 0.1875\n",
      "Epoch 9/30\n",
      "167/167 [==============================] - 10s 58ms/step - loss: 1.3878 - accuracy: 0.1966 - val_loss: 1.3879 - val_accuracy: 0.1875\n",
      "Epoch 10/30\n",
      "167/167 [==============================] - 10s 58ms/step - loss: 1.3878 - accuracy: 0.1913 - val_loss: 1.3879 - val_accuracy: 0.1875\n",
      "Epoch 11/30\n",
      "167/167 [==============================] - 10s 58ms/step - loss: 1.3877 - accuracy: 0.1938 - val_loss: 1.3879 - val_accuracy: 0.1875\n",
      "Epoch 12/30\n",
      "167/167 [==============================] - 10s 58ms/step - loss: 1.3878 - accuracy: 0.1916 - val_loss: 1.3879 - val_accuracy: 0.1875\n",
      "Epoch 13/30\n",
      "167/167 [==============================] - 10s 58ms/step - loss: 1.3882 - accuracy: 0.1863 - val_loss: 1.3879 - val_accuracy: 0.1875\n",
      "Epoch 14/30\n",
      "167/167 [==============================] - 10s 58ms/step - loss: 1.3879 - accuracy: 0.1894 - val_loss: 1.3879 - val_accuracy: 0.1875\n",
      "Epoch 15/30\n",
      "167/167 [==============================] - 10s 58ms/step - loss: 1.3876 - accuracy: 0.1938 - val_loss: 1.3879 - val_accuracy: 0.1875\n",
      "Epoch 16/30\n",
      "167/167 [==============================] - 10s 58ms/step - loss: 1.3877 - accuracy: 0.1942 - val_loss: 1.3879 - val_accuracy: 0.1875\n",
      "Epoch 17/30\n",
      "167/167 [==============================] - 10s 58ms/step - loss: 1.3880 - accuracy: 0.1895 - val_loss: 1.3879 - val_accuracy: 0.1875\n",
      "Epoch 18/30\n",
      "167/167 [==============================] - 10s 58ms/step - loss: 1.3878 - accuracy: 0.1917 - val_loss: 1.3879 - val_accuracy: 0.1875\n",
      "Epoch 19/30\n",
      "167/167 [==============================] - 10s 58ms/step - loss: 1.3881 - accuracy: 0.1838 - val_loss: 1.3879 - val_accuracy: 0.1875\n",
      "Epoch 20/30\n",
      "167/167 [==============================] - 10s 58ms/step - loss: 1.3878 - accuracy: 0.1906 - val_loss: 1.3879 - val_accuracy: 0.1875\n",
      "Epoch 21/30\n",
      "167/167 [==============================] - 10s 58ms/step - loss: 1.3879 - accuracy: 0.1872 - val_loss: 1.3879 - val_accuracy: 0.1875\n",
      "Epoch 22/30\n",
      "167/167 [==============================] - 10s 58ms/step - loss: 1.3880 - accuracy: 0.1909 - val_loss: 1.3879 - val_accuracy: 0.1875\n",
      "Epoch 23/30\n",
      "167/167 [==============================] - 10s 58ms/step - loss: 1.3879 - accuracy: 0.1870 - val_loss: 1.3879 - val_accuracy: 0.1875\n",
      "Epoch 24/30\n",
      "167/167 [==============================] - 10s 58ms/step - loss: 1.3878 - accuracy: 0.1887 - val_loss: 1.3879 - val_accuracy: 0.1875\n",
      "Epoch 25/30\n",
      "167/167 [==============================] - 10s 58ms/step - loss: 1.3877 - accuracy: 0.1899 - val_loss: 1.3879 - val_accuracy: 0.1875\n",
      "Epoch 26/30\n",
      "167/167 [==============================] - 10s 58ms/step - loss: 1.3878 - accuracy: 0.1891 - val_loss: 1.3879 - val_accuracy: 0.1875\n",
      "Epoch 27/30\n",
      "167/167 [==============================] - 10s 58ms/step - loss: 1.3879 - accuracy: 0.1917 - val_loss: 1.3879 - val_accuracy: 0.1875\n",
      "Epoch 28/30\n",
      "167/167 [==============================] - 10s 58ms/step - loss: 1.3879 - accuracy: 0.1957 - val_loss: 1.3879 - val_accuracy: 0.1875\n",
      "Epoch 29/30\n",
      "167/167 [==============================] - 10s 58ms/step - loss: 1.3877 - accuracy: 0.1990 - val_loss: 1.3879 - val_accuracy: 0.1875\n",
      "Epoch 30/30\n",
      "167/167 [==============================] - 10s 58ms/step - loss: 1.3878 - accuracy: 0.1935 - val_loss: 1.3879 - val_accuracy: 0.1875\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_8348.4_images_False_newWeights_True_lastLayerOnly/assets\n",
      "Test acc for resnet: 0.282025\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training opticnet for 0.1% of train size (aka 8348 images)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "167/167 [==============================] - 59s 319ms/step - loss: 290.2069 - accuracy: 0.1365 - val_loss: 217.3077 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "167/167 [==============================] - 48s 290ms/step - loss: 292.6784 - accuracy: 0.1325 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "167/167 [==============================] - 48s 290ms/step - loss: 294.7957 - accuracy: 0.1317 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "167/167 [==============================] - 48s 290ms/step - loss: 292.8738 - accuracy: 0.1388 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "167/167 [==============================] - 48s 290ms/step - loss: 294.3004 - accuracy: 0.1332 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "167/167 [==============================] - 49s 291ms/step - loss: 288.1158 - accuracy: 0.1378 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "167/167 [==============================] - 49s 291ms/step - loss: 292.8956 - accuracy: 0.1312 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "167/167 [==============================] - 48s 290ms/step - loss: 288.8946 - accuracy: 0.1378 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "167/167 [==============================] - 49s 290ms/step - loss: 292.6988 - accuracy: 0.1359 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "167/167 [==============================] - 48s 290ms/step - loss: 292.5761 - accuracy: 0.1316 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "167/167 [==============================] - 49s 290ms/step - loss: 292.8405 - accuracy: 0.1334 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "167/167 [==============================] - 49s 291ms/step - loss: 294.0252 - accuracy: 0.1280 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "167/167 [==============================] - 49s 291ms/step - loss: 291.2508 - accuracy: 0.1406 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "167/167 [==============================] - 49s 291ms/step - loss: 293.0966 - accuracy: 0.1266 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "167/167 [==============================] - 48s 290ms/step - loss: 294.2219 - accuracy: 0.1302 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "167/167 [==============================] - 48s 290ms/step - loss: 294.0299 - accuracy: 0.1363 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "167/167 [==============================] - 48s 290ms/step - loss: 294.3952 - accuracy: 0.1313 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "167/167 [==============================] - 49s 290ms/step - loss: 289.3485 - accuracy: 0.1393 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "167/167 [==============================] - 48s 290ms/step - loss: 294.6349 - accuracy: 0.1347 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "167/167 [==============================] - 48s 290ms/step - loss: 289.9324 - accuracy: 0.1305 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "167/167 [==============================] - 48s 290ms/step - loss: 294.6325 - accuracy: 0.1312 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "167/167 [==============================] - 48s 290ms/step - loss: 295.1054 - accuracy: 0.1280 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "167/167 [==============================] - 48s 290ms/step - loss: 292.3767 - accuracy: 0.1372 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "167/167 [==============================] - 48s 290ms/step - loss: 293.2896 - accuracy: 0.1333 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "167/167 [==============================] - 49s 290ms/step - loss: 292.6677 - accuracy: 0.1327 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "167/167 [==============================] - 48s 290ms/step - loss: 295.3037 - accuracy: 0.1323 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "167/167 [==============================] - 48s 290ms/step - loss: 295.1253 - accuracy: 0.1287 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "167/167 [==============================] - 49s 290ms/step - loss: 290.4227 - accuracy: 0.1326 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "167/167 [==============================] - 48s 290ms/step - loss: 292.6102 - accuracy: 0.1325 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "167/167 [==============================] - 48s 290ms/step - loss: 292.7001 - accuracy: 0.1316 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../opticnet/opticnet_30epochs_8348.4_images_False_newWeights_True_lastLayerOnly/assets\n",
      "Test acc for opticnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.25069352 0.25362183 0.24735636 0.23572423]\n",
      "Training xception for 0.25% of train size (aka 20871 images)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/418 [..............................] - ETA: 3:49 - loss: 1.4000 - accuracy: 0.1203WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1214s vs `on_train_batch_begin` time: 0.1352s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1214s vs `on_train_batch_end` time: 0.2284s). Check your callbacks.\n",
      "418/418 [==============================] - 57s 129ms/step - loss: 1.3990 - accuracy: 0.1376 - val_loss: 1.3909 - val_accuracy: 0.2188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "418/418 [==============================] - 51s 123ms/step - loss: 1.3992 - accuracy: 0.1387 - val_loss: 1.3909 - val_accuracy: 0.2188\n",
      "Epoch 3/30\n",
      "418/418 [==============================] - 52s 123ms/step - loss: 1.3990 - accuracy: 0.1370 - val_loss: 1.3909 - val_accuracy: 0.2188\n",
      "Epoch 4/30\n",
      "418/418 [==============================] - 52s 124ms/step - loss: 1.3991 - accuracy: 0.1347 - val_loss: 1.3909 - val_accuracy: 0.2188\n",
      "Epoch 5/30\n",
      "418/418 [==============================] - 52s 124ms/step - loss: 1.3989 - accuracy: 0.1389 - val_loss: 1.3909 - val_accuracy: 0.2188\n",
      "Epoch 6/30\n",
      "418/418 [==============================] - 52s 124ms/step - loss: 1.3993 - accuracy: 0.1349 - val_loss: 1.3909 - val_accuracy: 0.2188\n",
      "Epoch 7/30\n",
      "418/418 [==============================] - 52s 124ms/step - loss: 1.3990 - accuracy: 0.1369 - val_loss: 1.3909 - val_accuracy: 0.2188\n",
      "Epoch 8/30\n",
      "418/418 [==============================] - 52s 124ms/step - loss: 1.3987 - accuracy: 0.1407 - val_loss: 1.3909 - val_accuracy: 0.2188\n",
      "Epoch 9/30\n",
      "418/418 [==============================] - 52s 124ms/step - loss: 1.3993 - accuracy: 0.1347 - val_loss: 1.3909 - val_accuracy: 0.2188\n",
      "Epoch 10/30\n",
      "418/418 [==============================] - 52s 124ms/step - loss: 1.3990 - accuracy: 0.1373 - val_loss: 1.3909 - val_accuracy: 0.2188\n",
      "Epoch 11/30\n",
      "418/418 [==============================] - 52s 124ms/step - loss: 1.3988 - accuracy: 0.1401 - val_loss: 1.3909 - val_accuracy: 0.2188\n",
      "Epoch 12/30\n",
      "418/418 [==============================] - 52s 124ms/step - loss: 1.3989 - accuracy: 0.1415 - val_loss: 1.3909 - val_accuracy: 0.2188\n",
      "Epoch 13/30\n",
      "418/418 [==============================] - 52s 124ms/step - loss: 1.3991 - accuracy: 0.1358 - val_loss: 1.3909 - val_accuracy: 0.2188\n",
      "Epoch 14/30\n",
      "418/418 [==============================] - 52s 124ms/step - loss: 1.3988 - accuracy: 0.1396 - val_loss: 1.3909 - val_accuracy: 0.2188\n",
      "Epoch 15/30\n",
      "418/418 [==============================] - 52s 124ms/step - loss: 1.3986 - accuracy: 0.1437 - val_loss: 1.3909 - val_accuracy: 0.2188\n",
      "Epoch 16/30\n",
      "418/418 [==============================] - 52s 124ms/step - loss: 1.3992 - accuracy: 0.1340 - val_loss: 1.3909 - val_accuracy: 0.2188\n",
      "Epoch 17/30\n",
      "418/418 [==============================] - 52s 124ms/step - loss: 1.3993 - accuracy: 0.1361 - val_loss: 1.3909 - val_accuracy: 0.2188\n",
      "Epoch 18/30\n",
      "418/418 [==============================] - 52s 124ms/step - loss: 1.3990 - accuracy: 0.1364 - val_loss: 1.3909 - val_accuracy: 0.2188\n",
      "Epoch 19/30\n",
      "418/418 [==============================] - 52s 124ms/step - loss: 1.3992 - accuracy: 0.1364 - val_loss: 1.3909 - val_accuracy: 0.2188\n",
      "Epoch 20/30\n",
      "418/418 [==============================] - 52s 124ms/step - loss: 1.3990 - accuracy: 0.1401 - val_loss: 1.3909 - val_accuracy: 0.2188\n",
      "Epoch 21/30\n",
      "418/418 [==============================] - 52s 124ms/step - loss: 1.3990 - accuracy: 0.1392 - val_loss: 1.3909 - val_accuracy: 0.2188\n",
      "Epoch 22/30\n",
      "418/418 [==============================] - 52s 124ms/step - loss: 1.3990 - accuracy: 0.1389 - val_loss: 1.3909 - val_accuracy: 0.2188\n",
      "Epoch 23/30\n",
      "418/418 [==============================] - 52s 124ms/step - loss: 1.3990 - accuracy: 0.1383 - val_loss: 1.3909 - val_accuracy: 0.2188\n",
      "Epoch 24/30\n",
      "418/418 [==============================] - 52s 124ms/step - loss: 1.3988 - accuracy: 0.1409 - val_loss: 1.3909 - val_accuracy: 0.2188\n",
      "Epoch 25/30\n",
      "418/418 [==============================] - 52s 124ms/step - loss: 1.3993 - accuracy: 0.1376 - val_loss: 1.3909 - val_accuracy: 0.2188\n",
      "Epoch 26/30\n",
      "418/418 [==============================] - 52s 124ms/step - loss: 1.3988 - accuracy: 0.1382 - val_loss: 1.3909 - val_accuracy: 0.2188\n",
      "Epoch 27/30\n",
      "418/418 [==============================] - 52s 124ms/step - loss: 1.3990 - accuracy: 0.1355 - val_loss: 1.3909 - val_accuracy: 0.2188\n",
      "Epoch 28/30\n",
      "418/418 [==============================] - 52s 124ms/step - loss: 1.3990 - accuracy: 0.1388 - val_loss: 1.3909 - val_accuracy: 0.2188\n",
      "Epoch 29/30\n",
      "418/418 [==============================] - 52s 124ms/step - loss: 1.3988 - accuracy: 0.1407 - val_loss: 1.3909 - val_accuracy: 0.2188\n",
      "Epoch 30/30\n",
      "418/418 [==============================] - 52s 124ms/step - loss: 1.3992 - accuracy: 0.1371 - val_loss: 1.3909 - val_accuracy: 0.2188\n",
      "INFO:tensorflow:Assets written to: ../xception/xception_30epochs_20871.0_images_False_newWeights_True_lastLayerOnly/assets\n",
      "Test acc for xception: 0.245868\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training resnet for 0.25% of train size (aka 20871 images)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/418 [..............................] - ETA: 3:41 - loss: 1.3887 - accuracy: 0.2280WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0615s vs `on_train_batch_begin` time: 0.2066s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0615s vs `on_train_batch_end` time: 0.1910s). Check your callbacks.\n",
      "418/418 [==============================] - 31s 66ms/step - loss: 1.3862 - accuracy: 0.2557 - val_loss: 1.3843 - val_accuracy: 0.1875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "418/418 [==============================] - 24s 57ms/step - loss: 1.3857 - accuracy: 0.2708 - val_loss: 1.3843 - val_accuracy: 0.1875\n",
      "Epoch 3/30\n",
      "418/418 [==============================] - 24s 57ms/step - loss: 1.3858 - accuracy: 0.2695 - val_loss: 1.3843 - val_accuracy: 0.1875\n",
      "Epoch 4/30\n",
      "418/418 [==============================] - 24s 57ms/step - loss: 1.3859 - accuracy: 0.2635 - val_loss: 1.3843 - val_accuracy: 0.1875\n",
      "Epoch 5/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3861 - accuracy: 0.2603 - val_loss: 1.3843 - val_accuracy: 0.1875\n",
      "Epoch 6/30\n",
      "418/418 [==============================] - 24s 57ms/step - loss: 1.3861 - accuracy: 0.2642 - val_loss: 1.3843 - val_accuracy: 0.1875\n",
      "Epoch 7/30\n",
      "418/418 [==============================] - 24s 57ms/step - loss: 1.3859 - accuracy: 0.2624 - val_loss: 1.3843 - val_accuracy: 0.1875\n",
      "Epoch 8/30\n",
      "418/418 [==============================] - 24s 57ms/step - loss: 1.3858 - accuracy: 0.2635 - val_loss: 1.3843 - val_accuracy: 0.1875\n",
      "Epoch 9/30\n",
      "418/418 [==============================] - 24s 57ms/step - loss: 1.3859 - accuracy: 0.2640 - val_loss: 1.3843 - val_accuracy: 0.1875\n",
      "Epoch 10/30\n",
      "418/418 [==============================] - 24s 57ms/step - loss: 1.3861 - accuracy: 0.2576 - val_loss: 1.3843 - val_accuracy: 0.1875\n",
      "Epoch 11/30\n",
      "418/418 [==============================] - 24s 57ms/step - loss: 1.3859 - accuracy: 0.2623 - val_loss: 1.3843 - val_accuracy: 0.1875\n",
      "Epoch 12/30\n",
      "418/418 [==============================] - 24s 57ms/step - loss: 1.3861 - accuracy: 0.2562 - val_loss: 1.3843 - val_accuracy: 0.1875\n",
      "Epoch 13/30\n",
      "418/418 [==============================] - 24s 57ms/step - loss: 1.3862 - accuracy: 0.2612 - val_loss: 1.3843 - val_accuracy: 0.1875\n",
      "Epoch 14/30\n",
      "418/418 [==============================] - 24s 57ms/step - loss: 1.3860 - accuracy: 0.2649 - val_loss: 1.3843 - val_accuracy: 0.1875\n",
      "Epoch 15/30\n",
      "418/418 [==============================] - 24s 57ms/step - loss: 1.3862 - accuracy: 0.2565 - val_loss: 1.3843 - val_accuracy: 0.1875\n",
      "Epoch 16/30\n",
      "418/418 [==============================] - 24s 57ms/step - loss: 1.3858 - accuracy: 0.2637 - val_loss: 1.3843 - val_accuracy: 0.1875\n",
      "Epoch 17/30\n",
      "418/418 [==============================] - 24s 57ms/step - loss: 1.3860 - accuracy: 0.2615 - val_loss: 1.3843 - val_accuracy: 0.1875\n",
      "Epoch 18/30\n",
      "418/418 [==============================] - 24s 57ms/step - loss: 1.3860 - accuracy: 0.2601 - val_loss: 1.3843 - val_accuracy: 0.1875\n",
      "Epoch 19/30\n",
      "418/418 [==============================] - 24s 57ms/step - loss: 1.3859 - accuracy: 0.2645 - val_loss: 1.3843 - val_accuracy: 0.1875\n",
      "Epoch 20/30\n",
      "418/418 [==============================] - 24s 57ms/step - loss: 1.3861 - accuracy: 0.2596 - val_loss: 1.3843 - val_accuracy: 0.1875\n",
      "Epoch 21/30\n",
      "418/418 [==============================] - 24s 57ms/step - loss: 1.3862 - accuracy: 0.2591 - val_loss: 1.3843 - val_accuracy: 0.1875\n",
      "Epoch 22/30\n",
      "418/418 [==============================] - 24s 57ms/step - loss: 1.3861 - accuracy: 0.2616 - val_loss: 1.3843 - val_accuracy: 0.1875\n",
      "Epoch 23/30\n",
      "418/418 [==============================] - 24s 57ms/step - loss: 1.3859 - accuracy: 0.2640 - val_loss: 1.3843 - val_accuracy: 0.1875\n",
      "Epoch 24/30\n",
      "418/418 [==============================] - 24s 57ms/step - loss: 1.3861 - accuracy: 0.2580 - val_loss: 1.3843 - val_accuracy: 0.1875\n",
      "Epoch 25/30\n",
      "418/418 [==============================] - 24s 57ms/step - loss: 1.3860 - accuracy: 0.2623 - val_loss: 1.3843 - val_accuracy: 0.1875\n",
      "Epoch 26/30\n",
      "418/418 [==============================] - 24s 57ms/step - loss: 1.3859 - accuracy: 0.2622 - val_loss: 1.3843 - val_accuracy: 0.1875\n",
      "Epoch 27/30\n",
      "418/418 [==============================] - 24s 57ms/step - loss: 1.3862 - accuracy: 0.2573 - val_loss: 1.3843 - val_accuracy: 0.1875\n",
      "Epoch 28/30\n",
      "418/418 [==============================] - 24s 57ms/step - loss: 1.3859 - accuracy: 0.2647 - val_loss: 1.3843 - val_accuracy: 0.1875\n",
      "Epoch 29/30\n",
      "418/418 [==============================] - 24s 57ms/step - loss: 1.3860 - accuracy: 0.2587 - val_loss: 1.3843 - val_accuracy: 0.1875\n",
      "Epoch 30/30\n",
      "418/418 [==============================] - 24s 57ms/step - loss: 1.3859 - accuracy: 0.2648 - val_loss: 1.3843 - val_accuracy: 0.1875\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_20871.0_images_False_newWeights_True_lastLayerOnly/assets\n",
      "Test acc for resnet: 0.238636\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training opticnet for 0.25% of train size (aka 20871 images)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "418/418 [==============================] - 131s 300ms/step - loss: 293.5216 - accuracy: 0.1318 - val_loss: 217.3077 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "418/418 [==============================] - 121s 288ms/step - loss: 287.9570 - accuracy: 0.1382 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "418/418 [==============================] - 121s 289ms/step - loss: 291.0729 - accuracy: 0.1358 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "418/418 [==============================] - 121s 289ms/step - loss: 291.3672 - accuracy: 0.1315 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "418/418 [==============================] - 121s 289ms/step - loss: 291.8699 - accuracy: 0.1316 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "418/418 [==============================] - 121s 288ms/step - loss: 290.2654 - accuracy: 0.1346 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "418/418 [==============================] - 121s 288ms/step - loss: 290.5710 - accuracy: 0.1355 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "418/418 [==============================] - 121s 288ms/step - loss: 291.3544 - accuracy: 0.1340 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "418/418 [==============================] - 121s 288ms/step - loss: 290.9642 - accuracy: 0.1367 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "418/418 [==============================] - 121s 288ms/step - loss: 292.9332 - accuracy: 0.1324 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "418/418 [==============================] - 121s 289ms/step - loss: 292.9989 - accuracy: 0.1357 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "418/418 [==============================] - 121s 288ms/step - loss: 289.0414 - accuracy: 0.1369 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "418/418 [==============================] - 121s 288ms/step - loss: 291.9919 - accuracy: 0.1347 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "418/418 [==============================] - 121s 288ms/step - loss: 291.6181 - accuracy: 0.1369 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "418/418 [==============================] - 121s 288ms/step - loss: 290.9478 - accuracy: 0.1374 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "418/418 [==============================] - 121s 288ms/step - loss: 291.7834 - accuracy: 0.1317 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "418/418 [==============================] - 121s 288ms/step - loss: 290.8767 - accuracy: 0.1367 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "418/418 [==============================] - 121s 288ms/step - loss: 288.6395 - accuracy: 0.1372 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "418/418 [==============================] - 121s 289ms/step - loss: 290.6779 - accuracy: 0.1374 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "418/418 [==============================] - 120s 288ms/step - loss: 291.1799 - accuracy: 0.1311 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "418/418 [==============================] - 121s 288ms/step - loss: 290.1284 - accuracy: 0.1354 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "418/418 [==============================] - 121s 288ms/step - loss: 292.6382 - accuracy: 0.1320 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "418/418 [==============================] - 121s 288ms/step - loss: 291.8832 - accuracy: 0.1345 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "418/418 [==============================] - 121s 288ms/step - loss: 292.3032 - accuracy: 0.1344 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "418/418 [==============================] - 121s 288ms/step - loss: 293.1582 - accuracy: 0.1314 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "418/418 [==============================] - 121s 288ms/step - loss: 291.8971 - accuracy: 0.1325 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "418/418 [==============================] - 121s 288ms/step - loss: 291.7994 - accuracy: 0.1348 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "418/418 [==============================] - 121s 288ms/step - loss: 293.2871 - accuracy: 0.1309 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "418/418 [==============================] - 121s 289ms/step - loss: 291.8718 - accuracy: 0.1320 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "418/418 [==============================] - 121s 288ms/step - loss: 289.2733 - accuracy: 0.1331 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../opticnet/opticnet_30epochs_20871.0_images_False_newWeights_True_lastLayerOnly/assets\n",
      "Test acc for opticnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.39840395 0.40263405 0.40033486 0.39298979]\n",
      "Training xception for 0.4% of train size (aka 33393 images)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/668 [..............................] - ETA: 6:34 - loss: 1.3984 - accuracy: 0.2132WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1174s vs `on_train_batch_begin` time: 0.1989s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1174s vs `on_train_batch_end` time: 0.2003s). Check your callbacks.\n",
      "668/668 [==============================] - 88s 127ms/step - loss: 1.3925 - accuracy: 0.2841 - val_loss: 1.3866 - val_accuracy: 0.3125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "668/668 [==============================] - 83s 124ms/step - loss: 1.3926 - accuracy: 0.2829 - val_loss: 1.3866 - val_accuracy: 0.3125\n",
      "Epoch 3/30\n",
      "668/668 [==============================] - 83s 124ms/step - loss: 1.3928 - accuracy: 0.2826 - val_loss: 1.3866 - val_accuracy: 0.3125\n",
      "Epoch 4/30\n",
      "668/668 [==============================] - 83s 124ms/step - loss: 1.3925 - accuracy: 0.2848 - val_loss: 1.3866 - val_accuracy: 0.3125\n",
      "Epoch 5/30\n",
      "668/668 [==============================] - 83s 124ms/step - loss: 1.3921 - accuracy: 0.2872 - val_loss: 1.3866 - val_accuracy: 0.3125\n",
      "Epoch 6/30\n",
      "668/668 [==============================] - 83s 124ms/step - loss: 1.3929 - accuracy: 0.2789 - val_loss: 1.3866 - val_accuracy: 0.3125\n",
      "Epoch 7/30\n",
      "668/668 [==============================] - 83s 124ms/step - loss: 1.3926 - accuracy: 0.2842 - val_loss: 1.3866 - val_accuracy: 0.3125\n",
      "Epoch 8/30\n",
      "668/668 [==============================] - 83s 124ms/step - loss: 1.3928 - accuracy: 0.2823 - val_loss: 1.3866 - val_accuracy: 0.3125\n",
      "Epoch 9/30\n",
      "668/668 [==============================] - 83s 124ms/step - loss: 1.3925 - accuracy: 0.2843 - val_loss: 1.3866 - val_accuracy: 0.3125\n",
      "Epoch 10/30\n",
      "668/668 [==============================] - 83s 124ms/step - loss: 1.3927 - accuracy: 0.2810 - val_loss: 1.3866 - val_accuracy: 0.3125\n",
      "Epoch 11/30\n",
      "668/668 [==============================] - 83s 124ms/step - loss: 1.3923 - accuracy: 0.2856 - val_loss: 1.3866 - val_accuracy: 0.3125\n",
      "Epoch 12/30\n",
      "668/668 [==============================] - 83s 124ms/step - loss: 1.3922 - accuracy: 0.2871 - val_loss: 1.3866 - val_accuracy: 0.3125\n",
      "Epoch 13/30\n",
      "668/668 [==============================] - 83s 124ms/step - loss: 1.3930 - accuracy: 0.2786 - val_loss: 1.3866 - val_accuracy: 0.3125\n",
      "Epoch 14/30\n",
      "668/668 [==============================] - 83s 124ms/step - loss: 1.3926 - accuracy: 0.2829 - val_loss: 1.3866 - val_accuracy: 0.3125\n",
      "Epoch 15/30\n",
      "668/668 [==============================] - 83s 124ms/step - loss: 1.3928 - accuracy: 0.2805 - val_loss: 1.3866 - val_accuracy: 0.3125\n",
      "Epoch 16/30\n",
      "668/668 [==============================] - 83s 124ms/step - loss: 1.3926 - accuracy: 0.2859 - val_loss: 1.3866 - val_accuracy: 0.3125\n",
      "Epoch 17/30\n",
      "668/668 [==============================] - 83s 124ms/step - loss: 1.3928 - accuracy: 0.2812 - val_loss: 1.3866 - val_accuracy: 0.3125\n",
      "Epoch 18/30\n",
      "668/668 [==============================] - 83s 124ms/step - loss: 1.3924 - accuracy: 0.2835 - val_loss: 1.3866 - val_accuracy: 0.3125\n",
      "Epoch 19/30\n",
      "668/668 [==============================] - 83s 124ms/step - loss: 1.3926 - accuracy: 0.2832 - val_loss: 1.3866 - val_accuracy: 0.3125\n",
      "Epoch 20/30\n",
      "668/668 [==============================] - 83s 124ms/step - loss: 1.3928 - accuracy: 0.2812 - val_loss: 1.3866 - val_accuracy: 0.3125\n",
      "Epoch 21/30\n",
      "668/668 [==============================] - 83s 124ms/step - loss: 1.3927 - accuracy: 0.2824 - val_loss: 1.3866 - val_accuracy: 0.3125\n",
      "Epoch 22/30\n",
      "668/668 [==============================] - 83s 124ms/step - loss: 1.3925 - accuracy: 0.2850 - val_loss: 1.3866 - val_accuracy: 0.3125\n",
      "Epoch 23/30\n",
      "668/668 [==============================] - 83s 124ms/step - loss: 1.3928 - accuracy: 0.2824 - val_loss: 1.3866 - val_accuracy: 0.3125\n",
      "Epoch 24/30\n",
      "668/668 [==============================] - 83s 124ms/step - loss: 1.3929 - accuracy: 0.2817 - val_loss: 1.3866 - val_accuracy: 0.3125\n",
      "Epoch 25/30\n",
      "668/668 [==============================] - 83s 124ms/step - loss: 1.3926 - accuracy: 0.2809 - val_loss: 1.3866 - val_accuracy: 0.3125\n",
      "Epoch 26/30\n",
      "668/668 [==============================] - 83s 124ms/step - loss: 1.3927 - accuracy: 0.2823 - val_loss: 1.3866 - val_accuracy: 0.3125\n",
      "Epoch 27/30\n",
      "668/668 [==============================] - 83s 124ms/step - loss: 1.3923 - accuracy: 0.2877 - val_loss: 1.3866 - val_accuracy: 0.3125\n",
      "Epoch 28/30\n",
      "668/668 [==============================] - 83s 124ms/step - loss: 1.3927 - accuracy: 0.2827 - val_loss: 1.3866 - val_accuracy: 0.3125\n",
      "Epoch 29/30\n",
      "668/668 [==============================] - 83s 124ms/step - loss: 1.3927 - accuracy: 0.2829 - val_loss: 1.3866 - val_accuracy: 0.3125\n",
      "Epoch 30/30\n",
      "668/668 [==============================] - 83s 124ms/step - loss: 1.3923 - accuracy: 0.2850 - val_loss: 1.3866 - val_accuracy: 0.3125\n",
      "INFO:tensorflow:Assets written to: ../xception/xception_30epochs_33393.6_images_False_newWeights_True_lastLayerOnly/assets\n",
      "Test acc for xception: 0.258264\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training resnet for 0.4% of train size (aka 33393 images)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/668 [..............................] - ETA: 6:14 - loss: 1.3838 - accuracy: 0.3447WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0603s vs `on_train_batch_begin` time: 0.2075s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0603s vs `on_train_batch_end` time: 0.2141s). Check your callbacks.\n",
      "668/668 [==============================] - 47s 63ms/step - loss: 1.3832 - accuracy: 0.3106 - val_loss: 1.3880 - val_accuracy: 0.2188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "668/668 [==============================] - 38s 57ms/step - loss: 1.3832 - accuracy: 0.3115 - val_loss: 1.3880 - val_accuracy: 0.2188\n",
      "Epoch 3/30\n",
      "668/668 [==============================] - 38s 58ms/step - loss: 1.3833 - accuracy: 0.3127 - val_loss: 1.3880 - val_accuracy: 0.2188\n",
      "Epoch 4/30\n",
      "668/668 [==============================] - 39s 58ms/step - loss: 1.3832 - accuracy: 0.3085 - val_loss: 1.3880 - val_accuracy: 0.2188\n",
      "Epoch 5/30\n",
      "668/668 [==============================] - 39s 58ms/step - loss: 1.3833 - accuracy: 0.3132 - val_loss: 1.3880 - val_accuracy: 0.2188\n",
      "Epoch 6/30\n",
      "668/668 [==============================] - 39s 58ms/step - loss: 1.3832 - accuracy: 0.3118 - val_loss: 1.3880 - val_accuracy: 0.2188\n",
      "Epoch 7/30\n",
      "668/668 [==============================] - 39s 58ms/step - loss: 1.3832 - accuracy: 0.3121 - val_loss: 1.3880 - val_accuracy: 0.2188\n",
      "Epoch 8/30\n",
      "668/668 [==============================] - 39s 58ms/step - loss: 1.3833 - accuracy: 0.3134 - val_loss: 1.3880 - val_accuracy: 0.2188\n",
      "Epoch 9/30\n",
      "668/668 [==============================] - 39s 58ms/step - loss: 1.3834 - accuracy: 0.3089 - val_loss: 1.3880 - val_accuracy: 0.2188\n",
      "Epoch 10/30\n",
      "668/668 [==============================] - 39s 58ms/step - loss: 1.3832 - accuracy: 0.3132 - val_loss: 1.3880 - val_accuracy: 0.2188\n",
      "Epoch 11/30\n",
      "668/668 [==============================] - 39s 58ms/step - loss: 1.3833 - accuracy: 0.3125 - val_loss: 1.3880 - val_accuracy: 0.2188\n",
      "Epoch 12/30\n",
      "668/668 [==============================] - 39s 58ms/step - loss: 1.3834 - accuracy: 0.3065 - val_loss: 1.3880 - val_accuracy: 0.2188\n",
      "Epoch 13/30\n",
      "668/668 [==============================] - 38s 58ms/step - loss: 1.3832 - accuracy: 0.3097 - val_loss: 1.3880 - val_accuracy: 0.2188\n",
      "Epoch 14/30\n",
      "668/668 [==============================] - 39s 58ms/step - loss: 1.3832 - accuracy: 0.3152 - val_loss: 1.3880 - val_accuracy: 0.2188\n",
      "Epoch 15/30\n",
      "668/668 [==============================] - 39s 58ms/step - loss: 1.3833 - accuracy: 0.3126 - val_loss: 1.3880 - val_accuracy: 0.2188\n",
      "Epoch 16/30\n",
      "668/668 [==============================] - 38s 58ms/step - loss: 1.3832 - accuracy: 0.3135 - val_loss: 1.3880 - val_accuracy: 0.2188\n",
      "Epoch 17/30\n",
      "668/668 [==============================] - 38s 58ms/step - loss: 1.3831 - accuracy: 0.3114 - val_loss: 1.3880 - val_accuracy: 0.2188\n",
      "Epoch 18/30\n",
      "668/668 [==============================] - 38s 58ms/step - loss: 1.3833 - accuracy: 0.3139 - val_loss: 1.3880 - val_accuracy: 0.2188\n",
      "Epoch 19/30\n",
      "668/668 [==============================] - 38s 58ms/step - loss: 1.3832 - accuracy: 0.3122 - val_loss: 1.3880 - val_accuracy: 0.2188\n",
      "Epoch 20/30\n",
      "668/668 [==============================] - 39s 58ms/step - loss: 1.3832 - accuracy: 0.3118 - val_loss: 1.3880 - val_accuracy: 0.2188\n",
      "Epoch 21/30\n",
      "668/668 [==============================] - 39s 58ms/step - loss: 1.3831 - accuracy: 0.3155 - val_loss: 1.3880 - val_accuracy: 0.2188\n",
      "Epoch 22/30\n",
      "668/668 [==============================] - 39s 58ms/step - loss: 1.3833 - accuracy: 0.3097 - val_loss: 1.3880 - val_accuracy: 0.2188\n",
      "Epoch 23/30\n",
      "668/668 [==============================] - 39s 58ms/step - loss: 1.3831 - accuracy: 0.3154 - val_loss: 1.3880 - val_accuracy: 0.2188\n",
      "Epoch 24/30\n",
      "668/668 [==============================] - 38s 58ms/step - loss: 1.3831 - accuracy: 0.3164 - val_loss: 1.3880 - val_accuracy: 0.2188\n",
      "Epoch 25/30\n",
      "668/668 [==============================] - 39s 58ms/step - loss: 1.3830 - accuracy: 0.3150 - val_loss: 1.3880 - val_accuracy: 0.2188\n",
      "Epoch 26/30\n",
      "668/668 [==============================] - 38s 58ms/step - loss: 1.3832 - accuracy: 0.3149 - val_loss: 1.3880 - val_accuracy: 0.2188\n",
      "Epoch 27/30\n",
      "668/668 [==============================] - 39s 58ms/step - loss: 1.3832 - accuracy: 0.3118 - val_loss: 1.3880 - val_accuracy: 0.2188\n",
      "Epoch 28/30\n",
      "668/668 [==============================] - 39s 58ms/step - loss: 1.3832 - accuracy: 0.3119 - val_loss: 1.3880 - val_accuracy: 0.2188\n",
      "Epoch 29/30\n",
      "668/668 [==============================] - 39s 58ms/step - loss: 1.3833 - accuracy: 0.3098 - val_loss: 1.3880 - val_accuracy: 0.2188\n",
      "Epoch 30/30\n",
      "668/668 [==============================] - 38s 58ms/step - loss: 1.3833 - accuracy: 0.3109 - val_loss: 1.3880 - val_accuracy: 0.2188\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_33393.6_images_False_newWeights_True_lastLayerOnly/assets\n",
      "Test acc for resnet: 0.267562\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training opticnet for 0.4% of train size (aka 33393 images)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "668/668 [==============================] - 206s 297ms/step - loss: 289.3638 - accuracy: 0.1351 - val_loss: 217.3077 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "668/668 [==============================] - 194s 290ms/step - loss: 289.8459 - accuracy: 0.1385 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "668/668 [==============================] - 193s 289ms/step - loss: 289.5005 - accuracy: 0.1364 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "668/668 [==============================] - 193s 289ms/step - loss: 287.5753 - accuracy: 0.1397 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "668/668 [==============================] - 193s 289ms/step - loss: 288.2074 - accuracy: 0.1395 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "668/668 [==============================] - 193s 289ms/step - loss: 290.6992 - accuracy: 0.1359 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "668/668 [==============================] - 193s 289ms/step - loss: 289.3794 - accuracy: 0.1379 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "668/668 [==============================] - 193s 289ms/step - loss: 288.8968 - accuracy: 0.1372 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "668/668 [==============================] - 193s 290ms/step - loss: 289.7950 - accuracy: 0.1401 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "668/668 [==============================] - 193s 290ms/step - loss: 290.0679 - accuracy: 0.1355 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "668/668 [==============================] - 193s 290ms/step - loss: 290.0814 - accuracy: 0.1358 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "668/668 [==============================] - 193s 289ms/step - loss: 287.6744 - accuracy: 0.1363 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "668/668 [==============================] - 193s 289ms/step - loss: 290.2110 - accuracy: 0.1326 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "668/668 [==============================] - 193s 289ms/step - loss: 288.3925 - accuracy: 0.1364 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "668/668 [==============================] - 193s 289ms/step - loss: 289.6924 - accuracy: 0.1357 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "668/668 [==============================] - 193s 289ms/step - loss: 289.2131 - accuracy: 0.1383 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "668/668 [==============================] - 193s 290ms/step - loss: 289.8650 - accuracy: 0.1341 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "668/668 [==============================] - 193s 290ms/step - loss: 289.4342 - accuracy: 0.1360 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "668/668 [==============================] - 193s 289ms/step - loss: 290.4331 - accuracy: 0.1359 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "668/668 [==============================] - 193s 290ms/step - loss: 290.5855 - accuracy: 0.1366 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "668/668 [==============================] - 193s 290ms/step - loss: 289.9175 - accuracy: 0.1346 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "668/668 [==============================] - 193s 289ms/step - loss: 290.6837 - accuracy: 0.1350 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "668/668 [==============================] - 193s 290ms/step - loss: 289.7191 - accuracy: 0.1355 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "668/668 [==============================] - 193s 290ms/step - loss: 290.9750 - accuracy: 0.1335 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "668/668 [==============================] - 193s 289ms/step - loss: 290.3265 - accuracy: 0.1355 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "668/668 [==============================] - 193s 289ms/step - loss: 291.2071 - accuracy: 0.1339 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "668/668 [==============================] - 193s 289ms/step - loss: 289.7913 - accuracy: 0.1376 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "668/668 [==============================] - 193s 289ms/step - loss: 288.7531 - accuracy: 0.1352 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "668/668 [==============================] - 193s 289ms/step - loss: 289.2620 - accuracy: 0.1352 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "668/668 [==============================] - 193s 289ms/step - loss: 289.4716 - accuracy: 0.1351 - val_loss: 217.3077 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../opticnet/opticnet_30epochs_33393.6_images_False_newWeights_True_lastLayerOnly/assets\n",
      "Test acc for opticnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.49747292 0.50272813 0.49973564 0.49628598]\n",
      "Training xception for 0.5% of train size (aka 41742 images)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/835 [..............................] - ETA: 8:15 - loss: 1.3986 - accuracy: 0.1388WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1169s vs `on_train_batch_begin` time: 0.1964s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1169s vs `on_train_batch_end` time: 0.2044s). Check your callbacks.\n",
      "835/835 [==============================] - 108s 126ms/step - loss: 1.3983 - accuracy: 0.1367 - val_loss: 1.3871 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-797fd00c81c1>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "835/835 [==============================] - 103s 124ms/step - loss: 1.3981 - accuracy: 0.1393 - val_loss: 1.3871 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "835/835 [==============================] - 104s 124ms/step - loss: 1.3980 - accuracy: 0.1385 - val_loss: 1.3871 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "835/835 [==============================] - 104s 124ms/step - loss: 1.3981 - accuracy: 0.1382 - val_loss: 1.3871 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "835/835 [==============================] - 103s 124ms/step - loss: 1.3982 - accuracy: 0.1383 - val_loss: 1.3871 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "835/835 [==============================] - 103s 124ms/step - loss: 1.3981 - accuracy: 0.1379 - val_loss: 1.3871 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "835/835 [==============================] - 103s 124ms/step - loss: 1.3983 - accuracy: 0.1366 - val_loss: 1.3871 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "835/835 [==============================] - 103s 124ms/step - loss: 1.3980 - accuracy: 0.1391 - val_loss: 1.3871 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "835/835 [==============================] - 103s 124ms/step - loss: 1.3982 - accuracy: 0.1391 - val_loss: 1.3871 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "835/835 [==============================] - 103s 124ms/step - loss: 1.3980 - accuracy: 0.1394 - val_loss: 1.3871 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "835/835 [==============================] - 104s 124ms/step - loss: 1.3981 - accuracy: 0.1426 - val_loss: 1.3871 - val_accuracy: 0.2500\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import datetime\n",
    "\n",
    "newWeights=False; trainLastLayerOnly=True\n",
    "\n",
    "maxTrain = len(y_train)\n",
    "#for p in [1.0]:\n",
    "#for p in [0.1, 0.25, 0.4, 0.5, 0.6, 0.75, 0.9]:\n",
    "for p in [0.09, 0.1, 0.25, 0.4, 0.5, 0.6, 0.75, 0.9, 1.0]:\n",
    "    #X_trn, X_tst, y_trn, y_tst\n",
    "    if p < 1:\n",
    "        X_t, _, y_t, _ = train_test_split(images, y_train, test_size=1-p, random_state=123)\n",
    "    else:\n",
    "        X_t = images; y_t = y_train;\n",
    "    print(f\"Labels fraction: {sum(y_t == 1) / sum(y_train == 1)}\")\n",
    "    for net in [\"xception\", \"resnet\", \"opticnet\"]:\n",
    "        print(f\"Training {net} for {p}% of train size (aka {len(X_t)} images)...\")\n",
    "        model, size = emptyModelGenerator(net, newWeights=newWeights, lastOnly=trainLastLayerOnly)\n",
    "        X_trn = resizeIms(X_t, size)\n",
    "        X_val = resizeIms(x_val, size)\n",
    "        log_dir = f\"logs/{net}/fit/{p}trainSet_\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "        tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "        optim = Adam(learning_rate=0.001)\n",
    "        model.compile(optimizer=optim, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "        hist = model.fit(X_trn, y_t, epochs=epochs, validation_data = (X_val, y_validation), batch_size=batch_size,\n",
    "                    shuffle=True, max_queue_size=20,\n",
    "                    use_multiprocessing=True, workers=5, \n",
    "                    callbacks=[CustomCallback(fraction=0.9, model=net), tensorboard_callback])\n",
    "        model.save(f\"../{net}/{net}_{epochs}epochs_{p*maxTrain}_images_{newWeights}_newWeights_{trainLastLayerOnly}_lastLayerOnly\")\n",
    "        testPredict(model, size, name=net)\n",
    "        del model\n",
    "        del X_trn\n",
    "        del X_val\n",
    "        print(\"Done!\\n\" + '-'*50, end='\\n\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
