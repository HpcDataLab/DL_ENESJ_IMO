{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "import os\n",
    "import cv2\n",
    "import pickle\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataPath = \"../../data/OCT/OCT2017/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of Classes Detected : 4\n"
     ]
    }
   ],
   "source": [
    "labels_available = os.listdir(os.path.join(dataPath, \"train\"))\n",
    "print(\"Total Number of Classes Detected :\",len(labels_available))\n",
    "\n",
    "labels_list = ['NORMAL',\"CNV\",\"DME\",\"DRUSEN\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NORMAL CNV DME DRUSEN "
     ]
    }
   ],
   "source": [
    "images=[]\n",
    "y_trn=[]\n",
    "for x in labels_list:\n",
    "    xPath = os.path.join(dataPath, \"train\", x)\n",
    "    myPicList = os.listdir(xPath)\n",
    "    for y in myPicList:\n",
    "        images.append(cv2.imread(os.path.join(xPath, y)))\n",
    "        y_trn.append(labels_list.index(x))\n",
    "    print(x ,end=\" \")\n",
    "\n",
    "y_train = to_categorical(y_trn,len(labels_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NORMAL CNV DME DRUSEN "
     ]
    }
   ],
   "source": [
    "x_val=[]\n",
    "y_val=[]\n",
    "for x in labels_list:\n",
    "    xPath = os.path.join(dataPath, \"val\", x)\n",
    "    myPicList = os.listdir(xPath)\n",
    "    for y in myPicList:\n",
    "        x_val.append(cv2.imread(os.path.join(xPath, y)))\n",
    "        y_val.append(labels_list.index(x))\n",
    "    print(x ,end=\" \")\n",
    "\n",
    "y_validation = to_categorical(y_val,len(labels_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NORMAL CNV DME DRUSEN "
     ]
    }
   ],
   "source": [
    "x_tst=[]\n",
    "y_tst=[]\n",
    "for x in labels_list:\n",
    "    xPath = os.path.join(dataPath, \"test\", x)\n",
    "    myPicList = os.listdir(xPath)\n",
    "    for y in myPicList:\n",
    "        x_tst.append(cv2.imread(os.path.join(xPath, y)))\n",
    "        y_tst.append(labels_list.index(x))\n",
    "    print(x ,end=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resizeIm(im, size):\n",
    "    if im.shape[2] == 1:\n",
    "        im = cv2.cvtColor(im,cv2.COLOR_GRAY2RGB)\n",
    "    return cv2.resize(im, size)\n",
    "\n",
    "def resizeIms(x, size):\n",
    "    return np.array(list(map(lambda im: resizeIm(im, size), x)))\n",
    "\n",
    "# Substract the mean specified by Mean (https://www.mathworks.com/help/deeplearning/ref/nnet.cnn.layer.imageinputlayer.html)\n",
    "# Substract mean by channel\n",
    "def zerocenter(x):\n",
    "    return (x - np.mean(x, axis=(0, 1))) / (2*np.std(x, axis=(0, 1)))\n",
    "\n",
    "# Rescale the input to be in the range [-1, 1] using the minimum and maximum values specified by Min and Max, respectively. (https://www.mathworks.com/help/deeplearning/ref/nnet.cnn.layer.imageinputlayer.html)\n",
    "# Compute using the formula: $x\\prime = 2 * \\frac{x - \\min{x}}{\\max{x} - \\min{x}} - 1$ taken from: https://stats.stackexchange.com/a/178629\n",
    "def rescaleSymmetric(x):\n",
    "    x = zerocenter(x)\n",
    "    return 2 * (x - np.min(x, axis=(0, 1)))/np.ptp(x, axis=(0, 1)) - 1\n",
    "\n",
    "def normalizeIms(x, normalization):\n",
    "    if normalization == \"zerocenter\":\n",
    "        func = zerocenter\n",
    "    elif normalization == \"rescale-symmetric\":\n",
    "        func = rescaleSymmetric\n",
    "    else:\n",
    "        return x\n",
    "    return np.array(list(map(lambda im: func(im), x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self,fraction, model):\n",
    "        super(CustomCallback,self).__init__()\n",
    "        self.fraction = fraction\n",
    "        self.train_a = [];\n",
    "        self.val_a =[];\n",
    "        self.logPath = os.path.join(model, \"log.txt\")\n",
    "\n",
    "        if not os.path.isdir(model):\n",
    "            os.mkdir(model)\n",
    "\n",
    "        with open(self.logPath,'w') as f:\n",
    "            f.write('Starting of logging..\\n')\n",
    "\n",
    "        self.fig = plt.figure(figsize=(4,3))\n",
    "        self.ax = plt.subplot(1,1,1)\n",
    "        plt.ion()\n",
    "\n",
    "    def on_train_begin(self,logs=None):\n",
    "        self.fig.show()\n",
    "        self.fig.canvas.draw()\n",
    "\n",
    "    def on_train_end(self,logs=None):\n",
    "        with open(self.logPath,'a') as f:\n",
    "              f.write('End of logging..\\n')\n",
    "    \n",
    "    def on_epoch_begin(self,epoch,logs=None):\n",
    "        lr= tf.keras.backend.get_value(self.model.optimizer.lr)\n",
    "        lr *= self.fraction\n",
    "        tf.keras.backend.set_value(self.model.optimizer.lr,lr)\n",
    "        with open(self.logPath,'a') as f:\n",
    "            f.write('At epoch {:02d}, learning rate changed to {:.4f}\\n'.format(epoch,lr))\n",
    "    \n",
    "    def on_epoch_end(self,epoch,logs=None):\n",
    "        val_acc = logs.get('val_accuracy')\n",
    "        train_acc = logs.get('accuracy')\n",
    "        self.train_a.append(train_acc)\n",
    "        self.val_a.append(val_acc)\n",
    "        with open(self.logPath,'a') as f:\n",
    "            f.write('At epoch {:02d}, training accuracy: {:.3f}, validation accuracy: {:.3f}\\n'.format(epoch,train_acc,val_acc))\n",
    "        self.ax.clear()\n",
    "        self.ax.plot(range(1+epoch),self.train_a,label=\"Training\")\n",
    "        self.ax.plot(range(1+epoch),self.val_a,label=\"Validation\")\n",
    "        self.ax.set_xlabel('Epochs')\n",
    "        self.ax.set_ylabel('Accuracy')\n",
    "        self.ax.legend()\n",
    "        self.fig.canvas.draw()\n",
    "        self.fig.show()\n",
    "        \n",
    "class TimeHistory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.times = []\n",
    "\n",
    "    def on_epoch_begin(self, batch, logs={}):\n",
    "        self.epoch_time_start = time.time()\n",
    "\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.times.append(time.time() - self.epoch_time_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xception base model\n",
    "from tensorflow.keras.applications.xception import Xception\n",
    "from tensorflow.keras.applications.xception import preprocess_input, decode_predictions\n",
    "xceptionNetModel = Xception(weights='imagenet')\n",
    "\n",
    "# opticnet base model\n",
    "opticNetModel = tf.keras.models.load_model('../Optic_net-4_classes-Kermany2018.hdf5')\n",
    "\n",
    "# resnet base model\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "\n",
    "resNetModel = ResNet50(weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emptyModelGenerator(model, newWeights=False, lastOnly=False):\n",
    "    model = model.lower()\n",
    "    if model == \"resnet\":\n",
    "        x = resNetModel.output\n",
    "        predictions = Dense(len(labels_list), activation='softmax')(x)\n",
    "        newModel = Model(inputs=resNetModel.input, outputs=predictions)\n",
    "        size = (224, 224)\n",
    "        normalization = \"zerocenter\"\n",
    "    elif model == \"xception\":\n",
    "        x = xceptionNetModel.output\n",
    "        predictions = Dense(len(labels_list), activation='softmax')(x)\n",
    "        newModel = Model(inputs=xceptionNetModel.input, outputs=predictions)\n",
    "        size = (299, 299)\n",
    "        normalization = \"rescale-symmetric\"\n",
    "    elif model == \"opticnet\":\n",
    "        newModel = tf.keras.models.load_model('../Optic_net-4_classes-Kermany2018.hdf5')\n",
    "        size = (224, 224)\n",
    "        normalization = \"rescale-symmetric\"\n",
    "    if newWeights:\n",
    "        newModel = tf.keras.models.clone_model(newModel)\n",
    "    if lastOnly:\n",
    "        newModel = lastDenseTrainable(newModel) # block all layer except the last dense ones\n",
    "    return newModel, size, normalization\n",
    "\n",
    "\n",
    "def lastDenseTrainable(model):\n",
    "    model.trainable = False\n",
    "    for i in range(1, len(model.layers)):\n",
    "        if model.layers[-i].__class__.__name__ == \"Dense\":\n",
    "            model.layers[-i].trainable= True\n",
    "        elif model.layers[-i].__class__.__name__ == \"Activation\":\n",
    "            continue\n",
    "        else:\n",
    "            break\n",
    "    return model\n",
    "    \n",
    "\n",
    "def testPredict(model, size, name=None, normalization=None):\n",
    "    X_test = resizeIms(x_tst, size)\n",
    "    if normalization:\n",
    "        X_test = normalizeIms(X_test, normalization)\n",
    "    X_test = np.array(X_test)\n",
    "    Y_test = np.array(y_tst)\n",
    "    \n",
    "    prediction = model.predict(X_test)\n",
    "    preds = np.argmax(prediction, axis=1)\n",
    "    acc = sum(preds == Y_test) / len(Y_test)\n",
    "    print(f'Test acc for {name if name else \"model\"}: {acc:.6f}')\n",
    "    return acc\n",
    "    \n",
    "\n",
    "def computeConfussionMatrix(predictions, labels):\n",
    "    num_labels = len(labels_list)\n",
    "    cMatrix = np.zeros(shape=(num_labels, num_labels))\n",
    "    for i in len(predictions):\n",
    "        p = int(predictions[i])\n",
    "        t = int(predictions[i])\n",
    "        cMatrix[t, p] += 1\n",
    "    print(cMatrix)\n",
    "    ax = sns.heatmap(cMatrix, cmap=\"Blues\", annot=True, fmt=\"d\", xticklabels=labels_list, yticklabels=labels_list)\n",
    "    plt.xlabel(\"Predicted label\")\n",
    "    plt.ylabel(\"True label\")\n",
    "    plt.title(\"Confusion matrix\")\n",
    "    plt.show();\n",
    "    return cMatrix\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "**************************************************\n",
      "Model: xception\n",
      "**************************************************\n",
      "predictions True\n",
      "dense True\n",
      "\n",
      "Total: 135 trainable: 2\n",
      "\n",
      "\n",
      "**************************************************\n",
      "Model: resnet\n",
      "**************************************************\n",
      "predictions True\n",
      "dense_1 True\n",
      "\n",
      "Total: 178 trainable: 2\n",
      "\n",
      "\n",
      "**************************************************\n",
      "Model: opticnet\n",
      "**************************************************\n",
      "Dense_1 True\n",
      "Dense_2 True\n",
      "\n",
      "Total: 276 trainable: 2\n"
     ]
    }
   ],
   "source": [
    "models = [\"xception\", \"resnet\", \"opticnet\"]\n",
    "\n",
    "for mod in models:\n",
    "    print(\"\\n\\n\" + (\"*\"*50) + \"\\nModel: \" + mod + '\\n' + (\"*\"*50))\n",
    "    m = emptyModelGenerator(mod, newWeights=False, lastOnly=True)[0]\n",
    "    #m.trainable = False\n",
    "    a = 0\n",
    "    for l in m.layers:\n",
    "        #l.trainable = True\n",
    "        if l.trainable:\n",
    "            print(l.name, l.trainable)\n",
    "            a += 1\n",
    "            #print(l.trainable_weights)\n",
    "    print(f\"\\nTotal: {len(m.layers)} trainable: {a}\")\n",
    "    #print(m.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "momentum = 0.5\n",
    "optim = Adam(learning_rate=lr)\n",
    "#optim = SGD(learning_rate=lr, momentum=momentum)\n",
    "epochs = 30\n",
    "batch_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "results = pd.read_csv(\"Results.csv\")\n",
    "results[\"normalization\"] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels fraction: [0.0101463  0.00983739 0.01039831 0.00963324]\n",
      "Training xception for 0.01% of train size (aka 834 images) with pretrained: True and onlyLastLayersTrained: False...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      " 6/17 [=========>....................] - ETA: 3s - loss: 1.3669 - accuracy: 0.5078WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1148s vs `on_train_batch_begin` time: 0.1376s). Check your callbacks.\n",
      "17/17 [==============================] - 22s 345ms/step - loss: 1.3677 - accuracy: 0.4723 - val_loss: 1.3847 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "17/17 [==============================] - 2s 122ms/step - loss: 1.3556 - accuracy: 0.4667 - val_loss: 1.3793 - val_accuracy: 0.3438\n",
      "Epoch 3/30\n",
      "17/17 [==============================] - 2s 122ms/step - loss: 1.3404 - accuracy: 0.4876 - val_loss: 1.3739 - val_accuracy: 0.4062\n",
      "Epoch 4/30\n",
      "17/17 [==============================] - 2s 126ms/step - loss: 1.3227 - accuracy: 0.5417 - val_loss: 1.3666 - val_accuracy: 0.4375\n",
      "Epoch 5/30\n",
      "17/17 [==============================] - 2s 123ms/step - loss: 1.3131 - accuracy: 0.5571 - val_loss: 1.3626 - val_accuracy: 0.4375\n",
      "Epoch 6/30\n",
      "17/17 [==============================] - 2s 122ms/step - loss: 1.2986 - accuracy: 0.5705 - val_loss: 1.3618 - val_accuracy: 0.4062\n",
      "Epoch 7/30\n",
      "17/17 [==============================] - 2s 123ms/step - loss: 1.2885 - accuracy: 0.5823 - val_loss: 1.3601 - val_accuracy: 0.4375\n",
      "Epoch 8/30\n",
      "17/17 [==============================] - 2s 123ms/step - loss: 1.2887 - accuracy: 0.5668 - val_loss: 1.3590 - val_accuracy: 0.4062\n",
      "Epoch 9/30\n",
      "17/17 [==============================] - 2s 123ms/step - loss: 1.2748 - accuracy: 0.5977 - val_loss: 1.3614 - val_accuracy: 0.4062\n",
      "Epoch 10/30\n",
      "17/17 [==============================] - 2s 123ms/step - loss: 1.2615 - accuracy: 0.6302 - val_loss: 1.3597 - val_accuracy: 0.4062\n",
      "Epoch 11/30\n",
      "17/17 [==============================] - 2s 123ms/step - loss: 1.2675 - accuracy: 0.5982 - val_loss: 1.3627 - val_accuracy: 0.3750\n",
      "Epoch 12/30\n",
      "17/17 [==============================] - 2s 123ms/step - loss: 1.2611 - accuracy: 0.6039 - val_loss: 1.3585 - val_accuracy: 0.4062\n",
      "Epoch 13/30\n",
      "17/17 [==============================] - 2s 124ms/step - loss: 1.2525 - accuracy: 0.6243 - val_loss: 1.3564 - val_accuracy: 0.4062\n",
      "Epoch 14/30\n",
      "17/17 [==============================] - 2s 124ms/step - loss: 1.2485 - accuracy: 0.6327 - val_loss: 1.3541 - val_accuracy: 0.4062\n",
      "Epoch 15/30\n",
      "17/17 [==============================] - 2s 124ms/step - loss: 1.2426 - accuracy: 0.6495 - val_loss: 1.3590 - val_accuracy: 0.3750\n",
      "Epoch 16/30\n",
      "17/17 [==============================] - 2s 124ms/step - loss: 1.2307 - accuracy: 0.6642 - val_loss: 1.3532 - val_accuracy: 0.4062\n",
      "Epoch 17/30\n",
      "17/17 [==============================] - 2s 124ms/step - loss: 1.2326 - accuracy: 0.6345 - val_loss: 1.3538 - val_accuracy: 0.4062\n",
      "Epoch 18/30\n",
      "17/17 [==============================] - 2s 127ms/step - loss: 1.2347 - accuracy: 0.6503 - val_loss: 1.3529 - val_accuracy: 0.4062\n",
      "Epoch 19/30\n",
      "17/17 [==============================] - 2s 125ms/step - loss: 1.2297 - accuracy: 0.6422 - val_loss: 1.3553 - val_accuracy: 0.3750\n",
      "Epoch 20/30\n",
      "17/17 [==============================] - 2s 125ms/step - loss: 1.2295 - accuracy: 0.6466 - val_loss: 1.3548 - val_accuracy: 0.4062\n",
      "Epoch 21/30\n",
      "17/17 [==============================] - 2s 125ms/step - loss: 1.2200 - accuracy: 0.6637 - val_loss: 1.3529 - val_accuracy: 0.4062\n",
      "Epoch 22/30\n",
      "17/17 [==============================] - 2s 125ms/step - loss: 1.2322 - accuracy: 0.6340 - val_loss: 1.3528 - val_accuracy: 0.4062\n",
      "Epoch 23/30\n",
      "17/17 [==============================] - 2s 127ms/step - loss: 1.2288 - accuracy: 0.6406 - val_loss: 1.3506 - val_accuracy: 0.4062\n",
      "Epoch 24/30\n",
      "17/17 [==============================] - 2s 125ms/step - loss: 1.2197 - accuracy: 0.6612 - val_loss: 1.3529 - val_accuracy: 0.4062\n",
      "Epoch 25/30\n",
      "17/17 [==============================] - 2s 125ms/step - loss: 1.2371 - accuracy: 0.6269 - val_loss: 1.3525 - val_accuracy: 0.4062\n",
      "Epoch 26/30\n",
      "17/17 [==============================] - 2s 125ms/step - loss: 1.2305 - accuracy: 0.6258 - val_loss: 1.3518 - val_accuracy: 0.4062\n",
      "Epoch 27/30\n",
      "17/17 [==============================] - 2s 125ms/step - loss: 1.2103 - accuracy: 0.6725 - val_loss: 1.3519 - val_accuracy: 0.4062\n",
      "Epoch 28/30\n",
      "17/17 [==============================] - 2s 125ms/step - loss: 1.2233 - accuracy: 0.6490 - val_loss: 1.3515 - val_accuracy: 0.4062\n",
      "Epoch 29/30\n",
      "17/17 [==============================] - 2s 127ms/step - loss: 1.2238 - accuracy: 0.6403 - val_loss: 1.3505 - val_accuracy: 0.4062\n",
      "Epoch 30/30\n",
      "17/17 [==============================] - 2s 125ms/step - loss: 1.2151 - accuracy: 0.6524 - val_loss: 1.3511 - val_accuracy: 0.4062\n",
      "INFO:tensorflow:Assets written to: ../xception/xception_30epochs_834.84_images_False_newWeights_False_lastLayerOnly_rescale-symmetric_normalization/assets\n",
      "Test acc for xception: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training resnet for 0.01% of train size (aka 834 images) with pretrained: True and onlyLastLayersTrained: False...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      " 6/17 [=========>....................] - ETA: 4s - loss: 1.3848 - accuracy: 0.3557WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0563s vs `on_train_batch_begin` time: 0.1332s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0563s vs `on_train_batch_end` time: 0.1521s). Check your callbacks.\n",
      "17/17 [==============================] - 9s 296ms/step - loss: 1.3734 - accuracy: 0.4719 - val_loss: 1.3678 - val_accuracy: 0.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "17/17 [==============================] - 1s 62ms/step - loss: 1.3316 - accuracy: 0.6698 - val_loss: 1.3517 - val_accuracy: 0.5000\n",
      "Epoch 3/30\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.3047 - accuracy: 0.7070 - val_loss: 1.3464 - val_accuracy: 0.5000\n",
      "Epoch 4/30\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.2863 - accuracy: 0.7168 - val_loss: 1.3371 - val_accuracy: 0.5000\n",
      "Epoch 5/30\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.2656 - accuracy: 0.7299 - val_loss: 1.3318 - val_accuracy: 0.5000\n",
      "Epoch 6/30\n",
      "17/17 [==============================] - 1s 62ms/step - loss: 1.2539 - accuracy: 0.7336 - val_loss: 1.3279 - val_accuracy: 0.5000\n",
      "Epoch 7/30\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.2428 - accuracy: 0.7269 - val_loss: 1.3230 - val_accuracy: 0.5000\n",
      "Epoch 8/30\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.2405 - accuracy: 0.7181 - val_loss: 1.3211 - val_accuracy: 0.5000\n",
      "Epoch 9/30\n",
      "17/17 [==============================] - 1s 63ms/step - loss: 1.2260 - accuracy: 0.7276 - val_loss: 1.3166 - val_accuracy: 0.5000\n",
      "Epoch 10/30\n",
      "17/17 [==============================] - 1s 62ms/step - loss: 1.2132 - accuracy: 0.7351 - val_loss: 1.3165 - val_accuracy: 0.5000\n",
      "Epoch 11/30\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.2072 - accuracy: 0.7410 - val_loss: 1.3142 - val_accuracy: 0.5000\n",
      "Epoch 12/30\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.1961 - accuracy: 0.7455 - val_loss: 1.3129 - val_accuracy: 0.5000\n",
      "Epoch 13/30\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.1844 - accuracy: 0.7659 - val_loss: 1.3104 - val_accuracy: 0.5000\n",
      "Epoch 14/30\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.1868 - accuracy: 0.7442 - val_loss: 1.3094 - val_accuracy: 0.5000\n",
      "Epoch 15/30\n",
      "17/17 [==============================] - 1s 62ms/step - loss: 1.1820 - accuracy: 0.7478 - val_loss: 1.3088 - val_accuracy: 0.5000\n",
      "Epoch 16/30\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.1630 - accuracy: 0.7697 - val_loss: 1.3066 - val_accuracy: 0.5000\n",
      "Epoch 17/30\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.1654 - accuracy: 0.7625 - val_loss: 1.3068 - val_accuracy: 0.5000\n",
      "Epoch 18/30\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.1627 - accuracy: 0.7576 - val_loss: 1.3053 - val_accuracy: 0.5000\n",
      "Epoch 19/30\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.1569 - accuracy: 0.7631 - val_loss: 1.3052 - val_accuracy: 0.5000\n",
      "Epoch 20/30\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.1532 - accuracy: 0.7644 - val_loss: 1.3044 - val_accuracy: 0.5000\n",
      "Epoch 21/30\n",
      "17/17 [==============================] - 1s 63ms/step - loss: 1.1520 - accuracy: 0.7593 - val_loss: 1.3038 - val_accuracy: 0.5000\n",
      "Epoch 22/30\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.1563 - accuracy: 0.7493 - val_loss: 1.3033 - val_accuracy: 0.5000\n",
      "Epoch 23/30\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.1598 - accuracy: 0.7360 - val_loss: 1.3022 - val_accuracy: 0.5000\n",
      "Epoch 24/30\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.1463 - accuracy: 0.7620 - val_loss: 1.3021 - val_accuracy: 0.5000\n",
      "Epoch 25/30\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.1493 - accuracy: 0.7521 - val_loss: 1.3021 - val_accuracy: 0.5000\n",
      "Epoch 26/30\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.1461 - accuracy: 0.7553 - val_loss: 1.3014 - val_accuracy: 0.5000\n",
      "Epoch 27/30\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.1505 - accuracy: 0.7461 - val_loss: 1.3010 - val_accuracy: 0.5000\n",
      "Epoch 28/30\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.1466 - accuracy: 0.7471 - val_loss: 1.3006 - val_accuracy: 0.5000\n",
      "Epoch 29/30\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.1508 - accuracy: 0.7381 - val_loss: 1.3004 - val_accuracy: 0.5000\n",
      "Epoch 30/30\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.1420 - accuracy: 0.7556 - val_loss: 1.3000 - val_accuracy: 0.5000\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_834.84_images_False_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.272727\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training opticnet for 0.01% of train size (aka 834 images) with pretrained: True and onlyLastLayersTrained: False...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      " 6/17 [=========>....................] - ETA: 19s - loss: 5.1192 - accuracy: 0.1909 WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.4633s vs `on_train_batch_end` time: 0.9425s). Check your callbacks.\n",
      "17/17 [==============================] - 45s 2s/step - loss: 3.0868 - accuracy: 0.3988 - val_loss: 5.7287 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.5836 - accuracy: 0.7872 - val_loss: 2.9595 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.3196 - accuracy: 0.8619 - val_loss: 0.9419 - val_accuracy: 0.6562\n",
      "Epoch 4/30\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.1244 - accuracy: 0.9582 - val_loss: 1.3413 - val_accuracy: 0.4688\n",
      "Epoch 5/30\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.0713 - accuracy: 0.9763 - val_loss: 1.2388 - val_accuracy: 0.5938\n",
      "Epoch 6/30\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.0489 - accuracy: 0.9799 - val_loss: 0.6963 - val_accuracy: 0.7500\n",
      "Epoch 7/30\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.0400 - accuracy: 0.9872 - val_loss: 0.6480 - val_accuracy: 0.7812\n",
      "Epoch 8/30\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.0238 - accuracy: 0.9937 - val_loss: 0.5410 - val_accuracy: 0.8125\n",
      "Epoch 9/30\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.0173 - accuracy: 0.9959 - val_loss: 0.2818 - val_accuracy: 0.9062\n",
      "Epoch 10/30\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.0090 - accuracy: 0.9984 - val_loss: 0.1725 - val_accuracy: 0.9375\n",
      "Epoch 11/30\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.0868 - val_accuracy: 0.9375\n",
      "Epoch 12/30\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0912 - val_accuracy: 0.9688\n",
      "Epoch 13/30\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0609 - val_accuracy: 0.9688\n",
      "Epoch 14/30\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0647 - val_accuracy: 0.9688\n",
      "Epoch 15/30\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0671 - val_accuracy: 0.9688\n",
      "Epoch 16/30\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0626 - val_accuracy: 0.9688\n",
      "Epoch 17/30\n",
      "17/17 [==============================] - 20s 1s/step - loss: 5.4686e-04 - accuracy: 1.0000 - val_loss: 0.0638 - val_accuracy: 0.9688\n",
      "Epoch 18/30\n",
      "17/17 [==============================] - 20s 1s/step - loss: 7.2070e-04 - accuracy: 1.0000 - val_loss: 0.0644 - val_accuracy: 0.9688\n",
      "Epoch 19/30\n",
      "17/17 [==============================] - 20s 1s/step - loss: 6.2734e-04 - accuracy: 1.0000 - val_loss: 0.0715 - val_accuracy: 0.9688\n",
      "Epoch 20/30\n",
      "17/17 [==============================] - 20s 1s/step - loss: 7.8397e-04 - accuracy: 1.0000 - val_loss: 0.0756 - val_accuracy: 0.9688\n",
      "Epoch 21/30\n",
      "17/17 [==============================] - 20s 1s/step - loss: 4.5099e-04 - accuracy: 1.0000 - val_loss: 0.0800 - val_accuracy: 0.9688\n",
      "Epoch 22/30\n",
      "17/17 [==============================] - 20s 1s/step - loss: 5.6729e-04 - accuracy: 1.0000 - val_loss: 0.0822 - val_accuracy: 0.9688\n",
      "Epoch 23/30\n",
      "17/17 [==============================] - 20s 1s/step - loss: 8.7844e-04 - accuracy: 1.0000 - val_loss: 0.0859 - val_accuracy: 0.9688\n",
      "Epoch 24/30\n",
      "17/17 [==============================] - 20s 1s/step - loss: 5.6758e-04 - accuracy: 1.0000 - val_loss: 0.0903 - val_accuracy: 0.9688\n",
      "Epoch 25/30\n",
      "17/17 [==============================] - 20s 1s/step - loss: 9.1676e-04 - accuracy: 1.0000 - val_loss: 0.0979 - val_accuracy: 0.9688\n",
      "Epoch 26/30\n",
      "17/17 [==============================] - 20s 1s/step - loss: 6.8502e-04 - accuracy: 1.0000 - val_loss: 0.1008 - val_accuracy: 0.9688\n",
      "Epoch 27/30\n",
      "17/17 [==============================] - 20s 1s/step - loss: 3.7926e-04 - accuracy: 1.0000 - val_loss: 0.1005 - val_accuracy: 0.9688\n",
      "Epoch 28/30\n",
      "17/17 [==============================] - 20s 1s/step - loss: 4.9913e-04 - accuracy: 1.0000 - val_loss: 0.1038 - val_accuracy: 0.9688\n",
      "Epoch 29/30\n",
      "17/17 [==============================] - 20s 1s/step - loss: 3.1202e-04 - accuracy: 1.0000 - val_loss: 0.1058 - val_accuracy: 0.9688\n",
      "Epoch 30/30\n",
      "17/17 [==============================] - 20s 1s/step - loss: 3.4687e-04 - accuracy: 1.0000 - val_loss: 0.1061 - val_accuracy: 0.9688\n",
      "INFO:tensorflow:Assets written to: ../opticnet/opticnet_30epochs_834.84_images_False_newWeights_False_lastLayerOnly_rescale-symmetric_normalization/assets\n",
      "Test acc for opticnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.02451074 0.02513103 0.02467395 0.02634633]\n",
      "Training xception for 0.025% of train size (aka 2087 images) with pretrained: True and onlyLastLayersTrained: False...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      " 6/42 [===>..........................] - ETA: 19s - loss: 1.3772 - accuracy: 0.2454WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1218s vs `on_train_batch_begin` time: 0.1299s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1218s vs `on_train_batch_end` time: 0.2148s). Check your callbacks.\n",
      "42/42 [==============================] - 14s 216ms/step - loss: 1.3678 - accuracy: 0.3596 - val_loss: 1.3561 - val_accuracy: 0.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "42/42 [==============================] - 5s 122ms/step - loss: 1.3254 - accuracy: 0.5768 - val_loss: 1.3459 - val_accuracy: 0.4688\n",
      "Epoch 3/30\n",
      "42/42 [==============================] - 5s 122ms/step - loss: 1.2950 - accuracy: 0.6022 - val_loss: 1.3357 - val_accuracy: 0.5000\n",
      "Epoch 4/30\n",
      "42/42 [==============================] - 5s 123ms/step - loss: 1.2719 - accuracy: 0.5946 - val_loss: 1.3430 - val_accuracy: 0.4688\n",
      "Epoch 5/30\n",
      "42/42 [==============================] - 5s 123ms/step - loss: 1.2458 - accuracy: 0.6158 - val_loss: 1.3327 - val_accuracy: 0.4688\n",
      "Epoch 6/30\n",
      "42/42 [==============================] - 5s 123ms/step - loss: 1.2279 - accuracy: 0.6222 - val_loss: 1.3282 - val_accuracy: 0.4688\n",
      "Epoch 7/30\n",
      "42/42 [==============================] - 5s 123ms/step - loss: 1.2216 - accuracy: 0.5949 - val_loss: 1.3257 - val_accuracy: 0.4688\n",
      "Epoch 8/30\n",
      "42/42 [==============================] - 5s 123ms/step - loss: 1.1984 - accuracy: 0.6301 - val_loss: 1.3149 - val_accuracy: 0.5000\n",
      "Epoch 9/30\n",
      "42/42 [==============================] - 5s 123ms/step - loss: 1.1937 - accuracy: 0.6240 - val_loss: 1.3276 - val_accuracy: 0.4688\n",
      "Epoch 10/30\n",
      "42/42 [==============================] - 5s 123ms/step - loss: 1.1775 - accuracy: 0.6306 - val_loss: 1.3243 - val_accuracy: 0.4688\n",
      "Epoch 11/30\n",
      "42/42 [==============================] - 5s 124ms/step - loss: 1.1732 - accuracy: 0.6274 - val_loss: 1.3096 - val_accuracy: 0.5000\n",
      "Epoch 12/30\n",
      "42/42 [==============================] - 5s 124ms/step - loss: 1.1529 - accuracy: 0.6498 - val_loss: 1.3073 - val_accuracy: 0.5000\n",
      "Epoch 13/30\n",
      "42/42 [==============================] - 5s 124ms/step - loss: 1.1545 - accuracy: 0.6392 - val_loss: 1.3108 - val_accuracy: 0.5000\n",
      "Epoch 14/30\n",
      "42/42 [==============================] - 5s 123ms/step - loss: 1.1574 - accuracy: 0.6222 - val_loss: 1.3047 - val_accuracy: 0.5000\n",
      "Epoch 15/30\n",
      "42/42 [==============================] - 5s 123ms/step - loss: 1.1380 - accuracy: 0.6470 - val_loss: 1.3037 - val_accuracy: 0.5000\n",
      "Epoch 16/30\n",
      "42/42 [==============================] - 5s 124ms/step - loss: 1.1292 - accuracy: 0.6480 - val_loss: 1.3031 - val_accuracy: 0.5000\n",
      "Epoch 17/30\n",
      "42/42 [==============================] - 5s 124ms/step - loss: 1.1215 - accuracy: 0.6709 - val_loss: 1.3026 - val_accuracy: 0.5000\n",
      "Epoch 18/30\n",
      "42/42 [==============================] - 5s 124ms/step - loss: 1.1324 - accuracy: 0.6458 - val_loss: 1.3024 - val_accuracy: 0.5000\n",
      "Epoch 19/30\n",
      "42/42 [==============================] - 5s 124ms/step - loss: 1.1245 - accuracy: 0.6548 - val_loss: 1.3009 - val_accuracy: 0.5000\n",
      "Epoch 20/30\n",
      "42/42 [==============================] - 5s 124ms/step - loss: 1.1331 - accuracy: 0.6461 - val_loss: 1.2999 - val_accuracy: 0.5000\n",
      "Epoch 21/30\n",
      "42/42 [==============================] - 5s 124ms/step - loss: 1.1068 - accuracy: 0.6684 - val_loss: 1.3002 - val_accuracy: 0.5000\n",
      "Epoch 22/30\n",
      "42/42 [==============================] - 5s 124ms/step - loss: 1.1268 - accuracy: 0.6425 - val_loss: 1.2997 - val_accuracy: 0.5000\n",
      "Epoch 23/30\n",
      "42/42 [==============================] - 5s 124ms/step - loss: 1.1206 - accuracy: 0.6529 - val_loss: 1.2989 - val_accuracy: 0.5000\n",
      "Epoch 24/30\n",
      "42/42 [==============================] - 5s 124ms/step - loss: 1.1044 - accuracy: 0.6670 - val_loss: 1.2983 - val_accuracy: 0.5000\n",
      "Epoch 25/30\n",
      "42/42 [==============================] - 5s 124ms/step - loss: 1.1009 - accuracy: 0.6649 - val_loss: 1.2978 - val_accuracy: 0.5000\n",
      "Epoch 26/30\n",
      "42/42 [==============================] - 5s 123ms/step - loss: 1.1105 - accuracy: 0.6536 - val_loss: 1.2975 - val_accuracy: 0.5000\n",
      "Epoch 27/30\n",
      "42/42 [==============================] - 5s 124ms/step - loss: 1.1036 - accuracy: 0.6647 - val_loss: 1.2970 - val_accuracy: 0.5000\n",
      "Epoch 28/30\n",
      "42/42 [==============================] - 5s 124ms/step - loss: 1.0992 - accuracy: 0.6622 - val_loss: 1.2970 - val_accuracy: 0.5000\n",
      "Epoch 29/30\n",
      "42/42 [==============================] - 5s 124ms/step - loss: 1.1061 - accuracy: 0.6559 - val_loss: 1.2968 - val_accuracy: 0.5000\n",
      "Epoch 30/30\n",
      "42/42 [==============================] - 5s 124ms/step - loss: 1.0926 - accuracy: 0.6714 - val_loss: 1.2967 - val_accuracy: 0.5000\n",
      "INFO:tensorflow:Assets written to: ../xception/xception_30epochs_2087.1_images_False_newWeights_False_lastLayerOnly_rescale-symmetric_normalization/assets\n",
      "Test acc for xception: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training resnet for 0.025% of train size (aka 2087 images) with pretrained: True and onlyLastLayersTrained: False...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      " 6/42 [===>..........................] - ETA: 15s - loss: 1.3760 - accuracy: 0.5004WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0602s vs `on_train_batch_begin` time: 0.1332s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0602s vs `on_train_batch_end` time: 0.1741s). Check your callbacks.\n",
      "42/42 [==============================] - 11s 149ms/step - loss: 1.3590 - accuracy: 0.6463 - val_loss: 1.3663 - val_accuracy: 0.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "42/42 [==============================] - 2s 58ms/step - loss: 1.3095 - accuracy: 0.7265 - val_loss: 1.3525 - val_accuracy: 0.5000\n",
      "Epoch 3/30\n",
      "42/42 [==============================] - 2s 58ms/step - loss: 1.2661 - accuracy: 0.7392 - val_loss: 1.3432 - val_accuracy: 0.5000\n",
      "Epoch 4/30\n",
      "42/42 [==============================] - 2s 58ms/step - loss: 1.2312 - accuracy: 0.7464 - val_loss: 1.3352 - val_accuracy: 0.5000\n",
      "Epoch 5/30\n",
      "42/42 [==============================] - 2s 58ms/step - loss: 1.2044 - accuracy: 0.7401 - val_loss: 1.3320 - val_accuracy: 0.5000\n",
      "Epoch 6/30\n",
      "42/42 [==============================] - 2s 59ms/step - loss: 1.1766 - accuracy: 0.7551 - val_loss: 1.3273 - val_accuracy: 0.5000\n",
      "Epoch 7/30\n",
      "42/42 [==============================] - 2s 58ms/step - loss: 1.1570 - accuracy: 0.7488 - val_loss: 1.3247 - val_accuracy: 0.5000\n",
      "Epoch 8/30\n",
      "42/42 [==============================] - 2s 58ms/step - loss: 1.1552 - accuracy: 0.7282 - val_loss: 1.3193 - val_accuracy: 0.5000\n",
      "Epoch 9/30\n",
      "42/42 [==============================] - 2s 59ms/step - loss: 1.1185 - accuracy: 0.7614 - val_loss: 1.3205 - val_accuracy: 0.5000\n",
      "Epoch 10/30\n",
      "42/42 [==============================] - 2s 59ms/step - loss: 1.1222 - accuracy: 0.7388 - val_loss: 1.3159 - val_accuracy: 0.5000\n",
      "Epoch 11/30\n",
      "42/42 [==============================] - 2s 59ms/step - loss: 1.1003 - accuracy: 0.7499 - val_loss: 1.3145 - val_accuracy: 0.5000\n",
      "Epoch 12/30\n",
      "42/42 [==============================] - 2s 58ms/step - loss: 1.0904 - accuracy: 0.7522 - val_loss: 1.3125 - val_accuracy: 0.5000\n",
      "Epoch 13/30\n",
      "42/42 [==============================] - 2s 58ms/step - loss: 1.0957 - accuracy: 0.7383 - val_loss: 1.3124 - val_accuracy: 0.5000\n",
      "Epoch 14/30\n",
      "42/42 [==============================] - 2s 58ms/step - loss: 1.0659 - accuracy: 0.7602 - val_loss: 1.3153 - val_accuracy: 0.5000\n",
      "Epoch 15/30\n",
      "42/42 [==============================] - 2s 58ms/step - loss: 1.0577 - accuracy: 0.7639 - val_loss: 1.3113 - val_accuracy: 0.5000\n",
      "Epoch 16/30\n",
      "42/42 [==============================] - 2s 59ms/step - loss: 1.0493 - accuracy: 0.7646 - val_loss: 1.3122 - val_accuracy: 0.5000\n",
      "Epoch 17/30\n",
      "42/42 [==============================] - 2s 59ms/step - loss: 1.0643 - accuracy: 0.7443 - val_loss: 1.3116 - val_accuracy: 0.5000\n",
      "Epoch 18/30\n",
      "42/42 [==============================] - 2s 59ms/step - loss: 1.0579 - accuracy: 0.7468 - val_loss: 1.3113 - val_accuracy: 0.5000\n",
      "Epoch 19/30\n",
      "42/42 [==============================] - 2s 59ms/step - loss: 1.0442 - accuracy: 0.7565 - val_loss: 1.3122 - val_accuracy: 0.5000\n",
      "Epoch 20/30\n",
      "42/42 [==============================] - 2s 59ms/step - loss: 1.0360 - accuracy: 0.7623 - val_loss: 1.3089 - val_accuracy: 0.5000\n",
      "Epoch 21/30\n",
      "42/42 [==============================] - 2s 59ms/step - loss: 1.0595 - accuracy: 0.7362 - val_loss: 1.3098 - val_accuracy: 0.5000\n",
      "Epoch 22/30\n",
      "42/42 [==============================] - 2s 58ms/step - loss: 1.0527 - accuracy: 0.7395 - val_loss: 1.3089 - val_accuracy: 0.5000\n",
      "Epoch 23/30\n",
      "42/42 [==============================] - 2s 58ms/step - loss: 1.0285 - accuracy: 0.7608 - val_loss: 1.3094 - val_accuracy: 0.5000\n",
      "Epoch 24/30\n",
      "42/42 [==============================] - 2s 59ms/step - loss: 1.0291 - accuracy: 0.7598 - val_loss: 1.3072 - val_accuracy: 0.5000\n",
      "Epoch 25/30\n",
      "42/42 [==============================] - 2s 59ms/step - loss: 1.0399 - accuracy: 0.7475 - val_loss: 1.3095 - val_accuracy: 0.5000\n",
      "Epoch 26/30\n",
      "42/42 [==============================] - 2s 58ms/step - loss: 1.0237 - accuracy: 0.7587 - val_loss: 1.3087 - val_accuracy: 0.5000\n",
      "Epoch 27/30\n",
      "42/42 [==============================] - 2s 59ms/step - loss: 1.0285 - accuracy: 0.7543 - val_loss: 1.3076 - val_accuracy: 0.5000\n",
      "Epoch 28/30\n",
      "42/42 [==============================] - 2s 58ms/step - loss: 1.0173 - accuracy: 0.7631 - val_loss: 1.3071 - val_accuracy: 0.5000\n",
      "Epoch 29/30\n",
      "42/42 [==============================] - 2s 58ms/step - loss: 1.0424 - accuracy: 0.7392 - val_loss: 1.3082 - val_accuracy: 0.5000\n",
      "Epoch 30/30\n",
      "42/42 [==============================] - 2s 58ms/step - loss: 1.0162 - accuracy: 0.7614 - val_loss: 1.3065 - val_accuracy: 0.5000\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_2087.1_images_False_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training opticnet for 0.025% of train size (aka 2087 images) with pretrained: True and onlyLastLayersTrained: False...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      " 6/42 [===>..........................] - ETA: 1:03 - loss: 5.3456 - accuracy: 0.1877WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.4659s vs `on_train_batch_end` time: 1.0540s). Check your callbacks.\n",
      "42/42 [==============================] - 69s 1s/step - loss: 1.9796 - accuracy: 0.5703 - val_loss: 3.3953 - val_accuracy: 0.3438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "42/42 [==============================] - 49s 1s/step - loss: 0.2270 - accuracy: 0.9236 - val_loss: 0.9272 - val_accuracy: 0.6562\n",
      "Epoch 3/30\n",
      "42/42 [==============================] - 49s 1s/step - loss: 0.1560 - accuracy: 0.9476 - val_loss: 0.2262 - val_accuracy: 0.9062\n",
      "Epoch 4/30\n",
      "42/42 [==============================] - 49s 1s/step - loss: 0.0782 - accuracy: 0.9753 - val_loss: 0.1384 - val_accuracy: 0.9375\n",
      "Epoch 5/30\n",
      "42/42 [==============================] - 49s 1s/step - loss: 0.0682 - accuracy: 0.9765 - val_loss: 0.2927 - val_accuracy: 0.9062\n",
      "Epoch 6/30\n",
      "42/42 [==============================] - 49s 1s/step - loss: 0.0488 - accuracy: 0.9858 - val_loss: 0.0682 - val_accuracy: 0.9688\n",
      "Epoch 7/30\n",
      "42/42 [==============================] - 49s 1s/step - loss: 0.0319 - accuracy: 0.9888 - val_loss: 0.1955 - val_accuracy: 0.9688\n",
      "Epoch 8/30\n",
      "42/42 [==============================] - 49s 1s/step - loss: 0.0114 - accuracy: 0.9968 - val_loss: 0.1845 - val_accuracy: 0.9375\n",
      "Epoch 9/30\n",
      "42/42 [==============================] - 49s 1s/step - loss: 0.0081 - accuracy: 0.9975 - val_loss: 0.2601 - val_accuracy: 0.9375\n",
      "Epoch 10/30\n",
      "42/42 [==============================] - 49s 1s/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.2576 - val_accuracy: 0.9688\n",
      "Epoch 11/30\n",
      "42/42 [==============================] - 49s 1s/step - loss: 7.4317e-04 - accuracy: 1.0000 - val_loss: 0.2304 - val_accuracy: 0.9688\n",
      "Epoch 12/30\n",
      "42/42 [==============================] - 49s 1s/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2204 - val_accuracy: 0.9688\n",
      "Epoch 13/30\n",
      "42/42 [==============================] - 49s 1s/step - loss: 3.0664e-04 - accuracy: 1.0000 - val_loss: 0.2167 - val_accuracy: 0.9688\n",
      "Epoch 14/30\n",
      "42/42 [==============================] - 49s 1s/step - loss: 4.6324e-04 - accuracy: 1.0000 - val_loss: 0.1925 - val_accuracy: 0.9688\n",
      "Epoch 15/30\n",
      "42/42 [==============================] - 49s 1s/step - loss: 3.3620e-04 - accuracy: 1.0000 - val_loss: 0.1558 - val_accuracy: 0.9688\n",
      "Epoch 16/30\n",
      "42/42 [==============================] - 49s 1s/step - loss: 4.3272e-04 - accuracy: 1.0000 - val_loss: 0.0906 - val_accuracy: 0.9688\n",
      "Epoch 17/30\n",
      "42/42 [==============================] - 49s 1s/step - loss: 2.3561e-04 - accuracy: 1.0000 - val_loss: 0.1768 - val_accuracy: 0.9688\n",
      "Epoch 18/30\n",
      "42/42 [==============================] - 49s 1s/step - loss: 2.3408e-04 - accuracy: 1.0000 - val_loss: 0.2086 - val_accuracy: 0.9688\n",
      "Epoch 19/30\n",
      "42/42 [==============================] - 49s 1s/step - loss: 2.5179e-04 - accuracy: 1.0000 - val_loss: 0.2609 - val_accuracy: 0.9688\n",
      "Epoch 20/30\n",
      "42/42 [==============================] - 49s 1s/step - loss: 2.5618e-04 - accuracy: 1.0000 - val_loss: 0.2639 - val_accuracy: 0.9688\n",
      "Epoch 21/30\n",
      "42/42 [==============================] - 49s 1s/step - loss: 1.8501e-04 - accuracy: 1.0000 - val_loss: 0.2559 - val_accuracy: 0.9688\n",
      "Epoch 22/30\n",
      "42/42 [==============================] - 49s 1s/step - loss: 2.1751e-04 - accuracy: 1.0000 - val_loss: 0.2568 - val_accuracy: 0.9688\n",
      "Epoch 23/30\n",
      "42/42 [==============================] - 49s 1s/step - loss: 2.1524e-04 - accuracy: 1.0000 - val_loss: 0.2555 - val_accuracy: 0.9688\n",
      "Epoch 24/30\n",
      "42/42 [==============================] - 49s 1s/step - loss: 1.3023e-04 - accuracy: 1.0000 - val_loss: 0.2519 - val_accuracy: 0.9688\n",
      "Epoch 25/30\n",
      "42/42 [==============================] - 49s 1s/step - loss: 1.6332e-04 - accuracy: 1.0000 - val_loss: 0.2463 - val_accuracy: 0.9688\n",
      "Epoch 26/30\n",
      "42/42 [==============================] - 49s 1s/step - loss: 1.5209e-04 - accuracy: 1.0000 - val_loss: 0.2473 - val_accuracy: 0.9688\n",
      "Epoch 27/30\n",
      "42/42 [==============================] - 49s 1s/step - loss: 1.1840e-04 - accuracy: 1.0000 - val_loss: 0.2479 - val_accuracy: 0.9688\n",
      "Epoch 28/30\n",
      "42/42 [==============================] - 49s 1s/step - loss: 1.2537e-04 - accuracy: 1.0000 - val_loss: 0.2460 - val_accuracy: 0.9688\n",
      "Epoch 29/30\n",
      "42/42 [==============================] - 49s 1s/step - loss: 1.4128e-04 - accuracy: 1.0000 - val_loss: 0.2508 - val_accuracy: 0.9688\n",
      "Epoch 30/30\n",
      "42/42 [==============================] - 49s 1s/step - loss: 7.3629e-05 - accuracy: 1.0000 - val_loss: 0.2523 - val_accuracy: 0.9688\n",
      "INFO:tensorflow:Assets written to: ../opticnet/opticnet_30epochs_2087.1_images_False_newWeights_False_lastLayerOnly_rescale-symmetric_normalization/assets\n",
      "Test acc for opticnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.0498575  0.04993952 0.05172718 0.04839833]\n",
      "Training xception for 0.05% of train size (aka 4174 images) with pretrained: True and onlyLastLayersTrained: False...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      " 6/84 [=>............................] - ETA: 46s - loss: 1.3868 - accuracy: 0.0993WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1171s vs `on_train_batch_begin` time: 0.1920s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1171s vs `on_train_batch_end` time: 0.2071s). Check your callbacks.\n",
      "84/84 [==============================] - 17s 169ms/step - loss: 1.3707 - accuracy: 0.2728 - val_loss: 1.3965 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "84/84 [==============================] - 10s 121ms/step - loss: 1.3168 - accuracy: 0.4402 - val_loss: 1.4131 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "84/84 [==============================] - 10s 122ms/step - loss: 1.2863 - accuracy: 0.4359 - val_loss: 1.4312 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "84/84 [==============================] - 10s 122ms/step - loss: 1.2643 - accuracy: 0.4547 - val_loss: 1.4479 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "84/84 [==============================] - 10s 122ms/step - loss: 1.2543 - accuracy: 0.4448 - val_loss: 1.4620 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "84/84 [==============================] - 10s 122ms/step - loss: 1.2505 - accuracy: 0.4415 - val_loss: 1.4752 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "84/84 [==============================] - 10s 123ms/step - loss: 1.2408 - accuracy: 0.4453 - val_loss: 1.4528 - val_accuracy: 0.3125\n",
      "Epoch 8/30\n",
      "84/84 [==============================] - 10s 123ms/step - loss: 1.2261 - accuracy: 0.5221 - val_loss: 1.4102 - val_accuracy: 0.4375\n",
      "Epoch 9/30\n",
      "84/84 [==============================] - 10s 123ms/step - loss: 1.1963 - accuracy: 0.5781 - val_loss: 1.4161 - val_accuracy: 0.4375\n",
      "Epoch 10/30\n",
      "84/84 [==============================] - 10s 123ms/step - loss: 1.1705 - accuracy: 0.6006 - val_loss: 1.3812 - val_accuracy: 0.4688\n",
      "Epoch 11/30\n",
      "84/84 [==============================] - 10s 123ms/step - loss: 1.1589 - accuracy: 0.6089 - val_loss: 1.3715 - val_accuracy: 0.4688\n",
      "Epoch 12/30\n",
      "84/84 [==============================] - 10s 123ms/step - loss: 1.1381 - accuracy: 0.6268 - val_loss: 1.3830 - val_accuracy: 0.4688\n",
      "Epoch 13/30\n",
      "84/84 [==============================] - 10s 123ms/step - loss: 1.1334 - accuracy: 0.6214 - val_loss: 1.3757 - val_accuracy: 0.4688\n",
      "Epoch 14/30\n",
      "84/84 [==============================] - 10s 123ms/step - loss: 1.1059 - accuracy: 0.6411 - val_loss: 1.3510 - val_accuracy: 0.4688\n",
      "Epoch 15/30\n",
      "84/84 [==============================] - 10s 123ms/step - loss: 1.1018 - accuracy: 0.6425 - val_loss: 1.3705 - val_accuracy: 0.4688\n",
      "Epoch 16/30\n",
      "84/84 [==============================] - 10s 123ms/step - loss: 1.1059 - accuracy: 0.6401 - val_loss: 1.3600 - val_accuracy: 0.4688\n",
      "Epoch 17/30\n",
      "84/84 [==============================] - 10s 123ms/step - loss: 1.0903 - accuracy: 0.6482 - val_loss: 1.3532 - val_accuracy: 0.4688\n",
      "Epoch 18/30\n",
      "84/84 [==============================] - 10s 123ms/step - loss: 1.0916 - accuracy: 0.6494 - val_loss: 1.3602 - val_accuracy: 0.4688\n",
      "Epoch 19/30\n",
      "84/84 [==============================] - 10s 123ms/step - loss: 1.0918 - accuracy: 0.6405 - val_loss: 1.3534 - val_accuracy: 0.4688\n",
      "Epoch 20/30\n",
      "84/84 [==============================] - 10s 123ms/step - loss: 1.0932 - accuracy: 0.6389 - val_loss: 1.3594 - val_accuracy: 0.4688\n",
      "Epoch 21/30\n",
      "84/84 [==============================] - 10s 123ms/step - loss: 1.0778 - accuracy: 0.6498 - val_loss: 1.3409 - val_accuracy: 0.5000\n",
      "Epoch 22/30\n",
      "84/84 [==============================] - 10s 123ms/step - loss: 1.0638 - accuracy: 0.6609 - val_loss: 1.3544 - val_accuracy: 0.4688\n",
      "Epoch 23/30\n",
      "84/84 [==============================] - 10s 123ms/step - loss: 1.0591 - accuracy: 0.6651 - val_loss: 1.3513 - val_accuracy: 0.4688\n",
      "Epoch 24/30\n",
      "84/84 [==============================] - 10s 123ms/step - loss: 1.0631 - accuracy: 0.6550 - val_loss: 1.3492 - val_accuracy: 0.4688\n",
      "Epoch 25/30\n",
      "84/84 [==============================] - 10s 123ms/step - loss: 1.0507 - accuracy: 0.6658 - val_loss: 1.3468 - val_accuracy: 0.4688\n",
      "Epoch 26/30\n",
      "84/84 [==============================] - 10s 123ms/step - loss: 1.0629 - accuracy: 0.6560 - val_loss: 1.3634 - val_accuracy: 0.4688\n",
      "Epoch 27/30\n",
      "84/84 [==============================] - 10s 123ms/step - loss: 1.0604 - accuracy: 0.6615 - val_loss: 1.3485 - val_accuracy: 0.4688\n",
      "Epoch 28/30\n",
      "84/84 [==============================] - 10s 123ms/step - loss: 1.0687 - accuracy: 0.6525 - val_loss: 1.3531 - val_accuracy: 0.4688\n",
      "Epoch 29/30\n",
      "84/84 [==============================] - 10s 125ms/step - loss: 1.0500 - accuracy: 0.6668 - val_loss: 1.3512 - val_accuracy: 0.4688\n",
      "Epoch 30/30\n",
      "84/84 [==============================] - 10s 123ms/step - loss: 1.0546 - accuracy: 0.6575 - val_loss: 1.3569 - val_accuracy: 0.4688\n",
      "INFO:tensorflow:Assets written to: ../xception/xception_30epochs_4174.2_images_False_newWeights_False_lastLayerOnly_rescale-symmetric_normalization/assets\n",
      "Test acc for xception: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training resnet for 0.05% of train size (aka 4174 images) with pretrained: True and onlyLastLayersTrained: False...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      " 6/84 [=>............................] - ETA: 31s - loss: 1.4117 - accuracy: 0.1262WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0617s vs `on_train_batch_begin` time: 0.1264s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0617s vs `on_train_batch_end` time: 0.1598s). Check your callbacks.\n",
      "84/84 [==============================] - 12s 99ms/step - loss: 1.3736 - accuracy: 0.3515 - val_loss: 1.3454 - val_accuracy: 0.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "84/84 [==============================] - 5s 57ms/step - loss: 1.2482 - accuracy: 0.7443 - val_loss: 1.3173 - val_accuracy: 0.5000\n",
      "Epoch 3/30\n",
      "84/84 [==============================] - 5s 57ms/step - loss: 1.1726 - accuracy: 0.7441 - val_loss: 1.3077 - val_accuracy: 0.5000\n",
      "Epoch 4/30\n",
      "84/84 [==============================] - 5s 57ms/step - loss: 1.1173 - accuracy: 0.7438 - val_loss: 1.2859 - val_accuracy: 0.5000\n",
      "Epoch 5/30\n",
      "84/84 [==============================] - 5s 57ms/step - loss: 1.0744 - accuracy: 0.7417 - val_loss: 1.2684 - val_accuracy: 0.5000\n",
      "Epoch 6/30\n",
      "84/84 [==============================] - 5s 57ms/step - loss: 1.0382 - accuracy: 0.7359 - val_loss: 1.2313 - val_accuracy: 0.5000\n",
      "Epoch 7/30\n",
      "84/84 [==============================] - 5s 57ms/step - loss: 1.0003 - accuracy: 0.7374 - val_loss: 1.1968 - val_accuracy: 0.5000\n",
      "Epoch 8/30\n",
      "84/84 [==============================] - 5s 57ms/step - loss: 0.9471 - accuracy: 0.7631 - val_loss: 1.1678 - val_accuracy: 0.5000\n",
      "Epoch 9/30\n",
      "84/84 [==============================] - 5s 57ms/step - loss: 0.9405 - accuracy: 0.7416 - val_loss: 1.1463 - val_accuracy: 0.5000\n",
      "Epoch 10/30\n",
      "84/84 [==============================] - 5s 58ms/step - loss: 0.8950 - accuracy: 0.7624 - val_loss: 1.1466 - val_accuracy: 0.5000\n",
      "Epoch 11/30\n",
      "84/84 [==============================] - 5s 58ms/step - loss: 0.8911 - accuracy: 0.7468 - val_loss: 1.1356 - val_accuracy: 0.5000\n",
      "Epoch 12/30\n",
      "84/84 [==============================] - 5s 57ms/step - loss: 0.8782 - accuracy: 0.7454 - val_loss: 1.1056 - val_accuracy: 0.5000\n",
      "Epoch 13/30\n",
      "84/84 [==============================] - 5s 57ms/step - loss: 0.8612 - accuracy: 0.7462 - val_loss: 1.1057 - val_accuracy: 0.6250\n",
      "Epoch 14/30\n",
      "84/84 [==============================] - 5s 58ms/step - loss: 0.8401 - accuracy: 0.8166 - val_loss: 1.0934 - val_accuracy: 0.6562\n",
      "Epoch 15/30\n",
      "84/84 [==============================] - 5s 57ms/step - loss: 0.8397 - accuracy: 0.8211 - val_loss: 1.0985 - val_accuracy: 0.6562\n",
      "Epoch 16/30\n",
      "84/84 [==============================] - 5s 58ms/step - loss: 0.8162 - accuracy: 0.8333 - val_loss: 1.0818 - val_accuracy: 0.6875\n",
      "Epoch 17/30\n",
      "84/84 [==============================] - 5s 57ms/step - loss: 0.8044 - accuracy: 0.8424 - val_loss: 1.0778 - val_accuracy: 0.6875\n",
      "Epoch 18/30\n",
      "84/84 [==============================] - 5s 57ms/step - loss: 0.8083 - accuracy: 0.8393 - val_loss: 1.0733 - val_accuracy: 0.6875\n",
      "Epoch 19/30\n",
      "84/84 [==============================] - 5s 58ms/step - loss: 0.7836 - accuracy: 0.8510 - val_loss: 1.0654 - val_accuracy: 0.6875\n",
      "Epoch 20/30\n",
      "84/84 [==============================] - 5s 58ms/step - loss: 0.8006 - accuracy: 0.8409 - val_loss: 1.0598 - val_accuracy: 0.6875\n",
      "Epoch 21/30\n",
      "84/84 [==============================] - 5s 57ms/step - loss: 0.7779 - accuracy: 0.8526 - val_loss: 1.0641 - val_accuracy: 0.6875\n",
      "Epoch 22/30\n",
      "84/84 [==============================] - 5s 57ms/step - loss: 0.7814 - accuracy: 0.8422 - val_loss: 1.0569 - val_accuracy: 0.6875\n",
      "Epoch 23/30\n",
      "84/84 [==============================] - 5s 57ms/step - loss: 0.7656 - accuracy: 0.8550 - val_loss: 1.0516 - val_accuracy: 0.6875\n",
      "Epoch 24/30\n",
      "84/84 [==============================] - 5s 57ms/step - loss: 0.7705 - accuracy: 0.8524 - val_loss: 1.0485 - val_accuracy: 0.6875\n",
      "Epoch 25/30\n",
      "84/84 [==============================] - 5s 58ms/step - loss: 0.7560 - accuracy: 0.8588 - val_loss: 1.0437 - val_accuracy: 0.7188\n",
      "Epoch 26/30\n",
      "84/84 [==============================] - 5s 57ms/step - loss: 0.7601 - accuracy: 0.8507 - val_loss: 1.0451 - val_accuracy: 0.6875\n",
      "Epoch 27/30\n",
      "84/84 [==============================] - 5s 58ms/step - loss: 0.7588 - accuracy: 0.8559 - val_loss: 1.0424 - val_accuracy: 0.6875\n",
      "Epoch 28/30\n",
      "84/84 [==============================] - 5s 58ms/step - loss: 0.7467 - accuracy: 0.8599 - val_loss: 1.0378 - val_accuracy: 0.7188\n",
      "Epoch 29/30\n",
      "84/84 [==============================] - 5s 58ms/step - loss: 0.7598 - accuracy: 0.8556 - val_loss: 1.0406 - val_accuracy: 0.6875\n",
      "Epoch 30/30\n",
      "84/84 [==============================] - 5s 57ms/step - loss: 0.7581 - accuracy: 0.8536 - val_loss: 1.0344 - val_accuracy: 0.7188\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_4174.2_images_False_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training opticnet for 0.05% of train size (aka 4174 images) with pretrained: True and onlyLastLayersTrained: False...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      " 6/84 [=>............................] - ETA: 2:19 - loss: 5.1051 - accuracy: 0.1815WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.4691s vs `on_train_batch_end` time: 1.0659s). Check your callbacks.\n",
      "84/84 [==============================] - 118s 1s/step - loss: 1.3837 - accuracy: 0.6700 - val_loss: 0.7587 - val_accuracy: 0.7188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "84/84 [==============================] - 99s 1s/step - loss: 0.1934 - accuracy: 0.9340 - val_loss: 0.0751 - val_accuracy: 0.9688\n",
      "Epoch 3/30\n",
      "84/84 [==============================] - 99s 1s/step - loss: 0.1289 - accuracy: 0.9583 - val_loss: 0.0196 - val_accuracy: 1.0000\n",
      "Epoch 4/30\n",
      "84/84 [==============================] - 99s 1s/step - loss: 0.0751 - accuracy: 0.9769 - val_loss: 0.0722 - val_accuracy: 0.9688\n",
      "Epoch 5/30\n",
      "84/84 [==============================] - 99s 1s/step - loss: 0.0486 - accuracy: 0.9843 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
      "Epoch 6/30\n",
      "84/84 [==============================] - 99s 1s/step - loss: 0.0397 - accuracy: 0.9873 - val_loss: 0.1038 - val_accuracy: 0.9375\n",
      "Epoch 7/30\n",
      "84/84 [==============================] - 99s 1s/step - loss: 0.0287 - accuracy: 0.9901 - val_loss: 0.0297 - val_accuracy: 1.0000\n",
      "Epoch 8/30\n",
      "84/84 [==============================] - 99s 1s/step - loss: 0.0337 - accuracy: 0.9881 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
      "Epoch 9/30\n",
      "84/84 [==============================] - 99s 1s/step - loss: 0.0318 - accuracy: 0.9899 - val_loss: 4.0562e-04 - val_accuracy: 1.0000\n",
      "Epoch 10/30\n",
      "84/84 [==============================] - 98s 1s/step - loss: 0.0093 - accuracy: 0.9968 - val_loss: 6.2727e-05 - val_accuracy: 1.0000\n",
      "Epoch 11/30\n",
      "84/84 [==============================] - 97s 1s/step - loss: 0.0072 - accuracy: 0.9975 - val_loss: 6.6735e-05 - val_accuracy: 1.0000\n",
      "Epoch 12/30\n",
      "84/84 [==============================] - 97s 1s/step - loss: 0.0094 - accuracy: 0.9979 - val_loss: 0.0324 - val_accuracy: 0.9688\n",
      "Epoch 13/30\n",
      "84/84 [==============================] - 97s 1s/step - loss: 0.0019 - accuracy: 0.9993 - val_loss: 0.0277 - val_accuracy: 0.9688\n",
      "Epoch 14/30\n",
      "84/84 [==============================] - 98s 1s/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.0187 - val_accuracy: 1.0000\n",
      "Epoch 15/30\n",
      "84/84 [==============================] - 99s 1s/step - loss: 0.0017 - accuracy: 0.9996 - val_loss: 5.9241e-04 - val_accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "84/84 [==============================] - 98s 1s/step - loss: 0.0049 - accuracy: 0.9987 - val_loss: 4.3108e-04 - val_accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "84/84 [==============================] - 99s 1s/step - loss: 0.0012 - accuracy: 0.9997 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "84/84 [==============================] - 99s 1s/step - loss: 9.8272e-04 - accuracy: 0.9998 - val_loss: 5.0048e-04 - val_accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "84/84 [==============================] - 99s 1s/step - loss: 0.0012 - accuracy: 0.9993 - val_loss: 2.5324e-04 - val_accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "84/84 [==============================] - 99s 1s/step - loss: 0.0013 - accuracy: 0.9993 - val_loss: 7.8536e-04 - val_accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "84/84 [==============================] - 99s 1s/step - loss: 7.9883e-04 - accuracy: 0.9998 - val_loss: 1.1727e-04 - val_accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "84/84 [==============================] - 98s 1s/step - loss: 6.7299e-04 - accuracy: 0.9996 - val_loss: 1.6838e-04 - val_accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "84/84 [==============================] - 98s 1s/step - loss: 6.9046e-04 - accuracy: 0.9996 - val_loss: 1.3908e-04 - val_accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "84/84 [==============================] - 99s 1s/step - loss: 4.7897e-04 - accuracy: 1.0000 - val_loss: 1.8897e-04 - val_accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "84/84 [==============================] - 98s 1s/step - loss: 0.0015 - accuracy: 0.9990 - val_loss: 2.0669e-04 - val_accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "84/84 [==============================] - 99s 1s/step - loss: 9.6944e-04 - accuracy: 0.9992 - val_loss: 1.2889e-04 - val_accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "84/84 [==============================] - 99s 1s/step - loss: 6.6334e-04 - accuracy: 0.9999 - val_loss: 9.9160e-05 - val_accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "84/84 [==============================] - 98s 1s/step - loss: 8.5191e-04 - accuracy: 0.9993 - val_loss: 8.4947e-05 - val_accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "84/84 [==============================] - 99s 1s/step - loss: 7.0366e-04 - accuracy: 0.9997 - val_loss: 1.0325e-04 - val_accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "84/84 [==============================] - 98s 1s/step - loss: 0.0012 - accuracy: 0.9991 - val_loss: 1.0727e-04 - val_accuracy: 1.0000\n",
      "INFO:tensorflow:Assets written to: ../opticnet/opticnet_30epochs_4174.2_images_False_newWeights_False_lastLayerOnly_rescale-symmetric_normalization/assets\n",
      "Test acc for opticnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.07376021 0.07496304 0.07701798 0.07625348]\n",
      "Training xception for 0.075% of train size (aka 6261 images) with pretrained: True and onlyLastLayersTrained: False...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/126 [>.............................] - ETA: 1:10 - loss: 1.3703 - accuracy: 0.3616WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1180s vs `on_train_batch_begin` time: 0.1885s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1180s vs `on_train_batch_end` time: 0.2012s). Check your callbacks.\n",
      "126/126 [==============================] - 22s 150ms/step - loss: 1.3473 - accuracy: 0.4810 - val_loss: 1.3615 - val_accuracy: 0.4375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "126/126 [==============================] - 15s 121ms/step - loss: 1.2533 - accuracy: 0.6192 - val_loss: 1.3369 - val_accuracy: 0.5000\n",
      "Epoch 3/30\n",
      "126/126 [==============================] - 15s 122ms/step - loss: 1.1854 - accuracy: 0.6414 - val_loss: 1.3315 - val_accuracy: 0.4688\n",
      "Epoch 4/30\n",
      "126/126 [==============================] - 15s 122ms/step - loss: 1.1312 - accuracy: 0.6585 - val_loss: 1.3261 - val_accuracy: 0.5000\n",
      "Epoch 5/30\n",
      "126/126 [==============================] - 15s 122ms/step - loss: 1.1097 - accuracy: 0.6475 - val_loss: 1.3164 - val_accuracy: 0.5000\n",
      "Epoch 6/30\n",
      "126/126 [==============================] - 15s 123ms/step - loss: 1.0872 - accuracy: 0.6520 - val_loss: 1.3146 - val_accuracy: 0.5000\n",
      "Epoch 7/30\n",
      "126/126 [==============================] - 15s 123ms/step - loss: 1.0595 - accuracy: 0.6618 - val_loss: 1.3124 - val_accuracy: 0.5000\n",
      "Epoch 8/30\n",
      "126/126 [==============================] - 16s 123ms/step - loss: 1.0474 - accuracy: 0.6630 - val_loss: 1.3017 - val_accuracy: 0.5000\n",
      "Epoch 9/30\n",
      "126/126 [==============================] - 15s 123ms/step - loss: 1.0380 - accuracy: 0.6598 - val_loss: 1.2991 - val_accuracy: 0.5000\n",
      "Epoch 10/30\n",
      "126/126 [==============================] - 16s 123ms/step - loss: 1.0217 - accuracy: 0.6675 - val_loss: 1.3287 - val_accuracy: 0.4688\n",
      "Epoch 11/30\n",
      "126/126 [==============================] - 15s 123ms/step - loss: 1.0188 - accuracy: 0.6640 - val_loss: 1.2998 - val_accuracy: 0.5000\n",
      "Epoch 12/30\n",
      "126/126 [==============================] - 16s 123ms/step - loss: 1.0117 - accuracy: 0.6677 - val_loss: 1.2802 - val_accuracy: 0.5000\n",
      "Epoch 13/30\n",
      "126/126 [==============================] - 15s 123ms/step - loss: 1.0026 - accuracy: 0.6699 - val_loss: 1.2832 - val_accuracy: 0.5000\n",
      "Epoch 14/30\n",
      "126/126 [==============================] - 16s 123ms/step - loss: 0.9886 - accuracy: 0.6803 - val_loss: 1.2831 - val_accuracy: 0.5000\n",
      "Epoch 15/30\n",
      "126/126 [==============================] - 15s 123ms/step - loss: 0.9810 - accuracy: 0.6803 - val_loss: 1.2673 - val_accuracy: 0.5000\n",
      "Epoch 16/30\n",
      "126/126 [==============================] - 15s 123ms/step - loss: 0.9709 - accuracy: 0.6870 - val_loss: 1.2718 - val_accuracy: 0.5000\n",
      "Epoch 17/30\n",
      "126/126 [==============================] - 15s 123ms/step - loss: 0.9886 - accuracy: 0.6717 - val_loss: 1.2747 - val_accuracy: 0.5000\n",
      "Epoch 18/30\n",
      "126/126 [==============================] - 16s 123ms/step - loss: 0.9841 - accuracy: 0.6755 - val_loss: 1.2700 - val_accuracy: 0.5000\n",
      "Epoch 19/30\n",
      "126/126 [==============================] - 16s 123ms/step - loss: 0.9860 - accuracy: 0.6708 - val_loss: 1.2722 - val_accuracy: 0.5000\n",
      "Epoch 20/30\n",
      "126/126 [==============================] - 16s 123ms/step - loss: 0.9748 - accuracy: 0.6794 - val_loss: 1.2645 - val_accuracy: 0.5000\n",
      "Epoch 21/30\n",
      "126/126 [==============================] - 15s 123ms/step - loss: 0.9674 - accuracy: 0.6819 - val_loss: 1.2691 - val_accuracy: 0.5000\n",
      "Epoch 22/30\n",
      "126/126 [==============================] - 15s 123ms/step - loss: 0.9573 - accuracy: 0.6895 - val_loss: 1.2853 - val_accuracy: 0.5000\n",
      "Epoch 23/30\n",
      "126/126 [==============================] - 15s 123ms/step - loss: 0.9571 - accuracy: 0.6854 - val_loss: 1.2650 - val_accuracy: 0.5000\n",
      "Epoch 24/30\n",
      "126/126 [==============================] - 15s 123ms/step - loss: 0.9555 - accuracy: 0.6872 - val_loss: 1.2623 - val_accuracy: 0.5000\n",
      "Epoch 25/30\n",
      "126/126 [==============================] - 16s 123ms/step - loss: 0.9421 - accuracy: 0.6932 - val_loss: 1.2592 - val_accuracy: 0.5000\n",
      "Epoch 26/30\n",
      "126/126 [==============================] - 15s 123ms/step - loss: 0.9556 - accuracy: 0.6855 - val_loss: 1.2596 - val_accuracy: 0.5000\n",
      "Epoch 27/30\n",
      "126/126 [==============================] - 16s 123ms/step - loss: 0.9666 - accuracy: 0.6803 - val_loss: 1.2567 - val_accuracy: 0.5000\n",
      "Epoch 28/30\n",
      "126/126 [==============================] - 16s 123ms/step - loss: 0.9534 - accuracy: 0.6849 - val_loss: 1.2563 - val_accuracy: 0.5000\n",
      "Epoch 29/30\n",
      "126/126 [==============================] - 16s 123ms/step - loss: 0.9539 - accuracy: 0.6841 - val_loss: 1.2620 - val_accuracy: 0.5000\n",
      "Epoch 30/30\n",
      "126/126 [==============================] - 15s 123ms/step - loss: 0.9523 - accuracy: 0.6834 - val_loss: 1.2572 - val_accuracy: 0.5000\n",
      "INFO:tensorflow:Assets written to: ../xception/xception_30epochs_6261.3_images_False_newWeights_False_lastLayerOnly_rescale-symmetric_normalization/assets\n",
      "Test acc for xception: 0.247934\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training resnet for 0.075% of train size (aka 6261 images) with pretrained: True and onlyLastLayersTrained: False...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/126 [>.............................] - ETA: 58s - loss: 1.4087 - accuracy: 0.0221 WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0599s vs `on_train_batch_begin` time: 0.1920s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0599s vs `on_train_batch_end` time: 0.1639s). Check your callbacks.\n",
      "126/126 [==============================] - 15s 87ms/step - loss: 1.3752 - accuracy: 0.2946 - val_loss: 1.3990 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "126/126 [==============================] - 7s 57ms/step - loss: 1.2968 - accuracy: 0.4551 - val_loss: 1.4260 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "126/126 [==============================] - 7s 57ms/step - loss: 1.2646 - accuracy: 0.4493 - val_loss: 1.4536 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "126/126 [==============================] - 7s 57ms/step - loss: 1.2387 - accuracy: 0.4819 - val_loss: 1.3617 - val_accuracy: 0.5000\n",
      "Epoch 5/30\n",
      "126/126 [==============================] - 7s 57ms/step - loss: 1.1185 - accuracy: 0.7300 - val_loss: 1.3086 - val_accuracy: 0.5000\n",
      "Epoch 6/30\n",
      "126/126 [==============================] - 7s 57ms/step - loss: 1.0551 - accuracy: 0.7334 - val_loss: 1.2955 - val_accuracy: 0.5000\n",
      "Epoch 7/30\n",
      "126/126 [==============================] - 7s 57ms/step - loss: 1.0061 - accuracy: 0.7387 - val_loss: 1.2772 - val_accuracy: 0.5000\n",
      "Epoch 8/30\n",
      "126/126 [==============================] - 7s 57ms/step - loss: 0.9651 - accuracy: 0.7447 - val_loss: 1.2612 - val_accuracy: 0.5000\n",
      "Epoch 9/30\n",
      "126/126 [==============================] - 7s 57ms/step - loss: 0.9432 - accuracy: 0.7407 - val_loss: 1.2465 - val_accuracy: 0.5000\n",
      "Epoch 10/30\n",
      "126/126 [==============================] - 7s 57ms/step - loss: 0.9197 - accuracy: 0.7465 - val_loss: 1.2436 - val_accuracy: 0.5000\n",
      "Epoch 11/30\n",
      "126/126 [==============================] - 7s 57ms/step - loss: 0.9058 - accuracy: 0.7451 - val_loss: 1.2338 - val_accuracy: 0.5000\n",
      "Epoch 12/30\n",
      "126/126 [==============================] - 7s 58ms/step - loss: 0.8988 - accuracy: 0.7387 - val_loss: 1.2297 - val_accuracy: 0.5000\n",
      "Epoch 13/30\n",
      "126/126 [==============================] - 7s 57ms/step - loss: 0.8862 - accuracy: 0.7384 - val_loss: 1.2388 - val_accuracy: 0.5000\n",
      "Epoch 14/30\n",
      "126/126 [==============================] - 7s 58ms/step - loss: 0.8624 - accuracy: 0.7526 - val_loss: 1.2360 - val_accuracy: 0.5000\n",
      "Epoch 15/30\n",
      "126/126 [==============================] - 7s 57ms/step - loss: 0.8493 - accuracy: 0.7533 - val_loss: 1.2245 - val_accuracy: 0.5000\n",
      "Epoch 16/30\n",
      "126/126 [==============================] - 7s 57ms/step - loss: 0.8483 - accuracy: 0.7465 - val_loss: 1.2272 - val_accuracy: 0.5000\n",
      "Epoch 17/30\n",
      "126/126 [==============================] - 7s 57ms/step - loss: 0.8570 - accuracy: 0.7401 - val_loss: 1.2196 - val_accuracy: 0.5000\n",
      "Epoch 18/30\n",
      "126/126 [==============================] - 7s 57ms/step - loss: 0.8333 - accuracy: 0.7495 - val_loss: 1.2136 - val_accuracy: 0.5000\n",
      "Epoch 19/30\n",
      "126/126 [==============================] - 7s 57ms/step - loss: 0.8228 - accuracy: 0.7577 - val_loss: 1.2109 - val_accuracy: 0.5000\n",
      "Epoch 20/30\n",
      "126/126 [==============================] - 7s 57ms/step - loss: 0.8238 - accuracy: 0.7506 - val_loss: 1.2125 - val_accuracy: 0.5000\n",
      "Epoch 21/30\n",
      "126/126 [==============================] - 7s 57ms/step - loss: 0.8205 - accuracy: 0.7507 - val_loss: 1.2012 - val_accuracy: 0.5000\n",
      "Epoch 22/30\n",
      "126/126 [==============================] - 7s 57ms/step - loss: 0.8119 - accuracy: 0.7534 - val_loss: 1.2085 - val_accuracy: 0.5000\n",
      "Epoch 23/30\n",
      "126/126 [==============================] - 7s 57ms/step - loss: 0.8212 - accuracy: 0.7455 - val_loss: 1.2099 - val_accuracy: 0.5000\n",
      "Epoch 24/30\n",
      "126/126 [==============================] - 7s 57ms/step - loss: 0.8135 - accuracy: 0.7486 - val_loss: 1.2073 - val_accuracy: 0.5000\n",
      "Epoch 25/30\n",
      "126/126 [==============================] - 7s 57ms/step - loss: 0.7986 - accuracy: 0.7564 - val_loss: 1.2045 - val_accuracy: 0.5000\n",
      "Epoch 26/30\n",
      "126/126 [==============================] - 7s 57ms/step - loss: 0.7997 - accuracy: 0.7551 - val_loss: 1.2028 - val_accuracy: 0.5000\n",
      "Epoch 27/30\n",
      "126/126 [==============================] - 7s 57ms/step - loss: 0.8081 - accuracy: 0.7455 - val_loss: 1.2024 - val_accuracy: 0.5000\n",
      "Epoch 28/30\n",
      "126/126 [==============================] - 7s 57ms/step - loss: 0.8047 - accuracy: 0.7457 - val_loss: 1.1995 - val_accuracy: 0.5000\n",
      "Epoch 29/30\n",
      "126/126 [==============================] - 7s 57ms/step - loss: 0.7817 - accuracy: 0.7617 - val_loss: 1.2025 - val_accuracy: 0.5000\n",
      "Epoch 30/30\n",
      "126/126 [==============================] - 7s 58ms/step - loss: 0.8050 - accuracy: 0.7466 - val_loss: 1.2010 - val_accuracy: 0.5000\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_6261.3_images_False_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.259298\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training opticnet for 0.075% of train size (aka 6261 images) with pretrained: True and onlyLastLayersTrained: False...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/126 [>.............................] - ETA: 3:43 - loss: 5.6571 - accuracy: 0.1342WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.4679s vs `on_train_batch_end` time: 1.0702s). Check your callbacks.\n",
      "126/126 [==============================] - 167s 1s/step - loss: 1.1222 - accuracy: 0.7217 - val_loss: 0.2218 - val_accuracy: 0.9375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "126/126 [==============================] - 147s 1s/step - loss: 0.1732 - accuracy: 0.9411 - val_loss: 0.0581 - val_accuracy: 0.9688\n",
      "Epoch 3/30\n",
      "126/126 [==============================] - 148s 1s/step - loss: 0.1073 - accuracy: 0.9648 - val_loss: 0.0076 - val_accuracy: 1.0000\n",
      "Epoch 4/30\n",
      "126/126 [==============================] - 147s 1s/step - loss: 0.0720 - accuracy: 0.9752 - val_loss: 0.0099 - val_accuracy: 1.0000\n",
      "Epoch 5/30\n",
      "126/126 [==============================] - 148s 1s/step - loss: 0.0484 - accuracy: 0.9838 - val_loss: 0.0426 - val_accuracy: 1.0000\n",
      "Epoch 6/30\n",
      "126/126 [==============================] - 147s 1s/step - loss: 0.0715 - accuracy: 0.9773 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 7/30\n",
      "126/126 [==============================] - 148s 1s/step - loss: 0.0520 - accuracy: 0.9820 - val_loss: 6.7625e-04 - val_accuracy: 1.0000\n",
      "Epoch 8/30\n",
      "126/126 [==============================] - 147s 1s/step - loss: 0.0190 - accuracy: 0.9927 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
      "Epoch 9/30\n",
      "126/126 [==============================] - 148s 1s/step - loss: 0.0196 - accuracy: 0.9931 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 10/30\n",
      "126/126 [==============================] - 148s 1s/step - loss: 0.0179 - accuracy: 0.9924 - val_loss: 0.0540 - val_accuracy: 0.9688\n",
      "Epoch 11/30\n",
      "126/126 [==============================] - 148s 1s/step - loss: 0.0043 - accuracy: 0.9990 - val_loss: 0.0036 - val_accuracy: 1.0000\n",
      "Epoch 12/30\n",
      "126/126 [==============================] - 148s 1s/step - loss: 0.0106 - accuracy: 0.9973 - val_loss: 3.2340e-04 - val_accuracy: 1.0000\n",
      "Epoch 13/30\n",
      "126/126 [==============================] - 148s 1s/step - loss: 0.0037 - accuracy: 0.9992 - val_loss: 4.2410e-05 - val_accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "126/126 [==============================] - 148s 1s/step - loss: 0.0055 - accuracy: 0.9984 - val_loss: 2.3977e-04 - val_accuracy: 1.0000\n",
      "Epoch 15/30\n",
      "126/126 [==============================] - 148s 1s/step - loss: 0.0137 - accuracy: 0.9964 - val_loss: 0.0044 - val_accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "126/126 [==============================] - 148s 1s/step - loss: 0.0052 - accuracy: 0.9985 - val_loss: 1.3190e-04 - val_accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "126/126 [==============================] - 148s 1s/step - loss: 0.0040 - accuracy: 0.9986 - val_loss: 8.8481e-05 - val_accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "126/126 [==============================] - 148s 1s/step - loss: 0.0021 - accuracy: 0.9994 - val_loss: 3.7681e-05 - val_accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "126/126 [==============================] - 148s 1s/step - loss: 0.0024 - accuracy: 0.9990 - val_loss: 1.1370e-04 - val_accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "126/126 [==============================] - 148s 1s/step - loss: 0.0018 - accuracy: 0.9992 - val_loss: 1.2719e-04 - val_accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "126/126 [==============================] - 148s 1s/step - loss: 6.7051e-04 - accuracy: 0.9998 - val_loss: 7.4708e-05 - val_accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "126/126 [==============================] - 148s 1s/step - loss: 7.7985e-04 - accuracy: 0.9997 - val_loss: 4.0920e-05 - val_accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "126/126 [==============================] - 148s 1s/step - loss: 9.4607e-04 - accuracy: 0.9996 - val_loss: 8.8107e-05 - val_accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "126/126 [==============================] - 148s 1s/step - loss: 0.0015 - accuracy: 0.9991 - val_loss: 4.3822e-05 - val_accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "126/126 [==============================] - 148s 1s/step - loss: 0.0021 - accuracy: 0.9990 - val_loss: 3.5475e-05 - val_accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "126/126 [==============================] - 146s 1s/step - loss: 0.0013 - accuracy: 0.9993 - val_loss: 4.4826e-05 - val_accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "126/126 [==============================] - 147s 1s/step - loss: 0.0011 - accuracy: 0.9996 - val_loss: 4.4750e-05 - val_accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "126/126 [==============================] - 148s 1s/step - loss: 0.0012 - accuracy: 0.9993 - val_loss: 9.8500e-05 - val_accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "126/126 [==============================] - 148s 1s/step - loss: 0.0016 - accuracy: 0.9991 - val_loss: 6.6573e-05 - val_accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "126/126 [==============================] - 148s 1s/step - loss: 0.0028 - accuracy: 0.9985 - val_loss: 5.3710e-05 - val_accuracy: 1.0000\n",
      "INFO:tensorflow:Assets written to: ../opticnet/opticnet_30epochs_6261.3_images_False_newWeights_False_lastLayerOnly_rescale-symmetric_normalization/assets\n",
      "Test acc for opticnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.08835265 0.09025669 0.09111738 0.09238626]\n",
      "Training xception for 0.09% of train size (aka 7513 images) with pretrained: True and onlyLastLayersTrained: False...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/151 [>.............................] - ETA: 1:25 - loss: 1.4151 - accuracy: 0.1718WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1170s vs `on_train_batch_begin` time: 0.1935s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1170s vs `on_train_batch_end` time: 0.2005s). Check your callbacks.\n",
      "151/151 [==============================] - 25s 146ms/step - loss: 1.3657 - accuracy: 0.2946 - val_loss: 1.4202 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "151/151 [==============================] - 18s 121ms/step - loss: 1.2715 - accuracy: 0.4424 - val_loss: 1.4617 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "151/151 [==============================] - 18s 122ms/step - loss: 1.2396 - accuracy: 0.4581 - val_loss: 1.4927 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "151/151 [==============================] - 19s 123ms/step - loss: 1.2448 - accuracy: 0.4442 - val_loss: 1.5138 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "151/151 [==============================] - 19s 123ms/step - loss: 1.2308 - accuracy: 0.4542 - val_loss: 1.5265 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "151/151 [==============================] - 19s 123ms/step - loss: 1.2426 - accuracy: 0.4483 - val_loss: 1.5346 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "151/151 [==============================] - 19s 123ms/step - loss: 1.2411 - accuracy: 0.4361 - val_loss: 1.5408 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "151/151 [==============================] - 19s 123ms/step - loss: 1.2375 - accuracy: 0.4437 - val_loss: 1.5446 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "151/151 [==============================] - 19s 124ms/step - loss: 1.2343 - accuracy: 0.4470 - val_loss: 1.5466 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "151/151 [==============================] - 19s 123ms/step - loss: 1.2398 - accuracy: 0.4363 - val_loss: 1.5479 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "151/151 [==============================] - 19s 123ms/step - loss: 1.2389 - accuracy: 0.4455 - val_loss: 1.5495 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "151/151 [==============================] - 19s 124ms/step - loss: 1.2252 - accuracy: 0.4587 - val_loss: 1.5504 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "151/151 [==============================] - 19s 124ms/step - loss: 1.2297 - accuracy: 0.4498 - val_loss: 1.5504 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "151/151 [==============================] - 19s 124ms/step - loss: 1.2284 - accuracy: 0.4488 - val_loss: 1.5508 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "151/151 [==============================] - 19s 124ms/step - loss: 1.2220 - accuracy: 0.4543 - val_loss: 1.5508 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "151/151 [==============================] - 19s 124ms/step - loss: 1.2329 - accuracy: 0.4473 - val_loss: 1.5511 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "151/151 [==============================] - 19s 123ms/step - loss: 1.2341 - accuracy: 0.4476 - val_loss: 1.5513 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "151/151 [==============================] - 19s 123ms/step - loss: 1.2366 - accuracy: 0.4384 - val_loss: 1.5518 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "151/151 [==============================] - 19s 123ms/step - loss: 1.2232 - accuracy: 0.4498 - val_loss: 1.5520 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "151/151 [==============================] - 19s 123ms/step - loss: 1.2354 - accuracy: 0.4502 - val_loss: 1.5517 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "151/151 [==============================] - 19s 123ms/step - loss: 1.2282 - accuracy: 0.4463 - val_loss: 1.5519 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "151/151 [==============================] - 19s 123ms/step - loss: 1.2367 - accuracy: 0.4478 - val_loss: 1.5518 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "151/151 [==============================] - 19s 123ms/step - loss: 1.2391 - accuracy: 0.4410 - val_loss: 1.5520 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "151/151 [==============================] - 19s 123ms/step - loss: 1.2329 - accuracy: 0.4452 - val_loss: 1.5520 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "151/151 [==============================] - 19s 123ms/step - loss: 1.2368 - accuracy: 0.4431 - val_loss: 1.5521 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "151/151 [==============================] - 19s 123ms/step - loss: 1.2328 - accuracy: 0.4446 - val_loss: 1.5520 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "151/151 [==============================] - 19s 123ms/step - loss: 1.2320 - accuracy: 0.4469 - val_loss: 1.5520 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "151/151 [==============================] - 19s 123ms/step - loss: 1.2330 - accuracy: 0.4498 - val_loss: 1.5521 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "151/151 [==============================] - 19s 123ms/step - loss: 1.2379 - accuracy: 0.4385 - val_loss: 1.5520 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "151/151 [==============================] - 19s 123ms/step - loss: 1.2304 - accuracy: 0.4477 - val_loss: 1.5521 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../xception/xception_30epochs_7513.5599999999995_images_False_newWeights_False_lastLayerOnly_rescale-symmetric_normalization/assets\n",
      "Test acc for xception: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training resnet for 0.09% of train size (aka 7513 images) with pretrained: True and onlyLastLayersTrained: False...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/151 [>.............................] - ETA: 1:12 - loss: 1.3861 - accuracy: 0.2815WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0600s vs `on_train_batch_begin` time: 0.1849s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0600s vs `on_train_batch_end` time: 0.1805s). Check your callbacks.\n",
      "151/151 [==============================] - 17s 83ms/step - loss: 1.3407 - accuracy: 0.5943 - val_loss: 1.3362 - val_accuracy: 0.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "151/151 [==============================] - 9s 57ms/step - loss: 1.1863 - accuracy: 0.7455 - val_loss: 1.3041 - val_accuracy: 0.5000\n",
      "Epoch 3/30\n",
      "151/151 [==============================] - 9s 57ms/step - loss: 1.0859 - accuracy: 0.7457 - val_loss: 1.2788 - val_accuracy: 0.5000\n",
      "Epoch 4/30\n",
      "151/151 [==============================] - 9s 57ms/step - loss: 1.0158 - accuracy: 0.7485 - val_loss: 1.2565 - val_accuracy: 0.5000\n",
      "Epoch 5/30\n",
      "151/151 [==============================] - 9s 58ms/step - loss: 0.9666 - accuracy: 0.7452 - val_loss: 1.2614 - val_accuracy: 0.5000\n",
      "Epoch 6/30\n",
      "151/151 [==============================] - 9s 57ms/step - loss: 0.9215 - accuracy: 0.7530 - val_loss: 1.2383 - val_accuracy: 0.5000\n",
      "Epoch 7/30\n",
      "151/151 [==============================] - 9s 57ms/step - loss: 0.8947 - accuracy: 0.7532 - val_loss: 1.2305 - val_accuracy: 0.5000\n",
      "Epoch 8/30\n",
      "151/151 [==============================] - 9s 57ms/step - loss: 0.8685 - accuracy: 0.7505 - val_loss: 1.2313 - val_accuracy: 0.5000\n",
      "Epoch 9/30\n",
      "151/151 [==============================] - 9s 57ms/step - loss: 0.8613 - accuracy: 0.7448 - val_loss: 1.2073 - val_accuracy: 0.5000\n",
      "Epoch 10/30\n",
      "151/151 [==============================] - 9s 58ms/step - loss: 0.8448 - accuracy: 0.7481 - val_loss: 1.2128 - val_accuracy: 0.5000\n",
      "Epoch 11/30\n",
      "151/151 [==============================] - 9s 58ms/step - loss: 0.8328 - accuracy: 0.7425 - val_loss: 1.2107 - val_accuracy: 0.5000\n",
      "Epoch 12/30\n",
      "151/151 [==============================] - 9s 58ms/step - loss: 0.8183 - accuracy: 0.7502 - val_loss: 1.2038 - val_accuracy: 0.5000\n",
      "Epoch 13/30\n",
      "151/151 [==============================] - 9s 58ms/step - loss: 0.7992 - accuracy: 0.7534 - val_loss: 1.2024 - val_accuracy: 0.5000\n",
      "Epoch 14/30\n",
      "151/151 [==============================] - 9s 57ms/step - loss: 0.7872 - accuracy: 0.7533 - val_loss: 1.1953 - val_accuracy: 0.5000\n",
      "Epoch 15/30\n",
      "151/151 [==============================] - 9s 57ms/step - loss: 0.7955 - accuracy: 0.7471 - val_loss: 1.2036 - val_accuracy: 0.5000\n",
      "Epoch 16/30\n",
      "151/151 [==============================] - 9s 58ms/step - loss: 0.7846 - accuracy: 0.7500 - val_loss: 1.1772 - val_accuracy: 0.5000\n",
      "Epoch 17/30\n",
      "151/151 [==============================] - 9s 58ms/step - loss: 0.7799 - accuracy: 0.7481 - val_loss: 1.1875 - val_accuracy: 0.5000\n",
      "Epoch 18/30\n",
      "151/151 [==============================] - 9s 57ms/step - loss: 0.7614 - accuracy: 0.7595 - val_loss: 1.1874 - val_accuracy: 0.5000\n",
      "Epoch 19/30\n",
      "151/151 [==============================] - 9s 58ms/step - loss: 0.7803 - accuracy: 0.7446 - val_loss: 1.1955 - val_accuracy: 0.5000\n",
      "Epoch 20/30\n",
      "151/151 [==============================] - 9s 57ms/step - loss: 0.7616 - accuracy: 0.7559 - val_loss: 1.1606 - val_accuracy: 0.5000\n",
      "Epoch 21/30\n",
      "151/151 [==============================] - 9s 58ms/step - loss: 0.7666 - accuracy: 0.7479 - val_loss: 1.1776 - val_accuracy: 0.5000\n",
      "Epoch 22/30\n",
      "151/151 [==============================] - 9s 58ms/step - loss: 0.7548 - accuracy: 0.7514 - val_loss: 1.1707 - val_accuracy: 0.5000\n",
      "Epoch 23/30\n",
      "151/151 [==============================] - 9s 58ms/step - loss: 0.7481 - accuracy: 0.7548 - val_loss: 1.1627 - val_accuracy: 0.5000\n",
      "Epoch 24/30\n",
      "151/151 [==============================] - 9s 57ms/step - loss: 0.7588 - accuracy: 0.7488 - val_loss: 1.1689 - val_accuracy: 0.5000\n",
      "Epoch 25/30\n",
      "151/151 [==============================] - 9s 57ms/step - loss: 0.7544 - accuracy: 0.7504 - val_loss: 1.1574 - val_accuracy: 0.5000\n",
      "Epoch 26/30\n",
      "151/151 [==============================] - 9s 58ms/step - loss: 0.7560 - accuracy: 0.7470 - val_loss: 1.1672 - val_accuracy: 0.5000\n",
      "Epoch 27/30\n",
      "151/151 [==============================] - 9s 58ms/step - loss: 0.7422 - accuracy: 0.7563 - val_loss: 1.1600 - val_accuracy: 0.5000\n",
      "Epoch 28/30\n",
      "151/151 [==============================] - 9s 58ms/step - loss: 0.7371 - accuracy: 0.7587 - val_loss: 1.1577 - val_accuracy: 0.5000\n",
      "Epoch 29/30\n",
      "151/151 [==============================] - 9s 57ms/step - loss: 0.7497 - accuracy: 0.7456 - val_loss: 1.1622 - val_accuracy: 0.5000\n",
      "Epoch 30/30\n",
      "151/151 [==============================] - 9s 58ms/step - loss: 0.7274 - accuracy: 0.7616 - val_loss: 1.1627 - val_accuracy: 0.5000\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_7513.5599999999995_images_False_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.220041\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training opticnet for 0.09% of train size (aka 7513 images) with pretrained: True and onlyLastLayersTrained: False...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/151 [>.............................] - ETA: 4:27 - loss: 5.3703 - accuracy: 0.1507WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.4670s vs `on_train_batch_end` time: 1.0619s). Check your callbacks.\n",
      "151/151 [==============================] - 196s 1s/step - loss: 1.0160 - accuracy: 0.7380 - val_loss: 0.2260 - val_accuracy: 0.9062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "151/151 [==============================] - 177s 1s/step - loss: 0.1385 - accuracy: 0.9583 - val_loss: 0.0835 - val_accuracy: 1.0000\n",
      "Epoch 3/30\n",
      "151/151 [==============================] - 177s 1s/step - loss: 0.1127 - accuracy: 0.9607 - val_loss: 0.0658 - val_accuracy: 0.9688\n",
      "Epoch 4/30\n",
      "151/151 [==============================] - 177s 1s/step - loss: 0.0808 - accuracy: 0.9751 - val_loss: 0.0089 - val_accuracy: 1.0000\n",
      "Epoch 5/30\n",
      "151/151 [==============================] - 177s 1s/step - loss: 0.0694 - accuracy: 0.9749 - val_loss: 0.0465 - val_accuracy: 0.9688\n",
      "Epoch 6/30\n",
      "151/151 [==============================] - 177s 1s/step - loss: 0.0452 - accuracy: 0.9857 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
      "Epoch 7/30\n",
      "151/151 [==============================] - 177s 1s/step - loss: 0.0447 - accuracy: 0.9871 - val_loss: 0.0045 - val_accuracy: 1.0000\n",
      "Epoch 8/30\n",
      "151/151 [==============================] - 177s 1s/step - loss: 0.0263 - accuracy: 0.9925 - val_loss: 0.0737 - val_accuracy: 0.9688\n",
      "Epoch 9/30\n",
      "151/151 [==============================] - 177s 1s/step - loss: 0.0354 - accuracy: 0.9859 - val_loss: 0.0042 - val_accuracy: 1.0000\n",
      "Epoch 10/30\n",
      "151/151 [==============================] - 178s 1s/step - loss: 0.0091 - accuracy: 0.9972 - val_loss: 7.4327e-04 - val_accuracy: 1.0000\n",
      "Epoch 11/30\n",
      "151/151 [==============================] - 177s 1s/step - loss: 0.0080 - accuracy: 0.9980 - val_loss: 0.0435 - val_accuracy: 0.9688\n",
      "Epoch 12/30\n",
      "151/151 [==============================] - 177s 1s/step - loss: 0.0047 - accuracy: 0.9994 - val_loss: 0.0727 - val_accuracy: 0.9688\n",
      "Epoch 13/30\n",
      "151/151 [==============================] - 178s 1s/step - loss: 0.0168 - accuracy: 0.9943 - val_loss: 0.0080 - val_accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "151/151 [==============================] - 177s 1s/step - loss: 0.0063 - accuracy: 0.9983 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
      "Epoch 15/30\n",
      "151/151 [==============================] - 177s 1s/step - loss: 0.0031 - accuracy: 0.9990 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "151/151 [==============================] - 178s 1s/step - loss: 0.0016 - accuracy: 0.9996 - val_loss: 8.8550e-04 - val_accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "151/151 [==============================] - 177s 1s/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "151/151 [==============================] - 178s 1s/step - loss: 0.0017 - accuracy: 0.9995 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "151/151 [==============================] - 177s 1s/step - loss: 0.0017 - accuracy: 0.9989 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "151/151 [==============================] - 177s 1s/step - loss: 0.0033 - accuracy: 0.9985 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "151/151 [==============================] - 177s 1s/step - loss: 0.0011 - accuracy: 0.9992 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "151/151 [==============================] - 177s 1s/step - loss: 8.1257e-04 - accuracy: 0.9999 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "151/151 [==============================] - 177s 1s/step - loss: 0.0014 - accuracy: 0.9992 - val_loss: 9.4075e-04 - val_accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "151/151 [==============================] - 178s 1s/step - loss: 0.0016 - accuracy: 0.9994 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "151/151 [==============================] - 177s 1s/step - loss: 0.0027 - accuracy: 0.9990 - val_loss: 8.9152e-04 - val_accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "151/151 [==============================] - 177s 1s/step - loss: 0.0022 - accuracy: 0.9988 - val_loss: 7.2103e-04 - val_accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "151/151 [==============================] - 178s 1s/step - loss: 0.0018 - accuracy: 0.9989 - val_loss: 9.6287e-04 - val_accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "151/151 [==============================] - 177s 1s/step - loss: 5.4033e-04 - accuracy: 0.9998 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "151/151 [==============================] - 177s 1s/step - loss: 0.0014 - accuracy: 0.9992 - val_loss: 9.0674e-04 - val_accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "151/151 [==============================] - 177s 1s/step - loss: 0.0012 - accuracy: 0.9996 - val_loss: 9.0825e-04 - val_accuracy: 1.0000\n",
      "INFO:tensorflow:Assets written to: ../opticnet/opticnet_30epochs_7513.5599999999995_images_False_newWeights_False_lastLayerOnly_rescale-symmetric_normalization/assets\n",
      "Test acc for opticnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.09777693 0.10020159 0.10133944 0.10410864]\n",
      "Training xception for 0.1% of train size (aka 8348 images) with pretrained: True and onlyLastLayersTrained: False...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/167 [>.............................] - ETA: 1:29 - loss: 1.3735 - accuracy: 0.4418WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1192s vs `on_train_batch_begin` time: 0.1316s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1192s vs `on_train_batch_end` time: 0.2310s). Check your callbacks.\n",
      "167/167 [==============================] - 27s 145ms/step - loss: 1.3443 - accuracy: 0.4507 - val_loss: 1.4175 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "167/167 [==============================] - 20s 122ms/step - loss: 1.2740 - accuracy: 0.4424 - val_loss: 1.4610 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "167/167 [==============================] - 20s 122ms/step - loss: 1.2496 - accuracy: 0.4444 - val_loss: 1.4942 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "167/167 [==============================] - 21s 123ms/step - loss: 1.2519 - accuracy: 0.4339 - val_loss: 1.5159 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "167/167 [==============================] - 21s 124ms/step - loss: 1.2421 - accuracy: 0.4478 - val_loss: 1.5271 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "167/167 [==============================] - 21s 124ms/step - loss: 1.2338 - accuracy: 0.4527 - val_loss: 1.5191 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "167/167 [==============================] - 21s 124ms/step - loss: 1.2378 - accuracy: 0.4417 - val_loss: 1.5258 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "167/167 [==============================] - 21s 124ms/step - loss: 1.2288 - accuracy: 0.4598 - val_loss: 1.4145 - val_accuracy: 0.3750\n",
      "Epoch 9/30\n",
      "167/167 [==============================] - 21s 124ms/step - loss: 1.2108 - accuracy: 0.5251 - val_loss: 1.4048 - val_accuracy: 0.4062\n",
      "Epoch 10/30\n",
      "167/167 [==============================] - 21s 124ms/step - loss: 1.1777 - accuracy: 0.5538 - val_loss: 1.3621 - val_accuracy: 0.4688\n",
      "Epoch 11/30\n",
      "167/167 [==============================] - 21s 124ms/step - loss: 1.1573 - accuracy: 0.5679 - val_loss: 1.3572 - val_accuracy: 0.4688\n",
      "Epoch 12/30\n",
      "167/167 [==============================] - 21s 124ms/step - loss: 1.1434 - accuracy: 0.5825 - val_loss: 1.3176 - val_accuracy: 0.5000\n",
      "Epoch 13/30\n",
      "167/167 [==============================] - 21s 124ms/step - loss: 1.1223 - accuracy: 0.5998 - val_loss: 1.3206 - val_accuracy: 0.5000\n",
      "Epoch 14/30\n",
      "167/167 [==============================] - 21s 124ms/step - loss: 1.1295 - accuracy: 0.5878 - val_loss: 1.3066 - val_accuracy: 0.5000\n",
      "Epoch 15/30\n",
      "167/167 [==============================] - 21s 124ms/step - loss: 1.1014 - accuracy: 0.6102 - val_loss: 1.3012 - val_accuracy: 0.5000\n",
      "Epoch 16/30\n",
      "167/167 [==============================] - 21s 124ms/step - loss: 1.1035 - accuracy: 0.5997 - val_loss: 1.3064 - val_accuracy: 0.5000\n",
      "Epoch 17/30\n",
      "167/167 [==============================] - 21s 124ms/step - loss: 1.0857 - accuracy: 0.6181 - val_loss: 1.2874 - val_accuracy: 0.5000\n",
      "Epoch 18/30\n",
      "167/167 [==============================] - 21s 124ms/step - loss: 1.0899 - accuracy: 0.6146 - val_loss: 1.2943 - val_accuracy: 0.5000\n",
      "Epoch 19/30\n",
      "167/167 [==============================] - 21s 124ms/step - loss: 1.0766 - accuracy: 0.6237 - val_loss: 1.2758 - val_accuracy: 0.5000\n",
      "Epoch 20/30\n",
      "167/167 [==============================] - 21s 124ms/step - loss: 1.0884 - accuracy: 0.6078 - val_loss: 1.2895 - val_accuracy: 0.5000\n",
      "Epoch 21/30\n",
      "167/167 [==============================] - 21s 124ms/step - loss: 1.0718 - accuracy: 0.6180 - val_loss: 1.2843 - val_accuracy: 0.5000\n",
      "Epoch 22/30\n",
      "167/167 [==============================] - 21s 124ms/step - loss: 1.0615 - accuracy: 0.6272 - val_loss: 1.2782 - val_accuracy: 0.5000\n",
      "Epoch 23/30\n",
      "167/167 [==============================] - 21s 124ms/step - loss: 1.0680 - accuracy: 0.6216 - val_loss: 1.2774 - val_accuracy: 0.5000\n",
      "Epoch 24/30\n",
      "167/167 [==============================] - 21s 124ms/step - loss: 1.0693 - accuracy: 0.6207 - val_loss: 1.2771 - val_accuracy: 0.5000\n",
      "Epoch 25/30\n",
      "167/167 [==============================] - 21s 124ms/step - loss: 1.0698 - accuracy: 0.6232 - val_loss: 1.2761 - val_accuracy: 0.5000\n",
      "Epoch 26/30\n",
      "167/167 [==============================] - 21s 124ms/step - loss: 1.0379 - accuracy: 0.6443 - val_loss: 1.2740 - val_accuracy: 0.5000\n",
      "Epoch 27/30\n",
      "167/167 [==============================] - 21s 124ms/step - loss: 1.0605 - accuracy: 0.6269 - val_loss: 1.2725 - val_accuracy: 0.5000\n",
      "Epoch 28/30\n",
      "167/167 [==============================] - 21s 124ms/step - loss: 1.0544 - accuracy: 0.6317 - val_loss: 1.2717 - val_accuracy: 0.5000\n",
      "Epoch 29/30\n",
      "167/167 [==============================] - 21s 124ms/step - loss: 1.0503 - accuracy: 0.6353 - val_loss: 1.2704 - val_accuracy: 0.5000\n",
      "Epoch 30/30\n",
      "167/167 [==============================] - 21s 124ms/step - loss: 1.0586 - accuracy: 0.6275 - val_loss: 1.2710 - val_accuracy: 0.5000\n",
      "INFO:tensorflow:Assets written to: ../xception/xception_30epochs_8348.4_images_False_newWeights_False_lastLayerOnly_rescale-symmetric_normalization/assets\n",
      "Test acc for xception: 0.241736\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training resnet for 0.1% of train size (aka 8348 images) with pretrained: True and onlyLastLayersTrained: False...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/167 [>.............................] - ETA: 1:18 - loss: 1.3658 - accuracy: 0.4707WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0618s vs `on_train_batch_begin` time: 0.1970s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0618s vs `on_train_batch_end` time: 0.1590s). Check your callbacks.\n",
      "167/167 [==============================] - 17s 81ms/step - loss: 1.3149 - accuracy: 0.6229 - val_loss: 1.3056 - val_accuracy: 0.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "167/167 [==============================] - 10s 57ms/step - loss: 1.1578 - accuracy: 0.7368 - val_loss: 1.2708 - val_accuracy: 0.5000\n",
      "Epoch 3/30\n",
      "167/167 [==============================] - 10s 57ms/step - loss: 1.0457 - accuracy: 0.7466 - val_loss: 1.2455 - val_accuracy: 0.5000\n",
      "Epoch 4/30\n",
      "167/167 [==============================] - 10s 57ms/step - loss: 0.9735 - accuracy: 0.7518 - val_loss: 1.2400 - val_accuracy: 0.5000\n",
      "Epoch 5/30\n",
      "167/167 [==============================] - 10s 57ms/step - loss: 0.9192 - accuracy: 0.7519 - val_loss: 1.2258 - val_accuracy: 0.5000\n",
      "Epoch 6/30\n",
      "167/167 [==============================] - 10s 57ms/step - loss: 0.8841 - accuracy: 0.7526 - val_loss: 1.2275 - val_accuracy: 0.5000\n",
      "Epoch 7/30\n",
      "167/167 [==============================] - 10s 58ms/step - loss: 0.8567 - accuracy: 0.7526 - val_loss: 1.2070 - val_accuracy: 0.5000\n",
      "Epoch 8/30\n",
      "167/167 [==============================] - 10s 58ms/step - loss: 0.8452 - accuracy: 0.7468 - val_loss: 1.1945 - val_accuracy: 0.5000\n",
      "Epoch 9/30\n",
      "167/167 [==============================] - 10s 58ms/step - loss: 0.8113 - accuracy: 0.7577 - val_loss: 1.1850 - val_accuracy: 0.5000\n",
      "Epoch 10/30\n",
      "167/167 [==============================] - 10s 57ms/step - loss: 0.8128 - accuracy: 0.7487 - val_loss: 1.1732 - val_accuracy: 0.5000\n",
      "Epoch 11/30\n",
      "167/167 [==============================] - 10s 58ms/step - loss: 0.8034 - accuracy: 0.7479 - val_loss: 1.1775 - val_accuracy: 0.5000\n",
      "Epoch 12/30\n",
      "167/167 [==============================] - 10s 58ms/step - loss: 0.7920 - accuracy: 0.7435 - val_loss: 1.1845 - val_accuracy: 0.5000\n",
      "Epoch 13/30\n",
      "167/167 [==============================] - 10s 58ms/step - loss: 0.7706 - accuracy: 0.7537 - val_loss: 1.1697 - val_accuracy: 0.5000\n",
      "Epoch 14/30\n",
      "167/167 [==============================] - 10s 58ms/step - loss: 0.7745 - accuracy: 0.7494 - val_loss: 1.1783 - val_accuracy: 0.5000\n",
      "Epoch 15/30\n",
      "167/167 [==============================] - 10s 58ms/step - loss: 0.7655 - accuracy: 0.7504 - val_loss: 1.1514 - val_accuracy: 0.5000\n",
      "Epoch 16/30\n",
      "167/167 [==============================] - 10s 58ms/step - loss: 0.7500 - accuracy: 0.7574 - val_loss: 1.1818 - val_accuracy: 0.5000\n",
      "Epoch 17/30\n",
      "167/167 [==============================] - 10s 58ms/step - loss: 0.7445 - accuracy: 0.7591 - val_loss: 1.1558 - val_accuracy: 0.5000\n",
      "Epoch 18/30\n",
      "167/167 [==============================] - 10s 57ms/step - loss: 0.7425 - accuracy: 0.7532 - val_loss: 1.1471 - val_accuracy: 0.5000\n",
      "Epoch 19/30\n",
      "167/167 [==============================] - 10s 58ms/step - loss: 0.7477 - accuracy: 0.7481 - val_loss: 1.1549 - val_accuracy: 0.5000\n",
      "Epoch 20/30\n",
      "167/167 [==============================] - 10s 58ms/step - loss: 0.7387 - accuracy: 0.7497 - val_loss: 1.1456 - val_accuracy: 0.5000\n",
      "Epoch 21/30\n",
      "167/167 [==============================] - 10s 58ms/step - loss: 0.7394 - accuracy: 0.7490 - val_loss: 1.1529 - val_accuracy: 0.5000\n",
      "Epoch 22/30\n",
      "167/167 [==============================] - 10s 58ms/step - loss: 0.7391 - accuracy: 0.7484 - val_loss: 1.1612 - val_accuracy: 0.5000\n",
      "Epoch 23/30\n",
      "167/167 [==============================] - 10s 58ms/step - loss: 0.7250 - accuracy: 0.7548 - val_loss: 1.1465 - val_accuracy: 0.5000\n",
      "Epoch 24/30\n",
      "167/167 [==============================] - 10s 58ms/step - loss: 0.7133 - accuracy: 0.7619 - val_loss: 1.1548 - val_accuracy: 0.5000\n",
      "Epoch 25/30\n",
      "167/167 [==============================] - 10s 58ms/step - loss: 0.7270 - accuracy: 0.7516 - val_loss: 1.1511 - val_accuracy: 0.5000\n",
      "Epoch 26/30\n",
      "167/167 [==============================] - 10s 58ms/step - loss: 0.7189 - accuracy: 0.7564 - val_loss: 1.1395 - val_accuracy: 0.5000\n",
      "Epoch 27/30\n",
      "167/167 [==============================] - 10s 58ms/step - loss: 0.7272 - accuracy: 0.7519 - val_loss: 1.1433 - val_accuracy: 0.5000\n",
      "Epoch 28/30\n",
      "167/167 [==============================] - 10s 58ms/step - loss: 0.7183 - accuracy: 0.7502 - val_loss: 1.1460 - val_accuracy: 0.5000\n",
      "Epoch 29/30\n",
      "167/167 [==============================] - 10s 58ms/step - loss: 0.7241 - accuracy: 0.7514 - val_loss: 1.1501 - val_accuracy: 0.5000\n",
      "Epoch 30/30\n",
      "167/167 [==============================] - 10s 58ms/step - loss: 0.7299 - accuracy: 0.7421 - val_loss: 1.1428 - val_accuracy: 0.5000\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_8348.4_images_False_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.206612\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training opticnet for 0.1% of train size (aka 8348 images) with pretrained: True and onlyLastLayersTrained: False...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/167 [>.............................] - ETA: 5:02 - loss: 5.4964 - accuracy: 0.1677WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.4667s vs `on_train_batch_end` time: 1.0687s). Check your callbacks.\n",
      "167/167 [==============================] - 219s 1s/step - loss: 0.9410 - accuracy: 0.7632 - val_loss: 0.0782 - val_accuracy: 0.9375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "167/167 [==============================] - 197s 1s/step - loss: 0.1469 - accuracy: 0.9504 - val_loss: 0.0801 - val_accuracy: 1.0000\n",
      "Epoch 3/30\n",
      "167/167 [==============================] - 197s 1s/step - loss: 0.1164 - accuracy: 0.9602 - val_loss: 0.0724 - val_accuracy: 0.9688\n",
      "Epoch 4/30\n",
      "167/167 [==============================] - 197s 1s/step - loss: 0.0828 - accuracy: 0.9738 - val_loss: 0.0729 - val_accuracy: 0.9688\n",
      "Epoch 5/30\n",
      "167/167 [==============================] - 197s 1s/step - loss: 0.0607 - accuracy: 0.9797 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
      "Epoch 6/30\n",
      "167/167 [==============================] - 197s 1s/step - loss: 0.0327 - accuracy: 0.9895 - val_loss: 0.0268 - val_accuracy: 1.0000\n",
      "Epoch 7/30\n",
      "167/167 [==============================] - 197s 1s/step - loss: 0.0361 - accuracy: 0.9890 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 8/30\n",
      "167/167 [==============================] - 197s 1s/step - loss: 0.0202 - accuracy: 0.9928 - val_loss: 0.0074 - val_accuracy: 1.0000\n",
      "Epoch 9/30\n",
      "167/167 [==============================] - 196s 1s/step - loss: 0.0149 - accuracy: 0.9955 - val_loss: 0.0310 - val_accuracy: 0.9688\n",
      "Epoch 10/30\n",
      "167/167 [==============================] - 196s 1s/step - loss: 0.0119 - accuracy: 0.9956 - val_loss: 4.9199e-04 - val_accuracy: 1.0000\n",
      "Epoch 11/30\n",
      "167/167 [==============================] - 197s 1s/step - loss: 0.0087 - accuracy: 0.9979 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
      "Epoch 12/30\n",
      "167/167 [==============================] - 196s 1s/step - loss: 0.0066 - accuracy: 0.9981 - val_loss: 3.6661e-04 - val_accuracy: 1.0000\n",
      "Epoch 13/30\n",
      "167/167 [==============================] - 196s 1s/step - loss: 0.0030 - accuracy: 0.9991 - val_loss: 0.0046 - val_accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "167/167 [==============================] - 197s 1s/step - loss: 0.0027 - accuracy: 0.9991 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 15/30\n",
      "167/167 [==============================] - 197s 1s/step - loss: 0.0030 - accuracy: 0.9995 - val_loss: 5.9994e-04 - val_accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "167/167 [==============================] - 196s 1s/step - loss: 0.0023 - accuracy: 0.9992 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "167/167 [==============================] - 197s 1s/step - loss: 9.8860e-04 - accuracy: 0.9996 - val_loss: 0.0090 - val_accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "167/167 [==============================] - 197s 1s/step - loss: 0.0025 - accuracy: 0.9989 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "167/167 [==============================] - 195s 1s/step - loss: 8.8521e-04 - accuracy: 0.9998 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "167/167 [==============================] - 196s 1s/step - loss: 0.0021 - accuracy: 0.9993 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "167/167 [==============================] - 195s 1s/step - loss: 0.0012 - accuracy: 0.9993 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "167/167 [==============================] - 196s 1s/step - loss: 0.0018 - accuracy: 0.9989 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "167/167 [==============================] - 196s 1s/step - loss: 0.0017 - accuracy: 0.9992 - val_loss: 6.2106e-04 - val_accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "167/167 [==============================] - 196s 1s/step - loss: 0.0012 - accuracy: 0.9995 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "167/167 [==============================] - 196s 1s/step - loss: 0.0019 - accuracy: 0.9992 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "167/167 [==============================] - 197s 1s/step - loss: 0.0015 - accuracy: 0.9992 - val_loss: 8.0823e-04 - val_accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "167/167 [==============================] - 196s 1s/step - loss: 0.0022 - accuracy: 0.9987 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "167/167 [==============================] - 197s 1s/step - loss: 0.0011 - accuracy: 0.9995 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "167/167 [==============================] - 197s 1s/step - loss: 8.5352e-04 - accuracy: 0.9994 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "167/167 [==============================] - 197s 1s/step - loss: 0.0010 - accuracy: 0.9996 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "INFO:tensorflow:Assets written to: ../opticnet/opticnet_30epochs_8348.4_images_False_newWeights_False_lastLayerOnly_rescale-symmetric_normalization/assets\n",
      "Test acc for opticnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.24943948 0.24918694 0.24735636 0.25870474]\n",
      "Training xception for 0.25% of train size (aka 20871 images) with pretrained: True and onlyLastLayersTrained: False...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/418 [..............................] - ETA: 4:05 - loss: 1.4112 - accuracy: 0.1005WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1236s vs `on_train_batch_begin` time: 0.1938s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1236s vs `on_train_batch_end` time: 0.1997s). Check your callbacks.\n",
      "418/418 [==============================] - 57s 130ms/step - loss: 1.3260 - accuracy: 0.3636 - val_loss: 1.3705 - val_accuracy: 0.4688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "418/418 [==============================] - 51s 122ms/step - loss: 1.1339 - accuracy: 0.6024 - val_loss: 1.3578 - val_accuracy: 0.4688\n",
      "Epoch 3/30\n",
      "418/418 [==============================] - 51s 123ms/step - loss: 1.0756 - accuracy: 0.6137 - val_loss: 1.2943 - val_accuracy: 0.4688\n",
      "Epoch 4/30\n",
      "418/418 [==============================] - 51s 123ms/step - loss: 1.0400 - accuracy: 0.6374 - val_loss: 1.2407 - val_accuracy: 0.5000\n",
      "Epoch 5/30\n",
      "418/418 [==============================] - 51s 123ms/step - loss: 1.0259 - accuracy: 0.6401 - val_loss: 1.2593 - val_accuracy: 0.5000\n",
      "Epoch 6/30\n",
      "418/418 [==============================] - 51s 123ms/step - loss: 1.0114 - accuracy: 0.6471 - val_loss: 1.2377 - val_accuracy: 0.5000\n",
      "Epoch 7/30\n",
      "418/418 [==============================] - 52s 123ms/step - loss: 1.0059 - accuracy: 0.6500 - val_loss: 1.2704 - val_accuracy: 0.5000\n",
      "Epoch 8/30\n",
      "418/418 [==============================] - 51s 123ms/step - loss: 0.9952 - accuracy: 0.6557 - val_loss: 1.2490 - val_accuracy: 0.5000\n",
      "Epoch 9/30\n",
      "418/418 [==============================] - 52s 123ms/step - loss: 0.9885 - accuracy: 0.6571 - val_loss: 1.2130 - val_accuracy: 0.5000\n",
      "Epoch 10/30\n",
      "418/418 [==============================] - 51s 123ms/step - loss: 0.9770 - accuracy: 0.6647 - val_loss: 1.2270 - val_accuracy: 0.5000\n",
      "Epoch 11/30\n",
      "418/418 [==============================] - 51s 123ms/step - loss: 0.9790 - accuracy: 0.6611 - val_loss: 1.2237 - val_accuracy: 0.5000\n",
      "Epoch 12/30\n",
      "418/418 [==============================] - 51s 123ms/step - loss: 0.9769 - accuracy: 0.6616 - val_loss: 1.2105 - val_accuracy: 0.5000\n",
      "Epoch 13/30\n",
      "418/418 [==============================] - 51s 123ms/step - loss: 0.9751 - accuracy: 0.6620 - val_loss: 1.2083 - val_accuracy: 0.5000\n",
      "Epoch 14/30\n",
      "418/418 [==============================] - 51s 123ms/step - loss: 0.9601 - accuracy: 0.6704 - val_loss: 1.2086 - val_accuracy: 0.5000\n",
      "Epoch 15/30\n",
      "418/418 [==============================] - 51s 123ms/step - loss: 0.9579 - accuracy: 0.6713 - val_loss: 1.2090 - val_accuracy: 0.5000\n",
      "Epoch 16/30\n",
      "418/418 [==============================] - 51s 123ms/step - loss: 0.9494 - accuracy: 0.6760 - val_loss: 1.1997 - val_accuracy: 0.5000\n",
      "Epoch 17/30\n",
      "418/418 [==============================] - 51s 123ms/step - loss: 0.9655 - accuracy: 0.6669 - val_loss: 1.2091 - val_accuracy: 0.5000\n",
      "Epoch 18/30\n",
      "418/418 [==============================] - 51s 123ms/step - loss: 0.9530 - accuracy: 0.6720 - val_loss: 1.2041 - val_accuracy: 0.5000\n",
      "Epoch 19/30\n",
      "418/418 [==============================] - 51s 123ms/step - loss: 0.9548 - accuracy: 0.6712 - val_loss: 1.2015 - val_accuracy: 0.5000\n",
      "Epoch 20/30\n",
      "418/418 [==============================] - 52s 123ms/step - loss: 0.9592 - accuracy: 0.6707 - val_loss: 1.1965 - val_accuracy: 0.5000\n",
      "Epoch 21/30\n",
      "418/418 [==============================] - 51s 123ms/step - loss: 0.9487 - accuracy: 0.6749 - val_loss: 1.2099 - val_accuracy: 0.5000\n",
      "Epoch 22/30\n",
      "418/418 [==============================] - 51s 123ms/step - loss: 0.9420 - accuracy: 0.6768 - val_loss: 1.2025 - val_accuracy: 0.5000\n",
      "Epoch 23/30\n",
      "418/418 [==============================] - 51s 123ms/step - loss: 0.9537 - accuracy: 0.6722 - val_loss: 1.2047 - val_accuracy: 0.5000\n",
      "Epoch 24/30\n",
      "418/418 [==============================] - 51s 123ms/step - loss: 0.9525 - accuracy: 0.6722 - val_loss: 1.2026 - val_accuracy: 0.5000\n",
      "Epoch 25/30\n",
      "418/418 [==============================] - 51s 123ms/step - loss: 0.9480 - accuracy: 0.6755 - val_loss: 1.2039 - val_accuracy: 0.5000\n",
      "Epoch 26/30\n",
      "418/418 [==============================] - 51s 123ms/step - loss: 0.9471 - accuracy: 0.6748 - val_loss: 1.2000 - val_accuracy: 0.5000\n",
      "Epoch 27/30\n",
      "418/418 [==============================] - 52s 123ms/step - loss: 0.9441 - accuracy: 0.6777 - val_loss: 1.2031 - val_accuracy: 0.5000\n",
      "Epoch 28/30\n",
      "418/418 [==============================] - 51s 123ms/step - loss: 0.9526 - accuracy: 0.6725 - val_loss: 1.2048 - val_accuracy: 0.5000\n",
      "Epoch 29/30\n",
      "418/418 [==============================] - 51s 123ms/step - loss: 0.9447 - accuracy: 0.6767 - val_loss: 1.2047 - val_accuracy: 0.5000\n",
      "Epoch 30/30\n",
      "418/418 [==============================] - 51s 123ms/step - loss: 0.9417 - accuracy: 0.6775 - val_loss: 1.2026 - val_accuracy: 0.5000\n",
      "INFO:tensorflow:Assets written to: ../xception/xception_30epochs_20871.0_images_False_newWeights_False_lastLayerOnly_rescale-symmetric_normalization/assets\n",
      "Test acc for xception: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training resnet for 0.25% of train size (aka 20871 images) with pretrained: True and onlyLastLayersTrained: False...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/418 [..............................] - ETA: 3:19 - loss: 1.3500 - accuracy: 0.5611WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0607s vs `on_train_batch_begin` time: 0.1954s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0607s vs `on_train_batch_end` time: 0.1573s). Check your callbacks.\n",
      "418/418 [==============================] - 31s 66ms/step - loss: 1.2413 - accuracy: 0.7115 - val_loss: 1.2642 - val_accuracy: 0.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "418/418 [==============================] - 24s 57ms/step - loss: 0.9660 - accuracy: 0.7402 - val_loss: 1.2192 - val_accuracy: 0.5000\n",
      "Epoch 3/30\n",
      "418/418 [==============================] - 24s 57ms/step - loss: 0.8512 - accuracy: 0.7458 - val_loss: 1.2027 - val_accuracy: 0.5000\n",
      "Epoch 4/30\n",
      "418/418 [==============================] - 24s 57ms/step - loss: 0.7874 - accuracy: 0.7496 - val_loss: 1.1837 - val_accuracy: 0.5000\n",
      "Epoch 5/30\n",
      "418/418 [==============================] - 24s 57ms/step - loss: 0.7606 - accuracy: 0.7455 - val_loss: 1.1152 - val_accuracy: 0.5000\n",
      "Epoch 6/30\n",
      "418/418 [==============================] - 24s 57ms/step - loss: 0.7329 - accuracy: 0.7454 - val_loss: 1.1289 - val_accuracy: 0.5000\n",
      "Epoch 7/30\n",
      "418/418 [==============================] - 24s 57ms/step - loss: 0.7152 - accuracy: 0.7484 - val_loss: 1.1071 - val_accuracy: 0.5000\n",
      "Epoch 8/30\n",
      "418/418 [==============================] - 24s 57ms/step - loss: 0.6987 - accuracy: 0.7505 - val_loss: 1.1289 - val_accuracy: 0.5000\n",
      "Epoch 9/30\n",
      "418/418 [==============================] - 24s 57ms/step - loss: 0.6794 - accuracy: 0.7550 - val_loss: 1.1161 - val_accuracy: 0.5000\n",
      "Epoch 10/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 0.6758 - accuracy: 0.7516 - val_loss: 1.0905 - val_accuracy: 0.5000\n",
      "Epoch 11/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 0.6686 - accuracy: 0.7531 - val_loss: 1.0622 - val_accuracy: 0.5000\n",
      "Epoch 12/30\n",
      "418/418 [==============================] - 24s 57ms/step - loss: 0.6621 - accuracy: 0.7524 - val_loss: 1.0941 - val_accuracy: 0.5000\n",
      "Epoch 13/30\n",
      "418/418 [==============================] - 24s 57ms/step - loss: 0.6545 - accuracy: 0.7535 - val_loss: 1.0764 - val_accuracy: 0.5000\n",
      "Epoch 14/30\n",
      "418/418 [==============================] - 24s 57ms/step - loss: 0.6515 - accuracy: 0.7563 - val_loss: 1.0776 - val_accuracy: 0.5000\n",
      "Epoch 15/30\n",
      "418/418 [==============================] - 24s 57ms/step - loss: 0.6581 - accuracy: 0.7512 - val_loss: 1.0778 - val_accuracy: 0.5000\n",
      "Epoch 16/30\n",
      "418/418 [==============================] - 24s 57ms/step - loss: 0.6625 - accuracy: 0.7451 - val_loss: 1.0881 - val_accuracy: 0.5000\n",
      "Epoch 17/30\n",
      "418/418 [==============================] - 24s 57ms/step - loss: 0.6451 - accuracy: 0.7551 - val_loss: 1.1017 - val_accuracy: 0.5000\n",
      "Epoch 18/30\n",
      "418/418 [==============================] - 24s 57ms/step - loss: 0.6509 - accuracy: 0.7478 - val_loss: 1.0938 - val_accuracy: 0.5000\n",
      "Epoch 19/30\n",
      "418/418 [==============================] - 24s 57ms/step - loss: 0.6404 - accuracy: 0.7514 - val_loss: 1.0714 - val_accuracy: 0.5000\n",
      "Epoch 20/30\n",
      "418/418 [==============================] - 24s 57ms/step - loss: 0.6321 - accuracy: 0.7587 - val_loss: 1.0766 - val_accuracy: 0.5000\n",
      "Epoch 21/30\n",
      "418/418 [==============================] - 24s 57ms/step - loss: 0.6433 - accuracy: 0.7508 - val_loss: 1.0702 - val_accuracy: 0.5000\n",
      "Epoch 22/30\n",
      "418/418 [==============================] - 24s 57ms/step - loss: 0.6351 - accuracy: 0.7551 - val_loss: 1.0830 - val_accuracy: 0.5000\n",
      "Epoch 23/30\n",
      "418/418 [==============================] - 24s 57ms/step - loss: 0.6411 - accuracy: 0.7513 - val_loss: 1.0491 - val_accuracy: 0.5000\n",
      "Epoch 24/30\n",
      "418/418 [==============================] - 24s 57ms/step - loss: 0.6298 - accuracy: 0.7572 - val_loss: 1.0497 - val_accuracy: 0.5000\n",
      "Epoch 25/30\n",
      "418/418 [==============================] - 24s 57ms/step - loss: 0.6387 - accuracy: 0.7522 - val_loss: 1.0859 - val_accuracy: 0.5000\n",
      "Epoch 26/30\n",
      "418/418 [==============================] - 24s 57ms/step - loss: 0.6343 - accuracy: 0.7523 - val_loss: 1.0946 - val_accuracy: 0.5000\n",
      "Epoch 27/30\n",
      "418/418 [==============================] - 24s 57ms/step - loss: 0.6368 - accuracy: 0.7518 - val_loss: 1.0431 - val_accuracy: 0.5000\n",
      "Epoch 28/30\n",
      "418/418 [==============================] - 24s 57ms/step - loss: 0.6312 - accuracy: 0.7534 - val_loss: 1.0383 - val_accuracy: 0.5000\n",
      "Epoch 29/30\n",
      "418/418 [==============================] - 24s 57ms/step - loss: 0.6353 - accuracy: 0.7495 - val_loss: 1.0667 - val_accuracy: 0.5000\n",
      "Epoch 30/30\n",
      "418/418 [==============================] - 24s 57ms/step - loss: 0.6308 - accuracy: 0.7552 - val_loss: 1.0635 - val_accuracy: 0.5000\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_20871.0_images_False_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.248967\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training opticnet for 0.25% of train size (aka 20871 images) with pretrained: True and onlyLastLayersTrained: False...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:15: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  self.fig = plt.figure(figsize=(4,3))\n",
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/418 [..............................] - ETA: 12:29 - loss: 5.4660 - accuracy: 0.1714  WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.4645s vs `on_train_batch_end` time: 1.0534s). Check your callbacks.\n",
      "418/418 [==============================] - 512s 1s/step - loss: 0.5694 - accuracy: 0.8491 - val_loss: 0.0584 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "418/418 [==============================] - 490s 1s/step - loss: 0.1354 - accuracy: 0.9554 - val_loss: 0.3435 - val_accuracy: 0.8438\n",
      "Epoch 3/30\n",
      "418/418 [==============================] - 490s 1s/step - loss: 0.1080 - accuracy: 0.9635 - val_loss: 0.0409 - val_accuracy: 1.0000\n",
      "Epoch 4/30\n",
      "418/418 [==============================] - 490s 1s/step - loss: 0.0861 - accuracy: 0.9699 - val_loss: 0.0110 - val_accuracy: 1.0000\n",
      "Epoch 5/30\n",
      "418/418 [==============================] - 491s 1s/step - loss: 0.0676 - accuracy: 0.9775 - val_loss: 0.0282 - val_accuracy: 1.0000\n",
      "Epoch 6/30\n",
      "418/418 [==============================] - 491s 1s/step - loss: 0.0446 - accuracy: 0.9851 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
      "Epoch 7/30\n",
      "418/418 [==============================] - 490s 1s/step - loss: 0.0458 - accuracy: 0.9841 - val_loss: 0.0106 - val_accuracy: 1.0000\n",
      "Epoch 8/30\n",
      "418/418 [==============================] - 488s 1s/step - loss: 0.0278 - accuracy: 0.9912 - val_loss: 6.8164e-04 - val_accuracy: 1.0000\n",
      "Epoch 9/30\n",
      "418/418 [==============================] - 489s 1s/step - loss: 0.0179 - accuracy: 0.9941 - val_loss: 0.0137 - val_accuracy: 1.0000\n",
      "Epoch 10/30\n",
      "418/418 [==============================] - 491s 1s/step - loss: 0.0159 - accuracy: 0.9949 - val_loss: 0.0143 - val_accuracy: 1.0000\n",
      "Epoch 11/30\n",
      "418/418 [==============================] - 483s 1s/step - loss: 0.0131 - accuracy: 0.9963 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
      "Epoch 12/30\n",
      "418/418 [==============================] - 492s 1s/step - loss: 0.0099 - accuracy: 0.9969 - val_loss: 0.0071 - val_accuracy: 1.0000\n",
      "Epoch 13/30\n",
      "418/418 [==============================] - 491s 1s/step - loss: 0.0109 - accuracy: 0.9967 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "418/418 [==============================] - 491s 1s/step - loss: 0.0082 - accuracy: 0.9974 - val_loss: 9.4245e-04 - val_accuracy: 1.0000\n",
      "Epoch 15/30\n",
      "418/418 [==============================] - 491s 1s/step - loss: 0.0059 - accuracy: 0.9984 - val_loss: 4.7581e-04 - val_accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "418/418 [==============================] - 490s 1s/step - loss: 0.0038 - accuracy: 0.9987 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "418/418 [==============================] - 490s 1s/step - loss: 0.0043 - accuracy: 0.9987 - val_loss: 1.9992e-04 - val_accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "418/418 [==============================] - 490s 1s/step - loss: 0.0041 - accuracy: 0.9984 - val_loss: 1.6982e-04 - val_accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "418/418 [==============================] - 491s 1s/step - loss: 0.0029 - accuracy: 0.9992 - val_loss: 1.1969e-04 - val_accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "418/418 [==============================] - 486s 1s/step - loss: 0.0030 - accuracy: 0.9988 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "418/418 [==============================] - 490s 1s/step - loss: 0.0029 - accuracy: 0.9990 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "418/418 [==============================] - 490s 1s/step - loss: 0.0027 - accuracy: 0.9990 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "418/418 [==============================] - 487s 1s/step - loss: 0.0020 - accuracy: 0.9991 - val_loss: 3.4370e-04 - val_accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "418/418 [==============================] - 489s 1s/step - loss: 0.0028 - accuracy: 0.9984 - val_loss: 6.5065e-04 - val_accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "418/418 [==============================] - 490s 1s/step - loss: 0.0020 - accuracy: 0.9989 - val_loss: 1.7546e-04 - val_accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "418/418 [==============================] - 490s 1s/step - loss: 0.0013 - accuracy: 0.9994 - val_loss: 7.5604e-04 - val_accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "418/418 [==============================] - 491s 1s/step - loss: 0.0014 - accuracy: 0.9993 - val_loss: 1.6607e-04 - val_accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "418/418 [==============================] - 490s 1s/step - loss: 0.0022 - accuracy: 0.9987 - val_loss: 3.2743e-04 - val_accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "418/418 [==============================] - 491s 1s/step - loss: 0.0014 - accuracy: 0.9993 - val_loss: 1.1575e-04 - val_accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "418/418 [==============================] - 491s 1s/step - loss: 0.0016 - accuracy: 0.9990 - val_loss: 8.1526e-05 - val_accuracy: 1.0000\n",
      "INFO:tensorflow:Assets written to: ../opticnet/opticnet_30epochs_20871.0_images_False_newWeights_False_lastLayerOnly_rescale-symmetric_normalization/assets\n",
      "Test acc for opticnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.40068402 0.39922053 0.39813183 0.4036676 ]\n",
      "Training xception for 0.4% of train size (aka 33393 images) with pretrained: True and onlyLastLayersTrained: False...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/668 [..............................] - ETA: 6:33 - loss: 1.4134 - accuracy: 0.1152WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1174s vs `on_train_batch_begin` time: 0.1684s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1174s vs `on_train_batch_end` time: 0.2294s). Check your callbacks.\n",
      "668/668 [==============================] - 90s 127ms/step - loss: 1.3158 - accuracy: 0.3759 - val_loss: 1.5199 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "668/668 [==============================] - 82s 123ms/step - loss: 1.2295 - accuracy: 0.4444 - val_loss: 1.5539 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "668/668 [==============================] - 82s 123ms/step - loss: 1.2309 - accuracy: 0.4423 - val_loss: 1.5611 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "668/668 [==============================] - 82s 123ms/step - loss: 1.2312 - accuracy: 0.4439 - val_loss: 1.5591 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "668/668 [==============================] - 82s 123ms/step - loss: 1.2188 - accuracy: 0.4741 - val_loss: 1.3823 - val_accuracy: 0.4375\n",
      "Epoch 6/30\n",
      "668/668 [==============================] - 83s 124ms/step - loss: 1.0957 - accuracy: 0.6090 - val_loss: 1.3943 - val_accuracy: 0.4688\n",
      "Epoch 7/30\n",
      "668/668 [==============================] - 82s 123ms/step - loss: 1.0321 - accuracy: 0.6384 - val_loss: 1.3034 - val_accuracy: 0.5000\n",
      "Epoch 8/30\n",
      "668/668 [==============================] - 82s 123ms/step - loss: 1.0110 - accuracy: 0.6475 - val_loss: 1.2961 - val_accuracy: 0.5000\n",
      "Epoch 9/30\n",
      "668/668 [==============================] - 82s 123ms/step - loss: 0.9893 - accuracy: 0.6558 - val_loss: 1.2887 - val_accuracy: 0.5000\n",
      "Epoch 10/30\n",
      "668/668 [==============================] - 82s 123ms/step - loss: 0.9818 - accuracy: 0.6598 - val_loss: 1.2882 - val_accuracy: 0.5000\n",
      "Epoch 11/30\n",
      "668/668 [==============================] - 82s 123ms/step - loss: 0.9809 - accuracy: 0.6594 - val_loss: 1.2285 - val_accuracy: 0.5000\n",
      "Epoch 12/30\n",
      "668/668 [==============================] - 82s 123ms/step - loss: 0.9702 - accuracy: 0.6637 - val_loss: 1.2592 - val_accuracy: 0.5000\n",
      "Epoch 13/30\n",
      "668/668 [==============================] - 82s 123ms/step - loss: 0.9658 - accuracy: 0.6649 - val_loss: 1.2404 - val_accuracy: 0.5000\n",
      "Epoch 14/30\n",
      "668/668 [==============================] - 82s 123ms/step - loss: 0.9612 - accuracy: 0.6656 - val_loss: 1.2355 - val_accuracy: 0.5000\n",
      "Epoch 15/30\n",
      "668/668 [==============================] - 82s 123ms/step - loss: 0.9495 - accuracy: 0.6730 - val_loss: 1.2401 - val_accuracy: 0.5000\n",
      "Epoch 16/30\n",
      "668/668 [==============================] - 82s 123ms/step - loss: 0.9505 - accuracy: 0.6727 - val_loss: 1.2124 - val_accuracy: 0.5000\n",
      "Epoch 17/30\n",
      "668/668 [==============================] - 82s 123ms/step - loss: 0.9417 - accuracy: 0.6766 - val_loss: 1.2369 - val_accuracy: 0.5000\n",
      "Epoch 18/30\n",
      "668/668 [==============================] - 82s 123ms/step - loss: 0.9525 - accuracy: 0.6698 - val_loss: 1.2282 - val_accuracy: 0.5000\n",
      "Epoch 19/30\n",
      "668/668 [==============================] - 82s 123ms/step - loss: 0.9427 - accuracy: 0.6749 - val_loss: 1.2226 - val_accuracy: 0.5000\n",
      "Epoch 20/30\n",
      "668/668 [==============================] - 82s 123ms/step - loss: 0.9434 - accuracy: 0.6732 - val_loss: 1.2217 - val_accuracy: 0.5000\n",
      "Epoch 21/30\n",
      "668/668 [==============================] - 82s 123ms/step - loss: 0.9319 - accuracy: 0.6807 - val_loss: 1.2201 - val_accuracy: 0.5000\n",
      "Epoch 22/30\n",
      "668/668 [==============================] - 82s 123ms/step - loss: 0.9354 - accuracy: 0.6777 - val_loss: 1.2226 - val_accuracy: 0.5000\n",
      "Epoch 23/30\n",
      "668/668 [==============================] - 82s 123ms/step - loss: 0.9273 - accuracy: 0.6827 - val_loss: 1.2237 - val_accuracy: 0.5000\n",
      "Epoch 24/30\n",
      "668/668 [==============================] - 82s 123ms/step - loss: 0.9293 - accuracy: 0.6809 - val_loss: 1.2219 - val_accuracy: 0.5000\n",
      "Epoch 25/30\n",
      "668/668 [==============================] - 82s 123ms/step - loss: 0.9335 - accuracy: 0.6810 - val_loss: 1.2344 - val_accuracy: 0.5000\n",
      "Epoch 26/30\n",
      "668/668 [==============================] - 82s 123ms/step - loss: 0.9304 - accuracy: 0.6826 - val_loss: 1.2142 - val_accuracy: 0.5000\n",
      "Epoch 27/30\n",
      "668/668 [==============================] - 82s 123ms/step - loss: 0.9333 - accuracy: 0.6777 - val_loss: 1.2303 - val_accuracy: 0.5000\n",
      "Epoch 28/30\n",
      "668/668 [==============================] - 82s 123ms/step - loss: 0.9317 - accuracy: 0.6795 - val_loss: 1.2267 - val_accuracy: 0.5000\n",
      "Epoch 29/30\n",
      "668/668 [==============================] - 82s 123ms/step - loss: 0.9308 - accuracy: 0.6800 - val_loss: 1.2264 - val_accuracy: 0.5000\n",
      "Epoch 30/30\n",
      "668/668 [==============================] - 82s 123ms/step - loss: 0.9310 - accuracy: 0.6797 - val_loss: 1.2265 - val_accuracy: 0.5000\n",
      "INFO:tensorflow:Assets written to: ../xception/xception_30epochs_33393.6_images_False_newWeights_False_lastLayerOnly_rescale-symmetric_normalization/assets\n",
      "Test acc for xception: 0.248967\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training resnet for 0.4% of train size (aka 33393 images) with pretrained: True and onlyLastLayersTrained: False...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/668 [..............................] - ETA: 5:25 - loss: 1.3832 - accuracy: 0.3781WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0601s vs `on_train_batch_begin` time: 0.1976s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0601s vs `on_train_batch_end` time: 0.1629s). Check your callbacks.\n",
      "668/668 [==============================] - 45s 62ms/step - loss: 1.2209 - accuracy: 0.7169 - val_loss: 1.2433 - val_accuracy: 0.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "668/668 [==============================] - 38s 57ms/step - loss: 0.8718 - accuracy: 0.7516 - val_loss: 1.1621 - val_accuracy: 0.5000\n",
      "Epoch 3/30\n",
      "668/668 [==============================] - 38s 57ms/step - loss: 0.7652 - accuracy: 0.7528 - val_loss: 1.1372 - val_accuracy: 0.5000\n",
      "Epoch 4/30\n",
      "668/668 [==============================] - 38s 57ms/step - loss: 0.7230 - accuracy: 0.7511 - val_loss: 1.1201 - val_accuracy: 0.5000\n",
      "Epoch 5/30\n",
      "668/668 [==============================] - 38s 57ms/step - loss: 0.6940 - accuracy: 0.7503 - val_loss: 1.0830 - val_accuracy: 0.5000\n",
      "Epoch 6/30\n",
      "668/668 [==============================] - 38s 57ms/step - loss: 0.6726 - accuracy: 0.7536 - val_loss: 1.0633 - val_accuracy: 0.5000\n",
      "Epoch 7/30\n",
      "668/668 [==============================] - 38s 57ms/step - loss: 0.6603 - accuracy: 0.7529 - val_loss: 1.0497 - val_accuracy: 0.5000\n",
      "Epoch 8/30\n",
      "668/668 [==============================] - 38s 57ms/step - loss: 0.6560 - accuracy: 0.7507 - val_loss: 1.0716 - val_accuracy: 0.5000\n",
      "Epoch 9/30\n",
      "668/668 [==============================] - 38s 57ms/step - loss: 0.6483 - accuracy: 0.7501 - val_loss: 1.1068 - val_accuracy: 0.5000\n",
      "Epoch 10/30\n",
      "668/668 [==============================] - 38s 57ms/step - loss: 0.6387 - accuracy: 0.7533 - val_loss: 1.0428 - val_accuracy: 0.5000\n",
      "Epoch 11/30\n",
      "668/668 [==============================] - 38s 57ms/step - loss: 0.6341 - accuracy: 0.7544 - val_loss: 1.0813 - val_accuracy: 0.5000\n",
      "Epoch 12/30\n",
      "668/668 [==============================] - 38s 57ms/step - loss: 0.6245 - accuracy: 0.7560 - val_loss: 1.0384 - val_accuracy: 0.5000\n",
      "Epoch 13/30\n",
      "668/668 [==============================] - 38s 57ms/step - loss: 0.6284 - accuracy: 0.7549 - val_loss: 1.0582 - val_accuracy: 0.5000\n",
      "Epoch 14/30\n",
      "668/668 [==============================] - 38s 57ms/step - loss: 0.6264 - accuracy: 0.7536 - val_loss: 1.0661 - val_accuracy: 0.5000\n",
      "Epoch 15/30\n",
      "668/668 [==============================] - 38s 57ms/step - loss: 0.6210 - accuracy: 0.7543 - val_loss: 1.0453 - val_accuracy: 0.5000\n",
      "Epoch 16/30\n",
      "668/668 [==============================] - 38s 57ms/step - loss: 0.6138 - accuracy: 0.7574 - val_loss: 1.0466 - val_accuracy: 0.5000\n",
      "Epoch 17/30\n",
      "668/668 [==============================] - 38s 57ms/step - loss: 0.6246 - accuracy: 0.7547 - val_loss: 1.0499 - val_accuracy: 0.5000\n",
      "Epoch 18/30\n",
      "668/668 [==============================] - 38s 57ms/step - loss: 0.6167 - accuracy: 0.7583 - val_loss: 1.0772 - val_accuracy: 0.5000\n",
      "Epoch 19/30\n",
      "668/668 [==============================] - 38s 57ms/step - loss: 0.6127 - accuracy: 0.7591 - val_loss: 1.0352 - val_accuracy: 0.5000\n",
      "Epoch 20/30\n",
      "668/668 [==============================] - 38s 57ms/step - loss: 0.6221 - accuracy: 0.7548 - val_loss: 1.0525 - val_accuracy: 0.5312\n",
      "Epoch 21/30\n",
      "668/668 [==============================] - 38s 57ms/step - loss: 0.6062 - accuracy: 0.7646 - val_loss: 1.0404 - val_accuracy: 0.5000\n",
      "Epoch 22/30\n",
      "668/668 [==============================] - 38s 57ms/step - loss: 0.6168 - accuracy: 0.7587 - val_loss: 1.0477 - val_accuracy: 0.5312\n",
      "Epoch 23/30\n",
      "668/668 [==============================] - 38s 57ms/step - loss: 0.6121 - accuracy: 0.7583 - val_loss: 1.0369 - val_accuracy: 0.5000\n",
      "Epoch 24/30\n",
      "668/668 [==============================] - 38s 57ms/step - loss: 0.6042 - accuracy: 0.7640 - val_loss: 1.0481 - val_accuracy: 0.5312\n",
      "Epoch 25/30\n",
      "668/668 [==============================] - 38s 57ms/step - loss: 0.6063 - accuracy: 0.7634 - val_loss: 1.0492 - val_accuracy: 0.5312\n",
      "Epoch 26/30\n",
      "668/668 [==============================] - 38s 57ms/step - loss: 0.6080 - accuracy: 0.7604 - val_loss: 1.0531 - val_accuracy: 0.5312\n",
      "Epoch 27/30\n",
      "668/668 [==============================] - 38s 57ms/step - loss: 0.6100 - accuracy: 0.7604 - val_loss: 1.0574 - val_accuracy: 0.5312\n",
      "Epoch 28/30\n",
      "668/668 [==============================] - 38s 57ms/step - loss: 0.6088 - accuracy: 0.7621 - val_loss: 1.0445 - val_accuracy: 0.5312\n",
      "Epoch 29/30\n",
      "668/668 [==============================] - 38s 57ms/step - loss: 0.6027 - accuracy: 0.7645 - val_loss: 1.0497 - val_accuracy: 0.5312\n",
      "Epoch 30/30\n",
      "668/668 [==============================] - 38s 57ms/step - loss: 0.6139 - accuracy: 0.7568 - val_loss: 1.0464 - val_accuracy: 0.5312\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_33393.6_images_False_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training opticnet for 0.4% of train size (aka 33393 images) with pretrained: True and onlyLastLayersTrained: False...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/668 [..............................] - ETA: 20:27 - loss: 5.4519 - accuracy: 0.1771WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.4675s vs `on_train_batch_end` time: 1.0542s). Check your callbacks.\n",
      "668/668 [==============================] - 806s 1s/step - loss: 0.4684 - accuracy: 0.8713 - val_loss: 0.0669 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "668/668 [==============================] - 784s 1s/step - loss: 0.1233 - accuracy: 0.9576 - val_loss: 0.0295 - val_accuracy: 1.0000\n",
      "Epoch 3/30\n",
      "668/668 [==============================] - 784s 1s/step - loss: 0.0972 - accuracy: 0.9689 - val_loss: 0.0936 - val_accuracy: 0.9688\n",
      "Epoch 4/30\n",
      "668/668 [==============================] - 785s 1s/step - loss: 0.0872 - accuracy: 0.9706 - val_loss: 0.0195 - val_accuracy: 1.0000\n",
      "Epoch 5/30\n",
      "668/668 [==============================] - 785s 1s/step - loss: 0.0668 - accuracy: 0.9774 - val_loss: 0.0170 - val_accuracy: 1.0000\n",
      "Epoch 6/30\n",
      "668/668 [==============================] - 785s 1s/step - loss: 0.0589 - accuracy: 0.9802 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
      "Epoch 7/30\n",
      "668/668 [==============================] - 784s 1s/step - loss: 0.0389 - accuracy: 0.9868 - val_loss: 0.0260 - val_accuracy: 1.0000\n",
      "Epoch 8/30\n",
      "668/668 [==============================] - 785s 1s/step - loss: 0.0369 - accuracy: 0.9879 - val_loss: 0.0166 - val_accuracy: 1.0000\n",
      "Epoch 9/30\n",
      "668/668 [==============================] - 784s 1s/step - loss: 0.0229 - accuracy: 0.9933 - val_loss: 0.0456 - val_accuracy: 0.9688\n",
      "Epoch 10/30\n",
      "668/668 [==============================] - 783s 1s/step - loss: 0.0216 - accuracy: 0.9930 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
      "Epoch 11/30\n",
      "668/668 [==============================] - 781s 1s/step - loss: 0.0134 - accuracy: 0.9962 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
      "Epoch 12/30\n",
      "668/668 [==============================] - 785s 1s/step - loss: 0.0138 - accuracy: 0.9957 - val_loss: 0.0038 - val_accuracy: 1.0000\n",
      "Epoch 13/30\n",
      "668/668 [==============================] - 777s 1s/step - loss: 0.0088 - accuracy: 0.9976 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "668/668 [==============================] - 783s 1s/step - loss: 0.0083 - accuracy: 0.9972 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
      "Epoch 15/30\n",
      "668/668 [==============================] - 778s 1s/step - loss: 0.0127 - accuracy: 0.9956 - val_loss: 9.7885e-04 - val_accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "668/668 [==============================] - 784s 1s/step - loss: 0.0063 - accuracy: 0.9982 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "668/668 [==============================] - 780s 1s/step - loss: 0.0053 - accuracy: 0.9983 - val_loss: 2.1195e-04 - val_accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "668/668 [==============================] - 782s 1s/step - loss: 0.0041 - accuracy: 0.9986 - val_loss: 7.7025e-05 - val_accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "668/668 [==============================] - 783s 1s/step - loss: 0.0044 - accuracy: 0.9984 - val_loss: 2.0481e-04 - val_accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "668/668 [==============================] - 778s 1s/step - loss: 0.0028 - accuracy: 0.9990 - val_loss: 8.0068e-04 - val_accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "668/668 [==============================] - 783s 1s/step - loss: 0.0039 - accuracy: 0.9984 - val_loss: 1.1885e-04 - val_accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "668/668 [==============================] - 785s 1s/step - loss: 0.0031 - accuracy: 0.9985 - val_loss: 1.8313e-04 - val_accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "668/668 [==============================] - 786s 1s/step - loss: 0.0026 - accuracy: 0.9990 - val_loss: 3.5800e-04 - val_accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "668/668 [==============================] - 784s 1s/step - loss: 0.0026 - accuracy: 0.9989 - val_loss: 1.0046e-04 - val_accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "668/668 [==============================] - 781s 1s/step - loss: 0.0027 - accuracy: 0.9987 - val_loss: 1.8728e-04 - val_accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "668/668 [==============================] - 780s 1s/step - loss: 0.0030 - accuracy: 0.9984 - val_loss: 7.0492e-05 - val_accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "668/668 [==============================] - 778s 1s/step - loss: 0.0018 - accuracy: 0.9990 - val_loss: 6.8883e-05 - val_accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "668/668 [==============================] - 778s 1s/step - loss: 0.0021 - accuracy: 0.9986 - val_loss: 6.2669e-05 - val_accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "668/668 [==============================] - 783s 1s/step - loss: 0.0025 - accuracy: 0.9988 - val_loss: 3.0664e-05 - val_accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "668/668 [==============================] - 782s 1s/step - loss: 0.0020 - accuracy: 0.9989 - val_loss: 7.6977e-05 - val_accuracy: 1.0000\n",
      "INFO:tensorflow:Assets written to: ../opticnet/opticnet_30epochs_33393.6_images_False_newWeights_False_lastLayerOnly_rescale-symmetric_normalization/assets\n",
      "Test acc for opticnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.49766293 0.4985889  0.50608037 0.50522284]\n",
      "Training xception for 0.5% of train size (aka 41742 images) with pretrained: True and onlyLastLayersTrained: False...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/835 [..............................] - ETA: 7:20 - loss: 1.3754 - accuracy: 0.0804WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1170s vs `on_train_batch_begin` time: 0.1346s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1170s vs `on_train_batch_end` time: 0.2112s). Check your callbacks.\n",
      "835/835 [==============================] - 108s 126ms/step - loss: 1.2898 - accuracy: 0.4143 - val_loss: 1.5410 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "835/835 [==============================] - 102s 123ms/step - loss: 1.2306 - accuracy: 0.4449 - val_loss: 1.5476 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "835/835 [==============================] - 103s 123ms/step - loss: 1.2275 - accuracy: 0.4503 - val_loss: 1.5458 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "835/835 [==============================] - 103s 123ms/step - loss: 1.2303 - accuracy: 0.4486 - val_loss: 1.5537 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "835/835 [==============================] - 103s 123ms/step - loss: 1.2305 - accuracy: 0.4486 - val_loss: 1.5530 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "835/835 [==============================] - 103s 123ms/step - loss: 1.2272 - accuracy: 0.4489 - val_loss: 1.5498 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "835/835 [==============================] - 103s 123ms/step - loss: 1.2308 - accuracy: 0.4469 - val_loss: 1.5503 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "835/835 [==============================] - 103s 123ms/step - loss: 1.2319 - accuracy: 0.4455 - val_loss: 1.5528 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "835/835 [==============================] - 103s 123ms/step - loss: 1.2301 - accuracy: 0.4458 - val_loss: 1.5534 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "835/835 [==============================] - 103s 123ms/step - loss: 1.2324 - accuracy: 0.4463 - val_loss: 1.5566 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "835/835 [==============================] - 103s 123ms/step - loss: 1.2313 - accuracy: 0.4465 - val_loss: 1.5541 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "835/835 [==============================] - 103s 123ms/step - loss: 1.2312 - accuracy: 0.4454 - val_loss: 1.5326 - val_accuracy: 0.2812\n",
      "Epoch 13/30\n",
      "835/835 [==============================] - 103s 123ms/step - loss: 1.2305 - accuracy: 0.4492 - val_loss: 1.5538 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "835/835 [==============================] - 103s 123ms/step - loss: 1.2348 - accuracy: 0.4414 - val_loss: 1.5543 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "835/835 [==============================] - 103s 123ms/step - loss: 1.2307 - accuracy: 0.4513 - val_loss: 1.5423 - val_accuracy: 0.2812\n",
      "Epoch 16/30\n",
      "835/835 [==============================] - 102s 123ms/step - loss: 1.2308 - accuracy: 0.4506 - val_loss: 1.5448 - val_accuracy: 0.2812\n",
      "Epoch 17/30\n",
      "835/835 [==============================] - 103s 123ms/step - loss: 1.2319 - accuracy: 0.4539 - val_loss: 1.5435 - val_accuracy: 0.2812\n",
      "Epoch 18/30\n",
      "835/835 [==============================] - 103s 123ms/step - loss: 1.2300 - accuracy: 0.4530 - val_loss: 1.5459 - val_accuracy: 0.2812\n",
      "Epoch 19/30\n",
      "835/835 [==============================] - 103s 123ms/step - loss: 1.2276 - accuracy: 0.4578 - val_loss: 1.5336 - val_accuracy: 0.2812\n",
      "Epoch 20/30\n",
      "835/835 [==============================] - 103s 123ms/step - loss: 1.2261 - accuracy: 0.4590 - val_loss: 1.5262 - val_accuracy: 0.3125\n",
      "Epoch 21/30\n",
      "835/835 [==============================] - 103s 123ms/step - loss: 1.2205 - accuracy: 0.4710 - val_loss: 1.4910 - val_accuracy: 0.3438\n",
      "Epoch 22/30\n",
      "835/835 [==============================] - 103s 123ms/step - loss: 1.2010 - accuracy: 0.5071 - val_loss: 1.4215 - val_accuracy: 0.4688\n",
      "Epoch 23/30\n",
      "835/835 [==============================] - 103s 123ms/step - loss: 1.1930 - accuracy: 0.5224 - val_loss: 1.3965 - val_accuracy: 0.5000\n",
      "Epoch 24/30\n",
      "835/835 [==============================] - 103s 123ms/step - loss: 1.1810 - accuracy: 0.5308 - val_loss: 1.3824 - val_accuracy: 0.5000\n",
      "Epoch 25/30\n",
      "835/835 [==============================] - 103s 123ms/step - loss: 1.1713 - accuracy: 0.5454 - val_loss: 1.3775 - val_accuracy: 0.5000\n",
      "Epoch 26/30\n",
      "835/835 [==============================] - 103s 123ms/step - loss: 1.1674 - accuracy: 0.5525 - val_loss: 1.3791 - val_accuracy: 0.5000\n",
      "Epoch 27/30\n",
      "835/835 [==============================] - 103s 123ms/step - loss: 1.1574 - accuracy: 0.5633 - val_loss: 1.3591 - val_accuracy: 0.5000\n",
      "Epoch 28/30\n",
      "835/835 [==============================] - 103s 123ms/step - loss: 1.1398 - accuracy: 0.5790 - val_loss: 1.3614 - val_accuracy: 0.5000\n",
      "Epoch 29/30\n",
      "835/835 [==============================] - 103s 123ms/step - loss: 1.1356 - accuracy: 0.5847 - val_loss: 1.3397 - val_accuracy: 0.5000\n",
      "Epoch 30/30\n",
      "835/835 [==============================] - 103s 123ms/step - loss: 1.1126 - accuracy: 0.6030 - val_loss: 1.3339 - val_accuracy: 0.5000\n",
      "INFO:tensorflow:Assets written to: ../xception/xception_30epochs_41742.0_images_False_newWeights_False_lastLayerOnly_rescale-symmetric_normalization/assets\n",
      "Test acc for xception: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training resnet for 0.5% of train size (aka 41742 images) with pretrained: True and onlyLastLayersTrained: False...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/835 [..............................] - ETA: 6:54 - loss: 1.3530 - accuracy: 0.6388WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0603s vs `on_train_batch_begin` time: 0.1880s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0603s vs `on_train_batch_end` time: 0.1787s). Check your callbacks.\n",
      "835/835 [==============================] - 55s 61ms/step - loss: 1.1691 - accuracy: 0.7226 - val_loss: 1.2204 - val_accuracy: 0.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "835/835 [==============================] - 48s 57ms/step - loss: 0.8150 - accuracy: 0.7506 - val_loss: 1.1596 - val_accuracy: 0.5000\n",
      "Epoch 3/30\n",
      "835/835 [==============================] - 48s 57ms/step - loss: 0.7296 - accuracy: 0.7491 - val_loss: 1.0917 - val_accuracy: 0.5000\n",
      "Epoch 4/30\n",
      "835/835 [==============================] - 48s 57ms/step - loss: 0.6943 - accuracy: 0.7444 - val_loss: 1.1276 - val_accuracy: 0.5000\n",
      "Epoch 5/30\n",
      "835/835 [==============================] - 48s 57ms/step - loss: 0.6713 - accuracy: 0.7506 - val_loss: 1.1114 - val_accuracy: 0.5000\n",
      "Epoch 6/30\n",
      "835/835 [==============================] - 48s 57ms/step - loss: 0.6481 - accuracy: 0.7535 - val_loss: 1.0624 - val_accuracy: 0.5000\n",
      "Epoch 7/30\n",
      "835/835 [==============================] - 48s 57ms/step - loss: 0.6478 - accuracy: 0.7486 - val_loss: 1.0983 - val_accuracy: 0.5000\n",
      "Epoch 8/30\n",
      "835/835 [==============================] - 48s 57ms/step - loss: 0.6370 - accuracy: 0.7516 - val_loss: 1.0924 - val_accuracy: 0.5000\n",
      "Epoch 9/30\n",
      "835/835 [==============================] - 48s 57ms/step - loss: 0.6278 - accuracy: 0.7531 - val_loss: 1.0529 - val_accuracy: 0.5000\n",
      "Epoch 10/30\n",
      "835/835 [==============================] - 48s 57ms/step - loss: 0.6268 - accuracy: 0.7504 - val_loss: 1.0706 - val_accuracy: 0.5312\n",
      "Epoch 11/30\n",
      "835/835 [==============================] - 48s 57ms/step - loss: 0.6192 - accuracy: 0.7556 - val_loss: 1.0486 - val_accuracy: 0.5000\n",
      "Epoch 12/30\n",
      "835/835 [==============================] - 48s 57ms/step - loss: 0.6205 - accuracy: 0.7563 - val_loss: 1.0638 - val_accuracy: 0.5312\n",
      "Epoch 13/30\n",
      "835/835 [==============================] - 48s 57ms/step - loss: 0.6189 - accuracy: 0.7587 - val_loss: 1.0432 - val_accuracy: 0.5000\n",
      "Epoch 14/30\n",
      "835/835 [==============================] - 48s 58ms/step - loss: 0.6170 - accuracy: 0.7556 - val_loss: 1.0576 - val_accuracy: 0.5312\n",
      "Epoch 15/30\n",
      "835/835 [==============================] - 48s 57ms/step - loss: 0.6141 - accuracy: 0.7551 - val_loss: 1.0688 - val_accuracy: 0.5000\n",
      "Epoch 16/30\n",
      "835/835 [==============================] - 48s 57ms/step - loss: 0.6134 - accuracy: 0.7572 - val_loss: 1.0514 - val_accuracy: 0.5000\n",
      "Epoch 17/30\n",
      "835/835 [==============================] - 48s 57ms/step - loss: 0.6060 - accuracy: 0.7601 - val_loss: 1.0462 - val_accuracy: 0.5000\n",
      "Epoch 18/30\n",
      "835/835 [==============================] - 48s 57ms/step - loss: 0.6048 - accuracy: 0.7609 - val_loss: 1.0432 - val_accuracy: 0.5312\n",
      "Epoch 19/30\n",
      "835/835 [==============================] - 48s 57ms/step - loss: 0.5987 - accuracy: 0.7646 - val_loss: 1.0425 - val_accuracy: 0.5000\n",
      "Epoch 20/30\n",
      "835/835 [==============================] - 48s 57ms/step - loss: 0.5979 - accuracy: 0.7634 - val_loss: 1.0362 - val_accuracy: 0.5000\n",
      "Epoch 21/30\n",
      "835/835 [==============================] - 48s 57ms/step - loss: 0.5966 - accuracy: 0.7652 - val_loss: 1.0366 - val_accuracy: 0.5000\n",
      "Epoch 22/30\n",
      "835/835 [==============================] - 48s 57ms/step - loss: 0.6068 - accuracy: 0.7608 - val_loss: 1.0476 - val_accuracy: 0.5312\n",
      "Epoch 23/30\n",
      "835/835 [==============================] - 48s 57ms/step - loss: 0.6053 - accuracy: 0.7624 - val_loss: 1.0502 - val_accuracy: 0.5312\n",
      "Epoch 24/30\n",
      "835/835 [==============================] - 48s 57ms/step - loss: 0.5994 - accuracy: 0.7648 - val_loss: 1.0366 - val_accuracy: 0.5000\n",
      "Epoch 25/30\n",
      "835/835 [==============================] - 48s 57ms/step - loss: 0.5997 - accuracy: 0.7666 - val_loss: 1.0321 - val_accuracy: 0.5000\n",
      "Epoch 26/30\n",
      "835/835 [==============================] - 48s 58ms/step - loss: 0.6051 - accuracy: 0.7605 - val_loss: 1.0398 - val_accuracy: 0.5000\n",
      "Epoch 27/30\n",
      "835/835 [==============================] - 48s 57ms/step - loss: 0.5984 - accuracy: 0.7636 - val_loss: 1.0422 - val_accuracy: 0.5312\n",
      "Epoch 28/30\n",
      "835/835 [==============================] - 48s 57ms/step - loss: 0.6048 - accuracy: 0.7603 - val_loss: 1.0390 - val_accuracy: 0.5000\n",
      "Epoch 29/30\n",
      "835/835 [==============================] - 48s 57ms/step - loss: 0.5978 - accuracy: 0.7669 - val_loss: 1.0384 - val_accuracy: 0.5312\n",
      "Epoch 30/30\n",
      "835/835 [==============================] - 48s 57ms/step - loss: 0.5998 - accuracy: 0.7660 - val_loss: 1.0389 - val_accuracy: 0.5312\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_41742.0_images_False_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training opticnet for 0.5% of train size (aka 41742 images) with pretrained: True and onlyLastLayersTrained: False...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/835 [..............................] - ETA: 25:16 - loss: 5.2728 - accuracy: 0.1605  WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.4661s vs `on_train_batch_end` time: 1.0429s). Check your callbacks.\n",
      "835/835 [==============================] - 1001s 1s/step - loss: 0.3890 - accuracy: 0.8906 - val_loss: 0.0638 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "835/835 [==============================] - 980s 1s/step - loss: 0.1251 - accuracy: 0.9591 - val_loss: 0.0237 - val_accuracy: 1.0000\n",
      "Epoch 3/30\n",
      "835/835 [==============================] - 975s 1s/step - loss: 0.1093 - accuracy: 0.9643 - val_loss: 0.0236 - val_accuracy: 1.0000\n",
      "Epoch 4/30\n",
      "835/835 [==============================] - 979s 1s/step - loss: 0.0869 - accuracy: 0.9704 - val_loss: 0.0148 - val_accuracy: 1.0000\n",
      "Epoch 5/30\n",
      "835/835 [==============================] - 980s 1s/step - loss: 0.0669 - accuracy: 0.9766 - val_loss: 0.0057 - val_accuracy: 1.0000\n",
      "Epoch 6/30\n",
      "835/835 [==============================] - 980s 1s/step - loss: 0.0580 - accuracy: 0.9796 - val_loss: 0.0417 - val_accuracy: 1.0000\n",
      "Epoch 7/30\n",
      "835/835 [==============================] - 1051s 1s/step - loss: 0.0407 - accuracy: 0.9864 - val_loss: 0.1188 - val_accuracy: 0.9688\n",
      "Epoch 8/30\n",
      "835/835 [==============================] - 1053s 1s/step - loss: 0.0307 - accuracy: 0.9901 - val_loss: 0.0244 - val_accuracy: 1.0000\n",
      "Epoch 9/30\n",
      "835/835 [==============================] - 981s 1s/step - loss: 0.0262 - accuracy: 0.9918 - val_loss: 0.0777 - val_accuracy: 0.9688\n",
      "Epoch 10/30\n",
      "835/835 [==============================] - 982s 1s/step - loss: 0.0197 - accuracy: 0.9944 - val_loss: 0.1222 - val_accuracy: 0.9688\n",
      "Epoch 11/30\n",
      "835/835 [==============================] - 980s 1s/step - loss: 0.0176 - accuracy: 0.9943 - val_loss: 0.0506 - val_accuracy: 0.9688\n",
      "Epoch 12/30\n",
      "835/835 [==============================] - 982s 1s/step - loss: 0.0137 - accuracy: 0.9960 - val_loss: 0.0082 - val_accuracy: 1.0000\n",
      "Epoch 13/30\n",
      "835/835 [==============================] - 1106s 1s/step - loss: 0.0118 - accuracy: 0.9963 - val_loss: 0.0372 - val_accuracy: 0.9688\n",
      "Epoch 14/30\n",
      "835/835 [==============================] - 1070s 1s/step - loss: 0.0105 - accuracy: 0.9967 - val_loss: 0.3653 - val_accuracy: 0.9688\n",
      "Epoch 15/30\n",
      "835/835 [==============================] - 1107s 1s/step - loss: 0.0074 - accuracy: 0.9979 - val_loss: 0.2856 - val_accuracy: 0.9688\n",
      "Epoch 16/30\n",
      "835/835 [==============================] - 1075s 1s/step - loss: 0.0071 - accuracy: 0.9977 - val_loss: 0.1751 - val_accuracy: 0.9688\n",
      "Epoch 17/30\n",
      "835/835 [==============================] - 1101s 1s/step - loss: 0.0067 - accuracy: 0.9978 - val_loss: 0.2172 - val_accuracy: 0.9688\n",
      "Epoch 18/30\n",
      "835/835 [==============================] - 1079s 1s/step - loss: 0.0056 - accuracy: 0.9979 - val_loss: 0.1965 - val_accuracy: 0.9688\n",
      "Epoch 19/30\n",
      "835/835 [==============================] - 1094s 1s/step - loss: 0.0043 - accuracy: 0.9981 - val_loss: 0.1712 - val_accuracy: 0.9688\n",
      "Epoch 20/30\n",
      "835/835 [==============================] - 1086s 1s/step - loss: 0.0055 - accuracy: 0.9975 - val_loss: 0.2282 - val_accuracy: 0.9688\n",
      "Epoch 21/30\n",
      "835/835 [==============================] - 1093s 1s/step - loss: 0.0036 - accuracy: 0.9985 - val_loss: 0.2417 - val_accuracy: 0.9688\n",
      "Epoch 22/30\n",
      "835/835 [==============================] - 1091s 1s/step - loss: 0.0035 - accuracy: 0.9985 - val_loss: 0.1937 - val_accuracy: 0.9688\n",
      "Epoch 23/30\n",
      "835/835 [==============================] - 1089s 1s/step - loss: 0.0040 - accuracy: 0.9981 - val_loss: 0.2270 - val_accuracy: 0.9688\n",
      "Epoch 24/30\n",
      "835/835 [==============================] - 1095s 1s/step - loss: 0.0044 - accuracy: 0.9977 - val_loss: 0.1862 - val_accuracy: 0.9688\n",
      "Epoch 25/30\n",
      "835/835 [==============================] - 1084s 1s/step - loss: 0.0034 - accuracy: 0.9981 - val_loss: 0.2605 - val_accuracy: 0.9688\n",
      "Epoch 26/30\n",
      "835/835 [==============================] - 1100s 1s/step - loss: 0.0028 - accuracy: 0.9982 - val_loss: 0.2113 - val_accuracy: 0.9688\n",
      "Epoch 27/30\n",
      "835/835 [==============================] - 1074s 1s/step - loss: 0.0026 - accuracy: 0.9983 - val_loss: 0.2124 - val_accuracy: 0.9688\n",
      "Epoch 28/30\n",
      "835/835 [==============================] - 1105s 1s/step - loss: 0.0029 - accuracy: 0.9982 - val_loss: 0.1970 - val_accuracy: 0.9688\n",
      "Epoch 29/30\n",
      "835/835 [==============================] - 1074s 1s/step - loss: 0.0026 - accuracy: 0.9982 - val_loss: 0.1959 - val_accuracy: 0.9688\n",
      "Epoch 30/30\n",
      "835/835 [==============================] - 1107s 1s/step - loss: 0.0022 - accuracy: 0.9985 - val_loss: 0.2142 - val_accuracy: 0.9688\n",
      "INFO:tensorflow:Assets written to: ../opticnet/opticnet_30epochs_41742.0_images_False_newWeights_False_lastLayerOnly_rescale-symmetric_normalization/assets\n",
      "Test acc for opticnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels fraction: [0.59832795 0.59790351 0.60750793 0.6042247 ]\n",
      "Training xception for 0.6% of train size (aka 50090 images) with pretrained: True and onlyLastLayersTrained: False...\n",
      "Epoch 1/30\n",
      "   6/1002 [..............................] - ETA: 10:04 - loss: 1.3666 - accuracy: 0.5476WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1264s vs `on_train_batch_begin` time: 0.1962s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1264s vs `on_train_batch_end` time: 0.2046s). Check your callbacks.\n",
      "1002/1002 [==============================] - 144s 141ms/step - loss: 1.2184 - accuracy: 0.6206 - val_loss: 1.2798 - val_accuracy: 0.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "1002/1002 [==============================] - 146s 146ms/step - loss: 1.0264 - accuracy: 0.6435 - val_loss: 1.2653 - val_accuracy: 0.5000\n",
      "Epoch 3/30\n",
      "1002/1002 [==============================] - 162s 162ms/step - loss: 1.0129 - accuracy: 0.6442 - val_loss: 1.2221 - val_accuracy: 0.5000\n",
      "Epoch 4/30\n",
      "1002/1002 [==============================] - 140s 139ms/step - loss: 0.9839 - accuracy: 0.6566 - val_loss: 1.2565 - val_accuracy: 0.5000\n",
      "Epoch 5/30\n",
      "1002/1002 [==============================] - 150s 150ms/step - loss: 0.9688 - accuracy: 0.6644 - val_loss: 1.2217 - val_accuracy: 0.5000\n",
      "Epoch 6/30\n",
      "1002/1002 [==============================] - 159s 158ms/step - loss: 0.9655 - accuracy: 0.6648 - val_loss: 1.2821 - val_accuracy: 0.4688\n",
      "Epoch 7/30\n",
      "1002/1002 [==============================] - 139s 139ms/step - loss: 0.9632 - accuracy: 0.6647 - val_loss: 1.2463 - val_accuracy: 0.5000\n",
      "Epoch 8/30\n",
      "1002/1002 [==============================] - 152s 152ms/step - loss: 0.9414 - accuracy: 0.6761 - val_loss: 1.2226 - val_accuracy: 0.5000\n",
      "Epoch 9/30\n",
      "1002/1002 [==============================] - 158s 157ms/step - loss: 0.9437 - accuracy: 0.6739 - val_loss: 1.2223 - val_accuracy: 0.5000\n",
      "Epoch 10/30\n",
      "1002/1002 [==============================] - 138s 138ms/step - loss: 0.9388 - accuracy: 0.6766 - val_loss: 1.2421 - val_accuracy: 0.5000\n",
      "Epoch 11/30\n",
      "1002/1002 [==============================] - 150s 150ms/step - loss: 0.9326 - accuracy: 0.6762 - val_loss: 1.2396 - val_accuracy: 0.5000\n",
      "Epoch 12/30\n",
      "1002/1002 [==============================] - 159s 158ms/step - loss: 0.9384 - accuracy: 0.6752 - val_loss: 1.2517 - val_accuracy: 0.5000\n",
      "Epoch 13/30\n",
      "1002/1002 [==============================] - 138s 138ms/step - loss: 0.9269 - accuracy: 0.6796 - val_loss: 1.2389 - val_accuracy: 0.5000\n",
      "Epoch 14/30\n",
      "1002/1002 [==============================] - 149s 148ms/step - loss: 0.9180 - accuracy: 0.6844 - val_loss: 1.2541 - val_accuracy: 0.5000\n",
      "Epoch 15/30\n",
      "1002/1002 [==============================] - 159s 159ms/step - loss: 0.9227 - accuracy: 0.6793 - val_loss: 1.2413 - val_accuracy: 0.5000\n",
      "Epoch 16/30\n",
      "1002/1002 [==============================] - 139s 138ms/step - loss: 0.9177 - accuracy: 0.6810 - val_loss: 1.2608 - val_accuracy: 0.5000\n",
      "Epoch 17/30\n",
      "1002/1002 [==============================] - 145s 145ms/step - loss: 0.9085 - accuracy: 0.6856 - val_loss: 1.2495 - val_accuracy: 0.5000\n",
      "Epoch 18/30\n",
      "1002/1002 [==============================] - 163s 162ms/step - loss: 0.9084 - accuracy: 0.6856 - val_loss: 1.2554 - val_accuracy: 0.5000\n",
      "Epoch 19/30\n",
      "1002/1002 [==============================] - 139s 139ms/step - loss: 0.9095 - accuracy: 0.6843 - val_loss: 1.2554 - val_accuracy: 0.5000\n",
      "Epoch 20/30\n",
      "1002/1002 [==============================] - 145s 145ms/step - loss: 0.9028 - accuracy: 0.6870 - val_loss: 1.2512 - val_accuracy: 0.5000\n",
      "Epoch 21/30\n",
      "1002/1002 [==============================] - 164s 163ms/step - loss: 0.9049 - accuracy: 0.6855 - val_loss: 1.2558 - val_accuracy: 0.5000\n",
      "Epoch 22/30\n",
      "1002/1002 [==============================] - 139s 139ms/step - loss: 0.9070 - accuracy: 0.6845 - val_loss: 1.2769 - val_accuracy: 0.5000\n",
      "Epoch 23/30\n",
      "1002/1002 [==============================] - 143s 143ms/step - loss: 0.9020 - accuracy: 0.6864 - val_loss: 1.2646 - val_accuracy: 0.5000\n",
      "Epoch 24/30\n",
      "1002/1002 [==============================] - 160s 160ms/step - loss: 0.8981 - accuracy: 0.6887 - val_loss: 1.2837 - val_accuracy: 0.5000\n",
      "Epoch 25/30\n",
      "1002/1002 [==============================] - 142s 141ms/step - loss: 0.9020 - accuracy: 0.6862 - val_loss: 1.2639 - val_accuracy: 0.5000\n",
      "Epoch 26/30\n",
      "1002/1002 [==============================] - 139s 139ms/step - loss: 0.8983 - accuracy: 0.6878 - val_loss: 1.2681 - val_accuracy: 0.5000\n",
      "Epoch 27/30\n",
      "1002/1002 [==============================] - 159s 159ms/step - loss: 0.8985 - accuracy: 0.6890 - val_loss: 1.2831 - val_accuracy: 0.4688\n",
      "Epoch 28/30\n",
      "1002/1002 [==============================] - 147s 146ms/step - loss: 0.8968 - accuracy: 0.6888 - val_loss: 1.2832 - val_accuracy: 0.5000\n",
      "Epoch 29/30\n",
      "1002/1002 [==============================] - 138s 137ms/step - loss: 0.8861 - accuracy: 0.6953 - val_loss: 1.2741 - val_accuracy: 0.5000\n",
      "Epoch 30/30\n",
      "1002/1002 [==============================] - 152s 151ms/step - loss: 0.8932 - accuracy: 0.6914 - val_loss: 1.2919 - val_accuracy: 0.4688\n",
      "INFO:tensorflow:Assets written to: ../xception/xception_30epochs_50090.4_images_False_newWeights_False_lastLayerOnly_rescale-symmetric_normalization/assets\n",
      "Test acc for xception: 0.259298\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training resnet for 0.6% of train size (aka 50090 images) with pretrained: True and onlyLastLayersTrained: False...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "   6/1002 [..............................] - ETA: 8:38 - loss: 1.3956 - accuracy: 0.2536 WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0891s vs `on_train_batch_begin` time: 0.1957s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0891s vs `on_train_batch_end` time: 0.1653s). Check your callbacks.\n",
      "1002/1002 [==============================] - 88s 84ms/step - loss: 1.1743 - accuracy: 0.6589 - val_loss: 1.1992 - val_accuracy: 0.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "1002/1002 [==============================] - 77s 77ms/step - loss: 0.7928 - accuracy: 0.7490 - val_loss: 1.1368 - val_accuracy: 0.5000\n",
      "Epoch 3/30\n",
      "1002/1002 [==============================] - 75s 74ms/step - loss: 0.6975 - accuracy: 0.7541 - val_loss: 1.0616 - val_accuracy: 0.5000\n",
      "Epoch 4/30\n",
      "1002/1002 [==============================] - 74s 74ms/step - loss: 0.6755 - accuracy: 0.7475 - val_loss: 1.0500 - val_accuracy: 0.5000\n",
      "Epoch 5/30\n",
      "1002/1002 [==============================] - 75s 75ms/step - loss: 0.6568 - accuracy: 0.7493 - val_loss: 1.0464 - val_accuracy: 0.5000\n",
      "Epoch 6/30\n",
      "1002/1002 [==============================] - 75s 75ms/step - loss: 0.6355 - accuracy: 0.7540 - val_loss: 1.0998 - val_accuracy: 0.5000\n",
      "Epoch 7/30\n",
      "1002/1002 [==============================] - 74s 74ms/step - loss: 0.6306 - accuracy: 0.7508 - val_loss: 1.0387 - val_accuracy: 0.5000\n",
      "Epoch 8/30\n",
      "1002/1002 [==============================] - 75s 75ms/step - loss: 0.6286 - accuracy: 0.7497 - val_loss: 1.0316 - val_accuracy: 0.5000\n",
      "Epoch 9/30\n",
      "1002/1002 [==============================] - 75s 74ms/step - loss: 0.6239 - accuracy: 0.7533 - val_loss: 0.9830 - val_accuracy: 0.5000\n",
      "Epoch 10/30\n",
      "1002/1002 [==============================] - 75s 74ms/step - loss: 0.6208 - accuracy: 0.7531 - val_loss: 1.0327 - val_accuracy: 0.5312\n",
      "Epoch 11/30\n",
      "1002/1002 [==============================] - 74s 74ms/step - loss: 0.6089 - accuracy: 0.7595 - val_loss: 1.0203 - val_accuracy: 0.5000\n",
      "Epoch 12/30\n",
      "1002/1002 [==============================] - 75s 75ms/step - loss: 0.6112 - accuracy: 0.7565 - val_loss: 1.0300 - val_accuracy: 0.5000\n",
      "Epoch 13/30\n",
      "1002/1002 [==============================] - 76s 75ms/step - loss: 0.6149 - accuracy: 0.7577 - val_loss: 1.0169 - val_accuracy: 0.5000\n",
      "Epoch 14/30\n",
      "1002/1002 [==============================] - 76s 75ms/step - loss: 0.6009 - accuracy: 0.7642 - val_loss: 1.0230 - val_accuracy: 0.5000\n",
      "Epoch 15/30\n",
      "1002/1002 [==============================] - 75s 75ms/step - loss: 0.6035 - accuracy: 0.7605 - val_loss: 1.0128 - val_accuracy: 0.5312\n",
      "Epoch 16/30\n",
      "1002/1002 [==============================] - 75s 75ms/step - loss: 0.5952 - accuracy: 0.7652 - val_loss: 1.0046 - val_accuracy: 0.5000\n",
      "Epoch 17/30\n",
      "1002/1002 [==============================] - 76s 76ms/step - loss: 0.5921 - accuracy: 0.7677 - val_loss: 0.9939 - val_accuracy: 0.5000\n",
      "Epoch 18/30\n",
      "1002/1002 [==============================] - 77s 77ms/step - loss: 0.6021 - accuracy: 0.7627 - val_loss: 1.0112 - val_accuracy: 0.5000\n",
      "Epoch 19/30\n",
      "1002/1002 [==============================] - 78s 78ms/step - loss: 0.5995 - accuracy: 0.7653 - val_loss: 1.0032 - val_accuracy: 0.5000\n",
      "Epoch 20/30\n",
      "1002/1002 [==============================] - 80s 79ms/step - loss: 0.5947 - accuracy: 0.7642 - val_loss: 1.0100 - val_accuracy: 0.5000\n",
      "Epoch 21/30\n",
      "1002/1002 [==============================] - 79s 79ms/step - loss: 0.5968 - accuracy: 0.7638 - val_loss: 0.9928 - val_accuracy: 0.5000\n",
      "Epoch 22/30\n",
      "1002/1002 [==============================] - 79s 79ms/step - loss: 0.5985 - accuracy: 0.7641 - val_loss: 1.0326 - val_accuracy: 0.5312\n",
      "Epoch 23/30\n",
      "1002/1002 [==============================] - 80s 80ms/step - loss: 0.5986 - accuracy: 0.7644 - val_loss: 0.9784 - val_accuracy: 0.5000\n",
      "Epoch 24/30\n",
      "1002/1002 [==============================] - 78s 78ms/step - loss: 0.5995 - accuracy: 0.7625 - val_loss: 0.9911 - val_accuracy: 0.5000\n",
      "Epoch 25/30\n",
      "1002/1002 [==============================] - 79s 78ms/step - loss: 0.5994 - accuracy: 0.7631 - val_loss: 0.9964 - val_accuracy: 0.5312\n",
      "Epoch 26/30\n",
      "1002/1002 [==============================] - 78s 77ms/step - loss: 0.5895 - accuracy: 0.7682 - val_loss: 1.0048 - val_accuracy: 0.5625\n",
      "Epoch 27/30\n",
      "1002/1002 [==============================] - 76s 76ms/step - loss: 0.6000 - accuracy: 0.7634 - val_loss: 0.9996 - val_accuracy: 0.5312\n",
      "Epoch 28/30\n",
      "1002/1002 [==============================] - 74s 74ms/step - loss: 0.5943 - accuracy: 0.7662 - val_loss: 0.9930 - val_accuracy: 0.5000\n",
      "Epoch 29/30\n",
      "1002/1002 [==============================] - 75s 75ms/step - loss: 0.5928 - accuracy: 0.7685 - val_loss: 0.9791 - val_accuracy: 0.5000\n",
      "Epoch 30/30\n",
      "1002/1002 [==============================] - 76s 75ms/step - loss: 0.5892 - accuracy: 0.7679 - val_loss: 0.9984 - val_accuracy: 0.5625\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_50090.4_images_False_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training opticnet for 0.6% of train size (aka 50090 images) with pretrained: True and onlyLastLayersTrained: False...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "   6/1002 [..............................] - ETA: 31:30 - loss: 5.5590 - accuracy: 0.1323  WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.5112s vs `on_train_batch_end` time: 1.0623s). Check your callbacks.\n",
      "1002/1002 [==============================] - 1237s 1s/step - loss: 0.3706 - accuracy: 0.8940 - val_loss: 0.1147 - val_accuracy: 0.9375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "1002/1002 [==============================] - 1172s 1s/step - loss: 0.1262 - accuracy: 0.9582 - val_loss: 0.0252 - val_accuracy: 1.0000\n",
      "Epoch 3/30\n",
      "1002/1002 [==============================] - 1171s 1s/step - loss: 0.1038 - accuracy: 0.9656 - val_loss: 0.0413 - val_accuracy: 1.0000\n",
      "Epoch 4/30\n",
      "1002/1002 [==============================] - 1174s 1s/step - loss: 0.0919 - accuracy: 0.9698 - val_loss: 0.0087 - val_accuracy: 1.0000\n",
      "Epoch 5/30\n",
      "1002/1002 [==============================] - 1172s 1s/step - loss: 0.0742 - accuracy: 0.9741 - val_loss: 0.0035 - val_accuracy: 1.0000\n",
      "Epoch 6/30\n",
      "1002/1002 [==============================] - 1176s 1s/step - loss: 0.0563 - accuracy: 0.9803 - val_loss: 0.0220 - val_accuracy: 1.0000\n",
      "Epoch 7/30\n",
      "1002/1002 [==============================] - 1167s 1s/step - loss: 0.0467 - accuracy: 0.9848 - val_loss: 0.0104 - val_accuracy: 1.0000\n",
      "Epoch 8/30\n",
      "1002/1002 [==============================] - 1166s 1s/step - loss: 0.0335 - accuracy: 0.9888 - val_loss: 0.0834 - val_accuracy: 0.9688\n",
      "Epoch 9/30\n",
      "1002/1002 [==============================] - 1172s 1s/step - loss: 0.0269 - accuracy: 0.9912 - val_loss: 0.0289 - val_accuracy: 0.9688\n",
      "Epoch 10/30\n",
      "1002/1002 [==============================] - 1179s 1s/step - loss: 0.0209 - accuracy: 0.9936 - val_loss: 0.0603 - val_accuracy: 0.9688\n",
      "Epoch 11/30\n",
      "1002/1002 [==============================] - 1177s 1s/step - loss: 0.0175 - accuracy: 0.9948 - val_loss: 0.0266 - val_accuracy: 0.9688\n",
      "Epoch 12/30\n",
      "1002/1002 [==============================] - 1175s 1s/step - loss: 0.0151 - accuracy: 0.9952 - val_loss: 0.1606 - val_accuracy: 0.9688\n",
      "Epoch 13/30\n",
      "1002/1002 [==============================] - 1167s 1s/step - loss: 0.0129 - accuracy: 0.9959 - val_loss: 0.1143 - val_accuracy: 0.9688\n",
      "Epoch 14/30\n",
      "1002/1002 [==============================] - 1170s 1s/step - loss: 0.0096 - accuracy: 0.9972 - val_loss: 0.1426 - val_accuracy: 0.9688\n",
      "Epoch 15/30\n",
      "1002/1002 [==============================] - 1177s 1s/step - loss: 0.0078 - accuracy: 0.9972 - val_loss: 0.1754 - val_accuracy: 0.9688\n",
      "Epoch 16/30\n",
      "1002/1002 [==============================] - 1176s 1s/step - loss: 0.0083 - accuracy: 0.9971 - val_loss: 0.1586 - val_accuracy: 0.9688\n",
      "Epoch 17/30\n",
      "1002/1002 [==============================] - 1174s 1s/step - loss: 0.0074 - accuracy: 0.9975 - val_loss: 0.1079 - val_accuracy: 0.9688\n",
      "Epoch 18/30\n",
      "1002/1002 [==============================] - 1176s 1s/step - loss: 0.0061 - accuracy: 0.9977 - val_loss: 0.1395 - val_accuracy: 0.9688\n",
      "Epoch 19/30\n",
      "1002/1002 [==============================] - 1174s 1s/step - loss: 0.0060 - accuracy: 0.9976 - val_loss: 0.1962 - val_accuracy: 0.9688\n",
      "Epoch 20/30\n",
      "1002/1002 [==============================] - 1175s 1s/step - loss: 0.0057 - accuracy: 0.9974 - val_loss: 0.1234 - val_accuracy: 0.9688\n",
      "Epoch 21/30\n",
      "1002/1002 [==============================] - 1174s 1s/step - loss: 0.0047 - accuracy: 0.9980 - val_loss: 0.1677 - val_accuracy: 0.9688\n",
      "Epoch 22/30\n",
      "1002/1002 [==============================] - 1174s 1s/step - loss: 0.0050 - accuracy: 0.9975 - val_loss: 0.2035 - val_accuracy: 0.9688\n",
      "Epoch 23/30\n",
      "1002/1002 [==============================] - 1178s 1s/step - loss: 0.0042 - accuracy: 0.9979 - val_loss: 0.1434 - val_accuracy: 0.9688\n",
      "Epoch 24/30\n",
      "1002/1002 [==============================] - 1174s 1s/step - loss: 0.0044 - accuracy: 0.9977 - val_loss: 0.1969 - val_accuracy: 0.9688\n",
      "Epoch 25/30\n",
      "1002/1002 [==============================] - 1178s 1s/step - loss: 0.0036 - accuracy: 0.9978 - val_loss: 0.1779 - val_accuracy: 0.9688\n",
      "Epoch 26/30\n",
      "1002/1002 [==============================] - 1174s 1s/step - loss: 0.0038 - accuracy: 0.9976 - val_loss: 0.1885 - val_accuracy: 0.9688\n",
      "Epoch 27/30\n",
      "1002/1002 [==============================] - 1171s 1s/step - loss: 0.0032 - accuracy: 0.9981 - val_loss: 0.1921 - val_accuracy: 0.9688\n",
      "Epoch 28/30\n",
      "1002/1002 [==============================] - 1166s 1s/step - loss: 0.0030 - accuracy: 0.9982 - val_loss: 0.2332 - val_accuracy: 0.9688\n",
      "Epoch 29/30\n",
      "1002/1002 [==============================] - 1168s 1s/step - loss: 0.0030 - accuracy: 0.9982 - val_loss: 0.2140 - val_accuracy: 0.9688\n",
      "Epoch 30/30\n",
      "1002/1002 [==============================] - 1173s 1s/step - loss: 0.0030 - accuracy: 0.9980 - val_loss: 0.2224 - val_accuracy: 0.9688\n",
      "INFO:tensorflow:Assets written to: ../opticnet/opticnet_30epochs_50090.4_images_False_newWeights_False_lastLayerOnly_rescale-symmetric_normalization/assets\n",
      "Test acc for opticnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.7466084  0.75032926 0.75625661 0.75069638]\n",
      "Training xception for 0.75% of train size (aka 62613 images) with pretrained: True and onlyLastLayersTrained: False...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "   6/1253 [..............................] - ETA: 12:10 - loss: 1.3835 - accuracy: 0.3334WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1198s vs `on_train_batch_begin` time: 0.1971s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1198s vs `on_train_batch_end` time: 0.1915s). Check your callbacks.\n",
      "1253/1253 [==============================] - 158s 124ms/step - loss: 1.2795 - accuracy: 0.4439 - val_loss: 1.4696 - val_accuracy: 0.4062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "1253/1253 [==============================] - 154s 123ms/step - loss: 1.1906 - accuracy: 0.5116 - val_loss: 1.3971 - val_accuracy: 0.4375\n",
      "Epoch 3/30\n",
      "1253/1253 [==============================] - 154s 123ms/step - loss: 1.1224 - accuracy: 0.5724 - val_loss: 1.2974 - val_accuracy: 0.5000\n",
      "Epoch 4/30\n",
      "1253/1253 [==============================] - 154s 123ms/step - loss: 1.0686 - accuracy: 0.6098 - val_loss: 1.2670 - val_accuracy: 0.5000\n",
      "Epoch 5/30\n",
      "1253/1253 [==============================] - 154s 123ms/step - loss: 1.0293 - accuracy: 0.6329 - val_loss: 1.2429 - val_accuracy: 0.5000\n",
      "Epoch 6/30\n",
      "1253/1253 [==============================] - 154s 123ms/step - loss: 1.0007 - accuracy: 0.6474 - val_loss: 1.2208 - val_accuracy: 0.5000\n",
      "Epoch 7/30\n",
      "1253/1253 [==============================] - 154s 123ms/step - loss: 0.9832 - accuracy: 0.6556 - val_loss: 1.2021 - val_accuracy: 0.5000\n",
      "Epoch 8/30\n",
      "1253/1253 [==============================] - 154s 123ms/step - loss: 0.9740 - accuracy: 0.6574 - val_loss: 1.1989 - val_accuracy: 0.5000\n",
      "Epoch 9/30\n",
      "1253/1253 [==============================] - 154s 123ms/step - loss: 0.9623 - accuracy: 0.6623 - val_loss: 1.1699 - val_accuracy: 0.5000\n",
      "Epoch 10/30\n",
      "1253/1253 [==============================] - 154s 123ms/step - loss: 0.9555 - accuracy: 0.6639 - val_loss: 1.1952 - val_accuracy: 0.5000\n",
      "Epoch 11/30\n",
      "1253/1253 [==============================] - 154s 123ms/step - loss: 0.9519 - accuracy: 0.6643 - val_loss: 1.1754 - val_accuracy: 0.5000\n",
      "Epoch 12/30\n",
      "1253/1253 [==============================] - 154s 123ms/step - loss: 0.9402 - accuracy: 0.6684 - val_loss: 1.1732 - val_accuracy: 0.5000\n",
      "Epoch 13/30\n",
      "1253/1253 [==============================] - 154s 123ms/step - loss: 0.9365 - accuracy: 0.6698 - val_loss: 1.1653 - val_accuracy: 0.5000\n",
      "Epoch 14/30\n",
      "1253/1253 [==============================] - 154s 123ms/step - loss: 0.9284 - accuracy: 0.6734 - val_loss: 1.1570 - val_accuracy: 0.5000\n",
      "Epoch 15/30\n",
      "1253/1253 [==============================] - 154s 123ms/step - loss: 0.9286 - accuracy: 0.6724 - val_loss: 1.1545 - val_accuracy: 0.5000\n",
      "Epoch 16/30\n",
      "1253/1253 [==============================] - 154s 123ms/step - loss: 0.9248 - accuracy: 0.6750 - val_loss: 1.1754 - val_accuracy: 0.5000\n",
      "Epoch 17/30\n",
      "1253/1253 [==============================] - 154s 123ms/step - loss: 0.9179 - accuracy: 0.6773 - val_loss: 1.1824 - val_accuracy: 0.5000\n",
      "Epoch 18/30\n",
      "1253/1253 [==============================] - 154s 123ms/step - loss: 0.9172 - accuracy: 0.6766 - val_loss: 1.1748 - val_accuracy: 0.5000\n",
      "Epoch 19/30\n",
      "1253/1253 [==============================] - 154s 123ms/step - loss: 0.9110 - accuracy: 0.6794 - val_loss: 1.1872 - val_accuracy: 0.5000\n",
      "Epoch 20/30\n",
      "1253/1253 [==============================] - 154s 123ms/step - loss: 0.9092 - accuracy: 0.6783 - val_loss: 1.1801 - val_accuracy: 0.5000\n",
      "Epoch 21/30\n",
      "1253/1253 [==============================] - 154s 123ms/step - loss: 0.9107 - accuracy: 0.6787 - val_loss: 1.1776 - val_accuracy: 0.5000\n",
      "Epoch 22/30\n",
      "1253/1253 [==============================] - 154s 123ms/step - loss: 0.9104 - accuracy: 0.6777 - val_loss: 1.1989 - val_accuracy: 0.5000\n",
      "Epoch 23/30\n",
      "1253/1253 [==============================] - 154s 123ms/step - loss: 0.8999 - accuracy: 0.6840 - val_loss: 1.1852 - val_accuracy: 0.5000\n",
      "Epoch 24/30\n",
      "1253/1253 [==============================] - 154s 123ms/step - loss: 0.9051 - accuracy: 0.6797 - val_loss: 1.1973 - val_accuracy: 0.5000\n",
      "Epoch 25/30\n",
      "1253/1253 [==============================] - 154s 123ms/step - loss: 0.9079 - accuracy: 0.6796 - val_loss: 1.1963 - val_accuracy: 0.5000\n",
      "Epoch 26/30\n",
      "1253/1253 [==============================] - 154s 123ms/step - loss: 0.9006 - accuracy: 0.6820 - val_loss: 1.2056 - val_accuracy: 0.5000\n",
      "Epoch 27/30\n",
      "1253/1253 [==============================] - 154s 123ms/step - loss: 0.9021 - accuracy: 0.6800 - val_loss: 1.1868 - val_accuracy: 0.5000\n",
      "Epoch 28/30\n",
      "1253/1253 [==============================] - 154s 123ms/step - loss: 0.9020 - accuracy: 0.6810 - val_loss: 1.1938 - val_accuracy: 0.5000\n",
      "Epoch 29/30\n",
      "1253/1253 [==============================] - 154s 123ms/step - loss: 0.9073 - accuracy: 0.6778 - val_loss: 1.1929 - val_accuracy: 0.5000\n",
      "Epoch 30/30\n",
      "1253/1253 [==============================] - 154s 123ms/step - loss: 0.9043 - accuracy: 0.6787 - val_loss: 1.1955 - val_accuracy: 0.5000\n",
      "INFO:tensorflow:Assets written to: ../xception/xception_30epochs_62613.0_images_False_newWeights_False_lastLayerOnly_rescale-symmetric_normalization/assets\n",
      "Test acc for xception: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training resnet for 0.75% of train size (aka 62613 images) with pretrained: True and onlyLastLayersTrained: False...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "   6/1253 [..............................] - ETA: 10:01 - loss: 1.3948 - accuracy: 0.0638WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0597s vs `on_train_batch_begin` time: 0.1954s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0597s vs `on_train_batch_end` time: 0.1572s). Check your callbacks.\n",
      "1253/1253 [==============================] - 78s 60ms/step - loss: 1.1137 - accuracy: 0.6719 - val_loss: 0.9685 - val_accuracy: 0.6875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "1253/1253 [==============================] - 72s 57ms/step - loss: 0.6076 - accuracy: 0.8506 - val_loss: 0.7403 - val_accuracy: 0.7500\n",
      "Epoch 3/30\n",
      "1253/1253 [==============================] - 71s 57ms/step - loss: 0.4946 - accuracy: 0.8576 - val_loss: 0.7115 - val_accuracy: 0.7188\n",
      "Epoch 4/30\n",
      "1253/1253 [==============================] - 72s 57ms/step - loss: 0.4547 - accuracy: 0.8591 - val_loss: 0.7620 - val_accuracy: 0.6875\n",
      "Epoch 5/30\n",
      "1253/1253 [==============================] - 72s 57ms/step - loss: 0.4341 - accuracy: 0.8607 - val_loss: 0.6396 - val_accuracy: 0.7500\n",
      "Epoch 6/30\n",
      "1253/1253 [==============================] - 72s 58ms/step - loss: 0.4149 - accuracy: 0.8644 - val_loss: 0.6499 - val_accuracy: 0.7500\n",
      "Epoch 7/30\n",
      "1253/1253 [==============================] - 72s 57ms/step - loss: 0.4086 - accuracy: 0.8662 - val_loss: 0.6164 - val_accuracy: 0.7500\n",
      "Epoch 8/30\n",
      "1253/1253 [==============================] - 72s 58ms/step - loss: 0.3939 - accuracy: 0.8717 - val_loss: 0.5923 - val_accuracy: 0.7500\n",
      "Epoch 9/30\n",
      "1253/1253 [==============================] - 72s 58ms/step - loss: 0.3921 - accuracy: 0.8708 - val_loss: 0.6184 - val_accuracy: 0.7500\n",
      "Epoch 10/30\n",
      "1253/1253 [==============================] - 71s 57ms/step - loss: 0.3767 - accuracy: 0.8767 - val_loss: 0.6339 - val_accuracy: 0.7188\n",
      "Epoch 11/30\n",
      "1253/1253 [==============================] - 72s 57ms/step - loss: 0.3772 - accuracy: 0.8763 - val_loss: 0.6351 - val_accuracy: 0.7188\n",
      "Epoch 12/30\n",
      "1253/1253 [==============================] - 72s 57ms/step - loss: 0.3737 - accuracy: 0.8769 - val_loss: 0.5457 - val_accuracy: 0.7500\n",
      "Epoch 13/30\n",
      "1253/1253 [==============================] - 72s 57ms/step - loss: 0.3697 - accuracy: 0.8798 - val_loss: 0.4983 - val_accuracy: 0.7812\n",
      "Epoch 14/30\n",
      "1253/1253 [==============================] - 72s 57ms/step - loss: 0.3617 - accuracy: 0.8828 - val_loss: 0.4626 - val_accuracy: 0.7812\n",
      "Epoch 15/30\n",
      "1253/1253 [==============================] - 72s 58ms/step - loss: 0.3661 - accuracy: 0.8806 - val_loss: 0.4557 - val_accuracy: 0.8438\n",
      "Epoch 16/30\n",
      "1253/1253 [==============================] - 72s 58ms/step - loss: 0.3584 - accuracy: 0.8834 - val_loss: 0.4533 - val_accuracy: 0.8438\n",
      "Epoch 17/30\n",
      "1253/1253 [==============================] - 72s 57ms/step - loss: 0.3582 - accuracy: 0.8829 - val_loss: 0.4614 - val_accuracy: 0.8438\n",
      "Epoch 18/30\n",
      "1253/1253 [==============================] - 72s 57ms/step - loss: 0.3524 - accuracy: 0.8860 - val_loss: 0.4564 - val_accuracy: 0.8438\n",
      "Epoch 19/30\n",
      "1253/1253 [==============================] - 72s 57ms/step - loss: 0.3444 - accuracy: 0.8879 - val_loss: 0.4522 - val_accuracy: 0.8125\n",
      "Epoch 20/30\n",
      "1253/1253 [==============================] - 72s 58ms/step - loss: 0.3520 - accuracy: 0.8860 - val_loss: 0.4545 - val_accuracy: 0.8125\n",
      "Epoch 21/30\n",
      "1253/1253 [==============================] - 72s 57ms/step - loss: 0.3457 - accuracy: 0.8868 - val_loss: 0.4697 - val_accuracy: 0.8125\n",
      "Epoch 22/30\n",
      "1253/1253 [==============================] - 72s 57ms/step - loss: 0.3429 - accuracy: 0.8886 - val_loss: 0.4563 - val_accuracy: 0.8125\n",
      "Epoch 23/30\n",
      "1253/1253 [==============================] - 72s 58ms/step - loss: 0.3444 - accuracy: 0.8874 - val_loss: 0.4533 - val_accuracy: 0.8125\n",
      "Epoch 24/30\n",
      "1253/1253 [==============================] - 72s 58ms/step - loss: 0.3413 - accuracy: 0.8883 - val_loss: 0.4663 - val_accuracy: 0.7812\n",
      "Epoch 25/30\n",
      "1253/1253 [==============================] - 72s 57ms/step - loss: 0.3439 - accuracy: 0.8871 - val_loss: 0.4622 - val_accuracy: 0.8125\n",
      "Epoch 26/30\n",
      "1253/1253 [==============================] - 72s 57ms/step - loss: 0.3429 - accuracy: 0.8874 - val_loss: 0.4556 - val_accuracy: 0.8125\n",
      "Epoch 27/30\n",
      "1253/1253 [==============================] - 72s 58ms/step - loss: 0.3420 - accuracy: 0.8894 - val_loss: 0.4708 - val_accuracy: 0.7812\n",
      "Epoch 28/30\n",
      "1253/1253 [==============================] - 72s 57ms/step - loss: 0.3381 - accuracy: 0.8903 - val_loss: 0.4546 - val_accuracy: 0.8125\n",
      "Epoch 29/30\n",
      "1253/1253 [==============================] - 72s 57ms/step - loss: 0.3371 - accuracy: 0.8910 - val_loss: 0.4601 - val_accuracy: 0.8125\n",
      "Epoch 30/30\n",
      "1253/1253 [==============================] - 72s 57ms/step - loss: 0.3355 - accuracy: 0.8921 - val_loss: 0.4629 - val_accuracy: 0.8125\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_62613.0_images_False_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training opticnet for 0.75% of train size (aka 62613 images) with pretrained: True and onlyLastLayersTrained: False...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "   6/1253 [..............................] - ETA: 37:25 - loss: 5.3678 - accuracy: 0.1449  WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.4651s vs `on_train_batch_end` time: 1.0443s). Check your callbacks.\n",
      "1253/1253 [==============================] - 1485s 1s/step - loss: 0.3274 - accuracy: 0.9063 - val_loss: 0.8299 - val_accuracy: 0.8438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "1253/1253 [==============================] - 1468s 1s/step - loss: 0.1210 - accuracy: 0.9604 - val_loss: 0.0748 - val_accuracy: 0.9688\n",
      "Epoch 3/30\n",
      "1253/1253 [==============================] - 1470s 1s/step - loss: 0.1042 - accuracy: 0.9646 - val_loss: 0.0417 - val_accuracy: 1.0000\n",
      "Epoch 4/30\n",
      "1253/1253 [==============================] - 1467s 1s/step - loss: 0.0868 - accuracy: 0.9705 - val_loss: 0.0176 - val_accuracy: 1.0000\n",
      "Epoch 5/30\n",
      "1253/1253 [==============================] - 1469s 1s/step - loss: 0.0723 - accuracy: 0.9749 - val_loss: 0.0183 - val_accuracy: 1.0000\n",
      "Epoch 6/30\n",
      "1253/1253 [==============================] - 1470s 1s/step - loss: 0.0587 - accuracy: 0.9798 - val_loss: 0.0045 - val_accuracy: 1.0000\n",
      "Epoch 7/30\n",
      "1253/1253 [==============================] - 1469s 1s/step - loss: 0.0471 - accuracy: 0.9841 - val_loss: 0.0136 - val_accuracy: 1.0000\n",
      "Epoch 8/30\n",
      "1253/1253 [==============================] - 1465s 1s/step - loss: 0.0375 - accuracy: 0.9871 - val_loss: 0.0106 - val_accuracy: 1.0000\n",
      "Epoch 9/30\n",
      "1253/1253 [==============================] - 1471s 1s/step - loss: 0.0271 - accuracy: 0.9911 - val_loss: 0.0725 - val_accuracy: 0.9688\n",
      "Epoch 10/30\n",
      "1253/1253 [==============================] - 1468s 1s/step - loss: 0.0213 - accuracy: 0.9933 - val_loss: 0.0145 - val_accuracy: 1.0000\n",
      "Epoch 11/30\n",
      "1253/1253 [==============================] - 1465s 1s/step - loss: 0.0179 - accuracy: 0.9942 - val_loss: 0.1265 - val_accuracy: 0.9688\n",
      "Epoch 12/30\n",
      "1253/1253 [==============================] - 1472s 1s/step - loss: 0.0182 - accuracy: 0.9945 - val_loss: 0.0995 - val_accuracy: 0.9688\n",
      "Epoch 13/30\n",
      "1253/1253 [==============================] - 1470s 1s/step - loss: 0.0148 - accuracy: 0.9951 - val_loss: 0.0535 - val_accuracy: 0.9688\n",
      "Epoch 14/30\n",
      "1253/1253 [==============================] - 1469s 1s/step - loss: 0.0132 - accuracy: 0.9954 - val_loss: 0.0702 - val_accuracy: 0.9688\n",
      "Epoch 15/30\n",
      "1253/1253 [==============================] - 1473s 1s/step - loss: 0.0109 - accuracy: 0.9960 - val_loss: 0.0701 - val_accuracy: 0.9688\n",
      "Epoch 16/30\n",
      "1253/1253 [==============================] - 1471s 1s/step - loss: 0.0109 - accuracy: 0.9960 - val_loss: 0.0628 - val_accuracy: 0.9688\n",
      "Epoch 17/30\n",
      "1253/1253 [==============================] - 1468s 1s/step - loss: 0.0082 - accuracy: 0.9967 - val_loss: 0.2202 - val_accuracy: 0.9688\n",
      "Epoch 18/30\n",
      "1253/1253 [==============================] - 1472s 1s/step - loss: 0.0076 - accuracy: 0.9968 - val_loss: 0.1858 - val_accuracy: 0.9688\n",
      "Epoch 19/30\n",
      "1253/1253 [==============================] - 1474s 1s/step - loss: 0.0066 - accuracy: 0.9973 - val_loss: 0.1688 - val_accuracy: 0.9688\n",
      "Epoch 20/30\n",
      "1253/1253 [==============================] - 1472s 1s/step - loss: 0.0066 - accuracy: 0.9971 - val_loss: 0.0769 - val_accuracy: 0.9688\n",
      "Epoch 21/30\n",
      "1253/1253 [==============================] - 1473s 1s/step - loss: 0.0059 - accuracy: 0.9973 - val_loss: 0.1348 - val_accuracy: 0.9688\n",
      "Epoch 22/30\n",
      "1253/1253 [==============================] - 1469s 1s/step - loss: 0.0050 - accuracy: 0.9974 - val_loss: 0.1150 - val_accuracy: 0.9688\n",
      "Epoch 23/30\n",
      "1253/1253 [==============================] - 1476s 1s/step - loss: 0.0053 - accuracy: 0.9971 - val_loss: 0.0859 - val_accuracy: 0.9688\n",
      "Epoch 24/30\n",
      "1253/1253 [==============================] - 1474s 1s/step - loss: 0.0050 - accuracy: 0.9973 - val_loss: 0.1069 - val_accuracy: 0.9688\n",
      "Epoch 25/30\n",
      "1253/1253 [==============================] - 1473s 1s/step - loss: 0.0044 - accuracy: 0.9974 - val_loss: 0.1696 - val_accuracy: 0.9688\n",
      "Epoch 26/30\n",
      "1253/1253 [==============================] - 1461s 1s/step - loss: 0.0046 - accuracy: 0.9973 - val_loss: 0.1675 - val_accuracy: 0.9688\n",
      "Epoch 27/30\n",
      "1253/1253 [==============================] - 1459s 1s/step - loss: 0.0040 - accuracy: 0.9975 - val_loss: 0.1418 - val_accuracy: 0.9688\n",
      "Epoch 28/30\n",
      "1253/1253 [==============================] - 1465s 1s/step - loss: 0.0041 - accuracy: 0.9976 - val_loss: 0.1584 - val_accuracy: 0.9688\n",
      "Epoch 29/30\n",
      "1253/1253 [==============================] - 1461s 1s/step - loss: 0.0035 - accuracy: 0.9978 - val_loss: 0.1452 - val_accuracy: 0.9688\n",
      "Epoch 30/30\n",
      "1253/1253 [==============================] - 1468s 1s/step - loss: 0.0035 - accuracy: 0.9979 - val_loss: 0.1097 - val_accuracy: 0.9688\n",
      "INFO:tensorflow:Assets written to: ../opticnet/opticnet_30epochs_62613.0_images_False_newWeights_False_lastLayerOnly_rescale-symmetric_normalization/assets\n",
      "Test acc for opticnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.89918298 0.90025534 0.89857244 0.90320334]\n",
      "Training xception for 0.9% of train size (aka 75135 images) with pretrained: True and onlyLastLayersTrained: False...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "   6/1503 [..............................] - ETA: 14:40 - loss: 1.3756 - accuracy: 0.3661WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1181s vs `on_train_batch_begin` time: 0.1961s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1181s vs `on_train_batch_end` time: 0.1958s). Check your callbacks.\n",
      "1503/1503 [==============================] - 190s 124ms/step - loss: 1.1697 - accuracy: 0.6511 - val_loss: 1.2938 - val_accuracy: 0.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "1503/1503 [==============================] - 185s 123ms/step - loss: 0.9719 - accuracy: 0.6684 - val_loss: 1.2549 - val_accuracy: 0.5000\n",
      "Epoch 3/30\n",
      "1503/1503 [==============================] - 185s 123ms/step - loss: 0.9566 - accuracy: 0.6712 - val_loss: 1.3051 - val_accuracy: 0.4688\n",
      "Epoch 4/30\n",
      "1503/1503 [==============================] - 185s 123ms/step - loss: 0.9397 - accuracy: 0.6792 - val_loss: 1.3153 - val_accuracy: 0.4688\n",
      "Epoch 5/30\n",
      "1503/1503 [==============================] - 185s 123ms/step - loss: 0.9438 - accuracy: 0.6752 - val_loss: 1.2455 - val_accuracy: 0.5000\n",
      "Epoch 6/30\n",
      "1503/1503 [==============================] - 185s 123ms/step - loss: 0.9366 - accuracy: 0.6801 - val_loss: 1.3158 - val_accuracy: 0.4688\n",
      "Epoch 7/30\n",
      "1503/1503 [==============================] - 185s 123ms/step - loss: 0.9286 - accuracy: 0.6831 - val_loss: 1.3232 - val_accuracy: 0.4688\n",
      "Epoch 8/30\n",
      "1503/1503 [==============================] - 185s 123ms/step - loss: 0.9231 - accuracy: 0.6849 - val_loss: 1.2428 - val_accuracy: 0.5000\n",
      "Epoch 9/30\n",
      "1503/1503 [==============================] - 185s 123ms/step - loss: 0.9284 - accuracy: 0.6824 - val_loss: 1.2666 - val_accuracy: 0.5000\n",
      "Epoch 10/30\n",
      "1503/1503 [==============================] - 185s 123ms/step - loss: 0.9190 - accuracy: 0.6870 - val_loss: 1.2977 - val_accuracy: 0.4688\n",
      "Epoch 11/30\n",
      "1503/1503 [==============================] - 185s 123ms/step - loss: 0.9218 - accuracy: 0.6845 - val_loss: 1.3175 - val_accuracy: 0.4688\n",
      "Epoch 12/30\n",
      "1503/1503 [==============================] - 185s 123ms/step - loss: 0.9131 - accuracy: 0.6883 - val_loss: 1.3278 - val_accuracy: 0.4688\n",
      "Epoch 13/30\n",
      "1503/1503 [==============================] - 185s 123ms/step - loss: 0.9143 - accuracy: 0.6879 - val_loss: 1.2557 - val_accuracy: 0.5000\n",
      "Epoch 14/30\n",
      "1503/1503 [==============================] - 185s 123ms/step - loss: 0.9167 - accuracy: 0.6863 - val_loss: 1.2775 - val_accuracy: 0.4688\n",
      "Epoch 15/30\n",
      "1503/1503 [==============================] - 185s 123ms/step - loss: 0.9141 - accuracy: 0.6876 - val_loss: 1.3276 - val_accuracy: 0.4688\n",
      "Epoch 16/30\n",
      "1503/1503 [==============================] - 185s 123ms/step - loss: 0.9128 - accuracy: 0.6878 - val_loss: 1.2879 - val_accuracy: 0.4688\n",
      "Epoch 17/30\n",
      "1503/1503 [==============================] - 185s 123ms/step - loss: 0.9057 - accuracy: 0.6909 - val_loss: 1.3166 - val_accuracy: 0.4688\n",
      "Epoch 18/30\n",
      "1503/1503 [==============================] - 185s 123ms/step - loss: 0.9035 - accuracy: 0.6919 - val_loss: 1.2955 - val_accuracy: 0.4688\n",
      "Epoch 19/30\n",
      "1503/1503 [==============================] - 185s 123ms/step - loss: 0.9064 - accuracy: 0.6899 - val_loss: 1.3303 - val_accuracy: 0.4688\n",
      "Epoch 20/30\n",
      "1503/1503 [==============================] - 185s 123ms/step - loss: 0.9040 - accuracy: 0.6921 - val_loss: 1.3108 - val_accuracy: 0.4688\n",
      "Epoch 21/30\n",
      "1503/1503 [==============================] - 185s 123ms/step - loss: 0.9052 - accuracy: 0.6903 - val_loss: 1.2929 - val_accuracy: 0.4688\n",
      "Epoch 22/30\n",
      "1503/1503 [==============================] - 185s 123ms/step - loss: 0.8999 - accuracy: 0.6930 - val_loss: 1.3292 - val_accuracy: 0.4688\n",
      "Epoch 23/30\n",
      "1503/1503 [==============================] - 185s 123ms/step - loss: 0.9004 - accuracy: 0.6925 - val_loss: 1.3214 - val_accuracy: 0.4688\n",
      "Epoch 24/30\n",
      "1503/1503 [==============================] - 185s 123ms/step - loss: 0.8948 - accuracy: 0.6947 - val_loss: 1.3191 - val_accuracy: 0.4688\n",
      "Epoch 25/30\n",
      "1503/1503 [==============================] - 185s 123ms/step - loss: 0.8999 - accuracy: 0.6919 - val_loss: 1.3265 - val_accuracy: 0.4688\n",
      "Epoch 26/30\n",
      "1503/1503 [==============================] - 185s 123ms/step - loss: 0.8949 - accuracy: 0.6950 - val_loss: 1.2994 - val_accuracy: 0.4688\n",
      "Epoch 27/30\n",
      "1503/1503 [==============================] - 185s 123ms/step - loss: 0.8940 - accuracy: 0.6966 - val_loss: 1.3037 - val_accuracy: 0.4688\n",
      "Epoch 28/30\n",
      "1503/1503 [==============================] - 185s 123ms/step - loss: 0.8968 - accuracy: 0.6943 - val_loss: 1.3148 - val_accuracy: 0.4688\n",
      "Epoch 29/30\n",
      "1503/1503 [==============================] - 185s 123ms/step - loss: 0.8935 - accuracy: 0.6948 - val_loss: 1.3228 - val_accuracy: 0.4688\n",
      "Epoch 30/30\n",
      "1503/1503 [==============================] - 185s 123ms/step - loss: 0.8907 - accuracy: 0.6975 - val_loss: 1.3151 - val_accuracy: 0.4688\n",
      "INFO:tensorflow:Assets written to: ../xception/xception_30epochs_75135.6_images_False_newWeights_False_lastLayerOnly_rescale-symmetric_normalization/assets\n",
      "Test acc for xception: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training resnet for 0.9% of train size (aka 75135 images) with pretrained: True and onlyLastLayersTrained: False...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "   6/1503 [..............................] - ETA: 12:15 - loss: 1.3973 - accuracy: 0.0915WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0590s vs `on_train_batch_begin` time: 0.1975s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0590s vs `on_train_batch_end` time: 0.1632s). Check your callbacks.\n",
      "1503/1503 [==============================] - 93s 59ms/step - loss: 1.2371 - accuracy: 0.4290 - val_loss: 1.1632 - val_accuracy: 0.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "1503/1503 [==============================] - 85s 57ms/step - loss: 0.9821 - accuracy: 0.5778 - val_loss: 1.0792 - val_accuracy: 0.5000\n",
      "Epoch 3/30\n",
      "1503/1503 [==============================] - 86s 57ms/step - loss: 0.7419 - accuracy: 0.7325 - val_loss: 1.0575 - val_accuracy: 0.5000\n",
      "Epoch 4/30\n",
      "1503/1503 [==============================] - 86s 57ms/step - loss: 0.6829 - accuracy: 0.7407 - val_loss: 0.9969 - val_accuracy: 0.5000\n",
      "Epoch 5/30\n",
      "1503/1503 [==============================] - 86s 57ms/step - loss: 0.6616 - accuracy: 0.7429 - val_loss: 1.0882 - val_accuracy: 0.5000\n",
      "Epoch 6/30\n",
      "1503/1503 [==============================] - 86s 57ms/step - loss: 0.6479 - accuracy: 0.7456 - val_loss: 1.0230 - val_accuracy: 0.5000\n",
      "Epoch 7/30\n",
      "1503/1503 [==============================] - 86s 57ms/step - loss: 0.6417 - accuracy: 0.7495 - val_loss: 1.0710 - val_accuracy: 0.5312\n",
      "Epoch 8/30\n",
      "1503/1503 [==============================] - 85s 57ms/step - loss: 0.6316 - accuracy: 0.7496 - val_loss: 1.0264 - val_accuracy: 0.5000\n",
      "Epoch 9/30\n",
      "1503/1503 [==============================] - 85s 57ms/step - loss: 0.6245 - accuracy: 0.7529 - val_loss: 1.1098 - val_accuracy: 0.5312\n",
      "Epoch 10/30\n",
      "1503/1503 [==============================] - 86s 57ms/step - loss: 0.6233 - accuracy: 0.7533 - val_loss: 1.1578 - val_accuracy: 0.5000\n",
      "Epoch 11/30\n",
      "1503/1503 [==============================] - 85s 57ms/step - loss: 0.6179 - accuracy: 0.7548 - val_loss: 1.0658 - val_accuracy: 0.5000\n",
      "Epoch 12/30\n",
      "1503/1503 [==============================] - 85s 57ms/step - loss: 0.6144 - accuracy: 0.7541 - val_loss: 1.0982 - val_accuracy: 0.5000\n",
      "Epoch 13/30\n",
      "1503/1503 [==============================] - 86s 57ms/step - loss: 0.6121 - accuracy: 0.7575 - val_loss: 1.0286 - val_accuracy: 0.5312\n",
      "Epoch 14/30\n",
      "1503/1503 [==============================] - 86s 57ms/step - loss: 0.6063 - accuracy: 0.7580 - val_loss: 1.0110 - val_accuracy: 0.5000\n",
      "Epoch 15/30\n",
      "1503/1503 [==============================] - 86s 57ms/step - loss: 0.6067 - accuracy: 0.7573 - val_loss: 0.9733 - val_accuracy: 0.5000\n",
      "Epoch 16/30\n",
      "1503/1503 [==============================] - 85s 57ms/step - loss: 0.6012 - accuracy: 0.7607 - val_loss: 0.9721 - val_accuracy: 0.5312\n",
      "Epoch 17/30\n",
      "1503/1503 [==============================] - 85s 57ms/step - loss: 0.5978 - accuracy: 0.7625 - val_loss: 1.0032 - val_accuracy: 0.5000\n",
      "Epoch 18/30\n",
      "1503/1503 [==============================] - 85s 57ms/step - loss: 0.5963 - accuracy: 0.7617 - val_loss: 1.0355 - val_accuracy: 0.5312\n",
      "Epoch 19/30\n",
      "1503/1503 [==============================] - 85s 57ms/step - loss: 0.5992 - accuracy: 0.7601 - val_loss: 0.9472 - val_accuracy: 0.5312\n",
      "Epoch 20/30\n",
      "1503/1503 [==============================] - 85s 57ms/step - loss: 0.5889 - accuracy: 0.7667 - val_loss: 1.0027 - val_accuracy: 0.5625\n",
      "Epoch 21/30\n",
      "1503/1503 [==============================] - 86s 57ms/step - loss: 0.5908 - accuracy: 0.7653 - val_loss: 0.9280 - val_accuracy: 0.5312\n",
      "Epoch 22/30\n",
      "1503/1503 [==============================] - 86s 57ms/step - loss: 0.5900 - accuracy: 0.7647 - val_loss: 0.9624 - val_accuracy: 0.5312\n",
      "Epoch 23/30\n",
      "1503/1503 [==============================] - 85s 57ms/step - loss: 0.5912 - accuracy: 0.7639 - val_loss: 0.9615 - val_accuracy: 0.5312\n",
      "Epoch 24/30\n",
      "1503/1503 [==============================] - 85s 57ms/step - loss: 0.5857 - accuracy: 0.7668 - val_loss: 0.9358 - val_accuracy: 0.5312\n",
      "Epoch 25/30\n",
      "1503/1503 [==============================] - 85s 57ms/step - loss: 0.5857 - accuracy: 0.7650 - val_loss: 0.9514 - val_accuracy: 0.5312\n",
      "Epoch 26/30\n",
      "1503/1503 [==============================] - 85s 57ms/step - loss: 0.5837 - accuracy: 0.7665 - val_loss: 0.9459 - val_accuracy: 0.5000\n",
      "Epoch 27/30\n",
      "1503/1503 [==============================] - 85s 57ms/step - loss: 0.5844 - accuracy: 0.7653 - val_loss: 0.9730 - val_accuracy: 0.5312\n",
      "Epoch 28/30\n",
      "1503/1503 [==============================] - 85s 57ms/step - loss: 0.5816 - accuracy: 0.7659 - val_loss: 0.9757 - val_accuracy: 0.5312\n",
      "Epoch 29/30\n",
      "1503/1503 [==============================] - 85s 57ms/step - loss: 0.5799 - accuracy: 0.7684 - val_loss: 0.9789 - val_accuracy: 0.5312\n",
      "Epoch 30/30\n",
      "1503/1503 [==============================] - 86s 57ms/step - loss: 0.5818 - accuracy: 0.7686 - val_loss: 0.9580 - val_accuracy: 0.5312\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_75135.6_images_False_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.246901\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training opticnet for 0.9% of train size (aka 75135 images) with pretrained: True and onlyLastLayersTrained: False...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "   6/1503 [..............................] - ETA: 46:00 - loss: 5.3626 - accuracy: 0.1813  WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.4648s vs `on_train_batch_end` time: 1.0549s). Check your callbacks.\n",
      "1503/1503 [==============================] - 1779s 1s/step - loss: 0.3001 - accuracy: 0.9143 - val_loss: 0.0312 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "1503/1503 [==============================] - 1758s 1s/step - loss: 0.1209 - accuracy: 0.9597 - val_loss: 0.0643 - val_accuracy: 0.9688\n",
      "Epoch 3/30\n",
      "1503/1503 [==============================] - 1756s 1s/step - loss: 0.1055 - accuracy: 0.9648 - val_loss: 0.0042 - val_accuracy: 1.0000\n",
      "Epoch 4/30\n",
      "1503/1503 [==============================] - 1759s 1s/step - loss: 0.0896 - accuracy: 0.9691 - val_loss: 0.0122 - val_accuracy: 1.0000\n",
      "Epoch 5/30\n",
      "1503/1503 [==============================] - 1763s 1s/step - loss: 0.0748 - accuracy: 0.9742 - val_loss: 0.0104 - val_accuracy: 1.0000\n",
      "Epoch 6/30\n",
      "1503/1503 [==============================] - 1763s 1s/step - loss: 0.0567 - accuracy: 0.9809 - val_loss: 0.0125 - val_accuracy: 1.0000\n",
      "Epoch 7/30\n",
      "1503/1503 [==============================] - 1760s 1s/step - loss: 0.0476 - accuracy: 0.9843 - val_loss: 0.0165 - val_accuracy: 1.0000\n",
      "Epoch 8/30\n",
      "1503/1503 [==============================] - 1761s 1s/step - loss: 0.0343 - accuracy: 0.9884 - val_loss: 0.0141 - val_accuracy: 1.0000\n",
      "Epoch 9/30\n",
      "1503/1503 [==============================] - 1760s 1s/step - loss: 0.0296 - accuracy: 0.9902 - val_loss: 0.0084 - val_accuracy: 1.0000\n",
      "Epoch 10/30\n",
      "1503/1503 [==============================] - 1760s 1s/step - loss: 0.0262 - accuracy: 0.9913 - val_loss: 0.0065 - val_accuracy: 1.0000\n",
      "Epoch 11/30\n",
      "1503/1503 [==============================] - 1759s 1s/step - loss: 0.0190 - accuracy: 0.9938 - val_loss: 0.0074 - val_accuracy: 1.0000\n",
      "Epoch 12/30\n",
      "1503/1503 [==============================] - 1750s 1s/step - loss: 0.0176 - accuracy: 0.9936 - val_loss: 0.0072 - val_accuracy: 1.0000\n",
      "Epoch 13/30\n",
      "1503/1503 [==============================] - 1749s 1s/step - loss: 0.0156 - accuracy: 0.9945 - val_loss: 0.0066 - val_accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "1503/1503 [==============================] - 1758s 1s/step - loss: 0.0124 - accuracy: 0.9956 - val_loss: 0.0062 - val_accuracy: 1.0000\n",
      "Epoch 15/30\n",
      "1503/1503 [==============================] - 1762s 1s/step - loss: 0.0117 - accuracy: 0.9960 - val_loss: 0.0042 - val_accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "1503/1503 [==============================] - 1763s 1s/step - loss: 0.0111 - accuracy: 0.9958 - val_loss: 0.0117 - val_accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "1503/1503 [==============================] - 1761s 1s/step - loss: 0.0102 - accuracy: 0.9959 - val_loss: 0.0109 - val_accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "1503/1503 [==============================] - 1762s 1s/step - loss: 0.0084 - accuracy: 0.9963 - val_loss: 0.0325 - val_accuracy: 0.9688\n",
      "Epoch 19/30\n",
      "1503/1503 [==============================] - 1748s 1s/step - loss: 0.0078 - accuracy: 0.9962 - val_loss: 0.0244 - val_accuracy: 0.9688\n",
      "Epoch 20/30\n",
      "1503/1503 [==============================] - 1765s 1s/step - loss: 0.0074 - accuracy: 0.9963 - val_loss: 0.0174 - val_accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "1503/1503 [==============================] - 1761s 1s/step - loss: 0.0072 - accuracy: 0.9963 - val_loss: 0.0148 - val_accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "1503/1503 [==============================] - 1757s 1s/step - loss: 0.0058 - accuracy: 0.9967 - val_loss: 0.0287 - val_accuracy: 0.9688\n",
      "Epoch 23/30\n",
      "1503/1503 [==============================] - 1762s 1s/step - loss: 0.0058 - accuracy: 0.9965 - val_loss: 0.0231 - val_accuracy: 0.9688\n",
      "Epoch 24/30\n",
      "1503/1503 [==============================] - 1765s 1s/step - loss: 0.0054 - accuracy: 0.9968 - val_loss: 0.0215 - val_accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "1503/1503 [==============================] - 1764s 1s/step - loss: 0.0050 - accuracy: 0.9969 - val_loss: 0.0181 - val_accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "1503/1503 [==============================] - 1762s 1s/step - loss: 0.0051 - accuracy: 0.9964 - val_loss: 0.0258 - val_accuracy: 0.9688\n",
      "Epoch 27/30\n",
      "1503/1503 [==============================] - 1764s 1s/step - loss: 0.0050 - accuracy: 0.9966 - val_loss: 0.0255 - val_accuracy: 0.9688\n",
      "Epoch 28/30\n",
      "1503/1503 [==============================] - 1765s 1s/step - loss: 0.0047 - accuracy: 0.9968 - val_loss: 0.0204 - val_accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "1503/1503 [==============================] - 1758s 1s/step - loss: 0.0046 - accuracy: 0.9967 - val_loss: 0.0187 - val_accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "1503/1503 [==============================] - 1756s 1s/step - loss: 0.0044 - accuracy: 0.9970 - val_loss: 0.0203 - val_accuracy: 1.0000\n",
      "INFO:tensorflow:Assets written to: ../opticnet/opticnet_30epochs_75135.6_images_False_newWeights_False_lastLayerOnly_rescale-symmetric_normalization/assets\n",
      "Test acc for opticnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [1. 1. 1. 1.]\n",
      "Training xception for 1.0% of train size (aka 83484 images) with pretrained: True and onlyLastLayersTrained: False...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "   6/1670 [..............................] - ETA: 16:47 - loss: 1.4007 - accuracy: 0.3497WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1161s vs `on_train_batch_begin` time: 0.1980s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1161s vs `on_train_batch_end` time: 0.2098s). Check your callbacks.\n",
      "1670/1670 [==============================] - 210s 124ms/step - loss: 1.1686 - accuracy: 0.6263 - val_loss: 1.3432 - val_accuracy: 0.4688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "1670/1670 [==============================] - 206s 123ms/step - loss: 0.9514 - accuracy: 0.6772 - val_loss: 1.2467 - val_accuracy: 0.5000\n",
      "Epoch 3/30\n",
      "1670/1670 [==============================] - 206s 123ms/step - loss: 0.9282 - accuracy: 0.6842 - val_loss: 1.3216 - val_accuracy: 0.4688\n",
      "Epoch 4/30\n",
      "1670/1670 [==============================] - 206s 123ms/step - loss: 0.9271 - accuracy: 0.6833 - val_loss: 1.3399 - val_accuracy: 0.4688\n",
      "Epoch 5/30\n",
      "1670/1670 [==============================] - 206s 123ms/step - loss: 0.9256 - accuracy: 0.6841 - val_loss: 1.3263 - val_accuracy: 0.4688\n",
      "Epoch 6/30\n",
      "1670/1670 [==============================] - 206s 123ms/step - loss: 0.9103 - accuracy: 0.6911 - val_loss: 1.2544 - val_accuracy: 0.5000\n",
      "Epoch 7/30\n",
      "1670/1670 [==============================] - 206s 123ms/step - loss: 0.9183 - accuracy: 0.6872 - val_loss: 1.3410 - val_accuracy: 0.4688\n",
      "Epoch 8/30\n",
      "1670/1670 [==============================] - 206s 124ms/step - loss: 0.9083 - accuracy: 0.6907 - val_loss: 1.2605 - val_accuracy: 0.5000\n",
      "Epoch 9/30\n",
      "1670/1670 [==============================] - 206s 124ms/step - loss: 0.9046 - accuracy: 0.6925 - val_loss: 1.2597 - val_accuracy: 0.5000\n",
      "Epoch 10/30\n",
      "1670/1670 [==============================] - 206s 124ms/step - loss: 0.9108 - accuracy: 0.6887 - val_loss: 1.3364 - val_accuracy: 0.4688\n",
      "Epoch 11/30\n",
      "1670/1670 [==============================] - 206s 123ms/step - loss: 0.9073 - accuracy: 0.6905 - val_loss: 1.2996 - val_accuracy: 0.4688\n",
      "Epoch 12/30\n",
      "1670/1670 [==============================] - 206s 123ms/step - loss: 0.9040 - accuracy: 0.6922 - val_loss: 1.3078 - val_accuracy: 0.4688\n",
      "Epoch 13/30\n",
      "1670/1670 [==============================] - 206s 123ms/step - loss: 0.8999 - accuracy: 0.6936 - val_loss: 1.3355 - val_accuracy: 0.4688\n",
      "Epoch 14/30\n",
      "1670/1670 [==============================] - 206s 123ms/step - loss: 0.9081 - accuracy: 0.6888 - val_loss: 1.3221 - val_accuracy: 0.4688\n",
      "Epoch 15/30\n",
      "1670/1670 [==============================] - 206s 123ms/step - loss: 0.9021 - accuracy: 0.6917 - val_loss: 1.2921 - val_accuracy: 0.4688\n",
      "Epoch 16/30\n",
      "1670/1670 [==============================] - 206s 124ms/step - loss: 0.8976 - accuracy: 0.6939 - val_loss: 1.3407 - val_accuracy: 0.4688\n",
      "Epoch 17/30\n",
      "1670/1670 [==============================] - 206s 123ms/step - loss: 0.8952 - accuracy: 0.6944 - val_loss: 1.3115 - val_accuracy: 0.4688\n",
      "Epoch 18/30\n",
      "1670/1670 [==============================] - 206s 123ms/step - loss: 0.8890 - accuracy: 0.6981 - val_loss: 1.3365 - val_accuracy: 0.4688\n",
      "Epoch 19/30\n",
      "1670/1670 [==============================] - 206s 123ms/step - loss: 0.8924 - accuracy: 0.6956 - val_loss: 1.3103 - val_accuracy: 0.4688\n",
      "Epoch 20/30\n",
      "1670/1670 [==============================] - 206s 123ms/step - loss: 0.8919 - accuracy: 0.6966 - val_loss: 1.3465 - val_accuracy: 0.4688\n",
      "Epoch 21/30\n",
      "1670/1670 [==============================] - 206s 124ms/step - loss: 0.8826 - accuracy: 0.7008 - val_loss: 1.3222 - val_accuracy: 0.4688\n",
      "Epoch 22/30\n",
      "1670/1670 [==============================] - 206s 123ms/step - loss: 0.8909 - accuracy: 0.6957 - val_loss: 1.3278 - val_accuracy: 0.4688\n",
      "Epoch 23/30\n",
      "1670/1670 [==============================] - 206s 124ms/step - loss: 0.8898 - accuracy: 0.6972 - val_loss: 1.3357 - val_accuracy: 0.4688\n",
      "Epoch 24/30\n",
      "1670/1670 [==============================] - 206s 124ms/step - loss: 0.8916 - accuracy: 0.6952 - val_loss: 1.3052 - val_accuracy: 0.4688\n",
      "Epoch 25/30\n",
      "1670/1670 [==============================] - 206s 123ms/step - loss: 0.8817 - accuracy: 0.7005 - val_loss: 1.3347 - val_accuracy: 0.4688\n",
      "Epoch 26/30\n",
      "1670/1670 [==============================] - 206s 123ms/step - loss: 0.8868 - accuracy: 0.6981 - val_loss: 1.3351 - val_accuracy: 0.4688\n",
      "Epoch 27/30\n",
      "1670/1670 [==============================] - 207s 124ms/step - loss: 0.8825 - accuracy: 0.7000 - val_loss: 1.3133 - val_accuracy: 0.4688\n",
      "Epoch 28/30\n",
      "1670/1670 [==============================] - 206s 124ms/step - loss: 0.8821 - accuracy: 0.7003 - val_loss: 1.3242 - val_accuracy: 0.4688\n",
      "Epoch 29/30\n",
      "1670/1670 [==============================] - 206s 124ms/step - loss: 0.8869 - accuracy: 0.6983 - val_loss: 1.3334 - val_accuracy: 0.4688\n",
      "Epoch 30/30\n",
      "1670/1670 [==============================] - 207s 124ms/step - loss: 0.8834 - accuracy: 0.6991 - val_loss: 1.3075 - val_accuracy: 0.4688\n",
      "INFO:tensorflow:Assets written to: ../xception/xception_30epochs_83484.0_images_False_newWeights_False_lastLayerOnly_rescale-symmetric_normalization/assets\n",
      "Test acc for xception: 0.254132\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training resnet for 1.0% of train size (aka 83484 images) with pretrained: True and onlyLastLayersTrained: False...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "   6/1670 [..............................] - ETA: 13:34 - loss: 1.3926 - accuracy: 0.0829WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0592s vs `on_train_batch_begin` time: 0.2009s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0592s vs `on_train_batch_end` time: 0.1579s). Check your callbacks.\n",
      "1670/1670 [==============================] - 103s 60ms/step - loss: 1.0679 - accuracy: 0.7128 - val_loss: 1.1454 - val_accuracy: 0.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "1670/1670 [==============================] - 97s 58ms/step - loss: 0.7153 - accuracy: 0.7489 - val_loss: 1.0969 - val_accuracy: 0.5000\n",
      "Epoch 3/30\n",
      "1670/1670 [==============================] - 97s 58ms/step - loss: 0.6645 - accuracy: 0.7494 - val_loss: 1.1261 - val_accuracy: 0.5000\n",
      "Epoch 4/30\n",
      "1670/1670 [==============================] - 96s 57ms/step - loss: 0.6401 - accuracy: 0.7525 - val_loss: 1.0554 - val_accuracy: 0.5000\n",
      "Epoch 5/30\n",
      "1670/1670 [==============================] - 97s 58ms/step - loss: 0.6328 - accuracy: 0.7533 - val_loss: 1.0196 - val_accuracy: 0.5000\n",
      "Epoch 6/30\n",
      "1670/1670 [==============================] - 96s 58ms/step - loss: 0.6260 - accuracy: 0.7541 - val_loss: 1.0401 - val_accuracy: 0.5312\n",
      "Epoch 7/30\n",
      "1670/1670 [==============================] - 96s 57ms/step - loss: 0.6232 - accuracy: 0.7565 - val_loss: 1.0210 - val_accuracy: 0.5000\n",
      "Epoch 8/30\n",
      "1670/1670 [==============================] - 97s 58ms/step - loss: 0.6212 - accuracy: 0.7584 - val_loss: 0.9943 - val_accuracy: 0.5312\n",
      "Epoch 9/30\n",
      "1670/1670 [==============================] - 96s 58ms/step - loss: 0.5957 - accuracy: 0.7656 - val_loss: 0.6753 - val_accuracy: 0.6875\n",
      "Epoch 10/30\n",
      "1670/1670 [==============================] - 96s 57ms/step - loss: 0.5450 - accuracy: 0.7884 - val_loss: 0.6145 - val_accuracy: 0.7500\n",
      "Epoch 11/30\n",
      "1670/1670 [==============================] - 96s 57ms/step - loss: 0.5213 - accuracy: 0.7959 - val_loss: 0.6224 - val_accuracy: 0.6875\n",
      "Epoch 12/30\n",
      "1670/1670 [==============================] - 96s 58ms/step - loss: 0.5100 - accuracy: 0.7992 - val_loss: 0.5582 - val_accuracy: 0.7812\n",
      "Epoch 13/30\n",
      "1670/1670 [==============================] - 96s 58ms/step - loss: 0.5019 - accuracy: 0.8012 - val_loss: 0.5606 - val_accuracy: 0.7812\n",
      "Epoch 14/30\n",
      "1670/1670 [==============================] - 97s 58ms/step - loss: 0.4977 - accuracy: 0.8030 - val_loss: 0.5594 - val_accuracy: 0.7812\n",
      "Epoch 15/30\n",
      "1670/1670 [==============================] - 96s 57ms/step - loss: 0.4954 - accuracy: 0.8014 - val_loss: 0.5270 - val_accuracy: 0.8125\n",
      "Epoch 16/30\n",
      "1670/1670 [==============================] - 96s 57ms/step - loss: 0.4865 - accuracy: 0.8058 - val_loss: 0.6281 - val_accuracy: 0.6562\n",
      "Epoch 17/30\n",
      "1670/1670 [==============================] - 96s 57ms/step - loss: 0.4882 - accuracy: 0.8060 - val_loss: 0.5954 - val_accuracy: 0.7500\n",
      "Epoch 18/30\n",
      "1670/1670 [==============================] - 96s 58ms/step - loss: 0.4834 - accuracy: 0.8067 - val_loss: 0.5849 - val_accuracy: 0.7500\n",
      "Epoch 19/30\n",
      "1670/1670 [==============================] - 96s 57ms/step - loss: 0.4836 - accuracy: 0.8067 - val_loss: 0.5311 - val_accuracy: 0.7812\n",
      "Epoch 20/30\n",
      "1670/1670 [==============================] - 96s 57ms/step - loss: 0.4797 - accuracy: 0.8081 - val_loss: 0.5616 - val_accuracy: 0.7500\n",
      "Epoch 21/30\n",
      "1670/1670 [==============================] - 96s 58ms/step - loss: 0.4798 - accuracy: 0.8090 - val_loss: 0.5189 - val_accuracy: 0.7812\n",
      "Epoch 22/30\n",
      "1670/1670 [==============================] - 97s 58ms/step - loss: 0.4739 - accuracy: 0.8113 - val_loss: 0.5211 - val_accuracy: 0.7812\n",
      "Epoch 23/30\n",
      "1670/1670 [==============================] - 97s 58ms/step - loss: 0.4733 - accuracy: 0.8120 - val_loss: 0.5129 - val_accuracy: 0.8125\n",
      "Epoch 24/30\n",
      "1670/1670 [==============================] - 96s 58ms/step - loss: 0.4780 - accuracy: 0.8088 - val_loss: 0.5015 - val_accuracy: 0.7812\n",
      "Epoch 25/30\n",
      "1670/1670 [==============================] - 96s 57ms/step - loss: 0.4746 - accuracy: 0.8103 - val_loss: 0.5294 - val_accuracy: 0.7500\n",
      "Epoch 26/30\n",
      "1670/1670 [==============================] - 96s 57ms/step - loss: 0.4708 - accuracy: 0.8109 - val_loss: 0.5269 - val_accuracy: 0.7500\n",
      "Epoch 27/30\n",
      "1670/1670 [==============================] - 96s 57ms/step - loss: 0.4695 - accuracy: 0.8105 - val_loss: 0.5222 - val_accuracy: 0.7812\n",
      "Epoch 28/30\n",
      "1670/1670 [==============================] - 96s 58ms/step - loss: 0.4635 - accuracy: 0.8160 - val_loss: 0.5292 - val_accuracy: 0.7500\n",
      "Epoch 29/30\n",
      "1670/1670 [==============================] - 96s 57ms/step - loss: 0.4677 - accuracy: 0.8129 - val_loss: 0.5167 - val_accuracy: 0.7500\n",
      "Epoch 30/30\n",
      "1670/1670 [==============================] - 96s 58ms/step - loss: 0.4649 - accuracy: 0.8140 - val_loss: 0.5299 - val_accuracy: 0.7500\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_83484.0_images_False_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training opticnet for 1.0% of train size (aka 83484 images) with pretrained: True and onlyLastLayersTrained: False...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "   6/1670 [..............................] - ETA: 51:05 - loss: 5.3620 - accuracy: 0.1573  WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.4664s vs `on_train_batch_end` time: 1.0540s). Check your callbacks.\n",
      "1670/1670 [==============================] - 1981s 1s/step - loss: 0.3078 - accuracy: 0.9088 - val_loss: 0.0415 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "1670/1670 [==============================] - 1965s 1s/step - loss: 0.1227 - accuracy: 0.9588 - val_loss: 0.0993 - val_accuracy: 0.9688\n",
      "Epoch 3/30\n",
      "1670/1670 [==============================] - 1965s 1s/step - loss: 0.1021 - accuracy: 0.9658 - val_loss: 0.0148 - val_accuracy: 1.0000\n",
      "Epoch 4/30\n",
      "1670/1670 [==============================] - 1964s 1s/step - loss: 0.0868 - accuracy: 0.9709 - val_loss: 0.0054 - val_accuracy: 1.0000\n",
      "Epoch 5/30\n",
      "1670/1670 [==============================] - 1950s 1s/step - loss: 0.0705 - accuracy: 0.9752 - val_loss: 0.0098 - val_accuracy: 1.0000\n",
      "Epoch 6/30\n",
      "1670/1670 [==============================] - 1963s 1s/step - loss: 0.0575 - accuracy: 0.9801 - val_loss: 0.0174 - val_accuracy: 1.0000\n",
      "Epoch 7/30\n",
      "1670/1670 [==============================] - 1964s 1s/step - loss: 0.0456 - accuracy: 0.9841 - val_loss: 0.0413 - val_accuracy: 0.9688\n",
      "Epoch 8/30\n",
      "1670/1670 [==============================] - 1954s 1s/step - loss: 0.0357 - accuracy: 0.9882 - val_loss: 0.0123 - val_accuracy: 1.0000\n",
      "Epoch 9/30\n",
      "1670/1670 [==============================] - 1965s 1s/step - loss: 0.0293 - accuracy: 0.9894 - val_loss: 0.0490 - val_accuracy: 0.9688\n",
      "Epoch 10/30\n",
      "1670/1670 [==============================] - 1965s 1s/step - loss: 0.0236 - accuracy: 0.9921 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
      "Epoch 11/30\n",
      "1670/1670 [==============================] - 1947s 1s/step - loss: 0.0190 - accuracy: 0.9935 - val_loss: 0.0642 - val_accuracy: 0.9688\n",
      "Epoch 12/30\n",
      "1670/1670 [==============================] - 1956s 1s/step - loss: 0.0183 - accuracy: 0.9933 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
      "Epoch 13/30\n",
      "1670/1670 [==============================] - 1956s 1s/step - loss: 0.0157 - accuracy: 0.9948 - val_loss: 0.0049 - val_accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "1670/1670 [==============================] - 1956s 1s/step - loss: 0.0140 - accuracy: 0.9950 - val_loss: 0.0041 - val_accuracy: 1.0000\n",
      "Epoch 15/30\n",
      "1670/1670 [==============================] - 1959s 1s/step - loss: 0.0114 - accuracy: 0.9956 - val_loss: 0.1074 - val_accuracy: 0.9688\n",
      "Epoch 16/30\n",
      "1670/1670 [==============================] - 1954s 1s/step - loss: 0.0111 - accuracy: 0.9959 - val_loss: 0.3243 - val_accuracy: 0.9688\n",
      "Epoch 17/30\n",
      "1670/1670 [==============================] - 1955s 1s/step - loss: 0.0113 - accuracy: 0.9951 - val_loss: 0.0051 - val_accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "1670/1670 [==============================] - 1957s 1s/step - loss: 0.0084 - accuracy: 0.9964 - val_loss: 0.0066 - val_accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "1670/1670 [==============================] - 1955s 1s/step - loss: 0.0086 - accuracy: 0.9962 - val_loss: 0.0248 - val_accuracy: 0.9688\n",
      "Epoch 20/30\n",
      "1670/1670 [==============================] - 1955s 1s/step - loss: 0.0070 - accuracy: 0.9966 - val_loss: 0.0061 - val_accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "1670/1670 [==============================] - 1952s 1s/step - loss: 0.0067 - accuracy: 0.9965 - val_loss: 0.0218 - val_accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "1670/1670 [==============================] - 1951s 1s/step - loss: 0.0066 - accuracy: 0.9963 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "1670/1670 [==============================] - 1954s 1s/step - loss: 0.0059 - accuracy: 0.9966 - val_loss: 0.0202 - val_accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "1670/1670 [==============================] - 1952s 1s/step - loss: 0.0063 - accuracy: 0.9963 - val_loss: 0.0160 - val_accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "1670/1670 [==============================] - 1956s 1s/step - loss: 0.0056 - accuracy: 0.9967 - val_loss: 0.0331 - val_accuracy: 0.9688\n",
      "Epoch 26/30\n",
      "1670/1670 [==============================] - 1956s 1s/step - loss: 0.0052 - accuracy: 0.9969 - val_loss: 0.0283 - val_accuracy: 0.9688\n",
      "Epoch 27/30\n",
      "1670/1670 [==============================] - 1956s 1s/step - loss: 0.0047 - accuracy: 0.9971 - val_loss: 0.0330 - val_accuracy: 0.9688\n",
      "Epoch 28/30\n",
      "1670/1670 [==============================] - 1954s 1s/step - loss: 0.0056 - accuracy: 0.9963 - val_loss: 0.0219 - val_accuracy: 0.9688\n",
      "Epoch 29/30\n",
      "1670/1670 [==============================] - 1956s 1s/step - loss: 0.0048 - accuracy: 0.9970 - val_loss: 0.0271 - val_accuracy: 0.9688\n",
      "Epoch 30/30\n",
      "1670/1670 [==============================] - 1958s 1s/step - loss: 0.0045 - accuracy: 0.9966 - val_loss: 0.0311 - val_accuracy: 0.9688\n",
      "INFO:tensorflow:Assets written to: ../opticnet/opticnet_30epochs_83484.0_images_False_newWeights_False_lastLayerOnly_rescale-symmetric_normalization/assets\n",
      "Test acc for opticnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.0101463  0.00983739 0.01039831 0.00963324]\n",
      "Training xception for 0.01% of train size (aka 834 images) with pretrained: False and onlyLastLayersTrained: True...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      " 6/17 [=========>....................] - ETA: 6s - loss: 1.3862 - accuracy: 0.1162WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1179s vs `on_train_batch_begin` time: 0.1579s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1179s vs `on_train_batch_end` time: 0.2303s). Check your callbacks.\n",
      "17/17 [==============================] - 11s 349ms/step - loss: 1.3861 - accuracy: 0.1329 - val_loss: 1.3863 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "17/17 [==============================] - 2s 124ms/step - loss: 1.3861 - accuracy: 0.1370 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "17/17 [==============================] - 2s 124ms/step - loss: 1.3861 - accuracy: 0.1362 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "17/17 [==============================] - 2s 124ms/step - loss: 1.3861 - accuracy: 0.1472 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "17/17 [==============================] - 2s 124ms/step - loss: 1.3860 - accuracy: 0.1507 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "17/17 [==============================] - 2s 124ms/step - loss: 1.3861 - accuracy: 0.1354 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "17/17 [==============================] - 2s 125ms/step - loss: 1.3860 - accuracy: 0.1429 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "17/17 [==============================] - 2s 125ms/step - loss: 1.3860 - accuracy: 0.1506 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "17/17 [==============================] - 2s 126ms/step - loss: 1.3860 - accuracy: 0.1677 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "17/17 [==============================] - 2s 125ms/step - loss: 1.3861 - accuracy: 0.1445 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "17/17 [==============================] - 2s 124ms/step - loss: 1.3862 - accuracy: 0.1444 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "17/17 [==============================] - 2s 125ms/step - loss: 1.3862 - accuracy: 0.1227 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "17/17 [==============================] - 2s 125ms/step - loss: 1.3862 - accuracy: 0.1318 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "17/17 [==============================] - 2s 125ms/step - loss: 1.3861 - accuracy: 0.1435 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "17/17 [==============================] - 2s 125ms/step - loss: 1.3861 - accuracy: 0.1410 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "17/17 [==============================] - 2s 125ms/step - loss: 1.3861 - accuracy: 0.1502 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "17/17 [==============================] - 2s 125ms/step - loss: 1.3861 - accuracy: 0.1506 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "17/17 [==============================] - 2s 126ms/step - loss: 1.3861 - accuracy: 0.1373 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "17/17 [==============================] - 2s 125ms/step - loss: 1.3861 - accuracy: 0.1544 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "17/17 [==============================] - 2s 125ms/step - loss: 1.3861 - accuracy: 0.1681 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "17/17 [==============================] - 2s 126ms/step - loss: 1.3860 - accuracy: 0.1491 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "17/17 [==============================] - 2s 125ms/step - loss: 1.3862 - accuracy: 0.1172 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "17/17 [==============================] - 2s 127ms/step - loss: 1.3861 - accuracy: 0.1415 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "17/17 [==============================] - 2s 126ms/step - loss: 1.3861 - accuracy: 0.1331 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "17/17 [==============================] - 2s 125ms/step - loss: 1.3861 - accuracy: 0.1448 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "17/17 [==============================] - 2s 125ms/step - loss: 1.3861 - accuracy: 0.1428 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "17/17 [==============================] - 2s 125ms/step - loss: 1.3861 - accuracy: 0.1397 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "17/17 [==============================] - 2s 126ms/step - loss: 1.3861 - accuracy: 0.1417 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "17/17 [==============================] - 2s 126ms/step - loss: 1.3861 - accuracy: 0.1632 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "17/17 [==============================] - 2s 125ms/step - loss: 1.3861 - accuracy: 0.1383 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../xception/xception_30epochs_834.84_images_True_newWeights_True_lastLayerOnly_rescale-symmetric_normalization/assets\n",
      "Test acc for xception: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training resnet for 0.01% of train size (aka 834 images) with pretrained: False and onlyLastLayersTrained: True...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      " 6/17 [=========>....................] - ETA: 4s - loss: 1.3858 - accuracy: 0.3099WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0594s vs `on_train_batch_begin` time: 0.1371s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0594s vs `on_train_batch_end` time: 0.1677s). Check your callbacks.\n",
      "17/17 [==============================] - 8s 263ms/step - loss: 1.3860 - accuracy: 0.3539 - val_loss: 1.3862 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "17/17 [==============================] - 1s 59ms/step - loss: 1.3864 - accuracy: 0.3581 - val_loss: 1.3862 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.3862 - accuracy: 0.3721 - val_loss: 1.3862 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.3857 - accuracy: 0.4088 - val_loss: 1.3862 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.3859 - accuracy: 0.3771 - val_loss: 1.3862 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.3867 - accuracy: 0.3501 - val_loss: 1.3862 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "17/17 [==============================] - 1s 59ms/step - loss: 1.3858 - accuracy: 0.3672 - val_loss: 1.3862 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "17/17 [==============================] - 1s 59ms/step - loss: 1.3862 - accuracy: 0.3824 - val_loss: 1.3862 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.3855 - accuracy: 0.4027 - val_loss: 1.3862 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.3858 - accuracy: 0.4117 - val_loss: 1.3862 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.3856 - accuracy: 0.3863 - val_loss: 1.3862 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.3863 - accuracy: 0.3741 - val_loss: 1.3862 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "17/17 [==============================] - 1s 61ms/step - loss: 1.3861 - accuracy: 0.3783 - val_loss: 1.3862 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.3853 - accuracy: 0.4090 - val_loss: 1.3862 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "17/17 [==============================] - 1s 59ms/step - loss: 1.3859 - accuracy: 0.3693 - val_loss: 1.3862 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.3865 - accuracy: 0.3615 - val_loss: 1.3862 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "17/17 [==============================] - 1s 59ms/step - loss: 1.3862 - accuracy: 0.3882 - val_loss: 1.3862 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.3862 - accuracy: 0.3729 - val_loss: 1.3862 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.3863 - accuracy: 0.3883 - val_loss: 1.3862 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.3854 - accuracy: 0.3972 - val_loss: 1.3862 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.3860 - accuracy: 0.3777 - val_loss: 1.3862 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.3858 - accuracy: 0.3896 - val_loss: 1.3862 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.3859 - accuracy: 0.3929 - val_loss: 1.3862 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "17/17 [==============================] - 1s 59ms/step - loss: 1.3860 - accuracy: 0.3870 - val_loss: 1.3862 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.3862 - accuracy: 0.3737 - val_loss: 1.3862 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.3862 - accuracy: 0.3943 - val_loss: 1.3862 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.3857 - accuracy: 0.3939 - val_loss: 1.3862 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.3857 - accuracy: 0.3818 - val_loss: 1.3862 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "17/17 [==============================] - 1s 60ms/step - loss: 1.3862 - accuracy: 0.3848 - val_loss: 1.3862 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "17/17 [==============================] - 1s 59ms/step - loss: 1.3856 - accuracy: 0.3911 - val_loss: 1.3862 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_834.84_images_True_newWeights_True_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training opticnet for 0.01% of train size (aka 834 images) with pretrained: False and onlyLastLayersTrained: True...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "17/17 [==============================] - 15s 578ms/step - loss: 366.7943 - accuracy: 0.0918 - val_loss: 342.0490 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "17/17 [==============================] - 5s 293ms/step - loss: 364.7400 - accuracy: 0.0995 - val_loss: 342.0490 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "17/17 [==============================] - 5s 294ms/step - loss: 358.0874 - accuracy: 0.0979 - val_loss: 342.0490 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "17/17 [==============================] - 5s 294ms/step - loss: 371.6939 - accuracy: 0.1023 - val_loss: 342.0490 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "17/17 [==============================] - 5s 294ms/step - loss: 359.7793 - accuracy: 0.0970 - val_loss: 342.0490 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "17/17 [==============================] - 5s 294ms/step - loss: 366.8220 - accuracy: 0.0988 - val_loss: 342.0490 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "17/17 [==============================] - 5s 295ms/step - loss: 382.9550 - accuracy: 0.1000 - val_loss: 342.0490 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "17/17 [==============================] - 5s 295ms/step - loss: 381.6775 - accuracy: 0.0809 - val_loss: 342.0490 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "17/17 [==============================] - 5s 295ms/step - loss: 389.2728 - accuracy: 0.0914 - val_loss: 342.0490 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "17/17 [==============================] - 5s 295ms/step - loss: 367.0554 - accuracy: 0.0946 - val_loss: 342.0490 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "17/17 [==============================] - 5s 295ms/step - loss: 367.1106 - accuracy: 0.1125 - val_loss: 342.0490 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "17/17 [==============================] - 5s 294ms/step - loss: 371.0896 - accuracy: 0.1020 - val_loss: 342.0490 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "17/17 [==============================] - 5s 296ms/step - loss: 366.2518 - accuracy: 0.0960 - val_loss: 342.0490 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "17/17 [==============================] - 5s 295ms/step - loss: 374.8921 - accuracy: 0.0883 - val_loss: 342.0490 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "17/17 [==============================] - 5s 295ms/step - loss: 373.1736 - accuracy: 0.0960 - val_loss: 342.0490 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "17/17 [==============================] - 5s 295ms/step - loss: 358.5533 - accuracy: 0.1125 - val_loss: 342.0490 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "17/17 [==============================] - 5s 296ms/step - loss: 377.9987 - accuracy: 0.0919 - val_loss: 342.0490 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "17/17 [==============================] - 5s 295ms/step - loss: 366.4331 - accuracy: 0.0965 - val_loss: 342.0490 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "17/17 [==============================] - 5s 295ms/step - loss: 361.3579 - accuracy: 0.1139 - val_loss: 342.0490 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "17/17 [==============================] - 5s 296ms/step - loss: 371.7302 - accuracy: 0.0968 - val_loss: 342.0490 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "17/17 [==============================] - 5s 295ms/step - loss: 373.5296 - accuracy: 0.1015 - val_loss: 342.0490 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "17/17 [==============================] - 5s 295ms/step - loss: 386.8404 - accuracy: 0.0986 - val_loss: 342.0490 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "17/17 [==============================] - 5s 295ms/step - loss: 369.4853 - accuracy: 0.0972 - val_loss: 342.0490 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "17/17 [==============================] - 5s 295ms/step - loss: 375.8887 - accuracy: 0.0918 - val_loss: 342.0490 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "17/17 [==============================] - 5s 296ms/step - loss: 361.5725 - accuracy: 0.1025 - val_loss: 342.0490 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "17/17 [==============================] - 5s 295ms/step - loss: 361.8002 - accuracy: 0.0988 - val_loss: 342.0490 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "17/17 [==============================] - 5s 295ms/step - loss: 343.2481 - accuracy: 0.1032 - val_loss: 342.0490 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "17/17 [==============================] - 5s 295ms/step - loss: 366.2050 - accuracy: 0.1161 - val_loss: 342.0490 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "17/17 [==============================] - 5s 295ms/step - loss: 366.8522 - accuracy: 0.1161 - val_loss: 342.0490 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "17/17 [==============================] - 5s 295ms/step - loss: 379.1206 - accuracy: 0.0965 - val_loss: 342.0490 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../opticnet/opticnet_30epochs_834.84_images_True_newWeights_True_lastLayerOnly_rescale-symmetric_normalization/assets\n",
      "Test acc for opticnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.02451074 0.02513103 0.02467395 0.02634633]\n",
      "Training xception for 0.025% of train size (aka 2087 images) with pretrained: False and onlyLastLayersTrained: True...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      " 6/42 [===>..........................] - ETA: 19s - loss: 1.3862 - accuracy: 0.1056WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1195s vs `on_train_batch_begin` time: 0.1496s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1195s vs `on_train_batch_end` time: 0.1942s). Check your callbacks.\n",
      "42/42 [==============================] - 11s 199ms/step - loss: 1.3862 - accuracy: 0.1129 - val_loss: 1.3863 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "42/42 [==============================] - 5s 122ms/step - loss: 1.3862 - accuracy: 0.1096 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "42/42 [==============================] - 5s 122ms/step - loss: 1.3862 - accuracy: 0.1122 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "42/42 [==============================] - 5s 122ms/step - loss: 1.3862 - accuracy: 0.1108 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "42/42 [==============================] - 5s 123ms/step - loss: 1.3862 - accuracy: 0.1047 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "42/42 [==============================] - 5s 123ms/step - loss: 1.3862 - accuracy: 0.1016 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "42/42 [==============================] - 5s 123ms/step - loss: 1.3862 - accuracy: 0.1112 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "42/42 [==============================] - 5s 123ms/step - loss: 1.3862 - accuracy: 0.1103 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "42/42 [==============================] - 5s 123ms/step - loss: 1.3862 - accuracy: 0.1186 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "42/42 [==============================] - 5s 123ms/step - loss: 1.3862 - accuracy: 0.1110 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "42/42 [==============================] - 5s 123ms/step - loss: 1.3862 - accuracy: 0.1001 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "42/42 [==============================] - 5s 124ms/step - loss: 1.3862 - accuracy: 0.1014 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "42/42 [==============================] - 5s 124ms/step - loss: 1.3862 - accuracy: 0.1069 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "42/42 [==============================] - 5s 124ms/step - loss: 1.3862 - accuracy: 0.1009 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "42/42 [==============================] - 5s 124ms/step - loss: 1.3862 - accuracy: 0.1055 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "42/42 [==============================] - 5s 124ms/step - loss: 1.3862 - accuracy: 0.1118 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "42/42 [==============================] - 5s 124ms/step - loss: 1.3862 - accuracy: 0.1096 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "42/42 [==============================] - 5s 123ms/step - loss: 1.3862 - accuracy: 0.1066 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "42/42 [==============================] - 5s 123ms/step - loss: 1.3862 - accuracy: 0.1124 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "42/42 [==============================] - 5s 125ms/step - loss: 1.3862 - accuracy: 0.1096 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "42/42 [==============================] - 5s 124ms/step - loss: 1.3862 - accuracy: 0.1085 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "42/42 [==============================] - 5s 124ms/step - loss: 1.3862 - accuracy: 0.1034 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "42/42 [==============================] - 5s 124ms/step - loss: 1.3862 - accuracy: 0.1059 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "42/42 [==============================] - 5s 124ms/step - loss: 1.3862 - accuracy: 0.1060 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "42/42 [==============================] - 5s 124ms/step - loss: 1.3862 - accuracy: 0.1040 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "42/42 [==============================] - 5s 124ms/step - loss: 1.3862 - accuracy: 0.1033 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "42/42 [==============================] - 5s 124ms/step - loss: 1.3862 - accuracy: 0.1128 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "42/42 [==============================] - 5s 124ms/step - loss: 1.3862 - accuracy: 0.1035 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "42/42 [==============================] - 5s 124ms/step - loss: 1.3862 - accuracy: 0.1191 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "42/42 [==============================] - 5s 124ms/step - loss: 1.3862 - accuracy: 0.1191 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../xception/xception_30epochs_2087.1_images_True_newWeights_True_lastLayerOnly_rescale-symmetric_normalization/assets\n",
      "Test acc for xception: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training resnet for 0.025% of train size (aka 2087 images) with pretrained: False and onlyLastLayersTrained: True...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      " 6/42 [===>..........................] - ETA: 16s - loss: 1.3849 - accuracy: 0.2796WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0608s vs `on_train_batch_begin` time: 0.1498s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0608s vs `on_train_batch_end` time: 0.1900s). Check your callbacks.\n",
      "42/42 [==============================] - 11s 143ms/step - loss: 1.3851 - accuracy: 0.2727 - val_loss: 1.3859 - val_accuracy: 0.2812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "42/42 [==============================] - 2s 57ms/step - loss: 1.3852 - accuracy: 0.2732 - val_loss: 1.3859 - val_accuracy: 0.2812\n",
      "Epoch 3/30\n",
      "42/42 [==============================] - 2s 57ms/step - loss: 1.3850 - accuracy: 0.2677 - val_loss: 1.3859 - val_accuracy: 0.2812\n",
      "Epoch 4/30\n",
      "42/42 [==============================] - 2s 57ms/step - loss: 1.3849 - accuracy: 0.2855 - val_loss: 1.3859 - val_accuracy: 0.2812\n",
      "Epoch 5/30\n",
      "42/42 [==============================] - 2s 58ms/step - loss: 1.3852 - accuracy: 0.2684 - val_loss: 1.3859 - val_accuracy: 0.2812\n",
      "Epoch 6/30\n",
      "42/42 [==============================] - 2s 57ms/step - loss: 1.3852 - accuracy: 0.2558 - val_loss: 1.3859 - val_accuracy: 0.2812\n",
      "Epoch 7/30\n",
      "42/42 [==============================] - 2s 58ms/step - loss: 1.3850 - accuracy: 0.2749 - val_loss: 1.3859 - val_accuracy: 0.2812\n",
      "Epoch 8/30\n",
      "42/42 [==============================] - 2s 58ms/step - loss: 1.3855 - accuracy: 0.2488 - val_loss: 1.3859 - val_accuracy: 0.2812\n",
      "Epoch 9/30\n",
      "42/42 [==============================] - 2s 58ms/step - loss: 1.3848 - accuracy: 0.2808 - val_loss: 1.3859 - val_accuracy: 0.2812\n",
      "Epoch 10/30\n",
      "42/42 [==============================] - 2s 58ms/step - loss: 1.3852 - accuracy: 0.2707 - val_loss: 1.3859 - val_accuracy: 0.2812\n",
      "Epoch 11/30\n",
      "42/42 [==============================] - 2s 58ms/step - loss: 1.3852 - accuracy: 0.2519 - val_loss: 1.3859 - val_accuracy: 0.2812\n",
      "Epoch 12/30\n",
      "42/42 [==============================] - 2s 58ms/step - loss: 1.3853 - accuracy: 0.2627 - val_loss: 1.3859 - val_accuracy: 0.2812\n",
      "Epoch 13/30\n",
      "42/42 [==============================] - 2s 58ms/step - loss: 1.3849 - accuracy: 0.2732 - val_loss: 1.3859 - val_accuracy: 0.2812\n",
      "Epoch 14/30\n",
      "42/42 [==============================] - 2s 58ms/step - loss: 1.3851 - accuracy: 0.2767 - val_loss: 1.3859 - val_accuracy: 0.2812\n",
      "Epoch 15/30\n",
      "42/42 [==============================] - 2s 57ms/step - loss: 1.3851 - accuracy: 0.2494 - val_loss: 1.3859 - val_accuracy: 0.2812\n",
      "Epoch 16/30\n",
      "42/42 [==============================] - 2s 58ms/step - loss: 1.3849 - accuracy: 0.2690 - val_loss: 1.3859 - val_accuracy: 0.2812\n",
      "Epoch 17/30\n",
      "42/42 [==============================] - 2s 58ms/step - loss: 1.3851 - accuracy: 0.2637 - val_loss: 1.3859 - val_accuracy: 0.2812\n",
      "Epoch 18/30\n",
      "42/42 [==============================] - 2s 58ms/step - loss: 1.3850 - accuracy: 0.2631 - val_loss: 1.3859 - val_accuracy: 0.2812\n",
      "Epoch 19/30\n",
      "42/42 [==============================] - 2s 58ms/step - loss: 1.3849 - accuracy: 0.2707 - val_loss: 1.3859 - val_accuracy: 0.2812\n",
      "Epoch 20/30\n",
      "42/42 [==============================] - 2s 58ms/step - loss: 1.3849 - accuracy: 0.2724 - val_loss: 1.3859 - val_accuracy: 0.2812\n",
      "Epoch 21/30\n",
      "42/42 [==============================] - 2s 58ms/step - loss: 1.3850 - accuracy: 0.2770 - val_loss: 1.3859 - val_accuracy: 0.2812\n",
      "Epoch 22/30\n",
      "42/42 [==============================] - 2s 58ms/step - loss: 1.3851 - accuracy: 0.2615 - val_loss: 1.3859 - val_accuracy: 0.2812\n",
      "Epoch 23/30\n",
      "42/42 [==============================] - 2s 58ms/step - loss: 1.3849 - accuracy: 0.2813 - val_loss: 1.3859 - val_accuracy: 0.2812\n",
      "Epoch 24/30\n",
      "42/42 [==============================] - 2s 58ms/step - loss: 1.3849 - accuracy: 0.2731 - val_loss: 1.3859 - val_accuracy: 0.2812\n",
      "Epoch 25/30\n",
      "42/42 [==============================] - 2s 58ms/step - loss: 1.3848 - accuracy: 0.2751 - val_loss: 1.3859 - val_accuracy: 0.2812\n",
      "Epoch 26/30\n",
      "42/42 [==============================] - 2s 58ms/step - loss: 1.3851 - accuracy: 0.2710 - val_loss: 1.3859 - val_accuracy: 0.2812\n",
      "Epoch 27/30\n",
      "42/42 [==============================] - 2s 58ms/step - loss: 1.3853 - accuracy: 0.2492 - val_loss: 1.3859 - val_accuracy: 0.2812\n",
      "Epoch 28/30\n",
      "42/42 [==============================] - 2s 58ms/step - loss: 1.3852 - accuracy: 0.2708 - val_loss: 1.3859 - val_accuracy: 0.2812\n",
      "Epoch 29/30\n",
      "42/42 [==============================] - 2s 58ms/step - loss: 1.3851 - accuracy: 0.2689 - val_loss: 1.3859 - val_accuracy: 0.2812\n",
      "Epoch 30/30\n",
      "42/42 [==============================] - 2s 58ms/step - loss: 1.3849 - accuracy: 0.2874 - val_loss: 1.3859 - val_accuracy: 0.2812\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_2087.1_images_True_newWeights_True_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training opticnet for 0.025% of train size (aka 2087 images) with pretrained: False and onlyLastLayersTrained: True...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "42/42 [==============================] - 24s 417ms/step - loss: 800.2178 - accuracy: 0.1111 - val_loss: 598.1745 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "42/42 [==============================] - 12s 290ms/step - loss: 797.7320 - accuracy: 0.1033 - val_loss: 598.1745 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "42/42 [==============================] - 12s 290ms/step - loss: 795.9302 - accuracy: 0.1059 - val_loss: 598.1745 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "42/42 [==============================] - 12s 291ms/step - loss: 815.6170 - accuracy: 0.1034 - val_loss: 598.1745 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "42/42 [==============================] - 12s 291ms/step - loss: 784.8414 - accuracy: 0.1098 - val_loss: 598.1745 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "42/42 [==============================] - 12s 291ms/step - loss: 794.5942 - accuracy: 0.1155 - val_loss: 598.1745 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "42/42 [==============================] - 12s 291ms/step - loss: 797.9677 - accuracy: 0.1121 - val_loss: 598.1745 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "42/42 [==============================] - 12s 291ms/step - loss: 784.9846 - accuracy: 0.1142 - val_loss: 598.1745 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "42/42 [==============================] - 12s 291ms/step - loss: 781.3104 - accuracy: 0.1158 - val_loss: 598.1745 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "42/42 [==============================] - 12s 291ms/step - loss: 777.8545 - accuracy: 0.1126 - val_loss: 598.1745 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "42/42 [==============================] - 12s 291ms/step - loss: 780.3137 - accuracy: 0.1184 - val_loss: 598.1745 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "42/42 [==============================] - 12s 291ms/step - loss: 799.5142 - accuracy: 0.1070 - val_loss: 598.1745 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "42/42 [==============================] - 12s 291ms/step - loss: 816.7003 - accuracy: 0.1016 - val_loss: 598.1745 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "42/42 [==============================] - 12s 291ms/step - loss: 779.4422 - accuracy: 0.1117 - val_loss: 598.1745 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "42/42 [==============================] - 12s 292ms/step - loss: 772.9228 - accuracy: 0.1093 - val_loss: 598.1745 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "42/42 [==============================] - 12s 291ms/step - loss: 771.1817 - accuracy: 0.1139 - val_loss: 598.1745 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "42/42 [==============================] - 12s 291ms/step - loss: 788.0550 - accuracy: 0.1177 - val_loss: 598.1745 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "42/42 [==============================] - 12s 291ms/step - loss: 794.3386 - accuracy: 0.1035 - val_loss: 598.1745 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "42/42 [==============================] - 12s 291ms/step - loss: 810.7218 - accuracy: 0.1051 - val_loss: 598.1745 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "42/42 [==============================] - 12s 291ms/step - loss: 774.7671 - accuracy: 0.1050 - val_loss: 598.1745 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "42/42 [==============================] - 12s 292ms/step - loss: 779.4907 - accuracy: 0.1126 - val_loss: 598.1745 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "42/42 [==============================] - 12s 292ms/step - loss: 786.1434 - accuracy: 0.1236 - val_loss: 598.1745 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "42/42 [==============================] - 12s 292ms/step - loss: 819.9590 - accuracy: 0.1049 - val_loss: 598.1745 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "42/42 [==============================] - 12s 292ms/step - loss: 763.2260 - accuracy: 0.1285 - val_loss: 598.1745 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "42/42 [==============================] - 12s 291ms/step - loss: 800.8172 - accuracy: 0.1158 - val_loss: 598.1745 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "42/42 [==============================] - 12s 291ms/step - loss: 778.0788 - accuracy: 0.1217 - val_loss: 598.1745 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "42/42 [==============================] - 12s 292ms/step - loss: 797.5903 - accuracy: 0.1076 - val_loss: 598.1745 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "42/42 [==============================] - 12s 292ms/step - loss: 776.4825 - accuracy: 0.1161 - val_loss: 598.1745 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "42/42 [==============================] - 12s 292ms/step - loss: 797.0094 - accuracy: 0.1090 - val_loss: 598.1745 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "42/42 [==============================] - 12s 291ms/step - loss: 788.3577 - accuracy: 0.1122 - val_loss: 598.1745 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../opticnet/opticnet_30epochs_2087.1_images_True_newWeights_True_lastLayerOnly_rescale-symmetric_normalization/assets\n",
      "Test acc for opticnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.0498575  0.04993952 0.05172718 0.04839833]\n",
      "Training xception for 0.05% of train size (aka 4174 images) with pretrained: False and onlyLastLayersTrained: True...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      " 6/84 [=>............................] - ETA: 41s - loss: 1.3868 - accuracy: 0.0974WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1205s vs `on_train_batch_begin` time: 0.1468s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1205s vs `on_train_batch_end` time: 0.1968s). Check your callbacks.\n",
      "84/84 [==============================] - 16s 158ms/step - loss: 1.3867 - accuracy: 0.0990 - val_loss: 1.3863 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "84/84 [==============================] - 10s 120ms/step - loss: 1.3867 - accuracy: 0.1033 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "84/84 [==============================] - 10s 121ms/step - loss: 1.3867 - accuracy: 0.0987 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "84/84 [==============================] - 10s 122ms/step - loss: 1.3867 - accuracy: 0.0973 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "84/84 [==============================] - 10s 122ms/step - loss: 1.3867 - accuracy: 0.0950 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "84/84 [==============================] - 10s 122ms/step - loss: 1.3867 - accuracy: 0.0940 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "84/84 [==============================] - 10s 122ms/step - loss: 1.3867 - accuracy: 0.0947 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "84/84 [==============================] - 10s 123ms/step - loss: 1.3867 - accuracy: 0.0991 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "84/84 [==============================] - 10s 123ms/step - loss: 1.3867 - accuracy: 0.0995 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "84/84 [==============================] - 10s 123ms/step - loss: 1.3867 - accuracy: 0.0993 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "84/84 [==============================] - 10s 122ms/step - loss: 1.3867 - accuracy: 0.0965 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "84/84 [==============================] - 10s 123ms/step - loss: 1.3867 - accuracy: 0.0981 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "84/84 [==============================] - 10s 123ms/step - loss: 1.3867 - accuracy: 0.1003 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "84/84 [==============================] - 10s 123ms/step - loss: 1.3867 - accuracy: 0.0982 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "84/84 [==============================] - 10s 123ms/step - loss: 1.3867 - accuracy: 0.1002 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "84/84 [==============================] - 10s 123ms/step - loss: 1.3867 - accuracy: 0.1032 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "84/84 [==============================] - 10s 123ms/step - loss: 1.3867 - accuracy: 0.1064 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "84/84 [==============================] - 10s 123ms/step - loss: 1.3867 - accuracy: 0.0938 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "84/84 [==============================] - 10s 123ms/step - loss: 1.3867 - accuracy: 0.1004 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "84/84 [==============================] - 10s 123ms/step - loss: 1.3867 - accuracy: 0.1009 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "84/84 [==============================] - 10s 123ms/step - loss: 1.3867 - accuracy: 0.1031 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "84/84 [==============================] - 10s 123ms/step - loss: 1.3867 - accuracy: 0.1007 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "84/84 [==============================] - 10s 123ms/step - loss: 1.3867 - accuracy: 0.0948 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "84/84 [==============================] - 10s 123ms/step - loss: 1.3867 - accuracy: 0.1040 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "84/84 [==============================] - 10s 123ms/step - loss: 1.3867 - accuracy: 0.1071 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "84/84 [==============================] - 10s 123ms/step - loss: 1.3867 - accuracy: 0.1069 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "84/84 [==============================] - 10s 123ms/step - loss: 1.3867 - accuracy: 0.1021 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "84/84 [==============================] - 10s 123ms/step - loss: 1.3867 - accuracy: 0.0989 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "84/84 [==============================] - 10s 123ms/step - loss: 1.3867 - accuracy: 0.0998 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "84/84 [==============================] - 10s 123ms/step - loss: 1.3867 - accuracy: 0.0974 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../xception/xception_30epochs_4174.2_images_True_newWeights_True_lastLayerOnly_rescale-symmetric_normalization/assets\n",
      "Test acc for xception: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training resnet for 0.05% of train size (aka 4174 images) with pretrained: False and onlyLastLayersTrained: True...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      " 6/84 [=>............................] - ETA: 33s - loss: 1.3859 - accuracy: 0.1174WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0613s vs `on_train_batch_begin` time: 0.1381s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0613s vs `on_train_batch_end` time: 0.1670s). Check your callbacks.\n",
      "84/84 [==============================] - 12s 95ms/step - loss: 1.3848 - accuracy: 0.1397 - val_loss: 1.3872 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "84/84 [==============================] - 5s 56ms/step - loss: 1.3848 - accuracy: 0.1313 - val_loss: 1.3872 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "84/84 [==============================] - 5s 56ms/step - loss: 1.3845 - accuracy: 0.1373 - val_loss: 1.3872 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "84/84 [==============================] - 5s 56ms/step - loss: 1.3849 - accuracy: 0.1398 - val_loss: 1.3872 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "84/84 [==============================] - 5s 56ms/step - loss: 1.3849 - accuracy: 0.1373 - val_loss: 1.3872 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "84/84 [==============================] - 5s 56ms/step - loss: 1.3848 - accuracy: 0.1454 - val_loss: 1.3872 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "84/84 [==============================] - 5s 56ms/step - loss: 1.3847 - accuracy: 0.1421 - val_loss: 1.3872 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "84/84 [==============================] - 5s 56ms/step - loss: 1.3848 - accuracy: 0.1368 - val_loss: 1.3872 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "84/84 [==============================] - 5s 56ms/step - loss: 1.3849 - accuracy: 0.1404 - val_loss: 1.3872 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "84/84 [==============================] - 5s 57ms/step - loss: 1.3849 - accuracy: 0.1391 - val_loss: 1.3872 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "84/84 [==============================] - 5s 57ms/step - loss: 1.3847 - accuracy: 0.1387 - val_loss: 1.3872 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "84/84 [==============================] - 5s 56ms/step - loss: 1.3848 - accuracy: 0.1398 - val_loss: 1.3872 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "84/84 [==============================] - 5s 57ms/step - loss: 1.3845 - accuracy: 0.1472 - val_loss: 1.3872 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "84/84 [==============================] - 5s 56ms/step - loss: 1.3850 - accuracy: 0.1440 - val_loss: 1.3872 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "84/84 [==============================] - 5s 56ms/step - loss: 1.3852 - accuracy: 0.1303 - val_loss: 1.3872 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "84/84 [==============================] - 5s 57ms/step - loss: 1.3848 - accuracy: 0.1347 - val_loss: 1.3872 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "84/84 [==============================] - 5s 57ms/step - loss: 1.3850 - accuracy: 0.1256 - val_loss: 1.3872 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "84/84 [==============================] - 5s 57ms/step - loss: 1.3849 - accuracy: 0.1383 - val_loss: 1.3872 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "84/84 [==============================] - 5s 57ms/step - loss: 1.3844 - accuracy: 0.1488 - val_loss: 1.3872 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "84/84 [==============================] - 5s 56ms/step - loss: 1.3851 - accuracy: 0.1334 - val_loss: 1.3872 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "84/84 [==============================] - 5s 56ms/step - loss: 1.3846 - accuracy: 0.1435 - val_loss: 1.3872 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "84/84 [==============================] - 5s 57ms/step - loss: 1.3849 - accuracy: 0.1372 - val_loss: 1.3872 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "84/84 [==============================] - 5s 57ms/step - loss: 1.3845 - accuracy: 0.1518 - val_loss: 1.3872 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "84/84 [==============================] - 5s 57ms/step - loss: 1.3848 - accuracy: 0.1402 - val_loss: 1.3872 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "84/84 [==============================] - 5s 57ms/step - loss: 1.3853 - accuracy: 0.1250 - val_loss: 1.3872 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "84/84 [==============================] - 5s 57ms/step - loss: 1.3850 - accuracy: 0.1380 - val_loss: 1.3872 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "84/84 [==============================] - 5s 57ms/step - loss: 1.3848 - accuracy: 0.1344 - val_loss: 1.3872 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "84/84 [==============================] - 5s 57ms/step - loss: 1.3849 - accuracy: 0.1413 - val_loss: 1.3872 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "84/84 [==============================] - 5s 57ms/step - loss: 1.3847 - accuracy: 0.1408 - val_loss: 1.3872 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "84/84 [==============================] - 5s 57ms/step - loss: 1.3849 - accuracy: 0.1424 - val_loss: 1.3872 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_4174.2_images_True_newWeights_True_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training opticnet for 0.05% of train size (aka 4174 images) with pretrained: False and onlyLastLayersTrained: True...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "84/84 [==============================] - 34s 337ms/step - loss: 528.2696 - accuracy: 0.0885 - val_loss: 371.8175 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "84/84 [==============================] - 24s 287ms/step - loss: 525.3247 - accuracy: 0.0955 - val_loss: 371.8175 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "84/84 [==============================] - 24s 288ms/step - loss: 515.7721 - accuracy: 0.0989 - val_loss: 371.8175 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "84/84 [==============================] - 24s 288ms/step - loss: 523.7634 - accuracy: 0.0961 - val_loss: 371.8175 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "84/84 [==============================] - 24s 287ms/step - loss: 517.5023 - accuracy: 0.1044 - val_loss: 371.8175 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "84/84 [==============================] - 24s 288ms/step - loss: 516.6881 - accuracy: 0.1052 - val_loss: 371.8175 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "84/84 [==============================] - 24s 288ms/step - loss: 514.3872 - accuracy: 0.1069 - val_loss: 371.8175 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "84/84 [==============================] - 24s 288ms/step - loss: 517.3247 - accuracy: 0.1021 - val_loss: 371.8175 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "84/84 [==============================] - 24s 288ms/step - loss: 516.0630 - accuracy: 0.1018 - val_loss: 371.8175 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "84/84 [==============================] - 24s 288ms/step - loss: 516.9719 - accuracy: 0.1068 - val_loss: 371.8175 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "84/84 [==============================] - 24s 288ms/step - loss: 516.6149 - accuracy: 0.1009 - val_loss: 371.8175 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "84/84 [==============================] - 24s 288ms/step - loss: 522.4252 - accuracy: 0.0961 - val_loss: 371.8175 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "84/84 [==============================] - 24s 288ms/step - loss: 524.2045 - accuracy: 0.1059 - val_loss: 371.8175 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "84/84 [==============================] - 24s 288ms/step - loss: 521.6971 - accuracy: 0.1067 - val_loss: 371.8175 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "84/84 [==============================] - 24s 289ms/step - loss: 520.4094 - accuracy: 0.0979 - val_loss: 371.8175 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "84/84 [==============================] - 24s 289ms/step - loss: 524.1878 - accuracy: 0.0977 - val_loss: 371.8175 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "84/84 [==============================] - 24s 288ms/step - loss: 511.0848 - accuracy: 0.1100 - val_loss: 371.8175 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "84/84 [==============================] - 24s 288ms/step - loss: 524.6226 - accuracy: 0.1016 - val_loss: 371.8175 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "84/84 [==============================] - 24s 288ms/step - loss: 521.3901 - accuracy: 0.1037 - val_loss: 371.8175 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "84/84 [==============================] - 24s 288ms/step - loss: 530.7847 - accuracy: 0.0954 - val_loss: 371.8175 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "84/84 [==============================] - 24s 288ms/step - loss: 518.4502 - accuracy: 0.1057 - val_loss: 371.8175 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "84/84 [==============================] - 24s 288ms/step - loss: 518.7761 - accuracy: 0.1013 - val_loss: 371.8175 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "84/84 [==============================] - 24s 288ms/step - loss: 518.0058 - accuracy: 0.0969 - val_loss: 371.8175 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "84/84 [==============================] - 24s 288ms/step - loss: 520.2322 - accuracy: 0.1028 - val_loss: 371.8175 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "84/84 [==============================] - 24s 288ms/step - loss: 524.2224 - accuracy: 0.0984 - val_loss: 371.8175 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "84/84 [==============================] - 24s 288ms/step - loss: 518.6056 - accuracy: 0.1034 - val_loss: 371.8175 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "84/84 [==============================] - 24s 288ms/step - loss: 521.8329 - accuracy: 0.0996 - val_loss: 371.8175 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "84/84 [==============================] - 24s 288ms/step - loss: 514.2816 - accuracy: 0.0941 - val_loss: 371.8175 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "84/84 [==============================] - 24s 288ms/step - loss: 520.5556 - accuracy: 0.1017 - val_loss: 371.8175 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "84/84 [==============================] - 24s 288ms/step - loss: 518.2261 - accuracy: 0.1088 - val_loss: 371.8175 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../opticnet/opticnet_30epochs_4174.2_images_True_newWeights_True_lastLayerOnly_rescale-symmetric_normalization/assets\n",
      "Test acc for opticnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.07376021 0.07496304 0.07701798 0.07625348]\n",
      "Training xception for 0.075% of train size (aka 6261 images) with pretrained: False and onlyLastLayersTrained: True...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/126 [>.............................] - ETA: 1:06 - loss: 1.3863 - accuracy: 0.1058WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1191s vs `on_train_batch_begin` time: 0.1501s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1191s vs `on_train_batch_end` time: 0.2101s). Check your callbacks.\n",
      "126/126 [==============================] - 21s 146ms/step - loss: 1.3863 - accuracy: 0.1344 - val_loss: 1.3863 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "126/126 [==============================] - 15s 121ms/step - loss: 1.3863 - accuracy: 0.1444 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "126/126 [==============================] - 15s 121ms/step - loss: 1.3863 - accuracy: 0.1458 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "126/126 [==============================] - 15s 122ms/step - loss: 1.3863 - accuracy: 0.1421 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "126/126 [==============================] - 15s 122ms/step - loss: 1.3863 - accuracy: 0.1379 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "126/126 [==============================] - 15s 123ms/step - loss: 1.3863 - accuracy: 0.1366 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "126/126 [==============================] - 15s 122ms/step - loss: 1.3863 - accuracy: 0.1361 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "126/126 [==============================] - 15s 123ms/step - loss: 1.3863 - accuracy: 0.1343 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "126/126 [==============================] - 15s 123ms/step - loss: 1.3863 - accuracy: 0.1391 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "126/126 [==============================] - 15s 123ms/step - loss: 1.3863 - accuracy: 0.1398 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "126/126 [==============================] - 15s 123ms/step - loss: 1.3863 - accuracy: 0.1471 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "126/126 [==============================] - 15s 122ms/step - loss: 1.3863 - accuracy: 0.1453 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "126/126 [==============================] - 15s 122ms/step - loss: 1.3863 - accuracy: 0.1414 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "126/126 [==============================] - 15s 123ms/step - loss: 1.3863 - accuracy: 0.1424 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "126/126 [==============================] - 15s 123ms/step - loss: 1.3863 - accuracy: 0.1366 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "126/126 [==============================] - 15s 123ms/step - loss: 1.3863 - accuracy: 0.1414 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "126/126 [==============================] - 15s 123ms/step - loss: 1.3863 - accuracy: 0.1393 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "126/126 [==============================] - 15s 123ms/step - loss: 1.3863 - accuracy: 0.1412 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "126/126 [==============================] - 16s 123ms/step - loss: 1.3863 - accuracy: 0.1412 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "126/126 [==============================] - 16s 123ms/step - loss: 1.3863 - accuracy: 0.1373 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "126/126 [==============================] - 16s 123ms/step - loss: 1.3863 - accuracy: 0.1351 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "126/126 [==============================] - 15s 122ms/step - loss: 1.3863 - accuracy: 0.1397 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "126/126 [==============================] - 15s 123ms/step - loss: 1.3863 - accuracy: 0.1406 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "126/126 [==============================] - 15s 122ms/step - loss: 1.3863 - accuracy: 0.1416 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "126/126 [==============================] - 15s 122ms/step - loss: 1.3863 - accuracy: 0.1460 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "126/126 [==============================] - 15s 123ms/step - loss: 1.3863 - accuracy: 0.1403 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "126/126 [==============================] - 15s 122ms/step - loss: 1.3863 - accuracy: 0.1515 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "126/126 [==============================] - 15s 122ms/step - loss: 1.3863 - accuracy: 0.1366 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "126/126 [==============================] - 15s 122ms/step - loss: 1.3863 - accuracy: 0.1374 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "126/126 [==============================] - 15s 122ms/step - loss: 1.3863 - accuracy: 0.1387 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../xception/xception_30epochs_6261.3_images_True_newWeights_True_lastLayerOnly_rescale-symmetric_normalization/assets\n",
      "Test acc for xception: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training resnet for 0.075% of train size (aka 6261 images) with pretrained: False and onlyLastLayersTrained: True...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/126 [>.............................] - ETA: 47s - loss: 1.3856 - accuracy: 0.1381WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0580s vs `on_train_batch_begin` time: 0.1309s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0580s vs `on_train_batch_end` time: 0.1494s). Check your callbacks.\n",
      "126/126 [==============================] - 13s 80ms/step - loss: 1.3856 - accuracy: 0.1116 - val_loss: 1.3856 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "126/126 [==============================] - 7s 56ms/step - loss: 1.3854 - accuracy: 0.1070 - val_loss: 1.3856 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "126/126 [==============================] - 7s 56ms/step - loss: 1.3851 - accuracy: 0.1129 - val_loss: 1.3856 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "126/126 [==============================] - 7s 56ms/step - loss: 1.3857 - accuracy: 0.1092 - val_loss: 1.3856 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "126/126 [==============================] - 7s 56ms/step - loss: 1.3856 - accuracy: 0.1020 - val_loss: 1.3856 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "126/126 [==============================] - 7s 56ms/step - loss: 1.3854 - accuracy: 0.1084 - val_loss: 1.3856 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "126/126 [==============================] - 7s 56ms/step - loss: 1.3857 - accuracy: 0.1055 - val_loss: 1.3856 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "126/126 [==============================] - 7s 56ms/step - loss: 1.3852 - accuracy: 0.1189 - val_loss: 1.3856 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "126/126 [==============================] - 7s 56ms/step - loss: 1.3857 - accuracy: 0.1069 - val_loss: 1.3856 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "126/126 [==============================] - 7s 57ms/step - loss: 1.3854 - accuracy: 0.1142 - val_loss: 1.3856 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "126/126 [==============================] - 7s 56ms/step - loss: 1.3852 - accuracy: 0.1101 - val_loss: 1.3856 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "126/126 [==============================] - 7s 56ms/step - loss: 1.3856 - accuracy: 0.1055 - val_loss: 1.3856 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "126/126 [==============================] - 7s 57ms/step - loss: 1.3854 - accuracy: 0.1065 - val_loss: 1.3856 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "126/126 [==============================] - 7s 57ms/step - loss: 1.3854 - accuracy: 0.1134 - val_loss: 1.3856 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "126/126 [==============================] - 7s 57ms/step - loss: 1.3855 - accuracy: 0.1094 - val_loss: 1.3856 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "126/126 [==============================] - 7s 57ms/step - loss: 1.3851 - accuracy: 0.1165 - val_loss: 1.3856 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "126/126 [==============================] - 7s 57ms/step - loss: 1.3854 - accuracy: 0.1112 - val_loss: 1.3856 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "126/126 [==============================] - 7s 56ms/step - loss: 1.3855 - accuracy: 0.1109 - val_loss: 1.3856 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "126/126 [==============================] - 7s 57ms/step - loss: 1.3854 - accuracy: 0.1081 - val_loss: 1.3856 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "126/126 [==============================] - 7s 57ms/step - loss: 1.3855 - accuracy: 0.1095 - val_loss: 1.3856 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "126/126 [==============================] - 7s 57ms/step - loss: 1.3854 - accuracy: 0.1130 - val_loss: 1.3856 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "126/126 [==============================] - 7s 57ms/step - loss: 1.3851 - accuracy: 0.1199 - val_loss: 1.3856 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "126/126 [==============================] - 7s 57ms/step - loss: 1.3853 - accuracy: 0.1104 - val_loss: 1.3856 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "126/126 [==============================] - 7s 57ms/step - loss: 1.3852 - accuracy: 0.1114 - val_loss: 1.3856 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "126/126 [==============================] - 7s 57ms/step - loss: 1.3855 - accuracy: 0.1087 - val_loss: 1.3856 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "126/126 [==============================] - 7s 57ms/step - loss: 1.3856 - accuracy: 0.1074 - val_loss: 1.3856 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "126/126 [==============================] - 7s 57ms/step - loss: 1.3855 - accuracy: 0.1037 - val_loss: 1.3856 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "126/126 [==============================] - 7s 57ms/step - loss: 1.3855 - accuracy: 0.1201 - val_loss: 1.3856 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "126/126 [==============================] - 7s 57ms/step - loss: 1.3853 - accuracy: 0.1113 - val_loss: 1.3856 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "126/126 [==============================] - 7s 57ms/step - loss: 1.3854 - accuracy: 0.1099 - val_loss: 1.3856 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_6261.3_images_True_newWeights_True_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training opticnet for 0.075% of train size (aka 6261 images) with pretrained: False and onlyLastLayersTrained: True...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "126/126 [==============================] - 49s 324ms/step - loss: 165.2080 - accuracy: 0.4466 - val_loss: 210.8582 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "126/126 [==============================] - 36s 287ms/step - loss: 163.5122 - accuracy: 0.4510 - val_loss: 210.8582 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "126/126 [==============================] - 36s 287ms/step - loss: 168.7426 - accuracy: 0.4403 - val_loss: 210.8582 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "126/126 [==============================] - 36s 287ms/step - loss: 165.5040 - accuracy: 0.4464 - val_loss: 210.8582 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "126/126 [==============================] - 36s 287ms/step - loss: 166.0043 - accuracy: 0.4419 - val_loss: 210.8582 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "126/126 [==============================] - 36s 287ms/step - loss: 166.7475 - accuracy: 0.4416 - val_loss: 210.8582 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "126/126 [==============================] - 36s 287ms/step - loss: 165.0088 - accuracy: 0.4449 - val_loss: 210.8582 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "126/126 [==============================] - 36s 287ms/step - loss: 164.2088 - accuracy: 0.4469 - val_loss: 210.8582 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "126/126 [==============================] - 36s 287ms/step - loss: 164.9122 - accuracy: 0.4454 - val_loss: 210.8582 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "126/126 [==============================] - 36s 287ms/step - loss: 163.7453 - accuracy: 0.4499 - val_loss: 210.8582 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "126/126 [==============================] - 36s 287ms/step - loss: 166.3822 - accuracy: 0.4396 - val_loss: 210.8582 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "126/126 [==============================] - 36s 287ms/step - loss: 168.0210 - accuracy: 0.4369 - val_loss: 210.8582 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "126/126 [==============================] - 36s 287ms/step - loss: 165.6580 - accuracy: 0.4406 - val_loss: 210.8582 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "126/126 [==============================] - 36s 288ms/step - loss: 161.8779 - accuracy: 0.4535 - val_loss: 210.8582 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "126/126 [==============================] - 36s 287ms/step - loss: 163.7996 - accuracy: 0.4466 - val_loss: 210.8582 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "126/126 [==============================] - 36s 287ms/step - loss: 161.4386 - accuracy: 0.4537 - val_loss: 210.8582 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "126/126 [==============================] - 36s 287ms/step - loss: 163.8451 - accuracy: 0.4487 - val_loss: 210.8582 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "126/126 [==============================] - 36s 287ms/step - loss: 165.5759 - accuracy: 0.4435 - val_loss: 210.8582 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "126/126 [==============================] - 36s 287ms/step - loss: 161.7138 - accuracy: 0.4586 - val_loss: 210.8582 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "126/126 [==============================] - 36s 287ms/step - loss: 167.3366 - accuracy: 0.4389 - val_loss: 210.8582 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "126/126 [==============================] - 36s 287ms/step - loss: 160.2733 - accuracy: 0.4568 - val_loss: 210.8582 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "126/126 [==============================] - 36s 287ms/step - loss: 165.1141 - accuracy: 0.4502 - val_loss: 210.8582 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "126/126 [==============================] - 36s 287ms/step - loss: 161.1599 - accuracy: 0.4575 - val_loss: 210.8582 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "126/126 [==============================] - 36s 287ms/step - loss: 165.8132 - accuracy: 0.4389 - val_loss: 210.8582 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "126/126 [==============================] - 36s 287ms/step - loss: 165.6384 - accuracy: 0.4476 - val_loss: 210.8582 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "126/126 [==============================] - 36s 288ms/step - loss: 164.8324 - accuracy: 0.4455 - val_loss: 210.8582 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "126/126 [==============================] - 36s 287ms/step - loss: 164.5597 - accuracy: 0.4441 - val_loss: 210.8582 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "126/126 [==============================] - 36s 287ms/step - loss: 166.4534 - accuracy: 0.4429 - val_loss: 210.8582 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "126/126 [==============================] - 36s 287ms/step - loss: 166.4248 - accuracy: 0.4384 - val_loss: 210.8582 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "126/126 [==============================] - 36s 287ms/step - loss: 164.2025 - accuracy: 0.4490 - val_loss: 210.8582 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../opticnet/opticnet_30epochs_6261.3_images_True_newWeights_True_lastLayerOnly_rescale-symmetric_normalization/assets\n",
      "Test acc for opticnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.08835265 0.09025669 0.09111738 0.09238626]\n",
      "Training xception for 0.09% of train size (aka 7513 images) with pretrained: False and onlyLastLayersTrained: True...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/151 [>.............................] - ETA: 1:21 - loss: 1.3868 - accuracy: 0.1279WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1172s vs `on_train_batch_begin` time: 0.1463s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1172s vs `on_train_batch_end` time: 0.2231s). Check your callbacks.\n",
      "151/151 [==============================] - 24s 142ms/step - loss: 1.3868 - accuracy: 0.1399 - val_loss: 1.3863 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "151/151 [==============================] - 18s 122ms/step - loss: 1.3869 - accuracy: 0.1373 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "151/151 [==============================] - 19s 123ms/step - loss: 1.3869 - accuracy: 0.1362 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "151/151 [==============================] - 19s 123ms/step - loss: 1.3869 - accuracy: 0.1398 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "151/151 [==============================] - 19s 123ms/step - loss: 1.3869 - accuracy: 0.1371 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "151/151 [==============================] - 19s 123ms/step - loss: 1.3868 - accuracy: 0.1468 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "151/151 [==============================] - 19s 123ms/step - loss: 1.3869 - accuracy: 0.1396 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "151/151 [==============================] - 19s 123ms/step - loss: 1.3869 - accuracy: 0.1289 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "151/151 [==============================] - 19s 123ms/step - loss: 1.3869 - accuracy: 0.1384 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "151/151 [==============================] - 19s 123ms/step - loss: 1.3869 - accuracy: 0.1366 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "151/151 [==============================] - 19s 123ms/step - loss: 1.3869 - accuracy: 0.1326 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "151/151 [==============================] - 19s 123ms/step - loss: 1.3869 - accuracy: 0.1311 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "151/151 [==============================] - 19s 123ms/step - loss: 1.3869 - accuracy: 0.1378 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "151/151 [==============================] - 19s 123ms/step - loss: 1.3868 - accuracy: 0.1381 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "151/151 [==============================] - 19s 123ms/step - loss: 1.3869 - accuracy: 0.1273 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "151/151 [==============================] - 19s 123ms/step - loss: 1.3868 - accuracy: 0.1425 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "151/151 [==============================] - 19s 123ms/step - loss: 1.3869 - accuracy: 0.1411 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "151/151 [==============================] - 19s 123ms/step - loss: 1.3869 - accuracy: 0.1424 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "151/151 [==============================] - 19s 123ms/step - loss: 1.3869 - accuracy: 0.1372 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "151/151 [==============================] - 19s 123ms/step - loss: 1.3869 - accuracy: 0.1363 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "151/151 [==============================] - 19s 123ms/step - loss: 1.3869 - accuracy: 0.1375 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "151/151 [==============================] - 19s 123ms/step - loss: 1.3869 - accuracy: 0.1368 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "151/151 [==============================] - 19s 123ms/step - loss: 1.3869 - accuracy: 0.1317 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "151/151 [==============================] - 19s 124ms/step - loss: 1.3869 - accuracy: 0.1380 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "151/151 [==============================] - 19s 123ms/step - loss: 1.3869 - accuracy: 0.1378 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "151/151 [==============================] - 19s 123ms/step - loss: 1.3869 - accuracy: 0.1381 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "151/151 [==============================] - 19s 123ms/step - loss: 1.3869 - accuracy: 0.1376 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "151/151 [==============================] - 19s 123ms/step - loss: 1.3868 - accuracy: 0.1385 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "151/151 [==============================] - 19s 123ms/step - loss: 1.3869 - accuracy: 0.1383 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "151/151 [==============================] - 19s 123ms/step - loss: 1.3869 - accuracy: 0.1425 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../xception/xception_30epochs_7513.5599999999995_images_True_newWeights_True_lastLayerOnly_rescale-symmetric_normalization/assets\n",
      "Test acc for xception: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training resnet for 0.09% of train size (aka 7513 images) with pretrained: False and onlyLastLayersTrained: True...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/151 [>.............................] - ETA: 1:02 - loss: 1.3891 - accuracy: 0.2931WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0602s vs `on_train_batch_begin` time: 0.1504s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0602s vs `on_train_batch_end` time: 0.1573s). Check your callbacks.\n",
      "151/151 [==============================] - 15s 77ms/step - loss: 1.3876 - accuracy: 0.3094 - val_loss: 1.3876 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "151/151 [==============================] - 8s 56ms/step - loss: 1.3878 - accuracy: 0.3034 - val_loss: 1.3876 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "151/151 [==============================] - 9s 56ms/step - loss: 1.3877 - accuracy: 0.3108 - val_loss: 1.3876 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "151/151 [==============================] - 9s 56ms/step - loss: 1.3877 - accuracy: 0.3111 - val_loss: 1.3876 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "151/151 [==============================] - 9s 56ms/step - loss: 1.3878 - accuracy: 0.3065 - val_loss: 1.3876 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "151/151 [==============================] - 9s 56ms/step - loss: 1.3877 - accuracy: 0.3113 - val_loss: 1.3876 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "151/151 [==============================] - 9s 57ms/step - loss: 1.3877 - accuracy: 0.3056 - val_loss: 1.3876 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "151/151 [==============================] - 9s 57ms/step - loss: 1.3878 - accuracy: 0.3000 - val_loss: 1.3876 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "151/151 [==============================] - 9s 56ms/step - loss: 1.3881 - accuracy: 0.3015 - val_loss: 1.3876 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "151/151 [==============================] - 9s 57ms/step - loss: 1.3878 - accuracy: 0.3039 - val_loss: 1.3876 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "151/151 [==============================] - 9s 56ms/step - loss: 1.3874 - accuracy: 0.3133 - val_loss: 1.3876 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "151/151 [==============================] - 9s 57ms/step - loss: 1.3877 - accuracy: 0.3096 - val_loss: 1.3876 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "151/151 [==============================] - 9s 57ms/step - loss: 1.3875 - accuracy: 0.3133 - val_loss: 1.3876 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "151/151 [==============================] - 9s 57ms/step - loss: 1.3880 - accuracy: 0.2993 - val_loss: 1.3876 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "151/151 [==============================] - 9s 57ms/step - loss: 1.3878 - accuracy: 0.3039 - val_loss: 1.3876 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "151/151 [==============================] - 9s 57ms/step - loss: 1.3872 - accuracy: 0.3137 - val_loss: 1.3876 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "151/151 [==============================] - 9s 56ms/step - loss: 1.3875 - accuracy: 0.3139 - val_loss: 1.3876 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "151/151 [==============================] - 9s 57ms/step - loss: 1.3876 - accuracy: 0.3077 - val_loss: 1.3876 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "151/151 [==============================] - 9s 57ms/step - loss: 1.3872 - accuracy: 0.3178 - val_loss: 1.3876 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "151/151 [==============================] - 9s 57ms/step - loss: 1.3876 - accuracy: 0.3143 - val_loss: 1.3876 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "151/151 [==============================] - 9s 57ms/step - loss: 1.3874 - accuracy: 0.3109 - val_loss: 1.3876 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "151/151 [==============================] - 9s 57ms/step - loss: 1.3875 - accuracy: 0.3074 - val_loss: 1.3876 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "151/151 [==============================] - 9s 56ms/step - loss: 1.3875 - accuracy: 0.3062 - val_loss: 1.3876 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "151/151 [==============================] - 9s 57ms/step - loss: 1.3871 - accuracy: 0.3169 - val_loss: 1.3876 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "151/151 [==============================] - 9s 57ms/step - loss: 1.3878 - accuracy: 0.3080 - val_loss: 1.3876 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "151/151 [==============================] - 9s 57ms/step - loss: 1.3878 - accuracy: 0.3106 - val_loss: 1.3876 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "151/151 [==============================] - 9s 57ms/step - loss: 1.3876 - accuracy: 0.3087 - val_loss: 1.3876 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "151/151 [==============================] - 9s 57ms/step - loss: 1.3868 - accuracy: 0.3246 - val_loss: 1.3876 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "151/151 [==============================] - 9s 57ms/step - loss: 1.3874 - accuracy: 0.3116 - val_loss: 1.3876 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "151/151 [==============================] - 9s 57ms/step - loss: 1.3878 - accuracy: 0.3068 - val_loss: 1.3876 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_7513.5599999999995_images_True_newWeights_True_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training opticnet for 0.09% of train size (aka 7513 images) with pretrained: False and onlyLastLayersTrained: True...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "151/151 [==============================] - 56s 319ms/step - loss: 119.7713 - accuracy: 0.4364 - val_loss: 189.8557 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "151/151 [==============================] - 43s 286ms/step - loss: 116.1538 - accuracy: 0.4417 - val_loss: 189.8557 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "151/151 [==============================] - 43s 286ms/step - loss: 116.9944 - accuracy: 0.4428 - val_loss: 189.8557 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "151/151 [==============================] - 43s 286ms/step - loss: 116.0838 - accuracy: 0.4490 - val_loss: 189.8557 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "151/151 [==============================] - 43s 286ms/step - loss: 117.4296 - accuracy: 0.4470 - val_loss: 189.8557 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "151/151 [==============================] - 43s 286ms/step - loss: 113.8660 - accuracy: 0.4560 - val_loss: 189.8557 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "151/151 [==============================] - 43s 286ms/step - loss: 117.6355 - accuracy: 0.4419 - val_loss: 189.8557 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "151/151 [==============================] - 43s 287ms/step - loss: 115.8895 - accuracy: 0.4539 - val_loss: 189.8557 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "151/151 [==============================] - 43s 287ms/step - loss: 114.6420 - accuracy: 0.4481 - val_loss: 189.8557 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "151/151 [==============================] - 43s 286ms/step - loss: 115.6951 - accuracy: 0.4495 - val_loss: 189.8557 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "151/151 [==============================] - 43s 286ms/step - loss: 116.2084 - accuracy: 0.4512 - val_loss: 189.8557 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "151/151 [==============================] - 43s 287ms/step - loss: 115.0987 - accuracy: 0.4514 - val_loss: 189.8557 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "151/151 [==============================] - 43s 287ms/step - loss: 115.3257 - accuracy: 0.4475 - val_loss: 189.8557 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "151/151 [==============================] - 43s 286ms/step - loss: 116.8724 - accuracy: 0.4488 - val_loss: 189.8557 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "151/151 [==============================] - 43s 286ms/step - loss: 118.2331 - accuracy: 0.4502 - val_loss: 189.8557 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "151/151 [==============================] - 43s 286ms/step - loss: 117.8862 - accuracy: 0.4493 - val_loss: 189.8557 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "151/151 [==============================] - 43s 286ms/step - loss: 117.9775 - accuracy: 0.4522 - val_loss: 189.8557 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "151/151 [==============================] - 43s 286ms/step - loss: 113.3221 - accuracy: 0.4551 - val_loss: 189.8557 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "151/151 [==============================] - 43s 286ms/step - loss: 118.3521 - accuracy: 0.4446 - val_loss: 189.8557 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "151/151 [==============================] - 43s 286ms/step - loss: 117.5391 - accuracy: 0.4474 - val_loss: 189.8557 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "151/151 [==============================] - 43s 287ms/step - loss: 117.9833 - accuracy: 0.4477 - val_loss: 189.8557 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "151/151 [==============================] - 43s 287ms/step - loss: 114.7713 - accuracy: 0.4463 - val_loss: 189.8557 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "151/151 [==============================] - 43s 286ms/step - loss: 116.6659 - accuracy: 0.4477 - val_loss: 189.8557 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "151/151 [==============================] - 43s 286ms/step - loss: 116.2628 - accuracy: 0.4549 - val_loss: 189.8557 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "151/151 [==============================] - 43s 286ms/step - loss: 117.6267 - accuracy: 0.4399 - val_loss: 189.8557 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "151/151 [==============================] - 43s 287ms/step - loss: 119.5045 - accuracy: 0.4389 - val_loss: 189.8557 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "151/151 [==============================] - 43s 286ms/step - loss: 117.4009 - accuracy: 0.4489 - val_loss: 189.8557 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "151/151 [==============================] - 43s 287ms/step - loss: 119.1735 - accuracy: 0.4423 - val_loss: 189.8557 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "151/151 [==============================] - 43s 286ms/step - loss: 116.5292 - accuracy: 0.4526 - val_loss: 189.8557 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "151/151 [==============================] - 43s 287ms/step - loss: 114.7980 - accuracy: 0.4456 - val_loss: 189.8557 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../opticnet/opticnet_30epochs_7513.5599999999995_images_True_newWeights_True_lastLayerOnly_rescale-symmetric_normalization/assets\n",
      "Test acc for opticnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.09777693 0.10020159 0.10133944 0.10410864]\n",
      "Training xception for 0.1% of train size (aka 8348 images) with pretrained: False and onlyLastLayersTrained: True...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/167 [>.............................] - ETA: 1:36 - loss: 1.3856 - accuracy: 0.3178WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1180s vs `on_train_batch_begin` time: 0.1970s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1180s vs `on_train_batch_end` time: 0.2056s). Check your callbacks.\n",
      "167/167 [==============================] - 27s 143ms/step - loss: 1.3856 - accuracy: 0.3099 - val_loss: 1.3863 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "167/167 [==============================] - 20s 122ms/step - loss: 1.3856 - accuracy: 0.3072 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "167/167 [==============================] - 21s 123ms/step - loss: 1.3857 - accuracy: 0.2999 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "167/167 [==============================] - 21s 123ms/step - loss: 1.3857 - accuracy: 0.3015 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "167/167 [==============================] - 21s 123ms/step - loss: 1.3857 - accuracy: 0.3022 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "167/167 [==============================] - 21s 123ms/step - loss: 1.3856 - accuracy: 0.3208 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "167/167 [==============================] - 21s 124ms/step - loss: 1.3857 - accuracy: 0.3039 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "167/167 [==============================] - 21s 123ms/step - loss: 1.3856 - accuracy: 0.3104 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "167/167 [==============================] - 21s 124ms/step - loss: 1.3856 - accuracy: 0.3184 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "167/167 [==============================] - 21s 124ms/step - loss: 1.3857 - accuracy: 0.3062 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "167/167 [==============================] - 21s 124ms/step - loss: 1.3856 - accuracy: 0.3112 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "167/167 [==============================] - 21s 123ms/step - loss: 1.3856 - accuracy: 0.3158 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "167/167 [==============================] - 21s 124ms/step - loss: 1.3857 - accuracy: 0.3033 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "167/167 [==============================] - 21s 124ms/step - loss: 1.3857 - accuracy: 0.3056 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "167/167 [==============================] - 21s 124ms/step - loss: 1.3856 - accuracy: 0.3092 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "167/167 [==============================] - 21s 124ms/step - loss: 1.3856 - accuracy: 0.3098 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "167/167 [==============================] - 21s 124ms/step - loss: 1.3857 - accuracy: 0.3110 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "167/167 [==============================] - 21s 124ms/step - loss: 1.3857 - accuracy: 0.3058 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "167/167 [==============================] - 21s 124ms/step - loss: 1.3857 - accuracy: 0.3092 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "167/167 [==============================] - 21s 124ms/step - loss: 1.3857 - accuracy: 0.2970 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "167/167 [==============================] - 21s 124ms/step - loss: 1.3857 - accuracy: 0.2980 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "167/167 [==============================] - 21s 124ms/step - loss: 1.3856 - accuracy: 0.3097 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "167/167 [==============================] - 21s 124ms/step - loss: 1.3857 - accuracy: 0.3074 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "167/167 [==============================] - 21s 124ms/step - loss: 1.3857 - accuracy: 0.3036 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "167/167 [==============================] - 21s 124ms/step - loss: 1.3856 - accuracy: 0.3122 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "167/167 [==============================] - 21s 123ms/step - loss: 1.3857 - accuracy: 0.3082 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "167/167 [==============================] - 21s 123ms/step - loss: 1.3857 - accuracy: 0.3074 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "167/167 [==============================] - 21s 123ms/step - loss: 1.3856 - accuracy: 0.3126 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "167/167 [==============================] - 21s 124ms/step - loss: 1.3857 - accuracy: 0.3085 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "167/167 [==============================] - 21s 123ms/step - loss: 1.3857 - accuracy: 0.3024 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../xception/xception_30epochs_8348.4_images_True_newWeights_True_lastLayerOnly_rescale-symmetric_normalization/assets\n",
      "Test acc for xception: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training resnet for 0.1% of train size (aka 8348 images) with pretrained: False and onlyLastLayersTrained: True...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/167 [>.............................] - ETA: 1:13 - loss: 1.3807 - accuracy: 0.2425WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0594s vs `on_train_batch_begin` time: 0.1523s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0594s vs `on_train_batch_end` time: 0.1769s). Check your callbacks.\n",
      "167/167 [==============================] - 18s 77ms/step - loss: 1.3764 - accuracy: 0.3011 - val_loss: 1.3869 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "167/167 [==============================] - 9s 57ms/step - loss: 1.3762 - accuracy: 0.3068 - val_loss: 1.3869 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "167/167 [==============================] - 9s 57ms/step - loss: 1.3752 - accuracy: 0.3179 - val_loss: 1.3869 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "167/167 [==============================] - 9s 57ms/step - loss: 1.3762 - accuracy: 0.3046 - val_loss: 1.3869 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "167/167 [==============================] - 10s 57ms/step - loss: 1.3759 - accuracy: 0.3141 - val_loss: 1.3869 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "167/167 [==============================] - 10s 57ms/step - loss: 1.3758 - accuracy: 0.3136 - val_loss: 1.3869 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "167/167 [==============================] - 10s 57ms/step - loss: 1.3761 - accuracy: 0.3071 - val_loss: 1.3869 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "167/167 [==============================] - 10s 58ms/step - loss: 1.3761 - accuracy: 0.3066 - val_loss: 1.3869 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "167/167 [==============================] - 10s 57ms/step - loss: 1.3764 - accuracy: 0.3039 - val_loss: 1.3869 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "167/167 [==============================] - 10s 57ms/step - loss: 1.3759 - accuracy: 0.3109 - val_loss: 1.3869 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "167/167 [==============================] - 10s 57ms/step - loss: 1.3768 - accuracy: 0.2931 - val_loss: 1.3869 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "167/167 [==============================] - 10s 57ms/step - loss: 1.3758 - accuracy: 0.3107 - val_loss: 1.3869 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "167/167 [==============================] - 10s 57ms/step - loss: 1.3762 - accuracy: 0.3078 - val_loss: 1.3869 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "167/167 [==============================] - 10s 57ms/step - loss: 1.3765 - accuracy: 0.3077 - val_loss: 1.3869 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "167/167 [==============================] - 9s 57ms/step - loss: 1.3762 - accuracy: 0.3058 - val_loss: 1.3869 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "167/167 [==============================] - 10s 57ms/step - loss: 1.3762 - accuracy: 0.3031 - val_loss: 1.3869 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "167/167 [==============================] - 10s 57ms/step - loss: 1.3757 - accuracy: 0.3115 - val_loss: 1.3869 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "167/167 [==============================] - 10s 57ms/step - loss: 1.3760 - accuracy: 0.3095 - val_loss: 1.3869 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "167/167 [==============================] - 10s 57ms/step - loss: 1.3750 - accuracy: 0.3260 - val_loss: 1.3869 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "167/167 [==============================] - 10s 57ms/step - loss: 1.3761 - accuracy: 0.3079 - val_loss: 1.3869 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "167/167 [==============================] - 10s 57ms/step - loss: 1.3758 - accuracy: 0.3090 - val_loss: 1.3869 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "167/167 [==============================] - 10s 57ms/step - loss: 1.3764 - accuracy: 0.3039 - val_loss: 1.3869 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "167/167 [==============================] - 9s 57ms/step - loss: 1.3762 - accuracy: 0.3086 - val_loss: 1.3869 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "167/167 [==============================] - 10s 57ms/step - loss: 1.3758 - accuracy: 0.3072 - val_loss: 1.3869 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "167/167 [==============================] - 9s 57ms/step - loss: 1.3752 - accuracy: 0.3216 - val_loss: 1.3869 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "167/167 [==============================] - 10s 57ms/step - loss: 1.3760 - accuracy: 0.3057 - val_loss: 1.3869 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "167/167 [==============================] - 10s 57ms/step - loss: 1.3758 - accuracy: 0.3128 - val_loss: 1.3869 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "167/167 [==============================] - 10s 57ms/step - loss: 1.3761 - accuracy: 0.3030 - val_loss: 1.3869 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "167/167 [==============================] - 10s 57ms/step - loss: 1.3760 - accuracy: 0.3101 - val_loss: 1.3869 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "167/167 [==============================] - 10s 57ms/step - loss: 1.3760 - accuracy: 0.3090 - val_loss: 1.3869 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_8348.4_images_True_newWeights_True_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training opticnet for 0.1% of train size (aka 8348 images) with pretrained: False and onlyLastLayersTrained: True...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "167/167 [==============================] - 60s 318ms/step - loss: 52.1756 - accuracy: 0.4476 - val_loss: 75.0049 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "167/167 [==============================] - 48s 288ms/step - loss: 52.4909 - accuracy: 0.4383 - val_loss: 75.0049 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "167/167 [==============================] - 48s 289ms/step - loss: 52.0616 - accuracy: 0.4543 - val_loss: 75.0049 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "167/167 [==============================] - 48s 289ms/step - loss: 52.3765 - accuracy: 0.4519 - val_loss: 75.0049 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "167/167 [==============================] - 48s 288ms/step - loss: 52.7276 - accuracy: 0.4486 - val_loss: 75.0049 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "167/167 [==============================] - 48s 289ms/step - loss: 53.3784 - accuracy: 0.4427 - val_loss: 75.0049 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "167/167 [==============================] - 48s 289ms/step - loss: 53.1708 - accuracy: 0.4379 - val_loss: 75.0049 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "167/167 [==============================] - 48s 289ms/step - loss: 52.1122 - accuracy: 0.4505 - val_loss: 75.0049 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "167/167 [==============================] - 48s 289ms/step - loss: 51.6216 - accuracy: 0.4558 - val_loss: 75.0049 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "167/167 [==============================] - 48s 289ms/step - loss: 51.9568 - accuracy: 0.4496 - val_loss: 75.0049 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "167/167 [==============================] - 48s 289ms/step - loss: 53.3280 - accuracy: 0.4402 - val_loss: 75.0049 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "167/167 [==============================] - 48s 289ms/step - loss: 51.9628 - accuracy: 0.4502 - val_loss: 75.0049 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "167/167 [==============================] - 48s 289ms/step - loss: 53.2233 - accuracy: 0.4470 - val_loss: 75.0049 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "167/167 [==============================] - 48s 289ms/step - loss: 53.0457 - accuracy: 0.4417 - val_loss: 75.0049 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "167/167 [==============================] - 48s 289ms/step - loss: 53.2945 - accuracy: 0.4421 - val_loss: 75.0049 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "167/167 [==============================] - 48s 289ms/step - loss: 53.0854 - accuracy: 0.4470 - val_loss: 75.0049 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "167/167 [==============================] - 48s 289ms/step - loss: 51.9013 - accuracy: 0.4502 - val_loss: 75.0049 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "167/167 [==============================] - 48s 289ms/step - loss: 51.7412 - accuracy: 0.4547 - val_loss: 75.0049 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "167/167 [==============================] - 48s 288ms/step - loss: 52.8837 - accuracy: 0.4485 - val_loss: 75.0049 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "167/167 [==============================] - 48s 289ms/step - loss: 52.5364 - accuracy: 0.4425 - val_loss: 75.0049 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "167/167 [==============================] - 48s 289ms/step - loss: 52.5997 - accuracy: 0.4478 - val_loss: 75.0049 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "167/167 [==============================] - 48s 288ms/step - loss: 52.3747 - accuracy: 0.4518 - val_loss: 75.0049 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "167/167 [==============================] - 48s 289ms/step - loss: 53.3129 - accuracy: 0.4428 - val_loss: 75.0049 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "167/167 [==============================] - 48s 289ms/step - loss: 52.7893 - accuracy: 0.4503 - val_loss: 75.0049 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "167/167 [==============================] - 48s 289ms/step - loss: 53.0418 - accuracy: 0.4493 - val_loss: 75.0049 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "167/167 [==============================] - 48s 289ms/step - loss: 52.9485 - accuracy: 0.4384 - val_loss: 75.0049 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "167/167 [==============================] - 48s 289ms/step - loss: 53.0582 - accuracy: 0.4420 - val_loss: 75.0049 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "167/167 [==============================] - 48s 289ms/step - loss: 53.0953 - accuracy: 0.4470 - val_loss: 75.0049 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "167/167 [==============================] - 48s 289ms/step - loss: 52.1330 - accuracy: 0.4476 - val_loss: 75.0049 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "167/167 [==============================] - 48s 289ms/step - loss: 53.3043 - accuracy: 0.4407 - val_loss: 75.0049 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../opticnet/opticnet_30epochs_8348.4_images_True_newWeights_True_lastLayerOnly_rescale-symmetric_normalization/assets\n",
      "Test acc for opticnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.24943948 0.24918694 0.24735636 0.25870474]\n",
      "Training xception for 0.25% of train size (aka 20871 images) with pretrained: False and onlyLastLayersTrained: True...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/418 [..............................] - ETA: 4:04 - loss: 1.3869 - accuracy: 0.0770WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1243s vs `on_train_batch_begin` time: 0.1928s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1243s vs `on_train_batch_end` time: 0.1991s). Check your callbacks.\n",
      "418/418 [==============================] - 57s 129ms/step - loss: 1.3868 - accuracy: 0.1047 - val_loss: 1.3863 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "418/418 [==============================] - 51s 123ms/step - loss: 1.3868 - accuracy: 0.1112 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "418/418 [==============================] - 51s 123ms/step - loss: 1.3868 - accuracy: 0.1041 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "418/418 [==============================] - 52s 123ms/step - loss: 1.3868 - accuracy: 0.1060 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "418/418 [==============================] - 52s 123ms/step - loss: 1.3868 - accuracy: 0.1075 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "418/418 [==============================] - 52s 124ms/step - loss: 1.3868 - accuracy: 0.1056 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "418/418 [==============================] - 52s 124ms/step - loss: 1.3868 - accuracy: 0.1091 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "418/418 [==============================] - 51s 123ms/step - loss: 1.3868 - accuracy: 0.1069 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "418/418 [==============================] - 52s 124ms/step - loss: 1.3868 - accuracy: 0.1094 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "418/418 [==============================] - 52s 123ms/step - loss: 1.3868 - accuracy: 0.1087 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "418/418 [==============================] - 52s 123ms/step - loss: 1.3868 - accuracy: 0.1065 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "418/418 [==============================] - 52s 123ms/step - loss: 1.3868 - accuracy: 0.1063 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "418/418 [==============================] - 52s 124ms/step - loss: 1.3868 - accuracy: 0.1075 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "418/418 [==============================] - 52s 123ms/step - loss: 1.3868 - accuracy: 0.1086 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "418/418 [==============================] - 52s 123ms/step - loss: 1.3868 - accuracy: 0.1091 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "418/418 [==============================] - 52s 123ms/step - loss: 1.3868 - accuracy: 0.1072 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "418/418 [==============================] - 52s 123ms/step - loss: 1.3868 - accuracy: 0.1071 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "418/418 [==============================] - 52s 124ms/step - loss: 1.3868 - accuracy: 0.1075 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "418/418 [==============================] - 52s 124ms/step - loss: 1.3868 - accuracy: 0.1039 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "418/418 [==============================] - 52s 124ms/step - loss: 1.3868 - accuracy: 0.1052 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "418/418 [==============================] - 52s 124ms/step - loss: 1.3868 - accuracy: 0.1096 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "418/418 [==============================] - 52s 124ms/step - loss: 1.3868 - accuracy: 0.1067 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "418/418 [==============================] - 52s 123ms/step - loss: 1.3868 - accuracy: 0.1028 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "418/418 [==============================] - 52s 124ms/step - loss: 1.3868 - accuracy: 0.1087 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "418/418 [==============================] - 52s 123ms/step - loss: 1.3868 - accuracy: 0.1027 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "418/418 [==============================] - 52s 123ms/step - loss: 1.3868 - accuracy: 0.1099 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "418/418 [==============================] - 52s 123ms/step - loss: 1.3868 - accuracy: 0.1046 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "418/418 [==============================] - 52s 124ms/step - loss: 1.3868 - accuracy: 0.1086 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "418/418 [==============================] - 52s 124ms/step - loss: 1.3868 - accuracy: 0.1085 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "418/418 [==============================] - 52s 124ms/step - loss: 1.3868 - accuracy: 0.1060 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../xception/xception_30epochs_20871.0_images_True_newWeights_True_lastLayerOnly_rescale-symmetric_normalization/assets\n",
      "Test acc for xception: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training resnet for 0.25% of train size (aka 20871 images) with pretrained: False and onlyLastLayersTrained: True...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/418 [..............................] - ETA: 3:18 - loss: 1.3935 - accuracy: 0.0982WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0591s vs `on_train_batch_begin` time: 0.1900s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0591s vs `on_train_batch_end` time: 0.1616s). Check your callbacks.\n",
      "418/418 [==============================] - 30s 64ms/step - loss: 1.3927 - accuracy: 0.1055 - val_loss: 1.3857 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "418/418 [==============================] - 23s 56ms/step - loss: 1.3928 - accuracy: 0.1055 - val_loss: 1.3857 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "418/418 [==============================] - 24s 57ms/step - loss: 1.3927 - accuracy: 0.1070 - val_loss: 1.3857 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "418/418 [==============================] - 24s 57ms/step - loss: 1.3926 - accuracy: 0.1081 - val_loss: 1.3857 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "418/418 [==============================] - 24s 57ms/step - loss: 1.3926 - accuracy: 0.1099 - val_loss: 1.3857 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "418/418 [==============================] - 24s 57ms/step - loss: 1.3927 - accuracy: 0.1074 - val_loss: 1.3857 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "418/418 [==============================] - 24s 57ms/step - loss: 1.3928 - accuracy: 0.1045 - val_loss: 1.3857 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "418/418 [==============================] - 24s 57ms/step - loss: 1.3927 - accuracy: 0.1070 - val_loss: 1.3857 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "418/418 [==============================] - 24s 57ms/step - loss: 1.3926 - accuracy: 0.1066 - val_loss: 1.3857 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "418/418 [==============================] - 24s 57ms/step - loss: 1.3925 - accuracy: 0.1083 - val_loss: 1.3857 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "418/418 [==============================] - 24s 57ms/step - loss: 1.3925 - accuracy: 0.1093 - val_loss: 1.3857 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "418/418 [==============================] - 24s 58ms/step - loss: 1.3926 - accuracy: 0.1076 - val_loss: 1.3857 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "418/418 [==============================] - 24s 57ms/step - loss: 1.3923 - accuracy: 0.1130 - val_loss: 1.3857 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "418/418 [==============================] - 24s 57ms/step - loss: 1.3926 - accuracy: 0.1067 - val_loss: 1.3857 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "418/418 [==============================] - 24s 57ms/step - loss: 1.3927 - accuracy: 0.1066 - val_loss: 1.3857 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "418/418 [==============================] - 24s 57ms/step - loss: 1.3927 - accuracy: 0.1057 - val_loss: 1.3857 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "418/418 [==============================] - 24s 57ms/step - loss: 1.3925 - accuracy: 0.1088 - val_loss: 1.3857 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "418/418 [==============================] - 24s 57ms/step - loss: 1.3927 - accuracy: 0.1052 - val_loss: 1.3857 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "418/418 [==============================] - 24s 57ms/step - loss: 1.3928 - accuracy: 0.1056 - val_loss: 1.3857 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "418/418 [==============================] - 24s 57ms/step - loss: 1.3927 - accuracy: 0.1069 - val_loss: 1.3857 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "418/418 [==============================] - 24s 57ms/step - loss: 1.3927 - accuracy: 0.1054 - val_loss: 1.3857 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "418/418 [==============================] - 24s 57ms/step - loss: 1.3927 - accuracy: 0.1059 - val_loss: 1.3857 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "418/418 [==============================] - 24s 57ms/step - loss: 1.3930 - accuracy: 0.1013 - val_loss: 1.3857 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "418/418 [==============================] - 24s 57ms/step - loss: 1.3927 - accuracy: 0.1054 - val_loss: 1.3857 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "418/418 [==============================] - 24s 57ms/step - loss: 1.3927 - accuracy: 0.1052 - val_loss: 1.3857 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "418/418 [==============================] - 24s 57ms/step - loss: 1.3925 - accuracy: 0.1074 - val_loss: 1.3857 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "418/418 [==============================] - 24s 57ms/step - loss: 1.3926 - accuracy: 0.1069 - val_loss: 1.3857 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "418/418 [==============================] - 24s 57ms/step - loss: 1.3926 - accuracy: 0.1076 - val_loss: 1.3857 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "418/418 [==============================] - 24s 57ms/step - loss: 1.3925 - accuracy: 0.1090 - val_loss: 1.3857 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "418/418 [==============================] - 24s 57ms/step - loss: 1.3927 - accuracy: 0.1044 - val_loss: 1.3857 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_20871.0_images_True_newWeights_True_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training opticnet for 0.25% of train size (aka 20871 images) with pretrained: False and onlyLastLayersTrained: True...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "418/418 [==============================] - 132s 298ms/step - loss: 475.0571 - accuracy: 0.4436 - val_loss: 539.9960 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "418/418 [==============================] - 120s 287ms/step - loss: 474.6148 - accuracy: 0.4421 - val_loss: 539.9960 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "418/418 [==============================] - 120s 287ms/step - loss: 476.6080 - accuracy: 0.4442 - val_loss: 539.9960 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "418/418 [==============================] - 120s 287ms/step - loss: 479.7873 - accuracy: 0.4409 - val_loss: 539.9960 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "418/418 [==============================] - 120s 287ms/step - loss: 479.3366 - accuracy: 0.4434 - val_loss: 539.9960 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "418/418 [==============================] - 120s 287ms/step - loss: 475.9869 - accuracy: 0.4453 - val_loss: 539.9960 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "418/418 [==============================] - 120s 287ms/step - loss: 478.2924 - accuracy: 0.4411 - val_loss: 539.9960 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "418/418 [==============================] - 120s 287ms/step - loss: 474.7074 - accuracy: 0.4445 - val_loss: 539.9960 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "418/418 [==============================] - 120s 287ms/step - loss: 476.0468 - accuracy: 0.4436 - val_loss: 539.9960 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "418/418 [==============================] - 120s 287ms/step - loss: 477.9379 - accuracy: 0.4404 - val_loss: 539.9960 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "418/418 [==============================] - 120s 287ms/step - loss: 476.8721 - accuracy: 0.4466 - val_loss: 539.9960 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "418/418 [==============================] - 120s 287ms/step - loss: 476.7253 - accuracy: 0.4441 - val_loss: 539.9960 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "418/418 [==============================] - 120s 287ms/step - loss: 476.4207 - accuracy: 0.4429 - val_loss: 539.9960 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "418/418 [==============================] - 120s 287ms/step - loss: 476.9550 - accuracy: 0.4432 - val_loss: 539.9960 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "418/418 [==============================] - 120s 287ms/step - loss: 474.9072 - accuracy: 0.4464 - val_loss: 539.9960 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "418/418 [==============================] - 120s 287ms/step - loss: 471.7533 - accuracy: 0.4470 - val_loss: 539.9960 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "418/418 [==============================] - 120s 287ms/step - loss: 473.2515 - accuracy: 0.4454 - val_loss: 539.9960 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "418/418 [==============================] - 120s 287ms/step - loss: 475.7022 - accuracy: 0.4448 - val_loss: 539.9960 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "418/418 [==============================] - 121s 288ms/step - loss: 473.1767 - accuracy: 0.4456 - val_loss: 539.9960 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "418/418 [==============================] - 120s 287ms/step - loss: 477.1459 - accuracy: 0.4463 - val_loss: 539.9960 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "418/418 [==============================] - 120s 287ms/step - loss: 472.1489 - accuracy: 0.4438 - val_loss: 539.9960 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "418/418 [==============================] - 120s 287ms/step - loss: 481.1860 - accuracy: 0.4399 - val_loss: 539.9960 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "418/418 [==============================] - 120s 287ms/step - loss: 472.8944 - accuracy: 0.4480 - val_loss: 539.9960 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "418/418 [==============================] - 120s 287ms/step - loss: 474.1817 - accuracy: 0.4463 - val_loss: 539.9960 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "418/418 [==============================] - 120s 287ms/step - loss: 474.4184 - accuracy: 0.4445 - val_loss: 539.9960 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "418/418 [==============================] - 120s 287ms/step - loss: 476.5044 - accuracy: 0.4403 - val_loss: 539.9960 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "418/418 [==============================] - 120s 287ms/step - loss: 477.1061 - accuracy: 0.4440 - val_loss: 539.9960 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "418/418 [==============================] - 120s 287ms/step - loss: 476.1988 - accuracy: 0.4441 - val_loss: 539.9960 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "418/418 [==============================] - 120s 287ms/step - loss: 478.0980 - accuracy: 0.4419 - val_loss: 539.9960 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "418/418 [==============================] - 120s 288ms/step - loss: 476.8842 - accuracy: 0.4428 - val_loss: 539.9960 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../opticnet/opticnet_30epochs_20871.0_images_True_newWeights_True_lastLayerOnly_rescale-symmetric_normalization/assets\n",
      "Test acc for opticnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.40068402 0.39922053 0.39813183 0.4036676 ]\n",
      "Training xception for 0.4% of train size (aka 33393 images) with pretrained: False and onlyLastLayersTrained: True...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/668 [..............................] - ETA: 5:32 - loss: 1.3857 - accuracy: 0.3067WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1204s vs `on_train_batch_begin` time: 0.1329s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1204s vs `on_train_batch_end` time: 0.1856s). Check your callbacks.\n",
      "668/668 [==============================] - 87s 127ms/step - loss: 1.3857 - accuracy: 0.3146 - val_loss: 1.3863 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "668/668 [==============================] - 83s 124ms/step - loss: 1.3857 - accuracy: 0.3121 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "668/668 [==============================] - 83s 124ms/step - loss: 1.3857 - accuracy: 0.3126 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "668/668 [==============================] - 83s 124ms/step - loss: 1.3857 - accuracy: 0.3163 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "668/668 [==============================] - 83s 124ms/step - loss: 1.3857 - accuracy: 0.3162 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "668/668 [==============================] - 83s 124ms/step - loss: 1.3857 - accuracy: 0.3178 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "668/668 [==============================] - 83s 124ms/step - loss: 1.3857 - accuracy: 0.3171 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "668/668 [==============================] - 83s 124ms/step - loss: 1.3857 - accuracy: 0.3181 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "668/668 [==============================] - 83s 124ms/step - loss: 1.3857 - accuracy: 0.3120 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "668/668 [==============================] - 83s 124ms/step - loss: 1.3857 - accuracy: 0.3122 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "668/668 [==============================] - 83s 124ms/step - loss: 1.3857 - accuracy: 0.3142 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "668/668 [==============================] - 83s 124ms/step - loss: 1.3857 - accuracy: 0.3171 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "668/668 [==============================] - 83s 124ms/step - loss: 1.3857 - accuracy: 0.3111 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "668/668 [==============================] - 83s 124ms/step - loss: 1.3857 - accuracy: 0.3095 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "668/668 [==============================] - 83s 124ms/step - loss: 1.3857 - accuracy: 0.3160 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "668/668 [==============================] - 83s 124ms/step - loss: 1.3857 - accuracy: 0.3121 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "668/668 [==============================] - 83s 124ms/step - loss: 1.3857 - accuracy: 0.3168 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "668/668 [==============================] - 83s 124ms/step - loss: 1.3857 - accuracy: 0.3117 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "668/668 [==============================] - 83s 124ms/step - loss: 1.3857 - accuracy: 0.3152 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "668/668 [==============================] - 83s 124ms/step - loss: 1.3857 - accuracy: 0.3155 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "668/668 [==============================] - 83s 124ms/step - loss: 1.3857 - accuracy: 0.3167 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "668/668 [==============================] - 83s 124ms/step - loss: 1.3857 - accuracy: 0.3162 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "668/668 [==============================] - 83s 124ms/step - loss: 1.3857 - accuracy: 0.3138 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "668/668 [==============================] - 83s 124ms/step - loss: 1.3857 - accuracy: 0.3170 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "668/668 [==============================] - 83s 124ms/step - loss: 1.3857 - accuracy: 0.3179 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "668/668 [==============================] - 83s 124ms/step - loss: 1.3857 - accuracy: 0.3165 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "668/668 [==============================] - 83s 124ms/step - loss: 1.3857 - accuracy: 0.3151 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "668/668 [==============================] - 83s 124ms/step - loss: 1.3857 - accuracy: 0.3173 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "668/668 [==============================] - 83s 124ms/step - loss: 1.3857 - accuracy: 0.3163 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "668/668 [==============================] - 83s 124ms/step - loss: 1.3857 - accuracy: 0.3198 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../xception/xception_30epochs_33393.6_images_True_newWeights_True_lastLayerOnly_rescale-symmetric_normalization/assets\n",
      "Test acc for xception: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training resnet for 0.4% of train size (aka 33393 images) with pretrained: False and onlyLastLayersTrained: True...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/668 [..............................] - ETA: 5:12 - loss: 1.3907 - accuracy: 0.2940WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0617s vs `on_train_batch_begin` time: 0.1530s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0617s vs `on_train_batch_end` time: 0.1897s). Check your callbacks.\n",
      "668/668 [==============================] - 46s 62ms/step - loss: 1.3888 - accuracy: 0.3148 - val_loss: 1.3867 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "668/668 [==============================] - 38s 57ms/step - loss: 1.3889 - accuracy: 0.3111 - val_loss: 1.3867 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "668/668 [==============================] - 38s 57ms/step - loss: 1.3887 - accuracy: 0.3141 - val_loss: 1.3867 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "668/668 [==============================] - 38s 57ms/step - loss: 1.3887 - accuracy: 0.3141 - val_loss: 1.3867 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "668/668 [==============================] - 38s 57ms/step - loss: 1.3891 - accuracy: 0.3091 - val_loss: 1.3867 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "668/668 [==============================] - 38s 57ms/step - loss: 1.3889 - accuracy: 0.3117 - val_loss: 1.3867 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "668/668 [==============================] - 38s 57ms/step - loss: 1.3889 - accuracy: 0.3111 - val_loss: 1.3867 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "668/668 [==============================] - 38s 57ms/step - loss: 1.3889 - accuracy: 0.3143 - val_loss: 1.3867 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "668/668 [==============================] - 38s 57ms/step - loss: 1.3889 - accuracy: 0.3146 - val_loss: 1.3867 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "668/668 [==============================] - 39s 58ms/step - loss: 1.3888 - accuracy: 0.3151 - val_loss: 1.3867 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "668/668 [==============================] - 38s 57ms/step - loss: 1.3889 - accuracy: 0.3130 - val_loss: 1.3867 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "668/668 [==============================] - 38s 57ms/step - loss: 1.3888 - accuracy: 0.3137 - val_loss: 1.3867 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "668/668 [==============================] - 38s 57ms/step - loss: 1.3889 - accuracy: 0.3144 - val_loss: 1.3867 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "668/668 [==============================] - 38s 57ms/step - loss: 1.3887 - accuracy: 0.3175 - val_loss: 1.3867 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "668/668 [==============================] - 38s 57ms/step - loss: 1.3888 - accuracy: 0.3154 - val_loss: 1.3867 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "668/668 [==============================] - 38s 57ms/step - loss: 1.3888 - accuracy: 0.3178 - val_loss: 1.3867 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "668/668 [==============================] - 38s 57ms/step - loss: 1.3887 - accuracy: 0.3122 - val_loss: 1.3867 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "668/668 [==============================] - 38s 57ms/step - loss: 1.3888 - accuracy: 0.3150 - val_loss: 1.3867 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "668/668 [==============================] - 38s 57ms/step - loss: 1.3888 - accuracy: 0.3128 - val_loss: 1.3867 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "668/668 [==============================] - 38s 57ms/step - loss: 1.3891 - accuracy: 0.3074 - val_loss: 1.3867 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "668/668 [==============================] - 38s 57ms/step - loss: 1.3889 - accuracy: 0.3109 - val_loss: 1.3867 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "668/668 [==============================] - 38s 57ms/step - loss: 1.3886 - accuracy: 0.3181 - val_loss: 1.3867 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "668/668 [==============================] - 38s 57ms/step - loss: 1.3887 - accuracy: 0.3155 - val_loss: 1.3867 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "668/668 [==============================] - 38s 57ms/step - loss: 1.3887 - accuracy: 0.3172 - val_loss: 1.3867 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "668/668 [==============================] - 38s 57ms/step - loss: 1.3886 - accuracy: 0.3164 - val_loss: 1.3867 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "668/668 [==============================] - 38s 57ms/step - loss: 1.3889 - accuracy: 0.3137 - val_loss: 1.3867 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "668/668 [==============================] - 38s 57ms/step - loss: 1.3888 - accuracy: 0.3148 - val_loss: 1.3867 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "668/668 [==============================] - 38s 57ms/step - loss: 1.3884 - accuracy: 0.3215 - val_loss: 1.3867 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "668/668 [==============================] - 38s 57ms/step - loss: 1.3887 - accuracy: 0.3170 - val_loss: 1.3867 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "668/668 [==============================] - 38s 57ms/step - loss: 1.3890 - accuracy: 0.3120 - val_loss: 1.3867 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_33393.6_images_True_newWeights_True_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training opticnet for 0.4% of train size (aka 33393 images) with pretrained: False and onlyLastLayersTrained: True...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "668/668 [==============================] - 204s 296ms/step - loss: 489.6967 - accuracy: 0.1055 - val_loss: 363.7084 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "668/668 [==============================] - 193s 289ms/step - loss: 488.2666 - accuracy: 0.1057 - val_loss: 363.7084 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "668/668 [==============================] - 193s 288ms/step - loss: 490.0123 - accuracy: 0.1048 - val_loss: 363.7084 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "668/668 [==============================] - 192s 288ms/step - loss: 489.4920 - accuracy: 0.1026 - val_loss: 363.7084 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "668/668 [==============================] - 193s 288ms/step - loss: 492.0346 - accuracy: 0.1016 - val_loss: 363.7084 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "668/668 [==============================] - 193s 288ms/step - loss: 494.9440 - accuracy: 0.1011 - val_loss: 363.7084 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "668/668 [==============================] - 193s 289ms/step - loss: 491.6552 - accuracy: 0.1066 - val_loss: 363.7084 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "668/668 [==============================] - 193s 288ms/step - loss: 490.7669 - accuracy: 0.1037 - val_loss: 363.7084 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "668/668 [==============================] - 193s 288ms/step - loss: 487.0419 - accuracy: 0.1050 - val_loss: 363.7084 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "668/668 [==============================] - 193s 288ms/step - loss: 490.6289 - accuracy: 0.1034 - val_loss: 363.7084 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "668/668 [==============================] - 193s 288ms/step - loss: 490.4380 - accuracy: 0.1048 - val_loss: 363.7084 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "668/668 [==============================] - 193s 288ms/step - loss: 489.1909 - accuracy: 0.1031 - val_loss: 363.7084 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "668/668 [==============================] - 193s 289ms/step - loss: 489.4544 - accuracy: 0.1029 - val_loss: 363.7084 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "668/668 [==============================] - 193s 289ms/step - loss: 488.5707 - accuracy: 0.1066 - val_loss: 363.7084 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "668/668 [==============================] - 193s 288ms/step - loss: 494.5804 - accuracy: 0.1034 - val_loss: 363.7084 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "668/668 [==============================] - 193s 289ms/step - loss: 489.5162 - accuracy: 0.1043 - val_loss: 363.7084 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "668/668 [==============================] - 192s 288ms/step - loss: 490.3367 - accuracy: 0.1037 - val_loss: 363.7084 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "668/668 [==============================] - 193s 289ms/step - loss: 492.2997 - accuracy: 0.1054 - val_loss: 363.7084 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "668/668 [==============================] - 193s 289ms/step - loss: 488.1151 - accuracy: 0.1017 - val_loss: 363.7084 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "668/668 [==============================] - 193s 288ms/step - loss: 489.6357 - accuracy: 0.1042 - val_loss: 363.7084 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "668/668 [==============================] - 193s 288ms/step - loss: 489.7418 - accuracy: 0.1045 - val_loss: 363.7084 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "668/668 [==============================] - 193s 288ms/step - loss: 488.8564 - accuracy: 0.1009 - val_loss: 363.7084 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "668/668 [==============================] - 193s 288ms/step - loss: 485.1662 - accuracy: 0.1053 - val_loss: 363.7084 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "668/668 [==============================] - 193s 289ms/step - loss: 489.8955 - accuracy: 0.1047 - val_loss: 363.7084 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "668/668 [==============================] - 193s 289ms/step - loss: 491.9154 - accuracy: 0.1038 - val_loss: 363.7084 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "668/668 [==============================] - 193s 289ms/step - loss: 493.4603 - accuracy: 0.1031 - val_loss: 363.7084 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "668/668 [==============================] - 193s 289ms/step - loss: 490.3198 - accuracy: 0.1040 - val_loss: 363.7084 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "668/668 [==============================] - 193s 289ms/step - loss: 489.0566 - accuracy: 0.1038 - val_loss: 363.7084 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "668/668 [==============================] - 193s 288ms/step - loss: 493.7338 - accuracy: 0.1019 - val_loss: 363.7084 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "668/668 [==============================] - 193s 288ms/step - loss: 489.2674 - accuracy: 0.1069 - val_loss: 363.7084 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../opticnet/opticnet_30epochs_33393.6_images_True_newWeights_True_lastLayerOnly_rescale-symmetric_normalization/assets\n",
      "Test acc for opticnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.49766293 0.4985889  0.50608037 0.50522284]\n",
      "Training xception for 0.5% of train size (aka 41742 images) with pretrained: False and onlyLastLayersTrained: True...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/835 [..............................] - ETA: 8:24 - loss: 1.3859 - accuracy: 0.4057 WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1228s vs `on_train_batch_begin` time: 0.1855s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1228s vs `on_train_batch_end` time: 0.2198s). Check your callbacks.\n",
      "835/835 [==============================] - 109s 127ms/step - loss: 1.3857 - accuracy: 0.4395 - val_loss: 1.3863 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "835/835 [==============================] - 104s 125ms/step - loss: 1.3857 - accuracy: 0.4463 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "835/835 [==============================] - 104s 125ms/step - loss: 1.3857 - accuracy: 0.4421 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "835/835 [==============================] - 104s 125ms/step - loss: 1.3857 - accuracy: 0.4437 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "835/835 [==============================] - 104s 125ms/step - loss: 1.3857 - accuracy: 0.4447 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "835/835 [==============================] - 104s 125ms/step - loss: 1.3857 - accuracy: 0.4456 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "835/835 [==============================] - 104s 125ms/step - loss: 1.3857 - accuracy: 0.4416 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "835/835 [==============================] - 104s 125ms/step - loss: 1.3857 - accuracy: 0.4449 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "835/835 [==============================] - 104s 125ms/step - loss: 1.3857 - accuracy: 0.4458 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "835/835 [==============================] - 104s 125ms/step - loss: 1.3857 - accuracy: 0.4432 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "835/835 [==============================] - 104s 125ms/step - loss: 1.3857 - accuracy: 0.4434 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "835/835 [==============================] - 104s 125ms/step - loss: 1.3857 - accuracy: 0.4457 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "835/835 [==============================] - 104s 125ms/step - loss: 1.3857 - accuracy: 0.4448 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "835/835 [==============================] - 104s 125ms/step - loss: 1.3857 - accuracy: 0.4414 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "835/835 [==============================] - 104s 125ms/step - loss: 1.3857 - accuracy: 0.4462 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "835/835 [==============================] - 104s 125ms/step - loss: 1.3857 - accuracy: 0.4413 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "835/835 [==============================] - 104s 124ms/step - loss: 1.3857 - accuracy: 0.4438 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "835/835 [==============================] - 104s 125ms/step - loss: 1.3857 - accuracy: 0.4474 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "835/835 [==============================] - 104s 125ms/step - loss: 1.3857 - accuracy: 0.4451 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "835/835 [==============================] - 104s 125ms/step - loss: 1.3857 - accuracy: 0.4435 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "835/835 [==============================] - 104s 125ms/step - loss: 1.3857 - accuracy: 0.4457 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "835/835 [==============================] - 104s 125ms/step - loss: 1.3857 - accuracy: 0.4432 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "835/835 [==============================] - 104s 125ms/step - loss: 1.3857 - accuracy: 0.4421 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "835/835 [==============================] - 104s 125ms/step - loss: 1.3857 - accuracy: 0.4467 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "835/835 [==============================] - 104s 125ms/step - loss: 1.3857 - accuracy: 0.4442 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "835/835 [==============================] - 104s 125ms/step - loss: 1.3857 - accuracy: 0.4454 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "835/835 [==============================] - 104s 125ms/step - loss: 1.3857 - accuracy: 0.4392 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "835/835 [==============================] - 104s 125ms/step - loss: 1.3857 - accuracy: 0.4428 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "835/835 [==============================] - 104s 125ms/step - loss: 1.3857 - accuracy: 0.4444 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "835/835 [==============================] - 104s 125ms/step - loss: 1.3857 - accuracy: 0.4457 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../xception/xception_30epochs_41742.0_images_True_newWeights_True_lastLayerOnly_rescale-symmetric_normalization/assets\n",
      "Test acc for xception: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training resnet for 0.5% of train size (aka 41742 images) with pretrained: False and onlyLastLayersTrained: True...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/835 [..............................] - ETA: 6:36 - loss: 1.3857 - accuracy: 0.3033WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0607s vs `on_train_batch_begin` time: 0.1872s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0607s vs `on_train_batch_end` time: 0.1611s). Check your callbacks.\n",
      "835/835 [==============================] - 54s 61ms/step - loss: 1.3857 - accuracy: 0.3297 - val_loss: 1.3857 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "835/835 [==============================] - 48s 57ms/step - loss: 1.3855 - accuracy: 0.3252 - val_loss: 1.3857 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "835/835 [==============================] - 48s 57ms/step - loss: 1.3854 - accuracy: 0.3292 - val_loss: 1.3857 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "835/835 [==============================] - 48s 57ms/step - loss: 1.3855 - accuracy: 0.3293 - val_loss: 1.3857 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "835/835 [==============================] - 48s 57ms/step - loss: 1.3855 - accuracy: 0.3268 - val_loss: 1.3857 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "835/835 [==============================] - 48s 57ms/step - loss: 1.3854 - accuracy: 0.3302 - val_loss: 1.3857 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "835/835 [==============================] - 48s 57ms/step - loss: 1.3854 - accuracy: 0.3287 - val_loss: 1.3857 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "835/835 [==============================] - 48s 57ms/step - loss: 1.3853 - accuracy: 0.3307 - val_loss: 1.3857 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "835/835 [==============================] - 48s 57ms/step - loss: 1.3855 - accuracy: 0.3290 - val_loss: 1.3857 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "835/835 [==============================] - 48s 57ms/step - loss: 1.3854 - accuracy: 0.3318 - val_loss: 1.3857 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "835/835 [==============================] - 48s 57ms/step - loss: 1.3854 - accuracy: 0.3295 - val_loss: 1.3857 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "835/835 [==============================] - 48s 57ms/step - loss: 1.3856 - accuracy: 0.3269 - val_loss: 1.3857 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "835/835 [==============================] - 48s 58ms/step - loss: 1.3852 - accuracy: 0.3332 - val_loss: 1.3857 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "835/835 [==============================] - 48s 58ms/step - loss: 1.3855 - accuracy: 0.3281 - val_loss: 1.3857 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "835/835 [==============================] - 48s 57ms/step - loss: 1.3854 - accuracy: 0.3280 - val_loss: 1.3857 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "835/835 [==============================] - 48s 57ms/step - loss: 1.3854 - accuracy: 0.3286 - val_loss: 1.3857 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "835/835 [==============================] - 48s 57ms/step - loss: 1.3854 - accuracy: 0.3267 - val_loss: 1.3857 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "835/835 [==============================] - 48s 57ms/step - loss: 1.3857 - accuracy: 0.3279 - val_loss: 1.3857 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "835/835 [==============================] - 48s 57ms/step - loss: 1.3855 - accuracy: 0.3293 - val_loss: 1.3857 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "835/835 [==============================] - 48s 57ms/step - loss: 1.3855 - accuracy: 0.3259 - val_loss: 1.3857 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "835/835 [==============================] - 48s 57ms/step - loss: 1.3855 - accuracy: 0.3275 - val_loss: 1.3857 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "835/835 [==============================] - 48s 57ms/step - loss: 1.3854 - accuracy: 0.3303 - val_loss: 1.3857 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "835/835 [==============================] - 48s 57ms/step - loss: 1.3854 - accuracy: 0.3282 - val_loss: 1.3857 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "835/835 [==============================] - 48s 58ms/step - loss: 1.3853 - accuracy: 0.3296 - val_loss: 1.3857 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "835/835 [==============================] - 48s 58ms/step - loss: 1.3856 - accuracy: 0.3239 - val_loss: 1.3857 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "835/835 [==============================] - 48s 57ms/step - loss: 1.3855 - accuracy: 0.3284 - val_loss: 1.3857 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "835/835 [==============================] - 48s 57ms/step - loss: 1.3855 - accuracy: 0.3298 - val_loss: 1.3857 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "835/835 [==============================] - 48s 57ms/step - loss: 1.3856 - accuracy: 0.3275 - val_loss: 1.3857 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "835/835 [==============================] - 48s 57ms/step - loss: 1.3856 - accuracy: 0.3273 - val_loss: 1.3857 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "835/835 [==============================] - 48s 57ms/step - loss: 1.3854 - accuracy: 0.3276 - val_loss: 1.3857 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_41742.0_images_True_newWeights_True_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training opticnet for 0.5% of train size (aka 41742 images) with pretrained: False and onlyLastLayersTrained: True...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "835/835 [==============================] - 251s 294ms/step - loss: 135.6091 - accuracy: 0.1363 - val_loss: 101.0337 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "835/835 [==============================] - 241s 289ms/step - loss: 135.5489 - accuracy: 0.1396 - val_loss: 101.0337 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "835/835 [==============================] - 241s 288ms/step - loss: 135.1419 - accuracy: 0.1404 - val_loss: 101.0337 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "835/835 [==============================] - 241s 289ms/step - loss: 135.2550 - accuracy: 0.1390 - val_loss: 101.0337 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "835/835 [==============================] - 241s 289ms/step - loss: 135.3358 - accuracy: 0.1374 - val_loss: 101.0337 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "835/835 [==============================] - 241s 289ms/step - loss: 135.1899 - accuracy: 0.1370 - val_loss: 101.0337 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "835/835 [==============================] - 241s 289ms/step - loss: 135.7783 - accuracy: 0.1377 - val_loss: 101.0337 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "835/835 [==============================] - 241s 288ms/step - loss: 135.9630 - accuracy: 0.1356 - val_loss: 101.0337 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "835/835 [==============================] - 241s 289ms/step - loss: 135.1654 - accuracy: 0.1399 - val_loss: 101.0337 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "835/835 [==============================] - 241s 288ms/step - loss: 136.0487 - accuracy: 0.1373 - val_loss: 101.0337 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "835/835 [==============================] - 241s 289ms/step - loss: 135.3073 - accuracy: 0.1382 - val_loss: 101.0337 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "835/835 [==============================] - 241s 288ms/step - loss: 136.1825 - accuracy: 0.1367 - val_loss: 101.0337 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "835/835 [==============================] - 240s 288ms/step - loss: 135.8479 - accuracy: 0.1381 - val_loss: 101.0337 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "835/835 [==============================] - 240s 288ms/step - loss: 135.4706 - accuracy: 0.1369 - val_loss: 101.0337 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "835/835 [==============================] - 240s 288ms/step - loss: 134.9700 - accuracy: 0.1387 - val_loss: 101.0337 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "835/835 [==============================] - 240s 288ms/step - loss: 135.6515 - accuracy: 0.1370 - val_loss: 101.0337 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "835/835 [==============================] - 241s 288ms/step - loss: 136.1517 - accuracy: 0.1369 - val_loss: 101.0337 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "835/835 [==============================] - 241s 288ms/step - loss: 135.3144 - accuracy: 0.1377 - val_loss: 101.0337 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "835/835 [==============================] - 240s 288ms/step - loss: 136.1405 - accuracy: 0.1403 - val_loss: 101.0337 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "835/835 [==============================] - 240s 288ms/step - loss: 135.8736 - accuracy: 0.1398 - val_loss: 101.0337 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "835/835 [==============================] - 240s 288ms/step - loss: 135.5971 - accuracy: 0.1382 - val_loss: 101.0337 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "835/835 [==============================] - 240s 288ms/step - loss: 136.0129 - accuracy: 0.1361 - val_loss: 101.0337 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "835/835 [==============================] - 241s 288ms/step - loss: 136.2421 - accuracy: 0.1368 - val_loss: 101.0337 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "835/835 [==============================] - 240s 288ms/step - loss: 135.6849 - accuracy: 0.1363 - val_loss: 101.0337 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "835/835 [==============================] - 240s 288ms/step - loss: 136.0189 - accuracy: 0.1366 - val_loss: 101.0337 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "835/835 [==============================] - 240s 288ms/step - loss: 135.2915 - accuracy: 0.1388 - val_loss: 101.0337 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "835/835 [==============================] - 240s 288ms/step - loss: 135.3654 - accuracy: 0.1389 - val_loss: 101.0337 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "835/835 [==============================] - 241s 288ms/step - loss: 136.1986 - accuracy: 0.1366 - val_loss: 101.0337 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "835/835 [==============================] - 240s 288ms/step - loss: 136.0216 - accuracy: 0.1364 - val_loss: 101.0337 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "835/835 [==============================] - 240s 288ms/step - loss: 136.2964 - accuracy: 0.1334 - val_loss: 101.0337 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../opticnet/opticnet_30epochs_41742.0_images_True_newWeights_True_lastLayerOnly_rescale-symmetric_normalization/assets\n",
      "Test acc for opticnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.59832795 0.59790351 0.60750793 0.6042247 ]\n",
      "Training xception for 0.6% of train size (aka 50090 images) with pretrained: False and onlyLastLayersTrained: True...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "   6/1002 [..............................] - ETA: 9:34 - loss: 1.3858 - accuracy: 0.4438 WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1172s vs `on_train_batch_begin` time: 0.1869s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1172s vs `on_train_batch_end` time: 0.1961s). Check your callbacks.\n",
      "1002/1002 [==============================] - 129s 126ms/step - loss: 1.3858 - accuracy: 0.4410 - val_loss: 1.3863 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "1002/1002 [==============================] - 124s 124ms/step - loss: 1.3858 - accuracy: 0.4427 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "1002/1002 [==============================] - 124s 124ms/step - loss: 1.3858 - accuracy: 0.4473 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "1002/1002 [==============================] - 124s 124ms/step - loss: 1.3858 - accuracy: 0.4425 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "1002/1002 [==============================] - 124s 124ms/step - loss: 1.3858 - accuracy: 0.4413 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "1002/1002 [==============================] - 124s 124ms/step - loss: 1.3858 - accuracy: 0.4441 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "1002/1002 [==============================] - 124s 124ms/step - loss: 1.3858 - accuracy: 0.4476 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "1002/1002 [==============================] - 124s 124ms/step - loss: 1.3858 - accuracy: 0.4438 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "1002/1002 [==============================] - 124s 124ms/step - loss: 1.3858 - accuracy: 0.4459 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "1002/1002 [==============================] - 124s 124ms/step - loss: 1.3858 - accuracy: 0.4423 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "1002/1002 [==============================] - 124s 124ms/step - loss: 1.3858 - accuracy: 0.4427 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "1002/1002 [==============================] - 124s 124ms/step - loss: 1.3858 - accuracy: 0.4436 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "1002/1002 [==============================] - 124s 124ms/step - loss: 1.3858 - accuracy: 0.4457 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "1002/1002 [==============================] - 124s 124ms/step - loss: 1.3858 - accuracy: 0.4416 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "1002/1002 [==============================] - 124s 124ms/step - loss: 1.3858 - accuracy: 0.4413 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "1002/1002 [==============================] - 124s 124ms/step - loss: 1.3858 - accuracy: 0.4459 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "1002/1002 [==============================] - 124s 124ms/step - loss: 1.3858 - accuracy: 0.4453 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "1002/1002 [==============================] - 124s 124ms/step - loss: 1.3858 - accuracy: 0.4447 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "1002/1002 [==============================] - 124s 124ms/step - loss: 1.3858 - accuracy: 0.4457 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "1002/1002 [==============================] - 124s 124ms/step - loss: 1.3858 - accuracy: 0.4436 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "1002/1002 [==============================] - 124s 124ms/step - loss: 1.3858 - accuracy: 0.4435 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "1002/1002 [==============================] - 124s 124ms/step - loss: 1.3858 - accuracy: 0.4461 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "1002/1002 [==============================] - 124s 124ms/step - loss: 1.3858 - accuracy: 0.4437 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "1002/1002 [==============================] - 124s 124ms/step - loss: 1.3858 - accuracy: 0.4418 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "1002/1002 [==============================] - 124s 124ms/step - loss: 1.3858 - accuracy: 0.4432 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "1002/1002 [==============================] - 124s 124ms/step - loss: 1.3858 - accuracy: 0.4426 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "1002/1002 [==============================] - 124s 124ms/step - loss: 1.3858 - accuracy: 0.4464 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "1002/1002 [==============================] - 124s 124ms/step - loss: 1.3858 - accuracy: 0.4412 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "1002/1002 [==============================] - 124s 124ms/step - loss: 1.3858 - accuracy: 0.4441 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "1002/1002 [==============================] - 124s 124ms/step - loss: 1.3858 - accuracy: 0.4421 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../xception/xception_30epochs_50090.4_images_True_newWeights_True_lastLayerOnly_rescale-symmetric_normalization/assets\n",
      "Test acc for xception: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training resnet for 0.6% of train size (aka 50090 images) with pretrained: False and onlyLastLayersTrained: True...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "   6/1002 [..............................] - ETA: 7:34 - loss: 1.3896 - accuracy: 0.2602WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0598s vs `on_train_batch_begin` time: 0.1515s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0598s vs `on_train_batch_end` time: 0.1789s). Check your callbacks.\n",
      "1002/1002 [==============================] - 65s 60ms/step - loss: 1.3934 - accuracy: 0.2238 - val_loss: 1.3877 - val_accuracy: 0.2812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "1002/1002 [==============================] - 57s 57ms/step - loss: 1.3934 - accuracy: 0.2246 - val_loss: 1.3877 - val_accuracy: 0.2812\n",
      "Epoch 3/30\n",
      "1002/1002 [==============================] - 57s 57ms/step - loss: 1.3931 - accuracy: 0.2291 - val_loss: 1.3877 - val_accuracy: 0.2812\n",
      "Epoch 4/30\n",
      "1002/1002 [==============================] - 57s 57ms/step - loss: 1.3932 - accuracy: 0.2256 - val_loss: 1.3877 - val_accuracy: 0.2812\n",
      "Epoch 5/30\n",
      "1002/1002 [==============================] - 57s 57ms/step - loss: 1.3932 - accuracy: 0.2265 - val_loss: 1.3877 - val_accuracy: 0.2812\n",
      "Epoch 6/30\n",
      "1002/1002 [==============================] - 57s 57ms/step - loss: 1.3931 - accuracy: 0.2318 - val_loss: 1.3877 - val_accuracy: 0.2812\n",
      "Epoch 7/30\n",
      "1002/1002 [==============================] - 57s 57ms/step - loss: 1.3933 - accuracy: 0.2288 - val_loss: 1.3877 - val_accuracy: 0.2812\n",
      "Epoch 8/30\n",
      "1002/1002 [==============================] - 57s 57ms/step - loss: 1.3934 - accuracy: 0.2289 - val_loss: 1.3877 - val_accuracy: 0.2812\n",
      "Epoch 9/30\n",
      "1002/1002 [==============================] - 57s 57ms/step - loss: 1.3933 - accuracy: 0.2290 - val_loss: 1.3877 - val_accuracy: 0.2812\n",
      "Epoch 10/30\n",
      "1002/1002 [==============================] - 58s 57ms/step - loss: 1.3930 - accuracy: 0.2261 - val_loss: 1.3877 - val_accuracy: 0.2812\n",
      "Epoch 11/30\n",
      "1002/1002 [==============================] - 57s 57ms/step - loss: 1.3932 - accuracy: 0.2280 - val_loss: 1.3877 - val_accuracy: 0.2812\n",
      "Epoch 12/30\n",
      "1002/1002 [==============================] - 57s 57ms/step - loss: 1.3933 - accuracy: 0.2286 - val_loss: 1.3877 - val_accuracy: 0.2812\n",
      "Epoch 13/30\n",
      "1002/1002 [==============================] - 57s 57ms/step - loss: 1.3933 - accuracy: 0.2297 - val_loss: 1.3877 - val_accuracy: 0.2812\n",
      "Epoch 14/30\n",
      "1002/1002 [==============================] - 57s 57ms/step - loss: 1.3932 - accuracy: 0.2260 - val_loss: 1.3877 - val_accuracy: 0.2812\n",
      "Epoch 15/30\n",
      "1002/1002 [==============================] - 57s 57ms/step - loss: 1.3933 - accuracy: 0.2269 - val_loss: 1.3877 - val_accuracy: 0.2812\n",
      "Epoch 16/30\n",
      "1002/1002 [==============================] - 57s 57ms/step - loss: 1.3931 - accuracy: 0.2303 - val_loss: 1.3877 - val_accuracy: 0.2812\n",
      "Epoch 17/30\n",
      "1002/1002 [==============================] - 57s 57ms/step - loss: 1.3933 - accuracy: 0.2288 - val_loss: 1.3877 - val_accuracy: 0.2812\n",
      "Epoch 18/30\n",
      "1002/1002 [==============================] - 57s 57ms/step - loss: 1.3933 - accuracy: 0.2263 - val_loss: 1.3877 - val_accuracy: 0.2812\n",
      "Epoch 19/30\n",
      "1002/1002 [==============================] - 57s 57ms/step - loss: 1.3934 - accuracy: 0.2267 - val_loss: 1.3877 - val_accuracy: 0.2812\n",
      "Epoch 20/30\n",
      "1002/1002 [==============================] - 57s 57ms/step - loss: 1.3933 - accuracy: 0.2296 - val_loss: 1.3877 - val_accuracy: 0.2812\n",
      "Epoch 21/30\n",
      "1002/1002 [==============================] - 57s 57ms/step - loss: 1.3933 - accuracy: 0.2286 - val_loss: 1.3877 - val_accuracy: 0.2812\n",
      "Epoch 22/30\n",
      "1002/1002 [==============================] - 57s 57ms/step - loss: 1.3930 - accuracy: 0.2289 - val_loss: 1.3877 - val_accuracy: 0.2812\n",
      "Epoch 23/30\n",
      "1002/1002 [==============================] - 57s 57ms/step - loss: 1.3933 - accuracy: 0.2267 - val_loss: 1.3877 - val_accuracy: 0.2812\n",
      "Epoch 24/30\n",
      "1002/1002 [==============================] - 57s 57ms/step - loss: 1.3934 - accuracy: 0.2252 - val_loss: 1.3877 - val_accuracy: 0.2812\n",
      "Epoch 25/30\n",
      "1002/1002 [==============================] - 57s 57ms/step - loss: 1.3932 - accuracy: 0.2276 - val_loss: 1.3877 - val_accuracy: 0.2812\n",
      "Epoch 26/30\n",
      "1002/1002 [==============================] - 57s 57ms/step - loss: 1.3933 - accuracy: 0.2267 - val_loss: 1.3877 - val_accuracy: 0.2812\n",
      "Epoch 27/30\n",
      "1002/1002 [==============================] - 57s 57ms/step - loss: 1.3931 - accuracy: 0.2313 - val_loss: 1.3877 - val_accuracy: 0.2812\n",
      "Epoch 28/30\n",
      "1002/1002 [==============================] - 57s 57ms/step - loss: 1.3932 - accuracy: 0.2280 - val_loss: 1.3877 - val_accuracy: 0.2812\n",
      "Epoch 29/30\n",
      "1002/1002 [==============================] - 57s 57ms/step - loss: 1.3932 - accuracy: 0.2261 - val_loss: 1.3877 - val_accuracy: 0.2812\n",
      "Epoch 30/30\n",
      "1002/1002 [==============================] - 57s 57ms/step - loss: 1.3932 - accuracy: 0.2260 - val_loss: 1.3877 - val_accuracy: 0.2812\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_50090.4_images_True_newWeights_True_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training opticnet for 0.6% of train size (aka 50090 images) with pretrained: False and onlyLastLayersTrained: True...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1002/1002 [==============================] - 298s 291ms/step - loss: 300.4120 - accuracy: 0.4451 - val_loss: 444.4454 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "1002/1002 [==============================] - 287s 287ms/step - loss: 300.5399 - accuracy: 0.4470 - val_loss: 444.4454 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "1002/1002 [==============================] - 287s 287ms/step - loss: 300.3534 - accuracy: 0.4446 - val_loss: 444.4454 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "1002/1002 [==============================] - 287s 287ms/step - loss: 297.6064 - accuracy: 0.4482 - val_loss: 444.4454 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "1002/1002 [==============================] - 287s 287ms/step - loss: 305.1137 - accuracy: 0.4397 - val_loss: 444.4454 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "1002/1002 [==============================] - 288s 287ms/step - loss: 298.8423 - accuracy: 0.4438 - val_loss: 444.4454 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "1002/1002 [==============================] - 287s 287ms/step - loss: 303.6285 - accuracy: 0.4409 - val_loss: 444.4454 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "1002/1002 [==============================] - 287s 287ms/step - loss: 299.5015 - accuracy: 0.4453 - val_loss: 444.4454 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "1002/1002 [==============================] - 287s 287ms/step - loss: 301.7122 - accuracy: 0.4434 - val_loss: 444.4454 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "1002/1002 [==============================] - 288s 287ms/step - loss: 298.6612 - accuracy: 0.4447 - val_loss: 444.4454 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "1002/1002 [==============================] - 287s 287ms/step - loss: 303.7054 - accuracy: 0.4404 - val_loss: 444.4454 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "1002/1002 [==============================] - 287s 287ms/step - loss: 300.7972 - accuracy: 0.4424 - val_loss: 444.4454 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "1002/1002 [==============================] - 287s 287ms/step - loss: 302.3390 - accuracy: 0.4412 - val_loss: 444.4454 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "1002/1002 [==============================] - 287s 287ms/step - loss: 299.9832 - accuracy: 0.4442 - val_loss: 444.4454 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "1002/1002 [==============================] - 287s 287ms/step - loss: 301.2303 - accuracy: 0.4423 - val_loss: 444.4454 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "1002/1002 [==============================] - 287s 287ms/step - loss: 299.3291 - accuracy: 0.4452 - val_loss: 444.4454 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "1002/1002 [==============================] - 287s 287ms/step - loss: 302.1480 - accuracy: 0.4436 - val_loss: 444.4454 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "1002/1002 [==============================] - 288s 287ms/step - loss: 301.8982 - accuracy: 0.4419 - val_loss: 444.4454 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "1002/1002 [==============================] - 287s 287ms/step - loss: 302.2323 - accuracy: 0.4427 - val_loss: 444.4454 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "1002/1002 [==============================] - 287s 287ms/step - loss: 302.4605 - accuracy: 0.4421 - val_loss: 444.4454 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "1002/1002 [==============================] - 287s 287ms/step - loss: 298.5255 - accuracy: 0.4491 - val_loss: 444.4454 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "1002/1002 [==============================] - 287s 287ms/step - loss: 299.9145 - accuracy: 0.4462 - val_loss: 444.4454 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "1002/1002 [==============================] - 287s 287ms/step - loss: 300.3326 - accuracy: 0.4434 - val_loss: 444.4454 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "1002/1002 [==============================] - 287s 286ms/step - loss: 303.1515 - accuracy: 0.4392 - val_loss: 444.4454 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "1002/1002 [==============================] - 287s 287ms/step - loss: 299.0944 - accuracy: 0.4469 - val_loss: 444.4454 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "1002/1002 [==============================] - 287s 287ms/step - loss: 300.5508 - accuracy: 0.4439 - val_loss: 444.4454 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "1002/1002 [==============================] - 287s 287ms/step - loss: 302.0266 - accuracy: 0.4435 - val_loss: 444.4454 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "1002/1002 [==============================] - 287s 287ms/step - loss: 296.5103 - accuracy: 0.4485 - val_loss: 444.4454 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "1002/1002 [==============================] - 288s 287ms/step - loss: 300.2184 - accuracy: 0.4443 - val_loss: 444.4454 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "1002/1002 [==============================] - 288s 287ms/step - loss: 301.6934 - accuracy: 0.4428 - val_loss: 444.4454 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../opticnet/opticnet_30epochs_50090.4_images_True_newWeights_True_lastLayerOnly_rescale-symmetric_normalization/assets\n",
      "Test acc for opticnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.7466084  0.75032926 0.75625661 0.75069638]\n",
      "Training xception for 0.75% of train size (aka 62613 images) with pretrained: False and onlyLastLayersTrained: True...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "   6/1253 [..............................] - ETA: 12:25 - loss: 1.3860 - accuracy: 0.1597WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1173s vs `on_train_batch_begin` time: 0.1670s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1173s vs `on_train_batch_end` time: 0.2337s). Check your callbacks.\n",
      "1253/1253 [==============================] - 161s 125ms/step - loss: 1.3860 - accuracy: 0.1368 - val_loss: 1.3863 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "1253/1253 [==============================] - 155s 123ms/step - loss: 1.3860 - accuracy: 0.1390 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "1253/1253 [==============================] - 155s 124ms/step - loss: 1.3860 - accuracy: 0.1370 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "1253/1253 [==============================] - 155s 124ms/step - loss: 1.3860 - accuracy: 0.1382 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "1253/1253 [==============================] - 155s 124ms/step - loss: 1.3860 - accuracy: 0.1366 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "1253/1253 [==============================] - 155s 124ms/step - loss: 1.3860 - accuracy: 0.1380 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "1253/1253 [==============================] - 155s 124ms/step - loss: 1.3860 - accuracy: 0.1367 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "1253/1253 [==============================] - 164s 131ms/step - loss: 1.3860 - accuracy: 0.1345 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "1253/1253 [==============================] - 177s 141ms/step - loss: 1.3860 - accuracy: 0.1369 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "1253/1253 [==============================] - 177s 141ms/step - loss: 1.3860 - accuracy: 0.1386 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "1253/1253 [==============================] - 178s 142ms/step - loss: 1.3860 - accuracy: 0.1382 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "1253/1253 [==============================] - 178s 142ms/step - loss: 1.3860 - accuracy: 0.1394 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "1253/1253 [==============================] - 178s 142ms/step - loss: 1.3860 - accuracy: 0.1357 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "1253/1253 [==============================] - 178s 142ms/step - loss: 1.3860 - accuracy: 0.1373 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "1253/1253 [==============================] - 177s 141ms/step - loss: 1.3860 - accuracy: 0.1361 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "1253/1253 [==============================] - 177s 142ms/step - loss: 1.3860 - accuracy: 0.1352 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "1253/1253 [==============================] - 177s 142ms/step - loss: 1.3860 - accuracy: 0.1387 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "1253/1253 [==============================] - 180s 143ms/step - loss: 1.3860 - accuracy: 0.1377 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "1253/1253 [==============================] - 177s 141ms/step - loss: 1.3860 - accuracy: 0.1345 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "1253/1253 [==============================] - 178s 142ms/step - loss: 1.3860 - accuracy: 0.1373 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "1253/1253 [==============================] - 177s 141ms/step - loss: 1.3860 - accuracy: 0.1396 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "1253/1253 [==============================] - 177s 141ms/step - loss: 1.3860 - accuracy: 0.1360 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "1253/1253 [==============================] - 174s 139ms/step - loss: 1.3860 - accuracy: 0.1364 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "1253/1253 [==============================] - 177s 141ms/step - loss: 1.3860 - accuracy: 0.1370 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "1253/1253 [==============================] - 178s 142ms/step - loss: 1.3860 - accuracy: 0.1375 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "1253/1253 [==============================] - 177s 141ms/step - loss: 1.3860 - accuracy: 0.1347 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "1253/1253 [==============================] - 177s 141ms/step - loss: 1.3860 - accuracy: 0.1364 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "1253/1253 [==============================] - 177s 141ms/step - loss: 1.3860 - accuracy: 0.1376 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "1253/1253 [==============================] - 176s 140ms/step - loss: 1.3860 - accuracy: 0.1352 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "1253/1253 [==============================] - 177s 142ms/step - loss: 1.3860 - accuracy: 0.1401 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../xception/xception_30epochs_62613.0_images_True_newWeights_True_lastLayerOnly_rescale-symmetric_normalization/assets\n",
      "Test acc for xception: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training resnet for 0.75% of train size (aka 62613 images) with pretrained: False and onlyLastLayersTrained: True...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "   6/1253 [..............................] - ETA: 10:24 - loss: 1.3907 - accuracy: 0.2669WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0660s vs `on_train_batch_begin` time: 0.1899s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0660s vs `on_train_batch_end` time: 0.1736s). Check your callbacks.\n",
      "1253/1253 [==============================] - 99s 76ms/step - loss: 1.3902 - accuracy: 0.2744 - val_loss: 1.3862 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "1253/1253 [==============================] - 94s 75ms/step - loss: 1.3901 - accuracy: 0.2766 - val_loss: 1.3862 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "1253/1253 [==============================] - 93s 74ms/step - loss: 1.3902 - accuracy: 0.2729 - val_loss: 1.3862 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "1253/1253 [==============================] - 94s 75ms/step - loss: 1.3901 - accuracy: 0.2734 - val_loss: 1.3862 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "1253/1253 [==============================] - 93s 75ms/step - loss: 1.3902 - accuracy: 0.2724 - val_loss: 1.3862 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "1253/1253 [==============================] - 94s 75ms/step - loss: 1.3902 - accuracy: 0.2727 - val_loss: 1.3862 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "1253/1253 [==============================] - 94s 75ms/step - loss: 1.3903 - accuracy: 0.2707 - val_loss: 1.3862 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "1253/1253 [==============================] - 93s 74ms/step - loss: 1.3903 - accuracy: 0.2697 - val_loss: 1.3862 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "1253/1253 [==============================] - 93s 74ms/step - loss: 1.3901 - accuracy: 0.2753 - val_loss: 1.3862 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "1253/1253 [==============================] - 93s 75ms/step - loss: 1.3902 - accuracy: 0.2739 - val_loss: 1.3862 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "1253/1253 [==============================] - 94s 75ms/step - loss: 1.3901 - accuracy: 0.2745 - val_loss: 1.3862 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "1253/1253 [==============================] - 92s 74ms/step - loss: 1.3902 - accuracy: 0.2718 - val_loss: 1.3862 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "1253/1253 [==============================] - 93s 75ms/step - loss: 1.3902 - accuracy: 0.2737 - val_loss: 1.3862 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "1253/1253 [==============================] - 93s 74ms/step - loss: 1.3903 - accuracy: 0.2726 - val_loss: 1.3862 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "1253/1253 [==============================] - 93s 74ms/step - loss: 1.3903 - accuracy: 0.2722 - val_loss: 1.3862 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "1253/1253 [==============================] - 93s 74ms/step - loss: 1.3901 - accuracy: 0.2748 - val_loss: 1.3862 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "1253/1253 [==============================] - 93s 74ms/step - loss: 1.3902 - accuracy: 0.2742 - val_loss: 1.3862 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "1253/1253 [==============================] - 93s 74ms/step - loss: 1.3901 - accuracy: 0.2746 - val_loss: 1.3862 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "1253/1253 [==============================] - 92s 73ms/step - loss: 1.3903 - accuracy: 0.2706 - val_loss: 1.3862 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "1253/1253 [==============================] - 93s 74ms/step - loss: 1.3901 - accuracy: 0.2730 - val_loss: 1.3862 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "1253/1253 [==============================] - 93s 74ms/step - loss: 1.3900 - accuracy: 0.2766 - val_loss: 1.3862 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "1253/1253 [==============================] - 91s 73ms/step - loss: 1.3902 - accuracy: 0.2706 - val_loss: 1.3862 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "1253/1253 [==============================] - 92s 74ms/step - loss: 1.3902 - accuracy: 0.2748 - val_loss: 1.3862 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "1253/1253 [==============================] - 92s 74ms/step - loss: 1.3902 - accuracy: 0.2755 - val_loss: 1.3862 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "1253/1253 [==============================] - 92s 74ms/step - loss: 1.3900 - accuracy: 0.2764 - val_loss: 1.3862 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "1253/1253 [==============================] - 92s 74ms/step - loss: 1.3902 - accuracy: 0.2729 - val_loss: 1.3862 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "1253/1253 [==============================] - 92s 74ms/step - loss: 1.3902 - accuracy: 0.2706 - val_loss: 1.3862 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "1253/1253 [==============================] - 92s 74ms/step - loss: 1.3902 - accuracy: 0.2709 - val_loss: 1.3862 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "1253/1253 [==============================] - 92s 74ms/step - loss: 1.3903 - accuracy: 0.2714 - val_loss: 1.3862 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "1253/1253 [==============================] - 92s 74ms/step - loss: 1.3902 - accuracy: 0.2738 - val_loss: 1.3862 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_62613.0_images_True_newWeights_True_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training opticnet for 0.75% of train size (aka 62613 images) with pretrained: False and onlyLastLayersTrained: True...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1253/1253 [==============================] - 396s 311ms/step - loss: 82.2125 - accuracy: 0.4220 - val_loss: 158.7998 - val_accuracy: 0.1562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "1253/1253 [==============================] - 385s 307ms/step - loss: 82.1553 - accuracy: 0.4206 - val_loss: 158.7998 - val_accuracy: 0.1562\n",
      "Epoch 3/30\n",
      "1253/1253 [==============================] - 388s 310ms/step - loss: 81.7058 - accuracy: 0.4216 - val_loss: 158.7998 - val_accuracy: 0.1562\n",
      "Epoch 4/30\n",
      "1253/1253 [==============================] - 389s 310ms/step - loss: 81.2277 - accuracy: 0.4236 - val_loss: 158.7998 - val_accuracy: 0.1562\n",
      "Epoch 5/30\n",
      "1253/1253 [==============================] - 388s 310ms/step - loss: 81.3004 - accuracy: 0.4215 - val_loss: 158.7998 - val_accuracy: 0.1562\n",
      "Epoch 6/30\n",
      "1253/1253 [==============================] - 388s 310ms/step - loss: 81.3817 - accuracy: 0.4197 - val_loss: 158.7998 - val_accuracy: 0.1562\n",
      "Epoch 7/30\n",
      "1253/1253 [==============================] - 384s 307ms/step - loss: 81.2832 - accuracy: 0.4208 - val_loss: 158.7998 - val_accuracy: 0.1562\n",
      "Epoch 8/30\n",
      "1253/1253 [==============================] - 385s 307ms/step - loss: 80.5643 - accuracy: 0.4196 - val_loss: 158.7998 - val_accuracy: 0.1562\n",
      "Epoch 9/30\n",
      "1253/1253 [==============================] - 384s 307ms/step - loss: 81.6991 - accuracy: 0.4198 - val_loss: 158.7998 - val_accuracy: 0.1562\n",
      "Epoch 10/30\n",
      "1253/1253 [==============================] - 384s 306ms/step - loss: 80.0125 - accuracy: 0.4223 - val_loss: 158.7998 - val_accuracy: 0.1562\n",
      "Epoch 11/30\n",
      "1253/1253 [==============================] - 387s 308ms/step - loss: 81.9509 - accuracy: 0.4182 - val_loss: 158.7998 - val_accuracy: 0.1562\n",
      "Epoch 12/30\n",
      "1253/1253 [==============================] - 387s 309ms/step - loss: 80.6798 - accuracy: 0.4245 - val_loss: 158.7998 - val_accuracy: 0.1562\n",
      "Epoch 13/30\n",
      "1253/1253 [==============================] - 387s 309ms/step - loss: 79.3093 - accuracy: 0.4263 - val_loss: 158.7998 - val_accuracy: 0.1562\n",
      "Epoch 14/30\n",
      "1253/1253 [==============================] - 387s 309ms/step - loss: 79.6735 - accuracy: 0.4216 - val_loss: 158.7998 - val_accuracy: 0.1562\n",
      "Epoch 15/30\n",
      "1253/1253 [==============================] - 388s 309ms/step - loss: 81.1336 - accuracy: 0.4220 - val_loss: 158.7998 - val_accuracy: 0.1562\n",
      "Epoch 16/30\n",
      "1253/1253 [==============================] - 384s 306ms/step - loss: 80.2390 - accuracy: 0.4195 - val_loss: 158.7998 - val_accuracy: 0.1562\n",
      "Epoch 17/30\n",
      "1253/1253 [==============================] - 385s 307ms/step - loss: 80.9370 - accuracy: 0.4208 - val_loss: 158.7998 - val_accuracy: 0.1562\n",
      "Epoch 18/30\n",
      "1253/1253 [==============================] - 385s 307ms/step - loss: 81.8001 - accuracy: 0.4201 - val_loss: 158.7998 - val_accuracy: 0.1562\n",
      "Epoch 19/30\n",
      "1253/1253 [==============================] - 384s 306ms/step - loss: 81.9888 - accuracy: 0.4169 - val_loss: 158.7998 - val_accuracy: 0.1562\n",
      "Epoch 20/30\n",
      "1253/1253 [==============================] - 387s 309ms/step - loss: 79.9519 - accuracy: 0.4235 - val_loss: 158.7998 - val_accuracy: 0.1562\n",
      "Epoch 21/30\n",
      "1253/1253 [==============================] - 388s 310ms/step - loss: 81.0182 - accuracy: 0.4216 - val_loss: 158.7998 - val_accuracy: 0.1562\n",
      "Epoch 22/30\n",
      "1253/1253 [==============================] - 388s 310ms/step - loss: 81.5555 - accuracy: 0.4222 - val_loss: 158.7998 - val_accuracy: 0.1562\n",
      "Epoch 23/30\n",
      "1253/1253 [==============================] - 388s 310ms/step - loss: 81.5346 - accuracy: 0.4238 - val_loss: 158.7998 - val_accuracy: 0.1562\n",
      "Epoch 24/30\n",
      "1253/1253 [==============================] - 388s 309ms/step - loss: 81.5029 - accuracy: 0.4185 - val_loss: 158.7998 - val_accuracy: 0.1562\n",
      "Epoch 25/30\n",
      "1253/1253 [==============================] - 385s 307ms/step - loss: 80.4599 - accuracy: 0.4231 - val_loss: 158.7998 - val_accuracy: 0.1562\n",
      "Epoch 26/30\n",
      "1253/1253 [==============================] - 385s 307ms/step - loss: 81.0178 - accuracy: 0.4209 - val_loss: 158.7998 - val_accuracy: 0.1562\n",
      "Epoch 27/30\n",
      "1253/1253 [==============================] - 385s 307ms/step - loss: 80.6092 - accuracy: 0.4202 - val_loss: 158.7998 - val_accuracy: 0.1562\n",
      "Epoch 28/30\n",
      "1253/1253 [==============================] - 385s 307ms/step - loss: 81.0134 - accuracy: 0.4219 - val_loss: 158.7998 - val_accuracy: 0.1562\n",
      "Epoch 29/30\n",
      "1253/1253 [==============================] - 387s 309ms/step - loss: 81.6412 - accuracy: 0.4196 - val_loss: 158.7998 - val_accuracy: 0.1562\n",
      "Epoch 30/30\n",
      "1253/1253 [==============================] - 387s 309ms/step - loss: 81.6544 - accuracy: 0.4184 - val_loss: 158.7998 - val_accuracy: 0.1562\n",
      "INFO:tensorflow:Assets written to: ../opticnet/opticnet_30epochs_62613.0_images_True_newWeights_True_lastLayerOnly_rescale-symmetric_normalization/assets\n",
      "Test acc for opticnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.89918298 0.90025534 0.89857244 0.90320334]\n",
      "Training xception for 0.9% of train size (aka 75135 images) with pretrained: False and onlyLastLayersTrained: True...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "   6/1503 [..............................] - ETA: 16:43 - loss: 1.3856 - accuracy: 0.2902WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1407s vs `on_train_batch_begin` time: 0.1922s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1407s vs `on_train_batch_end` time: 0.2500s). Check your callbacks.\n",
      "1503/1503 [==============================] - 219s 143ms/step - loss: 1.3856 - accuracy: 0.3134 - val_loss: 1.3863 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "1503/1503 [==============================] - 214s 142ms/step - loss: 1.3856 - accuracy: 0.3104 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "1503/1503 [==============================] - 214s 142ms/step - loss: 1.3856 - accuracy: 0.3162 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "1503/1503 [==============================] - 214s 142ms/step - loss: 1.3856 - accuracy: 0.3124 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "1503/1503 [==============================] - 211s 141ms/step - loss: 1.3856 - accuracy: 0.3155 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "1503/1503 [==============================] - 211s 141ms/step - loss: 1.3856 - accuracy: 0.3136 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "1503/1503 [==============================] - 211s 141ms/step - loss: 1.3856 - accuracy: 0.3161 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "1503/1503 [==============================] - 212s 141ms/step - loss: 1.3856 - accuracy: 0.3153 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "1503/1503 [==============================] - 213s 141ms/step - loss: 1.3856 - accuracy: 0.3150 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "1503/1503 [==============================] - 212s 141ms/step - loss: 1.3856 - accuracy: 0.3173 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "1503/1503 [==============================] - 212s 141ms/step - loss: 1.3856 - accuracy: 0.3143 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "1503/1503 [==============================] - 215s 143ms/step - loss: 1.3856 - accuracy: 0.3169 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "1503/1503 [==============================] - 215s 143ms/step - loss: 1.3856 - accuracy: 0.3119 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "1503/1503 [==============================] - 215s 143ms/step - loss: 1.3856 - accuracy: 0.3133 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "1503/1503 [==============================] - 215s 143ms/step - loss: 1.3856 - accuracy: 0.3146 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "1503/1503 [==============================] - 214s 142ms/step - loss: 1.3856 - accuracy: 0.3150 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "1503/1503 [==============================] - 214s 142ms/step - loss: 1.3856 - accuracy: 0.3159 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "1503/1503 [==============================] - 212s 141ms/step - loss: 1.3856 - accuracy: 0.3147 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "1503/1503 [==============================] - 212s 141ms/step - loss: 1.3856 - accuracy: 0.3141 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "1503/1503 [==============================] - 213s 141ms/step - loss: 1.3856 - accuracy: 0.3142 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "1503/1503 [==============================] - 212s 141ms/step - loss: 1.3856 - accuracy: 0.3159 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "1503/1503 [==============================] - 213s 141ms/step - loss: 1.3856 - accuracy: 0.3151 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "1503/1503 [==============================] - 211s 140ms/step - loss: 1.3856 - accuracy: 0.3155 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "1503/1503 [==============================] - 212s 141ms/step - loss: 1.3856 - accuracy: 0.3165 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "1503/1503 [==============================] - 211s 140ms/step - loss: 1.3856 - accuracy: 0.3179 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "1503/1503 [==============================] - 212s 141ms/step - loss: 1.3856 - accuracy: 0.3156 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "1503/1503 [==============================] - 211s 140ms/step - loss: 1.3856 - accuracy: 0.3141 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "1503/1503 [==============================] - 214s 142ms/step - loss: 1.3856 - accuracy: 0.3140 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "1503/1503 [==============================] - 213s 142ms/step - loss: 1.3856 - accuracy: 0.3128 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "1503/1503 [==============================] - 214s 142ms/step - loss: 1.3856 - accuracy: 0.3124 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../xception/xception_30epochs_75135.6_images_True_newWeights_True_lastLayerOnly_rescale-symmetric_normalization/assets\n",
      "Test acc for xception: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training resnet for 0.9% of train size (aka 75135 images) with pretrained: False and onlyLastLayersTrained: True...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "   6/1503 [..............................] - ETA: 12:44 - loss: 1.3813 - accuracy: 0.3543WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0712s vs `on_train_batch_begin` time: 0.1877s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0712s vs `on_train_batch_end` time: 0.1804s). Check your callbacks.\n",
      "1503/1503 [==============================] - 120s 78ms/step - loss: 1.3817 - accuracy: 0.4113 - val_loss: 1.3863 - val_accuracy: 0.1875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "1503/1503 [==============================] - 112s 75ms/step - loss: 1.3817 - accuracy: 0.4123 - val_loss: 1.3863 - val_accuracy: 0.1875\n",
      "Epoch 3/30\n",
      "1503/1503 [==============================] - 113s 75ms/step - loss: 1.3817 - accuracy: 0.4084 - val_loss: 1.3863 - val_accuracy: 0.1875\n",
      "Epoch 4/30\n",
      "1503/1503 [==============================] - 112s 75ms/step - loss: 1.3818 - accuracy: 0.4099 - val_loss: 1.3863 - val_accuracy: 0.1875\n",
      "Epoch 5/30\n",
      "1503/1503 [==============================] - 112s 75ms/step - loss: 1.3817 - accuracy: 0.4090 - val_loss: 1.3863 - val_accuracy: 0.1875\n",
      "Epoch 6/30\n",
      "1503/1503 [==============================] - 114s 76ms/step - loss: 1.3817 - accuracy: 0.4093 - val_loss: 1.3863 - val_accuracy: 0.1875\n",
      "Epoch 7/30\n",
      "1503/1503 [==============================] - 112s 75ms/step - loss: 1.3817 - accuracy: 0.4117 - val_loss: 1.3863 - val_accuracy: 0.1875\n",
      "Epoch 8/30\n",
      "1503/1503 [==============================] - 112s 75ms/step - loss: 1.3817 - accuracy: 0.4095 - val_loss: 1.3863 - val_accuracy: 0.1875\n",
      "Epoch 9/30\n",
      "1503/1503 [==============================] - 114s 76ms/step - loss: 1.3817 - accuracy: 0.4118 - val_loss: 1.3863 - val_accuracy: 0.1875\n",
      "Epoch 10/30\n",
      "1503/1503 [==============================] - 111s 74ms/step - loss: 1.3817 - accuracy: 0.4107 - val_loss: 1.3863 - val_accuracy: 0.1875\n",
      "Epoch 11/30\n",
      "1503/1503 [==============================] - 110s 73ms/step - loss: 1.3817 - accuracy: 0.4111 - val_loss: 1.3863 - val_accuracy: 0.1875\n",
      "Epoch 12/30\n",
      "1503/1503 [==============================] - 110s 73ms/step - loss: 1.3817 - accuracy: 0.4130 - val_loss: 1.3863 - val_accuracy: 0.1875\n",
      "Epoch 13/30\n",
      "1503/1503 [==============================] - 110s 73ms/step - loss: 1.3817 - accuracy: 0.4109 - val_loss: 1.3863 - val_accuracy: 0.1875\n",
      "Epoch 14/30\n",
      "1503/1503 [==============================] - 110s 73ms/step - loss: 1.3817 - accuracy: 0.4106 - val_loss: 1.3863 - val_accuracy: 0.1875\n",
      "Epoch 15/30\n",
      "1503/1503 [==============================] - 111s 74ms/step - loss: 1.3817 - accuracy: 0.4105 - val_loss: 1.3863 - val_accuracy: 0.1875\n",
      "Epoch 16/30\n",
      "1503/1503 [==============================] - 110s 73ms/step - loss: 1.3817 - accuracy: 0.4111 - val_loss: 1.3863 - val_accuracy: 0.1875\n",
      "Epoch 17/30\n",
      "1503/1503 [==============================] - 110s 73ms/step - loss: 1.3818 - accuracy: 0.4068 - val_loss: 1.3863 - val_accuracy: 0.1875\n",
      "Epoch 18/30\n",
      "1503/1503 [==============================] - 110s 73ms/step - loss: 1.3817 - accuracy: 0.4110 - val_loss: 1.3863 - val_accuracy: 0.1875\n",
      "Epoch 19/30\n",
      "1503/1503 [==============================] - 112s 74ms/step - loss: 1.3817 - accuracy: 0.4068 - val_loss: 1.3863 - val_accuracy: 0.1875\n",
      "Epoch 20/30\n",
      "1503/1503 [==============================] - 111s 74ms/step - loss: 1.3818 - accuracy: 0.4078 - val_loss: 1.3863 - val_accuracy: 0.1875\n",
      "Epoch 21/30\n",
      "1503/1503 [==============================] - 110s 73ms/step - loss: 1.3816 - accuracy: 0.4119 - val_loss: 1.3863 - val_accuracy: 0.1875\n",
      "Epoch 22/30\n",
      "1503/1503 [==============================] - 111s 74ms/step - loss: 1.3817 - accuracy: 0.4121 - val_loss: 1.3863 - val_accuracy: 0.1875\n",
      "Epoch 23/30\n",
      "1503/1503 [==============================] - 110s 73ms/step - loss: 1.3817 - accuracy: 0.4134 - val_loss: 1.3863 - val_accuracy: 0.1875\n",
      "Epoch 24/30\n",
      "1503/1503 [==============================] - 112s 74ms/step - loss: 1.3818 - accuracy: 0.4078 - val_loss: 1.3863 - val_accuracy: 0.1875\n",
      "Epoch 25/30\n",
      "1503/1503 [==============================] - 111s 74ms/step - loss: 1.3817 - accuracy: 0.4091 - val_loss: 1.3863 - val_accuracy: 0.1875\n",
      "Epoch 26/30\n",
      "1503/1503 [==============================] - 111s 74ms/step - loss: 1.3817 - accuracy: 0.4105 - val_loss: 1.3863 - val_accuracy: 0.1875\n",
      "Epoch 27/30\n",
      "1503/1503 [==============================] - 111s 74ms/step - loss: 1.3818 - accuracy: 0.4102 - val_loss: 1.3863 - val_accuracy: 0.1875\n",
      "Epoch 28/30\n",
      "1503/1503 [==============================] - 111s 74ms/step - loss: 1.3817 - accuracy: 0.4095 - val_loss: 1.3863 - val_accuracy: 0.1875\n",
      "Epoch 29/30\n",
      "1503/1503 [==============================] - 111s 74ms/step - loss: 1.3817 - accuracy: 0.4098 - val_loss: 1.3863 - val_accuracy: 0.1875\n",
      "Epoch 30/30\n",
      "1503/1503 [==============================] - 112s 75ms/step - loss: 1.3818 - accuracy: 0.4096 - val_loss: 1.3863 - val_accuracy: 0.1875\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_75135.6_images_True_newWeights_True_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training opticnet for 0.9% of train size (aka 75135 images) with pretrained: False and onlyLastLayersTrained: True...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1503/1503 [==============================] - 475s 312ms/step - loss: 505.0883 - accuracy: 0.1038 - val_loss: 388.7061 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "1503/1503 [==============================] - 466s 310ms/step - loss: 503.8694 - accuracy: 0.1056 - val_loss: 388.7061 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "1503/1503 [==============================] - 461s 307ms/step - loss: 503.1746 - accuracy: 0.1055 - val_loss: 388.7061 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "1503/1503 [==============================] - 461s 307ms/step - loss: 504.1559 - accuracy: 0.1035 - val_loss: 388.7061 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "1503/1503 [==============================] - 461s 307ms/step - loss: 502.8287 - accuracy: 0.1039 - val_loss: 388.7061 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "1503/1503 [==============================] - 462s 307ms/step - loss: 503.7764 - accuracy: 0.1040 - val_loss: 388.7061 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "1503/1503 [==============================] - 463s 308ms/step - loss: 505.1357 - accuracy: 0.1034 - val_loss: 388.7061 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "1503/1503 [==============================] - 464s 309ms/step - loss: 507.0438 - accuracy: 0.1029 - val_loss: 388.7061 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "1503/1503 [==============================] - 463s 308ms/step - loss: 504.5117 - accuracy: 0.1036 - val_loss: 388.7061 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "1503/1503 [==============================] - 462s 308ms/step - loss: 504.9272 - accuracy: 0.1032 - val_loss: 388.7061 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "1503/1503 [==============================] - 461s 307ms/step - loss: 503.7497 - accuracy: 0.1043 - val_loss: 388.7061 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "1503/1503 [==============================] - 459s 306ms/step - loss: 505.2157 - accuracy: 0.1037 - val_loss: 388.7061 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "1503/1503 [==============================] - 460s 306ms/step - loss: 505.1766 - accuracy: 0.1034 - val_loss: 388.7061 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "1503/1503 [==============================] - 465s 310ms/step - loss: 503.3998 - accuracy: 0.1033 - val_loss: 388.7061 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "1503/1503 [==============================] - 465s 310ms/step - loss: 503.1411 - accuracy: 0.1055 - val_loss: 388.7061 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "1503/1503 [==============================] - 466s 310ms/step - loss: 505.0042 - accuracy: 0.1049 - val_loss: 388.7061 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "1503/1503 [==============================] - 464s 309ms/step - loss: 507.7510 - accuracy: 0.1032 - val_loss: 388.7061 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "1503/1503 [==============================] - 462s 308ms/step - loss: 503.9955 - accuracy: 0.1048 - val_loss: 388.7061 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "1503/1503 [==============================] - 461s 307ms/step - loss: 505.9504 - accuracy: 0.1043 - val_loss: 388.7061 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "1503/1503 [==============================] - 462s 307ms/step - loss: 507.0952 - accuracy: 0.1035 - val_loss: 388.7061 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "1503/1503 [==============================] - 464s 308ms/step - loss: 504.9732 - accuracy: 0.1024 - val_loss: 388.7061 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "1503/1503 [==============================] - 465s 309ms/step - loss: 504.5406 - accuracy: 0.1034 - val_loss: 388.7061 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "1503/1503 [==============================] - 467s 310ms/step - loss: 506.4555 - accuracy: 0.1044 - val_loss: 388.7061 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "1503/1503 [==============================] - 465s 310ms/step - loss: 503.5729 - accuracy: 0.1048 - val_loss: 388.7061 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "1503/1503 [==============================] - 461s 307ms/step - loss: 505.6534 - accuracy: 0.1051 - val_loss: 388.7061 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "1503/1503 [==============================] - 461s 307ms/step - loss: 505.9191 - accuracy: 0.1015 - val_loss: 388.7061 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "1503/1503 [==============================] - 461s 307ms/step - loss: 502.5302 - accuracy: 0.1022 - val_loss: 388.7061 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "1503/1503 [==============================] - 463s 308ms/step - loss: 505.5559 - accuracy: 0.1033 - val_loss: 388.7061 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "1503/1503 [==============================] - 464s 309ms/step - loss: 505.8609 - accuracy: 0.1026 - val_loss: 388.7061 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "1503/1503 [==============================] - 464s 309ms/step - loss: 505.0127 - accuracy: 0.1046 - val_loss: 388.7061 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../opticnet/opticnet_30epochs_75135.6_images_True_newWeights_True_lastLayerOnly_rescale-symmetric_normalization/assets\n",
      "Test acc for opticnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [1. 1. 1. 1.]\n",
      "Training xception for 1.0% of train size (aka 83484 images) with pretrained: False and onlyLastLayersTrained: True...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "   6/1670 [..............................] - ETA: 17:13 - loss: 1.3860 - accuracy: 0.3530WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1241s vs `on_train_batch_begin` time: 0.1890s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1241s vs `on_train_batch_end` time: 0.2259s). Check your callbacks.\n",
      "1670/1670 [==============================] - 245s 145ms/step - loss: 1.3861 - accuracy: 0.3146 - val_loss: 1.3863 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "1670/1670 [==============================] - 239s 143ms/step - loss: 1.3861 - accuracy: 0.3159 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "1670/1670 [==============================] - 237s 142ms/step - loss: 1.3861 - accuracy: 0.3145 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "1670/1670 [==============================] - 236s 142ms/step - loss: 1.3861 - accuracy: 0.3145 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "1670/1670 [==============================] - 236s 142ms/step - loss: 1.3861 - accuracy: 0.3150 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "1670/1670 [==============================] - 237s 142ms/step - loss: 1.3861 - accuracy: 0.3157 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "1670/1670 [==============================] - 237s 142ms/step - loss: 1.3861 - accuracy: 0.3133 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "1670/1670 [==============================] - 236s 141ms/step - loss: 1.3861 - accuracy: 0.3141 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "1670/1670 [==============================] - 238s 143ms/step - loss: 1.3861 - accuracy: 0.3162 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "1670/1670 [==============================] - 240s 144ms/step - loss: 1.3861 - accuracy: 0.3162 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "1670/1670 [==============================] - 239s 143ms/step - loss: 1.3861 - accuracy: 0.3163 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "1670/1670 [==============================] - 239s 143ms/step - loss: 1.3861 - accuracy: 0.3133 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "1670/1670 [==============================] - 239s 143ms/step - loss: 1.3861 - accuracy: 0.3135 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "1670/1670 [==============================] - 241s 144ms/step - loss: 1.3861 - accuracy: 0.3138 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "1670/1670 [==============================] - 241s 144ms/step - loss: 1.3861 - accuracy: 0.3174 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "1670/1670 [==============================] - 239s 143ms/step - loss: 1.3861 - accuracy: 0.3136 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "1670/1670 [==============================] - 235s 141ms/step - loss: 1.3861 - accuracy: 0.3143 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "1670/1670 [==============================] - 237s 142ms/step - loss: 1.3861 - accuracy: 0.3147 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "1670/1670 [==============================] - 237s 142ms/step - loss: 1.3861 - accuracy: 0.3162 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "1670/1670 [==============================] - 237s 142ms/step - loss: 1.3861 - accuracy: 0.3162 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "1670/1670 [==============================] - 236s 141ms/step - loss: 1.3861 - accuracy: 0.3139 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "1670/1670 [==============================] - 236s 141ms/step - loss: 1.3861 - accuracy: 0.3168 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "1670/1670 [==============================] - 236s 142ms/step - loss: 1.3861 - accuracy: 0.3156 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "1670/1670 [==============================] - 238s 142ms/step - loss: 1.3861 - accuracy: 0.3128 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "1670/1670 [==============================] - 238s 143ms/step - loss: 1.3861 - accuracy: 0.3181 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "1670/1670 [==============================] - 239s 143ms/step - loss: 1.3861 - accuracy: 0.3134 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "1670/1670 [==============================] - 239s 143ms/step - loss: 1.3861 - accuracy: 0.3144 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "1670/1670 [==============================] - 239s 143ms/step - loss: 1.3861 - accuracy: 0.3116 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "1670/1670 [==============================] - 239s 143ms/step - loss: 1.3861 - accuracy: 0.3149 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "1670/1670 [==============================] - 239s 143ms/step - loss: 1.3861 - accuracy: 0.3169 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../xception/xception_30epochs_83484.0_images_True_newWeights_True_lastLayerOnly_rescale-symmetric_normalization/assets\n",
      "Test acc for xception: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training resnet for 1.0% of train size (aka 83484 images) with pretrained: False and onlyLastLayersTrained: True...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "   6/1670 [..............................] - ETA: 14:42 - loss: 1.3898 - accuracy: 0.4385WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0712s vs `on_train_batch_begin` time: 0.1998s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0712s vs `on_train_batch_end` time: 0.1836s). Check your callbacks.\n",
      "1670/1670 [==============================] - 131s 76ms/step - loss: 1.3860 - accuracy: 0.4446 - val_loss: 1.3861 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "1670/1670 [==============================] - 122s 73ms/step - loss: 1.3859 - accuracy: 0.4487 - val_loss: 1.3861 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "1670/1670 [==============================] - 123s 73ms/step - loss: 1.3859 - accuracy: 0.4463 - val_loss: 1.3861 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "1670/1670 [==============================] - 123s 74ms/step - loss: 1.3859 - accuracy: 0.4477 - val_loss: 1.3861 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "1670/1670 [==============================] - 123s 74ms/step - loss: 1.3858 - accuracy: 0.4475 - val_loss: 1.3861 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "1670/1670 [==============================] - 122s 73ms/step - loss: 1.3861 - accuracy: 0.4448 - val_loss: 1.3861 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "1670/1670 [==============================] - 123s 74ms/step - loss: 1.3859 - accuracy: 0.4480 - val_loss: 1.3861 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "1670/1670 [==============================] - 122s 73ms/step - loss: 1.3860 - accuracy: 0.4464 - val_loss: 1.3861 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "1670/1670 [==============================] - 123s 74ms/step - loss: 1.3858 - accuracy: 0.4462 - val_loss: 1.3861 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "1670/1670 [==============================] - 123s 74ms/step - loss: 1.3861 - accuracy: 0.4444 - val_loss: 1.3861 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "1670/1670 [==============================] - 124s 74ms/step - loss: 1.3860 - accuracy: 0.4459 - val_loss: 1.3861 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "1670/1670 [==============================] - 123s 74ms/step - loss: 1.3857 - accuracy: 0.4494 - val_loss: 1.3861 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "1670/1670 [==============================] - 123s 73ms/step - loss: 1.3859 - accuracy: 0.4479 - val_loss: 1.3861 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "1670/1670 [==============================] - 124s 74ms/step - loss: 1.3858 - accuracy: 0.4463 - val_loss: 1.3861 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "1670/1670 [==============================] - 124s 74ms/step - loss: 1.3859 - accuracy: 0.4460 - val_loss: 1.3861 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "1670/1670 [==============================] - 125s 75ms/step - loss: 1.3858 - accuracy: 0.4481 - val_loss: 1.3861 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "1670/1670 [==============================] - 126s 75ms/step - loss: 1.3859 - accuracy: 0.4459 - val_loss: 1.3861 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "1670/1670 [==============================] - 125s 75ms/step - loss: 1.3860 - accuracy: 0.4433 - val_loss: 1.3861 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "1670/1670 [==============================] - 124s 74ms/step - loss: 1.3859 - accuracy: 0.4443 - val_loss: 1.3861 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "1670/1670 [==============================] - 124s 74ms/step - loss: 1.3860 - accuracy: 0.4465 - val_loss: 1.3861 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "1670/1670 [==============================] - 124s 74ms/step - loss: 1.3861 - accuracy: 0.4445 - val_loss: 1.3861 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "1670/1670 [==============================] - 124s 74ms/step - loss: 1.3860 - accuracy: 0.4418 - val_loss: 1.3861 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "1670/1670 [==============================] - 125s 75ms/step - loss: 1.3861 - accuracy: 0.4456 - val_loss: 1.3861 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "1670/1670 [==============================] - 124s 74ms/step - loss: 1.3860 - accuracy: 0.4434 - val_loss: 1.3861 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "1670/1670 [==============================] - 124s 74ms/step - loss: 1.3861 - accuracy: 0.4429 - val_loss: 1.3861 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "1670/1670 [==============================] - 122s 73ms/step - loss: 1.3860 - accuracy: 0.4455 - val_loss: 1.3861 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "1670/1670 [==============================] - 124s 74ms/step - loss: 1.3859 - accuracy: 0.4463 - val_loss: 1.3861 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "1670/1670 [==============================] - 124s 74ms/step - loss: 1.3860 - accuracy: 0.4457 - val_loss: 1.3861 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "1670/1670 [==============================] - 122s 73ms/step - loss: 1.3860 - accuracy: 0.4463 - val_loss: 1.3861 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "1670/1670 [==============================] - 123s 74ms/step - loss: 1.3860 - accuracy: 0.4457 - val_loss: 1.3861 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_83484.0_images_True_newWeights_True_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training opticnet for 1.0% of train size (aka 83484 images) with pretrained: False and onlyLastLayersTrained: True...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "   6/1670 [..............................] - ETA: 34:14 - loss: 433.6767 - accuracy: 0.3430WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.3064s vs `on_train_batch_end` time: 0.5795s). Check your callbacks.\n",
      "1670/1670 [==============================] - 525s 310ms/step - loss: 437.2704 - accuracy: 0.3139 - val_loss: 409.1056 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "1670/1670 [==============================] - 513s 307ms/step - loss: 437.9651 - accuracy: 0.3123 - val_loss: 409.1056 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "1670/1670 [==============================] - 515s 308ms/step - loss: 434.1690 - accuracy: 0.3172 - val_loss: 409.1056 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "1670/1670 [==============================] - 515s 309ms/step - loss: 434.6913 - accuracy: 0.3180 - val_loss: 409.1056 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "1670/1670 [==============================] - 516s 309ms/step - loss: 437.8054 - accuracy: 0.3138 - val_loss: 409.1056 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "1670/1670 [==============================] - 516s 309ms/step - loss: 436.8716 - accuracy: 0.3146 - val_loss: 409.1056 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "1670/1670 [==============================] - 513s 307ms/step - loss: 435.4405 - accuracy: 0.3176 - val_loss: 409.1056 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "1670/1670 [==============================] - 512s 307ms/step - loss: 437.0288 - accuracy: 0.3162 - val_loss: 409.1056 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "1670/1670 [==============================] - 513s 307ms/step - loss: 433.9987 - accuracy: 0.3182 - val_loss: 409.1056 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "1670/1670 [==============================] - 516s 309ms/step - loss: 436.8676 - accuracy: 0.3153 - val_loss: 409.1056 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "1670/1670 [==============================] - 516s 309ms/step - loss: 438.0843 - accuracy: 0.3127 - val_loss: 409.1056 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "1670/1670 [==============================] - 517s 310ms/step - loss: 437.5017 - accuracy: 0.3155 - val_loss: 409.1056 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "1670/1670 [==============================] - 515s 309ms/step - loss: 436.2695 - accuracy: 0.3170 - val_loss: 409.1056 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "1670/1670 [==============================] - 514s 308ms/step - loss: 433.6456 - accuracy: 0.3197 - val_loss: 409.1056 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "1670/1670 [==============================] - 512s 307ms/step - loss: 435.7477 - accuracy: 0.3165 - val_loss: 409.1056 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "1670/1670 [==============================] - 514s 308ms/step - loss: 437.8859 - accuracy: 0.3159 - val_loss: 409.1056 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "1670/1670 [==============================] - 516s 309ms/step - loss: 438.1309 - accuracy: 0.3129 - val_loss: 409.1056 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "1670/1670 [==============================] - 517s 310ms/step - loss: 438.3287 - accuracy: 0.3139 - val_loss: 409.1056 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "1670/1670 [==============================] - 518s 310ms/step - loss: 435.8148 - accuracy: 0.3168 - val_loss: 409.1056 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "1670/1670 [==============================] - 514s 308ms/step - loss: 436.6393 - accuracy: 0.3151 - val_loss: 409.1056 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "1670/1670 [==============================] - 512s 307ms/step - loss: 436.7644 - accuracy: 0.3152 - val_loss: 409.1056 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "1670/1670 [==============================] - 512s 307ms/step - loss: 437.8338 - accuracy: 0.3157 - val_loss: 409.1056 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "1670/1670 [==============================] - 517s 309ms/step - loss: 438.8415 - accuracy: 0.3129 - val_loss: 409.1056 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "1670/1670 [==============================] - 518s 310ms/step - loss: 437.6215 - accuracy: 0.3132 - val_loss: 409.1056 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "1670/1670 [==============================] - 517s 310ms/step - loss: 439.4682 - accuracy: 0.3129 - val_loss: 409.1056 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "1670/1670 [==============================] - 513s 307ms/step - loss: 437.3610 - accuracy: 0.3145 - val_loss: 409.1056 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "1670/1670 [==============================] - 511s 306ms/step - loss: 437.4855 - accuracy: 0.3149 - val_loss: 409.1056 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "1670/1670 [==============================] - 512s 306ms/step - loss: 436.3862 - accuracy: 0.3158 - val_loss: 409.1056 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "1670/1670 [==============================] - 515s 308ms/step - loss: 438.1420 - accuracy: 0.3146 - val_loss: 409.1056 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "1670/1670 [==============================] - 517s 310ms/step - loss: 435.7657 - accuracy: 0.3171 - val_loss: 409.1056 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../opticnet/opticnet_30epochs_83484.0_images_True_newWeights_True_lastLayerOnly_rescale-symmetric_normalization/assets\n",
      "Test acc for opticnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.0101463  0.00983739 0.01039831 0.00963324]\n",
      "Training xception for 0.01% of train size (aka 834 images) with pretrained: False and onlyLastLayersTrained: False...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      " 6/17 [=========>....................] - ETA: 7s - loss: 1.3844 - accuracy: 0.3306WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1421s vs `on_train_batch_begin` time: 0.1875s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1421s vs `on_train_batch_end` time: 0.2450s). Check your callbacks.\n",
      "17/17 [==============================] - 10s 395ms/step - loss: 1.3818 - accuracy: 0.3286 - val_loss: 1.3868 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "17/17 [==============================] - 3s 159ms/step - loss: 1.3678 - accuracy: 0.4317 - val_loss: 1.3878 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "17/17 [==============================] - 3s 157ms/step - loss: 1.3564 - accuracy: 0.4242 - val_loss: 1.3892 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "17/17 [==============================] - 3s 157ms/step - loss: 1.3496 - accuracy: 0.4213 - val_loss: 1.3908 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "17/17 [==============================] - 3s 156ms/step - loss: 1.3398 - accuracy: 0.4323 - val_loss: 1.3925 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "17/17 [==============================] - 3s 155ms/step - loss: 1.3334 - accuracy: 0.4411 - val_loss: 1.3941 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "17/17 [==============================] - 3s 148ms/step - loss: 1.3255 - accuracy: 0.4177 - val_loss: 1.3957 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "17/17 [==============================] - 3s 160ms/step - loss: 1.3232 - accuracy: 0.4389 - val_loss: 1.3973 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "17/17 [==============================] - 3s 150ms/step - loss: 1.3154 - accuracy: 0.4531 - val_loss: 1.3988 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "17/17 [==============================] - 3s 151ms/step - loss: 1.3130 - accuracy: 0.4402 - val_loss: 1.4002 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "17/17 [==============================] - 3s 148ms/step - loss: 1.3056 - accuracy: 0.4540 - val_loss: 1.4015 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "17/17 [==============================] - 3s 161ms/step - loss: 1.3015 - accuracy: 0.4681 - val_loss: 1.4027 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "17/17 [==============================] - 3s 156ms/step - loss: 1.3038 - accuracy: 0.4417 - val_loss: 1.4038 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "17/17 [==============================] - 3s 146ms/step - loss: 1.2977 - accuracy: 0.4406 - val_loss: 1.4048 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "17/17 [==============================] - 3s 147ms/step - loss: 1.3069 - accuracy: 0.4194 - val_loss: 1.4057 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "17/17 [==============================] - 3s 157ms/step - loss: 1.2971 - accuracy: 0.4352 - val_loss: 1.4066 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "17/17 [==============================] - 3s 162ms/step - loss: 1.2982 - accuracy: 0.4490 - val_loss: 1.4074 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "17/17 [==============================] - 3s 160ms/step - loss: 1.2993 - accuracy: 0.4417 - val_loss: 1.4081 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "17/17 [==============================] - 3s 156ms/step - loss: 1.2915 - accuracy: 0.4369 - val_loss: 1.4088 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "17/17 [==============================] - 3s 161ms/step - loss: 1.3046 - accuracy: 0.4160 - val_loss: 1.4094 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "17/17 [==============================] - 3s 152ms/step - loss: 1.2954 - accuracy: 0.4291 - val_loss: 1.4099 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "17/17 [==============================] - 3s 161ms/step - loss: 1.2941 - accuracy: 0.4281 - val_loss: 1.4104 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "17/17 [==============================] - 3s 160ms/step - loss: 1.2844 - accuracy: 0.4734 - val_loss: 1.4109 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "17/17 [==============================] - 3s 158ms/step - loss: 1.2922 - accuracy: 0.4154 - val_loss: 1.4113 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "17/17 [==============================] - 3s 161ms/step - loss: 1.2930 - accuracy: 0.4303 - val_loss: 1.4116 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "17/17 [==============================] - 3s 153ms/step - loss: 1.2816 - accuracy: 0.4703 - val_loss: 1.4120 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "17/17 [==============================] - 3s 160ms/step - loss: 1.2809 - accuracy: 0.4673 - val_loss: 1.4123 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "17/17 [==============================] - 3s 150ms/step - loss: 1.2885 - accuracy: 0.4368 - val_loss: 1.4126 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "17/17 [==============================] - 3s 153ms/step - loss: 1.2900 - accuracy: 0.4188 - val_loss: 1.4128 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "17/17 [==============================] - 3s 161ms/step - loss: 1.2897 - accuracy: 0.4242 - val_loss: 1.4130 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../xception/xception_30epochs_834.84_images_True_newWeights_False_lastLayerOnly_rescale-symmetric_normalization/assets\n",
      "Test acc for xception: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training resnet for 0.01% of train size (aka 834 images) with pretrained: False and onlyLastLayersTrained: False...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      " 6/17 [=========>....................] - ETA: 6s - loss: 1.3821 - accuracy: 0.2713WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0787s vs `on_train_batch_begin` time: 0.1985s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0787s vs `on_train_batch_end` time: 0.2028s). Check your callbacks.\n",
      "17/17 [==============================] - 9s 326ms/step - loss: 1.3700 - accuracy: 0.3477 - val_loss: 1.3894 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "17/17 [==============================] - 2s 90ms/step - loss: 1.3449 - accuracy: 0.4276 - val_loss: 1.3916 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "17/17 [==============================] - 2s 89ms/step - loss: 1.3368 - accuracy: 0.4328 - val_loss: 1.3940 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "17/17 [==============================] - 2s 88ms/step - loss: 1.3253 - accuracy: 0.4250 - val_loss: 1.3966 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "17/17 [==============================] - 1s 87ms/step - loss: 1.3158 - accuracy: 0.4629 - val_loss: 1.3991 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "17/17 [==============================] - 2s 92ms/step - loss: 1.3095 - accuracy: 0.4436 - val_loss: 1.4014 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "17/17 [==============================] - 1s 87ms/step - loss: 1.3091 - accuracy: 0.4375 - val_loss: 1.4037 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "17/17 [==============================] - 1s 87ms/step - loss: 1.3014 - accuracy: 0.4399 - val_loss: 1.4057 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "17/17 [==============================] - 2s 91ms/step - loss: 1.2968 - accuracy: 0.4414 - val_loss: 1.4077 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "17/17 [==============================] - 1s 84ms/step - loss: 1.2955 - accuracy: 0.4364 - val_loss: 1.4095 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "17/17 [==============================] - 2s 87ms/step - loss: 1.2933 - accuracy: 0.4336 - val_loss: 1.4111 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "17/17 [==============================] - 2s 91ms/step - loss: 1.2918 - accuracy: 0.4274 - val_loss: 1.4125 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "17/17 [==============================] - 1s 88ms/step - loss: 1.2887 - accuracy: 0.4458 - val_loss: 1.4139 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "17/17 [==============================] - 2s 96ms/step - loss: 1.2994 - accuracy: 0.4134 - val_loss: 1.4152 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "17/17 [==============================] - 1s 85ms/step - loss: 1.2831 - accuracy: 0.4324 - val_loss: 1.4163 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "17/17 [==============================] - 1s 83ms/step - loss: 1.2869 - accuracy: 0.4326 - val_loss: 1.4174 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "17/17 [==============================] - 2s 98ms/step - loss: 1.2907 - accuracy: 0.4197 - val_loss: 1.4183 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "17/17 [==============================] - 2s 91ms/step - loss: 1.2798 - accuracy: 0.4414 - val_loss: 1.4192 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "17/17 [==============================] - 2s 96ms/step - loss: 1.2712 - accuracy: 0.4705 - val_loss: 1.4200 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "17/17 [==============================] - 2s 97ms/step - loss: 1.2697 - accuracy: 0.4500 - val_loss: 1.4207 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "17/17 [==============================] - 1s 87ms/step - loss: 1.2777 - accuracy: 0.4295 - val_loss: 1.4213 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "17/17 [==============================] - 1s 83ms/step - loss: 1.2669 - accuracy: 0.4462 - val_loss: 1.4219 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "17/17 [==============================] - 2s 93ms/step - loss: 1.2746 - accuracy: 0.4344 - val_loss: 1.4224 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "17/17 [==============================] - 2s 102ms/step - loss: 1.2799 - accuracy: 0.4503 - val_loss: 1.4228 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "17/17 [==============================] - 2s 97ms/step - loss: 1.2820 - accuracy: 0.4083 - val_loss: 1.4232 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "17/17 [==============================] - 1s 80ms/step - loss: 1.2842 - accuracy: 0.4077 - val_loss: 1.4236 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "17/17 [==============================] - 2s 101ms/step - loss: 1.2734 - accuracy: 0.4496 - val_loss: 1.4240 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "17/17 [==============================] - 2s 91ms/step - loss: 1.2701 - accuracy: 0.4299 - val_loss: 1.4243 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "17/17 [==============================] - 2s 91ms/step - loss: 1.2805 - accuracy: 0.4311 - val_loss: 1.4246 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "17/17 [==============================] - 1s 82ms/step - loss: 1.2700 - accuracy: 0.4520 - val_loss: 1.4248 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_834.84_images_True_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training opticnet for 0.01% of train size (aka 834 images) with pretrained: False and onlyLastLayersTrained: False...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      " 6/17 [=========>....................] - ETA: 20s - loss: 24.9076 - accuracy: 0.3079WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.4862s vs `on_train_batch_end` time: 1.0866s). Check your callbacks.\n",
      "17/17 [==============================] - 39s 2s/step - loss: 19.8472 - accuracy: 0.3198 - val_loss: 96.0981 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "17/17 [==============================] - 20s 1s/step - loss: 4.0769 - accuracy: 0.3824 - val_loss: 15.8832 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "17/17 [==============================] - 20s 1s/step - loss: 1.7264 - accuracy: 0.3477 - val_loss: 4.5295 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "17/17 [==============================] - 20s 1s/step - loss: 1.4311 - accuracy: 0.4152 - val_loss: 1.7527 - val_accuracy: 0.2812\n",
      "Epoch 5/30\n",
      "17/17 [==============================] - 20s 1s/step - loss: 1.3164 - accuracy: 0.4077 - val_loss: 1.4265 - val_accuracy: 0.3125\n",
      "Epoch 6/30\n",
      "17/17 [==============================] - 20s 1s/step - loss: 1.3273 - accuracy: 0.4291 - val_loss: 1.3346 - val_accuracy: 0.3125\n",
      "Epoch 7/30\n",
      "17/17 [==============================] - 20s 1s/step - loss: 1.1303 - accuracy: 0.5569 - val_loss: 1.4302 - val_accuracy: 0.2812\n",
      "Epoch 8/30\n",
      "17/17 [==============================] - 20s 1s/step - loss: 1.0562 - accuracy: 0.6294 - val_loss: 1.5571 - val_accuracy: 0.2812\n",
      "Epoch 9/30\n",
      "17/17 [==============================] - 20s 1s/step - loss: 1.0286 - accuracy: 0.6064 - val_loss: 1.4992 - val_accuracy: 0.3125\n",
      "Epoch 10/30\n",
      "17/17 [==============================] - 20s 1s/step - loss: 1.0516 - accuracy: 0.5906 - val_loss: 1.4560 - val_accuracy: 0.3125\n",
      "Epoch 11/30\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.8864 - accuracy: 0.6634 - val_loss: 1.2561 - val_accuracy: 0.4062\n",
      "Epoch 12/30\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.9339 - accuracy: 0.6466 - val_loss: 1.4786 - val_accuracy: 0.3125\n",
      "Epoch 13/30\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.7726 - accuracy: 0.7170 - val_loss: 1.2071 - val_accuracy: 0.4688\n",
      "Epoch 14/30\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.6835 - accuracy: 0.7494 - val_loss: 1.0058 - val_accuracy: 0.5312\n",
      "Epoch 15/30\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.7123 - accuracy: 0.7123 - val_loss: 1.0208 - val_accuracy: 0.5938\n",
      "Epoch 16/30\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.5737 - accuracy: 0.7816 - val_loss: 0.9222 - val_accuracy: 0.5625\n",
      "Epoch 17/30\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.5319 - accuracy: 0.8037 - val_loss: 1.0629 - val_accuracy: 0.4375\n",
      "Epoch 18/30\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.4206 - accuracy: 0.8467 - val_loss: 0.9213 - val_accuracy: 0.5312\n",
      "Epoch 19/30\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.4479 - accuracy: 0.8352 - val_loss: 1.2655 - val_accuracy: 0.4062\n",
      "Epoch 20/30\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.3529 - accuracy: 0.8743 - val_loss: 0.9142 - val_accuracy: 0.5625\n",
      "Epoch 21/30\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2994 - accuracy: 0.8933 - val_loss: 0.9048 - val_accuracy: 0.6562\n",
      "Epoch 22/30\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2406 - accuracy: 0.9092 - val_loss: 0.9592 - val_accuracy: 0.5938\n",
      "Epoch 23/30\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2677 - accuracy: 0.8961 - val_loss: 1.1408 - val_accuracy: 0.5000\n",
      "Epoch 24/30\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.3065 - accuracy: 0.8741 - val_loss: 1.0002 - val_accuracy: 0.4688\n",
      "Epoch 25/30\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2294 - accuracy: 0.8994 - val_loss: 1.1466 - val_accuracy: 0.4688\n",
      "Epoch 26/30\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.1863 - accuracy: 0.9209 - val_loss: 1.1462 - val_accuracy: 0.5000\n",
      "Epoch 27/30\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.2060 - accuracy: 0.9305 - val_loss: 1.3178 - val_accuracy: 0.4688\n",
      "Epoch 28/30\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.1581 - accuracy: 0.9337 - val_loss: 1.1153 - val_accuracy: 0.5312\n",
      "Epoch 29/30\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.1885 - accuracy: 0.9269 - val_loss: 1.2578 - val_accuracy: 0.5000\n",
      "Epoch 30/30\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.1859 - accuracy: 0.9468 - val_loss: 1.2884 - val_accuracy: 0.5312\n",
      "INFO:tensorflow:Assets written to: ../opticnet/opticnet_30epochs_834.84_images_True_newWeights_False_lastLayerOnly_rescale-symmetric_normalization/assets\n",
      "Test acc for opticnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.02451074 0.02513103 0.02467395 0.02634633]\n",
      "Training xception for 0.025% of train size (aka 2087 images) with pretrained: False and onlyLastLayersTrained: False...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      " 6/42 [===>..........................] - ETA: 21s - loss: 1.3852 - accuracy: 0.3296WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1306s vs `on_train_batch_begin` time: 0.1675s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1306s vs `on_train_batch_end` time: 0.2206s). Check your callbacks.\n",
      "42/42 [==============================] - 12s 223ms/step - loss: 1.3777 - accuracy: 0.3638 - val_loss: 1.3884 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "42/42 [==============================] - 6s 149ms/step - loss: 1.3471 - accuracy: 0.4599 - val_loss: 1.3933 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "42/42 [==============================] - 6s 147ms/step - loss: 1.3258 - accuracy: 0.4506 - val_loss: 1.3997 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "42/42 [==============================] - 6s 147ms/step - loss: 1.3056 - accuracy: 0.4563 - val_loss: 1.4066 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "42/42 [==============================] - 6s 145ms/step - loss: 1.3000 - accuracy: 0.4353 - val_loss: 1.4136 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "42/42 [==============================] - 6s 145ms/step - loss: 1.2900 - accuracy: 0.4421 - val_loss: 1.4202 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "42/42 [==============================] - 6s 147ms/step - loss: 1.2764 - accuracy: 0.4465 - val_loss: 1.4265 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "42/42 [==============================] - 6s 146ms/step - loss: 1.2727 - accuracy: 0.4448 - val_loss: 1.4321 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "42/42 [==============================] - 6s 144ms/step - loss: 1.2676 - accuracy: 0.4430 - val_loss: 1.4375 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "42/42 [==============================] - 6s 143ms/step - loss: 1.2586 - accuracy: 0.4487 - val_loss: 1.4423 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "42/42 [==============================] - 6s 145ms/step - loss: 1.2616 - accuracy: 0.4460 - val_loss: 1.4467 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "42/42 [==============================] - 6s 144ms/step - loss: 1.2587 - accuracy: 0.4449 - val_loss: 1.4504 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "42/42 [==============================] - 6s 148ms/step - loss: 1.2490 - accuracy: 0.4538 - val_loss: 1.4541 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "42/42 [==============================] - 6s 145ms/step - loss: 1.2427 - accuracy: 0.4569 - val_loss: 1.4573 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "42/42 [==============================] - 6s 147ms/step - loss: 1.2559 - accuracy: 0.4413 - val_loss: 1.4600 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "42/42 [==============================] - 6s 142ms/step - loss: 1.2512 - accuracy: 0.4570 - val_loss: 1.4626 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "42/42 [==============================] - 6s 144ms/step - loss: 1.2356 - accuracy: 0.4602 - val_loss: 1.4650 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "42/42 [==============================] - 6s 144ms/step - loss: 1.2441 - accuracy: 0.4586 - val_loss: 1.4670 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "42/42 [==============================] - 6s 148ms/step - loss: 1.2374 - accuracy: 0.4537 - val_loss: 1.4689 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "42/42 [==============================] - 6s 144ms/step - loss: 1.2509 - accuracy: 0.4496 - val_loss: 1.4705 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "42/42 [==============================] - 6s 143ms/step - loss: 1.2608 - accuracy: 0.4243 - val_loss: 1.4719 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "42/42 [==============================] - 6s 146ms/step - loss: 1.2372 - accuracy: 0.4606 - val_loss: 1.4733 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "42/42 [==============================] - 6s 142ms/step - loss: 1.2559 - accuracy: 0.4437 - val_loss: 1.4745 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "42/42 [==============================] - 6s 146ms/step - loss: 1.2324 - accuracy: 0.4556 - val_loss: 1.4756 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "42/42 [==============================] - 6s 150ms/step - loss: 1.2381 - accuracy: 0.4604 - val_loss: 1.4766 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "42/42 [==============================] - 6s 147ms/step - loss: 1.2430 - accuracy: 0.4543 - val_loss: 1.4775 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "42/42 [==============================] - 6s 146ms/step - loss: 1.2476 - accuracy: 0.4343 - val_loss: 1.4783 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "42/42 [==============================] - 6s 143ms/step - loss: 1.2420 - accuracy: 0.4383 - val_loss: 1.4790 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "42/42 [==============================] - 6s 148ms/step - loss: 1.2513 - accuracy: 0.4508 - val_loss: 1.4796 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "42/42 [==============================] - 6s 144ms/step - loss: 1.2479 - accuracy: 0.4509 - val_loss: 1.4803 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../xception/xception_30epochs_2087.1_images_True_newWeights_False_lastLayerOnly_rescale-symmetric_normalization/assets\n",
      "Test acc for xception: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training resnet for 0.025% of train size (aka 2087 images) with pretrained: False and onlyLastLayersTrained: False...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      " 6/42 [===>..........................] - ETA: 19s - loss: 1.3842 - accuracy: 0.2543WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0721s vs `on_train_batch_begin` time: 0.2062s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0721s vs `on_train_batch_end` time: 0.1931s). Check your callbacks.\n",
      "42/42 [==============================] - 11s 169ms/step - loss: 1.3620 - accuracy: 0.3902 - val_loss: 1.3929 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "42/42 [==============================] - 3s 80ms/step - loss: 1.3213 - accuracy: 0.4674 - val_loss: 1.4005 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "42/42 [==============================] - 3s 80ms/step - loss: 1.3085 - accuracy: 0.4448 - val_loss: 1.4091 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "42/42 [==============================] - 3s 82ms/step - loss: 1.2904 - accuracy: 0.4599 - val_loss: 1.4176 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "42/42 [==============================] - 3s 83ms/step - loss: 1.2671 - accuracy: 0.4736 - val_loss: 1.4258 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "42/42 [==============================] - 3s 80ms/step - loss: 1.2649 - accuracy: 0.4524 - val_loss: 1.4330 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "42/42 [==============================] - 3s 82ms/step - loss: 1.2739 - accuracy: 0.4335 - val_loss: 1.4398 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "42/42 [==============================] - 3s 82ms/step - loss: 1.2633 - accuracy: 0.4357 - val_loss: 1.4459 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "42/42 [==============================] - 3s 78ms/step - loss: 1.2540 - accuracy: 0.4467 - val_loss: 1.4516 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "42/42 [==============================] - 3s 82ms/step - loss: 1.2531 - accuracy: 0.4429 - val_loss: 1.4566 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "42/42 [==============================] - 3s 79ms/step - loss: 1.2548 - accuracy: 0.4424 - val_loss: 1.4607 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "42/42 [==============================] - 3s 83ms/step - loss: 1.2517 - accuracy: 0.4394 - val_loss: 1.4647 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "42/42 [==============================] - 3s 81ms/step - loss: 1.2514 - accuracy: 0.4349 - val_loss: 1.4681 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "42/42 [==============================] - 5s 113ms/step - loss: 1.2417 - accuracy: 0.4531 - val_loss: 1.4713 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "42/42 [==============================] - 3s 80ms/step - loss: 1.2375 - accuracy: 0.4553 - val_loss: 1.4741 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "42/42 [==============================] - 3s 81ms/step - loss: 1.2421 - accuracy: 0.4549 - val_loss: 1.4765 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "42/42 [==============================] - 3s 77ms/step - loss: 1.2300 - accuracy: 0.4578 - val_loss: 1.4787 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "42/42 [==============================] - 3s 77ms/step - loss: 1.2438 - accuracy: 0.4388 - val_loss: 1.4806 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "42/42 [==============================] - 3s 82ms/step - loss: 1.2390 - accuracy: 0.4475 - val_loss: 1.4823 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "42/42 [==============================] - 3s 78ms/step - loss: 1.2607 - accuracy: 0.4323 - val_loss: 1.4837 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "42/42 [==============================] - 3s 83ms/step - loss: 1.2370 - accuracy: 0.4454 - val_loss: 1.4852 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "42/42 [==============================] - 3s 75ms/step - loss: 1.2397 - accuracy: 0.4521 - val_loss: 1.4864 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "42/42 [==============================] - 3s 79ms/step - loss: 1.2359 - accuracy: 0.4498 - val_loss: 1.4875 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "42/42 [==============================] - 3s 82ms/step - loss: 1.2480 - accuracy: 0.4329 - val_loss: 1.4885 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "42/42 [==============================] - 3s 80ms/step - loss: 1.2517 - accuracy: 0.4283 - val_loss: 1.4894 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "42/42 [==============================] - 3s 75ms/step - loss: 1.2447 - accuracy: 0.4482 - val_loss: 1.4902 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "42/42 [==============================] - 3s 77ms/step - loss: 1.2546 - accuracy: 0.4371 - val_loss: 1.4909 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "42/42 [==============================] - 3s 82ms/step - loss: 1.2335 - accuracy: 0.4595 - val_loss: 1.4915 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "42/42 [==============================] - 3s 80ms/step - loss: 1.2525 - accuracy: 0.4401 - val_loss: 1.4921 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "42/42 [==============================] - 3s 76ms/step - loss: 1.2414 - accuracy: 0.4377 - val_loss: 1.4926 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_2087.1_images_True_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training opticnet for 0.025% of train size (aka 2087 images) with pretrained: False and onlyLastLayersTrained: False...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      " 6/42 [===>..........................] - ETA: 1:07 - loss: 32.2336 - accuracy: 0.3051WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.4887s vs `on_train_batch_end` time: 1.0928s). Check your callbacks.\n",
      "42/42 [==============================] - 70s 1s/step - loss: 15.7043 - accuracy: 0.3218 - val_loss: 7.0296 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "42/42 [==============================] - 50s 1s/step - loss: 1.8282 - accuracy: 0.4038 - val_loss: 1.8359 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "42/42 [==============================] - 50s 1s/step - loss: 1.2267 - accuracy: 0.5436 - val_loss: 2.8133 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "42/42 [==============================] - 50s 1s/step - loss: 1.1676 - accuracy: 0.5996 - val_loss: 1.2691 - val_accuracy: 0.3750\n",
      "Epoch 5/30\n",
      "42/42 [==============================] - 50s 1s/step - loss: 1.0714 - accuracy: 0.6246 - val_loss: 1.3393 - val_accuracy: 0.5000\n",
      "Epoch 6/30\n",
      "42/42 [==============================] - 50s 1s/step - loss: 0.8922 - accuracy: 0.6642 - val_loss: 0.9644 - val_accuracy: 0.5938\n",
      "Epoch 7/30\n",
      "42/42 [==============================] - 50s 1s/step - loss: 0.7261 - accuracy: 0.7422 - val_loss: 1.0007 - val_accuracy: 0.5625\n",
      "Epoch 8/30\n",
      "42/42 [==============================] - 50s 1s/step - loss: 0.6702 - accuracy: 0.7419 - val_loss: 1.1827 - val_accuracy: 0.5625\n",
      "Epoch 9/30\n",
      "42/42 [==============================] - 50s 1s/step - loss: 0.6933 - accuracy: 0.7375 - val_loss: 1.0670 - val_accuracy: 0.5938\n",
      "Epoch 10/30\n",
      "42/42 [==============================] - 50s 1s/step - loss: 0.5165 - accuracy: 0.8072 - val_loss: 1.9803 - val_accuracy: 0.5312\n",
      "Epoch 11/30\n",
      "42/42 [==============================] - 50s 1s/step - loss: 0.4656 - accuracy: 0.8250 - val_loss: 0.9164 - val_accuracy: 0.5938\n",
      "Epoch 12/30\n",
      "42/42 [==============================] - 50s 1s/step - loss: 0.4017 - accuracy: 0.8483 - val_loss: 1.1024 - val_accuracy: 0.5938\n",
      "Epoch 13/30\n",
      "42/42 [==============================] - 50s 1s/step - loss: 0.3616 - accuracy: 0.8669 - val_loss: 1.8936 - val_accuracy: 0.5938\n",
      "Epoch 14/30\n",
      "42/42 [==============================] - 50s 1s/step - loss: 0.2955 - accuracy: 0.8961 - val_loss: 3.8855 - val_accuracy: 0.5625\n",
      "Epoch 15/30\n",
      "42/42 [==============================] - 50s 1s/step - loss: 0.1732 - accuracy: 0.9365 - val_loss: 1.2505 - val_accuracy: 0.6562\n",
      "Epoch 16/30\n",
      "42/42 [==============================] - 50s 1s/step - loss: 0.1441 - accuracy: 0.9466 - val_loss: 2.4159 - val_accuracy: 0.6250\n",
      "Epoch 17/30\n",
      "42/42 [==============================] - 50s 1s/step - loss: 0.0889 - accuracy: 0.9752 - val_loss: 1.2433 - val_accuracy: 0.7188\n",
      "Epoch 18/30\n",
      "42/42 [==============================] - 50s 1s/step - loss: 0.0882 - accuracy: 0.9712 - val_loss: 1.4808 - val_accuracy: 0.6875\n",
      "Epoch 19/30\n",
      "42/42 [==============================] - 50s 1s/step - loss: 0.0495 - accuracy: 0.9854 - val_loss: 1.3487 - val_accuracy: 0.7812\n",
      "Epoch 20/30\n",
      "42/42 [==============================] - 50s 1s/step - loss: 0.0599 - accuracy: 0.9763 - val_loss: 1.8467 - val_accuracy: 0.6250\n",
      "Epoch 21/30\n",
      "42/42 [==============================] - 50s 1s/step - loss: 0.0788 - accuracy: 0.9703 - val_loss: 1.4241 - val_accuracy: 0.7188\n",
      "Epoch 22/30\n",
      "42/42 [==============================] - 50s 1s/step - loss: 0.0686 - accuracy: 0.9770 - val_loss: 1.8667 - val_accuracy: 0.6250\n",
      "Epoch 23/30\n",
      "42/42 [==============================] - 50s 1s/step - loss: 0.0415 - accuracy: 0.9843 - val_loss: 1.1921 - val_accuracy: 0.6875\n",
      "Epoch 24/30\n",
      "42/42 [==============================] - 50s 1s/step - loss: 0.0262 - accuracy: 0.9928 - val_loss: 1.2810 - val_accuracy: 0.7500\n",
      "Epoch 25/30\n",
      "42/42 [==============================] - 50s 1s/step - loss: 0.0101 - accuracy: 0.9989 - val_loss: 2.0177 - val_accuracy: 0.6875\n",
      "Epoch 26/30\n",
      "42/42 [==============================] - 50s 1s/step - loss: 0.0129 - accuracy: 0.9982 - val_loss: 1.8010 - val_accuracy: 0.6875\n",
      "Epoch 27/30\n",
      "42/42 [==============================] - 50s 1s/step - loss: 0.0131 - accuracy: 0.9969 - val_loss: 1.6769 - val_accuracy: 0.6875\n",
      "Epoch 28/30\n",
      "42/42 [==============================] - 50s 1s/step - loss: 0.0119 - accuracy: 0.9994 - val_loss: 1.7921 - val_accuracy: 0.7188\n",
      "Epoch 29/30\n",
      "42/42 [==============================] - 50s 1s/step - loss: 0.0091 - accuracy: 0.9971 - val_loss: 1.5889 - val_accuracy: 0.7188\n",
      "Epoch 30/30\n",
      "42/42 [==============================] - 50s 1s/step - loss: 0.0095 - accuracy: 0.9992 - val_loss: 1.5635 - val_accuracy: 0.7188\n",
      "INFO:tensorflow:Assets written to: ../opticnet/opticnet_30epochs_2087.1_images_True_newWeights_False_lastLayerOnly_rescale-symmetric_normalization/assets\n",
      "Test acc for opticnet: 0.247934\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.0498575  0.04993952 0.05172718 0.04839833]\n",
      "Training xception for 0.05% of train size (aka 4174 images) with pretrained: False and onlyLastLayersTrained: False...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      " 6/84 [=>............................] - ETA: 50s - loss: 1.3850 - accuracy: 0.3938 WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1340s vs `on_train_batch_begin` time: 0.1907s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1340s vs `on_train_batch_end` time: 0.2370s). Check your callbacks.\n",
      "84/84 [==============================] - 19s 185ms/step - loss: 1.3684 - accuracy: 0.4418 - val_loss: 1.3946 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "84/84 [==============================] - 12s 142ms/step - loss: 1.3123 - accuracy: 0.4484 - val_loss: 1.4114 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "84/84 [==============================] - 12s 143ms/step - loss: 1.2877 - accuracy: 0.4406 - val_loss: 1.4294 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "84/84 [==============================] - 12s 144ms/step - loss: 1.2705 - accuracy: 0.4406 - val_loss: 1.4474 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "84/84 [==============================] - 12s 145ms/step - loss: 1.2536 - accuracy: 0.4518 - val_loss: 1.4633 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "84/84 [==============================] - 12s 144ms/step - loss: 1.2472 - accuracy: 0.4389 - val_loss: 1.4766 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "84/84 [==============================] - 12s 145ms/step - loss: 1.2418 - accuracy: 0.4456 - val_loss: 1.4879 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "84/84 [==============================] - 12s 144ms/step - loss: 1.2444 - accuracy: 0.4478 - val_loss: 1.4971 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "84/84 [==============================] - 12s 147ms/step - loss: 1.2295 - accuracy: 0.4450 - val_loss: 1.5044 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "84/84 [==============================] - 12s 146ms/step - loss: 1.2230 - accuracy: 0.4554 - val_loss: 1.5112 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "84/84 [==============================] - 12s 142ms/step - loss: 1.2371 - accuracy: 0.4401 - val_loss: 1.5158 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "84/84 [==============================] - 12s 147ms/step - loss: 1.2278 - accuracy: 0.4535 - val_loss: 1.5200 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "84/84 [==============================] - 12s 147ms/step - loss: 1.2283 - accuracy: 0.4499 - val_loss: 1.5235 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "84/84 [==============================] - 12s 144ms/step - loss: 1.2243 - accuracy: 0.4454 - val_loss: 1.5266 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "84/84 [==============================] - 12s 143ms/step - loss: 1.2159 - accuracy: 0.4576 - val_loss: 1.5291 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "84/84 [==============================] - 12s 143ms/step - loss: 1.2381 - accuracy: 0.4411 - val_loss: 1.5307 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "84/84 [==============================] - 13s 149ms/step - loss: 1.2257 - accuracy: 0.4549 - val_loss: 1.5327 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "84/84 [==============================] - 12s 143ms/step - loss: 1.2298 - accuracy: 0.4441 - val_loss: 1.5343 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "84/84 [==============================] - 12s 141ms/step - loss: 1.2422 - accuracy: 0.4317 - val_loss: 1.5353 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "84/84 [==============================] - 12s 143ms/step - loss: 1.2226 - accuracy: 0.4528 - val_loss: 1.5367 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "84/84 [==============================] - 12s 144ms/step - loss: 1.2246 - accuracy: 0.4462 - val_loss: 1.5376 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "84/84 [==============================] - 12s 146ms/step - loss: 1.2285 - accuracy: 0.4543 - val_loss: 1.5386 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "84/84 [==============================] - 12s 143ms/step - loss: 1.2231 - accuracy: 0.4517 - val_loss: 1.5394 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "84/84 [==============================] - 12s 145ms/step - loss: 1.2265 - accuracy: 0.4453 - val_loss: 1.5400 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "84/84 [==============================] - 12s 145ms/step - loss: 1.2257 - accuracy: 0.4543 - val_loss: 1.5406 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "84/84 [==============================] - 12s 147ms/step - loss: 1.2248 - accuracy: 0.4420 - val_loss: 1.5410 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "84/84 [==============================] - 12s 142ms/step - loss: 1.2412 - accuracy: 0.4283 - val_loss: 1.5416 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "84/84 [==============================] - 12s 145ms/step - loss: 1.2345 - accuracy: 0.4390 - val_loss: 1.5420 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "84/84 [==============================] - 12s 147ms/step - loss: 1.2348 - accuracy: 0.4427 - val_loss: 1.5424 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "84/84 [==============================] - 12s 145ms/step - loss: 1.2334 - accuracy: 0.4459 - val_loss: 1.5427 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../xception/xception_30epochs_4174.2_images_True_newWeights_False_lastLayerOnly_rescale-symmetric_normalization/assets\n",
      "Test acc for xception: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training resnet for 0.05% of train size (aka 4174 images) with pretrained: False and onlyLastLayersTrained: False...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      " 6/84 [=>............................] - ETA: 1:05 - loss: 1.3798 - accuracy: 0.2924WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0724s vs `on_train_batch_begin` time: 0.2034s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0724s vs `on_train_batch_end` time: 0.4334s). Check your callbacks.\n",
      "84/84 [==============================] - 16s 142ms/step - loss: 1.3463 - accuracy: 0.4204 - val_loss: 1.4047 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "84/84 [==============================] - 7s 79ms/step - loss: 1.2981 - accuracy: 0.4369 - val_loss: 1.4265 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "84/84 [==============================] - 7s 79ms/step - loss: 1.2705 - accuracy: 0.4428 - val_loss: 1.4476 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "84/84 [==============================] - 7s 81ms/step - loss: 1.2513 - accuracy: 0.4438 - val_loss: 1.4656 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "84/84 [==============================] - 7s 81ms/step - loss: 1.2450 - accuracy: 0.4485 - val_loss: 1.4813 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "84/84 [==============================] - 7s 79ms/step - loss: 1.2352 - accuracy: 0.4509 - val_loss: 1.4935 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "84/84 [==============================] - 7s 79ms/step - loss: 1.2288 - accuracy: 0.4493 - val_loss: 1.5032 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "84/84 [==============================] - 7s 80ms/step - loss: 1.2302 - accuracy: 0.4508 - val_loss: 1.5111 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "84/84 [==============================] - 7s 78ms/step - loss: 1.2307 - accuracy: 0.4401 - val_loss: 1.5174 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "84/84 [==============================] - 7s 79ms/step - loss: 1.2332 - accuracy: 0.4402 - val_loss: 1.5220 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "84/84 [==============================] - 7s 78ms/step - loss: 1.2257 - accuracy: 0.4529 - val_loss: 1.5266 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "84/84 [==============================] - 6s 76ms/step - loss: 1.2375 - accuracy: 0.4372 - val_loss: 1.5299 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "84/84 [==============================] - 7s 82ms/step - loss: 1.2308 - accuracy: 0.4332 - val_loss: 1.5326 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "84/84 [==============================] - 7s 82ms/step - loss: 1.2471 - accuracy: 0.4314 - val_loss: 1.5343 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "84/84 [==============================] - 7s 80ms/step - loss: 1.2221 - accuracy: 0.4504 - val_loss: 1.5368 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "84/84 [==============================] - 7s 77ms/step - loss: 1.2289 - accuracy: 0.4412 - val_loss: 1.5382 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "84/84 [==============================] - 6s 77ms/step - loss: 1.2238 - accuracy: 0.4519 - val_loss: 1.5397 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "84/84 [==============================] - 6s 77ms/step - loss: 1.2273 - accuracy: 0.4406 - val_loss: 1.5410 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "84/84 [==============================] - 7s 78ms/step - loss: 1.2300 - accuracy: 0.4438 - val_loss: 1.5419 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "84/84 [==============================] - 7s 79ms/step - loss: 1.2388 - accuracy: 0.4428 - val_loss: 1.5425 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "84/84 [==============================] - 6s 75ms/step - loss: 1.2395 - accuracy: 0.4414 - val_loss: 1.5432 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "84/84 [==============================] - 6s 75ms/step - loss: 1.2284 - accuracy: 0.4377 - val_loss: 1.5438 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "84/84 [==============================] - 7s 79ms/step - loss: 1.2326 - accuracy: 0.4448 - val_loss: 1.5444 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "84/84 [==============================] - 6s 76ms/step - loss: 1.2340 - accuracy: 0.4448 - val_loss: 1.5450 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "84/84 [==============================] - 6s 75ms/step - loss: 1.2353 - accuracy: 0.4472 - val_loss: 1.5454 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "84/84 [==============================] - 6s 75ms/step - loss: 1.2353 - accuracy: 0.4401 - val_loss: 1.5457 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "84/84 [==============================] - 7s 77ms/step - loss: 1.2296 - accuracy: 0.4458 - val_loss: 1.5461 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "84/84 [==============================] - 7s 79ms/step - loss: 1.2263 - accuracy: 0.4522 - val_loss: 1.5464 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "84/84 [==============================] - 7s 79ms/step - loss: 1.2463 - accuracy: 0.4254 - val_loss: 1.5466 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "84/84 [==============================] - 6s 75ms/step - loss: 1.2377 - accuracy: 0.4432 - val_loss: 1.5469 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_4174.2_images_True_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training opticnet for 0.05% of train size (aka 4174 images) with pretrained: False and onlyLastLayersTrained: False...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      " 6/84 [=>............................] - ETA: 2:32 - loss: 21.4591 - accuracy: 0.3026WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.4878s vs `on_train_batch_end` time: 1.1227s). Check your callbacks.\n",
      "84/84 [==============================] - 120s 1s/step - loss: 8.0469 - accuracy: 0.3568 - val_loss: 1.8041 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "84/84 [==============================] - 100s 1s/step - loss: 1.1004 - accuracy: 0.6063 - val_loss: 1.8449 - val_accuracy: 0.2812\n",
      "Epoch 3/30\n",
      "84/84 [==============================] - 100s 1s/step - loss: 0.8500 - accuracy: 0.7038 - val_loss: 2.4558 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "84/84 [==============================] - 100s 1s/step - loss: 0.7405 - accuracy: 0.7150 - val_loss: 1.6809 - val_accuracy: 0.4062\n",
      "Epoch 5/30\n",
      "84/84 [==============================] - 100s 1s/step - loss: 0.6875 - accuracy: 0.7613 - val_loss: 1.6068 - val_accuracy: 0.5000\n",
      "Epoch 6/30\n",
      "84/84 [==============================] - 100s 1s/step - loss: 0.5707 - accuracy: 0.7829 - val_loss: 0.9870 - val_accuracy: 0.6875\n",
      "Epoch 7/30\n",
      "84/84 [==============================] - 100s 1s/step - loss: 0.4624 - accuracy: 0.8341 - val_loss: 1.8685 - val_accuracy: 0.2812\n",
      "Epoch 8/30\n",
      "84/84 [==============================] - 100s 1s/step - loss: 0.3947 - accuracy: 0.8524 - val_loss: 1.7721 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "84/84 [==============================] - 100s 1s/step - loss: 0.3321 - accuracy: 0.8788 - val_loss: 0.6101 - val_accuracy: 0.6562\n",
      "Epoch 10/30\n",
      "84/84 [==============================] - 100s 1s/step - loss: 0.2774 - accuracy: 0.9041 - val_loss: 0.3677 - val_accuracy: 0.8438\n",
      "Epoch 11/30\n",
      "84/84 [==============================] - 100s 1s/step - loss: 0.1991 - accuracy: 0.9346 - val_loss: 0.3374 - val_accuracy: 0.8438\n",
      "Epoch 12/30\n",
      "84/84 [==============================] - 100s 1s/step - loss: 0.1271 - accuracy: 0.9525 - val_loss: 1.7968 - val_accuracy: 0.6875\n",
      "Epoch 13/30\n",
      "84/84 [==============================] - 100s 1s/step - loss: 0.1477 - accuracy: 0.9461 - val_loss: 0.4428 - val_accuracy: 0.7812\n",
      "Epoch 14/30\n",
      "84/84 [==============================] - 100s 1s/step - loss: 0.0903 - accuracy: 0.9671 - val_loss: 0.7985 - val_accuracy: 0.7812\n",
      "Epoch 15/30\n",
      "84/84 [==============================] - 100s 1s/step - loss: 0.0431 - accuracy: 0.9884 - val_loss: 0.3607 - val_accuracy: 0.9375\n",
      "Epoch 16/30\n",
      "84/84 [==============================] - 100s 1s/step - loss: 0.0674 - accuracy: 0.9724 - val_loss: 0.2643 - val_accuracy: 0.9688\n",
      "Epoch 17/30\n",
      "84/84 [==============================] - 100s 1s/step - loss: 0.0202 - accuracy: 0.9939 - val_loss: 0.5920 - val_accuracy: 0.9062\n",
      "Epoch 18/30\n",
      "84/84 [==============================] - 100s 1s/step - loss: 0.0162 - accuracy: 0.9948 - val_loss: 0.6612 - val_accuracy: 0.9062\n",
      "Epoch 19/30\n",
      "84/84 [==============================] - 100s 1s/step - loss: 0.0210 - accuracy: 0.9948 - val_loss: 0.4529 - val_accuracy: 0.9688\n",
      "Epoch 20/30\n",
      "84/84 [==============================] - 100s 1s/step - loss: 0.0099 - accuracy: 0.9978 - val_loss: 0.3158 - val_accuracy: 0.9688\n",
      "Epoch 21/30\n",
      "84/84 [==============================] - 100s 1s/step - loss: 0.0075 - accuracy: 0.9983 - val_loss: 0.4657 - val_accuracy: 0.9375\n",
      "Epoch 22/30\n",
      "84/84 [==============================] - 100s 1s/step - loss: 0.0031 - accuracy: 0.9989 - val_loss: 0.5352 - val_accuracy: 0.9062\n",
      "Epoch 23/30\n",
      "84/84 [==============================] - 100s 1s/step - loss: 0.0027 - accuracy: 0.9997 - val_loss: 0.5854 - val_accuracy: 0.9375\n",
      "Epoch 24/30\n",
      "84/84 [==============================] - 100s 1s/step - loss: 0.0030 - accuracy: 0.9993 - val_loss: 0.5373 - val_accuracy: 0.9688\n",
      "Epoch 25/30\n",
      "84/84 [==============================] - 100s 1s/step - loss: 0.0024 - accuracy: 0.9989 - val_loss: 0.5145 - val_accuracy: 0.9375\n",
      "Epoch 26/30\n",
      "84/84 [==============================] - 101s 1s/step - loss: 0.0026 - accuracy: 0.9992 - val_loss: 0.5251 - val_accuracy: 0.9375\n",
      "Epoch 27/30\n",
      "84/84 [==============================] - 100s 1s/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.5951 - val_accuracy: 0.9688\n",
      "Epoch 28/30\n",
      "84/84 [==============================] - 100s 1s/step - loss: 0.0012 - accuracy: 0.9999 - val_loss: 0.6194 - val_accuracy: 0.9062\n",
      "Epoch 29/30\n",
      "84/84 [==============================] - 100s 1s/step - loss: 0.0018 - accuracy: 0.9998 - val_loss: 0.5457 - val_accuracy: 0.9375\n",
      "Epoch 30/30\n",
      "84/84 [==============================] - 101s 1s/step - loss: 0.0024 - accuracy: 0.9993 - val_loss: 0.6236 - val_accuracy: 0.9375\n",
      "INFO:tensorflow:Assets written to: ../opticnet/opticnet_30epochs_4174.2_images_True_newWeights_False_lastLayerOnly_rescale-symmetric_normalization/assets\n",
      "Test acc for opticnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.07376021 0.07496304 0.07701798 0.07625348]\n",
      "Training xception for 0.075% of train size (aka 6261 images) with pretrained: False and onlyLastLayersTrained: False...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/126 [>.............................] - ETA: 1:12 - loss: 1.3853 - accuracy: 0.3531WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1395s vs `on_train_batch_begin` time: 0.1665s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1395s vs `on_train_batch_end` time: 0.2216s). Check your callbacks.\n",
      "126/126 [==============================] - 24s 169ms/step - loss: 1.3631 - accuracy: 0.4446 - val_loss: 1.4020 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "126/126 [==============================] - 18s 145ms/step - loss: 1.2958 - accuracy: 0.4515 - val_loss: 1.4315 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "126/126 [==============================] - 18s 145ms/step - loss: 1.2610 - accuracy: 0.4516 - val_loss: 1.4597 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "126/126 [==============================] - 18s 143ms/step - loss: 1.2509 - accuracy: 0.4435 - val_loss: 1.4831 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "126/126 [==============================] - 18s 143ms/step - loss: 1.2399 - accuracy: 0.4482 - val_loss: 1.5011 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "126/126 [==============================] - 18s 144ms/step - loss: 1.2369 - accuracy: 0.4415 - val_loss: 1.5139 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "126/126 [==============================] - 18s 145ms/step - loss: 1.2305 - accuracy: 0.4475 - val_loss: 1.5234 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "126/126 [==============================] - 18s 147ms/step - loss: 1.2396 - accuracy: 0.4409 - val_loss: 1.5296 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "126/126 [==============================] - 18s 145ms/step - loss: 1.2353 - accuracy: 0.4455 - val_loss: 1.5341 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "126/126 [==============================] - 18s 145ms/step - loss: 1.2313 - accuracy: 0.4446 - val_loss: 1.5378 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "126/126 [==============================] - 19s 148ms/step - loss: 1.2348 - accuracy: 0.4429 - val_loss: 1.5401 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "126/126 [==============================] - 18s 143ms/step - loss: 1.2394 - accuracy: 0.4510 - val_loss: 1.5421 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "126/126 [==============================] - 18s 146ms/step - loss: 1.2361 - accuracy: 0.4431 - val_loss: 1.5439 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "126/126 [==============================] - 18s 146ms/step - loss: 1.2380 - accuracy: 0.4351 - val_loss: 1.5442 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "126/126 [==============================] - 18s 145ms/step - loss: 1.2542 - accuracy: 0.4324 - val_loss: 1.5451 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "126/126 [==============================] - 18s 144ms/step - loss: 1.2407 - accuracy: 0.4421 - val_loss: 1.5464 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "126/126 [==============================] - 18s 145ms/step - loss: 1.2282 - accuracy: 0.4543 - val_loss: 1.5467 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "126/126 [==============================] - 18s 144ms/step - loss: 1.2347 - accuracy: 0.4451 - val_loss: 1.5471 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "126/126 [==============================] - 18s 146ms/step - loss: 1.2436 - accuracy: 0.4422 - val_loss: 1.5471 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "126/126 [==============================] - 18s 145ms/step - loss: 1.2385 - accuracy: 0.4390 - val_loss: 1.5480 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "126/126 [==============================] - 18s 146ms/step - loss: 1.2409 - accuracy: 0.4395 - val_loss: 1.5480 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "126/126 [==============================] - 18s 145ms/step - loss: 1.2338 - accuracy: 0.4468 - val_loss: 1.5483 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "126/126 [==============================] - 18s 146ms/step - loss: 1.2236 - accuracy: 0.4611 - val_loss: 1.5483 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "126/126 [==============================] - 18s 146ms/step - loss: 1.2383 - accuracy: 0.4484 - val_loss: 1.5485 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "126/126 [==============================] - 18s 140ms/step - loss: 1.2396 - accuracy: 0.4408 - val_loss: 1.5485 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "126/126 [==============================] - 18s 143ms/step - loss: 1.2315 - accuracy: 0.4486 - val_loss: 1.5488 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "126/126 [==============================] - 18s 143ms/step - loss: 1.2421 - accuracy: 0.4429 - val_loss: 1.5488 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "126/126 [==============================] - 18s 143ms/step - loss: 1.2214 - accuracy: 0.4588 - val_loss: 1.5489 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "126/126 [==============================] - 18s 143ms/step - loss: 1.2301 - accuracy: 0.4474 - val_loss: 1.5491 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "126/126 [==============================] - 18s 141ms/step - loss: 1.2301 - accuracy: 0.4517 - val_loss: 1.5491 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../xception/xception_30epochs_6261.3_images_True_newWeights_False_lastLayerOnly_rescale-symmetric_normalization/assets\n",
      "Test acc for xception: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training resnet for 0.075% of train size (aka 6261 images) with pretrained: False and onlyLastLayersTrained: False...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/126 [>.............................] - ETA: 1:05 - loss: 1.3839 - accuracy: 0.1975WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0771s vs `on_train_batch_begin` time: 0.1979s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0771s vs `on_train_batch_end` time: 0.1947s). Check your callbacks.\n",
      "126/126 [==============================] - 17s 102ms/step - loss: 1.3427 - accuracy: 0.3948 - val_loss: 1.4144 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "126/126 [==============================] - 9s 73ms/step - loss: 1.2749 - accuracy: 0.4477 - val_loss: 1.4473 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "126/126 [==============================] - 9s 75ms/step - loss: 1.2533 - accuracy: 0.4417 - val_loss: 1.4755 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "126/126 [==============================] - 10s 76ms/step - loss: 1.2415 - accuracy: 0.4462 - val_loss: 1.4966 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "126/126 [==============================] - 10s 77ms/step - loss: 1.2394 - accuracy: 0.4412 - val_loss: 1.5114 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "126/126 [==============================] - 9s 74ms/step - loss: 1.2357 - accuracy: 0.4392 - val_loss: 1.5224 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "126/126 [==============================] - 10s 78ms/step - loss: 1.2343 - accuracy: 0.4429 - val_loss: 1.5295 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "126/126 [==============================] - 9s 74ms/step - loss: 1.2272 - accuracy: 0.4479 - val_loss: 1.5344 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "126/126 [==============================] - 10s 76ms/step - loss: 1.2358 - accuracy: 0.4480 - val_loss: 1.5381 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "126/126 [==============================] - 9s 75ms/step - loss: 1.2366 - accuracy: 0.4465 - val_loss: 1.5407 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "126/126 [==============================] - 9s 74ms/step - loss: 1.2432 - accuracy: 0.4388 - val_loss: 1.5424 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "126/126 [==============================] - 9s 75ms/step - loss: 1.2321 - accuracy: 0.4537 - val_loss: 1.5437 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "126/126 [==============================] - 10s 77ms/step - loss: 1.2363 - accuracy: 0.4404 - val_loss: 1.5457 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "126/126 [==============================] - 9s 75ms/step - loss: 1.2320 - accuracy: 0.4508 - val_loss: 1.5462 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "126/126 [==============================] - 10s 79ms/step - loss: 1.2460 - accuracy: 0.4405 - val_loss: 1.5468 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "126/126 [==============================] - 10s 76ms/step - loss: 1.2327 - accuracy: 0.4442 - val_loss: 1.5477 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "126/126 [==============================] - 10s 78ms/step - loss: 1.2318 - accuracy: 0.4470 - val_loss: 1.5479 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "126/126 [==============================] - 10s 76ms/step - loss: 1.2361 - accuracy: 0.4372 - val_loss: 1.5484 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "126/126 [==============================] - 10s 76ms/step - loss: 1.2389 - accuracy: 0.4382 - val_loss: 1.5485 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "126/126 [==============================] - 9s 73ms/step - loss: 1.2280 - accuracy: 0.4511 - val_loss: 1.5486 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "126/126 [==============================] - 10s 75ms/step - loss: 1.2385 - accuracy: 0.4499 - val_loss: 1.5487 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "126/126 [==============================] - 9s 75ms/step - loss: 1.2363 - accuracy: 0.4490 - val_loss: 1.5486 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "126/126 [==============================] - 9s 74ms/step - loss: 1.2311 - accuracy: 0.4523 - val_loss: 1.5487 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "126/126 [==============================] - 10s 76ms/step - loss: 1.2373 - accuracy: 0.4480 - val_loss: 1.5489 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "126/126 [==============================] - 9s 74ms/step - loss: 1.2230 - accuracy: 0.4536 - val_loss: 1.5489 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "126/126 [==============================] - 9s 75ms/step - loss: 1.2387 - accuracy: 0.4429 - val_loss: 1.5490 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "126/126 [==============================] - 9s 74ms/step - loss: 1.2289 - accuracy: 0.4449 - val_loss: 1.5492 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "126/126 [==============================] - 9s 73ms/step - loss: 1.2398 - accuracy: 0.4443 - val_loss: 1.5492 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "126/126 [==============================] - 10s 76ms/step - loss: 1.2416 - accuracy: 0.4450 - val_loss: 1.5493 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "126/126 [==============================] - 9s 75ms/step - loss: 1.2297 - accuracy: 0.4469 - val_loss: 1.5493 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_6261.3_images_True_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training opticnet for 0.075% of train size (aka 6261 images) with pretrained: False and onlyLastLayersTrained: False...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/126 [>.............................] - ETA: 3:40 - loss: 28.8445 - accuracy: 0.3444WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.4782s vs `on_train_batch_end` time: 1.0971s). Check your callbacks.\n",
      "126/126 [==============================] - 169s 1s/step - loss: 7.9734 - accuracy: 0.3621 - val_loss: 2.9969 - val_accuracy: 0.3125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "126/126 [==============================] - 149s 1s/step - loss: 1.0527 - accuracy: 0.6354 - val_loss: 1.2761 - val_accuracy: 0.4688\n",
      "Epoch 3/30\n",
      "126/126 [==============================] - 149s 1s/step - loss: 0.7118 - accuracy: 0.7542 - val_loss: 2.3716 - val_accuracy: 0.4062\n",
      "Epoch 4/30\n",
      "126/126 [==============================] - 150s 1s/step - loss: 0.6511 - accuracy: 0.7669 - val_loss: 0.5905 - val_accuracy: 0.7188\n",
      "Epoch 5/30\n",
      "126/126 [==============================] - 150s 1s/step - loss: 0.4918 - accuracy: 0.8319 - val_loss: 1.3503 - val_accuracy: 0.4688\n",
      "Epoch 6/30\n",
      "126/126 [==============================] - 149s 1s/step - loss: 0.4272 - accuracy: 0.8524 - val_loss: 0.5929 - val_accuracy: 0.8125\n",
      "Epoch 7/30\n",
      "126/126 [==============================] - 150s 1s/step - loss: 0.3372 - accuracy: 0.8804 - val_loss: 2.0130 - val_accuracy: 0.4688\n",
      "Epoch 8/30\n",
      "126/126 [==============================] - 150s 1s/step - loss: 0.3081 - accuracy: 0.8930 - val_loss: 0.2065 - val_accuracy: 0.9375\n",
      "Epoch 9/30\n",
      "126/126 [==============================] - 150s 1s/step - loss: 0.2656 - accuracy: 0.9057 - val_loss: 0.1240 - val_accuracy: 0.9688\n",
      "Epoch 10/30\n",
      "126/126 [==============================] - 150s 1s/step - loss: 0.1889 - accuracy: 0.9318 - val_loss: 0.8409 - val_accuracy: 0.7500\n",
      "Epoch 11/30\n",
      "126/126 [==============================] - 150s 1s/step - loss: 0.1784 - accuracy: 0.9359 - val_loss: 0.9870 - val_accuracy: 0.7188\n",
      "Epoch 12/30\n",
      "126/126 [==============================] - 150s 1s/step - loss: 0.1190 - accuracy: 0.9598 - val_loss: 0.6655 - val_accuracy: 0.9062\n",
      "Epoch 13/30\n",
      "126/126 [==============================] - 150s 1s/step - loss: 0.0711 - accuracy: 0.9761 - val_loss: 0.0196 - val_accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "126/126 [==============================] - 150s 1s/step - loss: 0.0600 - accuracy: 0.9773 - val_loss: 0.3951 - val_accuracy: 0.9062\n",
      "Epoch 15/30\n",
      "126/126 [==============================] - 150s 1s/step - loss: 0.0830 - accuracy: 0.9704 - val_loss: 0.2374 - val_accuracy: 0.9375\n",
      "Epoch 16/30\n",
      "126/126 [==============================] - 150s 1s/step - loss: 0.0431 - accuracy: 0.9882 - val_loss: 0.5622 - val_accuracy: 0.9688\n",
      "Epoch 17/30\n",
      "126/126 [==============================] - 150s 1s/step - loss: 0.0263 - accuracy: 0.9919 - val_loss: 0.0929 - val_accuracy: 0.9375\n",
      "Epoch 18/30\n",
      "126/126 [==============================] - 150s 1s/step - loss: 0.0126 - accuracy: 0.9970 - val_loss: 0.2871 - val_accuracy: 0.9375\n",
      "Epoch 19/30\n",
      "126/126 [==============================] - 150s 1s/step - loss: 0.0174 - accuracy: 0.9944 - val_loss: 0.4410 - val_accuracy: 0.9375\n",
      "Epoch 20/30\n",
      "126/126 [==============================] - 150s 1s/step - loss: 0.0174 - accuracy: 0.9928 - val_loss: 0.4179 - val_accuracy: 0.9688\n",
      "Epoch 21/30\n",
      "126/126 [==============================] - 150s 1s/step - loss: 0.0073 - accuracy: 0.9976 - val_loss: 0.3601 - val_accuracy: 0.9688\n",
      "Epoch 22/30\n",
      "126/126 [==============================] - 150s 1s/step - loss: 0.0210 - accuracy: 0.9943 - val_loss: 0.2046 - val_accuracy: 0.9688\n",
      "Epoch 23/30\n",
      "126/126 [==============================] - 150s 1s/step - loss: 0.0092 - accuracy: 0.9966 - val_loss: 0.1857 - val_accuracy: 0.9688\n",
      "Epoch 24/30\n",
      "126/126 [==============================] - 149s 1s/step - loss: 0.0031 - accuracy: 0.9992 - val_loss: 0.2096 - val_accuracy: 0.9688\n",
      "Epoch 25/30\n",
      "126/126 [==============================] - 149s 1s/step - loss: 0.0103 - accuracy: 0.9966 - val_loss: 0.1225 - val_accuracy: 0.9688\n",
      "Epoch 26/30\n",
      "126/126 [==============================] - 150s 1s/step - loss: 0.0042 - accuracy: 0.9985 - val_loss: 0.0522 - val_accuracy: 0.9688\n",
      "Epoch 27/30\n",
      "126/126 [==============================] - 150s 1s/step - loss: 0.0027 - accuracy: 0.9994 - val_loss: 0.2556 - val_accuracy: 0.9688\n",
      "Epoch 28/30\n",
      "126/126 [==============================] - 150s 1s/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 0.2481 - val_accuracy: 0.9688\n",
      "Epoch 29/30\n",
      "126/126 [==============================] - 150s 1s/step - loss: 0.0019 - accuracy: 0.9990 - val_loss: 0.2455 - val_accuracy: 0.9688\n",
      "Epoch 30/30\n",
      "126/126 [==============================] - 150s 1s/step - loss: 0.0019 - accuracy: 0.9993 - val_loss: 0.1649 - val_accuracy: 0.9688\n",
      "INFO:tensorflow:Assets written to: ../opticnet/opticnet_30epochs_6261.3_images_True_newWeights_False_lastLayerOnly_rescale-symmetric_normalization/assets\n",
      "Test acc for opticnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.08835265 0.09025669 0.09111738 0.09238626]\n",
      "Training xception for 0.09% of train size (aka 7513 images) with pretrained: False and onlyLastLayersTrained: False...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/151 [>.............................] - ETA: 1:33 - loss: 1.3851 - accuracy: 0.2889WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1440s vs `on_train_batch_begin` time: 0.1888s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1440s vs `on_train_batch_end` time: 0.2310s). Check your callbacks.\n",
      "151/151 [==============================] - 28s 165ms/step - loss: 1.3580 - accuracy: 0.4241 - val_loss: 1.4087 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "151/151 [==============================] - 22s 142ms/step - loss: 1.2799 - accuracy: 0.4558 - val_loss: 1.4457 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "151/151 [==============================] - 22s 142ms/step - loss: 1.2552 - accuracy: 0.4434 - val_loss: 1.4782 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "151/151 [==============================] - 22s 147ms/step - loss: 1.2361 - accuracy: 0.4518 - val_loss: 1.5026 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "151/151 [==============================] - 22s 146ms/step - loss: 1.2342 - accuracy: 0.4441 - val_loss: 1.5185 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "151/151 [==============================] - 22s 147ms/step - loss: 1.2439 - accuracy: 0.4345 - val_loss: 1.5293 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "151/151 [==============================] - 22s 145ms/step - loss: 1.2407 - accuracy: 0.4379 - val_loss: 1.5352 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "151/151 [==============================] - 22s 146ms/step - loss: 1.2417 - accuracy: 0.4385 - val_loss: 1.5404 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "151/151 [==============================] - 22s 144ms/step - loss: 1.2273 - accuracy: 0.4501 - val_loss: 1.5441 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "151/151 [==============================] - 22s 146ms/step - loss: 1.2316 - accuracy: 0.4563 - val_loss: 1.5451 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "151/151 [==============================] - 22s 145ms/step - loss: 1.2381 - accuracy: 0.4466 - val_loss: 1.5460 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "151/151 [==============================] - 22s 146ms/step - loss: 1.2295 - accuracy: 0.4533 - val_loss: 1.5474 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "151/151 [==============================] - 22s 145ms/step - loss: 1.2289 - accuracy: 0.4481 - val_loss: 1.5480 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "151/151 [==============================] - 22s 143ms/step - loss: 1.2202 - accuracy: 0.4585 - val_loss: 1.5486 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "151/151 [==============================] - 22s 145ms/step - loss: 1.2352 - accuracy: 0.4521 - val_loss: 1.5495 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "151/151 [==============================] - 22s 146ms/step - loss: 1.2365 - accuracy: 0.4484 - val_loss: 1.5499 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "151/151 [==============================] - 22s 145ms/step - loss: 1.2400 - accuracy: 0.4420 - val_loss: 1.5502 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "151/151 [==============================] - 22s 146ms/step - loss: 1.2384 - accuracy: 0.4455 - val_loss: 1.5506 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "151/151 [==============================] - 22s 145ms/step - loss: 1.2282 - accuracy: 0.4497 - val_loss: 1.5509 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "151/151 [==============================] - 22s 144ms/step - loss: 1.2359 - accuracy: 0.4495 - val_loss: 1.5507 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "151/151 [==============================] - 22s 145ms/step - loss: 1.2325 - accuracy: 0.4413 - val_loss: 1.5509 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "151/151 [==============================] - 22s 147ms/step - loss: 1.2303 - accuracy: 0.4492 - val_loss: 1.5511 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "151/151 [==============================] - 22s 145ms/step - loss: 1.2439 - accuracy: 0.4425 - val_loss: 1.5507 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "151/151 [==============================] - 22s 144ms/step - loss: 1.2355 - accuracy: 0.4420 - val_loss: 1.5506 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "151/151 [==============================] - 22s 146ms/step - loss: 1.2405 - accuracy: 0.4393 - val_loss: 1.5506 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "151/151 [==============================] - 22s 146ms/step - loss: 1.2271 - accuracy: 0.4547 - val_loss: 1.5508 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "151/151 [==============================] - 22s 144ms/step - loss: 1.2401 - accuracy: 0.4410 - val_loss: 1.5508 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "151/151 [==============================] - 22s 146ms/step - loss: 1.2282 - accuracy: 0.4558 - val_loss: 1.5509 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "151/151 [==============================] - 22s 144ms/step - loss: 1.2534 - accuracy: 0.4401 - val_loss: 1.5508 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "151/151 [==============================] - 22s 146ms/step - loss: 1.2376 - accuracy: 0.4467 - val_loss: 1.5508 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../xception/xception_30epochs_7513.5599999999995_images_True_newWeights_False_lastLayerOnly_rescale-symmetric_normalization/assets\n",
      "Test acc for xception: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training resnet for 0.09% of train size (aka 7513 images) with pretrained: False and onlyLastLayersTrained: False...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/151 [>.............................] - ETA: 1:18 - loss: 1.3776 - accuracy: 0.3283WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0814s vs `on_train_batch_begin` time: 0.2028s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0814s vs `on_train_batch_end` time: 0.1844s). Check your callbacks.\n",
      "151/151 [==============================] - 19s 101ms/step - loss: 1.3339 - accuracy: 0.4403 - val_loss: 1.4223 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "151/151 [==============================] - 12s 80ms/step - loss: 1.2673 - accuracy: 0.4505 - val_loss: 1.4608 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "151/151 [==============================] - 11s 76ms/step - loss: 1.2525 - accuracy: 0.4402 - val_loss: 1.4919 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "151/151 [==============================] - 11s 74ms/step - loss: 1.2479 - accuracy: 0.4332 - val_loss: 1.5140 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "151/151 [==============================] - 12s 77ms/step - loss: 1.2301 - accuracy: 0.4498 - val_loss: 1.5269 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "151/151 [==============================] - 11s 76ms/step - loss: 1.2335 - accuracy: 0.4471 - val_loss: 1.5354 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "151/151 [==============================] - 12s 79ms/step - loss: 1.2420 - accuracy: 0.4393 - val_loss: 1.5406 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "151/151 [==============================] - 12s 78ms/step - loss: 1.2328 - accuracy: 0.4573 - val_loss: 1.5433 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "151/151 [==============================] - 12s 77ms/step - loss: 1.2320 - accuracy: 0.4414 - val_loss: 1.5465 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "151/151 [==============================] - 11s 76ms/step - loss: 1.2376 - accuracy: 0.4388 - val_loss: 1.5469 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "151/151 [==============================] - 11s 75ms/step - loss: 1.2321 - accuracy: 0.4447 - val_loss: 1.5483 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "151/151 [==============================] - 12s 77ms/step - loss: 1.2311 - accuracy: 0.4487 - val_loss: 1.5485 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "151/151 [==============================] - 12s 77ms/step - loss: 1.2339 - accuracy: 0.4479 - val_loss: 1.5494 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "151/151 [==============================] - 12s 77ms/step - loss: 1.2475 - accuracy: 0.4395 - val_loss: 1.5496 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "151/151 [==============================] - 12s 77ms/step - loss: 1.2321 - accuracy: 0.4496 - val_loss: 1.5504 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "151/151 [==============================] - 12s 78ms/step - loss: 1.2433 - accuracy: 0.4379 - val_loss: 1.5506 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "151/151 [==============================] - 12s 79ms/step - loss: 1.2299 - accuracy: 0.4474 - val_loss: 1.5511 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "151/151 [==============================] - 12s 79ms/step - loss: 1.2305 - accuracy: 0.4480 - val_loss: 1.5511 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "151/151 [==============================] - 12s 78ms/step - loss: 1.2479 - accuracy: 0.4430 - val_loss: 1.5510 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "151/151 [==============================] - 12s 77ms/step - loss: 1.2378 - accuracy: 0.4441 - val_loss: 1.5511 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "151/151 [==============================] - 12s 78ms/step - loss: 1.2267 - accuracy: 0.4564 - val_loss: 1.5513 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "151/151 [==============================] - 12s 77ms/step - loss: 1.2354 - accuracy: 0.4425 - val_loss: 1.5512 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "151/151 [==============================] - 12s 76ms/step - loss: 1.2504 - accuracy: 0.4400 - val_loss: 1.5511 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "151/151 [==============================] - 12s 79ms/step - loss: 1.2257 - accuracy: 0.4572 - val_loss: 1.5512 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "151/151 [==============================] - 12s 77ms/step - loss: 1.2349 - accuracy: 0.4495 - val_loss: 1.5513 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "151/151 [==============================] - 12s 77ms/step - loss: 1.2337 - accuracy: 0.4465 - val_loss: 1.5513 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "151/151 [==============================] - 11s 76ms/step - loss: 1.2315 - accuracy: 0.4448 - val_loss: 1.5514 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "151/151 [==============================] - 12s 78ms/step - loss: 1.2280 - accuracy: 0.4509 - val_loss: 1.5514 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "151/151 [==============================] - 12s 77ms/step - loss: 1.2283 - accuracy: 0.4534 - val_loss: 1.5514 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "151/151 [==============================] - 11s 75ms/step - loss: 1.2359 - accuracy: 0.4409 - val_loss: 1.5515 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_7513.5599999999995_images_True_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training opticnet for 0.09% of train size (aka 7513 images) with pretrained: False and onlyLastLayersTrained: False...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/151 [>.............................] - ETA: 4:42 - loss: 18.7225 - accuracy: 0.2169WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.4786s vs `on_train_batch_end` time: 1.1302s). Check your callbacks.\n",
      "151/151 [==============================] - 199s 1s/step - loss: 7.2192 - accuracy: 0.3642 - val_loss: 4.3627 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "151/151 [==============================] - 180s 1s/step - loss: 1.0810 - accuracy: 0.6222 - val_loss: 1.8751 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "151/151 [==============================] - 180s 1s/step - loss: 0.7488 - accuracy: 0.7291 - val_loss: 1.3923 - val_accuracy: 0.4062\n",
      "Epoch 4/30\n",
      "151/151 [==============================] - 179s 1s/step - loss: 0.6996 - accuracy: 0.7668 - val_loss: 1.8304 - val_accuracy: 0.3125\n",
      "Epoch 5/30\n",
      "151/151 [==============================] - 179s 1s/step - loss: 0.4712 - accuracy: 0.8258 - val_loss: 0.2762 - val_accuracy: 0.8750\n",
      "Epoch 6/30\n",
      "151/151 [==============================] - 179s 1s/step - loss: 0.4135 - accuracy: 0.8556 - val_loss: 0.1923 - val_accuracy: 0.9062\n",
      "Epoch 7/30\n",
      "151/151 [==============================] - 179s 1s/step - loss: 0.3041 - accuracy: 0.8948 - val_loss: 0.1957 - val_accuracy: 0.9062\n",
      "Epoch 8/30\n",
      "151/151 [==============================] - 180s 1s/step - loss: 0.2660 - accuracy: 0.9072 - val_loss: 0.1667 - val_accuracy: 0.9062\n",
      "Epoch 9/30\n",
      "151/151 [==============================] - 179s 1s/step - loss: 0.2447 - accuracy: 0.9211 - val_loss: 0.1661 - val_accuracy: 0.9375\n",
      "Epoch 10/30\n",
      "151/151 [==============================] - 180s 1s/step - loss: 0.1727 - accuracy: 0.9387 - val_loss: 0.1869 - val_accuracy: 0.9375\n",
      "Epoch 11/30\n",
      "151/151 [==============================] - 180s 1s/step - loss: 0.1638 - accuracy: 0.9449 - val_loss: 0.0325 - val_accuracy: 1.0000\n",
      "Epoch 12/30\n",
      "151/151 [==============================] - 180s 1s/step - loss: 0.2080 - accuracy: 0.9300 - val_loss: 0.4535 - val_accuracy: 0.9062\n",
      "Epoch 13/30\n",
      "151/151 [==============================] - 179s 1s/step - loss: 0.1164 - accuracy: 0.9609 - val_loss: 0.0836 - val_accuracy: 0.9688\n",
      "Epoch 14/30\n",
      "151/151 [==============================] - 180s 1s/step - loss: 0.0841 - accuracy: 0.9742 - val_loss: 0.0102 - val_accuracy: 1.0000\n",
      "Epoch 15/30\n",
      "151/151 [==============================] - 179s 1s/step - loss: 0.0658 - accuracy: 0.9765 - val_loss: 0.0619 - val_accuracy: 0.9688\n",
      "Epoch 16/30\n",
      "151/151 [==============================] - 179s 1s/step - loss: 0.0683 - accuracy: 0.9758 - val_loss: 0.0502 - val_accuracy: 0.9688\n",
      "Epoch 17/30\n",
      "151/151 [==============================] - 179s 1s/step - loss: 0.0395 - accuracy: 0.9861 - val_loss: 0.1458 - val_accuracy: 0.9688\n",
      "Epoch 18/30\n",
      "151/151 [==============================] - 180s 1s/step - loss: 0.0477 - accuracy: 0.9849 - val_loss: 0.0131 - val_accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "151/151 [==============================] - 180s 1s/step - loss: 0.0126 - accuracy: 0.9970 - val_loss: 0.0093 - val_accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "151/151 [==============================] - 180s 1s/step - loss: 0.0166 - accuracy: 0.9943 - val_loss: 0.0813 - val_accuracy: 0.9688\n",
      "Epoch 21/30\n",
      "151/151 [==============================] - 179s 1s/step - loss: 0.0045 - accuracy: 0.9988 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "151/151 [==============================] - 180s 1s/step - loss: 0.0049 - accuracy: 0.9987 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "151/151 [==============================] - 179s 1s/step - loss: 0.0053 - accuracy: 0.9983 - val_loss: 0.0735 - val_accuracy: 0.9688\n",
      "Epoch 24/30\n",
      "151/151 [==============================] - 179s 1s/step - loss: 0.0100 - accuracy: 0.9965 - val_loss: 0.0695 - val_accuracy: 0.9375\n",
      "Epoch 25/30\n",
      "151/151 [==============================] - 179s 1s/step - loss: 0.0053 - accuracy: 0.9986 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "151/151 [==============================] - 180s 1s/step - loss: 0.0058 - accuracy: 0.9990 - val_loss: 0.0092 - val_accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "151/151 [==============================] - 178s 1s/step - loss: 0.0037 - accuracy: 0.9987 - val_loss: 8.4483e-04 - val_accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "151/151 [==============================] - 179s 1s/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 8.0580e-05 - val_accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "151/151 [==============================] - 179s 1s/step - loss: 0.0036 - accuracy: 0.9988 - val_loss: 2.1094e-04 - val_accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "151/151 [==============================] - 180s 1s/step - loss: 8.2865e-04 - accuracy: 0.9998 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
      "INFO:tensorflow:Assets written to: ../opticnet/opticnet_30epochs_7513.5599999999995_images_True_newWeights_False_lastLayerOnly_rescale-symmetric_normalization/assets\n",
      "Test acc for opticnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.09777693 0.10020159 0.10133944 0.10410864]\n",
      "Training xception for 0.1% of train size (aka 8348 images) with pretrained: False and onlyLastLayersTrained: False...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/167 [>.............................] - ETA: 1:45 - loss: 1.3854 - accuracy: 0.3472WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1540s vs `on_train_batch_begin` time: 0.1890s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1540s vs `on_train_batch_end` time: 0.2282s). Check your callbacks.\n",
      "167/167 [==============================] - 30s 162ms/step - loss: 1.3563 - accuracy: 0.4376 - val_loss: 1.4131 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "167/167 [==============================] - 24s 142ms/step - loss: 1.2808 - accuracy: 0.4500 - val_loss: 1.4564 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "167/167 [==============================] - 24s 141ms/step - loss: 1.2543 - accuracy: 0.4403 - val_loss: 1.4909 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "167/167 [==============================] - 24s 142ms/step - loss: 1.2301 - accuracy: 0.4600 - val_loss: 1.5132 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "167/167 [==============================] - 24s 143ms/step - loss: 1.2380 - accuracy: 0.4496 - val_loss: 1.5261 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "167/167 [==============================] - 24s 142ms/step - loss: 1.2331 - accuracy: 0.4522 - val_loss: 1.5346 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "167/167 [==============================] - 24s 144ms/step - loss: 1.2439 - accuracy: 0.4401 - val_loss: 1.5390 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "167/167 [==============================] - 24s 143ms/step - loss: 1.2412 - accuracy: 0.4426 - val_loss: 1.5422 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "167/167 [==============================] - 24s 142ms/step - loss: 1.2363 - accuracy: 0.4511 - val_loss: 1.5444 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "167/167 [==============================] - 24s 143ms/step - loss: 1.2363 - accuracy: 0.4433 - val_loss: 1.5463 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "167/167 [==============================] - 24s 141ms/step - loss: 1.2496 - accuracy: 0.4410 - val_loss: 1.5464 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "167/167 [==============================] - 24s 143ms/step - loss: 1.2420 - accuracy: 0.4461 - val_loss: 1.5469 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "167/167 [==============================] - 24s 143ms/step - loss: 1.2339 - accuracy: 0.4509 - val_loss: 1.5476 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "167/167 [==============================] - 24s 143ms/step - loss: 1.2236 - accuracy: 0.4576 - val_loss: 1.5480 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "167/167 [==============================] - 24s 143ms/step - loss: 1.2312 - accuracy: 0.4496 - val_loss: 1.5480 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "167/167 [==============================] - 24s 142ms/step - loss: 1.2411 - accuracy: 0.4463 - val_loss: 1.5476 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "167/167 [==============================] - 24s 144ms/step - loss: 1.2367 - accuracy: 0.4424 - val_loss: 1.5478 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "167/167 [==============================] - 24s 145ms/step - loss: 1.2326 - accuracy: 0.4509 - val_loss: 1.5479 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "167/167 [==============================] - 24s 145ms/step - loss: 1.2378 - accuracy: 0.4442 - val_loss: 1.5483 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "167/167 [==============================] - 24s 147ms/step - loss: 1.2358 - accuracy: 0.4472 - val_loss: 1.5481 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "167/167 [==============================] - 24s 143ms/step - loss: 1.2326 - accuracy: 0.4486 - val_loss: 1.5483 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "167/167 [==============================] - 24s 144ms/step - loss: 1.2377 - accuracy: 0.4460 - val_loss: 1.5483 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "167/167 [==============================] - 24s 143ms/step - loss: 1.2297 - accuracy: 0.4545 - val_loss: 1.5482 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "167/167 [==============================] - 24s 146ms/step - loss: 1.2378 - accuracy: 0.4362 - val_loss: 1.5481 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "167/167 [==============================] - 25s 147ms/step - loss: 1.2385 - accuracy: 0.4462 - val_loss: 1.5483 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "167/167 [==============================] - 24s 145ms/step - loss: 1.2329 - accuracy: 0.4422 - val_loss: 1.5483 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "167/167 [==============================] - 24s 145ms/step - loss: 1.2396 - accuracy: 0.4452 - val_loss: 1.5482 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "167/167 [==============================] - 24s 145ms/step - loss: 1.2250 - accuracy: 0.4549 - val_loss: 1.5482 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "167/167 [==============================] - 24s 141ms/step - loss: 1.2300 - accuracy: 0.4445 - val_loss: 1.5482 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "167/167 [==============================] - 24s 145ms/step - loss: 1.2451 - accuracy: 0.4409 - val_loss: 1.5482 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../xception/xception_30epochs_8348.4_images_True_newWeights_False_lastLayerOnly_rescale-symmetric_normalization/assets\n",
      "Test acc for xception: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training resnet for 0.1% of train size (aka 8348 images) with pretrained: False and onlyLastLayersTrained: False...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/167 [>.............................] - ETA: 1:30 - loss: 1.3771 - accuracy: 0.3156WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0715s vs `on_train_batch_begin` time: 0.2005s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0715s vs `on_train_batch_end` time: 0.2083s). Check your callbacks.\n",
      "167/167 [==============================] - 21s 100ms/step - loss: 1.3385 - accuracy: 0.4329 - val_loss: 1.4226 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "167/167 [==============================] - 13s 76ms/step - loss: 1.2635 - accuracy: 0.4516 - val_loss: 1.4651 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "167/167 [==============================] - 13s 77ms/step - loss: 1.2472 - accuracy: 0.4408 - val_loss: 1.4977 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "167/167 [==============================] - 13s 76ms/step - loss: 1.2401 - accuracy: 0.4490 - val_loss: 1.5175 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "167/167 [==============================] - 13s 79ms/step - loss: 1.2365 - accuracy: 0.4495 - val_loss: 1.5293 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "167/167 [==============================] - 13s 78ms/step - loss: 1.2340 - accuracy: 0.4483 - val_loss: 1.5362 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "167/167 [==============================] - 13s 78ms/step - loss: 1.2439 - accuracy: 0.4370 - val_loss: 1.5409 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "167/167 [==============================] - 13s 77ms/step - loss: 1.2395 - accuracy: 0.4462 - val_loss: 1.5439 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "167/167 [==============================] - 13s 78ms/step - loss: 1.2348 - accuracy: 0.4449 - val_loss: 1.5455 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "167/167 [==============================] - 13s 79ms/step - loss: 1.2361 - accuracy: 0.4451 - val_loss: 1.5465 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "167/167 [==============================] - 13s 76ms/step - loss: 1.2359 - accuracy: 0.4463 - val_loss: 1.5467 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "167/167 [==============================] - 13s 76ms/step - loss: 1.2403 - accuracy: 0.4394 - val_loss: 1.5475 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "167/167 [==============================] - 12s 74ms/step - loss: 1.2319 - accuracy: 0.4526 - val_loss: 1.5477 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "167/167 [==============================] - 12s 74ms/step - loss: 1.2336 - accuracy: 0.4458 - val_loss: 1.5482 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "167/167 [==============================] - 13s 75ms/step - loss: 1.2381 - accuracy: 0.4403 - val_loss: 1.5483 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "167/167 [==============================] - 12s 75ms/step - loss: 1.2335 - accuracy: 0.4506 - val_loss: 1.5484 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "167/167 [==============================] - 13s 77ms/step - loss: 1.2224 - accuracy: 0.4574 - val_loss: 1.5483 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "167/167 [==============================] - 12s 74ms/step - loss: 1.2313 - accuracy: 0.4485 - val_loss: 1.5482 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "167/167 [==============================] - 13s 77ms/step - loss: 1.2400 - accuracy: 0.4442 - val_loss: 1.5483 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "167/167 [==============================] - 13s 77ms/step - loss: 1.2315 - accuracy: 0.4466 - val_loss: 1.5484 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "167/167 [==============================] - 13s 76ms/step - loss: 1.2353 - accuracy: 0.4426 - val_loss: 1.5485 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "167/167 [==============================] - 13s 76ms/step - loss: 1.2281 - accuracy: 0.4460 - val_loss: 1.5485 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "167/167 [==============================] - 13s 76ms/step - loss: 1.2465 - accuracy: 0.4340 - val_loss: 1.5485 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "167/167 [==============================] - 13s 77ms/step - loss: 1.2428 - accuracy: 0.4448 - val_loss: 1.5486 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "167/167 [==============================] - 13s 76ms/step - loss: 1.2344 - accuracy: 0.4452 - val_loss: 1.5487 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "167/167 [==============================] - 12s 73ms/step - loss: 1.2293 - accuracy: 0.4498 - val_loss: 1.5488 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "167/167 [==============================] - 13s 75ms/step - loss: 1.2292 - accuracy: 0.4418 - val_loss: 1.5487 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "167/167 [==============================] - 13s 77ms/step - loss: 1.2297 - accuracy: 0.4506 - val_loss: 1.5487 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "167/167 [==============================] - 13s 75ms/step - loss: 1.2316 - accuracy: 0.4468 - val_loss: 1.5488 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "167/167 [==============================] - 13s 76ms/step - loss: 1.2246 - accuracy: 0.4545 - val_loss: 1.5488 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_8348.4_images_True_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training opticnet for 0.1% of train size (aka 8348 images) with pretrained: False and onlyLastLayersTrained: False...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/167 [>.............................] - ETA: 5:11 - loss: 13.1192 - accuracy: 0.4067WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.4864s vs `on_train_batch_end` time: 1.1156s). Check your callbacks.\n",
      "167/167 [==============================] - 218s 1s/step - loss: 5.4970 - accuracy: 0.4152 - val_loss: 2.5350 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "167/167 [==============================] - 200s 1s/step - loss: 0.8713 - accuracy: 0.6987 - val_loss: 1.4119 - val_accuracy: 0.5312\n",
      "Epoch 3/30\n",
      "167/167 [==============================] - 200s 1s/step - loss: 0.5925 - accuracy: 0.7735 - val_loss: 1.3053 - val_accuracy: 0.5312\n",
      "Epoch 4/30\n",
      "167/167 [==============================] - 200s 1s/step - loss: 0.5173 - accuracy: 0.8081 - val_loss: 1.7179 - val_accuracy: 0.5625\n",
      "Epoch 5/30\n",
      "167/167 [==============================] - 200s 1s/step - loss: 0.4186 - accuracy: 0.8504 - val_loss: 0.9856 - val_accuracy: 0.4688\n",
      "Epoch 6/30\n",
      "167/167 [==============================] - 199s 1s/step - loss: 0.3534 - accuracy: 0.8772 - val_loss: 1.1012 - val_accuracy: 0.6562\n",
      "Epoch 7/30\n",
      "167/167 [==============================] - 199s 1s/step - loss: 0.3084 - accuracy: 0.8910 - val_loss: 0.6193 - val_accuracy: 0.7500\n",
      "Epoch 8/30\n",
      "167/167 [==============================] - 199s 1s/step - loss: 0.2458 - accuracy: 0.9141 - val_loss: 0.1344 - val_accuracy: 0.9688\n",
      "Epoch 9/30\n",
      "167/167 [==============================] - 199s 1s/step - loss: 0.2040 - accuracy: 0.9274 - val_loss: 0.0846 - val_accuracy: 0.9688\n",
      "Epoch 10/30\n",
      "167/167 [==============================] - 200s 1s/step - loss: 0.1695 - accuracy: 0.9443 - val_loss: 1.5825 - val_accuracy: 0.4688\n",
      "Epoch 11/30\n",
      "167/167 [==============================] - 199s 1s/step - loss: 0.1594 - accuracy: 0.9449 - val_loss: 0.2970 - val_accuracy: 0.8750\n",
      "Epoch 12/30\n",
      "167/167 [==============================] - 200s 1s/step - loss: 0.1067 - accuracy: 0.9669 - val_loss: 0.3325 - val_accuracy: 0.8750\n",
      "Epoch 13/30\n",
      "167/167 [==============================] - 199s 1s/step - loss: 0.1033 - accuracy: 0.9649 - val_loss: 0.5945 - val_accuracy: 0.8438\n",
      "Epoch 14/30\n",
      "167/167 [==============================] - 200s 1s/step - loss: 0.0998 - accuracy: 0.9668 - val_loss: 0.4791 - val_accuracy: 0.8750\n",
      "Epoch 15/30\n",
      "167/167 [==============================] - 200s 1s/step - loss: 0.0523 - accuracy: 0.9829 - val_loss: 0.2573 - val_accuracy: 0.9688\n",
      "Epoch 16/30\n",
      "167/167 [==============================] - 200s 1s/step - loss: 0.0415 - accuracy: 0.9861 - val_loss: 0.5662 - val_accuracy: 0.8750\n",
      "Epoch 17/30\n",
      "167/167 [==============================] - 200s 1s/step - loss: 0.0484 - accuracy: 0.9850 - val_loss: 0.0317 - val_accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "167/167 [==============================] - 200s 1s/step - loss: 0.0272 - accuracy: 0.9911 - val_loss: 0.0844 - val_accuracy: 0.9688\n",
      "Epoch 19/30\n",
      "167/167 [==============================] - 199s 1s/step - loss: 0.0225 - accuracy: 0.9939 - val_loss: 0.0550 - val_accuracy: 0.9688\n",
      "Epoch 20/30\n",
      "167/167 [==============================] - 199s 1s/step - loss: 0.0137 - accuracy: 0.9959 - val_loss: 0.2096 - val_accuracy: 0.9375\n",
      "Epoch 21/30\n",
      "167/167 [==============================] - 199s 1s/step - loss: 0.0126 - accuracy: 0.9962 - val_loss: 0.0456 - val_accuracy: 0.9688\n",
      "Epoch 22/30\n",
      "167/167 [==============================] - 200s 1s/step - loss: 0.0125 - accuracy: 0.9959 - val_loss: 0.0960 - val_accuracy: 0.9688\n",
      "Epoch 23/30\n",
      "167/167 [==============================] - 200s 1s/step - loss: 0.0308 - accuracy: 0.9896 - val_loss: 0.1083 - val_accuracy: 0.9688\n",
      "Epoch 24/30\n",
      "167/167 [==============================] - 199s 1s/step - loss: 0.0081 - accuracy: 0.9979 - val_loss: 0.0956 - val_accuracy: 0.9375\n",
      "Epoch 25/30\n",
      "167/167 [==============================] - 199s 1s/step - loss: 0.0051 - accuracy: 0.9985 - val_loss: 0.0763 - val_accuracy: 0.9688\n",
      "Epoch 26/30\n",
      "167/167 [==============================] - 199s 1s/step - loss: 0.0038 - accuracy: 0.9988 - val_loss: 0.1855 - val_accuracy: 0.9375\n",
      "Epoch 27/30\n",
      "167/167 [==============================] - 199s 1s/step - loss: 0.0053 - accuracy: 0.9988 - val_loss: 0.1256 - val_accuracy: 0.9688\n",
      "Epoch 28/30\n",
      "167/167 [==============================] - 199s 1s/step - loss: 0.0044 - accuracy: 0.9989 - val_loss: 0.1146 - val_accuracy: 0.9375\n",
      "Epoch 29/30\n",
      "167/167 [==============================] - 199s 1s/step - loss: 0.0035 - accuracy: 0.9993 - val_loss: 0.0853 - val_accuracy: 0.9688\n",
      "Epoch 30/30\n",
      "167/167 [==============================] - 199s 1s/step - loss: 0.0053 - accuracy: 0.9982 - val_loss: 0.0662 - val_accuracy: 0.9688\n",
      "INFO:tensorflow:Assets written to: ../opticnet/opticnet_30epochs_8348.4_images_True_newWeights_False_lastLayerOnly_rescale-symmetric_normalization/assets\n",
      "Test acc for opticnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.24943948 0.24918694 0.24735636 0.25870474]\n",
      "Training xception for 0.25% of train size (aka 20871 images) with pretrained: False and onlyLastLayersTrained: False...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/418 [..............................] - ETA: 3:40 - loss: 1.3848 - accuracy: 0.4011WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1325s vs `on_train_batch_end` time: 0.2079s). Check your callbacks.\n",
      "418/418 [==============================] - 65s 147ms/step - loss: 1.3233 - accuracy: 0.4429 - val_loss: 1.4847 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "418/418 [==============================] - 59s 141ms/step - loss: 1.2373 - accuracy: 0.4446 - val_loss: 1.5371 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "418/418 [==============================] - 59s 142ms/step - loss: 1.2344 - accuracy: 0.4426 - val_loss: 1.5520 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "418/418 [==============================] - 60s 145ms/step - loss: 1.2356 - accuracy: 0.4407 - val_loss: 1.5534 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "418/418 [==============================] - 60s 143ms/step - loss: 1.2306 - accuracy: 0.4410 - val_loss: 1.5528 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "418/418 [==============================] - 60s 143ms/step - loss: 1.2302 - accuracy: 0.4485 - val_loss: 1.5494 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "418/418 [==============================] - 60s 144ms/step - loss: 1.2273 - accuracy: 0.4467 - val_loss: 1.5492 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "418/418 [==============================] - 61s 145ms/step - loss: 1.2302 - accuracy: 0.4423 - val_loss: 1.5489 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "418/418 [==============================] - 61s 145ms/step - loss: 1.2328 - accuracy: 0.4398 - val_loss: 1.5482 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "418/418 [==============================] - 60s 143ms/step - loss: 1.2332 - accuracy: 0.4435 - val_loss: 1.5471 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "418/418 [==============================] - 61s 145ms/step - loss: 1.2263 - accuracy: 0.4464 - val_loss: 1.5464 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "418/418 [==============================] - 60s 144ms/step - loss: 1.2274 - accuracy: 0.4483 - val_loss: 1.5451 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "418/418 [==============================] - 60s 144ms/step - loss: 1.2296 - accuracy: 0.4418 - val_loss: 1.5446 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "418/418 [==============================] - 61s 145ms/step - loss: 1.2274 - accuracy: 0.4485 - val_loss: 1.5444 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "418/418 [==============================] - 60s 144ms/step - loss: 1.2302 - accuracy: 0.4508 - val_loss: 1.5431 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "418/418 [==============================] - 60s 145ms/step - loss: 1.2270 - accuracy: 0.4459 - val_loss: 1.5435 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "418/418 [==============================] - 60s 143ms/step - loss: 1.2263 - accuracy: 0.4462 - val_loss: 1.5432 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "418/418 [==============================] - 60s 143ms/step - loss: 1.2362 - accuracy: 0.4379 - val_loss: 1.5435 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "418/418 [==============================] - 60s 144ms/step - loss: 1.2222 - accuracy: 0.4449 - val_loss: 1.5433 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "418/418 [==============================] - 60s 144ms/step - loss: 1.2390 - accuracy: 0.4325 - val_loss: 1.5433 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "418/418 [==============================] - 61s 145ms/step - loss: 1.2295 - accuracy: 0.4427 - val_loss: 1.5434 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "418/418 [==============================] - 60s 145ms/step - loss: 1.2305 - accuracy: 0.4444 - val_loss: 1.5428 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "418/418 [==============================] - 60s 145ms/step - loss: 1.2266 - accuracy: 0.4455 - val_loss: 1.5429 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "418/418 [==============================] - 60s 143ms/step - loss: 1.2272 - accuracy: 0.4458 - val_loss: 1.5429 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "418/418 [==============================] - 60s 144ms/step - loss: 1.2329 - accuracy: 0.4418 - val_loss: 1.5428 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "418/418 [==============================] - 60s 143ms/step - loss: 1.2249 - accuracy: 0.4450 - val_loss: 1.5429 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "418/418 [==============================] - 60s 144ms/step - loss: 1.2352 - accuracy: 0.4419 - val_loss: 1.5429 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "418/418 [==============================] - 60s 143ms/step - loss: 1.2245 - accuracy: 0.4460 - val_loss: 1.5427 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "418/418 [==============================] - 60s 143ms/step - loss: 1.2217 - accuracy: 0.4463 - val_loss: 1.5426 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "418/418 [==============================] - 60s 144ms/step - loss: 1.2278 - accuracy: 0.4459 - val_loss: 1.5426 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../xception/xception_30epochs_20871.0_images_True_newWeights_False_lastLayerOnly_rescale-symmetric_normalization/assets\n",
      "Test acc for xception: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training resnet for 0.25% of train size (aka 20871 images) with pretrained: False and onlyLastLayersTrained: False...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/418 [..............................] - ETA: 3:46 - loss: 1.3736 - accuracy: 0.3819WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0787s vs `on_train_batch_begin` time: 0.1955s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0787s vs `on_train_batch_end` time: 0.1985s). Check your callbacks.\n",
      "418/418 [==============================] - 39s 84ms/step - loss: 1.3108 - accuracy: 0.4170 - val_loss: 1.4906 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "418/418 [==============================] - 31s 74ms/step - loss: 1.2347 - accuracy: 0.4394 - val_loss: 1.5381 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "418/418 [==============================] - 32s 76ms/step - loss: 1.2336 - accuracy: 0.4439 - val_loss: 1.5525 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "418/418 [==============================] - 31s 75ms/step - loss: 1.2318 - accuracy: 0.4432 - val_loss: 1.5526 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "418/418 [==============================] - 31s 73ms/step - loss: 1.2328 - accuracy: 0.4416 - val_loss: 1.5531 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "418/418 [==============================] - 31s 74ms/step - loss: 1.2257 - accuracy: 0.4511 - val_loss: 1.5502 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "418/418 [==============================] - 31s 74ms/step - loss: 1.2305 - accuracy: 0.4427 - val_loss: 1.5511 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "418/418 [==============================] - 31s 74ms/step - loss: 1.2341 - accuracy: 0.4436 - val_loss: 1.5530 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "418/418 [==============================] - 31s 74ms/step - loss: 1.2351 - accuracy: 0.4387 - val_loss: 1.5526 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "418/418 [==============================] - 31s 74ms/step - loss: 1.2310 - accuracy: 0.4461 - val_loss: 1.5515 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "418/418 [==============================] - 31s 74ms/step - loss: 1.2356 - accuracy: 0.4417 - val_loss: 1.5531 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "418/418 [==============================] - 31s 75ms/step - loss: 1.2305 - accuracy: 0.4455 - val_loss: 1.5522 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "418/418 [==============================] - 31s 74ms/step - loss: 1.2390 - accuracy: 0.4356 - val_loss: 1.5536 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "418/418 [==============================] - 32s 76ms/step - loss: 1.2327 - accuracy: 0.4452 - val_loss: 1.5529 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "418/418 [==============================] - 31s 74ms/step - loss: 1.2325 - accuracy: 0.4407 - val_loss: 1.5531 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "418/418 [==============================] - 31s 75ms/step - loss: 1.2286 - accuracy: 0.4457 - val_loss: 1.5525 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "418/418 [==============================] - 31s 75ms/step - loss: 1.2300 - accuracy: 0.4468 - val_loss: 1.5526 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "418/418 [==============================] - 31s 75ms/step - loss: 1.2327 - accuracy: 0.4440 - val_loss: 1.5525 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "418/418 [==============================] - 31s 73ms/step - loss: 1.2311 - accuracy: 0.4478 - val_loss: 1.5522 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "418/418 [==============================] - 31s 74ms/step - loss: 1.2277 - accuracy: 0.4479 - val_loss: 1.5525 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "418/418 [==============================] - 31s 75ms/step - loss: 1.2279 - accuracy: 0.4487 - val_loss: 1.5524 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "418/418 [==============================] - 31s 75ms/step - loss: 1.2344 - accuracy: 0.4442 - val_loss: 1.5524 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "418/418 [==============================] - 32s 76ms/step - loss: 1.2385 - accuracy: 0.4442 - val_loss: 1.5526 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "418/418 [==============================] - 32s 75ms/step - loss: 1.2371 - accuracy: 0.4408 - val_loss: 1.5526 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "418/418 [==============================] - 31s 74ms/step - loss: 1.2262 - accuracy: 0.4471 - val_loss: 1.5527 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "418/418 [==============================] - 31s 74ms/step - loss: 1.2293 - accuracy: 0.4458 - val_loss: 1.5525 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "418/418 [==============================] - 31s 74ms/step - loss: 1.2364 - accuracy: 0.4435 - val_loss: 1.5526 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "418/418 [==============================] - 31s 74ms/step - loss: 1.2334 - accuracy: 0.4454 - val_loss: 1.5527 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "418/418 [==============================] - 31s 74ms/step - loss: 1.2301 - accuracy: 0.4462 - val_loss: 1.5526 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "418/418 [==============================] - 31s 75ms/step - loss: 1.2346 - accuracy: 0.4442 - val_loss: 1.5527 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_20871.0_images_True_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training opticnet for 0.25% of train size (aka 20871 images) with pretrained: False and onlyLastLayersTrained: False...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/418 [..............................] - ETA: 13:10 - loss: 23.6214 - accuracy: 0.2943WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.4799s vs `on_train_batch_end` time: 1.1044s). Check your callbacks.\n",
      "418/418 [==============================] - 515s 1s/step - loss: 3.0881 - accuracy: 0.5295 - val_loss: 3.5643 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "418/418 [==============================] - 499s 1s/step - loss: 0.5730 - accuracy: 0.7941 - val_loss: 0.5487 - val_accuracy: 0.7500\n",
      "Epoch 3/30\n",
      "418/418 [==============================] - 499s 1s/step - loss: 0.3449 - accuracy: 0.8855 - val_loss: 1.0052 - val_accuracy: 0.7188\n",
      "Epoch 4/30\n",
      "418/418 [==============================] - 499s 1s/step - loss: 0.2605 - accuracy: 0.9128 - val_loss: 0.7552 - val_accuracy: 0.7812\n",
      "Epoch 5/30\n",
      "418/418 [==============================] - 498s 1s/step - loss: 0.2093 - accuracy: 0.9304 - val_loss: 0.8863 - val_accuracy: 0.5938\n",
      "Epoch 6/30\n",
      "418/418 [==============================] - 497s 1s/step - loss: 0.1819 - accuracy: 0.9367 - val_loss: 0.3180 - val_accuracy: 0.8438\n",
      "Epoch 7/30\n",
      "418/418 [==============================] - 497s 1s/step - loss: 0.1702 - accuracy: 0.9422 - val_loss: 0.1481 - val_accuracy: 0.9688\n",
      "Epoch 8/30\n",
      "418/418 [==============================] - 498s 1s/step - loss: 0.1444 - accuracy: 0.9501 - val_loss: 0.0730 - val_accuracy: 0.9688\n",
      "Epoch 9/30\n",
      "418/418 [==============================] - 498s 1s/step - loss: 0.1271 - accuracy: 0.9570 - val_loss: 0.2027 - val_accuracy: 0.9062\n",
      "Epoch 10/30\n",
      "418/418 [==============================] - 499s 1s/step - loss: 0.1003 - accuracy: 0.9652 - val_loss: 0.0691 - val_accuracy: 0.9688\n",
      "Epoch 11/30\n",
      "418/418 [==============================] - 498s 1s/step - loss: 0.0784 - accuracy: 0.9726 - val_loss: 0.0771 - val_accuracy: 0.9688\n",
      "Epoch 12/30\n",
      "418/418 [==============================] - 499s 1s/step - loss: 0.0632 - accuracy: 0.9783 - val_loss: 0.0445 - val_accuracy: 1.0000\n",
      "Epoch 13/30\n",
      "418/418 [==============================] - 499s 1s/step - loss: 0.0479 - accuracy: 0.9841 - val_loss: 0.0258 - val_accuracy: 0.9688\n",
      "Epoch 14/30\n",
      "418/418 [==============================] - 498s 1s/step - loss: 0.0372 - accuracy: 0.9879 - val_loss: 1.7395 - val_accuracy: 0.8438\n",
      "Epoch 15/30\n",
      "418/418 [==============================] - 498s 1s/step - loss: 0.0328 - accuracy: 0.9891 - val_loss: 0.0593 - val_accuracy: 0.9688\n",
      "Epoch 16/30\n",
      "418/418 [==============================] - 498s 1s/step - loss: 0.0219 - accuracy: 0.9931 - val_loss: 0.0073 - val_accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "418/418 [==============================] - 499s 1s/step - loss: 0.0175 - accuracy: 0.9938 - val_loss: 0.0232 - val_accuracy: 0.9688\n",
      "Epoch 18/30\n",
      "418/418 [==============================] - 499s 1s/step - loss: 0.0133 - accuracy: 0.9955 - val_loss: 9.5304e-04 - val_accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "418/418 [==============================] - 499s 1s/step - loss: 0.0097 - accuracy: 0.9971 - val_loss: 0.0213 - val_accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "418/418 [==============================] - 499s 1s/step - loss: 0.0082 - accuracy: 0.9979 - val_loss: 0.0466 - val_accuracy: 0.9688\n",
      "Epoch 21/30\n",
      "418/418 [==============================] - 497s 1s/step - loss: 0.0100 - accuracy: 0.9975 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "418/418 [==============================] - 496s 1s/step - loss: 0.0096 - accuracy: 0.9973 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "418/418 [==============================] - 498s 1s/step - loss: 0.0095 - accuracy: 0.9981 - val_loss: 4.4946e-04 - val_accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "418/418 [==============================] - 498s 1s/step - loss: 0.0048 - accuracy: 0.9989 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "418/418 [==============================] - 500s 1s/step - loss: 0.0036 - accuracy: 0.9993 - val_loss: 4.3898e-04 - val_accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "418/418 [==============================] - 499s 1s/step - loss: 0.0040 - accuracy: 0.9988 - val_loss: 4.2223e-04 - val_accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "418/418 [==============================] - 498s 1s/step - loss: 0.0037 - accuracy: 0.9990 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "418/418 [==============================] - 498s 1s/step - loss: 0.0033 - accuracy: 0.9990 - val_loss: 2.6031e-04 - val_accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "418/418 [==============================] - 498s 1s/step - loss: 0.0042 - accuracy: 0.9985 - val_loss: 8.8021e-04 - val_accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "418/418 [==============================] - 498s 1s/step - loss: 0.0033 - accuracy: 0.9988 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
      "INFO:tensorflow:Assets written to: ../opticnet/opticnet_30epochs_20871.0_images_True_newWeights_False_lastLayerOnly_rescale-symmetric_normalization/assets\n",
      "Test acc for opticnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels fraction: [0.40068402 0.39922053 0.39813183 0.4036676 ]\n",
      "Training xception for 0.4% of train size (aka 33393 images) with pretrained: False and onlyLastLayersTrained: False...\n",
      "Epoch 1/30\n",
      "  6/668 [..............................] - ETA: 6:35 - loss: 1.3854 - accuracy: 0.2845WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1367s vs `on_train_batch_begin` time: 0.1434s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1367s vs `on_train_batch_end` time: 0.2417s). Check your callbacks.\n",
      "668/668 [==============================] - 100s 145ms/step - loss: 1.3069 - accuracy: 0.4421 - val_loss: 1.5316 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "668/668 [==============================] - 95s 142ms/step - loss: 1.2266 - accuracy: 0.4482 - val_loss: 1.5468 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "668/668 [==============================] - 96s 143ms/step - loss: 1.2270 - accuracy: 0.4468 - val_loss: 1.5520 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "668/668 [==============================] - 95s 143ms/step - loss: 1.2271 - accuracy: 0.4480 - val_loss: 1.5545 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "668/668 [==============================] - 96s 143ms/step - loss: 1.2347 - accuracy: 0.4439 - val_loss: 1.5567 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "668/668 [==============================] - 96s 143ms/step - loss: 1.2310 - accuracy: 0.4424 - val_loss: 1.5547 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "668/668 [==============================] - 96s 143ms/step - loss: 1.2300 - accuracy: 0.4443 - val_loss: 1.5524 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "668/668 [==============================] - 95s 142ms/step - loss: 1.2282 - accuracy: 0.4485 - val_loss: 1.5519 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "668/668 [==============================] - 95s 142ms/step - loss: 1.2326 - accuracy: 0.4403 - val_loss: 1.5536 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "668/668 [==============================] - 95s 143ms/step - loss: 1.2248 - accuracy: 0.4473 - val_loss: 1.5491 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "668/668 [==============================] - 96s 144ms/step - loss: 1.2250 - accuracy: 0.4450 - val_loss: 1.5483 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "668/668 [==============================] - 96s 144ms/step - loss: 1.2175 - accuracy: 0.4530 - val_loss: 1.5455 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "668/668 [==============================] - 96s 144ms/step - loss: 1.2247 - accuracy: 0.4490 - val_loss: 1.5455 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "668/668 [==============================] - 95s 143ms/step - loss: 1.2280 - accuracy: 0.4398 - val_loss: 1.5471 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "668/668 [==============================] - 96s 144ms/step - loss: 1.2240 - accuracy: 0.4452 - val_loss: 1.5468 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "668/668 [==============================] - 96s 144ms/step - loss: 1.2211 - accuracy: 0.4509 - val_loss: 1.5465 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "668/668 [==============================] - 96s 144ms/step - loss: 1.2219 - accuracy: 0.4473 - val_loss: 1.5467 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "668/668 [==============================] - 95s 142ms/step - loss: 1.2281 - accuracy: 0.4457 - val_loss: 1.5467 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "668/668 [==============================] - 95s 142ms/step - loss: 1.2286 - accuracy: 0.4403 - val_loss: 1.5467 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "668/668 [==============================] - 95s 142ms/step - loss: 1.2234 - accuracy: 0.4457 - val_loss: 1.5467 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "668/668 [==============================] - 95s 142ms/step - loss: 1.2270 - accuracy: 0.4446 - val_loss: 1.5461 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "668/668 [==============================] - 94s 141ms/step - loss: 1.2280 - accuracy: 0.4431 - val_loss: 1.5461 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "668/668 [==============================] - 95s 142ms/step - loss: 1.2239 - accuracy: 0.4476 - val_loss: 1.5459 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "668/668 [==============================] - 94s 141ms/step - loss: 1.2265 - accuracy: 0.4439 - val_loss: 1.5461 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "668/668 [==============================] - 94s 141ms/step - loss: 1.2247 - accuracy: 0.4439 - val_loss: 1.5461 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "668/668 [==============================] - 94s 141ms/step - loss: 1.2227 - accuracy: 0.4480 - val_loss: 1.5462 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "668/668 [==============================] - 95s 142ms/step - loss: 1.2234 - accuracy: 0.4430 - val_loss: 1.5461 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "668/668 [==============================] - 94s 141ms/step - loss: 1.2240 - accuracy: 0.4447 - val_loss: 1.5459 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "668/668 [==============================] - 95s 142ms/step - loss: 1.2254 - accuracy: 0.4475 - val_loss: 1.5459 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "668/668 [==============================] - 95s 142ms/step - loss: 1.2235 - accuracy: 0.4473 - val_loss: 1.5460 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../xception/xception_30epochs_33393.6_images_True_newWeights_False_lastLayerOnly_rescale-symmetric_normalization/assets\n",
      "Test acc for xception: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training resnet for 0.4% of train size (aka 33393 images) with pretrained: False and onlyLastLayersTrained: False...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/668 [..............................] - ETA: 5:57 - loss: 1.3854 - accuracy: 0.3531WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0775s vs `on_train_batch_begin` time: 0.1958s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0775s vs `on_train_batch_end` time: 0.1911s). Check your callbacks.\n",
      "668/668 [==============================] - 56s 78ms/step - loss: 1.2951 - accuracy: 0.4205 - val_loss: 1.4811 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "668/668 [==============================] - 49s 73ms/step - loss: 1.2337 - accuracy: 0.4448 - val_loss: 1.5526 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "668/668 [==============================] - 50s 75ms/step - loss: 1.2307 - accuracy: 0.4452 - val_loss: 1.5545 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "668/668 [==============================] - 49s 74ms/step - loss: 1.2286 - accuracy: 0.4452 - val_loss: 1.5575 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "668/668 [==============================] - 50s 75ms/step - loss: 1.2252 - accuracy: 0.4485 - val_loss: 1.5520 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "668/668 [==============================] - 50s 74ms/step - loss: 1.2363 - accuracy: 0.4384 - val_loss: 1.5580 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "668/668 [==============================] - 50s 74ms/step - loss: 1.2322 - accuracy: 0.4439 - val_loss: 1.5582 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "668/668 [==============================] - 50s 75ms/step - loss: 1.2279 - accuracy: 0.4471 - val_loss: 1.5559 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "668/668 [==============================] - 50s 75ms/step - loss: 1.2319 - accuracy: 0.4420 - val_loss: 1.5565 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "668/668 [==============================] - 49s 73ms/step - loss: 1.2325 - accuracy: 0.4431 - val_loss: 1.5562 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "668/668 [==============================] - 50s 75ms/step - loss: 1.2272 - accuracy: 0.4460 - val_loss: 1.5556 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "668/668 [==============================] - 50s 75ms/step - loss: 1.2304 - accuracy: 0.4436 - val_loss: 1.5569 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "668/668 [==============================] - 50s 75ms/step - loss: 1.2273 - accuracy: 0.4466 - val_loss: 1.5559 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "668/668 [==============================] - 50s 75ms/step - loss: 1.2262 - accuracy: 0.4465 - val_loss: 1.5554 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "668/668 [==============================] - 51s 76ms/step - loss: 1.2305 - accuracy: 0.4461 - val_loss: 1.5556 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "668/668 [==============================] - 51s 76ms/step - loss: 1.2325 - accuracy: 0.4426 - val_loss: 1.5568 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "668/668 [==============================] - 50s 75ms/step - loss: 1.2278 - accuracy: 0.4443 - val_loss: 1.5565 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "668/668 [==============================] - 51s 76ms/step - loss: 1.2313 - accuracy: 0.4455 - val_loss: 1.5556 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "668/668 [==============================] - 50s 75ms/step - loss: 1.2347 - accuracy: 0.4382 - val_loss: 1.5567 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "668/668 [==============================] - 50s 75ms/step - loss: 1.2342 - accuracy: 0.4416 - val_loss: 1.5568 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "668/668 [==============================] - 51s 76ms/step - loss: 1.2277 - accuracy: 0.4474 - val_loss: 1.5563 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "668/668 [==============================] - 50s 75ms/step - loss: 1.2316 - accuracy: 0.4423 - val_loss: 1.5562 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "668/668 [==============================] - 51s 76ms/step - loss: 1.2266 - accuracy: 0.4445 - val_loss: 1.5562 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "668/668 [==============================] - 50s 75ms/step - loss: 1.2384 - accuracy: 0.4390 - val_loss: 1.5563 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "668/668 [==============================] - 50s 74ms/step - loss: 1.2319 - accuracy: 0.4460 - val_loss: 1.5564 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "668/668 [==============================] - 50s 75ms/step - loss: 1.2276 - accuracy: 0.4502 - val_loss: 1.5563 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "668/668 [==============================] - 49s 74ms/step - loss: 1.2306 - accuracy: 0.4465 - val_loss: 1.5563 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "668/668 [==============================] - 51s 76ms/step - loss: 1.2308 - accuracy: 0.4429 - val_loss: 1.5563 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "668/668 [==============================] - 50s 75ms/step - loss: 1.2302 - accuracy: 0.4456 - val_loss: 1.5562 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "668/668 [==============================] - 50s 76ms/step - loss: 1.2304 - accuracy: 0.4411 - val_loss: 1.5562 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_33393.6_images_True_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training opticnet for 0.4% of train size (aka 33393 images) with pretrained: False and onlyLastLayersTrained: False...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/668 [..............................] - ETA: 20:55 - loss: 24.2528 - accuracy: 0.3332WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.4859s vs `on_train_batch_end` time: 1.0850s). Check your callbacks.\n",
      "668/668 [==============================] - 818s 1s/step - loss: 2.5926 - accuracy: 0.6319 - val_loss: 2.3733 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "668/668 [==============================] - 795s 1s/step - loss: 0.3385 - accuracy: 0.8860 - val_loss: 0.3114 - val_accuracy: 0.9062\n",
      "Epoch 3/30\n",
      "668/668 [==============================] - 796s 1s/step - loss: 0.2594 - accuracy: 0.9116 - val_loss: 0.8816 - val_accuracy: 0.6250\n",
      "Epoch 4/30\n",
      "668/668 [==============================] - 799s 1s/step - loss: 0.2231 - accuracy: 0.9256 - val_loss: 0.6702 - val_accuracy: 0.7500\n",
      "Epoch 5/30\n",
      "668/668 [==============================] - 798s 1s/step - loss: 0.1889 - accuracy: 0.9369 - val_loss: 0.1970 - val_accuracy: 0.9062\n",
      "Epoch 6/30\n",
      "668/668 [==============================] - 797s 1s/step - loss: 0.1649 - accuracy: 0.9441 - val_loss: 0.2288 - val_accuracy: 0.9375\n",
      "Epoch 7/30\n",
      "668/668 [==============================] - 797s 1s/step - loss: 0.1535 - accuracy: 0.9463 - val_loss: 0.0604 - val_accuracy: 0.9375\n",
      "Epoch 8/30\n",
      "668/668 [==============================] - 798s 1s/step - loss: 0.1340 - accuracy: 0.9544 - val_loss: 0.0239 - val_accuracy: 1.0000\n",
      "Epoch 9/30\n",
      "668/668 [==============================] - 800s 1s/step - loss: 0.1237 - accuracy: 0.9561 - val_loss: 0.0724 - val_accuracy: 0.9688\n",
      "Epoch 10/30\n",
      "668/668 [==============================] - 799s 1s/step - loss: 0.1175 - accuracy: 0.9607 - val_loss: 0.0430 - val_accuracy: 0.9688\n",
      "Epoch 11/30\n",
      "668/668 [==============================] - 798s 1s/step - loss: 0.0925 - accuracy: 0.9678 - val_loss: 0.0428 - val_accuracy: 1.0000\n",
      "Epoch 12/30\n",
      "668/668 [==============================] - 799s 1s/step - loss: 0.0823 - accuracy: 0.9726 - val_loss: 0.0245 - val_accuracy: 1.0000\n",
      "Epoch 13/30\n",
      "668/668 [==============================] - 801s 1s/step - loss: 0.0677 - accuracy: 0.9766 - val_loss: 0.0156 - val_accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "668/668 [==============================] - 802s 1s/step - loss: 0.0602 - accuracy: 0.9788 - val_loss: 0.0065 - val_accuracy: 1.0000\n",
      "Epoch 15/30\n",
      "668/668 [==============================] - 801s 1s/step - loss: 0.0449 - accuracy: 0.9844 - val_loss: 0.0377 - val_accuracy: 0.9688\n",
      "Epoch 16/30\n",
      "668/668 [==============================] - 798s 1s/step - loss: 0.0332 - accuracy: 0.9873 - val_loss: 0.1402 - val_accuracy: 0.9062\n",
      "Epoch 17/30\n",
      "668/668 [==============================] - 799s 1s/step - loss: 0.0292 - accuracy: 0.9897 - val_loss: 7.9820e-04 - val_accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "668/668 [==============================] - 802s 1s/step - loss: 0.0206 - accuracy: 0.9924 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "668/668 [==============================] - 802s 1s/step - loss: 0.0233 - accuracy: 0.9926 - val_loss: 0.0056 - val_accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "668/668 [==============================] - 800s 1s/step - loss: 0.0130 - accuracy: 0.9962 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "668/668 [==============================] - 800s 1s/step - loss: 0.0117 - accuracy: 0.9969 - val_loss: 0.0051 - val_accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "668/668 [==============================] - 802s 1s/step - loss: 0.0116 - accuracy: 0.9960 - val_loss: 4.8970e-04 - val_accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "668/668 [==============================] - 802s 1s/step - loss: 0.0107 - accuracy: 0.9972 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "668/668 [==============================] - 802s 1s/step - loss: 0.0097 - accuracy: 0.9965 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "668/668 [==============================] - 800s 1s/step - loss: 0.0080 - accuracy: 0.9975 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "668/668 [==============================] - 800s 1s/step - loss: 0.0067 - accuracy: 0.9982 - val_loss: 2.6047e-04 - val_accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "668/668 [==============================] - 802s 1s/step - loss: 0.0056 - accuracy: 0.9982 - val_loss: 2.5745e-04 - val_accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "668/668 [==============================] - 803s 1s/step - loss: 0.0056 - accuracy: 0.9980 - val_loss: 6.7282e-04 - val_accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "668/668 [==============================] - 802s 1s/step - loss: 0.0047 - accuracy: 0.9987 - val_loss: 2.3892e-04 - val_accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "668/668 [==============================] - 801s 1s/step - loss: 0.0043 - accuracy: 0.9985 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
      "INFO:tensorflow:Assets written to: ../opticnet/opticnet_30epochs_33393.6_images_True_newWeights_False_lastLayerOnly_rescale-symmetric_normalization/assets\n",
      "Test acc for opticnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.49766293 0.4985889  0.50608037 0.50522284]\n",
      "Training xception for 0.5% of train size (aka 41742 images) with pretrained: False and onlyLastLayersTrained: False...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/835 [..............................] - ETA: 8:27 - loss: 1.3854 - accuracy: 0.2916 WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1310s vs `on_train_batch_begin` time: 0.1768s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1310s vs `on_train_batch_end` time: 0.2250s). Check your callbacks.\n",
      "835/835 [==============================] - 125s 145ms/step - loss: 1.3001 - accuracy: 0.4404 - val_loss: 1.5437 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "835/835 [==============================] - 119s 143ms/step - loss: 1.2361 - accuracy: 0.4426 - val_loss: 1.5505 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "835/835 [==============================] - 120s 144ms/step - loss: 1.2302 - accuracy: 0.4476 - val_loss: 1.5469 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "835/835 [==============================] - 119s 143ms/step - loss: 1.2301 - accuracy: 0.4466 - val_loss: 1.5479 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "835/835 [==============================] - 121s 145ms/step - loss: 1.2325 - accuracy: 0.4412 - val_loss: 1.5489 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "835/835 [==============================] - 120s 144ms/step - loss: 1.2305 - accuracy: 0.4401 - val_loss: 1.5465 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "835/835 [==============================] - 120s 143ms/step - loss: 1.2264 - accuracy: 0.4472 - val_loss: 1.5436 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "835/835 [==============================] - 121s 145ms/step - loss: 1.2263 - accuracy: 0.4470 - val_loss: 1.5392 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "835/835 [==============================] - 120s 144ms/step - loss: 1.2287 - accuracy: 0.4406 - val_loss: 1.5448 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "835/835 [==============================] - 120s 144ms/step - loss: 1.2298 - accuracy: 0.4441 - val_loss: 1.5413 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "835/835 [==============================] - 121s 145ms/step - loss: 1.2269 - accuracy: 0.4447 - val_loss: 1.5427 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "835/835 [==============================] - 120s 144ms/step - loss: 1.2250 - accuracy: 0.4493 - val_loss: 1.5422 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "835/835 [==============================] - 120s 143ms/step - loss: 1.2275 - accuracy: 0.4415 - val_loss: 1.5403 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "835/835 [==============================] - 120s 144ms/step - loss: 1.2261 - accuracy: 0.4442 - val_loss: 1.5411 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "835/835 [==============================] - 121s 145ms/step - loss: 1.2294 - accuracy: 0.4408 - val_loss: 1.5410 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "835/835 [==============================] - 120s 144ms/step - loss: 1.2272 - accuracy: 0.4459 - val_loss: 1.5417 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "835/835 [==============================] - 119s 143ms/step - loss: 1.2287 - accuracy: 0.4437 - val_loss: 1.5417 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "835/835 [==============================] - 120s 144ms/step - loss: 1.2263 - accuracy: 0.4455 - val_loss: 1.5411 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "835/835 [==============================] - 121s 144ms/step - loss: 1.2293 - accuracy: 0.4424 - val_loss: 1.5417 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "835/835 [==============================] - 120s 143ms/step - loss: 1.2237 - accuracy: 0.4476 - val_loss: 1.5407 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "835/835 [==============================] - 119s 143ms/step - loss: 1.2269 - accuracy: 0.4443 - val_loss: 1.5404 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "835/835 [==============================] - 119s 143ms/step - loss: 1.2243 - accuracy: 0.4476 - val_loss: 1.5401 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "835/835 [==============================] - 119s 143ms/step - loss: 1.2269 - accuracy: 0.4427 - val_loss: 1.5403 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "835/835 [==============================] - 119s 143ms/step - loss: 1.2231 - accuracy: 0.4480 - val_loss: 1.5398 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "835/835 [==============================] - 119s 143ms/step - loss: 1.2314 - accuracy: 0.4402 - val_loss: 1.5400 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "835/835 [==============================] - 120s 143ms/step - loss: 1.2242 - accuracy: 0.4436 - val_loss: 1.5400 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "835/835 [==============================] - 119s 143ms/step - loss: 1.2334 - accuracy: 0.4387 - val_loss: 1.5401 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "835/835 [==============================] - 119s 142ms/step - loss: 1.2266 - accuracy: 0.4454 - val_loss: 1.5400 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "835/835 [==============================] - 120s 143ms/step - loss: 1.2232 - accuracy: 0.4447 - val_loss: 1.5399 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "835/835 [==============================] - 120s 143ms/step - loss: 1.2272 - accuracy: 0.4437 - val_loss: 1.5398 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../xception/xception_30epochs_41742.0_images_True_newWeights_False_lastLayerOnly_rescale-symmetric_normalization/assets\n",
      "Test acc for xception: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training resnet for 0.5% of train size (aka 41742 images) with pretrained: False and onlyLastLayersTrained: False...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/835 [..............................] - ETA: 7:38 - loss: 1.3796 - accuracy: 0.2136WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0770s vs `on_train_batch_begin` time: 0.2014s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0770s vs `on_train_batch_end` time: 0.1966s). Check your callbacks.\n",
      "835/835 [==============================] - 70s 80ms/step - loss: 1.2839 - accuracy: 0.4367 - val_loss: 1.5431 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "835/835 [==============================] - 63s 75ms/step - loss: 1.2351 - accuracy: 0.4412 - val_loss: 1.5491 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "835/835 [==============================] - 62s 74ms/step - loss: 1.2271 - accuracy: 0.4457 - val_loss: 1.5469 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "835/835 [==============================] - 62s 75ms/step - loss: 1.2332 - accuracy: 0.4451 - val_loss: 1.5512 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "835/835 [==============================] - 64s 76ms/step - loss: 1.2304 - accuracy: 0.4474 - val_loss: 1.5489 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "835/835 [==============================] - 63s 76ms/step - loss: 1.2326 - accuracy: 0.4467 - val_loss: 1.5505 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "835/835 [==============================] - 64s 77ms/step - loss: 1.2304 - accuracy: 0.4458 - val_loss: 1.5529 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "835/835 [==============================] - 63s 75ms/step - loss: 1.2285 - accuracy: 0.4498 - val_loss: 1.5519 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "835/835 [==============================] - 64s 76ms/step - loss: 1.2331 - accuracy: 0.4432 - val_loss: 1.5523 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "835/835 [==============================] - 64s 76ms/step - loss: 1.2367 - accuracy: 0.4422 - val_loss: 1.5541 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "835/835 [==============================] - 63s 75ms/step - loss: 1.2331 - accuracy: 0.4419 - val_loss: 1.5557 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "835/835 [==============================] - 62s 74ms/step - loss: 1.2386 - accuracy: 0.4403 - val_loss: 1.5569 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "835/835 [==============================] - 64s 77ms/step - loss: 1.2335 - accuracy: 0.4456 - val_loss: 1.5542 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "835/835 [==============================] - 63s 76ms/step - loss: 1.2281 - accuracy: 0.4462 - val_loss: 1.5522 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "835/835 [==============================] - 64s 77ms/step - loss: 1.2330 - accuracy: 0.4451 - val_loss: 1.5532 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "835/835 [==============================] - 63s 76ms/step - loss: 1.2335 - accuracy: 0.4443 - val_loss: 1.5542 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "835/835 [==============================] - 63s 75ms/step - loss: 1.2319 - accuracy: 0.4487 - val_loss: 1.5536 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "835/835 [==============================] - 64s 76ms/step - loss: 1.2314 - accuracy: 0.4433 - val_loss: 1.5536 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "835/835 [==============================] - 64s 76ms/step - loss: 1.2374 - accuracy: 0.4378 - val_loss: 1.5540 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "835/835 [==============================] - 64s 76ms/step - loss: 1.2320 - accuracy: 0.4466 - val_loss: 1.5540 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "835/835 [==============================] - 63s 76ms/step - loss: 1.2363 - accuracy: 0.4420 - val_loss: 1.5541 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "835/835 [==============================] - 64s 76ms/step - loss: 1.2309 - accuracy: 0.4466 - val_loss: 1.5539 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "835/835 [==============================] - 63s 75ms/step - loss: 1.2324 - accuracy: 0.4451 - val_loss: 1.5538 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "835/835 [==============================] - 62s 75ms/step - loss: 1.2298 - accuracy: 0.4470 - val_loss: 1.5536 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "835/835 [==============================] - 64s 77ms/step - loss: 1.2321 - accuracy: 0.4430 - val_loss: 1.5536 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "835/835 [==============================] - 63s 76ms/step - loss: 1.2325 - accuracy: 0.4450 - val_loss: 1.5537 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "835/835 [==============================] - 63s 76ms/step - loss: 1.2340 - accuracy: 0.4450 - val_loss: 1.5538 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "835/835 [==============================] - 63s 76ms/step - loss: 1.2357 - accuracy: 0.4399 - val_loss: 1.5538 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "835/835 [==============================] - 64s 77ms/step - loss: 1.2373 - accuracy: 0.4393 - val_loss: 1.5538 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "835/835 [==============================] - 63s 76ms/step - loss: 1.2370 - accuracy: 0.4404 - val_loss: 1.5539 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_41742.0_images_True_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training opticnet for 0.5% of train size (aka 41742 images) with pretrained: False and onlyLastLayersTrained: False...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/835 [..............................] - ETA: 26:43 - loss: 19.5040 - accuracy: 0.2619WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.4789s vs `on_train_batch_end` time: 1.1093s). Check your callbacks.\n",
      "835/835 [==============================] - 1009s 1s/step - loss: 2.2393 - accuracy: 0.6125 - val_loss: 3.0205 - val_accuracy: 0.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "835/835 [==============================] - 993s 1s/step - loss: 0.3939 - accuracy: 0.8620 - val_loss: 0.4872 - val_accuracy: 0.7500\n",
      "Epoch 3/30\n",
      "835/835 [==============================] - 998s 1s/step - loss: 0.2465 - accuracy: 0.9182 - val_loss: 0.4306 - val_accuracy: 0.9062\n",
      "Epoch 4/30\n",
      "835/835 [==============================] - 994s 1s/step - loss: 0.2131 - accuracy: 0.9284 - val_loss: 0.0862 - val_accuracy: 0.9375\n",
      "Epoch 5/30\n",
      "835/835 [==============================] - 991s 1s/step - loss: 0.1725 - accuracy: 0.9436 - val_loss: 0.1408 - val_accuracy: 0.9688\n",
      "Epoch 6/30\n",
      "835/835 [==============================] - 999s 1s/step - loss: 0.1494 - accuracy: 0.9490 - val_loss: 0.0533 - val_accuracy: 1.0000\n",
      "Epoch 7/30\n",
      "835/835 [==============================] - 992s 1s/step - loss: 0.1380 - accuracy: 0.9545 - val_loss: 0.0722 - val_accuracy: 1.0000\n",
      "Epoch 8/30\n",
      "835/835 [==============================] - 993s 1s/step - loss: 0.1207 - accuracy: 0.9591 - val_loss: 0.0746 - val_accuracy: 0.9688\n",
      "Epoch 9/30\n",
      "835/835 [==============================] - 991s 1s/step - loss: 0.0981 - accuracy: 0.9666 - val_loss: 0.1556 - val_accuracy: 0.9375\n",
      "Epoch 10/30\n",
      "835/835 [==============================] - 992s 1s/step - loss: 0.0806 - accuracy: 0.9740 - val_loss: 0.1720 - val_accuracy: 0.9375\n",
      "Epoch 11/30\n",
      "835/835 [==============================] - 993s 1s/step - loss: 0.0652 - accuracy: 0.9787 - val_loss: 0.0095 - val_accuracy: 1.0000\n",
      "Epoch 12/30\n",
      "835/835 [==============================] - 990s 1s/step - loss: 0.0489 - accuracy: 0.9840 - val_loss: 0.1009 - val_accuracy: 0.9688\n",
      "Epoch 13/30\n",
      "835/835 [==============================] - 991s 1s/step - loss: 0.0378 - accuracy: 0.9875 - val_loss: 0.0415 - val_accuracy: 0.9688\n",
      "Epoch 14/30\n",
      "835/835 [==============================] - 995s 1s/step - loss: 0.0310 - accuracy: 0.9906 - val_loss: 0.1952 - val_accuracy: 0.9688\n",
      "Epoch 15/30\n",
      "835/835 [==============================] - 994s 1s/step - loss: 0.0248 - accuracy: 0.9919 - val_loss: 0.2144 - val_accuracy: 0.9688\n",
      "Epoch 16/30\n",
      "835/835 [==============================] - 991s 1s/step - loss: 0.0229 - accuracy: 0.9933 - val_loss: 0.5412 - val_accuracy: 0.9688\n",
      "Epoch 17/30\n",
      "835/835 [==============================] - 993s 1s/step - loss: 0.0180 - accuracy: 0.9953 - val_loss: 0.1528 - val_accuracy: 0.9688\n",
      "Epoch 18/30\n",
      "835/835 [==============================] - 993s 1s/step - loss: 0.0143 - accuracy: 0.9963 - val_loss: 0.3047 - val_accuracy: 0.9688\n",
      "Epoch 19/30\n",
      "835/835 [==============================] - 995s 1s/step - loss: 0.0120 - accuracy: 0.9968 - val_loss: 0.2782 - val_accuracy: 0.9688\n",
      "Epoch 20/30\n",
      "835/835 [==============================] - 993s 1s/step - loss: 0.0115 - accuracy: 0.9971 - val_loss: 0.6008 - val_accuracy: 0.9688\n",
      "Epoch 21/30\n",
      "835/835 [==============================] - 991s 1s/step - loss: 0.0112 - accuracy: 0.9969 - val_loss: 0.1989 - val_accuracy: 0.9688\n",
      "Epoch 22/30\n",
      "835/835 [==============================] - 994s 1s/step - loss: 0.0077 - accuracy: 0.9976 - val_loss: 0.3499 - val_accuracy: 0.9688\n",
      "Epoch 23/30\n",
      "835/835 [==============================] - 990s 1s/step - loss: 0.0070 - accuracy: 0.9977 - val_loss: 0.1686 - val_accuracy: 0.9688\n",
      "Epoch 24/30\n",
      "835/835 [==============================] - 992s 1s/step - loss: 0.0072 - accuracy: 0.9978 - val_loss: 0.1497 - val_accuracy: 0.9688\n",
      "Epoch 25/30\n",
      "835/835 [==============================] - 991s 1s/step - loss: 0.0070 - accuracy: 0.9978 - val_loss: 0.2242 - val_accuracy: 0.9688\n",
      "Epoch 26/30\n",
      "835/835 [==============================] - 990s 1s/step - loss: 0.0070 - accuracy: 0.9978 - val_loss: 0.2495 - val_accuracy: 0.9688\n",
      "Epoch 27/30\n",
      "835/835 [==============================] - 991s 1s/step - loss: 0.0061 - accuracy: 0.9978 - val_loss: 0.1541 - val_accuracy: 0.9688\n",
      "Epoch 28/30\n",
      "835/835 [==============================] - 991s 1s/step - loss: 0.0058 - accuracy: 0.9979 - val_loss: 0.2784 - val_accuracy: 0.9688\n",
      "Epoch 29/30\n",
      "835/835 [==============================] - 992s 1s/step - loss: 0.0045 - accuracy: 0.9980 - val_loss: 0.2199 - val_accuracy: 0.9688\n",
      "Epoch 30/30\n",
      "835/835 [==============================] - 990s 1s/step - loss: 0.0044 - accuracy: 0.9981 - val_loss: 0.1799 - val_accuracy: 0.9688\n",
      "INFO:tensorflow:Assets written to: ../opticnet/opticnet_30epochs_41742.0_images_True_newWeights_False_lastLayerOnly_rescale-symmetric_normalization/assets\n",
      "Test acc for opticnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.59832795 0.59790351 0.60750793 0.6042247 ]\n",
      "Training xception for 0.6% of train size (aka 50090 images) with pretrained: False and onlyLastLayersTrained: False...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "   6/1002 [..............................] - ETA: 9:15 - loss: 1.3852 - accuracy: 0.3017 WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1376s vs `on_train_batch_end` time: 0.2176s). Check your callbacks.\n",
      "1002/1002 [==============================] - 148s 144ms/step - loss: 1.2922 - accuracy: 0.4415 - val_loss: 1.5478 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "1002/1002 [==============================] - 142s 142ms/step - loss: 1.2315 - accuracy: 0.4445 - val_loss: 1.5535 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "1002/1002 [==============================] - 142s 142ms/step - loss: 1.2348 - accuracy: 0.4389 - val_loss: 1.5536 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "1002/1002 [==============================] - 142s 141ms/step - loss: 1.2337 - accuracy: 0.4434 - val_loss: 1.5537 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "1002/1002 [==============================] - 141s 141ms/step - loss: 1.2313 - accuracy: 0.4439 - val_loss: 1.5491 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "1002/1002 [==============================] - 142s 142ms/step - loss: 1.2316 - accuracy: 0.4437 - val_loss: 1.5463 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "1002/1002 [==============================] - 142s 141ms/step - loss: 1.2272 - accuracy: 0.4462 - val_loss: 1.5494 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "1002/1002 [==============================] - 142s 142ms/step - loss: 1.2254 - accuracy: 0.4436 - val_loss: 1.5423 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "1002/1002 [==============================] - 144s 143ms/step - loss: 1.2263 - accuracy: 0.4457 - val_loss: 1.5421 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "1002/1002 [==============================] - 143s 143ms/step - loss: 1.2257 - accuracy: 0.4419 - val_loss: 1.5470 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "1002/1002 [==============================] - 144s 143ms/step - loss: 1.2297 - accuracy: 0.4404 - val_loss: 1.5447 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "1002/1002 [==============================] - 144s 143ms/step - loss: 1.2260 - accuracy: 0.4449 - val_loss: 1.5423 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "1002/1002 [==============================] - 144s 143ms/step - loss: 1.2291 - accuracy: 0.4443 - val_loss: 1.5436 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "1002/1002 [==============================] - 144s 144ms/step - loss: 1.2266 - accuracy: 0.4418 - val_loss: 1.5436 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "1002/1002 [==============================] - 144s 144ms/step - loss: 1.2255 - accuracy: 0.4451 - val_loss: 1.5425 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "1002/1002 [==============================] - 144s 144ms/step - loss: 1.2296 - accuracy: 0.4427 - val_loss: 1.5434 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "1002/1002 [==============================] - 144s 144ms/step - loss: 1.2246 - accuracy: 0.4451 - val_loss: 1.5426 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "1002/1002 [==============================] - 144s 143ms/step - loss: 1.2244 - accuracy: 0.4465 - val_loss: 1.5419 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "1002/1002 [==============================] - 143s 143ms/step - loss: 1.2264 - accuracy: 0.4430 - val_loss: 1.5423 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "1002/1002 [==============================] - 144s 144ms/step - loss: 1.2244 - accuracy: 0.4489 - val_loss: 1.5421 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "1002/1002 [==============================] - 141s 141ms/step - loss: 1.2289 - accuracy: 0.4403 - val_loss: 1.5433 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "1002/1002 [==============================] - 143s 142ms/step - loss: 1.2264 - accuracy: 0.4442 - val_loss: 1.5429 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "1002/1002 [==============================] - 142s 142ms/step - loss: 1.2303 - accuracy: 0.4420 - val_loss: 1.5430 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "1002/1002 [==============================] - 143s 142ms/step - loss: 1.2218 - accuracy: 0.4475 - val_loss: 1.5420 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "1002/1002 [==============================] - 142s 142ms/step - loss: 1.2263 - accuracy: 0.4467 - val_loss: 1.5421 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "1002/1002 [==============================] - 142s 142ms/step - loss: 1.2291 - accuracy: 0.4434 - val_loss: 1.5421 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "1002/1002 [==============================] - 142s 142ms/step - loss: 1.2263 - accuracy: 0.4454 - val_loss: 1.5420 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "1002/1002 [==============================] - 142s 142ms/step - loss: 1.2284 - accuracy: 0.4436 - val_loss: 1.5420 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "1002/1002 [==============================] - 143s 142ms/step - loss: 1.2265 - accuracy: 0.4458 - val_loss: 1.5419 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "1002/1002 [==============================] - 142s 142ms/step - loss: 1.2248 - accuracy: 0.4435 - val_loss: 1.5418 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../xception/xception_30epochs_50090.4_images_True_newWeights_False_lastLayerOnly_rescale-symmetric_normalization/assets\n",
      "Test acc for xception: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training resnet for 0.6% of train size (aka 50090 images) with pretrained: False and onlyLastLayersTrained: False...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "   6/1002 [..............................] - ETA: 9:13 - loss: 1.3725 - accuracy: 0.4436 WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0727s vs `on_train_batch_begin` time: 0.2035s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0727s vs `on_train_batch_end` time: 0.1997s). Check your callbacks.\n",
      "1002/1002 [==============================] - 83s 79ms/step - loss: 1.2788 - accuracy: 0.4438 - val_loss: 1.5507 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "1002/1002 [==============================] - 76s 76ms/step - loss: 1.2318 - accuracy: 0.4427 - val_loss: 1.5513 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "1002/1002 [==============================] - 76s 76ms/step - loss: 1.2347 - accuracy: 0.4433 - val_loss: 1.5604 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "1002/1002 [==============================] - 75s 75ms/step - loss: 1.2294 - accuracy: 0.4456 - val_loss: 1.5517 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "1002/1002 [==============================] - 76s 76ms/step - loss: 1.2321 - accuracy: 0.4454 - val_loss: 1.5532 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "1002/1002 [==============================] - 76s 76ms/step - loss: 1.2336 - accuracy: 0.4449 - val_loss: 1.5546 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "1002/1002 [==============================] - 76s 76ms/step - loss: 1.2295 - accuracy: 0.4469 - val_loss: 1.5524 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "1002/1002 [==============================] - 76s 76ms/step - loss: 1.2323 - accuracy: 0.4427 - val_loss: 1.5551 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "1002/1002 [==============================] - 75s 75ms/step - loss: 1.2334 - accuracy: 0.4400 - val_loss: 1.5554 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "1002/1002 [==============================] - 76s 76ms/step - loss: 1.2334 - accuracy: 0.4439 - val_loss: 1.5547 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "1002/1002 [==============================] - 75s 75ms/step - loss: 1.2299 - accuracy: 0.4481 - val_loss: 1.5525 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "1002/1002 [==============================] - 75s 75ms/step - loss: 1.2311 - accuracy: 0.4502 - val_loss: 1.5532 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "1002/1002 [==============================] - 75s 75ms/step - loss: 1.2325 - accuracy: 0.4444 - val_loss: 1.5537 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "1002/1002 [==============================] - 76s 75ms/step - loss: 1.2306 - accuracy: 0.4473 - val_loss: 1.5524 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "1002/1002 [==============================] - 77s 76ms/step - loss: 1.2359 - accuracy: 0.4399 - val_loss: 1.5552 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "1002/1002 [==============================] - 76s 76ms/step - loss: 1.2307 - accuracy: 0.4435 - val_loss: 1.5547 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "1002/1002 [==============================] - 76s 76ms/step - loss: 1.2338 - accuracy: 0.4451 - val_loss: 1.5543 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "1002/1002 [==============================] - 76s 75ms/step - loss: 1.2325 - accuracy: 0.4444 - val_loss: 1.5538 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "1002/1002 [==============================] - 75s 75ms/step - loss: 1.2304 - accuracy: 0.4451 - val_loss: 1.5535 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "1002/1002 [==============================] - 76s 76ms/step - loss: 1.2379 - accuracy: 0.4414 - val_loss: 1.5546 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "1002/1002 [==============================] - 76s 75ms/step - loss: 1.2343 - accuracy: 0.4409 - val_loss: 1.5543 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "1002/1002 [==============================] - 75s 75ms/step - loss: 1.2327 - accuracy: 0.4452 - val_loss: 1.5542 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "1002/1002 [==============================] - 76s 75ms/step - loss: 1.2332 - accuracy: 0.4421 - val_loss: 1.5545 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "1002/1002 [==============================] - 75s 75ms/step - loss: 1.2375 - accuracy: 0.4389 - val_loss: 1.5547 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "1002/1002 [==============================] - 75s 74ms/step - loss: 1.2284 - accuracy: 0.4467 - val_loss: 1.5541 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "1002/1002 [==============================] - 75s 74ms/step - loss: 1.2324 - accuracy: 0.4432 - val_loss: 1.5539 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "1002/1002 [==============================] - 75s 74ms/step - loss: 1.2306 - accuracy: 0.4439 - val_loss: 1.5540 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "1002/1002 [==============================] - 75s 75ms/step - loss: 1.2317 - accuracy: 0.4444 - val_loss: 1.5539 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "1002/1002 [==============================] - 76s 76ms/step - loss: 1.2336 - accuracy: 0.4409 - val_loss: 1.5541 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "1002/1002 [==============================] - 75s 75ms/step - loss: 1.2341 - accuracy: 0.4451 - val_loss: 1.5540 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_50090.4_images_True_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training opticnet for 0.6% of train size (aka 50090 images) with pretrained: False and onlyLastLayersTrained: False...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "   6/1002 [..............................] - ETA: 30:28 - loss: 29.9996 - accuracy: 0.2687WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.4796s vs `on_train_batch_end` time: 1.0882s). Check your callbacks.\n",
      "1002/1002 [==============================] - 1211s 1s/step - loss: 2.3430 - accuracy: 0.6465 - val_loss: 4.7036 - val_accuracy: 0.2812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "1002/1002 [==============================] - 1196s 1s/step - loss: 0.2984 - accuracy: 0.9013 - val_loss: 0.3466 - val_accuracy: 0.8750\n",
      "Epoch 3/30\n",
      "1002/1002 [==============================] - 1193s 1s/step - loss: 0.2254 - accuracy: 0.9255 - val_loss: 0.5601 - val_accuracy: 0.7500\n",
      "Epoch 4/30\n",
      "1002/1002 [==============================] - 1195s 1s/step - loss: 0.1941 - accuracy: 0.9355 - val_loss: 1.2521 - val_accuracy: 0.5000\n",
      "Epoch 5/30\n",
      "1002/1002 [==============================] - 1199s 1s/step - loss: 0.1664 - accuracy: 0.9433 - val_loss: 0.2553 - val_accuracy: 0.8750\n",
      "Epoch 6/30\n",
      "1002/1002 [==============================] - 1193s 1s/step - loss: 0.1430 - accuracy: 0.9525 - val_loss: 0.0592 - val_accuracy: 0.9688\n",
      "Epoch 7/30\n",
      "1002/1002 [==============================] - 1193s 1s/step - loss: 0.1260 - accuracy: 0.9570 - val_loss: 0.0208 - val_accuracy: 1.0000\n",
      "Epoch 8/30\n",
      "1002/1002 [==============================] - 1198s 1s/step - loss: 0.1163 - accuracy: 0.9595 - val_loss: 0.1893 - val_accuracy: 0.9375\n",
      "Epoch 9/30\n",
      "1002/1002 [==============================] - 1195s 1s/step - loss: 0.0940 - accuracy: 0.9667 - val_loss: 0.0399 - val_accuracy: 1.0000\n",
      "Epoch 10/30\n",
      "1002/1002 [==============================] - 1193s 1s/step - loss: 0.0782 - accuracy: 0.9730 - val_loss: 0.0275 - val_accuracy: 1.0000\n",
      "Epoch 11/30\n",
      "1002/1002 [==============================] - 1195s 1s/step - loss: 0.0634 - accuracy: 0.9785 - val_loss: 0.0140 - val_accuracy: 1.0000\n",
      "Epoch 12/30\n",
      "1002/1002 [==============================] - 1195s 1s/step - loss: 0.0486 - accuracy: 0.9828 - val_loss: 0.0324 - val_accuracy: 0.9688\n",
      "Epoch 13/30\n",
      "1002/1002 [==============================] - 1192s 1s/step - loss: 0.0404 - accuracy: 0.9869 - val_loss: 0.0981 - val_accuracy: 0.9688\n",
      "Epoch 14/30\n",
      "1002/1002 [==============================] - 1193s 1s/step - loss: 0.0325 - accuracy: 0.9896 - val_loss: 0.0581 - val_accuracy: 0.9688\n",
      "Epoch 15/30\n",
      "1002/1002 [==============================] - 1194s 1s/step - loss: 0.0258 - accuracy: 0.9916 - val_loss: 0.1154 - val_accuracy: 0.9688\n",
      "Epoch 16/30\n",
      "1002/1002 [==============================] - 1191s 1s/step - loss: 0.0196 - accuracy: 0.9934 - val_loss: 0.1839 - val_accuracy: 0.9688\n",
      "Epoch 17/30\n",
      "1002/1002 [==============================] - 1195s 1s/step - loss: 0.0196 - accuracy: 0.9946 - val_loss: 0.0359 - val_accuracy: 0.9688\n",
      "Epoch 18/30\n",
      "1002/1002 [==============================] - 1195s 1s/step - loss: 0.0143 - accuracy: 0.9958 - val_loss: 0.1399 - val_accuracy: 0.9688\n",
      "Epoch 19/30\n",
      "1002/1002 [==============================] - 1191s 1s/step - loss: 0.0130 - accuracy: 0.9961 - val_loss: 0.2269 - val_accuracy: 0.9688\n",
      "Epoch 20/30\n",
      "1002/1002 [==============================] - 1194s 1s/step - loss: 0.0108 - accuracy: 0.9965 - val_loss: 0.1518 - val_accuracy: 0.9688\n",
      "Epoch 21/30\n",
      "1002/1002 [==============================] - 1197s 1s/step - loss: 0.0095 - accuracy: 0.9973 - val_loss: 0.1057 - val_accuracy: 0.9688\n",
      "Epoch 22/30\n",
      "1002/1002 [==============================] - 1195s 1s/step - loss: 0.0081 - accuracy: 0.9976 - val_loss: 0.1542 - val_accuracy: 0.9688\n",
      "Epoch 23/30\n",
      "1002/1002 [==============================] - 1196s 1s/step - loss: 0.0075 - accuracy: 0.9973 - val_loss: 0.1657 - val_accuracy: 0.9688\n",
      "Epoch 24/30\n",
      "1002/1002 [==============================] - 1197s 1s/step - loss: 0.0081 - accuracy: 0.9973 - val_loss: 0.1453 - val_accuracy: 0.9688\n",
      "Epoch 25/30\n",
      "1002/1002 [==============================] - 1197s 1s/step - loss: 0.0064 - accuracy: 0.9976 - val_loss: 0.1953 - val_accuracy: 0.9688\n",
      "Epoch 26/30\n",
      "1002/1002 [==============================] - 1197s 1s/step - loss: 0.0059 - accuracy: 0.9974 - val_loss: 0.1664 - val_accuracy: 0.9688\n",
      "Epoch 27/30\n",
      "1002/1002 [==============================] - 1201s 1s/step - loss: 0.0068 - accuracy: 0.9976 - val_loss: 0.2018 - val_accuracy: 0.9688\n",
      "Epoch 28/30\n",
      "1002/1002 [==============================] - 1193s 1s/step - loss: 0.0050 - accuracy: 0.9977 - val_loss: 0.1020 - val_accuracy: 0.9688\n",
      "Epoch 29/30\n",
      "1002/1002 [==============================] - 1196s 1s/step - loss: 0.0054 - accuracy: 0.9977 - val_loss: 0.1146 - val_accuracy: 0.9688\n",
      "Epoch 30/30\n",
      "1002/1002 [==============================] - 1198s 1s/step - loss: 0.0048 - accuracy: 0.9979 - val_loss: 0.1599 - val_accuracy: 0.9688\n",
      "INFO:tensorflow:Assets written to: ../opticnet/opticnet_30epochs_50090.4_images_True_newWeights_False_lastLayerOnly_rescale-symmetric_normalization/assets\n",
      "Test acc for opticnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels fraction: [0.7466084  0.75032926 0.75625661 0.75069638]\n",
      "Training xception for 0.75% of train size (aka 62613 images) with pretrained: False and onlyLastLayersTrained: False...\n",
      "Epoch 1/30\n",
      "   6/1253 [..............................] - ETA: 11:38 - loss: 1.3854 - accuracy: 0.2980WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1344s vs `on_train_batch_begin` time: 0.1429s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1344s vs `on_train_batch_end` time: 0.2129s). Check your callbacks.\n",
      "1253/1253 [==============================] - 184s 144ms/step - loss: 1.2840 - accuracy: 0.4451 - val_loss: 1.5576 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "1253/1253 [==============================] - 177s 142ms/step - loss: 1.2273 - accuracy: 0.4472 - val_loss: 1.5539 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "1253/1253 [==============================] - 178s 142ms/step - loss: 1.2271 - accuracy: 0.4462 - val_loss: 1.5455 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "1253/1253 [==============================] - 178s 142ms/step - loss: 1.2256 - accuracy: 0.4485 - val_loss: 1.5450 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "1253/1253 [==============================] - 177s 141ms/step - loss: 1.2256 - accuracy: 0.4469 - val_loss: 1.5442 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "1253/1253 [==============================] - 178s 142ms/step - loss: 1.2249 - accuracy: 0.4460 - val_loss: 1.5478 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "1253/1253 [==============================] - 177s 141ms/step - loss: 1.2257 - accuracy: 0.4456 - val_loss: 1.5429 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "1253/1253 [==============================] - 178s 142ms/step - loss: 1.2211 - accuracy: 0.4497 - val_loss: 1.5412 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "1253/1253 [==============================] - 178s 142ms/step - loss: 1.2256 - accuracy: 0.4471 - val_loss: 1.5439 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "1253/1253 [==============================] - 179s 143ms/step - loss: 1.2230 - accuracy: 0.4460 - val_loss: 1.5412 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "1253/1253 [==============================] - 179s 143ms/step - loss: 1.2220 - accuracy: 0.4514 - val_loss: 1.5425 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "1253/1253 [==============================] - 179s 143ms/step - loss: 1.2228 - accuracy: 0.4465 - val_loss: 1.5413 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "1253/1253 [==============================] - 180s 143ms/step - loss: 1.2223 - accuracy: 0.4463 - val_loss: 1.5389 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "1253/1253 [==============================] - 181s 145ms/step - loss: 1.2235 - accuracy: 0.4469 - val_loss: 1.5389 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "1253/1253 [==============================] - 181s 144ms/step - loss: 1.2210 - accuracy: 0.4444 - val_loss: 1.5401 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "1253/1253 [==============================] - 181s 144ms/step - loss: 1.2265 - accuracy: 0.4430 - val_loss: 1.5409 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "1253/1253 [==============================] - 180s 143ms/step - loss: 1.2236 - accuracy: 0.4465 - val_loss: 1.5388 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "1253/1253 [==============================] - 179s 143ms/step - loss: 1.2250 - accuracy: 0.4440 - val_loss: 1.5393 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "1253/1253 [==============================] - 180s 143ms/step - loss: 1.2190 - accuracy: 0.4484 - val_loss: 1.5376 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "1253/1253 [==============================] - 178s 142ms/step - loss: 1.2199 - accuracy: 0.4467 - val_loss: 1.5376 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "1253/1253 [==============================] - 179s 143ms/step - loss: 1.2225 - accuracy: 0.4467 - val_loss: 1.5370 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "1253/1253 [==============================] - 178s 142ms/step - loss: 1.2185 - accuracy: 0.4494 - val_loss: 1.5365 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "1253/1253 [==============================] - 178s 142ms/step - loss: 1.2232 - accuracy: 0.4426 - val_loss: 1.5369 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "1253/1253 [==============================] - 177s 142ms/step - loss: 1.2216 - accuracy: 0.4447 - val_loss: 1.5365 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "1253/1253 [==============================] - 178s 142ms/step - loss: 1.2210 - accuracy: 0.4467 - val_loss: 1.5365 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "1253/1253 [==============================] - 177s 141ms/step - loss: 1.2194 - accuracy: 0.4455 - val_loss: 1.5359 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "1253/1253 [==============================] - 177s 142ms/step - loss: 1.2226 - accuracy: 0.4451 - val_loss: 1.5360 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "1253/1253 [==============================] - 177s 141ms/step - loss: 1.2238 - accuracy: 0.4462 - val_loss: 1.5358 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "1253/1253 [==============================] - 179s 143ms/step - loss: 1.2214 - accuracy: 0.4479 - val_loss: 1.5355 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "1253/1253 [==============================] - 180s 143ms/step - loss: 1.2235 - accuracy: 0.4428 - val_loss: 1.5357 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../xception/xception_30epochs_62613.0_images_True_newWeights_False_lastLayerOnly_rescale-symmetric_normalization/assets\n",
      "Test acc for xception: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training resnet for 0.75% of train size (aka 62613 images) with pretrained: False and onlyLastLayersTrained: False...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "   6/1253 [..............................] - ETA: 10:29 - loss: 1.3720 - accuracy: 0.2436WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0708s vs `on_train_batch_begin` time: 0.2015s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0708s vs `on_train_batch_end` time: 0.1630s). Check your callbacks.\n",
      "1253/1253 [==============================] - 102s 78ms/step - loss: 1.2742 - accuracy: 0.4422 - val_loss: 1.5553 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "1253/1253 [==============================] - 95s 76ms/step - loss: 1.2300 - accuracy: 0.4466 - val_loss: 1.5563 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "1253/1253 [==============================] - 95s 76ms/step - loss: 1.2355 - accuracy: 0.4412 - val_loss: 1.5658 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "1253/1253 [==============================] - 96s 77ms/step - loss: 1.2335 - accuracy: 0.4436 - val_loss: 1.5582 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "1253/1253 [==============================] - 96s 77ms/step - loss: 1.2286 - accuracy: 0.4473 - val_loss: 1.5504 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "1253/1253 [==============================] - 95s 76ms/step - loss: 1.2339 - accuracy: 0.4445 - val_loss: 1.5619 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "1253/1253 [==============================] - 96s 76ms/step - loss: 1.2288 - accuracy: 0.4483 - val_loss: 1.5543 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "1253/1253 [==============================] - 95s 76ms/step - loss: 1.2302 - accuracy: 0.4493 - val_loss: 1.5566 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "1253/1253 [==============================] - 96s 76ms/step - loss: 1.2306 - accuracy: 0.4453 - val_loss: 1.5530 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "1253/1253 [==============================] - 96s 76ms/step - loss: 1.2327 - accuracy: 0.4441 - val_loss: 1.5547 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "1253/1253 [==============================] - 95s 76ms/step - loss: 1.2303 - accuracy: 0.4450 - val_loss: 1.5552 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "1253/1253 [==============================] - 96s 76ms/step - loss: 1.2323 - accuracy: 0.4441 - val_loss: 1.5572 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "1253/1253 [==============================] - 95s 76ms/step - loss: 1.2299 - accuracy: 0.4466 - val_loss: 1.5559 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "1253/1253 [==============================] - 94s 75ms/step - loss: 1.2253 - accuracy: 0.4497 - val_loss: 1.5537 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "1253/1253 [==============================] - 93s 74ms/step - loss: 1.2296 - accuracy: 0.4448 - val_loss: 1.5554 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "1253/1253 [==============================] - 94s 75ms/step - loss: 1.2317 - accuracy: 0.4439 - val_loss: 1.5562 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "1253/1253 [==============================] - 93s 75ms/step - loss: 1.2309 - accuracy: 0.4459 - val_loss: 1.5565 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "1253/1253 [==============================] - 93s 74ms/step - loss: 1.2335 - accuracy: 0.4426 - val_loss: 1.5572 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "1253/1253 [==============================] - 94s 75ms/step - loss: 1.2319 - accuracy: 0.4465 - val_loss: 1.5561 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "1253/1253 [==============================] - 93s 74ms/step - loss: 1.2319 - accuracy: 0.4437 - val_loss: 1.5561 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "1253/1253 [==============================] - 93s 74ms/step - loss: 1.2297 - accuracy: 0.4467 - val_loss: 1.5559 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "1253/1253 [==============================] - 93s 74ms/step - loss: 1.2282 - accuracy: 0.4471 - val_loss: 1.5557 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "1253/1253 [==============================] - 93s 74ms/step - loss: 1.2330 - accuracy: 0.4423 - val_loss: 1.5567 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "1253/1253 [==============================] - 93s 74ms/step - loss: 1.2319 - accuracy: 0.4463 - val_loss: 1.5565 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "1253/1253 [==============================] - 93s 74ms/step - loss: 1.2330 - accuracy: 0.4463 - val_loss: 1.5566 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "1253/1253 [==============================] - 94s 75ms/step - loss: 1.2279 - accuracy: 0.4470 - val_loss: 1.5565 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "1253/1253 [==============================] - 92s 74ms/step - loss: 1.2323 - accuracy: 0.4429 - val_loss: 1.5563 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "1253/1253 [==============================] - 92s 73ms/step - loss: 1.2310 - accuracy: 0.4480 - val_loss: 1.5562 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "1253/1253 [==============================] - 92s 73ms/step - loss: 1.2312 - accuracy: 0.4434 - val_loss: 1.5562 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "1253/1253 [==============================] - 93s 74ms/step - loss: 1.2291 - accuracy: 0.4462 - val_loss: 1.5561 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_62613.0_images_True_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training opticnet for 0.75% of train size (aka 62613 images) with pretrained: False and onlyLastLayersTrained: False...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "   6/1253 [..............................] - ETA: 40:36 - loss: 23.2973 - accuracy: 0.3430WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.4934s vs `on_train_batch_end` time: 1.1126s). Check your callbacks.\n",
      "1253/1253 [==============================] - 1518s 1s/step - loss: 1.8208 - accuracy: 0.6687 - val_loss: 0.3072 - val_accuracy: 0.8750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "1253/1253 [==============================] - 1497s 1s/step - loss: 0.2739 - accuracy: 0.9097 - val_loss: 0.3553 - val_accuracy: 0.8438\n",
      "Epoch 3/30\n",
      "1253/1253 [==============================] - 1498s 1s/step - loss: 0.2021 - accuracy: 0.9337 - val_loss: 0.6162 - val_accuracy: 0.6562\n",
      "Epoch 4/30\n",
      "1253/1253 [==============================] - 1496s 1s/step - loss: 0.1734 - accuracy: 0.9411 - val_loss: 0.2797 - val_accuracy: 0.9062\n",
      "Epoch 5/30\n",
      "1253/1253 [==============================] - 1493s 1s/step - loss: 0.1542 - accuracy: 0.9476 - val_loss: 0.0237 - val_accuracy: 1.0000\n",
      "Epoch 6/30\n",
      "1253/1253 [==============================] - 1498s 1s/step - loss: 0.1385 - accuracy: 0.9519 - val_loss: 0.0373 - val_accuracy: 1.0000\n",
      "Epoch 7/30\n",
      "1253/1253 [==============================] - 1492s 1s/step - loss: 0.1188 - accuracy: 0.9587 - val_loss: 0.0613 - val_accuracy: 1.0000\n",
      "Epoch 8/30\n",
      "1253/1253 [==============================] - 1493s 1s/step - loss: 0.1017 - accuracy: 0.9647 - val_loss: 0.0491 - val_accuracy: 0.9688\n",
      "Epoch 9/30\n",
      "1253/1253 [==============================] - 1495s 1s/step - loss: 0.0878 - accuracy: 0.9700 - val_loss: 0.0165 - val_accuracy: 1.0000\n",
      "Epoch 10/30\n",
      "1253/1253 [==============================] - 1491s 1s/step - loss: 0.0731 - accuracy: 0.9749 - val_loss: 0.0687 - val_accuracy: 0.9688\n",
      "Epoch 11/30\n",
      "1253/1253 [==============================] - 1495s 1s/step - loss: 0.0604 - accuracy: 0.9784 - val_loss: 0.0836 - val_accuracy: 0.9688\n",
      "Epoch 12/30\n",
      "1253/1253 [==============================] - 1490s 1s/step - loss: 0.0463 - accuracy: 0.9838 - val_loss: 0.0127 - val_accuracy: 1.0000\n",
      "Epoch 13/30\n",
      "1253/1253 [==============================] - 1495s 1s/step - loss: 0.0373 - accuracy: 0.9873 - val_loss: 0.0396 - val_accuracy: 0.9688\n",
      "Epoch 14/30\n",
      " 183/1253 [===>..........................] - ETA: 21:17 - loss: 0.0275 - accuracy: 0.9910"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import datetime\n",
    "\n",
    "maxTrain = len(y_train)\n",
    "#for newWeights in [False, True]:\n",
    "for newWeigths in False:\n",
    "    # if is pretrained, train both cases, otherwise train all\n",
    "    #tLayer = [False] if newWeights else [True, False]\n",
    "    for trainLastLayerOnly in tLayer:\n",
    "        for p in [0.01, 0.025, 0.05, 0.075, 0.09, 0.1, 0.25, 0.4, 0.5, 0.6, 0.75, 0.9, 1.0]:\n",
    "            #X_trn, X_tst, y_trn, y_tst\n",
    "            if p < 1:\n",
    "                X_t, _, y_t, _ = train_test_split(images, y_train, test_size=1-p, random_state=234)\n",
    "            else:\n",
    "                X_t = images; y_t = y_train;\n",
    "            print(f\"Labels fraction: {sum(y_t == 1) / sum(y_train == 1)}\")\n",
    "            for net in [\"xception\", \"resnet\", \"opticnet\"]:\n",
    "                print(f\"Training {net} for {p}% of train size (aka {len(X_t)} images) with pretrained: {not newWeights} and onlyLastLayersTrained: {trainLastLayerOnly}...\")\n",
    "                model, size, normalization = emptyModelGenerator(net, newWeights=newWeights, lastOnly=trainLastLayerOnly)\n",
    "                X_trn = resizeIms(X_t, size)\n",
    "                #X_trn = normalizeIms(X_trn, normalization=normalization)\n",
    "                X_val = resizeIms(x_val, size)\n",
    "                #X_val = normalizeIms(X_val, normalization=normalization)\n",
    "                log_dir = f\"logs/{net}/fit/{p}trainSet_\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "                tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "                optim = Adam(learning_rate=0.001)\n",
    "                time_callback = TimeHistory()\n",
    "                model.compile(optimizer=optim, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "                hist = model.fit(X_trn, y_t, epochs=epochs, validation_data = (X_val, y_validation), batch_size=batch_size,\n",
    "                            shuffle=True, max_queue_size=20,\n",
    "                            use_multiprocessing=True, workers=5, \n",
    "                            callbacks=[CustomCallback(fraction=0.9, model=net), tensorboard_callback, time_callback])\n",
    "                trainTime = sum(time_callback.times)\n",
    "                model.save(f\"../{net}/{net}_{epochs}epochs_{p*maxTrain}_images_{newWeights}_newWeights_{trainLastLayerOnly}_lastLayerOnly_{normalization}_normalization\")\n",
    "                tstAcc = testPredict(model, size, name=net, normalization=normalization)\n",
    "                results = results.append({\n",
    "                    'model': net, \n",
    "                    'train set images': len(X_t), \n",
    "                    'pretrained': not newWeights, \n",
    "                    'pretrained dataset': None if newWeights else (\"OCT2017,Srinivasan2014\" if net == \"opticnet\" else \"Imagenet\"),\n",
    "                    'Trained layers': \"Last dense\" if trainLastLayerOnly else \"All\", \n",
    "                    'epochs': epochs, \n",
    "                    'batch size': batch_size, \n",
    "                    'learning rate': lr, \n",
    "                    'optimizer': optim._name,\n",
    "                    'training time (seconds)': trainTime, \n",
    "                    'train accuracy': hist.history[\"accuracy\"][-1], \n",
    "                    'train loss': hist.history[\"loss\"][-1],\n",
    "                    'validation accuracy': hist.history[\"val_accuracy\"][-1], \n",
    "                    'validation loss': hist.history[\"val_loss\"][-1], \n",
    "                    'test accuracy': tstAcc,\n",
    "                    #'normalization': normalization\n",
    "                }, ignore_index=True)\n",
    "                results.to_csv(\"Results_temp.csv\", index=False)\n",
    "                del model\n",
    "                del X_trn\n",
    "                del X_val\n",
    "                print(\"Done!\\n\" + '-'*50, end='\\n\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
