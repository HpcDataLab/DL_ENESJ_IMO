{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "import os\n",
    "import cv2\n",
    "import pickle\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataPath = \"../../data/OCT/OCT2017/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of Classes Detected : 4\n"
     ]
    }
   ],
   "source": [
    "labels_available = os.listdir(os.path.join(dataPath, \"train\"))\n",
    "print(\"Total Number of Classes Detected :\",len(labels_available))\n",
    "\n",
    "labels_list = ['NORMAL',\"CNV\",\"DME\",\"DRUSEN\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NORMAL CNV DME DRUSEN "
     ]
    }
   ],
   "source": [
    "images=[]\n",
    "y_trn=[]\n",
    "for x in labels_list:\n",
    "    xPath = os.path.join(dataPath, \"train\", x)\n",
    "    myPicList = os.listdir(xPath)\n",
    "    for y in myPicList:\n",
    "        images.append(cv2.imread(os.path.join(xPath, y)))\n",
    "        y_trn.append(labels_list.index(x))\n",
    "    print(x ,end=\" \")\n",
    "\n",
    "y_train = to_categorical(y_trn,len(labels_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NORMAL CNV DME DRUSEN "
     ]
    }
   ],
   "source": [
    "x_val=[]\n",
    "y_val=[]\n",
    "for x in labels_list:\n",
    "    xPath = os.path.join(dataPath, \"val\", x)\n",
    "    myPicList = os.listdir(xPath)\n",
    "    for y in myPicList:\n",
    "        x_val.append(cv2.imread(os.path.join(xPath, y)))\n",
    "        y_val.append(labels_list.index(x))\n",
    "    print(x ,end=\" \")\n",
    "\n",
    "y_validation = to_categorical(y_val,len(labels_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NORMAL CNV DME DRUSEN "
     ]
    }
   ],
   "source": [
    "x_tst=[]\n",
    "y_tst=[]\n",
    "for x in labels_list:\n",
    "    xPath = os.path.join(dataPath, \"test\", x)\n",
    "    myPicList = os.listdir(xPath)\n",
    "    for y in myPicList:\n",
    "        x_tst.append(cv2.imread(os.path.join(xPath, y)))\n",
    "        y_tst.append(labels_list.index(x))\n",
    "    print(x ,end=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resizeIm(im, size):\n",
    "    if im.shape[2] == 1:\n",
    "        im = cv2.cvtColor(im,cv2.COLOR_GRAY2RGB)\n",
    "    return cv2.resize(im, size)\n",
    "\n",
    "def resizeIms(x, size):\n",
    "    return np.array(list(map(lambda im: resizeIm(im, size), x)))\n",
    "\n",
    "# Substract the mean specified by Mean (https://www.mathworks.com/help/deeplearning/ref/nnet.cnn.layer.imageinputlayer.html)\n",
    "# Substract mean by channel\n",
    "def zerocenter(x):\n",
    "    return (x - np.mean(x, axis=(0, 1))) / (2*np.std(x, axis=(0, 1)))\n",
    "\n",
    "# Rescale the input to be in the range [-1, 1] using the minimum and maximum values specified by Min and Max, respectively. (https://www.mathworks.com/help/deeplearning/ref/nnet.cnn.layer.imageinputlayer.html)\n",
    "# Compute using the formula: $x\\prime = 2 * \\frac{x - \\min{x}}{\\max{x} - \\min{x}} - 1$ taken from: https://stats.stackexchange.com/a/178629\n",
    "def rescaleSymmetric(x):\n",
    "    x = zerocenter(x)\n",
    "    return 2 * (x - np.min(x, axis=(0, 1)))/np.ptp(x, axis=(0, 1)) - 1\n",
    "\n",
    "def normalizeIms(x, normalization):\n",
    "    if normalization == \"zerocenter\":\n",
    "        func = zerocenter\n",
    "    elif normalization == \"rescale-symmetric\":\n",
    "        func = rescaleSymmetric\n",
    "    else:\n",
    "        return x\n",
    "    return np.array(list(map(lambda im: func(im), x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self,fraction, model):\n",
    "        super(CustomCallback,self).__init__()\n",
    "        self.fraction = fraction\n",
    "        self.train_a = [];\n",
    "        self.val_a =[];\n",
    "        self.logPath = os.path.join(model, \"log.txt\")\n",
    "\n",
    "        if not os.path.isdir(model):\n",
    "            os.mkdir(model)\n",
    "\n",
    "        with open(self.logPath,'w') as f:\n",
    "            f.write('Starting of logging..\\n')\n",
    "\n",
    "        self.fig = plt.figure(figsize=(4,3))\n",
    "        self.ax = plt.subplot(1,1,1)\n",
    "        plt.ion()\n",
    "\n",
    "    def on_train_begin(self,logs=None):\n",
    "        self.fig.show()\n",
    "        self.fig.canvas.draw()\n",
    "\n",
    "    def on_train_end(self,logs=None):\n",
    "        with open(self.logPath,'a') as f:\n",
    "              f.write('End of logging..\\n')\n",
    "    \n",
    "    def on_epoch_begin(self,epoch,logs=None):\n",
    "        lr= tf.keras.backend.get_value(self.model.optimizer.lr)\n",
    "        lr *= self.fraction\n",
    "        tf.keras.backend.set_value(self.model.optimizer.lr,lr)\n",
    "        with open(self.logPath,'a') as f:\n",
    "            f.write('At epoch {:02d}, learning rate changed to {:.4f}\\n'.format(epoch,lr))\n",
    "    \n",
    "    def on_epoch_end(self,epoch,logs=None):\n",
    "        val_acc = logs.get('val_accuracy')\n",
    "        train_acc = logs.get('accuracy')\n",
    "        self.train_a.append(train_acc)\n",
    "        self.val_a.append(val_acc)\n",
    "        with open(self.logPath,'a') as f:\n",
    "            f.write('At epoch {:02d}, training accuracy: {:.3f}, validation accuracy: {:.3f}\\n'.format(epoch,train_acc,val_acc))\n",
    "        self.ax.clear()\n",
    "        self.ax.plot(range(1+epoch),self.train_a,label=\"Training\")\n",
    "        self.ax.plot(range(1+epoch),self.val_a,label=\"Validation\")\n",
    "        self.ax.set_xlabel('Epochs')\n",
    "        self.ax.set_ylabel('Accuracy')\n",
    "        self.ax.legend()\n",
    "        self.fig.canvas.draw()\n",
    "        self.fig.show()\n",
    "        \n",
    "class TimeHistory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.times = []\n",
    "\n",
    "    def on_epoch_begin(self, batch, logs={}):\n",
    "        self.epoch_time_start = time.time()\n",
    "\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.times.append(time.time() - self.epoch_time_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xception base model\n",
    "from tensorflow.keras.applications.xception import Xception\n",
    "from tensorflow.keras.applications.xception import preprocess_input, decode_predictions\n",
    "xceptionNetModel = Xception(weights='imagenet')\n",
    "\n",
    "# opticnet base model\n",
    "opticNetModel = tf.keras.models.load_model('../Optic_net-4_classes-Kermany2018.hdf5')\n",
    "\n",
    "# resnet base model\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "\n",
    "resNetModel = ResNet50(weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emptyModelGenerator(model, newWeights=False, lastOnly=False):\n",
    "    model = model.lower()\n",
    "    if model == \"resnet\":\n",
    "        x = resNetModel.output\n",
    "        predictions = Dense(len(labels_list), activation='softmax')(x)\n",
    "        newModel = Model(inputs=resNetModel.input, outputs=predictions)\n",
    "        size = (224, 224)\n",
    "        normalization = \"zerocenter\"\n",
    "    elif model == \"xception\":\n",
    "        x = xceptionNetModel.output\n",
    "        predictions = Dense(len(labels_list), activation='softmax')(x)\n",
    "        newModel = Model(inputs=xceptionNetModel.input, outputs=predictions)\n",
    "        size = (299, 299)\n",
    "        normalization = \"rescale-symmetric\"\n",
    "    elif model == \"opticnet\":\n",
    "        newModel = tf.keras.models.load_model('../Optic_net-4_classes-Kermany2018.hdf5')\n",
    "        size = (224, 224)\n",
    "        normalization = \"rescale-symmetric\"\n",
    "    if newWeights:\n",
    "        newModel = tf.keras.models.clone_model(newModel)\n",
    "    if lastOnly:\n",
    "        newModel = lastDenseTrainable(newModel) # block all layer except the last dense ones\n",
    "    return newModel, size, normalization\n",
    "\n",
    "\n",
    "def lastDenseTrainable(model):\n",
    "    model.trainable = False\n",
    "    for i in range(1, len(model.layers)):\n",
    "        if model.layers[-i].__class__.__name__ == \"Dense\":\n",
    "            model.layers[-i].trainable= True\n",
    "        elif model.layers[-i].__class__.__name__ == \"Activation\":\n",
    "            continue\n",
    "        else:\n",
    "            break\n",
    "    return model\n",
    "    \n",
    "\n",
    "def testPredict(model, size, name=None, normalization=None):\n",
    "    X_test = resizeIms(x_tst, size)\n",
    "    if normalization:\n",
    "        X_test = normalizeIms(X_test, normalization)\n",
    "    X_test = np.array(X_test)\n",
    "    Y_test = np.array(y_tst)\n",
    "    \n",
    "    prediction = model.predict(X_test)\n",
    "    preds = np.argmax(prediction, axis=1)\n",
    "    acc = sum(preds == Y_test) / len(Y_test)\n",
    "    print(f'Test acc for {name if name else \"model\"}: {acc:.6f}')\n",
    "    return acc\n",
    "    \n",
    "\n",
    "def computeConfussionMatrix(predictions, labels):\n",
    "    num_labels = len(labels_list)\n",
    "    cMatrix = np.zeros(shape=(num_labels, num_labels))\n",
    "    for i in len(predictions):\n",
    "        p = int(predictions[i])\n",
    "        t = int(predictions[i])\n",
    "        cMatrix[t, p] += 1\n",
    "    print(cMatrix)\n",
    "    ax = sns.heatmap(cMatrix, cmap=\"Blues\", annot=True, fmt=\"d\", xticklabels=labels_list, yticklabels=labels_list)\n",
    "    plt.xlabel(\"Predicted label\")\n",
    "    plt.ylabel(\"True label\")\n",
    "    plt.title(\"Confusion matrix\")\n",
    "    plt.show();\n",
    "    return cMatrix\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "**************************************************\n",
      "Model: xception\n",
      "**************************************************\n",
      "predictions True\n",
      "dense_50 True\n",
      "\n",
      "Total: 135 trainable: 2\n",
      "\n",
      "\n",
      "**************************************************\n",
      "Model: resnet\n",
      "**************************************************\n",
      "predictions True\n",
      "dense_51 True\n",
      "\n",
      "Total: 178 trainable: 2\n",
      "\n",
      "\n",
      "**************************************************\n",
      "Model: opticnet\n",
      "**************************************************\n",
      "Dense_1 True\n",
      "Dense_2 True\n",
      "\n",
      "Total: 276 trainable: 2\n"
     ]
    }
   ],
   "source": [
    "models = [\"xception\", \"resnet\", \"opticnet\"]\n",
    "\n",
    "for mod in models:\n",
    "    print(\"\\n\\n\" + (\"*\"*50) + \"\\nModel: \" + mod + '\\n' + (\"*\"*50))\n",
    "    m = emptyModelGenerator(mod, newWeights=False, lastOnly=True)[0]\n",
    "    #m.trainable = False\n",
    "    a = 0\n",
    "    for l in m.layers:\n",
    "        #l.trainable = True\n",
    "        if l.trainable:\n",
    "            print(l.name, l.trainable)\n",
    "            a += 1\n",
    "            #print(l.trainable_weights)\n",
    "    print(f\"\\nTotal: {len(m.layers)} trainable: {a}\")\n",
    "    #print(m.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "optim = Adam(learning_rate=lr)\n",
    "epochs = 30\n",
    "batch_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "results = pd.read_csv(\"Results.csv\")\n",
    "results[\"normalization\"] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels fraction: [0.01037431 0.00938046 0.01092704 0.01021356]\n",
      "Training xception for 0.01% of train size (aka 834 images) with pretrained: True and onlyLastLayersTrained: True...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-228-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      " 6/17 [=========>....................] - ETA: 5s - loss: 1.3971 - accuracy: 0.1561WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1259s vs `on_train_batch_begin` time: 0.1759s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1259s vs `on_train_batch_end` time: 0.1395s). Check your callbacks.\n",
      "17/17 [==============================] - 8s 324ms/step - loss: 1.3963 - accuracy: 0.1550 - val_loss: 1.3792 - val_accuracy: 0.3125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-228-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "17/17 [==============================] - 2s 136ms/step - loss: 1.3948 - accuracy: 0.1707 - val_loss: 1.3792 - val_accuracy: 0.3125\n",
      "Epoch 3/30\n",
      "17/17 [==============================] - 2s 136ms/step - loss: 1.3958 - accuracy: 0.1525 - val_loss: 1.3792 - val_accuracy: 0.3125\n",
      "Epoch 4/30\n",
      "17/17 [==============================] - 2s 137ms/step - loss: 1.3969 - accuracy: 0.1415 - val_loss: 1.3792 - val_accuracy: 0.3125\n",
      "Epoch 5/30\n",
      "17/17 [==============================] - 2s 134ms/step - loss: 1.3954 - accuracy: 0.1596 - val_loss: 1.3792 - val_accuracy: 0.3125\n",
      "Epoch 6/30\n",
      "17/17 [==============================] - 2s 138ms/step - loss: 1.3978 - accuracy: 0.1357 - val_loss: 1.3792 - val_accuracy: 0.3125\n",
      "Epoch 7/30\n",
      "17/17 [==============================] - 2s 137ms/step - loss: 1.3945 - accuracy: 0.1543 - val_loss: 1.3792 - val_accuracy: 0.3125\n",
      "Epoch 8/30\n",
      "17/17 [==============================] - 2s 138ms/step - loss: 1.3964 - accuracy: 0.1479 - val_loss: 1.3792 - val_accuracy: 0.3125\n",
      "Epoch 9/30\n",
      "17/17 [==============================] - 2s 137ms/step - loss: 1.3961 - accuracy: 0.1531 - val_loss: 1.3792 - val_accuracy: 0.3125\n",
      "Epoch 10/30\n",
      "17/17 [==============================] - 2s 139ms/step - loss: 1.3959 - accuracy: 0.1361 - val_loss: 1.3792 - val_accuracy: 0.3125\n",
      "Epoch 11/30\n",
      "17/17 [==============================] - 2s 136ms/step - loss: 1.3962 - accuracy: 0.1459 - val_loss: 1.3792 - val_accuracy: 0.3125\n",
      "Epoch 12/30\n",
      "17/17 [==============================] - 2s 139ms/step - loss: 1.3962 - accuracy: 0.1311 - val_loss: 1.3792 - val_accuracy: 0.3125\n",
      "Epoch 13/30\n",
      "17/17 [==============================] - 5s 330ms/step - loss: 1.3958 - accuracy: 0.1575 - val_loss: 1.3792 - val_accuracy: 0.3125\n",
      "Epoch 14/30\n",
      "17/17 [==============================] - 2s 139ms/step - loss: 1.3961 - accuracy: 0.1455 - val_loss: 1.3792 - val_accuracy: 0.3125\n",
      "Epoch 15/30\n",
      "17/17 [==============================] - 2s 138ms/step - loss: 1.3965 - accuracy: 0.1583 - val_loss: 1.3792 - val_accuracy: 0.3125\n",
      "Epoch 16/30\n",
      "17/17 [==============================] - 2s 140ms/step - loss: 1.3950 - accuracy: 0.1479 - val_loss: 1.3792 - val_accuracy: 0.3125\n",
      "Epoch 17/30\n",
      "17/17 [==============================] - 2s 139ms/step - loss: 1.3960 - accuracy: 0.1604 - val_loss: 1.3792 - val_accuracy: 0.3125\n",
      "Epoch 18/30\n",
      "17/17 [==============================] - 2s 140ms/step - loss: 1.3954 - accuracy: 0.1419 - val_loss: 1.3792 - val_accuracy: 0.3125\n",
      "Epoch 19/30\n",
      "17/17 [==============================] - 2s 138ms/step - loss: 1.3958 - accuracy: 0.1527 - val_loss: 1.3792 - val_accuracy: 0.3125\n",
      "Epoch 20/30\n",
      "17/17 [==============================] - 2s 140ms/step - loss: 1.3954 - accuracy: 0.1535 - val_loss: 1.3792 - val_accuracy: 0.3125\n",
      "Epoch 21/30\n",
      "17/17 [==============================] - 2s 140ms/step - loss: 1.3969 - accuracy: 0.1405 - val_loss: 1.3792 - val_accuracy: 0.3125\n",
      "Epoch 22/30\n",
      "17/17 [==============================] - 2s 138ms/step - loss: 1.3961 - accuracy: 0.1420 - val_loss: 1.3792 - val_accuracy: 0.3125\n",
      "Epoch 23/30\n",
      "17/17 [==============================] - 2s 139ms/step - loss: 1.3958 - accuracy: 0.1463 - val_loss: 1.3792 - val_accuracy: 0.3125\n",
      "Epoch 24/30\n",
      "17/17 [==============================] - 2s 138ms/step - loss: 1.3961 - accuracy: 0.1568 - val_loss: 1.3792 - val_accuracy: 0.3125\n",
      "Epoch 25/30\n",
      "17/17 [==============================] - 3s 151ms/step - loss: 1.3948 - accuracy: 0.1522 - val_loss: 1.3792 - val_accuracy: 0.3125\n",
      "Epoch 26/30\n",
      "17/17 [==============================] - 2s 140ms/step - loss: 1.3972 - accuracy: 0.1369 - val_loss: 1.3792 - val_accuracy: 0.3125\n",
      "Epoch 27/30\n",
      "17/17 [==============================] - 2s 140ms/step - loss: 1.3968 - accuracy: 0.1411 - val_loss: 1.3792 - val_accuracy: 0.3125\n",
      "Epoch 28/30\n",
      "17/17 [==============================] - 2s 140ms/step - loss: 1.3953 - accuracy: 0.1513 - val_loss: 1.3792 - val_accuracy: 0.3125\n",
      "Epoch 29/30\n",
      "17/17 [==============================] - 2s 140ms/step - loss: 1.3972 - accuracy: 0.1431 - val_loss: 1.3792 - val_accuracy: 0.3125\n",
      "Epoch 30/30\n",
      "17/17 [==============================] - 2s 140ms/step - loss: 1.3969 - accuracy: 0.1475 - val_loss: 1.3792 - val_accuracy: 0.3125\n",
      "INFO:tensorflow:Assets written to: ../xception/xception_30epochs_834.84_images_False_newWeights_True_lastLayerOnly_rescale-symmetric_normalization/assets\n",
      "Test acc for xception: 0.274793\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training resnet for 0.01% of train size (aka 834 images) with pretrained: True and onlyLastLayersTrained: True...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-228-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      " 6/17 [=========>....................] - ETA: 5s - loss: 1.3871 - accuracy: 0.1781WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0668s vs `on_train_batch_begin` time: 0.1662s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0668s vs `on_train_batch_end` time: 0.1649s). Check your callbacks.\n",
      "17/17 [==============================] - 8s 284ms/step - loss: 1.3872 - accuracy: 0.1590 - val_loss: 1.3861 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-228-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "17/17 [==============================] - 1s 70ms/step - loss: 1.3873 - accuracy: 0.1605 - val_loss: 1.3861 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "17/17 [==============================] - 1s 68ms/step - loss: 1.3874 - accuracy: 0.1346 - val_loss: 1.3861 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "17/17 [==============================] - 1s 68ms/step - loss: 1.3874 - accuracy: 0.1433 - val_loss: 1.3861 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "17/17 [==============================] - 1s 66ms/step - loss: 1.3873 - accuracy: 0.1394 - val_loss: 1.3861 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "17/17 [==============================] - 1s 67ms/step - loss: 1.3872 - accuracy: 0.1579 - val_loss: 1.3861 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "17/17 [==============================] - 1s 66ms/step - loss: 1.3874 - accuracy: 0.1455 - val_loss: 1.3861 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "17/17 [==============================] - 1s 68ms/step - loss: 1.3872 - accuracy: 0.1661 - val_loss: 1.3861 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "17/17 [==============================] - 1s 67ms/step - loss: 1.3873 - accuracy: 0.1605 - val_loss: 1.3861 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "17/17 [==============================] - 1s 68ms/step - loss: 1.3872 - accuracy: 0.1518 - val_loss: 1.3861 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "17/17 [==============================] - 1s 66ms/step - loss: 1.3874 - accuracy: 0.1457 - val_loss: 1.3861 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "17/17 [==============================] - 1s 68ms/step - loss: 1.3872 - accuracy: 0.1503 - val_loss: 1.3861 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "17/17 [==============================] - 1s 67ms/step - loss: 1.3873 - accuracy: 0.1375 - val_loss: 1.3861 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "17/17 [==============================] - 1s 67ms/step - loss: 1.3874 - accuracy: 0.1285 - val_loss: 1.3861 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "17/17 [==============================] - 1s 68ms/step - loss: 1.3873 - accuracy: 0.1518 - val_loss: 1.3861 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "17/17 [==============================] - 1s 67ms/step - loss: 1.3875 - accuracy: 0.1318 - val_loss: 1.3861 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "17/17 [==============================] - 1s 66ms/step - loss: 1.3873 - accuracy: 0.1494 - val_loss: 1.3861 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "17/17 [==============================] - 1s 68ms/step - loss: 1.3872 - accuracy: 0.1486 - val_loss: 1.3861 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "17/17 [==============================] - 1s 68ms/step - loss: 1.3871 - accuracy: 0.1616 - val_loss: 1.3861 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "17/17 [==============================] - 1s 67ms/step - loss: 1.3872 - accuracy: 0.1484 - val_loss: 1.3861 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "17/17 [==============================] - 1s 67ms/step - loss: 1.3872 - accuracy: 0.1584 - val_loss: 1.3861 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "17/17 [==============================] - 1s 67ms/step - loss: 1.3872 - accuracy: 0.1499 - val_loss: 1.3861 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "17/17 [==============================] - 1s 66ms/step - loss: 1.3873 - accuracy: 0.1407 - val_loss: 1.3861 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "17/17 [==============================] - 1s 68ms/step - loss: 1.3872 - accuracy: 0.1569 - val_loss: 1.3861 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "17/17 [==============================] - 1s 68ms/step - loss: 1.3873 - accuracy: 0.1468 - val_loss: 1.3861 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "17/17 [==============================] - 1s 68ms/step - loss: 1.3872 - accuracy: 0.1560 - val_loss: 1.3861 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "17/17 [==============================] - 1s 68ms/step - loss: 1.3872 - accuracy: 0.1537 - val_loss: 1.3861 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "17/17 [==============================] - 1s 67ms/step - loss: 1.3873 - accuracy: 0.1615 - val_loss: 1.3861 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "17/17 [==============================] - 1s 66ms/step - loss: 1.3872 - accuracy: 0.1570 - val_loss: 1.3861 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "17/17 [==============================] - 1s 65ms/step - loss: 1.3873 - accuracy: 0.1484 - val_loss: 1.3861 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_834.84_images_False_newWeights_True_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.260331\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training opticnet for 0.01% of train size (aka 834 images) with pretrained: True and onlyLastLayersTrained: True...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-228-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "17/17 [==============================] - 16s 591ms/step - loss: 16.2503 - accuracy: 0.1312 - val_loss: 11.7011 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-228-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "17/17 [==============================] - 5s 299ms/step - loss: 15.4443 - accuracy: 0.1486 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "17/17 [==============================] - 5s 300ms/step - loss: 15.8035 - accuracy: 0.1452 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "17/17 [==============================] - 5s 300ms/step - loss: 15.6392 - accuracy: 0.1444 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "17/17 [==============================] - 5s 301ms/step - loss: 15.8285 - accuracy: 0.1452 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "17/17 [==============================] - 5s 302ms/step - loss: 15.5520 - accuracy: 0.1610 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "17/17 [==============================] - 5s 300ms/step - loss: 16.0493 - accuracy: 0.1345 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "17/17 [==============================] - 5s 300ms/step - loss: 15.5294 - accuracy: 0.1544 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "17/17 [==============================] - 5s 300ms/step - loss: 15.6870 - accuracy: 0.1465 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "17/17 [==============================] - 5s 302ms/step - loss: 16.0109 - accuracy: 0.1374 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "17/17 [==============================] - 5s 301ms/step - loss: 15.6902 - accuracy: 0.1564 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "17/17 [==============================] - 5s 303ms/step - loss: 15.8270 - accuracy: 0.1533 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "17/17 [==============================] - 5s 303ms/step - loss: 15.5286 - accuracy: 0.1598 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "17/17 [==============================] - 5s 303ms/step - loss: 15.9204 - accuracy: 0.1511 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "17/17 [==============================] - 5s 303ms/step - loss: 15.6847 - accuracy: 0.1507 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "17/17 [==============================] - 5s 305ms/step - loss: 15.8673 - accuracy: 0.1473 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "17/17 [==============================] - 5s 302ms/step - loss: 15.9351 - accuracy: 0.1432 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "17/17 [==============================] - 5s 302ms/step - loss: 15.8987 - accuracy: 0.1463 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "17/17 [==============================] - 5s 304ms/step - loss: 15.6854 - accuracy: 0.1563 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "17/17 [==============================] - 5s 302ms/step - loss: 15.8772 - accuracy: 0.1455 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "17/17 [==============================] - 5s 303ms/step - loss: 15.8079 - accuracy: 0.1393 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "17/17 [==============================] - 5s 303ms/step - loss: 15.7867 - accuracy: 0.1460 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "17/17 [==============================] - 5s 303ms/step - loss: 15.6096 - accuracy: 0.1546 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "17/17 [==============================] - 5s 303ms/step - loss: 15.3273 - accuracy: 0.1783 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "17/17 [==============================] - 5s 303ms/step - loss: 16.0981 - accuracy: 0.1360 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "17/17 [==============================] - 5s 305ms/step - loss: 15.9351 - accuracy: 0.1395 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "17/17 [==============================] - 5s 309ms/step - loss: 16.0725 - accuracy: 0.1295 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "17/17 [==============================] - 5s 308ms/step - loss: 15.7397 - accuracy: 0.1388 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "17/17 [==============================] - 5s 303ms/step - loss: 15.3106 - accuracy: 0.1580 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "17/17 [==============================] - 5s 301ms/step - loss: 15.7731 - accuracy: 0.1423 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../opticnet/opticnet_30epochs_834.84_images_False_newWeights_True_lastLayerOnly_rescale-symmetric_normalization/assets\n",
      "Test acc for opticnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.02485275 0.02486225 0.02511456 0.02588208]\n",
      "Training xception for 0.025% of train size (aka 2087 images) with pretrained: True and onlyLastLayersTrained: True...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-228-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      " 6/42 [===>..........................] - ETA: 19s - loss: 1.3841 - accuracy: 0.2659WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1278s vs `on_train_batch_begin` time: 0.1404s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1278s vs `on_train_batch_end` time: 0.2132s). Check your callbacks.\n",
      "42/42 [==============================] - 12s 224ms/step - loss: 1.3829 - accuracy: 0.3040 - val_loss: 1.3844 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-228-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "42/42 [==============================] - 6s 131ms/step - loss: 1.3813 - accuracy: 0.3387 - val_loss: 1.3844 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "42/42 [==============================] - 6s 133ms/step - loss: 1.3815 - accuracy: 0.3429 - val_loss: 1.3844 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "42/42 [==============================] - 6s 134ms/step - loss: 1.3822 - accuracy: 0.3329 - val_loss: 1.3844 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "42/42 [==============================] - 6s 133ms/step - loss: 1.3830 - accuracy: 0.3086 - val_loss: 1.3844 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "42/42 [==============================] - 6s 135ms/step - loss: 1.3828 - accuracy: 0.3178 - val_loss: 1.3844 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "42/42 [==============================] - 6s 135ms/step - loss: 1.3821 - accuracy: 0.3368 - val_loss: 1.3844 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "42/42 [==============================] - 6s 135ms/step - loss: 1.3822 - accuracy: 0.3265 - val_loss: 1.3844 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "42/42 [==============================] - 6s 136ms/step - loss: 1.3822 - accuracy: 0.3287 - val_loss: 1.3844 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "42/42 [==============================] - 6s 135ms/step - loss: 1.3822 - accuracy: 0.3282 - val_loss: 1.3844 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "42/42 [==============================] - 6s 137ms/step - loss: 1.3827 - accuracy: 0.3123 - val_loss: 1.3844 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "42/42 [==============================] - 6s 135ms/step - loss: 1.3827 - accuracy: 0.3190 - val_loss: 1.3844 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "42/42 [==============================] - 6s 137ms/step - loss: 1.3819 - accuracy: 0.3319 - val_loss: 1.3844 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "42/42 [==============================] - 6s 138ms/step - loss: 1.3835 - accuracy: 0.3059 - val_loss: 1.3844 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "42/42 [==============================] - 6s 137ms/step - loss: 1.3822 - accuracy: 0.3247 - val_loss: 1.3844 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "42/42 [==============================] - 6s 136ms/step - loss: 1.3827 - accuracy: 0.3132 - val_loss: 1.3844 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "42/42 [==============================] - 6s 137ms/step - loss: 1.3827 - accuracy: 0.3270 - val_loss: 1.3844 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "42/42 [==============================] - 6s 137ms/step - loss: 1.3832 - accuracy: 0.3054 - val_loss: 1.3844 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "42/42 [==============================] - 6s 135ms/step - loss: 1.3829 - accuracy: 0.3110 - val_loss: 1.3844 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "42/42 [==============================] - 6s 137ms/step - loss: 1.3841 - accuracy: 0.3007 - val_loss: 1.3844 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "42/42 [==============================] - 6s 136ms/step - loss: 1.3822 - accuracy: 0.3328 - val_loss: 1.3844 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "42/42 [==============================] - 6s 137ms/step - loss: 1.3826 - accuracy: 0.3188 - val_loss: 1.3844 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "42/42 [==============================] - 6s 137ms/step - loss: 1.3832 - accuracy: 0.3053 - val_loss: 1.3844 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "42/42 [==============================] - 6s 136ms/step - loss: 1.3825 - accuracy: 0.3224 - val_loss: 1.3844 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "42/42 [==============================] - 6s 136ms/step - loss: 1.3821 - accuracy: 0.3281 - val_loss: 1.3844 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "42/42 [==============================] - 6s 136ms/step - loss: 1.3819 - accuracy: 0.3316 - val_loss: 1.3844 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "42/42 [==============================] - 6s 135ms/step - loss: 1.3824 - accuracy: 0.3194 - val_loss: 1.3844 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "42/42 [==============================] - 6s 136ms/step - loss: 1.3828 - accuracy: 0.3169 - val_loss: 1.3844 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "42/42 [==============================] - 6s 133ms/step - loss: 1.3831 - accuracy: 0.3053 - val_loss: 1.3844 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "42/42 [==============================] - 6s 135ms/step - loss: 1.3830 - accuracy: 0.3109 - val_loss: 1.3844 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../xception/xception_30epochs_2087.1_images_False_newWeights_True_lastLayerOnly_rescale-symmetric_normalization/assets\n",
      "Test acc for xception: 0.262397\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training resnet for 0.025% of train size (aka 2087 images) with pretrained: True and onlyLastLayersTrained: True...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-228-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      " 6/42 [===>..........................] - ETA: 15s - loss: 1.3835 - accuracy: 0.4492WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0630s vs `on_train_batch_begin` time: 0.1427s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0630s vs `on_train_batch_end` time: 0.1539s). Check your callbacks.\n",
      "42/42 [==============================] - 10s 152ms/step - loss: 1.3837 - accuracy: 0.4415 - val_loss: 1.3861 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-228-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "42/42 [==============================] - 3s 62ms/step - loss: 1.3836 - accuracy: 0.4485 - val_loss: 1.3861 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "42/42 [==============================] - 3s 62ms/step - loss: 1.3837 - accuracy: 0.4487 - val_loss: 1.3861 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "42/42 [==============================] - 3s 62ms/step - loss: 1.3837 - accuracy: 0.4416 - val_loss: 1.3861 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "42/42 [==============================] - 3s 62ms/step - loss: 1.3835 - accuracy: 0.4505 - val_loss: 1.3861 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "42/42 [==============================] - 3s 63ms/step - loss: 1.3837 - accuracy: 0.4340 - val_loss: 1.3861 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "42/42 [==============================] - 3s 64ms/step - loss: 1.3838 - accuracy: 0.4296 - val_loss: 1.3861 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "42/42 [==============================] - 3s 65ms/step - loss: 1.3837 - accuracy: 0.4462 - val_loss: 1.3861 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "42/42 [==============================] - 3s 65ms/step - loss: 1.3837 - accuracy: 0.4390 - val_loss: 1.3861 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "42/42 [==============================] - 3s 65ms/step - loss: 1.3838 - accuracy: 0.4213 - val_loss: 1.3861 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "42/42 [==============================] - 3s 65ms/step - loss: 1.3836 - accuracy: 0.4429 - val_loss: 1.3861 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "42/42 [==============================] - 3s 63ms/step - loss: 1.3836 - accuracy: 0.4515 - val_loss: 1.3861 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "42/42 [==============================] - 3s 63ms/step - loss: 1.3839 - accuracy: 0.4196 - val_loss: 1.3861 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "42/42 [==============================] - 3s 62ms/step - loss: 1.3838 - accuracy: 0.4337 - val_loss: 1.3861 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "42/42 [==============================] - 3s 63ms/step - loss: 1.3836 - accuracy: 0.4554 - val_loss: 1.3861 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "42/42 [==============================] - 3s 62ms/step - loss: 1.3837 - accuracy: 0.4409 - val_loss: 1.3861 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "42/42 [==============================] - 3s 64ms/step - loss: 1.3836 - accuracy: 0.4515 - val_loss: 1.3861 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "42/42 [==============================] - 3s 62ms/step - loss: 1.3837 - accuracy: 0.4450 - val_loss: 1.3861 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "42/42 [==============================] - 3s 64ms/step - loss: 1.3837 - accuracy: 0.4388 - val_loss: 1.3861 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "42/42 [==============================] - 3s 64ms/step - loss: 1.3836 - accuracy: 0.4488 - val_loss: 1.3861 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "42/42 [==============================] - 3s 62ms/step - loss: 1.3839 - accuracy: 0.4356 - val_loss: 1.3861 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "42/42 [==============================] - 3s 63ms/step - loss: 1.3835 - accuracy: 0.4524 - val_loss: 1.3861 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "42/42 [==============================] - 3s 63ms/step - loss: 1.3838 - accuracy: 0.4383 - val_loss: 1.3861 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "42/42 [==============================] - 3s 63ms/step - loss: 1.3836 - accuracy: 0.4471 - val_loss: 1.3861 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "42/42 [==============================] - 3s 62ms/step - loss: 1.3839 - accuracy: 0.4203 - val_loss: 1.3861 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "42/42 [==============================] - 3s 63ms/step - loss: 1.3838 - accuracy: 0.4370 - val_loss: 1.3861 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "42/42 [==============================] - 3s 63ms/step - loss: 1.3839 - accuracy: 0.4332 - val_loss: 1.3861 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "42/42 [==============================] - 3s 62ms/step - loss: 1.3837 - accuracy: 0.4429 - val_loss: 1.3861 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "42/42 [==============================] - 3s 62ms/step - loss: 1.3838 - accuracy: 0.4249 - val_loss: 1.3861 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "42/42 [==============================] - 3s 64ms/step - loss: 1.3835 - accuracy: 0.4650 - val_loss: 1.3861 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_2087.1_images_False_newWeights_True_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training opticnet for 0.025% of train size (aka 2087 images) with pretrained: True and onlyLastLayersTrained: True...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-228-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "42/42 [==============================] - 25s 439ms/step - loss: 15.8070 - accuracy: 0.1405 - val_loss: 11.7011 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-228-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "42/42 [==============================] - 12s 294ms/step - loss: 16.1396 - accuracy: 0.1379 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "42/42 [==============================] - 12s 294ms/step - loss: 16.1587 - accuracy: 0.1223 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "42/42 [==============================] - 12s 295ms/step - loss: 15.7544 - accuracy: 0.1447 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "42/42 [==============================] - 12s 296ms/step - loss: 16.1824 - accuracy: 0.1261 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "42/42 [==============================] - 12s 296ms/step - loss: 16.2104 - accuracy: 0.1339 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "42/42 [==============================] - 13s 298ms/step - loss: 16.3614 - accuracy: 0.1250 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "42/42 [==============================] - 13s 299ms/step - loss: 16.0502 - accuracy: 0.1346 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "42/42 [==============================] - 13s 298ms/step - loss: 16.0609 - accuracy: 0.1374 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "42/42 [==============================] - 13s 300ms/step - loss: 16.0038 - accuracy: 0.1365 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "42/42 [==============================] - 12s 297ms/step - loss: 15.6700 - accuracy: 0.1517 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "42/42 [==============================] - 12s 297ms/step - loss: 15.8259 - accuracy: 0.1367 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "42/42 [==============================] - 12s 297ms/step - loss: 15.9103 - accuracy: 0.1388 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "42/42 [==============================] - 13s 298ms/step - loss: 15.7631 - accuracy: 0.1507 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "42/42 [==============================] - 13s 298ms/step - loss: 16.0988 - accuracy: 0.1392 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "42/42 [==============================] - 13s 299ms/step - loss: 16.0657 - accuracy: 0.1365 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "42/42 [==============================] - 13s 300ms/step - loss: 15.9210 - accuracy: 0.1408 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "42/42 [==============================] - 13s 299ms/step - loss: 15.9826 - accuracy: 0.1367 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "42/42 [==============================] - 12s 297ms/step - loss: 15.9937 - accuracy: 0.1396 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "42/42 [==============================] - 12s 296ms/step - loss: 15.8845 - accuracy: 0.1437 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "42/42 [==============================] - 12s 297ms/step - loss: 15.6782 - accuracy: 0.1523 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "42/42 [==============================] - 12s 297ms/step - loss: 15.9551 - accuracy: 0.1376 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "42/42 [==============================] - 12s 297ms/step - loss: 15.8835 - accuracy: 0.1429 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "42/42 [==============================] - 12s 297ms/step - loss: 15.9925 - accuracy: 0.1326 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "42/42 [==============================] - 12s 297ms/step - loss: 15.9592 - accuracy: 0.1332 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "42/42 [==============================] - 12s 297ms/step - loss: 15.9833 - accuracy: 0.1339 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "42/42 [==============================] - 12s 296ms/step - loss: 15.9036 - accuracy: 0.1342 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "42/42 [==============================] - 12s 298ms/step - loss: 15.9945 - accuracy: 0.1352 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "42/42 [==============================] - 12s 296ms/step - loss: 16.0413 - accuracy: 0.1385 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "42/42 [==============================] - 12s 296ms/step - loss: 16.0127 - accuracy: 0.1325 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../opticnet/opticnet_30epochs_2087.1_images_False_newWeights_True_lastLayerOnly_rescale-symmetric_normalization/assets\n",
      "Test acc for opticnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.04905947 0.05004704 0.05049348 0.05199629]\n",
      "Training xception for 0.05% of train size (aka 4174 images) with pretrained: True and onlyLastLayersTrained: True...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-228-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      " 6/84 [=>............................] - ETA: 41s - loss: 1.4023 - accuracy: 0.1128WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1240s vs `on_train_batch_begin` time: 0.1421s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1240s vs `on_train_batch_end` time: 0.2027s). Check your callbacks.\n",
      "84/84 [==============================] - 17s 171ms/step - loss: 1.4000 - accuracy: 0.1242 - val_loss: 1.3830 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-228-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "84/84 [==============================] - 11s 128ms/step - loss: 1.3986 - accuracy: 0.1306 - val_loss: 1.3830 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "84/84 [==============================] - 11s 130ms/step - loss: 1.3986 - accuracy: 0.1295 - val_loss: 1.3830 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "84/84 [==============================] - 11s 131ms/step - loss: 1.3990 - accuracy: 0.1226 - val_loss: 1.3830 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "84/84 [==============================] - 11s 134ms/step - loss: 1.3989 - accuracy: 0.1225 - val_loss: 1.3830 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "84/84 [==============================] - 11s 131ms/step - loss: 1.3986 - accuracy: 0.1319 - val_loss: 1.3830 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "84/84 [==============================] - 11s 134ms/step - loss: 1.3990 - accuracy: 0.1237 - val_loss: 1.3830 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "84/84 [==============================] - 12s 137ms/step - loss: 1.3988 - accuracy: 0.1273 - val_loss: 1.3830 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "84/84 [==============================] - 11s 134ms/step - loss: 1.3990 - accuracy: 0.1202 - val_loss: 1.3830 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "84/84 [==============================] - 11s 134ms/step - loss: 1.3990 - accuracy: 0.1288 - val_loss: 1.3830 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "84/84 [==============================] - 11s 133ms/step - loss: 1.3984 - accuracy: 0.1271 - val_loss: 1.3830 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "84/84 [==============================] - 11s 136ms/step - loss: 1.3985 - accuracy: 0.1183 - val_loss: 1.3830 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "84/84 [==============================] - 11s 133ms/step - loss: 1.3994 - accuracy: 0.1189 - val_loss: 1.3830 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "84/84 [==============================] - 11s 134ms/step - loss: 1.3989 - accuracy: 0.1246 - val_loss: 1.3830 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "84/84 [==============================] - 11s 133ms/step - loss: 1.3993 - accuracy: 0.1164 - val_loss: 1.3830 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "84/84 [==============================] - 11s 133ms/step - loss: 1.3987 - accuracy: 0.1281 - val_loss: 1.3830 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "84/84 [==============================] - 11s 133ms/step - loss: 1.3984 - accuracy: 0.1294 - val_loss: 1.3830 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "84/84 [==============================] - 11s 134ms/step - loss: 1.3994 - accuracy: 0.1254 - val_loss: 1.3830 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "84/84 [==============================] - 11s 133ms/step - loss: 1.3991 - accuracy: 0.1247 - val_loss: 1.3830 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "84/84 [==============================] - 11s 135ms/step - loss: 1.3988 - accuracy: 0.1220 - val_loss: 1.3830 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "84/84 [==============================] - 11s 134ms/step - loss: 1.3988 - accuracy: 0.1247 - val_loss: 1.3830 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "84/84 [==============================] - 11s 133ms/step - loss: 1.3989 - accuracy: 0.1221 - val_loss: 1.3830 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "84/84 [==============================] - 11s 135ms/step - loss: 1.3982 - accuracy: 0.1341 - val_loss: 1.3830 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "84/84 [==============================] - 12s 139ms/step - loss: 1.3998 - accuracy: 0.1157 - val_loss: 1.3830 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "84/84 [==============================] - 11s 135ms/step - loss: 1.3988 - accuracy: 0.1289 - val_loss: 1.3830 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "84/84 [==============================] - 11s 133ms/step - loss: 1.3985 - accuracy: 0.1241 - val_loss: 1.3830 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "84/84 [==============================] - 11s 133ms/step - loss: 1.3987 - accuracy: 0.1344 - val_loss: 1.3830 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "84/84 [==============================] - 11s 133ms/step - loss: 1.3988 - accuracy: 0.1263 - val_loss: 1.3830 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "84/84 [==============================] - 11s 133ms/step - loss: 1.3989 - accuracy: 0.1252 - val_loss: 1.3830 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "84/84 [==============================] - 11s 133ms/step - loss: 1.3990 - accuracy: 0.1274 - val_loss: 1.3830 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../xception/xception_30epochs_4174.2_images_False_newWeights_True_lastLayerOnly_rescale-symmetric_normalization/assets\n",
      "Test acc for xception: 0.233471\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training resnet for 0.05% of train size (aka 4174 images) with pretrained: True and onlyLastLayersTrained: True...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-228-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      " 6/84 [=>............................] - ETA: 34s - loss: 1.3880 - accuracy: 0.1207WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0635s vs `on_train_batch_begin` time: 0.1640s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0635s vs `on_train_batch_end` time: 0.1540s). Check your callbacks.\n",
      "84/84 [==============================] - 12s 106ms/step - loss: 1.3880 - accuracy: 0.1202 - val_loss: 1.3863 - val_accuracy: 0.2812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-228-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "84/84 [==============================] - 5s 61ms/step - loss: 1.3879 - accuracy: 0.1234 - val_loss: 1.3863 - val_accuracy: 0.2812\n",
      "Epoch 3/30\n",
      "84/84 [==============================] - 5s 62ms/step - loss: 1.3879 - accuracy: 0.1179 - val_loss: 1.3863 - val_accuracy: 0.2812\n",
      "Epoch 4/30\n",
      "84/84 [==============================] - 5s 62ms/step - loss: 1.3879 - accuracy: 0.1335 - val_loss: 1.3863 - val_accuracy: 0.2812\n",
      "Epoch 5/30\n",
      "84/84 [==============================] - 5s 62ms/step - loss: 1.3878 - accuracy: 0.1347 - val_loss: 1.3863 - val_accuracy: 0.2812\n",
      "Epoch 6/30\n",
      "84/84 [==============================] - 5s 62ms/step - loss: 1.3879 - accuracy: 0.1259 - val_loss: 1.3863 - val_accuracy: 0.2812\n",
      "Epoch 7/30\n",
      "84/84 [==============================] - 5s 62ms/step - loss: 1.3879 - accuracy: 0.1196 - val_loss: 1.3863 - val_accuracy: 0.2812\n",
      "Epoch 8/30\n",
      "84/84 [==============================] - 5s 64ms/step - loss: 1.3879 - accuracy: 0.1305 - val_loss: 1.3863 - val_accuracy: 0.2812\n",
      "Epoch 9/30\n",
      "84/84 [==============================] - 5s 63ms/step - loss: 1.3879 - accuracy: 0.1159 - val_loss: 1.3863 - val_accuracy: 0.2812\n",
      "Epoch 10/30\n",
      "84/84 [==============================] - 5s 62ms/step - loss: 1.3879 - accuracy: 0.1247 - val_loss: 1.3863 - val_accuracy: 0.2812\n",
      "Epoch 11/30\n",
      "84/84 [==============================] - 5s 62ms/step - loss: 1.3880 - accuracy: 0.1272 - val_loss: 1.3863 - val_accuracy: 0.2812\n",
      "Epoch 12/30\n",
      "84/84 [==============================] - 5s 63ms/step - loss: 1.3879 - accuracy: 0.1274 - val_loss: 1.3863 - val_accuracy: 0.2812\n",
      "Epoch 13/30\n",
      "84/84 [==============================] - 5s 62ms/step - loss: 1.3879 - accuracy: 0.1246 - val_loss: 1.3863 - val_accuracy: 0.2812\n",
      "Epoch 14/30\n",
      "84/84 [==============================] - 5s 64ms/step - loss: 1.3878 - accuracy: 0.1331 - val_loss: 1.3863 - val_accuracy: 0.2812\n",
      "Epoch 15/30\n",
      "84/84 [==============================] - 5s 64ms/step - loss: 1.3879 - accuracy: 0.1237 - val_loss: 1.3863 - val_accuracy: 0.2812\n",
      "Epoch 16/30\n",
      "84/84 [==============================] - 5s 63ms/step - loss: 1.3878 - accuracy: 0.1293 - val_loss: 1.3863 - val_accuracy: 0.2812\n",
      "Epoch 17/30\n",
      "84/84 [==============================] - 5s 64ms/step - loss: 1.3880 - accuracy: 0.1253 - val_loss: 1.3863 - val_accuracy: 0.2812\n",
      "Epoch 18/30\n",
      "84/84 [==============================] - 5s 63ms/step - loss: 1.3880 - accuracy: 0.1258 - val_loss: 1.3863 - val_accuracy: 0.2812\n",
      "Epoch 19/30\n",
      "84/84 [==============================] - 5s 64ms/step - loss: 1.3880 - accuracy: 0.1226 - val_loss: 1.3863 - val_accuracy: 0.2812\n",
      "Epoch 20/30\n",
      "84/84 [==============================] - 5s 62ms/step - loss: 1.3880 - accuracy: 0.1273 - val_loss: 1.3863 - val_accuracy: 0.2812\n",
      "Epoch 21/30\n",
      "84/84 [==============================] - 5s 62ms/step - loss: 1.3879 - accuracy: 0.1376 - val_loss: 1.3863 - val_accuracy: 0.2812\n",
      "Epoch 22/30\n",
      "84/84 [==============================] - 5s 64ms/step - loss: 1.3878 - accuracy: 0.1362 - val_loss: 1.3863 - val_accuracy: 0.2812\n",
      "Epoch 23/30\n",
      "84/84 [==============================] - 5s 64ms/step - loss: 1.3879 - accuracy: 0.1299 - val_loss: 1.3863 - val_accuracy: 0.2812\n",
      "Epoch 24/30\n",
      "84/84 [==============================] - 5s 64ms/step - loss: 1.3879 - accuracy: 0.1239 - val_loss: 1.3863 - val_accuracy: 0.2812\n",
      "Epoch 25/30\n",
      "84/84 [==============================] - 5s 64ms/step - loss: 1.3878 - accuracy: 0.1340 - val_loss: 1.3863 - val_accuracy: 0.2812\n",
      "Epoch 26/30\n",
      "84/84 [==============================] - 5s 63ms/step - loss: 1.3880 - accuracy: 0.1254 - val_loss: 1.3863 - val_accuracy: 0.2812\n",
      "Epoch 27/30\n",
      "84/84 [==============================] - 5s 63ms/step - loss: 1.3880 - accuracy: 0.1188 - val_loss: 1.3863 - val_accuracy: 0.2812\n",
      "Epoch 28/30\n",
      "84/84 [==============================] - 5s 63ms/step - loss: 1.3879 - accuracy: 0.1153 - val_loss: 1.3863 - val_accuracy: 0.2812\n",
      "Epoch 29/30\n",
      "84/84 [==============================] - 5s 64ms/step - loss: 1.3879 - accuracy: 0.1248 - val_loss: 1.3863 - val_accuracy: 0.2812\n",
      "Epoch 30/30\n",
      "84/84 [==============================] - 5s 64ms/step - loss: 1.3879 - accuracy: 0.1225 - val_loss: 1.3863 - val_accuracy: 0.2812\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_4174.2_images_False_newWeights_True_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.264463\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training opticnet for 0.05% of train size (aka 4174 images) with pretrained: True and onlyLastLayersTrained: True...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-228-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "84/84 [==============================] - 36s 355ms/step - loss: 16.0315 - accuracy: 0.1285 - val_loss: 11.7011 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-228-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "84/84 [==============================] - 25s 292ms/step - loss: 15.8599 - accuracy: 0.1416 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "84/84 [==============================] - 25s 293ms/step - loss: 16.1926 - accuracy: 0.1299 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "84/84 [==============================] - 25s 292ms/step - loss: 15.8516 - accuracy: 0.1391 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "84/84 [==============================] - 25s 293ms/step - loss: 16.0077 - accuracy: 0.1343 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "84/84 [==============================] - 25s 294ms/step - loss: 16.2689 - accuracy: 0.1279 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "84/84 [==============================] - 25s 296ms/step - loss: 15.9901 - accuracy: 0.1355 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "84/84 [==============================] - 25s 295ms/step - loss: 16.0103 - accuracy: 0.1327 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "84/84 [==============================] - 25s 297ms/step - loss: 16.0437 - accuracy: 0.1329 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "84/84 [==============================] - 25s 295ms/step - loss: 15.9589 - accuracy: 0.1363 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "84/84 [==============================] - 25s 294ms/step - loss: 15.8222 - accuracy: 0.1434 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "84/84 [==============================] - 25s 294ms/step - loss: 15.8691 - accuracy: 0.1381 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "84/84 [==============================] - 25s 295ms/step - loss: 15.9701 - accuracy: 0.1326 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "84/84 [==============================] - 25s 294ms/step - loss: 15.7918 - accuracy: 0.1428 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "84/84 [==============================] - 25s 295ms/step - loss: 15.8354 - accuracy: 0.1417 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "84/84 [==============================] - 25s 293ms/step - loss: 16.0259 - accuracy: 0.1332 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "84/84 [==============================] - 25s 293ms/step - loss: 15.9345 - accuracy: 0.1381 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "84/84 [==============================] - 25s 293ms/step - loss: 15.9666 - accuracy: 0.1389 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "84/84 [==============================] - 25s 293ms/step - loss: 15.9428 - accuracy: 0.1391 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "84/84 [==============================] - 25s 294ms/step - loss: 15.9278 - accuracy: 0.1351 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "84/84 [==============================] - 25s 295ms/step - loss: 15.9757 - accuracy: 0.1379 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "84/84 [==============================] - 25s 293ms/step - loss: 15.7152 - accuracy: 0.1433 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "84/84 [==============================] - 25s 292ms/step - loss: 15.9470 - accuracy: 0.1340 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "84/84 [==============================] - 25s 293ms/step - loss: 15.9932 - accuracy: 0.1316 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "84/84 [==============================] - 25s 293ms/step - loss: 15.9188 - accuracy: 0.1387 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "84/84 [==============================] - 25s 295ms/step - loss: 16.0898 - accuracy: 0.1308 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "84/84 [==============================] - 25s 294ms/step - loss: 16.0445 - accuracy: 0.1330 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "84/84 [==============================] - 25s 293ms/step - loss: 15.8934 - accuracy: 0.1381 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "84/84 [==============================] - 25s 294ms/step - loss: 15.7696 - accuracy: 0.1407 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "84/84 [==============================] - 25s 293ms/step - loss: 15.9566 - accuracy: 0.1318 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../opticnet/opticnet_30epochs_4174.2_images_False_newWeights_True_lastLayerOnly_rescale-symmetric_normalization/assets\n",
      "Test acc for opticnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.07474824 0.07533934 0.07472682 0.0746286 ]\n",
      "Training xception for 0.075% of train size (aka 6261 images) with pretrained: True and onlyLastLayersTrained: True...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-228-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/126 [>.............................] - ETA: 1:06 - loss: 1.3913 - accuracy: 0.1546WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1241s vs `on_train_batch_end` time: 0.2329s). Check your callbacks.\n",
      "126/126 [==============================] - 23s 155ms/step - loss: 1.3911 - accuracy: 0.1574 - val_loss: 1.3857 - val_accuracy: 0.3125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-228-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "126/126 [==============================] - 16s 130ms/step - loss: 1.3913 - accuracy: 0.1593 - val_loss: 1.3857 - val_accuracy: 0.3125\n",
      "Epoch 3/30\n",
      "126/126 [==============================] - 16s 130ms/step - loss: 1.3911 - accuracy: 0.1601 - val_loss: 1.3857 - val_accuracy: 0.3125\n",
      "Epoch 4/30\n",
      "126/126 [==============================] - 17s 132ms/step - loss: 1.3910 - accuracy: 0.1599 - val_loss: 1.3857 - val_accuracy: 0.3125\n",
      "Epoch 5/30\n",
      "126/126 [==============================] - 17s 132ms/step - loss: 1.3911 - accuracy: 0.1604 - val_loss: 1.3857 - val_accuracy: 0.3125\n",
      "Epoch 6/30\n",
      "126/126 [==============================] - 17s 132ms/step - loss: 1.3909 - accuracy: 0.1675 - val_loss: 1.3857 - val_accuracy: 0.3125\n",
      "Epoch 7/30\n",
      "126/126 [==============================] - 17s 132ms/step - loss: 1.3911 - accuracy: 0.1526 - val_loss: 1.3857 - val_accuracy: 0.3125\n",
      "Epoch 8/30\n",
      "126/126 [==============================] - 17s 133ms/step - loss: 1.3907 - accuracy: 0.1590 - val_loss: 1.3857 - val_accuracy: 0.3125\n",
      "Epoch 9/30\n",
      "126/126 [==============================] - 17s 134ms/step - loss: 1.3909 - accuracy: 0.1631 - val_loss: 1.3857 - val_accuracy: 0.3125\n",
      "Epoch 10/30\n",
      "126/126 [==============================] - 17s 136ms/step - loss: 1.3907 - accuracy: 0.1638 - val_loss: 1.3857 - val_accuracy: 0.3125\n",
      "Epoch 11/30\n",
      "126/126 [==============================] - 17s 135ms/step - loss: 1.3912 - accuracy: 0.1565 - val_loss: 1.3857 - val_accuracy: 0.3125\n",
      "Epoch 12/30\n",
      "126/126 [==============================] - 17s 134ms/step - loss: 1.3910 - accuracy: 0.1551 - val_loss: 1.3857 - val_accuracy: 0.3125\n",
      "Epoch 13/30\n",
      "126/126 [==============================] - 17s 134ms/step - loss: 1.3910 - accuracy: 0.1574 - val_loss: 1.3857 - val_accuracy: 0.3125\n",
      "Epoch 14/30\n",
      "126/126 [==============================] - 17s 134ms/step - loss: 1.3910 - accuracy: 0.1585 - val_loss: 1.3857 - val_accuracy: 0.3125\n",
      "Epoch 15/30\n",
      "126/126 [==============================] - 17s 134ms/step - loss: 1.3909 - accuracy: 0.1633 - val_loss: 1.3857 - val_accuracy: 0.3125\n",
      "Epoch 16/30\n",
      "126/126 [==============================] - 17s 133ms/step - loss: 1.3908 - accuracy: 0.1677 - val_loss: 1.3857 - val_accuracy: 0.3125\n",
      "Epoch 17/30\n",
      "126/126 [==============================] - 17s 135ms/step - loss: 1.3910 - accuracy: 0.1615 - val_loss: 1.3857 - val_accuracy: 0.3125\n",
      "Epoch 18/30\n",
      "126/126 [==============================] - 17s 135ms/step - loss: 1.3907 - accuracy: 0.1629 - val_loss: 1.3857 - val_accuracy: 0.3125\n",
      "Epoch 19/30\n",
      "126/126 [==============================] - 17s 134ms/step - loss: 1.3904 - accuracy: 0.1651 - val_loss: 1.3857 - val_accuracy: 0.3125\n",
      "Epoch 20/30\n",
      "126/126 [==============================] - 17s 136ms/step - loss: 1.3908 - accuracy: 0.1573 - val_loss: 1.3857 - val_accuracy: 0.3125\n",
      "Epoch 21/30\n",
      "126/126 [==============================] - 17s 135ms/step - loss: 1.3907 - accuracy: 0.1629 - val_loss: 1.3857 - val_accuracy: 0.3125\n",
      "Epoch 22/30\n",
      "126/126 [==============================] - 17s 133ms/step - loss: 1.3909 - accuracy: 0.1572 - val_loss: 1.3857 - val_accuracy: 0.3125\n",
      "Epoch 23/30\n",
      "126/126 [==============================] - 17s 133ms/step - loss: 1.3916 - accuracy: 0.1484 - val_loss: 1.3857 - val_accuracy: 0.3125\n",
      "Epoch 24/30\n",
      "126/126 [==============================] - 17s 134ms/step - loss: 1.3907 - accuracy: 0.1644 - val_loss: 1.3857 - val_accuracy: 0.3125\n",
      "Epoch 25/30\n",
      "126/126 [==============================] - 17s 136ms/step - loss: 1.3912 - accuracy: 0.1603 - val_loss: 1.3857 - val_accuracy: 0.3125\n",
      "Epoch 26/30\n",
      "126/126 [==============================] - 17s 134ms/step - loss: 1.3910 - accuracy: 0.1584 - val_loss: 1.3857 - val_accuracy: 0.3125\n",
      "Epoch 27/30\n",
      "126/126 [==============================] - 17s 135ms/step - loss: 1.3907 - accuracy: 0.1622 - val_loss: 1.3857 - val_accuracy: 0.3125\n",
      "Epoch 28/30\n",
      "126/126 [==============================] - 17s 134ms/step - loss: 1.3912 - accuracy: 0.1598 - val_loss: 1.3857 - val_accuracy: 0.3125\n",
      "Epoch 29/30\n",
      "126/126 [==============================] - 17s 134ms/step - loss: 1.3903 - accuracy: 0.1631 - val_loss: 1.3857 - val_accuracy: 0.3125\n",
      "Epoch 30/30\n",
      "126/126 [==============================] - 17s 133ms/step - loss: 1.3910 - accuracy: 0.1621 - val_loss: 1.3857 - val_accuracy: 0.3125\n",
      "INFO:tensorflow:Assets written to: ../xception/xception_30epochs_6261.3_images_False_newWeights_True_lastLayerOnly_rescale-symmetric_normalization/assets\n",
      "Test acc for xception: 0.246901\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training resnet for 0.075% of train size (aka 6261 images) with pretrained: True and onlyLastLayersTrained: True...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-228-a21c27d31b2a>:15: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  self.fig = plt.figure(figsize=(4,3))\n",
      "<ipython-input-228-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/126 [>.............................] - ETA: 58s - loss: 1.3864 - accuracy: 0.3004 WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0630s vs `on_train_batch_begin` time: 0.1854s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0630s vs `on_train_batch_end` time: 0.1662s). Check your callbacks.\n",
      "126/126 [==============================] - 15s 92ms/step - loss: 1.3864 - accuracy: 0.3141 - val_loss: 1.3862 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-228-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "126/126 [==============================] - 8s 62ms/step - loss: 1.3863 - accuracy: 0.3207 - val_loss: 1.3862 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "126/126 [==============================] - 8s 63ms/step - loss: 1.3863 - accuracy: 0.3173 - val_loss: 1.3862 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "126/126 [==============================] - 8s 62ms/step - loss: 1.3864 - accuracy: 0.3119 - val_loss: 1.3862 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "126/126 [==============================] - 8s 63ms/step - loss: 1.3864 - accuracy: 0.3077 - val_loss: 1.3862 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "126/126 [==============================] - 8s 64ms/step - loss: 1.3864 - accuracy: 0.3120 - val_loss: 1.3862 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "126/126 [==============================] - 8s 62ms/step - loss: 1.3864 - accuracy: 0.3038 - val_loss: 1.3862 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "126/126 [==============================] - 8s 65ms/step - loss: 1.3864 - accuracy: 0.3116 - val_loss: 1.3862 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "126/126 [==============================] - 8s 65ms/step - loss: 1.3863 - accuracy: 0.3131 - val_loss: 1.3862 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "126/126 [==============================] - 8s 62ms/step - loss: 1.3864 - accuracy: 0.3044 - val_loss: 1.3862 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "126/126 [==============================] - 8s 63ms/step - loss: 1.3864 - accuracy: 0.3059 - val_loss: 1.3862 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "126/126 [==============================] - 8s 63ms/step - loss: 1.3864 - accuracy: 0.3023 - val_loss: 1.3862 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "126/126 [==============================] - 8s 62ms/step - loss: 1.3864 - accuracy: 0.3002 - val_loss: 1.3862 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "126/126 [==============================] - 8s 62ms/step - loss: 1.3865 - accuracy: 0.2944 - val_loss: 1.3862 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "126/126 [==============================] - 8s 63ms/step - loss: 1.3864 - accuracy: 0.3078 - val_loss: 1.3862 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "126/126 [==============================] - 8s 62ms/step - loss: 1.3864 - accuracy: 0.2972 - val_loss: 1.3862 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "126/126 [==============================] - 8s 62ms/step - loss: 1.3864 - accuracy: 0.3079 - val_loss: 1.3862 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "126/126 [==============================] - 8s 63ms/step - loss: 1.3864 - accuracy: 0.2953 - val_loss: 1.3862 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "126/126 [==============================] - 8s 62ms/step - loss: 1.3864 - accuracy: 0.3065 - val_loss: 1.3862 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "126/126 [==============================] - 8s 62ms/step - loss: 1.3864 - accuracy: 0.3039 - val_loss: 1.3862 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "126/126 [==============================] - 8s 62ms/step - loss: 1.3864 - accuracy: 0.3016 - val_loss: 1.3862 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "126/126 [==============================] - 8s 63ms/step - loss: 1.3863 - accuracy: 0.3159 - val_loss: 1.3862 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "126/126 [==============================] - 8s 63ms/step - loss: 1.3864 - accuracy: 0.3029 - val_loss: 1.3862 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "126/126 [==============================] - 8s 62ms/step - loss: 1.3864 - accuracy: 0.3165 - val_loss: 1.3862 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "126/126 [==============================] - 8s 63ms/step - loss: 1.3864 - accuracy: 0.3075 - val_loss: 1.3862 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "126/126 [==============================] - 8s 63ms/step - loss: 1.3864 - accuracy: 0.3110 - val_loss: 1.3862 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "126/126 [==============================] - 8s 63ms/step - loss: 1.3864 - accuracy: 0.3062 - val_loss: 1.3862 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "126/126 [==============================] - 8s 64ms/step - loss: 1.3864 - accuracy: 0.3072 - val_loss: 1.3862 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "126/126 [==============================] - 8s 62ms/step - loss: 1.3865 - accuracy: 0.2943 - val_loss: 1.3862 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "126/126 [==============================] - 8s 63ms/step - loss: 1.3864 - accuracy: 0.3093 - val_loss: 1.3862 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_6261.3_images_False_newWeights_True_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.251033\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training opticnet for 0.075% of train size (aka 6261 images) with pretrained: True and onlyLastLayersTrained: True...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-228-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "126/126 [==============================] - 51s 335ms/step - loss: 15.9619 - accuracy: 0.1375 - val_loss: 11.7011 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-228-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "126/126 [==============================] - 37s 292ms/step - loss: 16.0542 - accuracy: 0.1310 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "126/126 [==============================] - 37s 292ms/step - loss: 16.1210 - accuracy: 0.1284 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "126/126 [==============================] - 37s 293ms/step - loss: 16.0138 - accuracy: 0.1341 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "126/126 [==============================] - 37s 295ms/step - loss: 15.9957 - accuracy: 0.1365 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "126/126 [==============================] - 37s 297ms/step - loss: 15.8835 - accuracy: 0.1352 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "126/126 [==============================] - 37s 295ms/step - loss: 15.9827 - accuracy: 0.1343 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "126/126 [==============================] - 37s 296ms/step - loss: 15.9312 - accuracy: 0.1372 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "126/126 [==============================] - 37s 294ms/step - loss: 15.9928 - accuracy: 0.1347 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "126/126 [==============================] - 37s 294ms/step - loss: 16.1148 - accuracy: 0.1330 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "126/126 [==============================] - 37s 293ms/step - loss: 15.9435 - accuracy: 0.1348 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "126/126 [==============================] - 37s 294ms/step - loss: 15.9812 - accuracy: 0.1349 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "126/126 [==============================] - 37s 293ms/step - loss: 15.9754 - accuracy: 0.1386 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "126/126 [==============================] - 37s 294ms/step - loss: 16.0639 - accuracy: 0.1327 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "126/126 [==============================] - 37s 294ms/step - loss: 16.0111 - accuracy: 0.1354 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "126/126 [==============================] - 37s 293ms/step - loss: 15.8789 - accuracy: 0.1338 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "126/126 [==============================] - 37s 294ms/step - loss: 15.9603 - accuracy: 0.1343 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "126/126 [==============================] - 37s 296ms/step - loss: 16.0423 - accuracy: 0.1354 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "126/126 [==============================] - 37s 294ms/step - loss: 15.9433 - accuracy: 0.1353 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "126/126 [==============================] - 37s 294ms/step - loss: 15.9920 - accuracy: 0.1369 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "126/126 [==============================] - 37s 295ms/step - loss: 15.9885 - accuracy: 0.1401 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "126/126 [==============================] - 37s 294ms/step - loss: 15.8778 - accuracy: 0.1391 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "126/126 [==============================] - 37s 293ms/step - loss: 15.8098 - accuracy: 0.1417 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "126/126 [==============================] - 37s 294ms/step - loss: 15.9904 - accuracy: 0.1356 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "126/126 [==============================] - 37s 294ms/step - loss: 16.0545 - accuracy: 0.1343 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "126/126 [==============================] - 37s 293ms/step - loss: 15.8895 - accuracy: 0.1375 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "126/126 [==============================] - 37s 296ms/step - loss: 15.9139 - accuracy: 0.1373 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "126/126 [==============================] - 37s 294ms/step - loss: 15.9395 - accuracy: 0.1354 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "126/126 [==============================] - 37s 294ms/step - loss: 15.9626 - accuracy: 0.1354 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "126/126 [==============================] - 37s 294ms/step - loss: 16.0563 - accuracy: 0.1329 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../opticnet/opticnet_30epochs_6261.3_images_False_newWeights_True_lastLayerOnly_rescale-symmetric_normalization/assets\n",
      "Test acc for opticnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.09029071 0.09041795 0.08909059 0.08844011]\n",
      "Training xception for 0.09% of train size (aka 7513 images) with pretrained: True and onlyLastLayersTrained: True...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-228-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/151 [>.............................] - ETA: 1:10 - loss: 1.3941 - accuracy: 0.1618WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1248s vs `on_train_batch_end` time: 0.2012s). Check your callbacks.\n",
      "151/151 [==============================] - 25s 149ms/step - loss: 1.3933 - accuracy: 0.1613 - val_loss: 1.3822 - val_accuracy: 0.2812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-228-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "151/151 [==============================] - 19s 127ms/step - loss: 1.3928 - accuracy: 0.1637 - val_loss: 1.3822 - val_accuracy: 0.2812\n",
      "Epoch 3/30\n",
      "151/151 [==============================] - 20s 129ms/step - loss: 1.3927 - accuracy: 0.1601 - val_loss: 1.3822 - val_accuracy: 0.2812\n",
      "Epoch 4/30\n",
      "151/151 [==============================] - 20s 131ms/step - loss: 1.3931 - accuracy: 0.1653 - val_loss: 1.3822 - val_accuracy: 0.2812\n",
      "Epoch 5/30\n",
      "151/151 [==============================] - 20s 132ms/step - loss: 1.3926 - accuracy: 0.1631 - val_loss: 1.3822 - val_accuracy: 0.2812\n",
      "Epoch 6/30\n",
      "151/151 [==============================] - 20s 131ms/step - loss: 1.3936 - accuracy: 0.1605 - val_loss: 1.3822 - val_accuracy: 0.2812\n",
      "Epoch 7/30\n",
      "151/151 [==============================] - 20s 134ms/step - loss: 1.3925 - accuracy: 0.1673 - val_loss: 1.3822 - val_accuracy: 0.2812\n",
      "Epoch 8/30\n",
      "151/151 [==============================] - 20s 132ms/step - loss: 1.3929 - accuracy: 0.1625 - val_loss: 1.3822 - val_accuracy: 0.2812\n",
      "Epoch 9/30\n",
      "151/151 [==============================] - 20s 133ms/step - loss: 1.3928 - accuracy: 0.1657 - val_loss: 1.3822 - val_accuracy: 0.2812\n",
      "Epoch 10/30\n",
      "151/151 [==============================] - 20s 135ms/step - loss: 1.3928 - accuracy: 0.1610 - val_loss: 1.3822 - val_accuracy: 0.2812\n",
      "Epoch 11/30\n",
      "151/151 [==============================] - 20s 133ms/step - loss: 1.3928 - accuracy: 0.1640 - val_loss: 1.3822 - val_accuracy: 0.2812\n",
      "Epoch 12/30\n",
      "151/151 [==============================] - 20s 133ms/step - loss: 1.3932 - accuracy: 0.1607 - val_loss: 1.3822 - val_accuracy: 0.2812\n",
      "Epoch 13/30\n",
      "151/151 [==============================] - 20s 133ms/step - loss: 1.3933 - accuracy: 0.1572 - val_loss: 1.3822 - val_accuracy: 0.2812\n",
      "Epoch 14/30\n",
      "151/151 [==============================] - 20s 133ms/step - loss: 1.3928 - accuracy: 0.1683 - val_loss: 1.3822 - val_accuracy: 0.2812\n",
      "Epoch 15/30\n",
      "151/151 [==============================] - 20s 133ms/step - loss: 1.3931 - accuracy: 0.1596 - val_loss: 1.3822 - val_accuracy: 0.2812\n",
      "Epoch 16/30\n",
      "151/151 [==============================] - 20s 132ms/step - loss: 1.3928 - accuracy: 0.1580 - val_loss: 1.3822 - val_accuracy: 0.2812\n",
      "Epoch 17/30\n",
      "151/151 [==============================] - 20s 135ms/step - loss: 1.3931 - accuracy: 0.1572 - val_loss: 1.3822 - val_accuracy: 0.2812\n",
      "Epoch 18/30\n",
      "151/151 [==============================] - 20s 135ms/step - loss: 1.3932 - accuracy: 0.1563 - val_loss: 1.3822 - val_accuracy: 0.2812\n",
      "Epoch 19/30\n",
      "151/151 [==============================] - 20s 134ms/step - loss: 1.3933 - accuracy: 0.1567 - val_loss: 1.3822 - val_accuracy: 0.2812\n",
      "Epoch 20/30\n",
      "151/151 [==============================] - 20s 135ms/step - loss: 1.3925 - accuracy: 0.1676 - val_loss: 1.3822 - val_accuracy: 0.2812\n",
      "Epoch 21/30\n",
      "151/151 [==============================] - 20s 136ms/step - loss: 1.3924 - accuracy: 0.1677 - val_loss: 1.3822 - val_accuracy: 0.2812\n",
      "Epoch 22/30\n",
      "151/151 [==============================] - 20s 135ms/step - loss: 1.3922 - accuracy: 0.1743 - val_loss: 1.3822 - val_accuracy: 0.2812\n",
      "Epoch 23/30\n",
      "151/151 [==============================] - 20s 134ms/step - loss: 1.3938 - accuracy: 0.1528 - val_loss: 1.3822 - val_accuracy: 0.2812\n",
      "Epoch 24/30\n",
      "151/151 [==============================] - 20s 133ms/step - loss: 1.3929 - accuracy: 0.1651 - val_loss: 1.3822 - val_accuracy: 0.2812\n",
      "Epoch 25/30\n",
      "151/151 [==============================] - 20s 134ms/step - loss: 1.3927 - accuracy: 0.1592 - val_loss: 1.3822 - val_accuracy: 0.2812\n",
      "Epoch 26/30\n",
      "151/151 [==============================] - 20s 134ms/step - loss: 1.3929 - accuracy: 0.1630 - val_loss: 1.3822 - val_accuracy: 0.2812\n",
      "Epoch 27/30\n",
      "151/151 [==============================] - 20s 134ms/step - loss: 1.3929 - accuracy: 0.1691 - val_loss: 1.3822 - val_accuracy: 0.2812\n",
      "Epoch 28/30\n",
      "151/151 [==============================] - 20s 132ms/step - loss: 1.3933 - accuracy: 0.1582 - val_loss: 1.3822 - val_accuracy: 0.2812\n",
      "Epoch 29/30\n",
      "151/151 [==============================] - 20s 133ms/step - loss: 1.3924 - accuracy: 0.1640 - val_loss: 1.3822 - val_accuracy: 0.2812\n",
      "Epoch 30/30\n",
      "151/151 [==============================] - 20s 133ms/step - loss: 1.3924 - accuracy: 0.1649 - val_loss: 1.3822 - val_accuracy: 0.2812\n",
      "INFO:tensorflow:Assets written to: ../xception/xception_30epochs_7513.5599999999995_images_False_newWeights_True_lastLayerOnly_rescale-symmetric_normalization/assets\n",
      "Test acc for xception: 0.248967\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training resnet for 0.09% of train size (aka 7513 images) with pretrained: True and onlyLastLayersTrained: True...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-228-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/151 [>.............................] - ETA: 55s - loss: 1.3900 - accuracy: 0.1741 WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0655s vs `on_train_batch_begin` time: 0.1086s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0655s vs `on_train_batch_end` time: 0.1555s). Check your callbacks.\n",
      "151/151 [==============================] - 16s 84ms/step - loss: 1.3898 - accuracy: 0.1364 - val_loss: 1.3863 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-228-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "151/151 [==============================] - 9s 61ms/step - loss: 1.3898 - accuracy: 0.1307 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "151/151 [==============================] - 9s 62ms/step - loss: 1.3898 - accuracy: 0.1334 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "151/151 [==============================] - 9s 62ms/step - loss: 1.3898 - accuracy: 0.1311 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "151/151 [==============================] - 9s 61ms/step - loss: 1.3897 - accuracy: 0.1359 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "151/151 [==============================] - 9s 61ms/step - loss: 1.3898 - accuracy: 0.1334 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "151/151 [==============================] - 9s 62ms/step - loss: 1.3897 - accuracy: 0.1418 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "151/151 [==============================] - 9s 62ms/step - loss: 1.3899 - accuracy: 0.1317 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "151/151 [==============================] - 9s 63ms/step - loss: 1.3898 - accuracy: 0.1319 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "151/151 [==============================] - 9s 63ms/step - loss: 1.3897 - accuracy: 0.1400 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "151/151 [==============================] - 9s 63ms/step - loss: 1.3897 - accuracy: 0.1378 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "151/151 [==============================] - 9s 62ms/step - loss: 1.3899 - accuracy: 0.1304 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "151/151 [==============================] - 9s 63ms/step - loss: 1.3897 - accuracy: 0.1418 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "151/151 [==============================] - 9s 62ms/step - loss: 1.3897 - accuracy: 0.1411 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "151/151 [==============================] - 9s 62ms/step - loss: 1.3898 - accuracy: 0.1330 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "151/151 [==============================] - 10s 63ms/step - loss: 1.3898 - accuracy: 0.1358 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "151/151 [==============================] - 9s 62ms/step - loss: 1.3897 - accuracy: 0.1373 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "151/151 [==============================] - 10s 63ms/step - loss: 1.3899 - accuracy: 0.1337 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "151/151 [==============================] - 10s 63ms/step - loss: 1.3897 - accuracy: 0.1374 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "151/151 [==============================] - 9s 62ms/step - loss: 1.3899 - accuracy: 0.1280 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "151/151 [==============================] - 10s 63ms/step - loss: 1.3900 - accuracy: 0.1329 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "151/151 [==============================] - 10s 63ms/step - loss: 1.3898 - accuracy: 0.1338 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "151/151 [==============================] - 10s 63ms/step - loss: 1.3897 - accuracy: 0.1362 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "151/151 [==============================] - 10s 63ms/step - loss: 1.3898 - accuracy: 0.1358 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "151/151 [==============================] - 9s 63ms/step - loss: 1.3897 - accuracy: 0.1378 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "151/151 [==============================] - 9s 63ms/step - loss: 1.3898 - accuracy: 0.1382 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "151/151 [==============================] - 9s 62ms/step - loss: 1.3898 - accuracy: 0.1357 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "151/151 [==============================] - 9s 62ms/step - loss: 1.3898 - accuracy: 0.1313 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "151/151 [==============================] - 9s 63ms/step - loss: 1.3898 - accuracy: 0.1310 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "151/151 [==============================] - 10s 64ms/step - loss: 1.3900 - accuracy: 0.1299 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_7513.5599999999995_images_False_newWeights_True_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training opticnet for 0.09% of train size (aka 7513 images) with pretrained: True and onlyLastLayersTrained: True...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-228-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/151 [>.............................] - ETA: 2:57 - loss: 16.4218 - accuracy: 0.1228WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2912s vs `on_train_batch_end` time: 0.6304s). Check your callbacks.\n",
      "151/151 [==============================] - 58s 343ms/step - loss: 16.0985 - accuracy: 0.1294 - val_loss: 11.7011 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-228-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "151/151 [==============================] - 44s 293ms/step - loss: 16.0683 - accuracy: 0.1349 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "151/151 [==============================] - 44s 294ms/step - loss: 15.9206 - accuracy: 0.1353 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "151/151 [==============================] - 44s 292ms/step - loss: 16.1326 - accuracy: 0.1271 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "151/151 [==============================] - 44s 294ms/step - loss: 15.9212 - accuracy: 0.1385 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "151/151 [==============================] - 44s 292ms/step - loss: 16.1911 - accuracy: 0.1300 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "151/151 [==============================] - 44s 293ms/step - loss: 16.0210 - accuracy: 0.1355 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "151/151 [==============================] - 44s 292ms/step - loss: 16.2054 - accuracy: 0.1251 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "151/151 [==============================] - 44s 294ms/step - loss: 15.9510 - accuracy: 0.1356 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "151/151 [==============================] - 44s 294ms/step - loss: 15.8199 - accuracy: 0.1410 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "151/151 [==============================] - 44s 294ms/step - loss: 16.0024 - accuracy: 0.1335 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "151/151 [==============================] - 44s 294ms/step - loss: 16.1113 - accuracy: 0.1347 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "151/151 [==============================] - 44s 294ms/step - loss: 15.9282 - accuracy: 0.1360 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "151/151 [==============================] - 44s 294ms/step - loss: 15.9997 - accuracy: 0.1334 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "151/151 [==============================] - 44s 295ms/step - loss: 15.9436 - accuracy: 0.1372 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "151/151 [==============================] - 44s 294ms/step - loss: 16.0949 - accuracy: 0.1315 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "151/151 [==============================] - 44s 294ms/step - loss: 16.0459 - accuracy: 0.1335 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "151/151 [==============================] - 44s 292ms/step - loss: 16.0170 - accuracy: 0.1337 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "151/151 [==============================] - 44s 294ms/step - loss: 16.0348 - accuracy: 0.1370 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "151/151 [==============================] - 44s 293ms/step - loss: 16.0080 - accuracy: 0.1322 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "151/151 [==============================] - 44s 295ms/step - loss: 15.9957 - accuracy: 0.1359 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "151/151 [==============================] - 45s 296ms/step - loss: 15.9967 - accuracy: 0.1330 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "151/151 [==============================] - 44s 295ms/step - loss: 16.1677 - accuracy: 0.1301 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "151/151 [==============================] - 44s 292ms/step - loss: 16.0123 - accuracy: 0.1318 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "151/151 [==============================] - 44s 293ms/step - loss: 16.0514 - accuracy: 0.1315 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "151/151 [==============================] - 44s 294ms/step - loss: 16.0349 - accuracy: 0.1344 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "151/151 [==============================] - 44s 293ms/step - loss: 16.1630 - accuracy: 0.1281 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "151/151 [==============================] - 44s 292ms/step - loss: 16.1046 - accuracy: 0.1246 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "151/151 [==============================] - 44s 294ms/step - loss: 16.0241 - accuracy: 0.1351 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "151/151 [==============================] - 44s 293ms/step - loss: 16.1033 - accuracy: 0.1318 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../opticnet/opticnet_30epochs_7513.5599999999995_images_False_newWeights_True_lastLayerOnly_rescale-symmetric_normalization/assets\n",
      "Test acc for opticnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.10115903 0.10044349 0.09834332 0.09668059]\n",
      "Training xception for 0.1% of train size (aka 8348 images) with pretrained: True and onlyLastLayersTrained: True...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-228-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/167 [>.............................] - ETA: 1:18 - loss: 1.3699 - accuracy: 0.4678WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1247s vs `on_train_batch_end` time: 0.2068s). Check your callbacks.\n",
      "167/167 [==============================] - 28s 149ms/step - loss: 1.3719 - accuracy: 0.4029 - val_loss: 1.3957 - val_accuracy: 0.1562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-228-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "167/167 [==============================] - 22s 129ms/step - loss: 1.3726 - accuracy: 0.3920 - val_loss: 1.3957 - val_accuracy: 0.1562\n",
      "Epoch 3/30\n",
      "167/167 [==============================] - 22s 132ms/step - loss: 1.3720 - accuracy: 0.3963 - val_loss: 1.3957 - val_accuracy: 0.1562\n",
      "Epoch 4/30\n",
      "167/167 [==============================] - 22s 132ms/step - loss: 1.3725 - accuracy: 0.3932 - val_loss: 1.3957 - val_accuracy: 0.1562\n",
      "Epoch 5/30\n",
      "167/167 [==============================] - 22s 134ms/step - loss: 1.3721 - accuracy: 0.3948 - val_loss: 1.3957 - val_accuracy: 0.1562\n",
      "Epoch 6/30\n",
      "167/167 [==============================] - 22s 133ms/step - loss: 1.3722 - accuracy: 0.3939 - val_loss: 1.3957 - val_accuracy: 0.1562\n",
      "Epoch 7/30\n",
      "167/167 [==============================] - 22s 133ms/step - loss: 1.3719 - accuracy: 0.3991 - val_loss: 1.3957 - val_accuracy: 0.1562\n",
      "Epoch 8/30\n",
      "167/167 [==============================] - 22s 133ms/step - loss: 1.3725 - accuracy: 0.3970 - val_loss: 1.3957 - val_accuracy: 0.1562\n",
      "Epoch 9/30\n",
      "167/167 [==============================] - 23s 135ms/step - loss: 1.3711 - accuracy: 0.4066 - val_loss: 1.3957 - val_accuracy: 0.1562\n",
      "Epoch 10/30\n",
      "167/167 [==============================] - 22s 135ms/step - loss: 1.3726 - accuracy: 0.3928 - val_loss: 1.3957 - val_accuracy: 0.1562\n",
      "Epoch 11/30\n",
      "167/167 [==============================] - 22s 134ms/step - loss: 1.3710 - accuracy: 0.4051 - val_loss: 1.3957 - val_accuracy: 0.1562\n",
      "Epoch 12/30\n",
      "167/167 [==============================] - 23s 139ms/step - loss: 1.3715 - accuracy: 0.4004 - val_loss: 1.3957 - val_accuracy: 0.1562\n",
      "Epoch 13/30\n",
      "167/167 [==============================] - 22s 135ms/step - loss: 1.3722 - accuracy: 0.3957 - val_loss: 1.3957 - val_accuracy: 0.1562\n",
      "Epoch 14/30\n",
      "167/167 [==============================] - 23s 135ms/step - loss: 1.3717 - accuracy: 0.4019 - val_loss: 1.3957 - val_accuracy: 0.1562\n",
      "Epoch 15/30\n",
      "167/167 [==============================] - 22s 133ms/step - loss: 1.3722 - accuracy: 0.3986 - val_loss: 1.3957 - val_accuracy: 0.1562\n",
      "Epoch 16/30\n",
      "167/167 [==============================] - 23s 136ms/step - loss: 1.3720 - accuracy: 0.3937 - val_loss: 1.3957 - val_accuracy: 0.1562\n",
      "Epoch 17/30\n",
      "167/167 [==============================] - 23s 136ms/step - loss: 1.3722 - accuracy: 0.4002 - val_loss: 1.3957 - val_accuracy: 0.1562\n",
      "Epoch 18/30\n",
      "167/167 [==============================] - 23s 136ms/step - loss: 1.3714 - accuracy: 0.4035 - val_loss: 1.3957 - val_accuracy: 0.1562\n",
      "Epoch 19/30\n",
      "167/167 [==============================] - 23s 136ms/step - loss: 1.3727 - accuracy: 0.3871 - val_loss: 1.3957 - val_accuracy: 0.1562\n",
      "Epoch 20/30\n",
      "167/167 [==============================] - 22s 134ms/step - loss: 1.3722 - accuracy: 0.3962 - val_loss: 1.3957 - val_accuracy: 0.1562\n",
      "Epoch 21/30\n",
      "167/167 [==============================] - 22s 134ms/step - loss: 1.3715 - accuracy: 0.4059 - val_loss: 1.3957 - val_accuracy: 0.1562\n",
      "Epoch 22/30\n",
      "167/167 [==============================] - 22s 133ms/step - loss: 1.3713 - accuracy: 0.4021 - val_loss: 1.3957 - val_accuracy: 0.1562\n",
      "Epoch 23/30\n",
      "167/167 [==============================] - 22s 133ms/step - loss: 1.3720 - accuracy: 0.3984 - val_loss: 1.3957 - val_accuracy: 0.1562\n",
      "Epoch 24/30\n",
      "167/167 [==============================] - 22s 133ms/step - loss: 1.3719 - accuracy: 0.4062 - val_loss: 1.3957 - val_accuracy: 0.1562\n",
      "Epoch 25/30\n",
      "167/167 [==============================] - 23s 136ms/step - loss: 1.3718 - accuracy: 0.4021 - val_loss: 1.3957 - val_accuracy: 0.1562\n",
      "Epoch 26/30\n",
      "167/167 [==============================] - 22s 134ms/step - loss: 1.3720 - accuracy: 0.3924 - val_loss: 1.3957 - val_accuracy: 0.1562\n",
      "Epoch 27/30\n",
      "167/167 [==============================] - 22s 135ms/step - loss: 1.3721 - accuracy: 0.3997 - val_loss: 1.3957 - val_accuracy: 0.1562\n",
      "Epoch 28/30\n",
      "167/167 [==============================] - 22s 135ms/step - loss: 1.3724 - accuracy: 0.4021 - val_loss: 1.3957 - val_accuracy: 0.1562\n",
      "Epoch 29/30\n",
      "167/167 [==============================] - 22s 134ms/step - loss: 1.3722 - accuracy: 0.3917 - val_loss: 1.3957 - val_accuracy: 0.1562\n",
      "Epoch 30/30\n",
      "167/167 [==============================] - 22s 134ms/step - loss: 1.3721 - accuracy: 0.3930 - val_loss: 1.3957 - val_accuracy: 0.1562\n",
      "INFO:tensorflow:Assets written to: ../xception/xception_30epochs_8348.4_images_False_newWeights_True_lastLayerOnly_rescale-symmetric_normalization/assets\n",
      "Test acc for xception: 0.214876\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training resnet for 0.1% of train size (aka 8348 images) with pretrained: True and onlyLastLayersTrained: True...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-228-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/167 [>.............................] - ETA: 1:17 - loss: 1.3839 - accuracy: 0.4584WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0666s vs `on_train_batch_begin` time: 0.1724s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0666s vs `on_train_batch_end` time: 0.1717s). Check your callbacks.\n",
      "167/167 [==============================] - 18s 86ms/step - loss: 1.3840 - accuracy: 0.4505 - val_loss: 1.3863 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-228-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "167/167 [==============================] - 10s 61ms/step - loss: 1.3840 - accuracy: 0.4544 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "167/167 [==============================] - 10s 62ms/step - loss: 1.3840 - accuracy: 0.4450 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "167/167 [==============================] - 10s 62ms/step - loss: 1.3841 - accuracy: 0.4429 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "167/167 [==============================] - 10s 62ms/step - loss: 1.3841 - accuracy: 0.4428 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "167/167 [==============================] - 10s 62ms/step - loss: 1.3840 - accuracy: 0.4437 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "167/167 [==============================] - 11s 63ms/step - loss: 1.3840 - accuracy: 0.4420 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "167/167 [==============================] - 10s 63ms/step - loss: 1.3840 - accuracy: 0.4400 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "167/167 [==============================] - 10s 62ms/step - loss: 1.3839 - accuracy: 0.4526 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "167/167 [==============================] - 10s 63ms/step - loss: 1.3840 - accuracy: 0.4511 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "167/167 [==============================] - 11s 63ms/step - loss: 1.3840 - accuracy: 0.4503 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "167/167 [==============================] - 10s 62ms/step - loss: 1.3840 - accuracy: 0.4411 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "167/167 [==============================] - 11s 64ms/step - loss: 1.3839 - accuracy: 0.4523 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "167/167 [==============================] - 11s 63ms/step - loss: 1.3841 - accuracy: 0.4399 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "167/167 [==============================] - 10s 62ms/step - loss: 1.3840 - accuracy: 0.4460 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "167/167 [==============================] - 10s 63ms/step - loss: 1.3840 - accuracy: 0.4389 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "167/167 [==============================] - 11s 63ms/step - loss: 1.3840 - accuracy: 0.4452 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "167/167 [==============================] - 11s 63ms/step - loss: 1.3840 - accuracy: 0.4471 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "167/167 [==============================] - 11s 63ms/step - loss: 1.3840 - accuracy: 0.4443 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "167/167 [==============================] - 10s 62ms/step - loss: 1.3839 - accuracy: 0.4534 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "167/167 [==============================] - 11s 64ms/step - loss: 1.3840 - accuracy: 0.4530 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "167/167 [==============================] - 11s 63ms/step - loss: 1.3839 - accuracy: 0.4538 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "167/167 [==============================] - 11s 64ms/step - loss: 1.3839 - accuracy: 0.4518 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "167/167 [==============================] - 10s 62ms/step - loss: 1.3839 - accuracy: 0.4528 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "167/167 [==============================] - 11s 63ms/step - loss: 1.3841 - accuracy: 0.4379 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "167/167 [==============================] - 11s 63ms/step - loss: 1.3840 - accuracy: 0.4483 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "167/167 [==============================] - 10s 62ms/step - loss: 1.3840 - accuracy: 0.4473 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "167/167 [==============================] - 11s 63ms/step - loss: 1.3840 - accuracy: 0.4461 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "167/167 [==============================] - 11s 63ms/step - loss: 1.3839 - accuracy: 0.4503 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "167/167 [==============================] - 11s 63ms/step - loss: 1.3840 - accuracy: 0.4553 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_8348.4_images_False_newWeights_True_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training opticnet for 0.1% of train size (aka 8348 images) with pretrained: True and onlyLastLayersTrained: True...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-228-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "167/167 [==============================] - 61s 328ms/step - loss: 16.1293 - accuracy: 0.1268 - val_loss: 11.7011 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-228-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "167/167 [==============================] - 49s 294ms/step - loss: 16.0060 - accuracy: 0.1357 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "167/167 [==============================] - 49s 296ms/step - loss: 16.0310 - accuracy: 0.1331 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "167/167 [==============================] - 49s 294ms/step - loss: 16.0953 - accuracy: 0.1323 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "167/167 [==============================] - 49s 294ms/step - loss: 16.0445 - accuracy: 0.1343 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "167/167 [==============================] - 49s 295ms/step - loss: 16.0130 - accuracy: 0.1313 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "167/167 [==============================] - 49s 295ms/step - loss: 16.0005 - accuracy: 0.1365 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "167/167 [==============================] - 49s 294ms/step - loss: 15.9646 - accuracy: 0.1369 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "167/167 [==============================] - 49s 294ms/step - loss: 16.0639 - accuracy: 0.1294 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "167/167 [==============================] - 49s 294ms/step - loss: 15.9869 - accuracy: 0.1333 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "167/167 [==============================] - 49s 294ms/step - loss: 16.0839 - accuracy: 0.1338 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "167/167 [==============================] - 49s 294ms/step - loss: 16.1172 - accuracy: 0.1269 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "167/167 [==============================] - 49s 296ms/step - loss: 16.1492 - accuracy: 0.1308 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "167/167 [==============================] - 49s 296ms/step - loss: 15.9197 - accuracy: 0.1388 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "167/167 [==============================] - 49s 296ms/step - loss: 15.9664 - accuracy: 0.1339 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "167/167 [==============================] - 49s 295ms/step - loss: 16.0961 - accuracy: 0.1328 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "167/167 [==============================] - 49s 294ms/step - loss: 15.9783 - accuracy: 0.1366 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "167/167 [==============================] - 49s 296ms/step - loss: 16.2365 - accuracy: 0.1279 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "167/167 [==============================] - 49s 294ms/step - loss: 15.8260 - accuracy: 0.1433 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "167/167 [==============================] - 49s 295ms/step - loss: 16.0154 - accuracy: 0.1360 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "167/167 [==============================] - 49s 295ms/step - loss: 16.0455 - accuracy: 0.1350 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "167/167 [==============================] - 49s 294ms/step - loss: 16.1459 - accuracy: 0.1361 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "167/167 [==============================] - 50s 296ms/step - loss: 16.1020 - accuracy: 0.1306 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "167/167 [==============================] - 50s 296ms/step - loss: 16.1879 - accuracy: 0.1275 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "167/167 [==============================] - 50s 297ms/step - loss: 16.0674 - accuracy: 0.1328 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "167/167 [==============================] - 49s 296ms/step - loss: 16.1453 - accuracy: 0.1300 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "167/167 [==============================] - 50s 296ms/step - loss: 16.0886 - accuracy: 0.1323 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "167/167 [==============================] - 49s 296ms/step - loss: 15.9936 - accuracy: 0.1352 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "167/167 [==============================] - 50s 297ms/step - loss: 15.9639 - accuracy: 0.1374 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "167/167 [==============================] - 49s 296ms/step - loss: 15.9543 - accuracy: 0.1389 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../opticnet/opticnet_30epochs_8348.4_images_False_newWeights_True_lastLayerOnly_rescale-symmetric_normalization/assets\n",
      "Test acc for opticnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.25069352 0.25362183 0.24735636 0.23572423]\n",
      "Training xception for 0.25% of train size (aka 20871 images) with pretrained: True and onlyLastLayersTrained: True...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-228-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/418 [..............................] - ETA: 3:47 - loss: 1.3769 - accuracy: 0.2331WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1249s vs `on_train_batch_begin` time: 0.1558s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1249s vs `on_train_batch_end` time: 0.2012s). Check your callbacks.\n",
      "418/418 [==============================] - 60s 137ms/step - loss: 1.3825 - accuracy: 0.2181 - val_loss: 1.3919 - val_accuracy: 0.3125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-228-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "418/418 [==============================] - 55s 131ms/step - loss: 1.3833 - accuracy: 0.2157 - val_loss: 1.3919 - val_accuracy: 0.3125\n",
      "Epoch 3/30\n",
      "418/418 [==============================] - 55s 132ms/step - loss: 1.3824 - accuracy: 0.2185 - val_loss: 1.3919 - val_accuracy: 0.3125\n",
      "Epoch 4/30\n",
      "418/418 [==============================] - 56s 134ms/step - loss: 1.3836 - accuracy: 0.2102 - val_loss: 1.3919 - val_accuracy: 0.3125\n",
      "Epoch 5/30\n",
      "418/418 [==============================] - 55s 132ms/step - loss: 1.3838 - accuracy: 0.2146 - val_loss: 1.3919 - val_accuracy: 0.3125\n",
      "Epoch 6/30\n",
      "418/418 [==============================] - 56s 134ms/step - loss: 1.3833 - accuracy: 0.2180 - val_loss: 1.3919 - val_accuracy: 0.3125\n",
      "Epoch 7/30\n",
      "418/418 [==============================] - 56s 134ms/step - loss: 1.3832 - accuracy: 0.2122 - val_loss: 1.3919 - val_accuracy: 0.3125\n",
      "Epoch 8/30\n",
      "418/418 [==============================] - 56s 133ms/step - loss: 1.3838 - accuracy: 0.2068 - val_loss: 1.3919 - val_accuracy: 0.3125\n",
      "Epoch 9/30\n",
      "418/418 [==============================] - 57s 136ms/step - loss: 1.3829 - accuracy: 0.2124 - val_loss: 1.3919 - val_accuracy: 0.3125\n",
      "Epoch 10/30\n",
      "418/418 [==============================] - 56s 134ms/step - loss: 1.3831 - accuracy: 0.2150 - val_loss: 1.3919 - val_accuracy: 0.3125\n",
      "Epoch 11/30\n",
      "418/418 [==============================] - 57s 136ms/step - loss: 1.3837 - accuracy: 0.2154 - val_loss: 1.3919 - val_accuracy: 0.3125\n",
      "Epoch 12/30\n",
      "418/418 [==============================] - 57s 136ms/step - loss: 1.3834 - accuracy: 0.2133 - val_loss: 1.3919 - val_accuracy: 0.3125\n",
      "Epoch 13/30\n",
      "418/418 [==============================] - 57s 136ms/step - loss: 1.3831 - accuracy: 0.2121 - val_loss: 1.3919 - val_accuracy: 0.3125\n",
      "Epoch 14/30\n",
      "418/418 [==============================] - 57s 136ms/step - loss: 1.3830 - accuracy: 0.2154 - val_loss: 1.3919 - val_accuracy: 0.3125\n",
      "Epoch 15/30\n",
      "418/418 [==============================] - 57s 136ms/step - loss: 1.3830 - accuracy: 0.2153 - val_loss: 1.3919 - val_accuracy: 0.3125\n",
      "Epoch 16/30\n",
      "418/418 [==============================] - 57s 135ms/step - loss: 1.3826 - accuracy: 0.2142 - val_loss: 1.3919 - val_accuracy: 0.3125\n",
      "Epoch 17/30\n",
      "418/418 [==============================] - 56s 135ms/step - loss: 1.3836 - accuracy: 0.2095 - val_loss: 1.3919 - val_accuracy: 0.3125\n",
      "Epoch 18/30\n",
      "418/418 [==============================] - 56s 135ms/step - loss: 1.3832 - accuracy: 0.2162 - val_loss: 1.3919 - val_accuracy: 0.3125\n",
      "Epoch 19/30\n",
      "418/418 [==============================] - 56s 135ms/step - loss: 1.3836 - accuracy: 0.2086 - val_loss: 1.3919 - val_accuracy: 0.3125\n",
      "Epoch 20/30\n",
      "418/418 [==============================] - 56s 135ms/step - loss: 1.3831 - accuracy: 0.2136 - val_loss: 1.3919 - val_accuracy: 0.3125\n",
      "Epoch 21/30\n",
      "418/418 [==============================] - 56s 135ms/step - loss: 1.3831 - accuracy: 0.2133 - val_loss: 1.3919 - val_accuracy: 0.3125\n",
      "Epoch 22/30\n",
      "418/418 [==============================] - 56s 135ms/step - loss: 1.3836 - accuracy: 0.2126 - val_loss: 1.3919 - val_accuracy: 0.3125\n",
      "Epoch 23/30\n",
      "418/418 [==============================] - 56s 135ms/step - loss: 1.3830 - accuracy: 0.2095 - val_loss: 1.3919 - val_accuracy: 0.3125\n",
      "Epoch 24/30\n",
      "418/418 [==============================] - 56s 135ms/step - loss: 1.3835 - accuracy: 0.2087 - val_loss: 1.3919 - val_accuracy: 0.3125\n",
      "Epoch 25/30\n",
      "418/418 [==============================] - 56s 135ms/step - loss: 1.3831 - accuracy: 0.2155 - val_loss: 1.3919 - val_accuracy: 0.3125\n",
      "Epoch 26/30\n",
      "418/418 [==============================] - 57s 135ms/step - loss: 1.3832 - accuracy: 0.2130 - val_loss: 1.3919 - val_accuracy: 0.3125\n",
      "Epoch 27/30\n",
      "418/418 [==============================] - 57s 136ms/step - loss: 1.3826 - accuracy: 0.2162 - val_loss: 1.3919 - val_accuracy: 0.3125\n",
      "Epoch 28/30\n",
      "418/418 [==============================] - 57s 136ms/step - loss: 1.3836 - accuracy: 0.2084 - val_loss: 1.3919 - val_accuracy: 0.3125\n",
      "Epoch 29/30\n",
      "418/418 [==============================] - 57s 135ms/step - loss: 1.3833 - accuracy: 0.2121 - val_loss: 1.3919 - val_accuracy: 0.3125\n",
      "Epoch 30/30\n",
      "418/418 [==============================] - 56s 135ms/step - loss: 1.3836 - accuracy: 0.2112 - val_loss: 1.3919 - val_accuracy: 0.3125\n",
      "INFO:tensorflow:Assets written to: ../xception/xception_30epochs_20871.0_images_False_newWeights_True_lastLayerOnly_rescale-symmetric_normalization/assets\n",
      "Test acc for xception: 0.293388\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training resnet for 0.25% of train size (aka 20871 images) with pretrained: True and onlyLastLayersTrained: True...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-228-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/418 [..............................] - ETA: 3:00 - loss: 1.3866 - accuracy: 0.4127WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0673s vs `on_train_batch_begin` time: 0.1290s). Check your callbacks.\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0673s vs `on_train_batch_end` time: 0.1803s). Check your callbacks.\n",
      "418/418 [==============================] - 34s 71ms/step - loss: 1.3862 - accuracy: 0.4355 - val_loss: 1.3862 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-228-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "418/418 [==============================] - 26s 62ms/step - loss: 1.3861 - accuracy: 0.4404 - val_loss: 1.3862 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "418/418 [==============================] - 26s 63ms/step - loss: 1.3862 - accuracy: 0.4287 - val_loss: 1.3862 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "418/418 [==============================] - 26s 63ms/step - loss: 1.3862 - accuracy: 0.4314 - val_loss: 1.3862 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "418/418 [==============================] - 27s 64ms/step - loss: 1.3861 - accuracy: 0.4368 - val_loss: 1.3862 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "418/418 [==============================] - 27s 63ms/step - loss: 1.3861 - accuracy: 0.4356 - val_loss: 1.3862 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "418/418 [==============================] - 27s 64ms/step - loss: 1.3861 - accuracy: 0.4325 - val_loss: 1.3862 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "418/418 [==============================] - 27s 64ms/step - loss: 1.3861 - accuracy: 0.4345 - val_loss: 1.3862 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "418/418 [==============================] - 27s 64ms/step - loss: 1.3861 - accuracy: 0.4354 - val_loss: 1.3862 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "418/418 [==============================] - 26s 63ms/step - loss: 1.3861 - accuracy: 0.4357 - val_loss: 1.3862 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "418/418 [==============================] - 27s 64ms/step - loss: 1.3861 - accuracy: 0.4280 - val_loss: 1.3862 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "418/418 [==============================] - 27s 64ms/step - loss: 1.3861 - accuracy: 0.4368 - val_loss: 1.3862 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "418/418 [==============================] - 26s 63ms/step - loss: 1.3862 - accuracy: 0.4302 - val_loss: 1.3862 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "418/418 [==============================] - 27s 64ms/step - loss: 1.3861 - accuracy: 0.4399 - val_loss: 1.3862 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "418/418 [==============================] - 27s 64ms/step - loss: 1.3861 - accuracy: 0.4372 - val_loss: 1.3862 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "418/418 [==============================] - 27s 65ms/step - loss: 1.3862 - accuracy: 0.4326 - val_loss: 1.3862 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "418/418 [==============================] - 27s 64ms/step - loss: 1.3862 - accuracy: 0.4271 - val_loss: 1.3862 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "418/418 [==============================] - 27s 64ms/step - loss: 1.3862 - accuracy: 0.4310 - val_loss: 1.3862 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "418/418 [==============================] - 27s 63ms/step - loss: 1.3861 - accuracy: 0.4371 - val_loss: 1.3862 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "418/418 [==============================] - 27s 64ms/step - loss: 1.3861 - accuracy: 0.4344 - val_loss: 1.3862 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "418/418 [==============================] - 26s 63ms/step - loss: 1.3861 - accuracy: 0.4290 - val_loss: 1.3862 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "418/418 [==============================] - 27s 63ms/step - loss: 1.3861 - accuracy: 0.4344 - val_loss: 1.3862 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "418/418 [==============================] - 27s 63ms/step - loss: 1.3862 - accuracy: 0.4287 - val_loss: 1.3862 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "418/418 [==============================] - 27s 64ms/step - loss: 1.3862 - accuracy: 0.4317 - val_loss: 1.3862 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "418/418 [==============================] - 26s 63ms/step - loss: 1.3861 - accuracy: 0.4336 - val_loss: 1.3862 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "418/418 [==============================] - 27s 64ms/step - loss: 1.3862 - accuracy: 0.4293 - val_loss: 1.3862 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "418/418 [==============================] - 27s 63ms/step - loss: 1.3861 - accuracy: 0.4383 - val_loss: 1.3862 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "418/418 [==============================] - 27s 63ms/step - loss: 1.3862 - accuracy: 0.4263 - val_loss: 1.3862 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "418/418 [==============================] - 27s 64ms/step - loss: 1.3861 - accuracy: 0.4332 - val_loss: 1.3862 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "418/418 [==============================] - 26s 63ms/step - loss: 1.3861 - accuracy: 0.4314 - val_loss: 1.3862 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_20871.0_images_False_newWeights_True_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.251033\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Training opticnet for 0.25% of train size (aka 20871 images) with pretrained: True and onlyLastLayersTrained: True...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-228-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "418/418 [==============================] - 134s 306ms/step - loss: 16.1873 - accuracy: 0.1307 - val_loss: 11.7011 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-228-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "418/418 [==============================] - 123s 295ms/step - loss: 16.1675 - accuracy: 0.1306 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "418/418 [==============================] - 123s 295ms/step - loss: 16.0242 - accuracy: 0.1358 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "418/418 [==============================] - 123s 295ms/step - loss: 16.1186 - accuracy: 0.1340 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "418/418 [==============================] - 124s 296ms/step - loss: 16.0768 - accuracy: 0.1352 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "418/418 [==============================] - 123s 295ms/step - loss: 16.0160 - accuracy: 0.1376 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "418/418 [==============================] - 123s 295ms/step - loss: 16.2214 - accuracy: 0.1290 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "418/418 [==============================] - 123s 295ms/step - loss: 16.0876 - accuracy: 0.1328 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "418/418 [==============================] - 123s 295ms/step - loss: 16.0551 - accuracy: 0.1352 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "418/418 [==============================] - 123s 295ms/step - loss: 16.0425 - accuracy: 0.1384 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "418/418 [==============================] - 123s 295ms/step - loss: 16.0418 - accuracy: 0.1354 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "418/418 [==============================] - 123s 295ms/step - loss: 16.0899 - accuracy: 0.1345 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "418/418 [==============================] - 123s 295ms/step - loss: 16.0680 - accuracy: 0.1376 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "418/418 [==============================] - 124s 296ms/step - loss: 16.0829 - accuracy: 0.1341 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "418/418 [==============================] - 123s 295ms/step - loss: 16.0768 - accuracy: 0.1359 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "418/418 [==============================] - 123s 295ms/step - loss: 16.1150 - accuracy: 0.1348 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "418/418 [==============================] - 123s 295ms/step - loss: 16.1898 - accuracy: 0.1308 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "418/418 [==============================] - 123s 295ms/step - loss: 16.1450 - accuracy: 0.1321 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "418/418 [==============================] - 123s 295ms/step - loss: 16.0171 - accuracy: 0.1383 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "418/418 [==============================] - 124s 296ms/step - loss: 16.0807 - accuracy: 0.1328 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "418/418 [==============================] - 123s 295ms/step - loss: 16.0504 - accuracy: 0.1358 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "418/418 [==============================] - 123s 295ms/step - loss: 16.2039 - accuracy: 0.1289 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "418/418 [==============================] - 123s 295ms/step - loss: 16.0918 - accuracy: 0.1357 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "418/418 [==============================] - 123s 295ms/step - loss: 16.1097 - accuracy: 0.1328 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "418/418 [==============================] - 123s 295ms/step - loss: 16.0134 - accuracy: 0.1367 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "418/418 [==============================] - 123s 295ms/step - loss: 16.1065 - accuracy: 0.1319 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "418/418 [==============================] - 124s 296ms/step - loss: 16.0259 - accuracy: 0.1354 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "418/418 [==============================] - 123s 295ms/step - loss: 16.0941 - accuracy: 0.1344 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "418/418 [==============================] - 123s 295ms/step - loss: 16.0597 - accuracy: 0.1338 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "418/418 [==============================] - 123s 295ms/step - loss: 16.0850 - accuracy: 0.1350 - val_loss: 11.7011 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../opticnet/opticnet_30epochs_20871.0_images_False_newWeights_True_lastLayerOnly_rescale-symmetric_normalization/assets\n",
      "Test acc for opticnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.39840395 0.40263405 0.40033486 0.39298979]\n",
      "Training xception for 0.4% of train size (aka 33393 images) with pretrained: True and onlyLastLayersTrained: True...\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import datetime\n",
    "\n",
    "maxTrain = len(y_train)\n",
    "for newWeights in [False]:\n",
    "    for trainLastLayerOnly in [True]:\n",
    "        for p in [0.01, 0.025, 0.05, 0.075, 0.09, 0.1, 0.25, 0.4, 0.5, 0.6, 0.75, 0.9, 1.0]:\n",
    "            #X_trn, X_tst, y_trn, y_tst\n",
    "            if p < 1:\n",
    "                X_t, _, y_t, _ = train_test_split(images, y_train, test_size=1-p, random_state=123)\n",
    "            else:\n",
    "                X_t = images; y_t = y_train;\n",
    "            print(f\"Labels fraction: {sum(y_t == 1) / sum(y_train == 1)}\")\n",
    "            for net in [\"xception\", \"resnet\", \"opticnet\"]:\n",
    "                print(f\"Training {net} for {p}% of train size (aka {len(X_t)} images) with pretrained: {not newWeights} and onlyLastLayersTrained: {trainLastLayerOnly}...\")\n",
    "                model, size, normalization = emptyModelGenerator(net, newWeights=newWeights, lastOnly=trainLastLayerOnly)\n",
    "                X_trn = resizeIms(X_t, size)\n",
    "                X_trn = normalizeIms(X_trn, normalization=normalization)\n",
    "                X_val = resizeIms(x_val, size)\n",
    "                X_val = normalizeIms(X_val, normalization=normalization)\n",
    "                log_dir = f\"logs/{net}/fit/{p}trainSet_\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "                tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "                optim = Adam(learning_rate=0.001)\n",
    "                time_callback = TimeHistory()\n",
    "                model.compile(optimizer=optim, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "                hist = model.fit(X_trn, y_t, epochs=epochs, validation_data = (X_val, y_validation), batch_size=batch_size,\n",
    "                            shuffle=True, max_queue_size=20,\n",
    "                            use_multiprocessing=True, workers=5, \n",
    "                            callbacks=[CustomCallback(fraction=0.9, model=net), tensorboard_callback, time_callback])\n",
    "                trainTime = sum(time_callback.times)\n",
    "                model.save(f\"../{net}/{net}_{epochs}epochs_{p*maxTrain}_images_{newWeights}_newWeights_{trainLastLayerOnly}_lastLayerOnly_{normalization}_normalization\")\n",
    "                tstAcc = testPredict(model, size, name=net, normalization=normalization)\n",
    "                results = results.append({\n",
    "                    'model': net, \n",
    "                    'train set images': len(X_t), \n",
    "                    'pretrained': not newWeights, \n",
    "                    'pretrained dataset': None if newWeights else (\"OCT2017,Srinivasan2014\" if net == \"opticnet\" else \"Imagenet\"),\n",
    "                    'Trained layers': \"Last dense\" if trainLastLayerOnly else \"All\", \n",
    "                    'epochs': epochs, \n",
    "                    'batch size': batch_size, \n",
    "                    'learning rate': lr, \n",
    "                    'optimizer': optim._name,\n",
    "                    'training time (seconds)': trainTime, \n",
    "                    'train accuracy': hist.history[\"accuracy\"][-1], \n",
    "                    'train loss': hist.history[\"loss\"][-1],\n",
    "                    'validation accuracy': hist.history[\"val_accuracy\"][-1], \n",
    "                    'validation loss': hist.history[\"val_loss\"][-1], \n",
    "                    'test accuracy': tstAcc,\n",
    "                    'normalization': normalization\n",
    "                }, ignore_index=True)\n",
    "                del model\n",
    "                del X_trn\n",
    "                del X_val\n",
    "                print(\"Done!\\n\" + '-'*50, end='\\n\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
