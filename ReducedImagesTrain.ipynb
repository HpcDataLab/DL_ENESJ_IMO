{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "import os\n",
    "import cv2\n",
    "import pickle\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version is: 2.4.1\n"
     ]
    }
   ],
   "source": [
    "print(f\"Tensorflow version is: {tf.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataPath = \"../../data/OCT/OCT2017/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of Classes Detected : 4\n"
     ]
    }
   ],
   "source": [
    "labels_available = os.listdir(os.path.join(dataPath, \"train\"))\n",
    "print(\"Total Number of Classes Detected :\",len(labels_available))\n",
    "\n",
    "labels_list = ['NORMAL',\"CNV\",\"DME\",\"DRUSEN\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NORMAL CNV DME DRUSEN "
     ]
    }
   ],
   "source": [
    "images=[]\n",
    "y_trn=[]\n",
    "for x in labels_list:\n",
    "    xPath = os.path.join(dataPath, \"train\", x)\n",
    "    myPicList = os.listdir(xPath)\n",
    "    for y in myPicList:\n",
    "        images.append(cv2.imread(os.path.join(xPath, y)))\n",
    "        y_trn.append(labels_list.index(x))\n",
    "    print(x ,end=\" \")\n",
    "\n",
    "y_train = to_categorical(y_trn,len(labels_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NORMAL CNV DME DRUSEN "
     ]
    }
   ],
   "source": [
    "x_val=[]\n",
    "y_val=[]\n",
    "for x in labels_list:\n",
    "    xPath = os.path.join(dataPath, \"val\", x)\n",
    "    myPicList = os.listdir(xPath)\n",
    "    for y in myPicList:\n",
    "        x_val.append(cv2.imread(os.path.join(xPath, y)))\n",
    "        y_val.append(labels_list.index(x))\n",
    "    print(x ,end=\" \")\n",
    "\n",
    "y_validation = to_categorical(y_val,len(labels_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NORMAL CNV DME DRUSEN "
     ]
    }
   ],
   "source": [
    "x_tst=[]\n",
    "y_tst=[]\n",
    "for x in labels_list:\n",
    "    xPath = os.path.join(dataPath, \"test\", x)\n",
    "    myPicList = os.listdir(xPath)\n",
    "    for y in myPicList:\n",
    "        x_tst.append(cv2.imread(os.path.join(xPath, y)))\n",
    "        y_tst.append(labels_list.index(x))\n",
    "    print(x ,end=\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of images per category and set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label\t\tTrain\t\tValidation\t\tTest\n",
      "NORMAL\t\t26315\t\t8\t\t\t242\n",
      "CNV\t\t37205\t\t8\t\t\t242\n",
      "DME\t\t11348\t\t8\t\t\t242\n",
      "DRUSEN\t\t8616\t\t8\t\t\t242\n"
     ]
    }
   ],
   "source": [
    "def getNumberOfItems(labels, itemLabel):\n",
    "    return sum(list(map(lambda x: x == itemLabel, labels))) \n",
    "\n",
    "\n",
    "print(\"Label\\t\\tTrain\\t\\tValidation\\t\\tTest\")\n",
    "for i, label in enumerate(labels_list):\n",
    "    print(f\"{label}\\t\\t{getNumberOfItems(y_trn, i)}\\t\\t{getNumberOfItems(y_val, i)}\\t\\t\\t{getNumberOfItems(y_tst, i)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resizeIm(im, size):\n",
    "    if im.shape[2] == 1:\n",
    "        im = cv2.cvtColor(im,cv2.COLOR_GRAY2RGB)\n",
    "    return cv2.resize(im, size)\n",
    "\n",
    "def resizeIms(x, size):\n",
    "    return np.array(list(map(lambda im: resizeIm(im, size), x)))\n",
    "\n",
    "# Substract the mean specified by Mean (https://www.mathworks.com/help/deeplearning/ref/nnet.cnn.layer.imageinputlayer.html)\n",
    "# Substract mean by channel\n",
    "def zerocenter(x):\n",
    "    return (x - np.mean(x, axis=(0, 1))) / (2*np.std(x, axis=(0, 1)))\n",
    "\n",
    "# Rescale the input to be in the range [-1, 1] using the minimum and maximum values specified by Min and Max, respectively. (https://www.mathworks.com/help/deeplearning/ref/nnet.cnn.layer.imageinputlayer.html)\n",
    "# Compute using the formula: $x\\prime = 2 * \\frac{x - \\min{x}}{\\max{x} - \\min{x}} - 1$ taken from: https://stats.stackexchange.com/a/178629\n",
    "def rescaleSymmetric(x):\n",
    "    x = zerocenter(x)\n",
    "    return 2 * (x - np.min(x, axis=(0, 1)))/np.ptp(x, axis=(0, 1)) - 1\n",
    "\n",
    "def normalizeIms(x, normalization):\n",
    "    if normalization == \"zerocenter\":\n",
    "        func = zerocenter\n",
    "    elif normalization == \"rescale-symmetric\":\n",
    "        func = rescaleSymmetric\n",
    "    else:\n",
    "        return x\n",
    "    return np.array(list(map(lambda im: func(im), x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self,fraction, model):\n",
    "        super(CustomCallback,self).__init__()\n",
    "        self.fraction = fraction\n",
    "        self.train_a = [];\n",
    "        self.val_a =[];\n",
    "        self.logPath = os.path.join(model, \"log.txt\")\n",
    "\n",
    "        if not os.path.isdir(model):\n",
    "            os.mkdir(model)\n",
    "\n",
    "        with open(self.logPath,'w') as f:\n",
    "            f.write('Starting of logging..\\n')\n",
    "\n",
    "        self.fig = plt.figure(figsize=(4,3))\n",
    "        self.ax = plt.subplot(1,1,1)\n",
    "        plt.ion()\n",
    "\n",
    "    def on_train_begin(self,logs=None):\n",
    "        self.fig.show()\n",
    "        self.fig.canvas.draw()\n",
    "\n",
    "    def on_train_end(self,logs=None):\n",
    "        with open(self.logPath,'a') as f:\n",
    "              f.write('End of logging..\\n')\n",
    "    \n",
    "    def on_epoch_begin(self,epoch,logs=None):\n",
    "        lr= tf.keras.backend.get_value(self.model.optimizer.lr)\n",
    "        lr *= self.fraction\n",
    "        tf.keras.backend.set_value(self.model.optimizer.lr,lr)\n",
    "        with open(self.logPath,'a') as f:\n",
    "            f.write('At epoch {:02d}, learning rate changed to {:.4f}\\n'.format(epoch,lr))\n",
    "    \n",
    "    def on_epoch_end(self,epoch,logs=None):\n",
    "        val_acc = logs.get('val_accuracy')\n",
    "        train_acc = logs.get('accuracy')\n",
    "        self.train_a.append(train_acc)\n",
    "        self.val_a.append(val_acc)\n",
    "        with open(self.logPath,'a') as f:\n",
    "            f.write('At epoch {:02d}, training accuracy: {:.3f}, validation accuracy: {:.3f}\\n'.format(epoch,train_acc,val_acc))\n",
    "        self.ax.clear()\n",
    "        self.ax.plot(range(1+epoch),self.train_a,label=\"Training\")\n",
    "        self.ax.plot(range(1+epoch),self.val_a,label=\"Validation\")\n",
    "        self.ax.set_xlabel('Epochs')\n",
    "        self.ax.set_ylabel('Accuracy')\n",
    "        self.ax.legend()\n",
    "        self.fig.canvas.draw()\n",
    "        self.fig.show()\n",
    "        \n",
    "class TimeHistory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.times = []\n",
    "\n",
    "    def on_epoch_begin(self, batch, logs={}):\n",
    "        self.epoch_time_start = time.time()\n",
    "\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.times.append(time.time() - self.epoch_time_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "# xception base model\n",
    "#from tensorflow.keras.applications.xception import Xception\n",
    "#from tensorflow.keras.applications.xception import preprocess_input, decode_predictions\n",
    "#xceptionNetModel = Xception(weights='imagenet')\n",
    "#xceptionNetModel.save(\"../Xception.hdf5\")\n",
    "\n",
    "xceptionNetModel = tf.keras.models.load_model('../Xception.hdf5')\n",
    "\n",
    "# opticnet base model\n",
    "opticNetModel = tf.keras.models.load_model('../Optic_net-4_classes-Kermany2018.hdf5')\n",
    "\n",
    "# resnet base model\n",
    "#from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "#from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "#resNetModel = ResNet50(weights='imagenet')\n",
    "#resNetModel.save(\"../Resnet50.hdf5\")\n",
    "\n",
    "resNetModel = tf.keras.models.load_model('../Resnet50.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 221, 221, 32)      4736      \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 221, 221, 32)      128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 110, 110, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 104, 104, 32)      50208     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 104, 104, 32)      128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 52, 52, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 48, 48, 64)        51264     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 48, 48, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 24, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 20, 20, 128)       204928    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 20, 20, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 10, 10, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 8, 8, 256)         295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d (AveragePo (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               131200    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4)                 132       \n",
      "_________________________________________________________________\n",
      "softmax (Softmax)            (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 743,812\n",
      "Trainable params: 742,788\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "conv_init = tf.keras.initializers.RandomNormal(mean=0., stddev=1.) # convolutional layer with zero mean and 1 sd\n",
    "#batch_init = tf.keras.initializers.RandomNormal(mean=1., stddev=0.02) # non-sense here\n",
    "\n",
    "octnet = keras.models.Sequential() # empty model\n",
    "\n",
    "octnet.add(keras.layers.Conv2D(32, (7, 7), activation=\"relu\", use_bias=True, input_shape=(227, 227, 3), kernel_initializer=conv_init))\n",
    "octnet.add(keras.layers.BatchNormalization())\n",
    "octnet.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "octnet.add(keras.layers.Conv2D(32, (7, 7), activation=\"relu\", use_bias=True, kernel_initializer=conv_init))\n",
    "octnet.add(keras.layers.BatchNormalization())\n",
    "octnet.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "octnet.add(keras.layers.Conv2D(64, (5, 5), activation=\"relu\", use_bias=True, kernel_initializer=conv_init))\n",
    "octnet.add(keras.layers.BatchNormalization())\n",
    "octnet.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "octnet.add(keras.layers.Conv2D(128, (5, 5), activation=\"relu\", use_bias=True, kernel_initializer=conv_init))\n",
    "octnet.add(keras.layers.BatchNormalization())\n",
    "octnet.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "octnet.add(keras.layers.Conv2D(256, (3, 3), activation=\"relu\", use_bias=True, kernel_initializer=conv_init))\n",
    "octnet.add(keras.layers.BatchNormalization())\n",
    "octnet.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "#octnet.add(keras.layers.Conv2D(512, (3, 3), activation=\"relu\", use_bias=True))\n",
    "#octnet.add(keras.layers.BatchNormalization())\n",
    "#octnet.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "octnet.add(keras.layers.AveragePooling2D())\n",
    "octnet.add(keras.layers.Flatten())\n",
    "octnet.add(keras.layers.Dense(128))\n",
    "octnet.add(keras.layers.Dropout(0.5))\n",
    "octnet.add(keras.layers.Dense(32))\n",
    "octnet.add(keras.layers.Dropout(0.5))\n",
    "octnet.add(keras.layers.Dense(4))\n",
    "octnet.add(keras.layers.Softmax())\n",
    "\n",
    "octnet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emptyModelGenerator(model, newWeights=False, lastOnly=False):\n",
    "    model = model.lower() # lower case model name\n",
    "    if model == \"resnet\":\n",
    "        x = resNetModel.output\n",
    "        predictions = Dense(len(labels_list), activation='softmax')(x)\n",
    "        newModel = Model(inputs=resNetModel.input, outputs=predictions)\n",
    "        size = (224, 224)\n",
    "        normalization = \"zerocenter\"\n",
    "    elif model == \"xception\":\n",
    "        x = xceptionNetModel.output\n",
    "        predictions = Dense(len(labels_list), activation='softmax')(x)\n",
    "        newModel = Model(inputs=xceptionNetModel.input, outputs=predictions)\n",
    "        size = (299, 299)\n",
    "        normalization = \"rescale-symmetric\"\n",
    "    elif model == \"opticnet\":\n",
    "        newModel = tf.keras.models.load_model('../Optic_net-4_classes-Kermany2018.hdf5')\n",
    "        size = (224, 224)\n",
    "        normalization = \"rescale-symmetric\"\n",
    "    elif model == \"octnet\":\n",
    "        newModel = tf.keras.models.clone_model(octnet)\n",
    "        size = (227, 227)\n",
    "        normalization = \"zerocenter\"\n",
    "    if newWeights:\n",
    "        newModel = tf.keras.models.clone_model(newModel)\n",
    "    if lastOnly:\n",
    "        newModel = lastDenseTrainable(newModel) # block all layer except the last dense ones\n",
    "    else:\n",
    "        newModel.trainable = True\n",
    "    return newModel, size, normalization\n",
    "\n",
    "\n",
    "def lastDenseTrainable(model):\n",
    "    model.trainable = False\n",
    "    for i in range(1, len(model.layers)):\n",
    "        if model.layers[-i].__class__.__name__ == \"Dense\":\n",
    "            model.layers[-i].trainable= True\n",
    "        elif model.layers[-i].__class__.__name__ == \"Activation\":\n",
    "            continue\n",
    "        else:\n",
    "            break\n",
    "    return model\n",
    "    \n",
    "\n",
    "def testPredict(model, size, name=None, normalization=None):\n",
    "    X_test = resizeIms(x_tst, size)\n",
    "    if normalization:\n",
    "        X_test = normalizeIms(X_test, normalization)\n",
    "    X_test = np.array(X_test)\n",
    "    Y_test = np.array(y_tst)\n",
    "    \n",
    "    prediction = model.predict(X_test)\n",
    "    preds = np.argmax(prediction, axis=1)\n",
    "    acc = sum(preds == Y_test) / len(Y_test)\n",
    "    print(f'Test acc for {name if name else \"model\"}: {acc:.6f}')\n",
    "    return acc\n",
    "    \n",
    "\n",
    "def computeConfussionMatrix(predictions, labels):\n",
    "    num_labels = len(labels_list)\n",
    "    cMatrix = np.zeros(shape=(num_labels, num_labels))\n",
    "    for i in len(predictions):\n",
    "        p = int(predictions[i])\n",
    "        t = int(predictions[i])\n",
    "        cMatrix[t, p] += 1\n",
    "    print(cMatrix)\n",
    "    ax = sns.heatmap(cMatrix, cmap=\"Blues\", annot=True, fmt=\"d\", xticklabels=labels_list, yticklabels=labels_list)\n",
    "    plt.xlabel(\"Predicted label\")\n",
    "    plt.ylabel(\"True label\")\n",
    "    plt.title(\"Confusion matrix\")\n",
    "    plt.show();\n",
    "    return cMatrix\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "**************************************************\n",
      "Model: xception\n",
      "**************************************************\n",
      "\n",
      "Total: 135 trainable: 2\n",
      "\n",
      "\n",
      "**************************************************\n",
      "Model: resnet\n",
      "**************************************************\n",
      "\n",
      "Total: 178 trainable: 2\n",
      "\n",
      "\n",
      "**************************************************\n",
      "Model: opticnet\n",
      "**************************************************\n",
      "\n",
      "Total: 276 trainable: 2\n",
      "\n",
      "\n",
      "**************************************************\n",
      "Model: octnet\n",
      "**************************************************\n",
      "\n",
      "Total: 23 trainable: 0\n"
     ]
    }
   ],
   "source": [
    "models = [\"xception\", \"resnet\", \"opticnet\", \"octnet\"]\n",
    "\n",
    "def printTrainableLayers(m):\n",
    "    a = 0\n",
    "    for l in m.layers:\n",
    "        #l.trainable = True\n",
    "        if l.trainable:\n",
    "            #print(l.name, l.trainable)\n",
    "            a += 1\n",
    "    print(f\"\\nTotal: {len(m.layers)} trainable: {a}\")\n",
    "\n",
    "for mod in models:\n",
    "    print(\"\\n\\n\" + (\"*\"*50) + \"\\nModel: \" + mod + '\\n' + (\"*\"*50))\n",
    "    m = emptyModelGenerator(mod, newWeights=False, lastOnly=True)[0]\n",
    "    printTrainableLayers(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.1\n",
    "momentum = 0.6\n",
    "optim = lambda lr: Adam(learning_rate=lr)\n",
    "#optim = lambda lr, momentum: SGD(learning_rate=lr, momentum=momentum)\n",
    "epochs = 30\n",
    "batch_size = 50\n",
    "#batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "results = pd.read_csv(\"Results_temp.csv\")\n",
    "results[\"normalization\"] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pandas as pd\n",
    "#res = pd.read_csv(\"Results_temp.csv\")\n",
    "#res.to_csv(\"Results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels fraction: [0.0100323  0.01083188 0.00863588 0.00800836]\n",
      "Training resnet for 0.01% of train size (aka 834 images) with pretrained: False and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 178 trainable: 178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      " 6/17 [=========>....................] - ETA: 3s - loss: 1.3691 - accuracy: 0.4099WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0940s vs `on_train_batch_end` time: 0.2081s). Check your callbacks.\n",
      "17/17 [==============================] - 14s 431ms/step - loss: 1.3267 - accuracy: 0.4512 - val_loss: 1.4631 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "17/17 [==============================] - 3s 186ms/step - loss: 1.1819 - accuracy: 0.4803 - val_loss: 1.4997 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "17/17 [==============================] - 3s 186ms/step - loss: 1.1660 - accuracy: 0.4889 - val_loss: 1.5033 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "17/17 [==============================] - 3s 186ms/step - loss: 1.1581 - accuracy: 0.4877 - val_loss: 1.5109 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "17/17 [==============================] - 3s 186ms/step - loss: 1.1706 - accuracy: 0.4750 - val_loss: 1.5139 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "17/17 [==============================] - 3s 187ms/step - loss: 1.1679 - accuracy: 0.4916 - val_loss: 1.5148 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "17/17 [==============================] - 3s 188ms/step - loss: 1.1773 - accuracy: 0.4859 - val_loss: 1.5198 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "17/17 [==============================] - 3s 188ms/step - loss: 1.1885 - accuracy: 0.4757 - val_loss: 1.5245 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "17/17 [==============================] - 3s 189ms/step - loss: 1.1488 - accuracy: 0.4902 - val_loss: 1.5313 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "17/17 [==============================] - 3s 189ms/step - loss: 1.1525 - accuracy: 0.4762 - val_loss: 1.5363 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "17/17 [==============================] - 3s 188ms/step - loss: 1.1817 - accuracy: 0.4809 - val_loss: 1.5415 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "17/17 [==============================] - 3s 189ms/step - loss: 1.1570 - accuracy: 0.5022 - val_loss: 1.5523 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "17/17 [==============================] - 3s 189ms/step - loss: 1.1705 - accuracy: 0.4977 - val_loss: 1.5622 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "17/17 [==============================] - 3s 189ms/step - loss: 1.1542 - accuracy: 0.4970 - val_loss: 1.5710 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "17/17 [==============================] - 3s 189ms/step - loss: 1.1790 - accuracy: 0.4834 - val_loss: 1.5809 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "17/17 [==============================] - 3s 190ms/step - loss: 1.1780 - accuracy: 0.4877 - val_loss: 1.5873 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "17/17 [==============================] - 3s 191ms/step - loss: 1.1686 - accuracy: 0.4794 - val_loss: 1.5973 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "17/17 [==============================] - 3s 190ms/step - loss: 1.1588 - accuracy: 0.4833 - val_loss: 1.6034 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "17/17 [==============================] - 3s 190ms/step - loss: 1.2143 - accuracy: 0.4531 - val_loss: 1.6079 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "17/17 [==============================] - 3s 191ms/step - loss: 1.1865 - accuracy: 0.4605 - val_loss: 1.6150 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "17/17 [==============================] - 3s 191ms/step - loss: 1.1775 - accuracy: 0.4758 - val_loss: 1.6180 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "17/17 [==============================] - 3s 191ms/step - loss: 1.1753 - accuracy: 0.4812 - val_loss: 1.6196 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "17/17 [==============================] - 3s 191ms/step - loss: 1.1768 - accuracy: 0.4760 - val_loss: 1.6224 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "17/17 [==============================] - 3s 191ms/step - loss: 1.1707 - accuracy: 0.4852 - val_loss: 1.6229 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "17/17 [==============================] - 3s 193ms/step - loss: 1.1459 - accuracy: 0.5152 - val_loss: 1.6236 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "17/17 [==============================] - 3s 192ms/step - loss: 1.1989 - accuracy: 0.4774 - val_loss: 1.6244 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "17/17 [==============================] - 3s 191ms/step - loss: 1.1933 - accuracy: 0.4746 - val_loss: 1.6254 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "17/17 [==============================] - 3s 192ms/step - loss: 1.1829 - accuracy: 0.4669 - val_loss: 1.6262 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "17/17 [==============================] - 3s 192ms/step - loss: 1.1738 - accuracy: 0.4853 - val_loss: 1.6266 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "17/17 [==============================] - 3s 192ms/step - loss: 1.1922 - accuracy: 0.4650 - val_loss: 1.6265 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_835_images_True_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.02420673 0.02577611 0.02634826 0.02228412]\n",
      "Training resnet for 0.025% of train size (aka 2087 images) with pretrained: False and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 178 trainable: 178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      " 6/42 [===>..........................] - ETA: 14s - loss: 1.3738 - accuracy: 0.3986WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0961s vs `on_train_batch_end` time: 0.2566s). Check your callbacks.\n",
      "42/42 [==============================] - 17s 270ms/step - loss: 1.2939 - accuracy: 0.4500 - val_loss: 1.4597 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "42/42 [==============================] - 8s 189ms/step - loss: 1.2239 - accuracy: 0.4497 - val_loss: 1.4670 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "42/42 [==============================] - 8s 190ms/step - loss: 1.2218 - accuracy: 0.4585 - val_loss: 1.4747 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "42/42 [==============================] - 8s 191ms/step - loss: 1.2235 - accuracy: 0.4631 - val_loss: 1.5008 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "42/42 [==============================] - 8s 191ms/step - loss: 1.2162 - accuracy: 0.4619 - val_loss: 1.5190 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "42/42 [==============================] - 8s 191ms/step - loss: 1.2254 - accuracy: 0.4510 - val_loss: 1.5510 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "42/42 [==============================] - 8s 192ms/step - loss: 1.2251 - accuracy: 0.4486 - val_loss: 1.5608 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "42/42 [==============================] - 8s 192ms/step - loss: 1.2162 - accuracy: 0.4560 - val_loss: 1.5591 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "42/42 [==============================] - 8s 192ms/step - loss: 1.2086 - accuracy: 0.4679 - val_loss: 1.5618 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "42/42 [==============================] - 8s 192ms/step - loss: 1.2280 - accuracy: 0.4477 - val_loss: 1.5747 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "42/42 [==============================] - 8s 192ms/step - loss: 1.2366 - accuracy: 0.4320 - val_loss: 1.5806 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "42/42 [==============================] - 8s 192ms/step - loss: 1.2095 - accuracy: 0.4692 - val_loss: 1.5708 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "42/42 [==============================] - 8s 192ms/step - loss: 1.2261 - accuracy: 0.4599 - val_loss: 1.5741 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "42/42 [==============================] - 8s 193ms/step - loss: 1.2202 - accuracy: 0.4580 - val_loss: 1.5746 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "42/42 [==============================] - 8s 192ms/step - loss: 1.2271 - accuracy: 0.4540 - val_loss: 1.5739 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "42/42 [==============================] - 8s 192ms/step - loss: 1.2079 - accuracy: 0.4526 - val_loss: 1.5753 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "42/42 [==============================] - 8s 193ms/step - loss: 1.2224 - accuracy: 0.4527 - val_loss: 1.5737 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "42/42 [==============================] - 8s 193ms/step - loss: 1.2339 - accuracy: 0.4487 - val_loss: 1.5744 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "42/42 [==============================] - 8s 193ms/step - loss: 1.2088 - accuracy: 0.4640 - val_loss: 1.5726 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "42/42 [==============================] - 8s 192ms/step - loss: 1.1979 - accuracy: 0.4676 - val_loss: 1.5726 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "42/42 [==============================] - 8s 193ms/step - loss: 1.2208 - accuracy: 0.4650 - val_loss: 1.5728 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "42/42 [==============================] - 8s 193ms/step - loss: 1.2116 - accuracy: 0.4482 - val_loss: 1.5734 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "42/42 [==============================] - 8s 192ms/step - loss: 1.2104 - accuracy: 0.4717 - val_loss: 1.5724 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "42/42 [==============================] - 8s 192ms/step - loss: 1.2220 - accuracy: 0.4576 - val_loss: 1.5732 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "42/42 [==============================] - 8s 193ms/step - loss: 1.2331 - accuracy: 0.4415 - val_loss: 1.5742 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "42/42 [==============================] - 8s 193ms/step - loss: 1.2266 - accuracy: 0.4510 - val_loss: 1.5729 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "42/42 [==============================] - 8s 193ms/step - loss: 1.2151 - accuracy: 0.4528 - val_loss: 1.5733 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "42/42 [==============================] - 8s 193ms/step - loss: 1.2106 - accuracy: 0.4659 - val_loss: 1.5729 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "42/42 [==============================] - 8s 193ms/step - loss: 1.2194 - accuracy: 0.4671 - val_loss: 1.5730 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "42/42 [==============================] - 8s 193ms/step - loss: 1.2191 - accuracy: 0.4663 - val_loss: 1.5731 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_2087_images_True_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.04902147 0.05096089 0.0489073  0.05025534]\n",
      "Training resnet for 0.05% of train size (aka 4174 images) with pretrained: False and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 178 trainable: 178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      " 6/84 [=>............................] - ETA: 30s - loss: 1.3702 - accuracy: 0.4894WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0938s vs `on_train_batch_end` time: 0.2599s). Check your callbacks.\n",
      "84/84 [==============================] - 25s 227ms/step - loss: 1.2742 - accuracy: 0.4603 - val_loss: 1.4687 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "84/84 [==============================] - 16s 190ms/step - loss: 1.2252 - accuracy: 0.4561 - val_loss: 1.4861 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "84/84 [==============================] - 16s 191ms/step - loss: 1.2298 - accuracy: 0.4491 - val_loss: 1.5282 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "84/84 [==============================] - 16s 192ms/step - loss: 1.2297 - accuracy: 0.4451 - val_loss: 1.5671 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "84/84 [==============================] - 16s 192ms/step - loss: 1.2235 - accuracy: 0.4503 - val_loss: 1.5540 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "84/84 [==============================] - 16s 193ms/step - loss: 1.2318 - accuracy: 0.4518 - val_loss: 1.5620 - val_accuracy: 0.2500\n",
      "Epoch 7/30\n",
      "84/84 [==============================] - 16s 193ms/step - loss: 1.2152 - accuracy: 0.4590 - val_loss: 1.5431 - val_accuracy: 0.2500\n",
      "Epoch 8/30\n",
      "84/84 [==============================] - 16s 193ms/step - loss: 1.2158 - accuracy: 0.4581 - val_loss: 1.5612 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "84/84 [==============================] - 16s 193ms/step - loss: 1.2269 - accuracy: 0.4532 - val_loss: 1.5652 - val_accuracy: 0.2500\n",
      "Epoch 10/30\n",
      "84/84 [==============================] - 16s 193ms/step - loss: 1.2234 - accuracy: 0.4599 - val_loss: 1.5535 - val_accuracy: 0.2500\n",
      "Epoch 11/30\n",
      "84/84 [==============================] - 16s 193ms/step - loss: 1.2251 - accuracy: 0.4556 - val_loss: 1.5626 - val_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "84/84 [==============================] - 16s 193ms/step - loss: 1.2127 - accuracy: 0.4560 - val_loss: 1.5589 - val_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "84/84 [==============================] - 16s 193ms/step - loss: 1.2351 - accuracy: 0.4431 - val_loss: 1.5636 - val_accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "84/84 [==============================] - 16s 193ms/step - loss: 1.2320 - accuracy: 0.4552 - val_loss: 1.5629 - val_accuracy: 0.2500\n",
      "Epoch 15/30\n",
      "84/84 [==============================] - 16s 194ms/step - loss: 1.2428 - accuracy: 0.4479 - val_loss: 1.5678 - val_accuracy: 0.2500\n",
      "Epoch 16/30\n",
      "84/84 [==============================] - 16s 193ms/step - loss: 1.2216 - accuracy: 0.4555 - val_loss: 1.5605 - val_accuracy: 0.2500\n",
      "Epoch 17/30\n",
      "84/84 [==============================] - 16s 193ms/step - loss: 1.2310 - accuracy: 0.4471 - val_loss: 1.5597 - val_accuracy: 0.2500\n",
      "Epoch 18/30\n",
      "84/84 [==============================] - 16s 193ms/step - loss: 1.2364 - accuracy: 0.4422 - val_loss: 1.5679 - val_accuracy: 0.2500\n",
      "Epoch 19/30\n",
      "84/84 [==============================] - 16s 193ms/step - loss: 1.2164 - accuracy: 0.4558 - val_loss: 1.5631 - val_accuracy: 0.2500\n",
      "Epoch 20/30\n",
      "84/84 [==============================] - 16s 193ms/step - loss: 1.2353 - accuracy: 0.4482 - val_loss: 1.5637 - val_accuracy: 0.2500\n",
      "Epoch 21/30\n",
      "84/84 [==============================] - 16s 193ms/step - loss: 1.2136 - accuracy: 0.4544 - val_loss: 1.5621 - val_accuracy: 0.2500\n",
      "Epoch 22/30\n",
      "84/84 [==============================] - 16s 193ms/step - loss: 1.2296 - accuracy: 0.4508 - val_loss: 1.5634 - val_accuracy: 0.2500\n",
      "Epoch 23/30\n",
      "84/84 [==============================] - 16s 194ms/step - loss: 1.2279 - accuracy: 0.4540 - val_loss: 1.5632 - val_accuracy: 0.2500\n",
      "Epoch 24/30\n",
      "84/84 [==============================] - 16s 193ms/step - loss: 1.2326 - accuracy: 0.4538 - val_loss: 1.5631 - val_accuracy: 0.2500\n",
      "Epoch 25/30\n",
      "84/84 [==============================] - 16s 193ms/step - loss: 1.2196 - accuracy: 0.4596 - val_loss: 1.5617 - val_accuracy: 0.2500\n",
      "Epoch 26/30\n",
      "84/84 [==============================] - 16s 193ms/step - loss: 1.2298 - accuracy: 0.4527 - val_loss: 1.5628 - val_accuracy: 0.2500\n",
      "Epoch 27/30\n",
      "84/84 [==============================] - 16s 193ms/step - loss: 1.2180 - accuracy: 0.4597 - val_loss: 1.5624 - val_accuracy: 0.2500\n",
      "Epoch 28/30\n",
      "84/84 [==============================] - 16s 193ms/step - loss: 1.2325 - accuracy: 0.4506 - val_loss: 1.5625 - val_accuracy: 0.2500\n",
      "Epoch 29/30\n",
      "84/84 [==============================] - 16s 193ms/step - loss: 1.2201 - accuracy: 0.4626 - val_loss: 1.5618 - val_accuracy: 0.2500\n",
      "Epoch 30/30\n",
      "84/84 [==============================] - 16s 193ms/step - loss: 1.2252 - accuracy: 0.4503 - val_loss: 1.5618 - val_accuracy: 0.2500\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_4174_images_True_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.250000\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.07501425 0.07571563 0.07340501 0.07393222]\n",
      "Training resnet for 0.075% of train size (aka 6261 images) with pretrained: False and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 178 trainable: 178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/126 [>.............................] - ETA: 46s - loss: 1.3709 - accuracy: 0.3283WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0943s vs `on_train_batch_end` time: 0.2582s). Check your callbacks.\n",
      "126/126 [==============================] - 32s 213ms/step - loss: 1.2639 - accuracy: 0.4348 - val_loss: 1.5388 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "126/126 [==============================] - 24s 191ms/step - loss: 1.2190 - accuracy: 0.4485 - val_loss: 1.5897 - val_accuracy: 0.3438\n",
      "Epoch 3/30\n",
      "126/126 [==============================] - 24s 192ms/step - loss: 0.9955 - accuracy: 0.6606 - val_loss: 1.6848 - val_accuracy: 0.2812\n",
      "Epoch 4/30\n",
      "126/126 [==============================] - 24s 193ms/step - loss: 0.8149 - accuracy: 0.7087 - val_loss: 1.2824 - val_accuracy: 0.4062\n",
      "Epoch 5/30\n",
      "126/126 [==============================] - 24s 193ms/step - loss: 0.7072 - accuracy: 0.7402 - val_loss: 1.1731 - val_accuracy: 0.5312\n",
      "Epoch 6/30\n",
      "126/126 [==============================] - 24s 193ms/step - loss: 0.7005 - accuracy: 0.7584 - val_loss: 1.2446 - val_accuracy: 0.5000\n",
      "Epoch 7/30\n",
      "126/126 [==============================] - 24s 193ms/step - loss: 0.7095 - accuracy: 0.7525 - val_loss: 1.1927 - val_accuracy: 0.4375\n",
      "Epoch 8/30\n",
      "126/126 [==============================] - 24s 193ms/step - loss: 0.6446 - accuracy: 0.7837 - val_loss: 1.1115 - val_accuracy: 0.6562\n",
      "Epoch 9/30\n",
      "126/126 [==============================] - 24s 193ms/step - loss: 0.6202 - accuracy: 0.7955 - val_loss: 0.9799 - val_accuracy: 0.6875\n",
      "Epoch 10/30\n",
      "126/126 [==============================] - 24s 193ms/step - loss: 0.5840 - accuracy: 0.8077 - val_loss: 1.2245 - val_accuracy: 0.5938\n",
      "Epoch 11/30\n",
      "126/126 [==============================] - 24s 194ms/step - loss: 0.5469 - accuracy: 0.8288 - val_loss: 1.1005 - val_accuracy: 0.6875\n",
      "Epoch 12/30\n",
      "126/126 [==============================] - 24s 194ms/step - loss: 0.5353 - accuracy: 0.8283 - val_loss: 1.1527 - val_accuracy: 0.6875\n",
      "Epoch 13/30\n",
      "126/126 [==============================] - 24s 193ms/step - loss: 0.4736 - accuracy: 0.8511 - val_loss: 0.6995 - val_accuracy: 0.7188\n",
      "Epoch 14/30\n",
      "126/126 [==============================] - 24s 193ms/step - loss: 0.4510 - accuracy: 0.8558 - val_loss: 0.6171 - val_accuracy: 0.7188\n",
      "Epoch 15/30\n",
      "126/126 [==============================] - 24s 193ms/step - loss: 0.4233 - accuracy: 0.8618 - val_loss: 0.7771 - val_accuracy: 0.6875\n",
      "Epoch 16/30\n",
      "126/126 [==============================] - 24s 194ms/step - loss: 0.4160 - accuracy: 0.8571 - val_loss: 0.8288 - val_accuracy: 0.6875\n",
      "Epoch 17/30\n",
      "126/126 [==============================] - 24s 193ms/step - loss: 0.3751 - accuracy: 0.8689 - val_loss: 0.6950 - val_accuracy: 0.6562\n",
      "Epoch 18/30\n",
      "126/126 [==============================] - 24s 193ms/step - loss: 0.3391 - accuracy: 0.8796 - val_loss: 0.5306 - val_accuracy: 0.7500\n",
      "Epoch 19/30\n",
      "126/126 [==============================] - 24s 193ms/step - loss: 0.3627 - accuracy: 0.8603 - val_loss: 0.5712 - val_accuracy: 0.6875\n",
      "Epoch 20/30\n",
      "126/126 [==============================] - 24s 193ms/step - loss: 0.3227 - accuracy: 0.8808 - val_loss: 0.4487 - val_accuracy: 0.7812\n",
      "Epoch 21/30\n",
      "126/126 [==============================] - 24s 193ms/step - loss: 0.2738 - accuracy: 0.8986 - val_loss: 0.3883 - val_accuracy: 0.8750\n",
      "Epoch 22/30\n",
      "126/126 [==============================] - 24s 193ms/step - loss: 0.2617 - accuracy: 0.9233 - val_loss: 0.5033 - val_accuracy: 0.9062\n",
      "Epoch 23/30\n",
      "126/126 [==============================] - 24s 193ms/step - loss: 0.2398 - accuracy: 0.9583 - val_loss: 0.3382 - val_accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "126/126 [==============================] - 24s 193ms/step - loss: 0.2393 - accuracy: 0.9612 - val_loss: 0.3242 - val_accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "126/126 [==============================] - 24s 193ms/step - loss: 0.2158 - accuracy: 0.9750 - val_loss: 0.3137 - val_accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "126/126 [==============================] - 24s 193ms/step - loss: 0.2058 - accuracy: 0.9752 - val_loss: 0.3618 - val_accuracy: 0.9688\n",
      "Epoch 27/30\n",
      "126/126 [==============================] - 24s 193ms/step - loss: 0.2033 - accuracy: 0.9786 - val_loss: 0.5396 - val_accuracy: 0.8750\n",
      "Epoch 28/30\n",
      "126/126 [==============================] - 24s 193ms/step - loss: 0.1855 - accuracy: 0.9865 - val_loss: 0.4373 - val_accuracy: 0.9375\n",
      "Epoch 29/30\n",
      "126/126 [==============================] - 24s 194ms/step - loss: 0.1829 - accuracy: 0.9877 - val_loss: 0.2971 - val_accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "126/126 [==============================] - 24s 193ms/step - loss: 0.1796 - accuracy: 0.9875 - val_loss: 0.3197 - val_accuracy: 0.9375\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_6261_images_True_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.921488\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.08956869 0.0906061  0.09067677 0.08774373]\n",
      "Training resnet for 0.09% of train size (aka 7513 images) with pretrained: False and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 178 trainable: 178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/151 [>.............................] - ETA: 57s - loss: 1.3755 - accuracy: 0.3488 WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0942s vs `on_train_batch_end` time: 0.2623s). Check your callbacks.\n",
      "151/151 [==============================] - 38s 210ms/step - loss: 1.2616 - accuracy: 0.4386 - val_loss: 1.5436 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "151/151 [==============================] - 29s 191ms/step - loss: 1.2206 - accuracy: 0.4559 - val_loss: 1.5607 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "151/151 [==============================] - 29s 192ms/step - loss: 1.2183 - accuracy: 0.4516 - val_loss: 1.5895 - val_accuracy: 0.2188\n",
      "Epoch 4/30\n",
      "151/151 [==============================] - 29s 193ms/step - loss: 1.0295 - accuracy: 0.6582 - val_loss: 1.6034 - val_accuracy: 0.4688\n",
      "Epoch 5/30\n",
      "151/151 [==============================] - 29s 193ms/step - loss: 0.7937 - accuracy: 0.7301 - val_loss: 1.7788 - val_accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "151/151 [==============================] - 29s 193ms/step - loss: 0.7338 - accuracy: 0.7400 - val_loss: 1.4694 - val_accuracy: 0.4062\n",
      "Epoch 7/30\n",
      "151/151 [==============================] - 29s 193ms/step - loss: 0.6724 - accuracy: 0.7666 - val_loss: 1.2841 - val_accuracy: 0.3750\n",
      "Epoch 8/30\n",
      "151/151 [==============================] - 29s 193ms/step - loss: 0.6581 - accuracy: 0.7843 - val_loss: 2.1756 - val_accuracy: 0.2500\n",
      "Epoch 9/30\n",
      "151/151 [==============================] - 29s 193ms/step - loss: 0.6246 - accuracy: 0.7916 - val_loss: 1.0128 - val_accuracy: 0.6562\n",
      "Epoch 10/30\n",
      "151/151 [==============================] - 29s 193ms/step - loss: 0.5740 - accuracy: 0.8190 - val_loss: 0.8497 - val_accuracy: 0.6250\n",
      "Epoch 11/30\n",
      "151/151 [==============================] - 29s 194ms/step - loss: 0.5579 - accuracy: 0.8135 - val_loss: 1.1341 - val_accuracy: 0.5000\n",
      "Epoch 12/30\n",
      "151/151 [==============================] - 29s 193ms/step - loss: 0.4963 - accuracy: 0.8312 - val_loss: 1.0986 - val_accuracy: 0.6250\n",
      "Epoch 13/30\n",
      "151/151 [==============================] - 29s 193ms/step - loss: 0.4681 - accuracy: 0.8353 - val_loss: 0.9176 - val_accuracy: 0.6250\n",
      "Epoch 14/30\n",
      "151/151 [==============================] - 29s 193ms/step - loss: 0.4355 - accuracy: 0.8477 - val_loss: 0.7622 - val_accuracy: 0.7500\n",
      "Epoch 15/30\n",
      "151/151 [==============================] - 29s 193ms/step - loss: 0.4080 - accuracy: 0.8724 - val_loss: 0.8133 - val_accuracy: 0.7500\n",
      "Epoch 16/30\n",
      "151/151 [==============================] - 29s 193ms/step - loss: 0.3563 - accuracy: 0.9092 - val_loss: 0.6640 - val_accuracy: 0.8438\n",
      "Epoch 17/30\n",
      "151/151 [==============================] - 29s 193ms/step - loss: 0.3734 - accuracy: 0.8985 - val_loss: 0.4518 - val_accuracy: 0.9375\n",
      "Epoch 18/30\n",
      "151/151 [==============================] - 29s 193ms/step - loss: 0.3100 - accuracy: 0.9294 - val_loss: 0.6538 - val_accuracy: 0.8438\n",
      "Epoch 19/30\n",
      "151/151 [==============================] - 29s 192ms/step - loss: 0.3000 - accuracy: 0.9309 - val_loss: 0.3752 - val_accuracy: 0.9688\n",
      "Epoch 20/30\n",
      "151/151 [==============================] - 29s 193ms/step - loss: 0.2937 - accuracy: 0.9336 - val_loss: 0.3838 - val_accuracy: 0.9688\n",
      "Epoch 21/30\n",
      "151/151 [==============================] - 29s 193ms/step - loss: 0.2633 - accuracy: 0.9452 - val_loss: 0.2964 - val_accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "151/151 [==============================] - 29s 192ms/step - loss: 0.2230 - accuracy: 0.9602 - val_loss: 0.5326 - val_accuracy: 0.9062\n",
      "Epoch 23/30\n",
      "151/151 [==============================] - 29s 193ms/step - loss: 0.2084 - accuracy: 0.9665 - val_loss: 0.2848 - val_accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "151/151 [==============================] - 29s 193ms/step - loss: 0.1886 - accuracy: 0.9762 - val_loss: 0.2571 - val_accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "151/151 [==============================] - 29s 192ms/step - loss: 0.1777 - accuracy: 0.9786 - val_loss: 0.3079 - val_accuracy: 0.9375\n",
      "Epoch 26/30\n",
      "151/151 [==============================] - 29s 192ms/step - loss: 0.1737 - accuracy: 0.9785 - val_loss: 0.2300 - val_accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "151/151 [==============================] - 29s 192ms/step - loss: 0.1580 - accuracy: 0.9843 - val_loss: 0.2215 - val_accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "151/151 [==============================] - 29s 192ms/step - loss: 0.1437 - accuracy: 0.9883 - val_loss: 0.2091 - val_accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "151/151 [==============================] - 29s 192ms/step - loss: 0.1416 - accuracy: 0.9904 - val_loss: 0.1903 - val_accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "151/151 [==============================] - 29s 192ms/step - loss: 0.1241 - accuracy: 0.9927 - val_loss: 0.1780 - val_accuracy: 1.0000\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_7514_images_True_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.947314\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.09804294 0.10108856 0.10213253 0.09842154]\n",
      "Training resnet for 0.1% of train size (aka 8348 images) with pretrained: False and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 178 trainable: 178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/167 [>.............................] - ETA: 1:03 - loss: 1.3779 - accuracy: 0.3111WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0927s vs `on_train_batch_end` time: 0.2608s). Check your callbacks.\n",
      "167/167 [==============================] - 41s 212ms/step - loss: 1.2635 - accuracy: 0.4331 - val_loss: 1.5551 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "167/167 [==============================] - 32s 193ms/step - loss: 1.2230 - accuracy: 0.4534 - val_loss: 1.5649 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "167/167 [==============================] - 33s 195ms/step - loss: 1.2249 - accuracy: 0.4516 - val_loss: 1.8160 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "167/167 [==============================] - 33s 195ms/step - loss: 0.9919 - accuracy: 0.6363 - val_loss: 1.4577 - val_accuracy: 0.5000\n",
      "Epoch 5/30\n",
      "167/167 [==============================] - 33s 195ms/step - loss: 0.7808 - accuracy: 0.7289 - val_loss: 1.2817 - val_accuracy: 0.5000\n",
      "Epoch 6/30\n",
      "167/167 [==============================] - 33s 195ms/step - loss: 0.6968 - accuracy: 0.7486 - val_loss: 1.0124 - val_accuracy: 0.5625\n",
      "Epoch 7/30\n",
      "167/167 [==============================] - 33s 195ms/step - loss: 0.6770 - accuracy: 0.7701 - val_loss: 1.1305 - val_accuracy: 0.5000\n",
      "Epoch 8/30\n",
      "167/167 [==============================] - 33s 195ms/step - loss: 0.6352 - accuracy: 0.7975 - val_loss: 1.2332 - val_accuracy: 0.5000\n",
      "Epoch 9/30\n",
      "167/167 [==============================] - 33s 195ms/step - loss: 0.5995 - accuracy: 0.8025 - val_loss: 1.3187 - val_accuracy: 0.5312\n",
      "Epoch 10/30\n",
      "167/167 [==============================] - 33s 195ms/step - loss: 0.5509 - accuracy: 0.8211 - val_loss: 0.6948 - val_accuracy: 0.7500\n",
      "Epoch 11/30\n",
      "167/167 [==============================] - 32s 194ms/step - loss: 0.5161 - accuracy: 0.8237 - val_loss: 1.3281 - val_accuracy: 0.4062\n",
      "Epoch 12/30\n",
      "167/167 [==============================] - 32s 194ms/step - loss: 0.4778 - accuracy: 0.8337 - val_loss: 1.0276 - val_accuracy: 0.5625\n",
      "Epoch 13/30\n",
      "167/167 [==============================] - 32s 194ms/step - loss: 0.4181 - accuracy: 0.8519 - val_loss: 0.5895 - val_accuracy: 0.7812\n",
      "Epoch 14/30\n",
      "167/167 [==============================] - 32s 194ms/step - loss: 0.3877 - accuracy: 0.8820 - val_loss: 0.7016 - val_accuracy: 0.8125\n",
      "Epoch 15/30\n",
      "167/167 [==============================] - 32s 194ms/step - loss: 0.3754 - accuracy: 0.9048 - val_loss: 0.7138 - val_accuracy: 0.7812\n",
      "Epoch 16/30\n",
      "167/167 [==============================] - 32s 194ms/step - loss: 0.3347 - accuracy: 0.9215 - val_loss: 0.8927 - val_accuracy: 0.8125\n",
      "Epoch 17/30\n",
      "167/167 [==============================] - 32s 194ms/step - loss: 0.3238 - accuracy: 0.9232 - val_loss: 1.0371 - val_accuracy: 0.6250\n",
      "Epoch 18/30\n",
      "167/167 [==============================] - 32s 194ms/step - loss: 0.3087 - accuracy: 0.9279 - val_loss: 0.3220 - val_accuracy: 0.9688\n",
      "Epoch 19/30\n",
      "167/167 [==============================] - 32s 194ms/step - loss: 0.2636 - accuracy: 0.9378 - val_loss: 0.4668 - val_accuracy: 0.9375\n",
      "Epoch 20/30\n",
      "167/167 [==============================] - 32s 194ms/step - loss: 0.2399 - accuracy: 0.9481 - val_loss: 0.3690 - val_accuracy: 0.9375\n",
      "Epoch 21/30\n",
      "167/167 [==============================] - 32s 194ms/step - loss: 0.2220 - accuracy: 0.9545 - val_loss: 1.3078 - val_accuracy: 0.6250\n",
      "Epoch 22/30\n",
      "167/167 [==============================] - 32s 194ms/step - loss: 0.1829 - accuracy: 0.9656 - val_loss: 0.4099 - val_accuracy: 0.8438\n",
      "Epoch 23/30\n",
      "167/167 [==============================] - 32s 194ms/step - loss: 0.1820 - accuracy: 0.9651 - val_loss: 0.3684 - val_accuracy: 0.9375\n",
      "Epoch 24/30\n",
      "167/167 [==============================] - 32s 194ms/step - loss: 0.1572 - accuracy: 0.9722 - val_loss: 0.4101 - val_accuracy: 0.9375\n",
      "Epoch 25/30\n",
      "167/167 [==============================] - 32s 194ms/step - loss: 0.1337 - accuracy: 0.9792 - val_loss: 0.2598 - val_accuracy: 0.9688\n",
      "Epoch 26/30\n",
      "167/167 [==============================] - 32s 194ms/step - loss: 0.1272 - accuracy: 0.9821 - val_loss: 0.1100 - val_accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "167/167 [==============================] - 32s 194ms/step - loss: 0.1137 - accuracy: 0.9849 - val_loss: 0.2696 - val_accuracy: 0.9688\n",
      "Epoch 28/30\n",
      "167/167 [==============================] - 32s 194ms/step - loss: 0.1029 - accuracy: 0.9884 - val_loss: 0.2671 - val_accuracy: 0.9688\n",
      "Epoch 29/30\n",
      "167/167 [==============================] - 32s 194ms/step - loss: 0.1007 - accuracy: 0.9890 - val_loss: 0.2198 - val_accuracy: 0.9688\n",
      "Epoch 30/30\n",
      "167/167 [==============================] - 32s 194ms/step - loss: 0.0984 - accuracy: 0.9883 - val_loss: 0.2551 - val_accuracy: 0.9688\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_8348_images_True_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.974174\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.25061752 0.25077275 0.247092   0.24860724]\n",
      "Training resnet for 0.25% of train size (aka 20871 images) with pretrained: False and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 178 trainable: 178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/418 [..............................] - ETA: 2:43 - loss: 1.3761 - accuracy: 0.3986WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0946s vs `on_train_batch_end` time: 0.2628s). Check your callbacks.\n",
      "418/418 [==============================] - 89s 199ms/step - loss: 1.2505 - accuracy: 0.4414 - val_loss: 1.5687 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "418/418 [==============================] - 81s 194ms/step - loss: 1.0103 - accuracy: 0.6429 - val_loss: 2.0962 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "418/418 [==============================] - 81s 194ms/step - loss: 0.7393 - accuracy: 0.7301 - val_loss: 1.7554 - val_accuracy: 0.2812\n",
      "Epoch 4/30\n",
      "418/418 [==============================] - 81s 194ms/step - loss: 0.6703 - accuracy: 0.7541 - val_loss: 1.4736 - val_accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "418/418 [==============================] - 81s 193ms/step - loss: 0.6058 - accuracy: 0.7954 - val_loss: 1.6131 - val_accuracy: 0.1875\n",
      "Epoch 6/30\n",
      "418/418 [==============================] - 81s 193ms/step - loss: 0.5314 - accuracy: 0.8124 - val_loss: 2.3535 - val_accuracy: 0.2812\n",
      "Epoch 7/30\n",
      "418/418 [==============================] - 81s 193ms/step - loss: 0.4413 - accuracy: 0.8693 - val_loss: 1.3961 - val_accuracy: 0.5000\n",
      "Epoch 8/30\n",
      "418/418 [==============================] - 81s 193ms/step - loss: 0.4366 - accuracy: 0.8711 - val_loss: 1.2454 - val_accuracy: 0.6250\n",
      "Epoch 9/30\n",
      "418/418 [==============================] - 81s 193ms/step - loss: 0.3752 - accuracy: 0.8943 - val_loss: 1.0428 - val_accuracy: 0.6250\n",
      "Epoch 10/30\n",
      "418/418 [==============================] - 81s 193ms/step - loss: 0.3830 - accuracy: 0.8918 - val_loss: 0.2515 - val_accuracy: 1.0000\n",
      "Epoch 11/30\n",
      "418/418 [==============================] - 81s 193ms/step - loss: 0.3023 - accuracy: 0.9218 - val_loss: 0.2532 - val_accuracy: 0.9375\n",
      "Epoch 12/30\n",
      "418/418 [==============================] - 81s 193ms/step - loss: 0.2725 - accuracy: 0.9283 - val_loss: 0.3237 - val_accuracy: 0.9062\n",
      "Epoch 13/30\n",
      "418/418 [==============================] - 81s 193ms/step - loss: 0.2376 - accuracy: 0.9394 - val_loss: 0.1465 - val_accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "418/418 [==============================] - 81s 193ms/step - loss: 0.2251 - accuracy: 0.9445 - val_loss: 0.2357 - val_accuracy: 0.9688\n",
      "Epoch 15/30\n",
      "418/418 [==============================] - 81s 193ms/step - loss: 0.1880 - accuracy: 0.9546 - val_loss: 0.1776 - val_accuracy: 0.9688\n",
      "Epoch 16/30\n",
      "418/418 [==============================] - 81s 193ms/step - loss: 0.1757 - accuracy: 0.9588 - val_loss: 0.1042 - val_accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "418/418 [==============================] - 81s 193ms/step - loss: 0.1500 - accuracy: 0.9681 - val_loss: 0.1345 - val_accuracy: 0.9688\n",
      "Epoch 18/30\n",
      "418/418 [==============================] - 81s 193ms/step - loss: 0.1312 - accuracy: 0.9728 - val_loss: 0.0814 - val_accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "418/418 [==============================] - 81s 193ms/step - loss: 0.1218 - accuracy: 0.9756 - val_loss: 0.0764 - val_accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "418/418 [==============================] - 81s 193ms/step - loss: 0.1029 - accuracy: 0.9822 - val_loss: 0.0722 - val_accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "418/418 [==============================] - 81s 193ms/step - loss: 0.0970 - accuracy: 0.9836 - val_loss: 0.0760 - val_accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "418/418 [==============================] - 81s 193ms/step - loss: 0.0912 - accuracy: 0.9842 - val_loss: 0.0663 - val_accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "418/418 [==============================] - 81s 193ms/step - loss: 0.0823 - accuracy: 0.9871 - val_loss: 0.0634 - val_accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "418/418 [==============================] - 81s 193ms/step - loss: 0.0768 - accuracy: 0.9892 - val_loss: 0.0620 - val_accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "418/418 [==============================] - 81s 193ms/step - loss: 0.0702 - accuracy: 0.9913 - val_loss: 0.0590 - val_accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "418/418 [==============================] - 81s 193ms/step - loss: 0.0687 - accuracy: 0.9916 - val_loss: 0.0574 - val_accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "418/418 [==============================] - 81s 193ms/step - loss: 0.0660 - accuracy: 0.9922 - val_loss: 0.0570 - val_accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "418/418 [==============================] - 81s 193ms/step - loss: 0.0599 - accuracy: 0.9931 - val_loss: 0.0546 - val_accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "418/418 [==============================] - 81s 193ms/step - loss: 0.0617 - accuracy: 0.9929 - val_loss: 0.0537 - val_accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "418/418 [==============================] - 81s 193ms/step - loss: 0.0606 - accuracy: 0.9930 - val_loss: 0.0528 - val_accuracy: 1.0000\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_20871_images_True_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.981405\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.39931598 0.39956995 0.40236165 0.40076602]\n",
      "Training resnet for 0.4% of train size (aka 33393 images) with pretrained: False and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 178 trainable: 178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/668 [..............................] - ETA: 4:25 - loss: 1.3718 - accuracy: 0.4257WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0933s vs `on_train_batch_end` time: 0.2671s). Check your callbacks.\n",
      "668/668 [==============================] - 139s 199ms/step - loss: 1.2472 - accuracy: 0.4430 - val_loss: 1.7265 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "668/668 [==============================] - 130s 195ms/step - loss: 0.9601 - accuracy: 0.6471 - val_loss: 1.2477 - val_accuracy: 0.5625\n",
      "Epoch 3/30\n",
      "668/668 [==============================] - 130s 194ms/step - loss: 0.6756 - accuracy: 0.7773 - val_loss: 1.8121 - val_accuracy: 0.3438\n",
      "Epoch 4/30\n",
      "668/668 [==============================] - 130s 194ms/step - loss: 0.5716 - accuracy: 0.8089 - val_loss: 0.7854 - val_accuracy: 0.7188\n",
      "Epoch 5/30\n",
      "668/668 [==============================] - 129s 194ms/step - loss: 0.4727 - accuracy: 0.8571 - val_loss: 0.4076 - val_accuracy: 0.9062\n",
      "Epoch 6/30\n",
      "668/668 [==============================] - 129s 194ms/step - loss: 0.3881 - accuracy: 0.8827 - val_loss: 0.6362 - val_accuracy: 0.8125\n",
      "Epoch 7/30\n",
      "668/668 [==============================] - 129s 194ms/step - loss: 0.3632 - accuracy: 0.8940 - val_loss: 0.3996 - val_accuracy: 0.9062\n",
      "Epoch 8/30\n",
      "668/668 [==============================] - 129s 194ms/step - loss: 0.3789 - accuracy: 0.8929 - val_loss: 0.1865 - val_accuracy: 1.0000\n",
      "Epoch 9/30\n",
      "668/668 [==============================] - 129s 194ms/step - loss: 0.2955 - accuracy: 0.9217 - val_loss: 0.1420 - val_accuracy: 1.0000\n",
      "Epoch 10/30\n",
      "668/668 [==============================] - 129s 194ms/step - loss: 0.2447 - accuracy: 0.9360 - val_loss: 0.1052 - val_accuracy: 1.0000\n",
      "Epoch 11/30\n",
      "668/668 [==============================] - 129s 194ms/step - loss: 0.2022 - accuracy: 0.9470 - val_loss: 0.1099 - val_accuracy: 1.0000\n",
      "Epoch 12/30\n",
      "668/668 [==============================] - 129s 194ms/step - loss: 0.1760 - accuracy: 0.9575 - val_loss: 0.0811 - val_accuracy: 1.0000\n",
      "Epoch 13/30\n",
      "668/668 [==============================] - 129s 193ms/step - loss: 0.1577 - accuracy: 0.9605 - val_loss: 0.0679 - val_accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "668/668 [==============================] - 129s 194ms/step - loss: 0.1313 - accuracy: 0.9696 - val_loss: 0.0572 - val_accuracy: 1.0000\n",
      "Epoch 15/30\n",
      "668/668 [==============================] - 129s 194ms/step - loss: 0.1168 - accuracy: 0.9730 - val_loss: 0.0924 - val_accuracy: 0.9688\n",
      "Epoch 16/30\n",
      "668/668 [==============================] - 129s 194ms/step - loss: 0.1052 - accuracy: 0.9768 - val_loss: 0.0545 - val_accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "668/668 [==============================] - 129s 194ms/step - loss: 0.0852 - accuracy: 0.9828 - val_loss: 0.1473 - val_accuracy: 0.9375\n",
      "Epoch 18/30\n",
      "668/668 [==============================] - 129s 194ms/step - loss: 0.0797 - accuracy: 0.9839 - val_loss: 0.0404 - val_accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "668/668 [==============================] - 129s 194ms/step - loss: 0.0719 - accuracy: 0.9873 - val_loss: 0.0380 - val_accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "668/668 [==============================] - 130s 194ms/step - loss: 0.0665 - accuracy: 0.9881 - val_loss: 0.0398 - val_accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "668/668 [==============================] - 129s 194ms/step - loss: 0.0565 - accuracy: 0.9915 - val_loss: 0.0350 - val_accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "668/668 [==============================] - 129s 194ms/step - loss: 0.0495 - accuracy: 0.9925 - val_loss: 0.0347 - val_accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "668/668 [==============================] - 130s 194ms/step - loss: 0.0479 - accuracy: 0.9932 - val_loss: 0.0320 - val_accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "668/668 [==============================] - 129s 194ms/step - loss: 0.0457 - accuracy: 0.9941 - val_loss: 0.0308 - val_accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "668/668 [==============================] - 129s 194ms/step - loss: 0.0430 - accuracy: 0.9947 - val_loss: 0.0300 - val_accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "668/668 [==============================] - 129s 194ms/step - loss: 0.0398 - accuracy: 0.9953 - val_loss: 0.0294 - val_accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "668/668 [==============================] - 129s 194ms/step - loss: 0.0401 - accuracy: 0.9950 - val_loss: 0.0293 - val_accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "668/668 [==============================] - 129s 194ms/step - loss: 0.0414 - accuracy: 0.9948 - val_loss: 0.0283 - val_accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "668/668 [==============================] - 129s 194ms/step - loss: 0.0386 - accuracy: 0.9952 - val_loss: 0.0279 - val_accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "668/668 [==============================] - 129s 194ms/step - loss: 0.0362 - accuracy: 0.9959 - val_loss: 0.0275 - val_accuracy: 1.0000\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_33394_images_True_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.990702\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.50279308 0.49955651 0.50035249 0.49292015]\n",
      "Training resnet for 0.5% of train size (aka 41742 images) with pretrained: False and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 178 trainable: 178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/835 [..............................] - ETA: 5:44 - loss: 1.3738 - accuracy: 0.4184WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0931s vs `on_train_batch_end` time: 0.2784s). Check your callbacks.\n",
      "835/835 [==============================] - 172s 198ms/step - loss: 1.1109 - accuracy: 0.5350 - val_loss: 1.2539 - val_accuracy: 0.5625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "835/835 [==============================] - 163s 195ms/step - loss: 0.6866 - accuracy: 0.7665 - val_loss: 1.2422 - val_accuracy: 0.5000\n",
      "Epoch 3/30\n",
      "835/835 [==============================] - 162s 194ms/step - loss: 0.5454 - accuracy: 0.8188 - val_loss: 0.7425 - val_accuracy: 0.8125\n",
      "Epoch 4/30\n",
      "835/835 [==============================] - 162s 194ms/step - loss: 0.4426 - accuracy: 0.8633 - val_loss: 0.4853 - val_accuracy: 0.9062\n",
      "Epoch 5/30\n",
      "835/835 [==============================] - 162s 194ms/step - loss: 0.3863 - accuracy: 0.8840 - val_loss: 1.4323 - val_accuracy: 0.5938\n",
      "Epoch 6/30\n",
      "835/835 [==============================] - 162s 194ms/step - loss: 0.3055 - accuracy: 0.9126 - val_loss: 0.1339 - val_accuracy: 1.0000\n",
      "Epoch 7/30\n",
      "835/835 [==============================] - 162s 193ms/step - loss: 0.2511 - accuracy: 0.9296 - val_loss: 0.1375 - val_accuracy: 1.0000\n",
      "Epoch 8/30\n",
      "835/835 [==============================] - 162s 194ms/step - loss: 0.2008 - accuracy: 0.9452 - val_loss: 0.2412 - val_accuracy: 0.9062\n",
      "Epoch 9/30\n",
      "835/835 [==============================] - 162s 194ms/step - loss: 0.1717 - accuracy: 0.9542 - val_loss: 0.1178 - val_accuracy: 0.9688\n",
      "Epoch 10/30\n",
      "835/835 [==============================] - 162s 194ms/step - loss: 0.1491 - accuracy: 0.9595 - val_loss: 0.0663 - val_accuracy: 1.0000\n",
      "Epoch 11/30\n",
      "835/835 [==============================] - 162s 194ms/step - loss: 0.1287 - accuracy: 0.9658 - val_loss: 0.0511 - val_accuracy: 1.0000\n",
      "Epoch 12/30\n",
      "835/835 [==============================] - 162s 194ms/step - loss: 0.1153 - accuracy: 0.9706 - val_loss: 0.1698 - val_accuracy: 0.9375\n",
      "Epoch 13/30\n",
      "835/835 [==============================] - 162s 194ms/step - loss: 0.1198 - accuracy: 0.9691 - val_loss: 0.0543 - val_accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "835/835 [==============================] - 162s 194ms/step - loss: 0.0928 - accuracy: 0.9775 - val_loss: 0.0383 - val_accuracy: 1.0000\n",
      "Epoch 15/30\n",
      "835/835 [==============================] - 162s 194ms/step - loss: 0.0845 - accuracy: 0.9795 - val_loss: 0.0339 - val_accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "835/835 [==============================] - 162s 194ms/step - loss: 0.0662 - accuracy: 0.9865 - val_loss: 0.0295 - val_accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "835/835 [==============================] - 162s 194ms/step - loss: 0.0549 - accuracy: 0.9897 - val_loss: 0.0327 - val_accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "835/835 [==============================] - 162s 194ms/step - loss: 0.0524 - accuracy: 0.9902 - val_loss: 0.0273 - val_accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "835/835 [==============================] - 162s 194ms/step - loss: 0.0455 - accuracy: 0.9925 - val_loss: 0.0241 - val_accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "835/835 [==============================] - 162s 194ms/step - loss: 0.0401 - accuracy: 0.9933 - val_loss: 0.0231 - val_accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "835/835 [==============================] - 162s 194ms/step - loss: 0.0423 - accuracy: 0.9930 - val_loss: 0.0223 - val_accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "835/835 [==============================] - 162s 194ms/step - loss: 0.0367 - accuracy: 0.9945 - val_loss: 0.0215 - val_accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "835/835 [==============================] - 162s 194ms/step - loss: 0.0333 - accuracy: 0.9953 - val_loss: 0.0210 - val_accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "835/835 [==============================] - 162s 194ms/step - loss: 0.0337 - accuracy: 0.9952 - val_loss: 0.0205 - val_accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "835/835 [==============================] - 162s 194ms/step - loss: 0.0308 - accuracy: 0.9956 - val_loss: 0.0199 - val_accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "835/835 [==============================] - 162s 194ms/step - loss: 0.0294 - accuracy: 0.9960 - val_loss: 0.0199 - val_accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "835/835 [==============================] - 162s 194ms/step - loss: 0.0277 - accuracy: 0.9962 - val_loss: 0.0193 - val_accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "835/835 [==============================] - 162s 194ms/step - loss: 0.0291 - accuracy: 0.9960 - val_loss: 0.0190 - val_accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "835/835 [==============================] - 162s 194ms/step - loss: 0.0271 - accuracy: 0.9962 - val_loss: 0.0188 - val_accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "835/835 [==============================] - 162s 194ms/step - loss: 0.0266 - accuracy: 0.9963 - val_loss: 0.0186 - val_accuracy: 1.0000\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_41742_images_True_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.993802\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.60167205 0.60102137 0.59878393 0.59203807]\n",
      "Training resnet for 0.6% of train size (aka 50090 images) with pretrained: False and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 178 trainable: 178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "   6/1002 [..............................] - ETA: 6:42 - loss: 1.3716 - accuracy: 0.3407WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0971s vs `on_train_batch_end` time: 0.2662s). Check your callbacks.\n",
      "1002/1002 [==============================] - 204s 198ms/step - loss: 0.9876 - accuracy: 0.6119 - val_loss: 0.9758 - val_accuracy: 0.5625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "1002/1002 [==============================] - 194s 194ms/step - loss: 0.6294 - accuracy: 0.7909 - val_loss: 0.8309 - val_accuracy: 0.7500\n",
      "Epoch 3/30\n",
      "1002/1002 [==============================] - 194s 193ms/step - loss: 0.4983 - accuracy: 0.8449 - val_loss: 1.1792 - val_accuracy: 0.6250\n",
      "Epoch 4/30\n",
      "1002/1002 [==============================] - 194s 194ms/step - loss: 0.4157 - accuracy: 0.8733 - val_loss: 0.4661 - val_accuracy: 0.8438\n",
      "Epoch 5/30\n",
      "1002/1002 [==============================] - 194s 193ms/step - loss: 0.3302 - accuracy: 0.9056 - val_loss: 0.1952 - val_accuracy: 1.0000\n",
      "Epoch 6/30\n",
      "1002/1002 [==============================] - 194s 193ms/step - loss: 0.2695 - accuracy: 0.9244 - val_loss: 0.1119 - val_accuracy: 1.0000\n",
      "Epoch 7/30\n",
      "1002/1002 [==============================] - 194s 194ms/step - loss: 0.2232 - accuracy: 0.9386 - val_loss: 0.0824 - val_accuracy: 1.0000\n",
      "Epoch 8/30\n",
      "1002/1002 [==============================] - 194s 194ms/step - loss: 0.1947 - accuracy: 0.9448 - val_loss: 0.0858 - val_accuracy: 1.0000\n",
      "Epoch 9/30\n",
      "1002/1002 [==============================] - 194s 194ms/step - loss: 0.1701 - accuracy: 0.9532 - val_loss: 0.1043 - val_accuracy: 0.9688\n",
      "Epoch 10/30\n",
      "1002/1002 [==============================] - 194s 194ms/step - loss: 0.1462 - accuracy: 0.9606 - val_loss: 0.0523 - val_accuracy: 1.0000\n",
      "Epoch 11/30\n",
      "1002/1002 [==============================] - 194s 194ms/step - loss: 0.1272 - accuracy: 0.9664 - val_loss: 0.0492 - val_accuracy: 1.0000\n",
      "Epoch 12/30\n",
      "1002/1002 [==============================] - 194s 194ms/step - loss: 0.1112 - accuracy: 0.9704 - val_loss: 0.0390 - val_accuracy: 1.0000\n",
      "Epoch 13/30\n",
      "1002/1002 [==============================] - 194s 194ms/step - loss: 0.0975 - accuracy: 0.9748 - val_loss: 0.0404 - val_accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "1002/1002 [==============================] - 194s 194ms/step - loss: 0.0805 - accuracy: 0.9794 - val_loss: 0.0282 - val_accuracy: 1.0000\n",
      "Epoch 15/30\n",
      "1002/1002 [==============================] - 194s 194ms/step - loss: 0.0726 - accuracy: 0.9830 - val_loss: 0.0358 - val_accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "1002/1002 [==============================] - 194s 194ms/step - loss: 0.0655 - accuracy: 0.9849 - val_loss: 0.0722 - val_accuracy: 0.9688\n",
      "Epoch 17/30\n",
      "1002/1002 [==============================] - 194s 194ms/step - loss: 0.0533 - accuracy: 0.9890 - val_loss: 0.0238 - val_accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "1002/1002 [==============================] - 194s 194ms/step - loss: 0.0531 - accuracy: 0.9885 - val_loss: 0.0230 - val_accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "1002/1002 [==============================] - 194s 194ms/step - loss: 0.0464 - accuracy: 0.9907 - val_loss: 0.0215 - val_accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "1002/1002 [==============================] - 194s 194ms/step - loss: 0.0412 - accuracy: 0.9926 - val_loss: 0.0192 - val_accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "1002/1002 [==============================] - 194s 194ms/step - loss: 0.0336 - accuracy: 0.9945 - val_loss: 0.0184 - val_accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "1002/1002 [==============================] - 194s 194ms/step - loss: 0.0319 - accuracy: 0.9952 - val_loss: 0.0184 - val_accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "1002/1002 [==============================] - 194s 194ms/step - loss: 0.0301 - accuracy: 0.9955 - val_loss: 0.0174 - val_accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "1002/1002 [==============================] - 194s 194ms/step - loss: 0.0285 - accuracy: 0.9958 - val_loss: 0.0179 - val_accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "1002/1002 [==============================] - 194s 194ms/step - loss: 0.0293 - accuracy: 0.9955 - val_loss: 0.0168 - val_accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "1002/1002 [==============================] - 194s 194ms/step - loss: 0.0257 - accuracy: 0.9966 - val_loss: 0.0166 - val_accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "1002/1002 [==============================] - 194s 194ms/step - loss: 0.0249 - accuracy: 0.9965 - val_loss: 0.0167 - val_accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "1002/1002 [==============================] - 194s 194ms/step - loss: 0.0230 - accuracy: 0.9966 - val_loss: 0.0160 - val_accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "1002/1002 [==============================] - 194s 194ms/step - loss: 0.0237 - accuracy: 0.9967 - val_loss: 0.0166 - val_accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "1002/1002 [==============================] - 194s 194ms/step - loss: 0.0239 - accuracy: 0.9966 - val_loss: 0.0160 - val_accuracy: 1.0000\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_50090_images_True_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.990702\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.75265058 0.74871657 0.74929503 0.74837512]\n",
      "Training resnet for 0.75% of train size (aka 62613 images) with pretrained: False and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 178 trainable: 178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "   6/1253 [..............................] - ETA: 8:12 - loss: 1.3778 - accuracy: 0.2576WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0941s vs `on_train_batch_end` time: 0.2623s). Check your callbacks.\n",
      "1253/1253 [==============================] - 251s 196ms/step - loss: 1.1077 - accuracy: 0.5296 - val_loss: 1.2903 - val_accuracy: 0.4688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "1253/1253 [==============================] - 244s 195ms/step - loss: 0.6184 - accuracy: 0.7893 - val_loss: 1.1807 - val_accuracy: 0.4688\n",
      "Epoch 3/30\n",
      "1253/1253 [==============================] - 242s 193ms/step - loss: 0.4407 - accuracy: 0.8543 - val_loss: 0.4542 - val_accuracy: 0.9375\n",
      "Epoch 4/30\n",
      "1253/1253 [==============================] - 242s 193ms/step - loss: 0.3249 - accuracy: 0.9050 - val_loss: 0.2949 - val_accuracy: 0.7500\n",
      "Epoch 5/30\n",
      "1253/1253 [==============================] - 242s 193ms/step - loss: 0.2598 - accuracy: 0.9296 - val_loss: 0.4005 - val_accuracy: 0.8125\n",
      "Epoch 6/30\n",
      "1253/1253 [==============================] - 242s 193ms/step - loss: 0.2221 - accuracy: 0.9421 - val_loss: 0.1243 - val_accuracy: 1.0000\n",
      "Epoch 7/30\n",
      "1253/1253 [==============================] - 243s 194ms/step - loss: 0.2030 - accuracy: 0.9462 - val_loss: 0.1133 - val_accuracy: 1.0000\n",
      "Epoch 8/30\n",
      "1253/1253 [==============================] - 243s 194ms/step - loss: 0.1619 - accuracy: 0.9583 - val_loss: 0.1887 - val_accuracy: 0.9062\n",
      "Epoch 9/30\n",
      "1253/1253 [==============================] - 243s 194ms/step - loss: 0.1382 - accuracy: 0.9655 - val_loss: 0.4811 - val_accuracy: 0.7812\n",
      "Epoch 10/30\n",
      "1253/1253 [==============================] - 242s 193ms/step - loss: 0.1229 - accuracy: 0.9699 - val_loss: 0.0653 - val_accuracy: 1.0000\n",
      "Epoch 11/30\n",
      "1253/1253 [==============================] - 243s 194ms/step - loss: 0.1007 - accuracy: 0.9755 - val_loss: 0.0535 - val_accuracy: 1.0000\n",
      "Epoch 12/30\n",
      "1253/1253 [==============================] - 243s 194ms/step - loss: 0.0894 - accuracy: 0.9799 - val_loss: 0.0972 - val_accuracy: 0.9688\n",
      "Epoch 13/30\n",
      "1253/1253 [==============================] - 242s 194ms/step - loss: 0.0827 - accuracy: 0.9814 - val_loss: 0.0452 - val_accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "1253/1253 [==============================] - 243s 194ms/step - loss: 0.0685 - accuracy: 0.9867 - val_loss: 0.0587 - val_accuracy: 1.0000\n",
      "Epoch 15/30\n",
      "1253/1253 [==============================] - 243s 194ms/step - loss: 0.0908 - accuracy: 0.9792 - val_loss: 0.1036 - val_accuracy: 0.9688\n",
      "Epoch 16/30\n",
      "1253/1253 [==============================] - 243s 194ms/step - loss: 0.0569 - accuracy: 0.9893 - val_loss: 0.0614 - val_accuracy: 0.9688\n",
      "Epoch 17/30\n",
      "1253/1253 [==============================] - 243s 194ms/step - loss: 0.0470 - accuracy: 0.9923 - val_loss: 0.1318 - val_accuracy: 0.9688\n",
      "Epoch 18/30\n",
      "1253/1253 [==============================] - 242s 193ms/step - loss: 0.0449 - accuracy: 0.9932 - val_loss: 0.0348 - val_accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "1253/1253 [==============================] - 242s 193ms/step - loss: 0.0395 - accuracy: 0.9946 - val_loss: 0.0357 - val_accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "1253/1253 [==============================] - 242s 193ms/step - loss: 0.0388 - accuracy: 0.9948 - val_loss: 0.0381 - val_accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "1253/1253 [==============================] - 243s 194ms/step - loss: 0.0356 - accuracy: 0.9953 - val_loss: 0.0313 - val_accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "1253/1253 [==============================] - 243s 194ms/step - loss: 0.0319 - accuracy: 0.9959 - val_loss: 0.0354 - val_accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "1253/1253 [==============================] - 243s 194ms/step - loss: 0.0305 - accuracy: 0.9961 - val_loss: 0.0446 - val_accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "1253/1253 [==============================] - 242s 193ms/step - loss: 0.0313 - accuracy: 0.9960 - val_loss: 0.0462 - val_accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "1253/1253 [==============================] - 242s 194ms/step - loss: 0.0320 - accuracy: 0.9960 - val_loss: 0.0342 - val_accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "1253/1253 [==============================] - 243s 194ms/step - loss: 0.0303 - accuracy: 0.9961 - val_loss: 0.0335 - val_accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "1253/1253 [==============================] - 243s 194ms/step - loss: 0.0270 - accuracy: 0.9964 - val_loss: 0.0379 - val_accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "1253/1253 [==============================] - 243s 194ms/step - loss: 0.0282 - accuracy: 0.9962 - val_loss: 0.0335 - val_accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "1253/1253 [==============================] - 243s 194ms/step - loss: 0.0272 - accuracy: 0.9964 - val_loss: 0.0376 - val_accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "1253/1253 [==============================] - 243s 194ms/step - loss: 0.0271 - accuracy: 0.9966 - val_loss: 0.0416 - val_accuracy: 1.0000\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_62613_images_True_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.997934\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [0.89895497 0.90022846 0.90306662 0.89809656]\n",
      "Training resnet for 0.9% of train size (aka 75135 images) with pretrained: False and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 178 trainable: 178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "   6/1503 [..............................] - ETA: 10:32 - loss: 1.3732 - accuracy: 0.4018WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0949s vs `on_train_batch_end` time: 0.2823s). Check your callbacks.\n",
      "1503/1503 [==============================] - 303s 197ms/step - loss: 1.2374 - accuracy: 0.4435 - val_loss: 1.5785 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "1503/1503 [==============================] - 292s 194ms/step - loss: 1.2319 - accuracy: 0.4450 - val_loss: 1.5625 - val_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "1503/1503 [==============================] - 292s 194ms/step - loss: 1.2314 - accuracy: 0.4460 - val_loss: 2.0114 - val_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "1503/1503 [==============================] - 292s 194ms/step - loss: 0.7584 - accuracy: 0.7380 - val_loss: 0.8440 - val_accuracy: 0.6250\n",
      "Epoch 5/30\n",
      "1503/1503 [==============================] - 291s 194ms/step - loss: 0.4879 - accuracy: 0.8496 - val_loss: 0.4907 - val_accuracy: 0.9062\n",
      "Epoch 6/30\n",
      "1503/1503 [==============================] - 291s 194ms/step - loss: 0.3242 - accuracy: 0.9068 - val_loss: 0.1330 - val_accuracy: 1.0000\n",
      "Epoch 7/30\n",
      "1503/1503 [==============================] - 291s 194ms/step - loss: 0.2287 - accuracy: 0.9369 - val_loss: 0.0816 - val_accuracy: 1.0000\n",
      "Epoch 8/30\n",
      "1503/1503 [==============================] - 291s 194ms/step - loss: 0.1862 - accuracy: 0.9469 - val_loss: 0.0617 - val_accuracy: 1.0000\n",
      "Epoch 9/30\n",
      "1503/1503 [==============================] - 292s 194ms/step - loss: 0.1518 - accuracy: 0.9567 - val_loss: 0.7975 - val_accuracy: 0.7188\n",
      "Epoch 10/30\n",
      "1503/1503 [==============================] - 292s 194ms/step - loss: 0.1674 - accuracy: 0.9511 - val_loss: 0.0404 - val_accuracy: 1.0000\n",
      "Epoch 11/30\n",
      "1503/1503 [==============================] - 292s 194ms/step - loss: 0.1246 - accuracy: 0.9650 - val_loss: 0.4372 - val_accuracy: 0.7812\n",
      "Epoch 12/30\n",
      "1503/1503 [==============================] - 292s 194ms/step - loss: 0.1065 - accuracy: 0.9703 - val_loss: 0.0639 - val_accuracy: 0.9688\n",
      "Epoch 13/30\n",
      "1503/1503 [==============================] - 292s 194ms/step - loss: 0.0902 - accuracy: 0.9754 - val_loss: 0.0274 - val_accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "1503/1503 [==============================] - 291s 194ms/step - loss: 0.0703 - accuracy: 0.9820 - val_loss: 0.0217 - val_accuracy: 1.0000\n",
      "Epoch 15/30\n",
      "1503/1503 [==============================] - 292s 194ms/step - loss: 0.0612 - accuracy: 0.9843 - val_loss: 0.0348 - val_accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "1503/1503 [==============================] - 292s 194ms/step - loss: 0.0501 - accuracy: 0.9881 - val_loss: 0.0217 - val_accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "1503/1503 [==============================] - 292s 194ms/step - loss: 0.0446 - accuracy: 0.9898 - val_loss: 0.0257 - val_accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "1503/1503 [==============================] - 292s 194ms/step - loss: 0.0397 - accuracy: 0.9914 - val_loss: 0.0457 - val_accuracy: 0.9688\n",
      "Epoch 19/30\n",
      "1503/1503 [==============================] - 292s 194ms/step - loss: 0.0336 - accuracy: 0.9932 - val_loss: 0.0203 - val_accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "1503/1503 [==============================] - 292s 194ms/step - loss: 0.0312 - accuracy: 0.9936 - val_loss: 0.0221 - val_accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "1503/1503 [==============================] - 292s 194ms/step - loss: 0.0291 - accuracy: 0.9939 - val_loss: 0.0254 - val_accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "1503/1503 [==============================] - 292s 194ms/step - loss: 0.0259 - accuracy: 0.9950 - val_loss: 0.0165 - val_accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "1503/1503 [==============================] - 291s 194ms/step - loss: 0.0244 - accuracy: 0.9950 - val_loss: 0.0219 - val_accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "1503/1503 [==============================] - 292s 194ms/step - loss: 0.0229 - accuracy: 0.9952 - val_loss: 0.0360 - val_accuracy: 0.9688\n",
      "Epoch 25/30\n",
      "1503/1503 [==============================] - 292s 194ms/step - loss: 0.0202 - accuracy: 0.9958 - val_loss: 0.0230 - val_accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "1503/1503 [==============================] - 292s 194ms/step - loss: 0.0180 - accuracy: 0.9963 - val_loss: 0.0345 - val_accuracy: 0.9688\n",
      "Epoch 27/30\n",
      "1503/1503 [==============================] - 292s 194ms/step - loss: 0.0186 - accuracy: 0.9961 - val_loss: 0.0220 - val_accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "1503/1503 [==============================] - 292s 194ms/step - loss: 0.0181 - accuracy: 0.9963 - val_loss: 0.0206 - val_accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "1503/1503 [==============================] - 292s 194ms/step - loss: 0.0168 - accuracy: 0.9964 - val_loss: 0.0217 - val_accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "1503/1503 [==============================] - 292s 194ms/step - loss: 0.0166 - accuracy: 0.9966 - val_loss: 0.0288 - val_accuracy: 1.0000\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_75136_images_True_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.997934\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels fraction: [1. 1. 1. 1.]\n",
      "Training resnet for 1.0% of train size (aka 83484 images) with pretrained: False and onlyLastLayersTrained: False...\n",
      "\n",
      "Total: 178 trainable: 178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:20: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "   6/1670 [..............................] - ETA: 10:57 - loss: 1.3766 - accuracy: 0.2864WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0937s vs `on_train_batch_end` time: 0.2634s). Check your callbacks.\n",
      "1670/1670 [==============================] - 332s 195ms/step - loss: 1.1567 - accuracy: 0.4960 - val_loss: 2.2059 - val_accuracy: 0.3438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a21c27d31b2a>:48: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "1670/1670 [==============================] - 323s 193ms/step - loss: 0.6325 - accuracy: 0.7829 - val_loss: 0.6908 - val_accuracy: 0.8125\n",
      "Epoch 3/30\n",
      "1670/1670 [==============================] - 322s 193ms/step - loss: 0.4617 - accuracy: 0.8548 - val_loss: 0.4081 - val_accuracy: 0.9375\n",
      "Epoch 4/30\n",
      "1670/1670 [==============================] - 322s 193ms/step - loss: 0.3003 - accuracy: 0.9119 - val_loss: 0.1075 - val_accuracy: 0.9688\n",
      "Epoch 5/30\n",
      "1670/1670 [==============================] - 322s 193ms/step - loss: 0.2329 - accuracy: 0.9318 - val_loss: 0.0568 - val_accuracy: 1.0000\n",
      "Epoch 6/30\n",
      "1670/1670 [==============================] - 322s 193ms/step - loss: 0.1887 - accuracy: 0.9449 - val_loss: 0.0437 - val_accuracy: 1.0000\n",
      "Epoch 7/30\n",
      "1670/1670 [==============================] - 322s 193ms/step - loss: 0.1522 - accuracy: 0.9549 - val_loss: 0.2060 - val_accuracy: 0.8750\n",
      "Epoch 8/30\n",
      "1670/1670 [==============================] - 323s 193ms/step - loss: 0.1353 - accuracy: 0.9600 - val_loss: 0.0370 - val_accuracy: 1.0000\n",
      "Epoch 9/30\n",
      "1670/1670 [==============================] - 323s 193ms/step - loss: 0.1188 - accuracy: 0.9653 - val_loss: 0.0218 - val_accuracy: 1.0000\n",
      "Epoch 10/30\n",
      "1670/1670 [==============================] - 323s 193ms/step - loss: 0.0973 - accuracy: 0.9707 - val_loss: 0.1337 - val_accuracy: 0.9688\n",
      "Epoch 11/30\n",
      "1670/1670 [==============================] - 323s 193ms/step - loss: 0.0840 - accuracy: 0.9764 - val_loss: 0.0622 - val_accuracy: 1.0000\n",
      "Epoch 12/30\n",
      "1670/1670 [==============================] - 323s 193ms/step - loss: 0.0712 - accuracy: 0.9799 - val_loss: 0.2407 - val_accuracy: 0.8750\n",
      "Epoch 13/30\n",
      "1670/1670 [==============================] - 323s 193ms/step - loss: 0.0634 - accuracy: 0.9827 - val_loss: 0.0269 - val_accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "1670/1670 [==============================] - 323s 193ms/step - loss: 0.0542 - accuracy: 0.9852 - val_loss: 0.0342 - val_accuracy: 1.0000\n",
      "Epoch 15/30\n",
      "1670/1670 [==============================] - 323s 193ms/step - loss: 0.0443 - accuracy: 0.9883 - val_loss: 0.0107 - val_accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "1670/1670 [==============================] - 323s 193ms/step - loss: 0.0423 - accuracy: 0.9887 - val_loss: 0.0124 - val_accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "1670/1670 [==============================] - 323s 193ms/step - loss: 0.0336 - accuracy: 0.9917 - val_loss: 0.0127 - val_accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "1670/1670 [==============================] - 323s 193ms/step - loss: 0.0270 - accuracy: 0.9926 - val_loss: 0.0170 - val_accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "1670/1670 [==============================] - 323s 193ms/step - loss: 0.0259 - accuracy: 0.9939 - val_loss: 0.0151 - val_accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "1670/1670 [==============================] - 323s 193ms/step - loss: 0.0219 - accuracy: 0.9944 - val_loss: 0.0320 - val_accuracy: 0.9688\n",
      "Epoch 21/30\n",
      "1670/1670 [==============================] - 323s 194ms/step - loss: 0.0216 - accuracy: 0.9945 - val_loss: 0.0682 - val_accuracy: 0.9688\n",
      "Epoch 22/30\n",
      "1670/1670 [==============================] - 323s 193ms/step - loss: 0.0210 - accuracy: 0.9948 - val_loss: 0.0301 - val_accuracy: 0.9688\n",
      "Epoch 23/30\n",
      "1670/1670 [==============================] - 323s 193ms/step - loss: 0.0187 - accuracy: 0.9950 - val_loss: 0.0278 - val_accuracy: 0.9688\n",
      "Epoch 24/30\n",
      "1670/1670 [==============================] - 354s 212ms/step - loss: 0.0187 - accuracy: 0.9948 - val_loss: 0.0213 - val_accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "1670/1670 [==============================] - 323s 193ms/step - loss: 0.0172 - accuracy: 0.9955 - val_loss: 0.0395 - val_accuracy: 0.9688\n",
      "Epoch 26/30\n",
      "1670/1670 [==============================] - 323s 194ms/step - loss: 0.0162 - accuracy: 0.9956 - val_loss: 0.0295 - val_accuracy: 0.9688\n",
      "Epoch 27/30\n",
      "1670/1670 [==============================] - 323s 194ms/step - loss: 0.0168 - accuracy: 0.9953 - val_loss: 0.0329 - val_accuracy: 0.9688\n",
      "Epoch 28/30\n",
      "1670/1670 [==============================] - 438s 262ms/step - loss: 0.0142 - accuracy: 0.9958 - val_loss: 0.0287 - val_accuracy: 0.9688\n",
      "Epoch 29/30\n",
      "1670/1670 [==============================] - 324s 194ms/step - loss: 0.0157 - accuracy: 0.9955 - val_loss: 0.0294 - val_accuracy: 0.9688\n",
      "Epoch 30/30\n",
      "1670/1670 [==============================] - 414s 248ms/step - loss: 0.0144 - accuracy: 0.9958 - val_loss: 0.0248 - val_accuracy: 1.0000\n",
      "INFO:tensorflow:Assets written to: ../resnet/resnet_30epochs_83484_images_True_newWeights_False_lastLayerOnly_zerocenter_normalization/assets\n",
      "Test acc for resnet: 0.998967\n",
      "Done!\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import datetime\n",
    "\n",
    "maxTrain = len(y_train)\n",
    "for newWeights in [True]:\n",
    "    tLayer = [False] if newWeights else [True, False] # do not train only last layer if new weights will be produced \n",
    "    for trainLastLayerOnly in tLayer:\n",
    "        for p in [0.01, 0.025, 0.05, 0.075, 0.09, 0.1, 0.25, 0.4, 0.5, 0.6, 0.75, 0.9, 1.0]:\n",
    "            for r_state in [45687864]:\n",
    "                #X_trn, X_tst, y_trn, y_tst\n",
    "                if p < 1:\n",
    "                    X_t, _, y_t, _ = train_test_split(images, y_train, test_size=1-p, random_state=r_state)\n",
    "                else:\n",
    "                    X_t = images; y_t = y_train;\n",
    "                print(f\"Labels fraction: {sum(y_t == 1) / sum(y_train == 1)}\")\n",
    "                for net in [\"resnet\"]:\n",
    "                    print(f\"Training {net} for {p}% of train size (aka {len(X_t)} images) with pretrained: {not newWeights} and onlyLastLayersTrained: {trainLastLayerOnly}...\")\n",
    "                    model, size, normalization = emptyModelGenerator(net, newWeights=newWeights, lastOnly=trainLastLayerOnly)\n",
    "                    printTrainableLayers(model) # see if model is really well trained\n",
    "                    X_trn = resizeIms(X_t, size)\n",
    "                    #X_trn = normalizeIms(X_trn, normalization=normalization)\n",
    "                    X_val = resizeIms(x_val, size)\n",
    "                    #X_val = normalizeIms(X_val, normalization=normalization)\n",
    "                    log_dir = f\"logs/{net}/fit/{p}trainSet_\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "                    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "                    optimizer = SGD(learning_rate=learning_rate, momentum=momentum) # Adam(learning_rate) # amsgrad=amsgrad) #create new optimizers\n",
    "                    time_callback = TimeHistory()\n",
    "                    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "                    hist = model.fit(X_trn, y_t, epochs=epochs, validation_data = (X_val, y_validation), batch_size=batch_size,\n",
    "                                shuffle=True, max_queue_size=20,\n",
    "                                use_multiprocessing=True, workers=5, \n",
    "                                callbacks=[CustomCallback(fraction=0.9, model=net), tensorboard_callback, time_callback])\n",
    "                    trainTime = sum(time_callback.times)\n",
    "                    model.save(f\"../{net}/{net}_{epochs}epochs_{p*maxTrain:.0f}_images_{newWeights}_newWeights_{trainLastLayerOnly}_lastLayerOnly_{normalization}_normalization\")\n",
    "                    tstAcc = testPredict(model, size, name=net) #, normalization=normalization)\n",
    "                    results = results.append({\n",
    "                        'model': net, \n",
    "                        'train set images': len(X_t), \n",
    "                        'pretrained': not newWeights, \n",
    "                        'pretrained dataset': None if newWeights or net == \"octnet\" else (\"OCT2017,Srinivasan2014\" if net == \"opticnet\" else \"Imagenet\"),\n",
    "                        'Trained layers': \"Last dense\" if trainLastLayerOnly else \"All\", \n",
    "                        'epochs': epochs, \n",
    "                        'batch size': batch_size, \n",
    "                        'learning rate': f\"{learning_rate}_{momentum}\" if optimizer._name == \"SGD\" else learning_rate, \n",
    "                        'optimizer': optimizer._name,\n",
    "                        'training time (seconds)': trainTime, \n",
    "                        'train accuracy': hist.history[\"accuracy\"][-1], \n",
    "                        'train loss': hist.history[\"loss\"][-1],\n",
    "                        'validation accuracy': hist.history[\"val_accuracy\"][-1], \n",
    "                        'validation loss': hist.history[\"val_loss\"][-1], \n",
    "                        'test accuracy': tstAcc,\n",
    "                        #'normalization': normalization\n",
    "                    }, ignore_index=True)\n",
    "                    results.to_csv(\"Results_temp.csv\", index=False)\n",
    "                    del model\n",
    "                    del X_trn\n",
    "                    del X_val\n",
    "                    print(\"Done!\\n\" + '-'*50, end='\\n\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
