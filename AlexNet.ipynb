{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15dcfda4",
   "metadata": {},
   "source": [
    "# AlexNet implementation (with PyTorch)\n",
    "Model from: https://pytorch.org/hub/pytorch_vision_alexnet/\n",
    "\n",
    "Training loop from: https://kushaj.medium.com/training-alexnet-with-tips-and-checks-on-how-to-train-cnns-practical-cnns-in-pytorch-1-61daa679c74a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da2e53bd",
   "metadata": {},
   "source": [
    "## Import required modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25939272",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from copy import deepcopy\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import time\n",
    "import os\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e467ecf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(1234) # reproducibility seed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cdfe337",
   "metadata": {},
   "source": [
    "## Get model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe49a12",
   "metadata": {},
   "source": [
    "### Get pretrained model from source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e451b6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "alexnet = torch.hub.load('pytorch/vision:v0.9.0', 'alexnet', pretrained=True)\n",
    "alexnet.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1031d94a",
   "metadata": {},
   "source": [
    "## Data transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d04866",
   "metadata": {},
   "source": [
    "Set number of classifications labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67f2d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_labels = 4 # CNV, DME, DRUSEN, NORMAL\n",
    "labels_list = [\"CNV\", \"DME\", \"DRUSEN\", \"NORMAL\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f85d80fd",
   "metadata": {},
   "source": [
    "#### Create train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b78fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.utils import make_grid\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "data_dir = '/volume/OCT/OCT2017/'\n",
    "sets = [\"train\", \"val\", \"test\"]\n",
    "\n",
    "size = 224 # given by alexnet\n",
    "batch_size = 32 # prefered by alexnet\n",
    "\n",
    "# num_workers = 8 # only if multi-processing is needed\n",
    "\n",
    "data_transforms = {\n",
    "    set_type: transforms.Compose([\n",
    "        transforms.Resize((size, size)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ]) for set_type in sets\n",
    "}\n",
    "\n",
    "image_datasets = {\n",
    "    set_type : ImageFolder(data_dir + set_type, transform=data_transforms[set_type])\n",
    "    for set_type in sets\n",
    "}\n",
    "\n",
    "data_loader = {\n",
    "    x: torch.utils.data.DataLoader(image_datasets[x],\n",
    "                                   batch_size=batch_size,\n",
    "                                   shuffle=True,\n",
    "                                   pin_memory=True) for x in sets\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9262d95",
   "metadata": {},
   "source": [
    "Sets shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0adbb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for set_type in sets:\n",
    "    print(f\"Set: {set_type}. Images: {len(data_loader[set_type].dataset.imgs)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ab29cd",
   "metadata": {},
   "source": [
    "Check labels and images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55fcdeeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# Our images are normalized so denormalize then and convert them to numpy\n",
    "def imshow(img, title=None):\n",
    "    img = img.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    img = std*img + mean\n",
    "    img = np.clip(img, 0, 1)\n",
    "    plt.imshow(img)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.001)\n",
    "    \n",
    "\n",
    "images, labels = next(iter(data_loader['val']))\n",
    "grid_img = make_grid(images[:4], nrow=4)\n",
    "imshow(grid_img, title = [labels_list[x] for x in labels[:4]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d9d73f",
   "metadata": {},
   "source": [
    "## LIMO model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b89186c",
   "metadata": {},
   "source": [
    "### Modify architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86047d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def newAlexNet(num_labels):\n",
    "    newAlexnet = deepcopy(alexnet)\n",
    "    lastLayer = newAlexnet.classifier[-1] # get usual last layer\n",
    "    newAlexnet.classifier[-1] = nn.Linear(lastLayer.in_features, num_labels) # modify last layer number of outputs (labels to be classified)\n",
    "    return newAlexnet\n",
    "\n",
    "limoAlexnet = newAlexNet(num_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf0aa43",
   "metadata": {},
   "source": [
    "### Set hiperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed59422",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "momentum = 0.9\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb57524",
   "metadata": {},
   "source": [
    "### Loss function, optimizer and scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d626d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(limoAlexnet.parameters(), lr=learning_rate, momentum=momentum)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b42d0e3",
   "metadata": {},
   "source": [
    "### Train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763db441",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, data_loader, criterion, optimizer, scheduler = None, num_epochs=100, seed=None):\n",
    "    since = time.time()\n",
    "    if seed:\n",
    "        random .seed(seed)\n",
    "    \n",
    "    train_batch_loss = []\n",
    "    train_epoch_loss = []\n",
    "    val_epoch_loss = []\n",
    "    \n",
    "    model.to(device)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch+1, num_epochs))\n",
    "        print('-'*15)\n",
    "        \n",
    "        # You perform validation test after every epoch\n",
    "        for phase in [\"train\", \"val\"]:\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "                \n",
    "            running_loss = 0; running_corrects = 0;\n",
    "            \n",
    "            num_batches = int(len(data_loader[phase].dataset) / batch_size)\n",
    "            \n",
    "            for idx, (inputs, labels) in enumerate(data_loader[phase]):\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                \n",
    "                # zero accumulated gradients\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                # During train phase we want to remember history for grads\n",
    "                # and during val we do not want history of grads\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    \n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    \n",
    "                    if idx%200 == 0 or idx == num_batches - 1:\n",
    "                        train_batch_loss.append(loss.item())\n",
    "                        print('Epoch {}: {}/{} steps in progress'.format(epoch+1, idx+1, num_batches))\n",
    "                        \n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                        \n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "                \n",
    "            epoch_loss = running_loss / len(data_loader[phase].dataset)\n",
    "            epoch_acc = running_corrects.double() / len(data_loader[phase].dataset)\n",
    "            \n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "            \n",
    "            if phase == 'val':\n",
    "                val_epoch_loss.append((epoch_loss, epoch_acc))\n",
    "                if scheduler:\n",
    "                    scheduler.step(loss.item())\n",
    "            else:\n",
    "                train_epoch_loss.append((epoch_loss, epoch_acc))\n",
    "                \n",
    "        print()\n",
    "        \n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17dce639",
   "metadata": {},
   "source": [
    "### Train model with train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6ab1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainedLimoModel = train(limoAlexnet, data_loader, loss_fn, optimizer, scheduler, epochs, seed=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb3d917",
   "metadata": {},
   "source": [
    "Evaluate model over test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf74488f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval() # set model to be evaluated (ignore grads)\n",
    "confMatrix = np.zeros((num_labels, num_labels), dtype=\"Int64\")\n",
    "trainedLimoModel.eval()\n",
    "for batchNum, (inputs, labels) in enumerate(data_loader[\"test\"]):\n",
    "    outputs = trainedLimoModel(inputs)\n",
    "    _, preds = torch.max(outputs, 1)\n",
    "    for i, pred in enumerate(preds):\n",
    "        confMatrix[pred, labels[i]] += 1\n",
    "        \n",
    "testAcc = confMatrix.trace() / confMatrix.sum()\n",
    "print(f'Test set accuracy: {testAcc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cfb0894",
   "metadata": {},
   "source": [
    "Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1a1d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "x_axis_labels = labels_list # labels for x-axis\n",
    "y_axis_labels = labels_list # labels for y-axis\n",
    "ax = sns.heatmap(a, cmap=\"Blues\", annot=True, fmt=\"d\", xticklabels=x_axis_labels, yticklabels=y_axis_labels)\n",
    "plt.xlabel(\"Predicted label\")\n",
    "plt.ylabel(\"True label\")\n",
    "plt.title(\"Confusion matrix\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4ee278",
   "metadata": {},
   "outputs": [],
   "source": [
    "accLabel = {labels_list[lab]: confMatrix[lab, lab] / sum(confMatrix[:, lab]) for lab in range(num_labels)}\n",
    "print(\"Acc by label: {}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4395f6",
   "metadata": {},
   "source": [
    "Save model into files (saved models listed in file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9254480",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../nets/'\n",
    "netVer = len(os.listdir(path))\n",
    "netType = \"alexnet\"\n",
    "netID = \"_\".join([netType, str(netVer)])\n",
    "torch.save(trainedLimoModel, path + netID + \".pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333790e6",
   "metadata": {},
   "source": [
    "Load saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd59ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(path + netID + \".pth\")\n",
    "model.eval()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
